{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llmcoder.treeofcompletions.PriorityQueue import PriorityQueue, Conversation\n",
    "import openai\n",
    "\n",
    "messages = [\n",
    "    {\n",
    "        \"role\": \"system\",\n",
    "        \"content\": \" \"\n",
    "    }, {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": \" Please provide a cute easy code in python \"\n",
    "    }\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Please provide a cute easy code in python \n"
     ]
    }
   ],
   "source": [
    "print(messages[1][\"content\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sure! Here's a simple program that prints out different cute animals randomly from a list every time it runs:\n",
      "\n",
      "```python\n",
      "import random\n",
      "\n",
      "def print_random_animal():\n",
      "    animals = ['Kitten', 'Puppy', 'Bunny']\n",
      "    random_animal = random.choice(animals)\n",
      "    print(random_animal)\n",
      "\n",
      "print_random_animal()\n",
      "```\n",
      "\n",
      "Every time you run this program, it will print out a random animal from the list `['Kitten', 'Puppy', 'Bunny']`. It could be a Kitten, a Puppy, or a Bunny.\n",
      "\n",
      "You can feel free to add or modify the list of animals as per your preferences.\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "from llmcoder.utils import get_openai_key\n",
    "\n",
    "client = OpenAI(api_key = get_openai_key())\n",
    "messages = client.chat.completions.create(messages=messages, model=\"gpt-3.5-turbo\", temperature=1.5, n = 3)\n",
    "print(messages.choices[0].message.content)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sure! Here's a fun little program that prints a heart shape using ASCII art: \n",
      "\n",
      "```python\n",
      "print(\"    ♥ ♥\")\n",
      "print(\"  ♥     ♥\")\n",
      "print(\" ♥       ♥\")\n",
      "print(\"  ♥     ♥\")\n",
      "print(\"    ♥ ♥\")\n",
      "```\n",
      "\n",
      "When you run this code, you'll see a heart symbol printed out in the console like this:\n",
      "\n",
      "```\n",
      "    ♥ ♥\n",
      "  ♥     ♥\n",
      " ♥       ♥\n",
      "  ♥     ♥\n",
      "    ♥ ♥\n",
      "```\n",
      "\n",
      "Feel free to modify, add, or combine ASCII art elements to create your own cute patterns!\n"
     ]
    }
   ],
   "source": [
    "print(messages.choices[1].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[9.47950441]\n"
     ]
    }
   ],
   "source": [
    "from llmcoder.analyze.GPTScoreAnalyzer import GPTScoreAnalyzer\n",
    "analyzer = GPTScoreAnalyzer()\n",
    "score1 = analyzer.score_code(messages.choices[1].message.content)\n",
    "print(score1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Choice(finish_reason='stop', index=1, logprobs=None, message=ChatCompletionMessage(content='Certainly! Here\\'s a simple code that simulates a little animal that sleepily opens its eyes whenever its name is called:\\n\\n```python\\nname = input(\"Enter your animal\\\\\\'s name: \")\\n\\ndef animal_wakes_up(name):\\n    print(f\"{name} gently opens its eyes and looks at you.\")\\n\\n# Somewhere in the code...\\nanimal_wakes_up(name)\\n```\\n\\nHope that solves your query! Is there anything specific you would like to learn or explore further?', role='assistant', function_call=None, tool_calls=None)),)\n"
     ]
    }
   ],
   "source": [
    "import heapq\n",
    "analyzer_results_history = \"\"\n",
    "priority_queue = PriorityQueue()\n",
    "conversation1 = Conversation(score1, messages.choices[1], analyzer_results_history)\n",
    "# conversations = [(conversation1, conversation2)]\n",
    "# priority_queue.create_priority_queue(conversations)\n",
    "priority_queue.push(conversation1)\n",
    "conversation = priority_queue.get_highest_scored_conversation()\n",
    "print(conversation._get_messages())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'PriorityQueue' from 'llmcoder' (C:\\Users\\anaca\\Documents\\quinto.curso\\ai.tools\\llmcoder\\23ws-LLMcoder\\src\\llmcoder\\__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mllmcoder\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m LLMCoder\n\u001b[0;32m      2\u001b[0m llmcoder \u001b[38;5;241m=\u001b[39m LLMCoder(log_conversation\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m      3\u001b[0m conversation \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\Documents\\quinto.curso\\ai.tools\\llmcoder\\23ws-LLMcoder\\src\\llmcoder\\LLMCoder.py:8\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mconcurrent\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfutures\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ThreadPoolExecutor\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdatetime\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m datetime\n\u001b[1;32m----> 8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mllmcoder\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m PriorityQueue, Conversation\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mopenai\u001b[39;00m\n",
      "\u001b[1;31mImportError\u001b[0m: cannot import name 'PriorityQueue' from 'llmcoder' (C:\\Users\\anaca\\Documents\\quinto.curso\\ai.tools\\llmcoder\\23ws-LLMcoder\\src\\llmcoder\\__init__.py)"
     ]
    }
   ],
   "source": [
    "from llmcoder import LLMCoder\n",
    "llmcoder = LLMCoder(log_conversation=False)\n",
    "conversation = None\n",
    "llmcoder._add_message_to_conversation(\"user\", conversation, message = messages[1][\"content\"], model= \"gpt-3.5-turbo\", n = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'llmcoder' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[15], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m results \u001b[38;5;241m=\u001b[39m llmcoder\u001b[38;5;241m.\u001b[39m_get_completions(temperature \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.7\u001b[39m, n \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m3\u001b[39m)\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m result \u001b[38;5;129;01min\u001b[39;00m results:\n\u001b[0;32m      4\u001b[0m     valid_choices, analysis_results_list, candidate_scores \u001b[38;5;241m=\u001b[39m result\n",
      "\u001b[1;31mNameError\u001b[0m: name 'llmcoder' is not defined"
     ]
    }
   ],
   "source": [
    "results = llmcoder._get_completions(temperature = 0.7, n = 3)\n",
    "\n",
    "for result in results:\n",
    "    valid_choices, analysis_results_list, candidate_scores = result\n",
    "    print(candidate_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv_python",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
