{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llmcoder import LLMCoder\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_code = '''from llmcoder import LLMCoder\n",
    "\n",
    "# Create an LLMCoder with the \"mypy_analyzer_v1\" and up to three feedback iterations.\n",
    "llmcoder = LLMCoder('''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear LLMcoder with Mypy, Signatures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "llmcoder = LLMCoder(\n",
    "    analyzers=[\"mypy_analyzer_v1\", \"signature_analyzer_v1\"],\n",
    "    max_iter=3,\n",
    "    feedback_variant=\"coworker\", verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# By default, only generate one completion\n",
    "completion = llmcoder.complete(user_code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "analyzers=[\"mypy_analyzer_v1\"], max_iter=3)\n"
     ]
    }
   ],
   "source": [
    "# Final Completion\n",
    "print(completion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SYSTEM\n",
      "You are AutocompleteGPT, a useful AI autocomplete tool that provides code completions based on the user's code.\n",
      "You are a precision-focused tool for code autocompletion, adept in languages like Python, JavaScript, C++, and SQL.\n",
      "Precisely continue the code from the point of interruption and do not repeat or modify the original code, even if it is incorrect or the code interrupts in the middle of a line.\n",
      "Your code is well documented with comments and annotations, and you should provide a clear explanation of the code's purpose in your code completion.\n",
      "Your unique capability is to provide completions without altering, repeating, or commenting on the original code.\n",
      "You offer only the necessary code to complete the snippet, ensuring the response is exclusively code, with no additional comments, explanations, or annotations.\n",
      "This approach makes you an ideal assistant for users seeking straightforward and efficient code extensions, enhancing their work with accurate, logic-driven completions while maintaining the integrity and simplicity of the original input.\n",
      "Your response begins with the next characters of the line if the last line of the user's code is incomplete, or the next line if the last line of the user's code is complete.\n",
      "Your application is a VSCode extension like GitHub Copilot, which provides seamless code completions based on the user's code at the point of interruption.\n",
      "--------------------------------------------------------------------------------\n",
      "USER\n",
      "from llmcoder import LLMCoder\n",
      "\n",
      "# Create an LLMCoder with the \"mypy_analyzer_v1\" and up to three feedback iterations.\n",
      "llmcoder = LLMCoder(\n",
      "--------------------------------------------------------------------------------\n",
      "ASSISTANT\n",
      "\"mypy_analyzer_v1\", feedback_iterations=3)\n",
      "--------------------------------------------------------------------------------\n",
      "USER\n",
      "[INST]\n",
      "The completion you provided resulted in the following errors:\n",
      "your completion:4: error: Unexpected keyword argument \"feedback_iterations\" for \"LLMCoder\"  [call-arg]\n",
      "/home/paulsaegert/23ws-LLMcoder/src/llmcoder/LLMCoder.py:38: note: \"LLMCoder\" defined here\n",
      "your completion:4: error: Argument 1 to \"LLMCoder\" has incompatible type \"str\"; expected \"list[str]\"  [arg-type]\n",
      "Found 2 errors in 1 file (checked 1 source file)\n",
      "To fix these errors, use these ground truth signatures as a reference for your next completion:\n",
      "LLMCoder: (analyzers: list[str] = None, model_first: str = 'ft:gpt-3.5-turbo-1106:personal::8LCi9Q0d', model_feedback: str = 'gpt-3.5-turbo', feedback_variant: str = 'separate', system_prompt: str | None = None, max_iter: int = 10, log_conversation: bool = True, n_procs: int = 1, verbose: bool = True) -> None\n",
      "\n",
      "Fix, improve and rewrite your completion for the following code:\n",
      "[/INST]\n",
      "from llmcoder import LLMCoder\n",
      "\n",
      "# Create an LLMCoder with the \"mypy_analyzer_v1\" and up to three feedback iterations.\n",
      "llmcoder = LLMCoder(\n",
      "--------------------------------------------------------------------------------\n",
      "ASSISTANT\n",
      "analyzers=[\"mypy_analyzer_v1\"], max_iter=3)\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Conversation\n",
    "for message in llmcoder.messages:\n",
    "    print(message['role'].upper())\n",
    "    print(message['content'])\n",
    "    print('-' * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tree LLMcoder with Mypy, Signatures, and GPT-Scoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "llmcoder = LLMCoder(\n",
    "    analyzers=[\"mypy_analyzer_v1\", \"signature_analyzer_v1\", \"gpt_score_analyzer_v1\"],\n",
    "    max_iter=3,\n",
    "    feedback_variant=\"coworker\",\n",
    "    n_procs=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LLMcoder] Creating first completion...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LLMcoder] Analyzing 4 completions...\n",
      "[LLMcoder] Analyzing code in coworker mode...\n",
      "[LLMcoder] Running mypy_analyzer_v1...\n",
      "[LLMcoder] Analyzing code in coworker mode...\n",
      "[LLMcoder] Running mypy_analyzer_v1...\n",
      "[LLMcoder] Analyzing code in coworker mode...\n",
      "[LLMcoder] Running mypy_analyzer_v1...\n",
      "[LLMcoder] Analyzing code in coworker mode...\n",
      "[LLMcoder] Running mypy_analyzer_v1...\n",
      "[Mypy] No missing stubs found.\n",
      "[Mypy] /tmp/tmpolvhmels.py:4: error: Unexpected keyword argument \"model\" for \"LLMCoder\"  [call-arg]\n",
      "[Mypy] /tmp/tmpolvhmels.py:4: error: Unexpected keyword argument \"feedback\" for \"LLMCoder\"  [call-arg]\n",
      "[Mypy] Found 2 errors in 1 file (checked 1 source file)\n",
      "[LLMcoder] Running signature_analyzer_v1...\n",
      "[Signatures] Using context from previous analyzers: ['mypy_analyzer_v1']\n",
      "[Signatures] Found problematic function or class: LLMCoder\n",
      "[Signatures] Found problematic function or class: LLMCoder\n",
      "[Mypy] No missing stubs found.\n",
      "[Mypy] /tmp/tmp1tbv9ntl.py:4: error: Unexpected keyword argument \"max_iterations\" for \"LLMCoder\"  [call-arg]\n",
      "[Mypy] /tmp/tmp1tbv9ntl.py:4: error: Argument 1 to \"LLMCoder\" has incompatible type \"str\"; expected \"list[str]\"  [arg-type]\n",
      "[Mypy] Found 2 errors in 1 file (checked 1 source file)\n",
      "[Signatures] module_alias='llmcoder' func_name='LLMCoder'\n",
      "[Signatures] Got signatures and documentations:\n",
      "[Signatures] LLMCoder: (analyzers: list[str] = None, model_first: str = 'ft:gpt-3.5-turbo-1106:personal::8LCi9Q0d', model_feedback: str = 'gpt-3.5-turbo', feedback_variant: str = 'separate', system_prompt: str | None = None, max_iter: int = 10, log_conversation: bool = True, n_procs: int = 1, verbose: bool = True) -> None, Initialize the LLMCoder\n",
      "[LLMcoder] Running signature_analyzer_v1...\n",
      "[LLMcoder] Running gpt_score_analyzer_v1...\n",
      "[Signatures] Using context from previous analyzers: ['mypy_analyzer_v1']\n",
      "[Signatures] Found problematic function or class: LLMCoder\n",
      "[Signatures] Found problematic function or class: LLMCoder\n",
      "[Signatures] module_alias='llmcoder' func_name='LLMCoder'\n",
      "[Signatures] Got signatures and documentations:\n",
      "[Signatures] LLMCoder: (analyzers: list[str] = None, model_first: str = 'ft:gpt-3.5-turbo-1106:personal::8LCi9Q0d', model_feedback: str = 'gpt-3.5-turbo', feedback_variant: str = 'separate', system_prompt: str | None = None, max_iter: int = 10, log_conversation: bool = True, n_procs: int = 1, verbose: bool = True) -> None, Initialize the LLMCoder\n",
      "[LLMcoder] Running gpt_score_analyzer_v1...\n",
      "[Mypy] No missing stubs found.\n",
      "[Mypy] /tmp/tmp4te4t8_c.py:4: error: Unexpected keyword argument \"model\" for \"LLMCoder\"  [call-arg]\n",
      "[Mypy] /tmp/tmp4te4t8_c.py:4: error: Unexpected keyword argument \"max_iterations\" for \"LLMCoder\"  [call-arg]\n",
      "[Mypy] Found 2 errors in 1 file (checked 1 source file)\n",
      "[LLMcoder] Running signature_analyzer_v1...\n",
      "[Signatures] Using context from previous analyzers: ['mypy_analyzer_v1']\n",
      "[Signatures] Found problematic function or class: LLMCoder\n",
      "[Signatures] Found problematic function or class: LLMCoder\n",
      "[Signatures] module_alias='llmcoder' func_name='LLMCoder'\n",
      "[Signatures] Got signatures and documentations:\n",
      "[Signatures] LLMCoder: (analyzers: list[str] = None, model_first: str = 'ft:gpt-3.5-turbo-1106:personal::8LCi9Q0d', model_feedback: str = 'gpt-3.5-turbo', feedback_variant: str = 'separate', system_prompt: str | None = None, max_iter: int = 10, log_conversation: bool = True, n_procs: int = 1, verbose: bool = True) -> None, Initialize the LLMCoder\n",
      "[LLMcoder] Running gpt_score_analyzer_v1...\n",
      "[Mypy] No missing stubs found.\n",
      "[Mypy] /tmp/tmpnw_a4jq3.py:4: error: Unexpected keyword argument \"model\" for \"LLMCoder\"  [call-arg]\n",
      "[Mypy] /tmp/tmpnw_a4jq3.py:4: error: Unexpected keyword argument \"feedback_iterations\" for \"LLMCoder\"  [call-arg]\n",
      "[Mypy] Found 2 errors in 1 file (checked 1 source file)\n",
      "[LLMcoder] Running signature_analyzer_v1...\n",
      "[Signatures] Using context from previous analyzers: ['mypy_analyzer_v1']\n",
      "[Signatures] Found problematic function or class: LLMCoder\n",
      "[Signatures] Found problematic function or class: LLMCoder\n",
      "[Signatures] module_alias='llmcoder' func_name='LLMCoder'\n",
      "[Signatures] Got signatures and documentations:\n",
      "[Signatures] LLMCoder: (analyzers: list[str] = None, model_first: str = 'ft:gpt-3.5-turbo-1106:personal::8LCi9Q0d', model_feedback: str = 'gpt-3.5-turbo', feedback_variant: str = 'separate', system_prompt: str | None = None, max_iter: int = 10, log_conversation: bool = True, n_procs: int = 1, verbose: bool = True) -> None, Initialize the LLMCoder\n",
      "[LLMcoder] Running gpt_score_analyzer_v1...\n",
      "[Scoring] Choosing message 0 with score 6.211558703193814\n",
      "[LLMcoder] 0 / 1 analyzers passed\n",
      "[LLMcoder] Starting feedback loop...\n",
      "[LLMcoder] Starting feedback iteration 1...\n",
      "[LLMcoder] Analyzing 4 completions...\n",
      "[LLMcoder] Analyzing code in coworker mode...\n",
      "[LLMcoder] Running mypy_analyzer_v1...\n",
      "[LLMcoder] Analyzing code in coworker mode...\n",
      "[LLMcoder] Running mypy_analyzer_v1...\n",
      "[LLMcoder] Analyzing code in coworker mode...\n",
      "[LLMcoder] Running mypy_analyzer_v1...\n",
      "[LLMcoder] Analyzing code in coworker mode...\n",
      "[LLMcoder] Running mypy_analyzer_v1...\n",
      "[Mypy] No missing stubs found.\n",
      "[Mypy] Success: no issues found in 1 source file\n",
      "[LLMcoder] Running signature_analyzer_v1...\n",
      "[Signatures] Using context from previous analyzers: ['mypy_analyzer_v1']\n",
      "[Signatures] No problematic functions or classes found in the context.\n",
      "[Mypy] No missing stubs found.\n",
      "[Mypy] Success: no issues found in 1 source file\n",
      "[LLMcoder] Running gpt_score_analyzer_v1...\n",
      "[LLMcoder] Running signature_analyzer_v1...\n",
      "[Signatures] Using context from previous analyzers: ['mypy_analyzer_v1']\n",
      "[Signatures] No problematic functions or classes found in the context.\n",
      "[LLMcoder] Running gpt_score_analyzer_v1...\n",
      "[Mypy] No missing stubs found.\n",
      "[Mypy] Success: no issues found in 1 source file\n",
      "[LLMcoder] Running signature_analyzer_v1...\n",
      "[Signatures] Using context from previous analyzers: ['mypy_analyzer_v1']\n",
      "[Signatures] No problematic functions or classes found in the context.\n",
      "[LLMcoder] Running gpt_score_analyzer_v1...\n",
      "[Mypy] No missing stubs found.\n",
      "[Mypy] Success: no issues found in 1 source file\n",
      "[LLMcoder] Running signature_analyzer_v1...\n",
      "[Signatures] Using context from previous analyzers: ['mypy_analyzer_v1']\n",
      "[Signatures] No problematic functions or classes found in the context.\n",
      "[LLMcoder] Running gpt_score_analyzer_v1...\n",
      "[Scoring] Choosing message 0 with score 9.211558703193814\n",
      "[LLMcoder] 1 / 1 analyzers passed\n"
     ]
    }
   ],
   "source": [
    "# Analyze four completions in parallel\n",
    "completion = llmcoder.complete(user_code, n=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "analyzers=[\"mypy_analyzer_v1\"], max_iter=3)\n"
     ]
    }
   ],
   "source": [
    "# Final Completion\n",
    "print(completion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SYSTEM\n",
      "You are AutocompleteGPT, a useful AI autocomplete tool that provides code completions based on the user's code.\n",
      "You are a precision-focused tool for code autocompletion, adept in languages like Python, JavaScript, C++, and SQL.\n",
      "Precisely continue the code from the point of interruption and do not repeat or modify the original code, even if it is incorrect or the code interrupts in the middle of a line.\n",
      "Your code is well documented with comments and annotations, and you should provide a clear explanation of the code's purpose in your code completion.\n",
      "Your unique capability is to provide completions without altering, repeating, or commenting on the original code.\n",
      "You offer only the necessary code to complete the snippet, ensuring the response is exclusively code, with no additional comments, explanations, or annotations.\n",
      "This approach makes you an ideal assistant for users seeking straightforward and efficient code extensions, enhancing their work with accurate, logic-driven completions while maintaining the integrity and simplicity of the original input.\n",
      "Your response begins with the next characters of the line if the last line of the user's code is incomplete, or the next line if the last line of the user's code is complete.\n",
      "Your application is a VSCode extension like GitHub Copilot, which provides seamless code completions based on the user's code at the point of interruption.\n",
      "--------------------------------------------------------------------------------\n",
      "USER\n",
      "from llmcoder import LLMCoder\n",
      "\n",
      "# Create an LLMCoder with the \"mypy_analyzer_v1\" and up to three feedback iterations.\n",
      "llmcoder = LLMCoder(\n",
      "--------------------------------------------------------------------------------\n",
      "ASSISTANT\n",
      "model=\"mypy_analyzer_v1\", feedback_iterations=3)\n",
      "--------------------------------------------------------------------------------\n",
      "USER\n",
      "[INST]\n",
      "The completion you provided resulted in the following errors:\n",
      "your completion:4: error: Unexpected keyword argument \"model\" for \"LLMCoder\"  [call-arg]\n",
      "your completion:4: error: Unexpected keyword argument \"feedback_iterations\" for \"LLMCoder\"  [call-arg]\n",
      "Found 2 errors in 1 file (checked 1 source file)\n",
      "To fix these errors, use these ground truth signatures as a reference for your next completion:\n",
      "LLMCoder: (analyzers: list[str] = None, model_first: str = 'ft:gpt-3.5-turbo-1106:personal::8LCi9Q0d', model_feedback: str = 'gpt-3.5-turbo', feedback_variant: str = 'separate', system_prompt: str | None = None, max_iter: int = 10, log_conversation: bool = True, n_procs: int = 1, verbose: bool = True) -> None\n",
      "\n",
      "Fix, improve and rewrite your completion for the following code:\n",
      "[/INST]\n",
      "from llmcoder import LLMCoder\n",
      "\n",
      "# Create an LLMCoder with the \"mypy_analyzer_v1\" and up to three feedback iterations.\n",
      "llmcoder = LLMCoder(\n",
      "--------------------------------------------------------------------------------\n",
      "ASSISTANT\n",
      "analyzers=[\"mypy_analyzer_v1\"], max_iter=3)\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Conversation\n",
    "for message in llmcoder.messages:\n",
    "    print(message['role'].upper())\n",
    "    print(message['content'])\n",
    "    print('-' * 80)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llmcoder",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
