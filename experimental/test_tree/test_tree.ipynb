{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llmcoder.treeofcompletions.PriorityQueue import PriorityQueue, Conversation\n",
    "import openai\n",
    "\n",
    "messages = [\n",
    "    {\n",
    "        \"role\": \"system\",\n",
    "        \"content\": \"You are AutocompleteGPT, a useful AI autocomplete tool that provides code completions based on the user's code.\"\n",
    "    }, {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": \" Please provide a cute easy code in python \"\n",
    "    }\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sure! Here's a simple Python code that prints a cute message:\n",
      "\n",
      "```python\n",
      "print(\"You are cute!\")\n",
      "```\n",
      "\n",
      "When you run this code, it will output the message \"You are cute!\" to the console. Feel free to customize the message to suit your needs!\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "from llmcoder.utils import get_openai_key\n",
    "\n",
    "client = OpenAI(api_key = get_openai_key())\n",
    "completions = client.chat.completions.create(messages=messages, model=\"gpt-3.5-turbo\", temperature=0.7, n = 3)\n",
    "print(completions.choices[0].message.content)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[9.45741609]\n"
     ]
    }
   ],
   "source": [
    "from llmcoder.analyze.GPTScoreAnalyzer import GPTScoreAnalyzer\n",
    "analyzer = GPTScoreAnalyzer()\n",
    "score = analyzer.score_code(completions.choices[1].message.content)\n",
    "print(score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'role': 'system',\n",
       "  'content': \"You are AutocompleteGPT, a useful AI autocomplete tool that provides code completions based on the user's code. You are a precision-focused tool for code autocompletion, adept in languages like Python, JavaScript, C++, and SQL. Precisely continue the code from the point of interruption and do not repeat or modify the original code, even if it is incorrect or the code interrupts in the middle of a line. Your code is well documented with comments and annotations, and you should provide a clear explanation of the code's purpose in your code completion. Your unique capability is to provide completions without altering, repeating, or commenting on the original code. Your response begins with the next characters of the line if the last line of the user's code is incomplete, or the next line if the last line of the user's code is complete. Your application is a VSCode extension like GitHub Copilot, which provides seamless code completions based on the user's code at the point of interruption.\"},\n",
       " {'role': 'user', 'content': ' Please provide a cute easy code in python '}]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "conversation = Conversation(score, messages=messages, analyzer_results_history=[])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'role': 'system',\n",
       "  'content': \"You are AutocompleteGPT, a useful AI autocomplete tool that provides code completions based on the user's code.\"},\n",
       " {'role': 'user', 'content': ' Please provide a cute easy code in python '}]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation._get_messages()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_message = {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": completions.choices[1].message.content,\n",
    "            }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation._add_message(new_message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'role': 'system',\n",
       "  'content': \"You are AutocompleteGPT, a useful AI autocomplete tool that provides code completions based on the user's code.\"},\n",
       " {'role': 'user', 'content': ' Please provide a cute easy code in python '},\n",
       " {'role': 'system',\n",
       "  'content': 'Sure! Here\\'s a simple Python code that prints a cute message:\\n\\n```python\\nprint(\"Hello, cutie!\")\\n```\\n\\nFeel free to run this code and enjoy the cute message!'}]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation._get_messages()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' Please provide a cute easy code in python Sure! Here\\'s a cute and easy code in Python that prints a heart shape:\\n\\n```python\\nheart = [\\n    \"  ❤️ ❤️  \",\\n    \"❤️     ❤️\",\\n    \" ❤️   ❤️ \",\\n    \"  ❤️ ❤️  \"\\n]\\n\\nfor line in heart:\\n    print(line)\\n```\\n\\nWhen you run this code, it will display a heart shape using ASCII characters. Enjoy!'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "code = conversation._get_messages()[1][\"content\"] + conversation._get_last_message()\n",
    "code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We have created 3 completions and have 3 valid choices\n",
      "We will analyze the following completion: Here's another cute code snippet in Python that generates a random cute animal name:\n",
      "\n",
      "```python\n",
      "import random\n",
      "\n",
      "cute_animals = [\"Fluffy\", \"Bubbles\", \"Cupcake\", \"Snuggles\", \"Nibbles\"]\n",
      "\n",
      "random_name = random.choice(cute_animals)\n",
      "print(\"Your cute animal name is:\", random_name)\n",
      "```\n",
      "\n",
      "Each time you run this code, it will randomly select a cute animal name from the list and print it out. Have fun with your adorable animal name!\n",
      "Choices printed.\n",
      "[LLMcoder] Analyzing 3 completions...\n",
      "[LLMcoder] Analyzing code in separate mode...\n",
      "[LLMcoder] Running mypy_analyzer_v1...\n",
      "[MyPy] Received input:  Please provide a cute easy code in python \n",
      "[MyPy] Received completion: Here's another simple Python code that generates a random cute animal name:\n",
      "\n",
      "```python\n",
      "import random\n",
      "\n",
      "cute_animals = ['Bunny', 'Kitten', 'Panda', 'Puppy', 'Otter']\n",
      "random_animal = random.choice(cute_animals)\n",
      "\n",
      "print(\"Your cute animal name is:\", random_animal)\n",
      "```\n",
      "\n",
      "Each time you run this code, it will pick a random cute animal name from the list and display it as your cute animal name. Have fun!\n",
      "[LLMcoder] Analyzing code in separate mode...\n",
      "[LLMcoder] Running mypy_analyzer_v1...\n",
      "[LLMcoder] An exception occurred during analysis of choice: I/O operation on closed file.\n",
      "[MyPy] Received input:  Please provide a cute easy code in python \n",
      "[MyPy] Received completion: Here's a cute Python code that generates a random compliment:\n",
      "\n",
      "```python\n",
      "import random\n",
      "\n",
      "compliments = [\n",
      "    \"You're absolutely adorable!\",\n",
      "    \"You have the sweetest smile!\",\n",
      "    \"You're as cute as a button!\",\n",
      "    \"You brighten up my day!\",\n",
      "    \"You're a ray of sunshine!\",\n",
      "]\n",
      "\n",
      "random_compliment = random.choice(compliments)\n",
      "print(random_compliment)\n",
      "```\n",
      "\n",
      "Each time you run this code, it will output a random compliment. Enjoy the positive vibes!\n",
      "[LLMcoder] Analyzing code in separate mode...\n",
      "[LLMcoder] Running mypy_analyzer_v1...\n",
      "[MyPy] Received input:  Please provide a cute easy code in python \n",
      "[MyPy] Received completion: Here's another cute code snippet in Python that generates a random cute animal name:\n",
      "\n",
      "```python\n",
      "import random\n",
      "\n",
      "cute_animals = [\"Fluffy\", \"Bubbles\", \"Cupcake\", \"Snuggles\", \"Nibbles\"]\n",
      "\n",
      "random_name = random.choice(cute_animals)\n",
      "print(\"Your cute animal name is:\", random_name)\n",
      "```\n",
      "\n",
      "Each time you run this code, it will randomly select a cute animal name from the list and print it out. Have fun with your adorable animal name!\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "I/O operation on closed file.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 10\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mllmcoder\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mLLMCoder\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m LLMCoder\n\u001b[0;32m      2\u001b[0m llmcoder \u001b[38;5;241m=\u001b[39m LLMCoder(analyzers \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmypy_analyzer_v1\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[0;32m      3\u001b[0m                     model_first \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mft:gpt-3.5-turbo-1106:personal::8LCi9Q0d\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m      4\u001b[0m                     model_feedback \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgpt-3.5-turbo\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m      8\u001b[0m                     log_conversation\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, \n\u001b[0;32m      9\u001b[0m                     )\n\u001b[1;32m---> 10\u001b[0m llmcoder\u001b[38;5;241m.\u001b[39m_get_completions_for(conversation, n\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m)\n",
      "File \u001b[1;32m~\\Documents\\quinto.curso\\ai.tools\\llmcoder\\23ws-LLMcoder\\src\\llmcoder\\LLMCoder.py:324\u001b[0m, in \u001b[0;36mLLMCoder._get_completions_for\u001b[1;34m(self, conversation, model, temperature, n)\u001b[0m\n\u001b[0;32m    322\u001b[0m             \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose:\n\u001b[0;32m    323\u001b[0m                 \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[LLMcoder] An exception occurred during analysis of choice: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mexc\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 324\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m exc\n\u001b[0;32m    325\u001b[0m             \u001b[38;5;66;03m# analysis_results_list.append({\u001b[39;00m\n\u001b[0;32m    326\u001b[0m             \u001b[38;5;66;03m#     \"score\": -np.inf,\u001b[39;00m\n\u001b[0;32m    327\u001b[0m             \u001b[38;5;66;03m#     \"type\": \"ignore\",\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    331\u001b[0m \n\u001b[0;32m    332\u001b[0m \u001b[38;5;66;03m# Select the best completion\u001b[39;00m\n\u001b[0;32m    333\u001b[0m best_conversation \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconversations\u001b[38;5;241m.\u001b[39mget_highest_scored_conversation()\n",
      "File \u001b[1;32m~\\Documents\\quinto.curso\\ai.tools\\llmcoder\\23ws-LLMcoder\\src\\llmcoder\\LLMCoder.py:306\u001b[0m, in \u001b[0;36mLLMCoder._get_completions_for\u001b[1;34m(self, conversation, model, temperature, n)\u001b[0m\n\u001b[0;32m    303\u001b[0m future \u001b[38;5;241m=\u001b[39m choice_to_future[i]\n\u001b[0;32m    304\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    305\u001b[0m     \u001b[38;5;66;03m# Update the analyzer results history with the results of total completion\u001b[39;00m\n\u001b[1;32m--> 306\u001b[0m     analysis_results \u001b[38;5;241m=\u001b[39m future\u001b[38;5;241m.\u001b[39mresult()\n\u001b[0;32m    307\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe analysis results are: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00manalysis_results\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    308\u001b[0m     analysis_results_list\u001b[38;5;241m.\u001b[39mappend(analysis_results)\n",
      "File \u001b[1;32mc:\\Users\\anaca\\miniconda3\\envs\\llmcoder_env\\Lib\\concurrent\\futures\\_base.py:456\u001b[0m, in \u001b[0;36mFuture.result\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    454\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m CancelledError()\n\u001b[0;32m    455\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;241m==\u001b[39m FINISHED:\n\u001b[1;32m--> 456\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__get_result()\n\u001b[0;32m    457\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    458\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTimeoutError\u001b[39;00m()\n",
      "File \u001b[1;32mc:\\Users\\anaca\\miniconda3\\envs\\llmcoder_env\\Lib\\concurrent\\futures\\_base.py:401\u001b[0m, in \u001b[0;36mFuture.__get_result\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    399\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception:\n\u001b[0;32m    400\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 401\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception\n\u001b[0;32m    402\u001b[0m     \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    403\u001b[0m         \u001b[38;5;66;03m# Break a reference cycle with the exception in self._exception\u001b[39;00m\n\u001b[0;32m    404\u001b[0m         \u001b[38;5;28mself\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\anaca\\miniconda3\\envs\\llmcoder_env\\Lib\\concurrent\\futures\\thread.py:58\u001b[0m, in \u001b[0;36m_WorkItem.run\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     55\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[0;32m     57\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 58\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfn(\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkwargs)\n\u001b[0;32m     59\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[0;32m     60\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfuture\u001b[38;5;241m.\u001b[39mset_exception(exc)\n",
      "File \u001b[1;32m~\\Documents\\quinto.curso\\ai.tools\\llmcoder\\23ws-LLMcoder\\src\\llmcoder\\LLMCoder.py:460\u001b[0m, in \u001b[0;36mLLMCoder.run_analyzers\u001b[1;34m(self, code, completion)\u001b[0m\n\u001b[0;32m    458\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose:\n\u001b[0;32m    459\u001b[0m             \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[LLMcoder] Running \u001b[39m\u001b[38;5;132;01m{\u001b[39;00manalyzer_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 460\u001b[0m         analyzer_results[analyzer_name] \u001b[38;5;241m=\u001b[39m analyzer_instance\u001b[38;5;241m.\u001b[39manalyze(code, completion)\n\u001b[0;32m    462\u001b[0m \u001b[38;5;66;03m# In coworker mode, the analyzers are run in parallel and share a context\u001b[39;00m\n\u001b[0;32m    463\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfeedback_variant \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcoworker\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[1;32m~\\Documents\\quinto.curso\\ai.tools\\llmcoder\\23ws-LLMcoder\\src\\llmcoder\\analyze\\MypyAnalyzer.py:65\u001b[0m, in \u001b[0;36mMypyAnalyzer.analyze\u001b[1;34m(self, input, completion, install_stubs, mypy_args, context)\u001b[0m\n\u001b[0;32m     63\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[MyPy] Received completion: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcompletion\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     64\u001b[0m \u001b[38;5;66;03m# Write a line of text to the file\u001b[39;00m\n\u001b[1;32m---> 65\u001b[0m completion_file\u001b[38;5;241m.\u001b[39mwrite(code)\n\u001b[0;32m     67\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tempfile\u001b[38;5;241m.\u001b[39mNamedTemporaryFile(delete\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, suffix\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.py\u001b[39m\u001b[38;5;124m\"\u001b[39m, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m temp_file:\n\u001b[0;32m     68\u001b[0m     temp_file_name \u001b[38;5;241m=\u001b[39m temp_file\u001b[38;5;241m.\u001b[39mname\n",
      "\u001b[1;31mValueError\u001b[0m: I/O operation on closed file."
     ]
    }
   ],
   "source": [
    "from llmcoder.LLMCoder import LLMCoder\n",
    "llmcoder = LLMCoder(analyzers = [\"mypy_analyzer_v1\"],\n",
    "                    feedback_variant = \"separate\",\n",
    "                    max_iter = 2,\n",
    "                    verbose = True,\n",
    "                    log_conversation=False, \n",
    "                    )\n",
    "llmcoder._get_completions_for(conversation, n=3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv_python",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
