{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llmcoder.treeofcompletions.PriorityQueue import PriorityQueue, Conversation\n",
    "import openai\n",
    "\n",
    "messages = [\n",
    "    {\n",
    "        \"role\": \"system\",\n",
    "        \"content\": \"You are AutocompleteGPT, a useful AI autocomplete tool that provides code completions based on the user's code.\"\n",
    "    }, {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": \" Please provide a cute easy code in python \"\n",
    "    }\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sure! How about a simple Python code that generates a random cute animal fact? Here's an example:\n",
      "\n",
      "```python\n",
      "import random\n",
      "\n",
      "animal_facts = [\n",
      "    \"Did you know that a group of pugs is called a grumble?\",\n",
      "    \"Did you know that baby pandas are called cubs?\",\n",
      "    \"Did you know that otters hold hands when they sleep so they don't drift apart?\",\n",
      "    \"Did you know that baby bunnies are called kits?\",\n",
      "    \"Did you know that dolphins have names for each other?\",\n",
      "    \"Did you know that baby kangaroos are called joeys?\",\n",
      "]\n",
      "\n",
      "# Generate a random cute animal fact\n",
      "random_fact = random.choice(animal_facts)\n",
      "print(random_fact)\n",
      "```\n",
      "\n",
      "This code randomly selects a fact from a list of cute animal facts and prints it to the console. Each time you run the code, you'll get a different fact!\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "from llmcoder.utils import get_openai_key\n",
    "\n",
    "client = OpenAI(api_key = get_openai_key())\n",
    "completions = client.chat.completions.create(messages=messages, model=\"gpt-3.5-turbo\", temperature=0.7, n = 3)\n",
    "print(completions.choices[0].message.content)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[9.2115587]\n"
     ]
    }
   ],
   "source": [
    "from llmcoder.analyze.GPTScoreAnalyzer import GPTScoreAnalyzer\n",
    "analyzer = GPTScoreAnalyzer()\n",
    "score = analyzer.score_code(completions.choices[1].message.content)\n",
    "print(score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'role': 'system',\n",
       "  'content': \"You are AutocompleteGPT, a useful AI autocomplete tool that provides code completions based on the user's code.\"},\n",
       " {'role': 'user', 'content': ' Please provide a cute easy code in python '}]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "conversation = Conversation(score, messages=messages, analyzer_results_history=[])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'role': 'system',\n",
       "  'content': \"You are AutocompleteGPT, a useful AI autocomplete tool that provides code completions based on the user's code.\"},\n",
       " {'role': 'user', 'content': ' Please provide a cute easy code in python '}]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation._get_messages()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_message = {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": completions.choices[1].message.content,\n",
    "            }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation._add_message(new_message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'role': 'system',\n",
       "  'content': \"You are AutocompleteGPT, a useful AI autocomplete tool that provides code completions based on the user's code.\"},\n",
       " {'role': 'user', 'content': ' Please provide a cute easy code in python '},\n",
       " {'role': 'system',\n",
       "  'content': 'Sure! Here\\'s a cute and easy Python code that prints a heart shape:\\n\\n```python\\nheart = [\\n    \"  ❤️   ❤️  \",\\n    \"❤️       ❤️\",\\n    \"❤️       ❤️\",\\n    \"  ❤️   ❤️  \",\\n    \"    ❤️     \"\\n]\\n\\nfor line in heart:\\n    print(line)\\n```\\n\\nWhen you run this code, it will display a heart shape made out of the ❤️ emoji. Enjoy!'}]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation._get_messages()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' Please provide a cute easy code in python Sure! Here\\'s a cute and easy code in Python that prints a heart shape:\\n\\n```python\\nheart = [\\n    \"  ❤️ ❤️  \",\\n    \"❤️     ❤️\",\\n    \" ❤️   ❤️ \",\\n    \"  ❤️ ❤️  \"\\n]\\n\\nfor line in heart:\\n    print(line)\\n```\\n\\nWhen you run this code, it will display a heart shape using ASCII characters. Enjoy!'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "code = conversation._get_messages()[1][\"content\"] + conversation._get_last_message()\n",
    "code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We have created 3 completions and have 3 valid choices\n",
      "We will analyze the following completion: That's a lovely code! Is there anything else I can help you with?\n",
      "Choices printed.\n",
      "[LLMcoder] Analyzing 3 completions...\n",
      "[LLMcoder] Analyzing code in separate mode...\n",
      "[LLMcoder] Running mypy_analyzer_v1...\n",
      "[MyPy] Received input:  Please provide a cute easy code in python \n",
      "[MyPy] Received completion: That's a lovely code! If you have any more requests, feel free to ask!\n",
      "[Mypy] No missing stubs found.\n",
      "Found line: C:\\Users\\anaca\\AppData\\Local\\Temp\\tmpdcu2p_b1.py:1: error: unexpected indent  [syntax]\n",
      "[Mypy] C:\\Users\\anaca\\AppData\\Local\\Temp\\tmpdcu2p_b1.py:1: error: unexpected indent  [syntax]\n",
      "Found line: Found 1 error in 1 file (errors prevented further checking)\n",
      "[Mypy] Found 1 error in 1 file (errors prevented further checking)\n",
      "Found line: \n",
      "[LLMcoder] Analyzing code in separate mode...\n",
      "[LLMcoder] Running mypy_analyzer_v1...\n",
      "[MyPy] Received input:  Please provide a cute easy code in python \n",
      "[MyPy] Received completion: That's so cute! I hope you like it. Let me know if there's anything else I can help you with!\n",
      "[LLMcoder] An exception occurred during analysis of choice: invalid literal for int() with base 10: '\\\\Users\\\\anaca\\\\AppData\\\\Local\\\\Temp\\\\tmpdcu2p_b1.py'\n",
      "[Mypy] No missing stubs found.\n",
      "Found line: C:\\Users\\anaca\\AppData\\Local\\Temp\\tmpadpgnltd.py:1: error: unexpected indent  [syntax]\n",
      "[Mypy] C:\\Users\\anaca\\AppData\\Local\\Temp\\tmpadpgnltd.py:1: error: unexpected indent  [syntax]\n",
      "Found line: Found 1 error in 1 file (errors prevented further checking)\n",
      "[Mypy] Found 1 error in 1 file (errors prevented further checking)\n",
      "Found line: \n",
      "[LLMcoder] Analyzing code in separate mode...\n",
      "[LLMcoder] Running mypy_analyzer_v1...\n",
      "[MyPy] Received input:  Please provide a cute easy code in python \n",
      "[MyPy] Received completion: That's a lovely code! Is there anything else I can help you with?\n",
      "[Mypy] No missing stubs found.\n",
      "Found line: C:\\Users\\anaca\\AppData\\Local\\Temp\\tmp6lpnrpca.py:1: error: unexpected indent  [syntax]\n",
      "[Mypy] C:\\Users\\anaca\\AppData\\Local\\Temp\\tmp6lpnrpca.py:1: error: unexpected indent  [syntax]\n",
      "Found line: Found 1 error in 1 file (errors prevented further checking)\n",
      "[Mypy] Found 1 error in 1 file (errors prevented further checking)\n",
      "Found line: \n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "invalid literal for int() with base 10: '\\\\Users\\\\anaca\\\\AppData\\\\Local\\\\Temp\\\\tmpdcu2p_b1.py'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 8\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mllmcoder\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mLLMCoder\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m LLMCoder\n\u001b[0;32m      2\u001b[0m llmcoder \u001b[38;5;241m=\u001b[39m LLMCoder(analyzers \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmypy_analyzer_v1\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[0;32m      3\u001b[0m                     feedback_variant \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mseparate\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m      4\u001b[0m                     max_iter \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m2\u001b[39m,\n\u001b[0;32m      5\u001b[0m                     verbose \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m      6\u001b[0m                     log_conversation\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, \n\u001b[0;32m      7\u001b[0m                     )\n\u001b[1;32m----> 8\u001b[0m llmcoder\u001b[38;5;241m.\u001b[39m_get_completions_for(conversation, n\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m)\n",
      "File \u001b[1;32m~\\Documents\\quinto.curso\\ai.tools\\llmcoder\\23ws-LLMcoder\\src\\llmcoder\\LLMCoder.py:324\u001b[0m, in \u001b[0;36mLLMCoder._get_completions_for\u001b[1;34m(self, conversation, model, temperature, n)\u001b[0m\n\u001b[0;32m    322\u001b[0m             \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose:\n\u001b[0;32m    323\u001b[0m                 \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[LLMcoder] An exception occurred during analysis of choice: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mexc\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 324\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m exc\n\u001b[0;32m    325\u001b[0m             \u001b[38;5;66;03m# analysis_results_list.append({\u001b[39;00m\n\u001b[0;32m    326\u001b[0m             \u001b[38;5;66;03m#     \"score\": -np.inf,\u001b[39;00m\n\u001b[0;32m    327\u001b[0m             \u001b[38;5;66;03m#     \"type\": \"ignore\",\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    331\u001b[0m \n\u001b[0;32m    332\u001b[0m \u001b[38;5;66;03m# Select the best completion\u001b[39;00m\n\u001b[0;32m    333\u001b[0m best_conversation \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconversations\u001b[38;5;241m.\u001b[39mget_highest_scored_conversation()\n",
      "File \u001b[1;32m~\\Documents\\quinto.curso\\ai.tools\\llmcoder\\23ws-LLMcoder\\src\\llmcoder\\LLMCoder.py:306\u001b[0m, in \u001b[0;36mLLMCoder._get_completions_for\u001b[1;34m(self, conversation, model, temperature, n)\u001b[0m\n\u001b[0;32m    303\u001b[0m future \u001b[38;5;241m=\u001b[39m choice_to_future[i]\n\u001b[0;32m    304\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    305\u001b[0m     \u001b[38;5;66;03m# Update the analyzer results history with the results of total completion\u001b[39;00m\n\u001b[1;32m--> 306\u001b[0m     analysis_results \u001b[38;5;241m=\u001b[39m future\u001b[38;5;241m.\u001b[39mresult()\n\u001b[0;32m    307\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe analysis results are: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00manalysis_results\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    308\u001b[0m     analysis_results_list\u001b[38;5;241m.\u001b[39mappend(analysis_results)\n",
      "File \u001b[1;32mc:\\Users\\anaca\\miniconda3\\envs\\llmcoder_env\\Lib\\concurrent\\futures\\_base.py:456\u001b[0m, in \u001b[0;36mFuture.result\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    454\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m CancelledError()\n\u001b[0;32m    455\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;241m==\u001b[39m FINISHED:\n\u001b[1;32m--> 456\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__get_result()\n\u001b[0;32m    457\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    458\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTimeoutError\u001b[39;00m()\n",
      "File \u001b[1;32mc:\\Users\\anaca\\miniconda3\\envs\\llmcoder_env\\Lib\\concurrent\\futures\\_base.py:401\u001b[0m, in \u001b[0;36mFuture.__get_result\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    399\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception:\n\u001b[0;32m    400\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 401\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception\n\u001b[0;32m    402\u001b[0m     \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    403\u001b[0m         \u001b[38;5;66;03m# Break a reference cycle with the exception in self._exception\u001b[39;00m\n\u001b[0;32m    404\u001b[0m         \u001b[38;5;28mself\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\anaca\\miniconda3\\envs\\llmcoder_env\\Lib\\concurrent\\futures\\thread.py:58\u001b[0m, in \u001b[0;36m_WorkItem.run\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     55\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[0;32m     57\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 58\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfn(\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkwargs)\n\u001b[0;32m     59\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[0;32m     60\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfuture\u001b[38;5;241m.\u001b[39mset_exception(exc)\n",
      "File \u001b[1;32m~\\Documents\\quinto.curso\\ai.tools\\llmcoder\\23ws-LLMcoder\\src\\llmcoder\\LLMCoder.py:460\u001b[0m, in \u001b[0;36mLLMCoder.run_analyzers\u001b[1;34m(self, code, completion)\u001b[0m\n\u001b[0;32m    458\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose:\n\u001b[0;32m    459\u001b[0m             \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[LLMcoder] Running \u001b[39m\u001b[38;5;132;01m{\u001b[39;00manalyzer_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 460\u001b[0m         analyzer_results[analyzer_name] \u001b[38;5;241m=\u001b[39m analyzer_instance\u001b[38;5;241m.\u001b[39manalyze(code, completion)\n\u001b[0;32m    462\u001b[0m \u001b[38;5;66;03m# In coworker mode, the analyzers are run in parallel and share a context\u001b[39;00m\n\u001b[0;32m    463\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfeedback_variant \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcoworker\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[1;32m~\\Documents\\quinto.curso\\ai.tools\\llmcoder\\23ws-LLMcoder\\src\\llmcoder\\analyze\\MypyAnalyzer.py:106\u001b[0m, in \u001b[0;36mMypyAnalyzer.analyze\u001b[1;34m(self, input, completion, install_stubs, mypy_args, context)\u001b[0m\n\u001b[0;32m    104\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m line \u001b[38;5;129;01min\u001b[39;00m result\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m    105\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m line\u001b[38;5;241m.\u001b[39mstartswith(temp_file_name):\n\u001b[1;32m--> 106\u001b[0m         line_number \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(line\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m:\u001b[39m\u001b[38;5;124m\"\u001b[39m)[\u001b[38;5;241m1\u001b[39m])\n\u001b[0;32m    107\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m line_number \u001b[38;5;241m>\u001b[39m n_input_lines:\n\u001b[0;32m    108\u001b[0m             filtered_result\u001b[38;5;241m.\u001b[39mappend(line)\n",
      "\u001b[1;31mValueError\u001b[0m: invalid literal for int() with base 10: '\\\\Users\\\\anaca\\\\AppData\\\\Local\\\\Temp\\\\tmpdcu2p_b1.py'"
     ]
    }
   ],
   "source": [
    "from llmcoder import LLMCoder\n",
    "llmcoder = LLMCoder(\n",
    "    # analyzers=[\"mypy_analyzer_v1\", \"signature_analyzer_v1\"],\n",
    "    analyzers=[\"signature_analyzer_v1\"],\n",
    "    max_iter=5,\n",
    "    feedback_variant=\"coworker\",\n",
    "    n_procs=3,\n",
    "    min_score=5,\n",
    "    backtracking=False, \n",
    "    combining=True,\n",
    "    verbose=True\n",
    "    )\n",
    "llmcoder._get_completions_for(conversation, n=3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv_python",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
