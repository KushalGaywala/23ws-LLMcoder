{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "from dynaconf import Dynaconf\n",
    "\n",
    "from llmcoder.utils import get_config_dir, get_data_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "level_0__ft__mypy__5_steps__1_choice\n",
      "level_0__ft__mypy_signature_5_steps__1_choice\n",
      "level_0__ft__mypy_signature_5_steps__3_choices\n",
      "level_0__ft__mypy_signature_gptscore_5_steps__3_choices\n",
      "level_0__ft__no_analyzers__1_step\n",
      "level_0__gpt-3.5__no_analyzers__1_step\n",
      "level_1__ft__mypy__5_steps__1_choice\n",
      "level_1__ft__mypy_signature_5_steps__1_choice\n",
      "level_1__ft__mypy_signature_5_steps__3_choices\n",
      "level_1__ft__mypy_signature_gptscore_5_steps__3_choices\n",
      "level_1__ft__no_analyzers__1_step\n",
      "level_1__gpt-3.5__no_analyzers__1_step\n",
      "level_2__ft__mypy__5_steps__1_choice\n",
      "level_2__ft__mypy_signature_5_steps__1_choice\n",
      "level_2__ft__mypy_signature_5_steps__3_choices\n",
      "level_2__ft__mypy_signature_gptscore_5_steps__3_choices\n",
      "level_2__ft__no_analyzers__1_step\n",
      "level_2__gpt-3.5__no_analyzers__1_step\n"
     ]
    }
   ],
   "source": [
    "# Get all configs\n",
    "config_dir = get_config_dir()\n",
    "config_file_list = sorted(file for file in os.listdir(config_dir) if file.endswith(\".yaml\"))\n",
    "config_list = [Dynaconf(settings_file=os.path.join(config_dir, config_name)) for config_name in config_file_list]\n",
    "config_name_list = [os.path.splitext(config_name)[0] for config_name in config_file_list]\n",
    "\n",
    "for config_name in config_name_list:\n",
    "    print(config_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# /data/name/of/dataset/eval/<config_name>/<run_id>/metrics.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load all metrics.csv files into a dict\n",
    "metrics_dict = {}\n",
    "\n",
    "for config_name, config in zip(config_name_list, config_list):\n",
    "    dataset = config.get('dataset')\n",
    "    path_to_eval = os.path.join(get_data_dir(dataset), 'eval', config_name)\n",
    "\n",
    "    metrics_dict[config_name] = {}\n",
    "\n",
    "    for run_id in os.listdir(path_to_eval):\n",
    "        path_to_metrics = os.path.join(path_to_eval, run_id, 'metrics.csv')\n",
    "        if os.path.exists(path_to_metrics):\n",
    "            with open(path_to_metrics, 'r') as f:\n",
    "                metrics_dict[config_name][run_id] = pd.read_csv(f, index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dimensions: (config, run, example, metric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>levenshtein_distance_score</th>\n",
       "      <th>bleu_score</th>\n",
       "      <th>trf_similarity_score</th>\n",
       "      <th>sequence_matcher_score</th>\n",
       "      <th>gpt_reviewer_score</th>\n",
       "      <th>loops_required_score</th>\n",
       "      <th>tokens_used_score</th>\n",
       "      <th>agility_score</th>\n",
       "      <th>time_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>299</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.510669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>298</td>\n",
       "      <td>0.111787</td>\n",
       "      <td>0.813752</td>\n",
       "      <td>0.456835</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1075</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.627634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>255</td>\n",
       "      <td>0.296616</td>\n",
       "      <td>0.693067</td>\n",
       "      <td>0.419530</td>\n",
       "      <td>-4.0</td>\n",
       "      <td>5</td>\n",
       "      <td>3955</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18.539025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>93</td>\n",
       "      <td>0.381036</td>\n",
       "      <td>0.855461</td>\n",
       "      <td>0.686869</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>481</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.694365</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   levenshtein_distance_score  bleu_score  ...  agility_score  time_score\n",
       "0                           0    1.000000  ...            0.0    0.510669\n",
       "1                         298    0.111787  ...            0.0    1.627634\n",
       "2                         255    0.296616  ...            0.0   18.539025\n",
       "3                          93    0.381036  ...            0.0    0.694365\n",
       "\n",
       "[4 rows x 9 columns]"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics_dict['level_0__ft__mypy__5_steps__1_choice']['2024-01-13_16-46-25']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Average across runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import reduce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create two new dataframes for the mean and std of each entry in the dataframe stored in metrics_dict['<config_name>']['<run_id>'] across all runs\n",
    "# The index of the new dataframe should be the same as the index of the original dataframe\n",
    "\n",
    "for k, v in metrics_dict.items():\n",
    "    # mean\n",
    "    metrics_dict[k]['mean'] = reduce(lambda a, b: a.add(b, fill_value=0), metrics_dict[k].values()) / len(metrics_dict[k])\n",
    "\n",
    "    # std\n",
    "    metrics_dict[k]['std'] = reduce(lambda a, b: a.add(b, fill_value=0), [((metrics_dict[k][run_id] - metrics_dict[k]['mean']) ** 2) for run_id in metrics_dict[k]]) / len(metrics_dict[k])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>levenshtein_distance_score</th>\n",
       "      <th>bleu_score</th>\n",
       "      <th>trf_similarity_score</th>\n",
       "      <th>sequence_matcher_score</th>\n",
       "      <th>gpt_reviewer_score</th>\n",
       "      <th>loops_required_score</th>\n",
       "      <th>tokens_used_score</th>\n",
       "      <th>agility_score</th>\n",
       "      <th>time_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>299.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.514487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>298.5</td>\n",
       "      <td>0.109268</td>\n",
       "      <td>0.800504</td>\n",
       "      <td>0.441030</td>\n",
       "      <td>0.5</td>\n",
       "      <td>2.5</td>\n",
       "      <td>3332.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20.665795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>312.0</td>\n",
       "      <td>0.148308</td>\n",
       "      <td>0.380148</td>\n",
       "      <td>0.217517</td>\n",
       "      <td>-7.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2701.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>14.006182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>93.0</td>\n",
       "      <td>0.381036</td>\n",
       "      <td>0.855461</td>\n",
       "      <td>0.686869</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>481.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.731782</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   levenshtein_distance_score  bleu_score  ...  agility_score  time_score\n",
       "0                         0.0    1.000000  ...            0.0    0.514487\n",
       "1                       298.5    0.109268  ...            0.0   20.665795\n",
       "2                       312.0    0.148308  ...            0.5   14.006182\n",
       "3                        93.0    0.381036  ...            0.0    0.731782\n",
       "\n",
       "[4 rows x 9 columns]"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics_dict['level_0__ft__mypy__5_steps__1_choice']['mean']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>levenshtein_distance_score</th>\n",
       "      <th>bleu_score</th>\n",
       "      <th>trf_similarity_score</th>\n",
       "      <th>sequence_matcher_score</th>\n",
       "      <th>gpt_reviewer_score</th>\n",
       "      <th>loops_required_score</th>\n",
       "      <th>tokens_used_score</th>\n",
       "      <th>agility_score</th>\n",
       "      <th>time_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000117</td>\n",
       "      <td>0.000167</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>4.166667</td>\n",
       "      <td>3.396033e+06</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>241.634399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2166.000000</td>\n",
       "      <td>0.014664</td>\n",
       "      <td>0.065279</td>\n",
       "      <td>0.027206</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>2.666667</td>\n",
       "      <td>1.048344e+06</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>13.697780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000933</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   levenshtein_distance_score  bleu_score  ...  agility_score  time_score\n",
       "0                    0.000000    0.000000  ...       0.000000    0.000010\n",
       "1                    0.166667    0.000004  ...       0.000000  241.634399\n",
       "2                 2166.000000    0.014664  ...       0.166667   13.697780\n",
       "3                    0.000000    0.000000  ...       0.000000    0.000933\n",
       "\n",
       "[4 rows x 9 columns]"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics_dict['level_0__ft__mypy__5_steps__1_choice']['std']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llmcoder",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
