{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llmcoder import LLMCoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "llmcoder = LLMCoder(analyzers=[\"mypy_analyzer_v1\", \"signature_analyzer_v1\", \"gpt_score_analyzer_v1\"], max_iter=3, feedback_variant=\"coworker\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "code = \"\"\"from langchain.document_loaders import DirectoryLoader, JSONLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "# Embed and store\n",
    "from langchain.vectorstores.elasticsearch import ElasticsearchStore \n",
    "from langchain.embeddings import GPT4AllEmbeddings\n",
    "from langchain.embeddings import OllamaEmbeddings # We can also try Ollama embeddings\n",
    "\n",
    "from langchain.llms import Ollama\n",
    "from langchain.callbacks.manager import CallbackManager\n",
    "from langchain.callbacks.streaming_stdout import StreamingStdOutCallbackHandler\n",
    "\n",
    "import os\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "\n",
    "import torch\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# pip install jq\n",
    "schema = {\n",
    "    'jq_schema': '.text'\n",
    "}\n",
    "\n",
    "es = get_es_connection()\n",
    "\n",
    "REINDEX = False\n",
    "\n",
    "# pip install gpt4all\n",
    "# Needs Ubuntu > 22.04 because of glibc\n",
    "\n",
    "if REINDEX:\n",
    "    # Clear the index\n",
    "    es.indices.delete(index=\"eurlex-langchain\", ignore=[400, 404])\n",
    "\n",
    "    start_time = time.time()\n",
    "    vectorstore = \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LLMcoder] Creating first completion...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LLMcoder] Analyzing 2 completions...\n",
      "[LLMcoder] Analyzing completion 0...\n",
      "[LLMcoder] Analyzing code in a coworker mode...\n",
      "[LLMcoder] Running mypy_analyzer_v1...\n",
      "[Mypy] No missing stubs found.\n",
      "[Mypy] /tmp/tmpg2v3bz0b.py:27: error: Name \"get_es_connection\" is not defined  [name-defined]\n",
      "[Mypy] /tmp/tmpg2v3bz0b.py:39: error: Unexpected keyword argument \"index\" for \"ElasticsearchStore\"  [call-arg]\n",
      "[Mypy] /tmp/tmpg2v3bz0b.py:39: error: Unexpected keyword argument \"use_agg_tables\" for \"ElasticsearchStore\"  [call-arg]\n",
      "[Mypy] /tmp/tmpg2v3bz0b.py:39: error: Unexpected keyword argument \"agg_table_size\" for \"ElasticsearchStore\"  [call-arg]\n",
      "[Mypy] /tmp/tmpg2v3bz0b.py:40: error: \"ElasticsearchStore\" has no attribute \"clear\"  [attr-defined]\n",
      "[Mypy] /tmp/tmpg2v3bz0b.py:41: error: \"ElasticsearchStore\" has no attribute \"close\"  [attr-defined]\n",
      "[Mypy] Found 6 errors in 1 file (checked 1 source file)\n",
      "[LLMcoder] Running signature_analyzer_v1...\n",
      "[Signatures] Using context from previous analyzers: ['mypy_analyzer_v1']\n",
      "[Signatures] Found problematic function or class: ElasticsearchStore\n",
      "[Signatures] Found problematic function or class: ElasticsearchStore\n",
      "[Signatures] Found problematic function or class: ElasticsearchStore\n",
      "[Signatures] Found problematic function or class: ElasticsearchStore\n",
      "[Signatures] Found problematic function or class: ElasticsearchStore\n",
      "[Signatures] import_aliases={'os': 'os', 'json': 'json', 'time': 'time', 'torch': 'torch'}\n",
      "[Signatures] direct_imports={'DirectoryLoader': 'langchain.document_loaders', 'JSONLoader': 'langchain.document_loaders', 'RecursiveCharacterTextSplitter': 'langchain.text_splitter', 'ElasticsearchStore': 'langchain.vectorstores.elasticsearch', 'GPT4AllEmbeddings': 'langchain.embeddings', 'OllamaEmbeddings': 'langchain.embeddings', 'Ollama': 'langchain.llms', 'CallbackManager': 'langchain.callbacks.manager', 'StreamingStdOutCallbackHandler': 'langchain.callbacks.streaming_stdout', 'tqdm': 'tqdm', 'BeautifulSoup': 'bs4'}\n",
      "[Signatures] function_calls=[(None, 'ElasticsearchStore')]\n",
      "[Signatures] module_alias='langchain.vectorstores.elasticsearch' func_name='ElasticsearchStore'\n",
      "[Signatures] Got signatures and documentations:\n",
      "[Signatures] ElasticsearchStore: (index_name: str, *, embedding: Optional[langchain_core.embeddings.Embeddings] = None, es_connection: Optional[ForwardRef('Elasticsearch')] = None, es_url: Optional[str] = None, es_cloud_id: Optional[str] = None, es_user: Optional[str] = None, es_api_key: Optional[str] = None, es_password: Optional[str] = None, vector_query_field: str = 'vector', query_field: str = 'text', distance_strategy: Optional[Literal[<DistanceStrategy.COSINE: 'COSINE'>, <DistanceStrategy.DOT_PRODUCT: 'DOT_PRODUCT'>, <DistanceStrategy.EUCLIDEAN_DISTANCE: 'EUCLIDEAN_DISTANCE'>]] = None, strategy: langchain.vectorstores.elasticsearch.BaseRetrievalStrategy = <langchain.vectorstores.elasticsearch.ApproxRetrievalStrategy object at 0x7f6631aba190>), `Elasticsearch` vector store.\n",
      "[LLMcoder] Running gpt_score_analyzer_v1...\n",
      "[LLMcoder] Analyzing completion 1...\n",
      "[LLMcoder] Analyzing code in a coworker mode...\n",
      "[LLMcoder] Running mypy_analyzer_v1...\n",
      "[Mypy] No missing stubs found.\n",
      "[Mypy] /tmp/tmp79t_cknn.py:27: error: Name \"get_es_connection\" is not defined  [name-defined]\n",
      "[Mypy] /tmp/tmp79t_cknn.py:39: error: Too many positional arguments for \"ElasticsearchStore\"  [misc]\n",
      "[Mypy] /tmp/tmp79t_cknn.py:39: error: Argument 2 to \"ElasticsearchStore\" has incompatible type \"str\"; expected \"Embeddings | None\"  [arg-type]\n",
      "[Mypy] /tmp/tmp79t_cknn.py:40: error: \"ElasticsearchStore\" has no attribute \"init\"  [attr-defined]\n",
      "[Mypy] Found 4 errors in 1 file (checked 1 source file)\n",
      "[LLMcoder] Running signature_analyzer_v1...\n",
      "[Signatures] Using context from previous analyzers: ['mypy_analyzer_v1']\n",
      "[Signatures] Found problematic function or class: ElasticsearchStore\n",
      "[Signatures] Found problematic function or class: ElasticsearchStore\n",
      "[Signatures] Found problematic function or class: ElasticsearchStore\n",
      "[Signatures] import_aliases={'os': 'os', 'json': 'json', 'time': 'time', 'torch': 'torch'}\n",
      "[Signatures] direct_imports={'DirectoryLoader': 'langchain.document_loaders', 'JSONLoader': 'langchain.document_loaders', 'RecursiveCharacterTextSplitter': 'langchain.text_splitter', 'ElasticsearchStore': 'langchain.vectorstores.elasticsearch', 'GPT4AllEmbeddings': 'langchain.embeddings', 'OllamaEmbeddings': 'langchain.embeddings', 'Ollama': 'langchain.llms', 'CallbackManager': 'langchain.callbacks.manager', 'StreamingStdOutCallbackHandler': 'langchain.callbacks.streaming_stdout', 'tqdm': 'tqdm', 'BeautifulSoup': 'bs4'}\n",
      "[Signatures] function_calls=[(None, 'ElasticsearchStore')]\n",
      "[Signatures] module_alias='langchain.vectorstores.elasticsearch' func_name='ElasticsearchStore'\n",
      "[Signatures] Got signatures and documentations:\n",
      "[Signatures] ElasticsearchStore: (index_name: str, *, embedding: Optional[langchain_core.embeddings.Embeddings] = None, es_connection: Optional[ForwardRef('Elasticsearch')] = None, es_url: Optional[str] = None, es_cloud_id: Optional[str] = None, es_user: Optional[str] = None, es_api_key: Optional[str] = None, es_password: Optional[str] = None, vector_query_field: str = 'vector', query_field: str = 'text', distance_strategy: Optional[Literal[<DistanceStrategy.COSINE: 'COSINE'>, <DistanceStrategy.DOT_PRODUCT: 'DOT_PRODUCT'>, <DistanceStrategy.EUCLIDEAN_DISTANCE: 'EUCLIDEAN_DISTANCE'>]] = None, strategy: langchain.vectorstores.elasticsearch.BaseRetrievalStrategy = <langchain.vectorstores.elasticsearch.ApproxRetrievalStrategy object at 0x7f6631aba190>), `Elasticsearch` vector store.\n",
      "[LLMcoder] Running gpt_score_analyzer_v1...\n",
      "[Scoring] Choosing message 1 with score 3.4155855021346815\n",
      "[LLMcoder] 0 / 1 analyzers passed\n",
      "[LLMcoder] Starting feedback loop...\n",
      "[LLMcoder] Starting feedback iteration 1...\n",
      "[LLMcoder] Analyzing 2 completions...\n",
      "[LLMcoder] Analyzing completion 0...\n",
      "[LLMcoder] Analyzing code in a coworker mode...\n",
      "[LLMcoder] Running mypy_analyzer_v1...\n",
      "[Mypy] No missing stubs found.\n",
      "[Mypy] /tmp/tmpz3wbwvr7.py:27: error: Name \"get_es_connection\" is not defined  [name-defined]\n",
      "[Mypy] /tmp/tmpz3wbwvr7.py:39: error: Missing named argument \"client\" for \"GPT4AllEmbeddings\"  [call-arg]\n",
      "[Mypy] /tmp/tmpz3wbwvr7.py:40: error: \"ElasticsearchStore\" has no attribute \"init\"  [attr-defined]\n",
      "[Mypy] Found 3 errors in 1 file (checked 1 source file)\n",
      "[LLMcoder] Running signature_analyzer_v1...\n",
      "[Signatures] Using context from previous analyzers: ['mypy_analyzer_v1']\n",
      "[Signatures] Found problematic function or class: GPT4AllEmbeddings\n",
      "[Signatures] Found problematic function or class: ElasticsearchStore\n",
      "[Signatures] import_aliases={'os': 'os', 'json': 'json', 'time': 'time', 'torch': 'torch'}\n",
      "[Signatures] direct_imports={'DirectoryLoader': 'langchain.document_loaders', 'JSONLoader': 'langchain.document_loaders', 'RecursiveCharacterTextSplitter': 'langchain.text_splitter', 'ElasticsearchStore': 'langchain.vectorstores.elasticsearch', 'GPT4AllEmbeddings': 'langchain.embeddings', 'OllamaEmbeddings': 'langchain.embeddings', 'Ollama': 'langchain.llms', 'CallbackManager': 'langchain.callbacks.manager', 'StreamingStdOutCallbackHandler': 'langchain.callbacks.streaming_stdout', 'tqdm': 'tqdm', 'BeautifulSoup': 'bs4'}\n",
      "[Signatures] function_calls=[(None, 'ElasticsearchStore'), (None, 'GPT4AllEmbeddings')]\n",
      "[Signatures] module_alias='langchain.vectorstores.elasticsearch' func_name='ElasticsearchStore'\n",
      "[Signatures] module_alias='langchain.embeddings' func_name='GPT4AllEmbeddings'\n",
      "[Signatures] Got signatures and documentations:\n",
      "[Signatures] ElasticsearchStore: (index_name: str, *, embedding: Optional[langchain_core.embeddings.Embeddings] = None, es_connection: Optional[ForwardRef('Elasticsearch')] = None, es_url: Optional[str] = None, es_cloud_id: Optional[str] = None, es_user: Optional[str] = None, es_api_key: Optional[str] = None, es_password: Optional[str] = None, vector_query_field: str = 'vector', query_field: str = 'text', distance_strategy: Optional[Literal[<DistanceStrategy.COSINE: 'COSINE'>, <DistanceStrategy.DOT_PRODUCT: 'DOT_PRODUCT'>, <DistanceStrategy.EUCLIDEAN_DISTANCE: 'EUCLIDEAN_DISTANCE'>]] = None, strategy: langchain.vectorstores.elasticsearch.BaseRetrievalStrategy = <langchain.vectorstores.elasticsearch.ApproxRetrievalStrategy object at 0x7f6631aba190>), `Elasticsearch` vector store.\n",
      "[Signatures] GPT4AllEmbeddings: (*, client: Any = None) -> None, GPT4All embedding models.\n",
      "[LLMcoder] Running gpt_score_analyzer_v1...\n",
      "[LLMcoder] Analyzing completion 1...\n",
      "[LLMcoder] Analyzing code in a coworker mode...\n",
      "[LLMcoder] Running mypy_analyzer_v1...\n",
      "[Mypy] No missing stubs found.\n",
      "[Mypy] /tmp/tmp8efj0z_6.py:27: error: Name \"get_es_connection\" is not defined  [name-defined]\n",
      "[Mypy] Found 1 error in 1 file (checked 1 source file)\n",
      "[LLMcoder] Running signature_analyzer_v1...\n",
      "[Signatures] Using context from previous analyzers: ['mypy_analyzer_v1']\n",
      "[Signatures] No problematic functions or classes found in the context.\n",
      "[LLMcoder] Running gpt_score_analyzer_v1...\n",
      "[Scoring] Choosing message 1 with score 7.4155855021346815\n",
      "[LLMcoder] 1 / 1 analyzers passed\n"
     ]
    }
   ],
   "source": [
    "result = llmcoder.complete(code, n=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ElasticsearchStore(\"eurlex-langchain\", embedding=OllamaEmbeddings(), es_connection=es)\n",
      "    print(\"--- %s seconds ---\" % (time.time() - start_time))\n"
     ]
    }
   ],
   "source": [
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'role': 'system',\n",
       "  'content': \"You are AutocompleteGPT, a useful AI autocomplete tool that provides code completions based on the user's code.\\nYou are a precision-focused tool for code autocompletion, adept in languages like Python, JavaScript, C++, and SQL.\\nPrecisely continue the code from the point of interruption and do not repeat or modify the original code, even if it is incorrect or the code interrupts in the middle of a line.\\nYour code is well documented with comments and annotations, and you should provide a clear explanation of the code's purpose in your code completion.\\nYour unique capability is to provide completions without altering, repeating, or commenting on the original code.\\nYou offer only the necessary code to complete the snippet, ensuring the response is exclusively code, with no additional comments, explanations, or annotations.\\nThis approach makes you an ideal assistant for users seeking straightforward and efficient code extensions, enhancing their work with accurate, logic-driven completions while maintaining the integrity and simplicity of the original input.\\nYour response begins with the next characters of the line if the last line of the user's code is incomplete, or the next line if the last line of the user's code is complete.\\nYour application is a VSCode extension like GitHub Copilot, which provides seamless code completions based on the user's code at the point of interruption.\"},\n",
       " {'role': 'user',\n",
       "  'content': 'from langchain.document_loaders import DirectoryLoader, JSONLoader\\nfrom langchain.text_splitter import RecursiveCharacterTextSplitter\\n\\n# Embed and store\\nfrom langchain.vectorstores.elasticsearch import ElasticsearchStore \\nfrom langchain.embeddings import GPT4AllEmbeddings\\nfrom langchain.embeddings import OllamaEmbeddings # We can also try Ollama embeddings\\n\\nfrom langchain.llms import Ollama\\nfrom langchain.callbacks.manager import CallbackManager\\nfrom langchain.callbacks.streaming_stdout import StreamingStdOutCallbackHandler\\n\\nimport os\\nimport json\\nfrom tqdm import tqdm\\nfrom bs4 import BeautifulSoup\\nimport time\\n\\nimport torch\\ndevice = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\\n\\n# pip install jq\\nschema = {\\n    \\'jq_schema\\': \\'.text\\'\\n}\\n\\nes = get_es_connection()\\n\\nREINDEX = False\\n\\n# pip install gpt4all\\n# Needs Ubuntu > 22.04 because of glibc\\n\\nif REINDEX:\\n    # Clear the index\\n    es.indices.delete(index=\"eurlex-langchain\", ignore=[400, 404])\\n\\n    start_time = time.time()\\n    vectorstore = '},\n",
       " {'role': 'assistant',\n",
       "  'content': 'ElasticsearchStore(es, \"eurlex-langchain\", \"text\")\\n    vectorstore.init()\\n    print(\"--- %s seconds ---\" % (time.time() - start_time))'},\n",
       " {'role': 'user',\n",
       "  'content': '[INST]\\nThe completion you provided resulted in the following errors:\\nyour completion:39: error: Too many positional arguments for \"ElasticsearchStore\"  [misc]\\nyour completion:39: error: Argument 2 to \"ElasticsearchStore\" has incompatible type \"str\"; expected \"Embeddings | None\"  [arg-type]\\nyour completion:40: error: \"ElasticsearchStore\" has no attribute \"init\"  [attr-defined]\\nFound 4 errors in 1 file (checked 1 source file)\\n\\nTo fix these errors, use these ground truth signatures as a reference for your next completion:\\nElasticsearchStore: (index_name: str, *, embedding: Optional[langchain_core.embeddings.Embeddings] = None, es_connection: Optional[ForwardRef(\\'Elasticsearch\\')] = None, es_url: Optional[str] = None, es_cloud_id: Optional[str] = None, es_user: Optional[str] = None, es_api_key: Optional[str] = None, es_password: Optional[str] = None, vector_query_field: str = \\'vector\\', query_field: str = \\'text\\', distance_strategy: Optional[Literal[<DistanceStrategy.COSINE: \\'COSINE\\'>, <DistanceStrategy.DOT_PRODUCT: \\'DOT_PRODUCT\\'>, <DistanceStrategy.EUCLIDEAN_DISTANCE: \\'EUCLIDEAN_DISTANCE\\'>]] = None, strategy: langchain.vectorstores.elasticsearch.BaseRetrievalStrategy = <langchain.vectorstores.elasticsearch.ApproxRetrievalStrategy object at 0x7f6631aba190>)\\n\\nFix, improve and rewrite your completion for the following code:\\n[/INST]\\nfrom langchain.document_loaders import DirectoryLoader, JSONLoader\\nfrom langchain.text_splitter import RecursiveCharacterTextSplitter\\n\\n# Embed and store\\nfrom langchain.vectorstores.elasticsearch import ElasticsearchStore \\nfrom langchain.embeddings import GPT4AllEmbeddings\\nfrom langchain.embeddings import OllamaEmbeddings # We can also try Ollama embeddings\\n\\nfrom langchain.llms import Ollama\\nfrom langchain.callbacks.manager import CallbackManager\\nfrom langchain.callbacks.streaming_stdout import StreamingStdOutCallbackHandler\\n\\nimport os\\nimport json\\nfrom tqdm import tqdm\\nfrom bs4 import BeautifulSoup\\nimport time\\n\\nimport torch\\ndevice = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\\n\\n# pip install jq\\nschema = {\\n    \\'jq_schema\\': \\'.text\\'\\n}\\n\\nes = get_es_connection()\\n\\nREINDEX = False\\n\\n# pip install gpt4all\\n# Needs Ubuntu > 22.04 because of glibc\\n\\nif REINDEX:\\n    # Clear the index\\n    es.indices.delete(index=\"eurlex-langchain\", ignore=[400, 404])\\n\\n    start_time = time.time()\\n    vectorstore = '},\n",
       " {'role': 'assistant',\n",
       "  'content': 'ElasticsearchStore(\"eurlex-langchain\", embedding=OllamaEmbeddings(), es_connection=es)\\n    print(\"--- %s seconds ---\" % (time.time() - start_time))'}]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llmcoder.messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'mypy_analyzer_v1': {'type': 'critical',\n",
       "   'score': -3,\n",
       "   'pass': False,\n",
       "   'message': 'The completion you provided resulted in the following errors:\\nyour completion:39: error: Too many positional arguments for \"ElasticsearchStore\"  [misc]\\nyour completion:39: error: Argument 2 to \"ElasticsearchStore\" has incompatible type \"str\"; expected \"Embeddings | None\"  [arg-type]\\nyour completion:40: error: \"ElasticsearchStore\" has no attribute \"init\"  [attr-defined]\\nFound 4 errors in 1 file (checked 1 source file)\\n'},\n",
       "  'signature_analyzer_v1': {'pass': True,\n",
       "   'type': 'info',\n",
       "   'score': -1,\n",
       "   'message': \"To fix these errors, use these ground truth signatures as a reference for your next completion:\\nElasticsearchStore: (index_name: str, *, embedding: Optional[langchain_core.embeddings.Embeddings] = None, es_connection: Optional[ForwardRef('Elasticsearch')] = None, es_url: Optional[str] = None, es_cloud_id: Optional[str] = None, es_user: Optional[str] = None, es_api_key: Optional[str] = None, es_password: Optional[str] = None, vector_query_field: str = 'vector', query_field: str = 'text', distance_strategy: Optional[Literal[<DistanceStrategy.COSINE: 'COSINE'>, <DistanceStrategy.DOT_PRODUCT: 'DOT_PRODUCT'>, <DistanceStrategy.EUCLIDEAN_DISTANCE: 'EUCLIDEAN_DISTANCE'>]] = None, strategy: langchain.vectorstores.elasticsearch.BaseRetrievalStrategy = <langchain.vectorstores.elasticsearch.ApproxRetrievalStrategy object at 0x7f6631aba190>)\"},\n",
       "  'gpt_score_analyzer_v1': {'type': 'score',\n",
       "   'score': 7.4155855021346815,\n",
       "   'pass': True,\n",
       "   'message': ''}},\n",
       " {'mypy_analyzer_v1': {'type': 'critical',\n",
       "   'score': 0,\n",
       "   'pass': True,\n",
       "   'message': 'The completion you provided resulted in the following errors:\\nFound 1 error in 1 file (checked 1 source file)\\n'},\n",
       "  'signature_analyzer_v1': {'pass': True,\n",
       "   'type': 'info',\n",
       "   'score': 0,\n",
       "   'message': 'All functions and classes in your completion are called correctly (their signatures match with the documentation).'},\n",
       "  'gpt_score_analyzer_v1': {'type': 'score',\n",
       "   'score': 7.4155855021346815,\n",
       "   'pass': True,\n",
       "   'message': ''}}]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llmcoder.analyzer_results_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llmcoder",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
