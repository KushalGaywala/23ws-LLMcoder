{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llmcoder.analyze.JediAnalyzer import JediAnalyzer\n",
    "from llmcoder.analyze.MypyAnalyzer import MypyAnalyzer\n",
    "from llmcoder.analyze.SignatureAnalyzer import SignatureAnalyzer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "code ='''import os\n",
    "import re\n",
    "\n",
    "from openai import OpenAI\n",
    "\n",
    "from llmcoder.analyze.Analyzer import Analyzer\n",
    "from llmcoder.utils import get_openai_key, get_system_prompt, get_system_prompt_dir\n",
    "\n",
    "\n",
    "class GPTReviewAnalyzer_v1(Analyzer):\n",
    "    \"\"\"\n",
    "    Concise, professional Python code advisor for targeted feedback.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    model : str, optional\n",
    "        The model to use, by default \"gpt-3.5-turbo\"\n",
    "    system_prompt : str, optional\n",
    "        The system prompt to use, by default `2023-12-02_GPTReviewAnalyzer_v4.txt`, created by GPTBuilder\n",
    "    min_score : int, optional\n",
    "        The minimum score to pass the review, by default 6\n",
    "\n",
    "    \"\"\"\n",
    "    def __init__(self, model: str = \"gpt-3.5-turbo\", system_prompt: str | None = None, min_score: int = 6, temperature: float = 0.2):\n",
    "        \"\"\"\n",
    "        Initialize the GPTReviewAnalyzer\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        model : str, optional\n",
    "            The model to use, by default \"gpt-3.5-turbo\"\n",
    "        system_prompt : str, optional\n",
    "            The system prompt to use, by default `2023-12-02_GPTReviewAnalyzer_v4.txt`, created by GPTBuilder\n",
    "        min_score : int, optional\n",
    "            The minimum score to pass the review, by default 6\n",
    "        \"\"\"\n",
    "        self.model = model\n",
    "\n",
    "        self.messages: list[dict[str, str]] = []\n",
    "\n",
    "        self.client = OpenAI(api_key=get_openai_key())\n",
    "\n",
    "        if system_prompt is None:\n",
    "            self.system_prompt = get_system_prompt(\"2023-12-02_GPTReviewAnalyzer_v4.txt\")\n",
    "        elif system_prompt in os.listdir(get_system_prompt_dir()):\n",
    "            self.system_prompt = get_system_prompt(system_prompt)\n",
    "        else:\n",
    "            self.system_prompt = system_prompt\n",
    "\n",
    "        self.min_score = min_score\n",
    "\n",
    "        self.temperature = temperature\n",
    "\n",
    "    def analyze(self, input: str, completion: str, context: dict[str, dict[str, bool | str]] | None = None) -> dict:\n",
    "        \"\"\"\n",
    "        Analyze the input and completion\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        input : str\n",
    "            The input to analyze\n",
    "        completion : str\n",
    "            The completion to analyze\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        dict\n",
    "            The analysis of the input and completion\n",
    "\n",
    "        \"\"\"\n",
    "        self.messages = []  # Think about it having a memory in the future and running in parallel as a discriminative reviewer with the generative LLMcoder\n",
    "\n",
    "        self.messages.append({\n",
    "            \"role\": \"system\",\n",
    "            \"content\": self.system_prompt\n",
    "        })'''\n",
    "completion = '''self.messages.append({\n",
    "            \"role\": \"user\",\n",
    "            \"content\": self._prompt_template(input, completion)\n",
    "        })\n",
    "        chat_completion = self.client.chat.completions.create(messages=self.messages, model=self.model, temperature=self.temperature) # type: ignore\n",
    "\n",
    "        self.messages.append({\n",
    "            \"role\": \"assistant\",\n",
    "            \"content\": str(chat_completion.choices[0].message.content)\n",
    "        })\n",
    "\n",
    "        # Find the score in the message. The score line has the format \"SCORE: <score, int{0, 10}>\"\n",
    "        # Define a robust regex to find the score\n",
    "        score_regex = re.compile(r\"SCORE: (\\d+)\")\n",
    "        score_match = score_regex.search(self.messages[-1][\"content\"])\n",
    "\n",
    "        if score_match is None:\n",
    "            return {\n",
    "                \"message\": self.messages[-1][\"content\"],\n",
    "                \"pass\": None\n",
    "            }\n",
    "\n",
    "        return {\n",
    "            \"message\": self.messages[-1][\"content\"],\n",
    "            \"pass\": int(score_match.group(1)) >= self.min_score\n",
    "        }\n",
    "\n",
    "    @staticmethod\n",
    "    def _prompt_template(input: str, completion: str) -> str:\n",
    "        return f\"\"\"[INCOMPLETE]{input}[/INCOMPLETE]\n",
    "\n",
    "[COMPLETE]{input + completion}[/COMPLETE]\"\"\"'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "jedi = JediAnalyzer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "if os.path.exists(\"~/.cache/jedi\"):\n",
    "    shutil.rmtree(\"~/.cache/jedi\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='openai.OpenAI', description='class OpenAI'>>,\n",
      "name.signature: Type[OpenAI],\n",
      "name.docstring: OpenAI(*, api_key: str | None=None, organization: str | None=None, base_url: str | httpx.URL | None=None, timeout: Union[float, Timeout, None, NotGiven]=NOT_GIVEN, max_retries: int=DEFAULT_MAX_RETRIES, default_headers: Mapping[str, str] | None=None, default_query: Mapping[str, object] | None=None, http_client: httpx.Client | None=None, _strict_response_validation: bool=False)\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='llmcoder.analyze.Analyzer.Analyzer', description='class Analyzer'>>,\n",
      "name.signature: Type[Analyzer],\n",
      "name.docstring: Analyzer(verbose: bool=False)\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='llmcoder.utils.get_openai_key', description='def get_openai_key'>>,\n",
      "name.signature: get_openai_key(key: str = \"\") -> str,\n",
      "name.docstring: get_openai_key(key: str=\"\") -> str\n",
      "\n",
      "Get OpenAI API key. Try to interpret the key as a key first, then as a path to a file containing the key.\n",
      "Finally, fall back to the default key.txt file or the OPENAI_KEY environment variable.\n",
      "\n",
      "Parameters\n",
      "----------\n",
      "key : str\n",
      "    The key or path to the key file.\n",
      "\n",
      "Returns\n",
      "-------\n",
      "str\n",
      "    The key.\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='llmcoder.utils.get_system_prompt', description='def get_system_prompt'>>,\n",
      "name.signature: get_system_prompt(name: str = \"2023-11-15_GPT-Builder.txt\") -> str,\n",
      "name.docstring: get_system_prompt(name: str=\"2023-11-15_GPT-Builder.txt\") -> str\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='llmcoder.utils.get_system_prompt_dir', description='def get_system_prompt_dir'>>,\n",
      "name.signature: get_system_prompt_dir(*args: str, create: bool = False) -> str,\n",
      "name.docstring: get_system_prompt_dir(*, create: bool=False) -> str\n",
      "\n",
      "Get the path to the system prompts directory.\n",
      "\n",
      "Parameters\n",
      "----------\n",
      "args : str\n",
      "    The path to the system prompts directory.\n",
      "create : bool\n",
      "    Whether to create the directory if it does not exist.\n",
      "\n",
      "Returns\n",
      "-------\n",
      "str\n",
      "    The path to the system prompts directory.\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='__main__.GPTReviewAnalyzer_v1', description='class GPTReviewAnalyzer_v1'>>,\n",
      "name.signature: Type[GPTReviewAnalyzer_v1],\n",
      "name.docstring: GPTReviewAnalyzer_v1(model: str=\"gpt-3.5-turbo\", system_prompt: str | None=None, min_score: int=6, temperature: float=0.2)\n",
      "\n",
      "Concise, professional Python code advisor for targeted feedback.\n",
      "\n",
      "Parameters\n",
      "----------\n",
      "model : str, optional\n",
      "    The model to use, by default \"gpt-3.5-turbo\"\n",
      "system_prompt : str, optional\n",
      "    The system prompt to use, by default `2023-12-02_GPTReviewAnalyzer_v4.txt`, created by GPTBuilder\n",
      "min_score : int, optional\n",
      "    The minimum score to pass the review, by default 6\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='__main__.GPTReviewAnalyzer_v1.__init__', description='def __init__'>>,\n",
      "name.signature: __init__(self, model: str=\"gpt-3.5-turbo\", system_prompt: Optional[str]=None, min_score: int=6, temperature: float=0.2),\n",
      "name.docstring: __init__(self, model: str=\"gpt-3.5-turbo\", system_prompt: str | None=None, min_score: int=6, temperature: float=0.2)\n",
      "\n",
      "Initialize the GPTReviewAnalyzer\n",
      "\n",
      "Parameters\n",
      "----------\n",
      "model : str, optional\n",
      "    The model to use, by default \"gpt-3.5-turbo\"\n",
      "system_prompt : str, optional\n",
      "    The system prompt to use, by default `2023-12-02_GPTReviewAnalyzer_v4.txt`, created by GPTBuilder\n",
      "min_score : int, optional\n",
      "    The minimum score to pass the review, by default 6\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='__main__.GPTReviewAnalyzer_v1.analyze', description='def analyze'>>,\n",
      "name.signature: analyze(self, input: str, completion: str, context: dict[str, dict[str, bool | str]] | None = None) -> dict,\n",
      "name.docstring: analyze(self, input: str, completion: str, context: dict[str, dict[str, bool | str]] | None=None) -> dict\n",
      "\n",
      "Analyze the input and completion\n",
      "\n",
      "Parameters\n",
      "----------\n",
      "input : str\n",
      "    The input to analyze\n",
      "completion : str\n",
      "    The completion to analyze\n",
      "\n",
      "Returns\n",
      "-------\n",
      "dict\n",
      "    The analysis of the input and completion\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='__main__.GPTReviewAnalyzer_v1._prompt_template', description='def _prompt_template'>>,\n",
      "name.signature: _prompt_template(input: str, completion: str) -> str,\n",
      "name.docstring: _prompt_template(input: str, completion: str) -> str\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='openai.OpenAI', description='class OpenAI'>>,\n",
      "name.signature: Type[OpenAI],\n",
      "name.docstring: OpenAI(*, api_key: str | None=None, organization: str | None=None, base_url: str | httpx.URL | None=None, timeout: Union[float, Timeout, None, NotGiven]=NOT_GIVEN, max_retries: int=DEFAULT_MAX_RETRIES, default_headers: Mapping[str, str] | None=None, default_query: Mapping[str, object] | None=None, http_client: httpx.Client | None=None, _strict_response_validation: bool=False)\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='llmcoder.analyze.Analyzer.Analyzer', description='class Analyzer'>>,\n",
      "name.signature: Type[Analyzer],\n",
      "name.docstring: Analyzer(verbose: bool=False)\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='llmcoder.utils.get_openai_key', description='def get_openai_key'>>,\n",
      "name.signature: get_openai_key(key: str = \"\") -> str,\n",
      "name.docstring: get_openai_key(key: str=\"\") -> str\n",
      "\n",
      "Get OpenAI API key. Try to interpret the key as a key first, then as a path to a file containing the key.\n",
      "Finally, fall back to the default key.txt file or the OPENAI_KEY environment variable.\n",
      "\n",
      "Parameters\n",
      "----------\n",
      "key : str\n",
      "    The key or path to the key file.\n",
      "\n",
      "Returns\n",
      "-------\n",
      "str\n",
      "    The key.\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='llmcoder.utils.get_system_prompt', description='def get_system_prompt'>>,\n",
      "name.signature: get_system_prompt(name: str = \"2023-11-15_GPT-Builder.txt\") -> str,\n",
      "name.docstring: get_system_prompt(name: str=\"2023-11-15_GPT-Builder.txt\") -> str\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='llmcoder.utils.get_system_prompt_dir', description='def get_system_prompt_dir'>>,\n",
      "name.signature: get_system_prompt_dir(*args: str, create: bool = False) -> str,\n",
      "name.docstring: get_system_prompt_dir(*, create: bool=False) -> str\n",
      "\n",
      "Get the path to the system prompts directory.\n",
      "\n",
      "Parameters\n",
      "----------\n",
      "args : str\n",
      "    The path to the system prompts directory.\n",
      "create : bool\n",
      "    Whether to create the directory if it does not exist.\n",
      "\n",
      "Returns\n",
      "-------\n",
      "str\n",
      "    The path to the system prompts directory.\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='__main__.GPTReviewAnalyzer_v1', description='class GPTReviewAnalyzer_v1'>>,\n",
      "name.signature: Type[GPTReviewAnalyzer_v1],\n",
      "name.docstring: GPTReviewAnalyzer_v1(model: str=\"gpt-3.5-turbo\", system_prompt: str | None=None, min_score: int=6, temperature: float=0.2)\n",
      "\n",
      "Concise, professional Python code advisor for targeted feedback.\n",
      "\n",
      "Parameters\n",
      "----------\n",
      "model : str, optional\n",
      "    The model to use, by default \"gpt-3.5-turbo\"\n",
      "system_prompt : str, optional\n",
      "    The system prompt to use, by default `2023-12-02_GPTReviewAnalyzer_v4.txt`, created by GPTBuilder\n",
      "min_score : int, optional\n",
      "    The minimum score to pass the review, by default 6\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='__main__.GPTReviewAnalyzer_v1.__init__', description='def __init__'>>,\n",
      "name.signature: __init__(self, model: str=\"gpt-3.5-turbo\", system_prompt: Optional[str]=None, min_score: int=6, temperature: float=0.2),\n",
      "name.docstring: __init__(self, model: str=\"gpt-3.5-turbo\", system_prompt: str | None=None, min_score: int=6, temperature: float=0.2)\n",
      "\n",
      "Initialize the GPTReviewAnalyzer\n",
      "\n",
      "Parameters\n",
      "----------\n",
      "model : str, optional\n",
      "    The model to use, by default \"gpt-3.5-turbo\"\n",
      "system_prompt : str, optional\n",
      "    The system prompt to use, by default `2023-12-02_GPTReviewAnalyzer_v4.txt`, created by GPTBuilder\n",
      "min_score : int, optional\n",
      "    The minimum score to pass the review, by default 6\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='__main__.GPTReviewAnalyzer_v1.analyze', description='def analyze'>>,\n",
      "name.signature: analyze(self, input: str, completion: str, context: dict[str, dict[str, bool | str]] | None = None) -> dict,\n",
      "name.docstring: analyze(self, input: str, completion: str, context: dict[str, dict[str, bool | str]] | None=None) -> dict\n",
      "\n",
      "Analyze the input and completion\n",
      "\n",
      "Parameters\n",
      "----------\n",
      "input : str\n",
      "    The input to analyze\n",
      "completion : str\n",
      "    The completion to analyze\n",
      "\n",
      "Returns\n",
      "-------\n",
      "dict\n",
      "    The analysis of the input and completion\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='__main__.GPTReviewAnalyzer_v1._prompt_template', description='def _prompt_template'>>,\n",
      "name.signature: _prompt_template(input: str, completion: str) -> str,\n",
      "name.docstring: _prompt_template(input: str, completion: str) -> str\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='openai.OpenAI', description='class OpenAI'>>,\n",
      "name.signature: Type[OpenAI],\n",
      "name.docstring: OpenAI(*, api_key: str | None=None, organization: str | None=None, base_url: str | httpx.URL | None=None, timeout: Union[float, Timeout, None, NotGiven]=NOT_GIVEN, max_retries: int=DEFAULT_MAX_RETRIES, default_headers: Mapping[str, str] | None=None, default_query: Mapping[str, object] | None=None, http_client: httpx.Client | None=None, _strict_response_validation: bool=False)\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='llmcoder.analyze.Analyzer.Analyzer', description='class Analyzer'>>,\n",
      "name.signature: Type[Analyzer],\n",
      "name.docstring: Analyzer(verbose: bool=False)\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='llmcoder.utils.get_openai_key', description='def get_openai_key'>>,\n",
      "name.signature: get_openai_key(key: str = \"\") -> str,\n",
      "name.docstring: get_openai_key(key: str=\"\") -> str\n",
      "\n",
      "Get OpenAI API key. Try to interpret the key as a key first, then as a path to a file containing the key.\n",
      "Finally, fall back to the default key.txt file or the OPENAI_KEY environment variable.\n",
      "\n",
      "Parameters\n",
      "----------\n",
      "key : str\n",
      "    The key or path to the key file.\n",
      "\n",
      "Returns\n",
      "-------\n",
      "str\n",
      "    The key.\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='llmcoder.utils.get_system_prompt', description='def get_system_prompt'>>,\n",
      "name.signature: get_system_prompt(name: str = \"2023-11-15_GPT-Builder.txt\") -> str,\n",
      "name.docstring: get_system_prompt(name: str=\"2023-11-15_GPT-Builder.txt\") -> str\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='llmcoder.utils.get_system_prompt_dir', description='def get_system_prompt_dir'>>,\n",
      "name.signature: get_system_prompt_dir(*args: str, create: bool = False) -> str,\n",
      "name.docstring: get_system_prompt_dir(*, create: bool=False) -> str\n",
      "\n",
      "Get the path to the system prompts directory.\n",
      "\n",
      "Parameters\n",
      "----------\n",
      "args : str\n",
      "    The path to the system prompts directory.\n",
      "create : bool\n",
      "    Whether to create the directory if it does not exist.\n",
      "\n",
      "Returns\n",
      "-------\n",
      "str\n",
      "    The path to the system prompts directory.\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='__main__.GPTReviewAnalyzer_v1', description='class GPTReviewAnalyzer_v1'>>,\n",
      "name.signature: Type[GPTReviewAnalyzer_v1],\n",
      "name.docstring: GPTReviewAnalyzer_v1(model: str=\"gpt-3.5-turbo\", system_prompt: str | None=None, min_score: int=6, temperature: float=0.2)\n",
      "\n",
      "Concise, professional Python code advisor for targeted feedback.\n",
      "\n",
      "Parameters\n",
      "----------\n",
      "model : str, optional\n",
      "    The model to use, by default \"gpt-3.5-turbo\"\n",
      "system_prompt : str, optional\n",
      "    The system prompt to use, by default `2023-12-02_GPTReviewAnalyzer_v4.txt`, created by GPTBuilder\n",
      "min_score : int, optional\n",
      "    The minimum score to pass the review, by default 6\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='__main__.GPTReviewAnalyzer_v1.__init__', description='def __init__'>>,\n",
      "name.signature: __init__(self, model: str=\"gpt-3.5-turbo\", system_prompt: Optional[str]=None, min_score: int=6, temperature: float=0.2),\n",
      "name.docstring: __init__(self, model: str=\"gpt-3.5-turbo\", system_prompt: str | None=None, min_score: int=6, temperature: float=0.2)\n",
      "\n",
      "Initialize the GPTReviewAnalyzer\n",
      "\n",
      "Parameters\n",
      "----------\n",
      "model : str, optional\n",
      "    The model to use, by default \"gpt-3.5-turbo\"\n",
      "system_prompt : str, optional\n",
      "    The system prompt to use, by default `2023-12-02_GPTReviewAnalyzer_v4.txt`, created by GPTBuilder\n",
      "min_score : int, optional\n",
      "    The minimum score to pass the review, by default 6\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='__main__.GPTReviewAnalyzer_v1.analyze', description='def analyze'>>,\n",
      "name.signature: analyze(self, input: str, completion: str, context: dict[str, dict[str, bool | str]] | None = None) -> dict,\n",
      "name.docstring: analyze(self, input: str, completion: str, context: dict[str, dict[str, bool | str]] | None=None) -> dict\n",
      "\n",
      "Analyze the input and completion\n",
      "\n",
      "Parameters\n",
      "----------\n",
      "input : str\n",
      "    The input to analyze\n",
      "completion : str\n",
      "    The completion to analyze\n",
      "\n",
      "Returns\n",
      "-------\n",
      "dict\n",
      "    The analysis of the input and completion\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='__main__.GPTReviewAnalyzer_v1._prompt_template', description='def _prompt_template'>>,\n",
      "name.signature: _prompt_template(input: str, completion: str) -> str,\n",
      "name.docstring: _prompt_template(input: str, completion: str) -> str\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='openai.OpenAI', description='class OpenAI'>>,\n",
      "name.signature: Type[OpenAI],\n",
      "name.docstring: OpenAI(*, api_key: str | None=None, organization: str | None=None, base_url: str | httpx.URL | None=None, timeout: Union[float, Timeout, None, NotGiven]=NOT_GIVEN, max_retries: int=DEFAULT_MAX_RETRIES, default_headers: Mapping[str, str] | None=None, default_query: Mapping[str, object] | None=None, http_client: httpx.Client | None=None, _strict_response_validation: bool=False)\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='llmcoder.analyze.Analyzer.Analyzer', description='class Analyzer'>>,\n",
      "name.signature: Type[Analyzer],\n",
      "name.docstring: Analyzer(verbose: bool=False)\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='llmcoder.utils.get_openai_key', description='def get_openai_key'>>,\n",
      "name.signature: get_openai_key(key: str = \"\") -> str,\n",
      "name.docstring: get_openai_key(key: str=\"\") -> str\n",
      "\n",
      "Get OpenAI API key. Try to interpret the key as a key first, then as a path to a file containing the key.\n",
      "Finally, fall back to the default key.txt file or the OPENAI_KEY environment variable.\n",
      "\n",
      "Parameters\n",
      "----------\n",
      "key : str\n",
      "    The key or path to the key file.\n",
      "\n",
      "Returns\n",
      "-------\n",
      "str\n",
      "    The key.\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='llmcoder.utils.get_system_prompt', description='def get_system_prompt'>>,\n",
      "name.signature: get_system_prompt(name: str = \"2023-11-15_GPT-Builder.txt\") -> str,\n",
      "name.docstring: get_system_prompt(name: str=\"2023-11-15_GPT-Builder.txt\") -> str\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='llmcoder.utils.get_system_prompt_dir', description='def get_system_prompt_dir'>>,\n",
      "name.signature: get_system_prompt_dir(*args: str, create: bool = False) -> str,\n",
      "name.docstring: get_system_prompt_dir(*, create: bool=False) -> str\n",
      "\n",
      "Get the path to the system prompts directory.\n",
      "\n",
      "Parameters\n",
      "----------\n",
      "args : str\n",
      "    The path to the system prompts directory.\n",
      "create : bool\n",
      "    Whether to create the directory if it does not exist.\n",
      "\n",
      "Returns\n",
      "-------\n",
      "str\n",
      "    The path to the system prompts directory.\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='__main__.GPTReviewAnalyzer_v1', description='class GPTReviewAnalyzer_v1'>>,\n",
      "name.signature: Type[GPTReviewAnalyzer_v1],\n",
      "name.docstring: GPTReviewAnalyzer_v1(model: str=\"gpt-3.5-turbo\", system_prompt: str | None=None, min_score: int=6, temperature: float=0.2)\n",
      "\n",
      "Concise, professional Python code advisor for targeted feedback.\n",
      "\n",
      "Parameters\n",
      "----------\n",
      "model : str, optional\n",
      "    The model to use, by default \"gpt-3.5-turbo\"\n",
      "system_prompt : str, optional\n",
      "    The system prompt to use, by default `2023-12-02_GPTReviewAnalyzer_v4.txt`, created by GPTBuilder\n",
      "min_score : int, optional\n",
      "    The minimum score to pass the review, by default 6\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='__main__.GPTReviewAnalyzer_v1.__init__', description='def __init__'>>,\n",
      "name.signature: __init__(self, model: str=\"gpt-3.5-turbo\", system_prompt: Optional[str]=None, min_score: int=6, temperature: float=0.2),\n",
      "name.docstring: __init__(self, model: str=\"gpt-3.5-turbo\", system_prompt: str | None=None, min_score: int=6, temperature: float=0.2)\n",
      "\n",
      "Initialize the GPTReviewAnalyzer\n",
      "\n",
      "Parameters\n",
      "----------\n",
      "model : str, optional\n",
      "    The model to use, by default \"gpt-3.5-turbo\"\n",
      "system_prompt : str, optional\n",
      "    The system prompt to use, by default `2023-12-02_GPTReviewAnalyzer_v4.txt`, created by GPTBuilder\n",
      "min_score : int, optional\n",
      "    The minimum score to pass the review, by default 6\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='__main__.GPTReviewAnalyzer_v1.analyze', description='def analyze'>>,\n",
      "name.signature: analyze(self, input: str, completion: str, context: dict[str, dict[str, bool | str]] | None = None) -> dict,\n",
      "name.docstring: analyze(self, input: str, completion: str, context: dict[str, dict[str, bool | str]] | None=None) -> dict\n",
      "\n",
      "Analyze the input and completion\n",
      "\n",
      "Parameters\n",
      "----------\n",
      "input : str\n",
      "    The input to analyze\n",
      "completion : str\n",
      "    The completion to analyze\n",
      "\n",
      "Returns\n",
      "-------\n",
      "dict\n",
      "    The analysis of the input and completion\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='__main__.GPTReviewAnalyzer_v1._prompt_template', description='def _prompt_template'>>,\n",
      "name.signature: _prompt_template(input: str, completion: str) -> str,\n",
      "name.docstring: _prompt_template(input: str, completion: str) -> str\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='openai.OpenAI', description='class OpenAI'>>,\n",
      "name.signature: Type[OpenAI],\n",
      "name.docstring: OpenAI(*, api_key: str | None=None, organization: str | None=None, base_url: str | httpx.URL | None=None, timeout: Union[float, Timeout, None, NotGiven]=NOT_GIVEN, max_retries: int=DEFAULT_MAX_RETRIES, default_headers: Mapping[str, str] | None=None, default_query: Mapping[str, object] | None=None, http_client: httpx.Client | None=None, _strict_response_validation: bool=False)\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='llmcoder.analyze.Analyzer.Analyzer', description='class Analyzer'>>,\n",
      "name.signature: Type[Analyzer],\n",
      "name.docstring: Analyzer(verbose: bool=False)\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='llmcoder.utils.get_openai_key', description='def get_openai_key'>>,\n",
      "name.signature: get_openai_key(key: str = \"\") -> str,\n",
      "name.docstring: get_openai_key(key: str=\"\") -> str\n",
      "\n",
      "Get OpenAI API key. Try to interpret the key as a key first, then as a path to a file containing the key.\n",
      "Finally, fall back to the default key.txt file or the OPENAI_KEY environment variable.\n",
      "\n",
      "Parameters\n",
      "----------\n",
      "key : str\n",
      "    The key or path to the key file.\n",
      "\n",
      "Returns\n",
      "-------\n",
      "str\n",
      "    The key.\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='llmcoder.utils.get_system_prompt', description='def get_system_prompt'>>,\n",
      "name.signature: get_system_prompt(name: str = \"2023-11-15_GPT-Builder.txt\") -> str,\n",
      "name.docstring: get_system_prompt(name: str=\"2023-11-15_GPT-Builder.txt\") -> str\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='llmcoder.utils.get_system_prompt_dir', description='def get_system_prompt_dir'>>,\n",
      "name.signature: get_system_prompt_dir(*args: str, create: bool = False) -> str,\n",
      "name.docstring: get_system_prompt_dir(*, create: bool=False) -> str\n",
      "\n",
      "Get the path to the system prompts directory.\n",
      "\n",
      "Parameters\n",
      "----------\n",
      "args : str\n",
      "    The path to the system prompts directory.\n",
      "create : bool\n",
      "    Whether to create the directory if it does not exist.\n",
      "\n",
      "Returns\n",
      "-------\n",
      "str\n",
      "    The path to the system prompts directory.\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='__main__.GPTReviewAnalyzer_v1', description='class GPTReviewAnalyzer_v1'>>,\n",
      "name.signature: Type[GPTReviewAnalyzer_v1],\n",
      "name.docstring: GPTReviewAnalyzer_v1(model: str=\"gpt-3.5-turbo\", system_prompt: str | None=None, min_score: int=6, temperature: float=0.2)\n",
      "\n",
      "Concise, professional Python code advisor for targeted feedback.\n",
      "\n",
      "Parameters\n",
      "----------\n",
      "model : str, optional\n",
      "    The model to use, by default \"gpt-3.5-turbo\"\n",
      "system_prompt : str, optional\n",
      "    The system prompt to use, by default `2023-12-02_GPTReviewAnalyzer_v4.txt`, created by GPTBuilder\n",
      "min_score : int, optional\n",
      "    The minimum score to pass the review, by default 6\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='__main__.GPTReviewAnalyzer_v1.__init__', description='def __init__'>>,\n",
      "name.signature: __init__(self, model: str=\"gpt-3.5-turbo\", system_prompt: Optional[str]=None, min_score: int=6, temperature: float=0.2),\n",
      "name.docstring: __init__(self, model: str=\"gpt-3.5-turbo\", system_prompt: str | None=None, min_score: int=6, temperature: float=0.2)\n",
      "\n",
      "Initialize the GPTReviewAnalyzer\n",
      "\n",
      "Parameters\n",
      "----------\n",
      "model : str, optional\n",
      "    The model to use, by default \"gpt-3.5-turbo\"\n",
      "system_prompt : str, optional\n",
      "    The system prompt to use, by default `2023-12-02_GPTReviewAnalyzer_v4.txt`, created by GPTBuilder\n",
      "min_score : int, optional\n",
      "    The minimum score to pass the review, by default 6\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='__main__.GPTReviewAnalyzer_v1.analyze', description='def analyze'>>,\n",
      "name.signature: analyze(self, input: str, completion: str, context: dict[str, dict[str, bool | str]] | None = None) -> dict,\n",
      "name.docstring: analyze(self, input: str, completion: str, context: dict[str, dict[str, bool | str]] | None=None) -> dict\n",
      "\n",
      "Analyze the input and completion\n",
      "\n",
      "Parameters\n",
      "----------\n",
      "input : str\n",
      "    The input to analyze\n",
      "completion : str\n",
      "    The completion to analyze\n",
      "\n",
      "Returns\n",
      "-------\n",
      "dict\n",
      "    The analysis of the input and completion\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='__main__.GPTReviewAnalyzer_v1._prompt_template', description='def _prompt_template'>>,\n",
      "name.signature: _prompt_template(input: str, completion: str) -> str,\n",
      "name.docstring: _prompt_template(input: str, completion: str) -> str\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='openai.OpenAI', description='class OpenAI'>>,\n",
      "name.signature: Type[OpenAI],\n",
      "name.docstring: OpenAI(*, api_key: str | None=None, organization: str | None=None, base_url: str | httpx.URL | None=None, timeout: Union[float, Timeout, None, NotGiven]=NOT_GIVEN, max_retries: int=DEFAULT_MAX_RETRIES, default_headers: Mapping[str, str] | None=None, default_query: Mapping[str, object] | None=None, http_client: httpx.Client | None=None, _strict_response_validation: bool=False)\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='llmcoder.analyze.Analyzer.Analyzer', description='class Analyzer'>>,\n",
      "name.signature: Type[Analyzer],\n",
      "name.docstring: Analyzer(verbose: bool=False)\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='llmcoder.utils.get_openai_key', description='def get_openai_key'>>,\n",
      "name.signature: get_openai_key(key: str = \"\") -> str,\n",
      "name.docstring: get_openai_key(key: str=\"\") -> str\n",
      "\n",
      "Get OpenAI API key. Try to interpret the key as a key first, then as a path to a file containing the key.\n",
      "Finally, fall back to the default key.txt file or the OPENAI_KEY environment variable.\n",
      "\n",
      "Parameters\n",
      "----------\n",
      "key : str\n",
      "    The key or path to the key file.\n",
      "\n",
      "Returns\n",
      "-------\n",
      "str\n",
      "    The key.\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='llmcoder.utils.get_system_prompt', description='def get_system_prompt'>>,\n",
      "name.signature: get_system_prompt(name: str = \"2023-11-15_GPT-Builder.txt\") -> str,\n",
      "name.docstring: get_system_prompt(name: str=\"2023-11-15_GPT-Builder.txt\") -> str\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='llmcoder.utils.get_system_prompt_dir', description='def get_system_prompt_dir'>>,\n",
      "name.signature: get_system_prompt_dir(*args: str, create: bool = False) -> str,\n",
      "name.docstring: get_system_prompt_dir(*, create: bool=False) -> str\n",
      "\n",
      "Get the path to the system prompts directory.\n",
      "\n",
      "Parameters\n",
      "----------\n",
      "args : str\n",
      "    The path to the system prompts directory.\n",
      "create : bool\n",
      "    Whether to create the directory if it does not exist.\n",
      "\n",
      "Returns\n",
      "-------\n",
      "str\n",
      "    The path to the system prompts directory.\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='__main__.GPTReviewAnalyzer_v1', description='class GPTReviewAnalyzer_v1'>>,\n",
      "name.signature: Type[GPTReviewAnalyzer_v1],\n",
      "name.docstring: GPTReviewAnalyzer_v1(model: str=\"gpt-3.5-turbo\", system_prompt: str | None=None, min_score: int=6, temperature: float=0.2)\n",
      "\n",
      "Concise, professional Python code advisor for targeted feedback.\n",
      "\n",
      "Parameters\n",
      "----------\n",
      "model : str, optional\n",
      "    The model to use, by default \"gpt-3.5-turbo\"\n",
      "system_prompt : str, optional\n",
      "    The system prompt to use, by default `2023-12-02_GPTReviewAnalyzer_v4.txt`, created by GPTBuilder\n",
      "min_score : int, optional\n",
      "    The minimum score to pass the review, by default 6\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='__main__.GPTReviewAnalyzer_v1.__init__', description='def __init__'>>,\n",
      "name.signature: __init__(self, model: str=\"gpt-3.5-turbo\", system_prompt: Optional[str]=None, min_score: int=6, temperature: float=0.2),\n",
      "name.docstring: __init__(self, model: str=\"gpt-3.5-turbo\", system_prompt: str | None=None, min_score: int=6, temperature: float=0.2)\n",
      "\n",
      "Initialize the GPTReviewAnalyzer\n",
      "\n",
      "Parameters\n",
      "----------\n",
      "model : str, optional\n",
      "    The model to use, by default \"gpt-3.5-turbo\"\n",
      "system_prompt : str, optional\n",
      "    The system prompt to use, by default `2023-12-02_GPTReviewAnalyzer_v4.txt`, created by GPTBuilder\n",
      "min_score : int, optional\n",
      "    The minimum score to pass the review, by default 6\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='__main__.GPTReviewAnalyzer_v1.analyze', description='def analyze'>>,\n",
      "name.signature: analyze(self, input: str, completion: str, context: dict[str, dict[str, bool | str]] | None = None) -> dict,\n",
      "name.docstring: analyze(self, input: str, completion: str, context: dict[str, dict[str, bool | str]] | None=None) -> dict\n",
      "\n",
      "Analyze the input and completion\n",
      "\n",
      "Parameters\n",
      "----------\n",
      "input : str\n",
      "    The input to analyze\n",
      "completion : str\n",
      "    The completion to analyze\n",
      "\n",
      "Returns\n",
      "-------\n",
      "dict\n",
      "    The analysis of the input and completion\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='__main__.GPTReviewAnalyzer_v1._prompt_template', description='def _prompt_template'>>,\n",
      "name.signature: _prompt_template(input: str, completion: str) -> str,\n",
      "name.docstring: _prompt_template(input: str, completion: str) -> str\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='openai.OpenAI', description='class OpenAI'>>,\n",
      "name.signature: Type[OpenAI],\n",
      "name.docstring: OpenAI(*, api_key: str | None=None, organization: str | None=None, base_url: str | httpx.URL | None=None, timeout: Union[float, Timeout, None, NotGiven]=NOT_GIVEN, max_retries: int=DEFAULT_MAX_RETRIES, default_headers: Mapping[str, str] | None=None, default_query: Mapping[str, object] | None=None, http_client: httpx.Client | None=None, _strict_response_validation: bool=False)\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='llmcoder.analyze.Analyzer.Analyzer', description='class Analyzer'>>,\n",
      "name.signature: Type[Analyzer],\n",
      "name.docstring: Analyzer(verbose: bool=False)\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='llmcoder.utils.get_openai_key', description='def get_openai_key'>>,\n",
      "name.signature: get_openai_key(key: str = \"\") -> str,\n",
      "name.docstring: get_openai_key(key: str=\"\") -> str\n",
      "\n",
      "Get OpenAI API key. Try to interpret the key as a key first, then as a path to a file containing the key.\n",
      "Finally, fall back to the default key.txt file or the OPENAI_KEY environment variable.\n",
      "\n",
      "Parameters\n",
      "----------\n",
      "key : str\n",
      "    The key or path to the key file.\n",
      "\n",
      "Returns\n",
      "-------\n",
      "str\n",
      "    The key.\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='llmcoder.utils.get_system_prompt', description='def get_system_prompt'>>,\n",
      "name.signature: get_system_prompt(name: str = \"2023-11-15_GPT-Builder.txt\") -> str,\n",
      "name.docstring: get_system_prompt(name: str=\"2023-11-15_GPT-Builder.txt\") -> str\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='llmcoder.utils.get_system_prompt_dir', description='def get_system_prompt_dir'>>,\n",
      "name.signature: get_system_prompt_dir(*args: str, create: bool = False) -> str,\n",
      "name.docstring: get_system_prompt_dir(*, create: bool=False) -> str\n",
      "\n",
      "Get the path to the system prompts directory.\n",
      "\n",
      "Parameters\n",
      "----------\n",
      "args : str\n",
      "    The path to the system prompts directory.\n",
      "create : bool\n",
      "    Whether to create the directory if it does not exist.\n",
      "\n",
      "Returns\n",
      "-------\n",
      "str\n",
      "    The path to the system prompts directory.\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='__main__.GPTReviewAnalyzer_v1', description='class GPTReviewAnalyzer_v1'>>,\n",
      "name.signature: Type[GPTReviewAnalyzer_v1],\n",
      "name.docstring: GPTReviewAnalyzer_v1(model: str=\"gpt-3.5-turbo\", system_prompt: str | None=None, min_score: int=6, temperature: float=0.2)\n",
      "\n",
      "Concise, professional Python code advisor for targeted feedback.\n",
      "\n",
      "Parameters\n",
      "----------\n",
      "model : str, optional\n",
      "    The model to use, by default \"gpt-3.5-turbo\"\n",
      "system_prompt : str, optional\n",
      "    The system prompt to use, by default `2023-12-02_GPTReviewAnalyzer_v4.txt`, created by GPTBuilder\n",
      "min_score : int, optional\n",
      "    The minimum score to pass the review, by default 6\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='__main__.GPTReviewAnalyzer_v1.__init__', description='def __init__'>>,\n",
      "name.signature: __init__(self, model: str=\"gpt-3.5-turbo\", system_prompt: Optional[str]=None, min_score: int=6, temperature: float=0.2),\n",
      "name.docstring: __init__(self, model: str=\"gpt-3.5-turbo\", system_prompt: str | None=None, min_score: int=6, temperature: float=0.2)\n",
      "\n",
      "Initialize the GPTReviewAnalyzer\n",
      "\n",
      "Parameters\n",
      "----------\n",
      "model : str, optional\n",
      "    The model to use, by default \"gpt-3.5-turbo\"\n",
      "system_prompt : str, optional\n",
      "    The system prompt to use, by default `2023-12-02_GPTReviewAnalyzer_v4.txt`, created by GPTBuilder\n",
      "min_score : int, optional\n",
      "    The minimum score to pass the review, by default 6\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='__main__.GPTReviewAnalyzer_v1.analyze', description='def analyze'>>,\n",
      "name.signature: analyze(self, input: str, completion: str, context: dict[str, dict[str, bool | str]] | None = None) -> dict,\n",
      "name.docstring: analyze(self, input: str, completion: str, context: dict[str, dict[str, bool | str]] | None=None) -> dict\n",
      "\n",
      "Analyze the input and completion\n",
      "\n",
      "Parameters\n",
      "----------\n",
      "input : str\n",
      "    The input to analyze\n",
      "completion : str\n",
      "    The completion to analyze\n",
      "\n",
      "Returns\n",
      "-------\n",
      "dict\n",
      "    The analysis of the input and completion\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='__main__.GPTReviewAnalyzer_v1._prompt_template', description='def _prompt_template'>>,\n",
      "name.signature: _prompt_template(input: str, completion: str) -> str,\n",
      "name.docstring: _prompt_template(input: str, completion: str) -> str\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='openai.OpenAI', description='class OpenAI'>>,\n",
      "name.signature: Type[OpenAI],\n",
      "name.docstring: OpenAI(*, api_key: str | None=None, organization: str | None=None, base_url: str | httpx.URL | None=None, timeout: Union[float, Timeout, None, NotGiven]=NOT_GIVEN, max_retries: int=DEFAULT_MAX_RETRIES, default_headers: Mapping[str, str] | None=None, default_query: Mapping[str, object] | None=None, http_client: httpx.Client | None=None, _strict_response_validation: bool=False)\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='llmcoder.analyze.Analyzer.Analyzer', description='class Analyzer'>>,\n",
      "name.signature: Type[Analyzer],\n",
      "name.docstring: Analyzer(verbose: bool=False)\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='llmcoder.utils.get_openai_key', description='def get_openai_key'>>,\n",
      "name.signature: get_openai_key(key: str = \"\") -> str,\n",
      "name.docstring: get_openai_key(key: str=\"\") -> str\n",
      "\n",
      "Get OpenAI API key. Try to interpret the key as a key first, then as a path to a file containing the key.\n",
      "Finally, fall back to the default key.txt file or the OPENAI_KEY environment variable.\n",
      "\n",
      "Parameters\n",
      "----------\n",
      "key : str\n",
      "    The key or path to the key file.\n",
      "\n",
      "Returns\n",
      "-------\n",
      "str\n",
      "    The key.\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='llmcoder.utils.get_system_prompt', description='def get_system_prompt'>>,\n",
      "name.signature: get_system_prompt(name: str = \"2023-11-15_GPT-Builder.txt\") -> str,\n",
      "name.docstring: get_system_prompt(name: str=\"2023-11-15_GPT-Builder.txt\") -> str\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='llmcoder.utils.get_system_prompt_dir', description='def get_system_prompt_dir'>>,\n",
      "name.signature: get_system_prompt_dir(*args: str, create: bool = False) -> str,\n",
      "name.docstring: get_system_prompt_dir(*, create: bool=False) -> str\n",
      "\n",
      "Get the path to the system prompts directory.\n",
      "\n",
      "Parameters\n",
      "----------\n",
      "args : str\n",
      "    The path to the system prompts directory.\n",
      "create : bool\n",
      "    Whether to create the directory if it does not exist.\n",
      "\n",
      "Returns\n",
      "-------\n",
      "str\n",
      "    The path to the system prompts directory.\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='__main__.GPTReviewAnalyzer_v1', description='class GPTReviewAnalyzer_v1'>>,\n",
      "name.signature: Type[GPTReviewAnalyzer_v1],\n",
      "name.docstring: GPTReviewAnalyzer_v1(model: str=\"gpt-3.5-turbo\", system_prompt: str | None=None, min_score: int=6, temperature: float=0.2)\n",
      "\n",
      "Concise, professional Python code advisor for targeted feedback.\n",
      "\n",
      "Parameters\n",
      "----------\n",
      "model : str, optional\n",
      "    The model to use, by default \"gpt-3.5-turbo\"\n",
      "system_prompt : str, optional\n",
      "    The system prompt to use, by default `2023-12-02_GPTReviewAnalyzer_v4.txt`, created by GPTBuilder\n",
      "min_score : int, optional\n",
      "    The minimum score to pass the review, by default 6\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='__main__.GPTReviewAnalyzer_v1.__init__', description='def __init__'>>,\n",
      "name.signature: __init__(self, model: str=\"gpt-3.5-turbo\", system_prompt: Optional[str]=None, min_score: int=6, temperature: float=0.2),\n",
      "name.docstring: __init__(self, model: str=\"gpt-3.5-turbo\", system_prompt: str | None=None, min_score: int=6, temperature: float=0.2)\n",
      "\n",
      "Initialize the GPTReviewAnalyzer\n",
      "\n",
      "Parameters\n",
      "----------\n",
      "model : str, optional\n",
      "    The model to use, by default \"gpt-3.5-turbo\"\n",
      "system_prompt : str, optional\n",
      "    The system prompt to use, by default `2023-12-02_GPTReviewAnalyzer_v4.txt`, created by GPTBuilder\n",
      "min_score : int, optional\n",
      "    The minimum score to pass the review, by default 6\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='__main__.GPTReviewAnalyzer_v1.analyze', description='def analyze'>>,\n",
      "name.signature: analyze(self, input: str, completion: str, context: dict[str, dict[str, bool | str]] | None = None) -> dict,\n",
      "name.docstring: analyze(self, input: str, completion: str, context: dict[str, dict[str, bool | str]] | None=None) -> dict\n",
      "\n",
      "Analyze the input and completion\n",
      "\n",
      "Parameters\n",
      "----------\n",
      "input : str\n",
      "    The input to analyze\n",
      "completion : str\n",
      "    The completion to analyze\n",
      "\n",
      "Returns\n",
      "-------\n",
      "dict\n",
      "    The analysis of the input and completion\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='__main__.GPTReviewAnalyzer_v1._prompt_template', description='def _prompt_template'>>,\n",
      "name.signature: _prompt_template(input: str, completion: str) -> str,\n",
      "name.docstring: _prompt_template(input: str, completion: str) -> str\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='openai.OpenAI', description='class OpenAI'>>,\n",
      "name.signature: Type[OpenAI],\n",
      "name.docstring: OpenAI(*, api_key: str | None=None, organization: str | None=None, base_url: str | httpx.URL | None=None, timeout: Union[float, Timeout, None, NotGiven]=NOT_GIVEN, max_retries: int=DEFAULT_MAX_RETRIES, default_headers: Mapping[str, str] | None=None, default_query: Mapping[str, object] | None=None, http_client: httpx.Client | None=None, _strict_response_validation: bool=False)\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='llmcoder.analyze.Analyzer.Analyzer', description='class Analyzer'>>,\n",
      "name.signature: Type[Analyzer],\n",
      "name.docstring: Analyzer(verbose: bool=False)\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='llmcoder.utils.get_openai_key', description='def get_openai_key'>>,\n",
      "name.signature: get_openai_key(key: str = \"\") -> str,\n",
      "name.docstring: get_openai_key(key: str=\"\") -> str\n",
      "\n",
      "Get OpenAI API key. Try to interpret the key as a key first, then as a path to a file containing the key.\n",
      "Finally, fall back to the default key.txt file or the OPENAI_KEY environment variable.\n",
      "\n",
      "Parameters\n",
      "----------\n",
      "key : str\n",
      "    The key or path to the key file.\n",
      "\n",
      "Returns\n",
      "-------\n",
      "str\n",
      "    The key.\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='llmcoder.utils.get_system_prompt', description='def get_system_prompt'>>,\n",
      "name.signature: get_system_prompt(name: str = \"2023-11-15_GPT-Builder.txt\") -> str,\n",
      "name.docstring: get_system_prompt(name: str=\"2023-11-15_GPT-Builder.txt\") -> str\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='llmcoder.utils.get_system_prompt_dir', description='def get_system_prompt_dir'>>,\n",
      "name.signature: get_system_prompt_dir(*args: str, create: bool = False) -> str,\n",
      "name.docstring: get_system_prompt_dir(*, create: bool=False) -> str\n",
      "\n",
      "Get the path to the system prompts directory.\n",
      "\n",
      "Parameters\n",
      "----------\n",
      "args : str\n",
      "    The path to the system prompts directory.\n",
      "create : bool\n",
      "    Whether to create the directory if it does not exist.\n",
      "\n",
      "Returns\n",
      "-------\n",
      "str\n",
      "    The path to the system prompts directory.\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='__main__.GPTReviewAnalyzer_v1', description='class GPTReviewAnalyzer_v1'>>,\n",
      "name.signature: Type[GPTReviewAnalyzer_v1],\n",
      "name.docstring: GPTReviewAnalyzer_v1(model: str=\"gpt-3.5-turbo\", system_prompt: str | None=None, min_score: int=6, temperature: float=0.2)\n",
      "\n",
      "Concise, professional Python code advisor for targeted feedback.\n",
      "\n",
      "Parameters\n",
      "----------\n",
      "model : str, optional\n",
      "    The model to use, by default \"gpt-3.5-turbo\"\n",
      "system_prompt : str, optional\n",
      "    The system prompt to use, by default `2023-12-02_GPTReviewAnalyzer_v4.txt`, created by GPTBuilder\n",
      "min_score : int, optional\n",
      "    The minimum score to pass the review, by default 6\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='__main__.GPTReviewAnalyzer_v1.__init__', description='def __init__'>>,\n",
      "name.signature: __init__(self, model: str=\"gpt-3.5-turbo\", system_prompt: Optional[str]=None, min_score: int=6, temperature: float=0.2),\n",
      "name.docstring: __init__(self, model: str=\"gpt-3.5-turbo\", system_prompt: str | None=None, min_score: int=6, temperature: float=0.2)\n",
      "\n",
      "Initialize the GPTReviewAnalyzer\n",
      "\n",
      "Parameters\n",
      "----------\n",
      "model : str, optional\n",
      "    The model to use, by default \"gpt-3.5-turbo\"\n",
      "system_prompt : str, optional\n",
      "    The system prompt to use, by default `2023-12-02_GPTReviewAnalyzer_v4.txt`, created by GPTBuilder\n",
      "min_score : int, optional\n",
      "    The minimum score to pass the review, by default 6\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='__main__.GPTReviewAnalyzer_v1.analyze', description='def analyze'>>,\n",
      "name.signature: analyze(self, input: str, completion: str, context: dict[str, dict[str, bool | str]] | None = None) -> dict,\n",
      "name.docstring: analyze(self, input: str, completion: str, context: dict[str, dict[str, bool | str]] | None=None) -> dict\n",
      "\n",
      "Analyze the input and completion\n",
      "\n",
      "Parameters\n",
      "----------\n",
      "input : str\n",
      "    The input to analyze\n",
      "completion : str\n",
      "    The completion to analyze\n",
      "\n",
      "Returns\n",
      "-------\n",
      "dict\n",
      "    The analysis of the input and completion\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='__main__.GPTReviewAnalyzer_v1._prompt_template', description='def _prompt_template'>>,\n",
      "name.signature: _prompt_template(input: str, completion: str) -> str,\n",
      "name.docstring: _prompt_template(input: str, completion: str) -> str\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='openai.OpenAI', description='class OpenAI'>>,\n",
      "name.signature: Type[OpenAI],\n",
      "name.docstring: OpenAI(*, api_key: str | None=None, organization: str | None=None, base_url: str | httpx.URL | None=None, timeout: Union[float, Timeout, None, NotGiven]=NOT_GIVEN, max_retries: int=DEFAULT_MAX_RETRIES, default_headers: Mapping[str, str] | None=None, default_query: Mapping[str, object] | None=None, http_client: httpx.Client | None=None, _strict_response_validation: bool=False)\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='llmcoder.analyze.Analyzer.Analyzer', description='class Analyzer'>>,\n",
      "name.signature: Type[Analyzer],\n",
      "name.docstring: Analyzer(verbose: bool=False)\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='llmcoder.utils.get_openai_key', description='def get_openai_key'>>,\n",
      "name.signature: get_openai_key(key: str = \"\") -> str,\n",
      "name.docstring: get_openai_key(key: str=\"\") -> str\n",
      "\n",
      "Get OpenAI API key. Try to interpret the key as a key first, then as a path to a file containing the key.\n",
      "Finally, fall back to the default key.txt file or the OPENAI_KEY environment variable.\n",
      "\n",
      "Parameters\n",
      "----------\n",
      "key : str\n",
      "    The key or path to the key file.\n",
      "\n",
      "Returns\n",
      "-------\n",
      "str\n",
      "    The key.\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='llmcoder.utils.get_system_prompt', description='def get_system_prompt'>>,\n",
      "name.signature: get_system_prompt(name: str = \"2023-11-15_GPT-Builder.txt\") -> str,\n",
      "name.docstring: get_system_prompt(name: str=\"2023-11-15_GPT-Builder.txt\") -> str\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='llmcoder.utils.get_system_prompt_dir', description='def get_system_prompt_dir'>>,\n",
      "name.signature: get_system_prompt_dir(*args: str, create: bool = False) -> str,\n",
      "name.docstring: get_system_prompt_dir(*, create: bool=False) -> str\n",
      "\n",
      "Get the path to the system prompts directory.\n",
      "\n",
      "Parameters\n",
      "----------\n",
      "args : str\n",
      "    The path to the system prompts directory.\n",
      "create : bool\n",
      "    Whether to create the directory if it does not exist.\n",
      "\n",
      "Returns\n",
      "-------\n",
      "str\n",
      "    The path to the system prompts directory.\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='__main__.GPTReviewAnalyzer_v1', description='class GPTReviewAnalyzer_v1'>>,\n",
      "name.signature: Type[GPTReviewAnalyzer_v1],\n",
      "name.docstring: GPTReviewAnalyzer_v1(model: str=\"gpt-3.5-turbo\", system_prompt: str | None=None, min_score: int=6, temperature: float=0.2)\n",
      "\n",
      "Concise, professional Python code advisor for targeted feedback.\n",
      "\n",
      "Parameters\n",
      "----------\n",
      "model : str, optional\n",
      "    The model to use, by default \"gpt-3.5-turbo\"\n",
      "system_prompt : str, optional\n",
      "    The system prompt to use, by default `2023-12-02_GPTReviewAnalyzer_v4.txt`, created by GPTBuilder\n",
      "min_score : int, optional\n",
      "    The minimum score to pass the review, by default 6\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='__main__.GPTReviewAnalyzer_v1.__init__', description='def __init__'>>,\n",
      "name.signature: __init__(self, model: str=\"gpt-3.5-turbo\", system_prompt: Optional[str]=None, min_score: int=6, temperature: float=0.2),\n",
      "name.docstring: __init__(self, model: str=\"gpt-3.5-turbo\", system_prompt: str | None=None, min_score: int=6, temperature: float=0.2)\n",
      "\n",
      "Initialize the GPTReviewAnalyzer\n",
      "\n",
      "Parameters\n",
      "----------\n",
      "model : str, optional\n",
      "    The model to use, by default \"gpt-3.5-turbo\"\n",
      "system_prompt : str, optional\n",
      "    The system prompt to use, by default `2023-12-02_GPTReviewAnalyzer_v4.txt`, created by GPTBuilder\n",
      "min_score : int, optional\n",
      "    The minimum score to pass the review, by default 6\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='__main__.GPTReviewAnalyzer_v1.analyze', description='def analyze'>>,\n",
      "name.signature: analyze(self, input: str, completion: str, context: dict[str, dict[str, bool | str]] | None = None) -> dict,\n",
      "name.docstring: analyze(self, input: str, completion: str, context: dict[str, dict[str, bool | str]] | None=None) -> dict\n",
      "\n",
      "Analyze the input and completion\n",
      "\n",
      "Parameters\n",
      "----------\n",
      "input : str\n",
      "    The input to analyze\n",
      "completion : str\n",
      "    The completion to analyze\n",
      "\n",
      "Returns\n",
      "-------\n",
      "dict\n",
      "    The analysis of the input and completion\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='__main__.GPTReviewAnalyzer_v1._prompt_template', description='def _prompt_template'>>,\n",
      "name.signature: _prompt_template(input: str, completion: str) -> str,\n",
      "name.docstring: _prompt_template(input: str, completion: str) -> str\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='openai.OpenAI', description='class OpenAI'>>,\n",
      "name.signature: Type[OpenAI],\n",
      "name.docstring: OpenAI(*, api_key: str | None=None, organization: str | None=None, base_url: str | httpx.URL | None=None, timeout: Union[float, Timeout, None, NotGiven]=NOT_GIVEN, max_retries: int=DEFAULT_MAX_RETRIES, default_headers: Mapping[str, str] | None=None, default_query: Mapping[str, object] | None=None, http_client: httpx.Client | None=None, _strict_response_validation: bool=False)\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='llmcoder.analyze.Analyzer.Analyzer', description='class Analyzer'>>,\n",
      "name.signature: Type[Analyzer],\n",
      "name.docstring: Analyzer(verbose: bool=False)\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='llmcoder.utils.get_openai_key', description='def get_openai_key'>>,\n",
      "name.signature: get_openai_key(key: str = \"\") -> str,\n",
      "name.docstring: get_openai_key(key: str=\"\") -> str\n",
      "\n",
      "Get OpenAI API key. Try to interpret the key as a key first, then as a path to a file containing the key.\n",
      "Finally, fall back to the default key.txt file or the OPENAI_KEY environment variable.\n",
      "\n",
      "Parameters\n",
      "----------\n",
      "key : str\n",
      "    The key or path to the key file.\n",
      "\n",
      "Returns\n",
      "-------\n",
      "str\n",
      "    The key.\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='llmcoder.utils.get_system_prompt', description='def get_system_prompt'>>,\n",
      "name.signature: get_system_prompt(name: str = \"2023-11-15_GPT-Builder.txt\") -> str,\n",
      "name.docstring: get_system_prompt(name: str=\"2023-11-15_GPT-Builder.txt\") -> str\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='llmcoder.utils.get_system_prompt_dir', description='def get_system_prompt_dir'>>,\n",
      "name.signature: get_system_prompt_dir(*args: str, create: bool = False) -> str,\n",
      "name.docstring: get_system_prompt_dir(*, create: bool=False) -> str\n",
      "\n",
      "Get the path to the system prompts directory.\n",
      "\n",
      "Parameters\n",
      "----------\n",
      "args : str\n",
      "    The path to the system prompts directory.\n",
      "create : bool\n",
      "    Whether to create the directory if it does not exist.\n",
      "\n",
      "Returns\n",
      "-------\n",
      "str\n",
      "    The path to the system prompts directory.\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='__main__.GPTReviewAnalyzer_v1', description='class GPTReviewAnalyzer_v1'>>,\n",
      "name.signature: Type[GPTReviewAnalyzer_v1],\n",
      "name.docstring: GPTReviewAnalyzer_v1(model: str=\"gpt-3.5-turbo\", system_prompt: str | None=None, min_score: int=6, temperature: float=0.2)\n",
      "\n",
      "Concise, professional Python code advisor for targeted feedback.\n",
      "\n",
      "Parameters\n",
      "----------\n",
      "model : str, optional\n",
      "    The model to use, by default \"gpt-3.5-turbo\"\n",
      "system_prompt : str, optional\n",
      "    The system prompt to use, by default `2023-12-02_GPTReviewAnalyzer_v4.txt`, created by GPTBuilder\n",
      "min_score : int, optional\n",
      "    The minimum score to pass the review, by default 6\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='__main__.GPTReviewAnalyzer_v1.__init__', description='def __init__'>>,\n",
      "name.signature: __init__(self, model: str=\"gpt-3.5-turbo\", system_prompt: Optional[str]=None, min_score: int=6, temperature: float=0.2),\n",
      "name.docstring: __init__(self, model: str=\"gpt-3.5-turbo\", system_prompt: str | None=None, min_score: int=6, temperature: float=0.2)\n",
      "\n",
      "Initialize the GPTReviewAnalyzer\n",
      "\n",
      "Parameters\n",
      "----------\n",
      "model : str, optional\n",
      "    The model to use, by default \"gpt-3.5-turbo\"\n",
      "system_prompt : str, optional\n",
      "    The system prompt to use, by default `2023-12-02_GPTReviewAnalyzer_v4.txt`, created by GPTBuilder\n",
      "min_score : int, optional\n",
      "    The minimum score to pass the review, by default 6\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='__main__.GPTReviewAnalyzer_v1.analyze', description='def analyze'>>,\n",
      "name.signature: analyze(self, input: str, completion: str, context: dict[str, dict[str, bool | str]] | None = None) -> dict,\n",
      "name.docstring: analyze(self, input: str, completion: str, context: dict[str, dict[str, bool | str]] | None=None) -> dict\n",
      "\n",
      "Analyze the input and completion\n",
      "\n",
      "Parameters\n",
      "----------\n",
      "input : str\n",
      "    The input to analyze\n",
      "completion : str\n",
      "    The completion to analyze\n",
      "\n",
      "Returns\n",
      "-------\n",
      "dict\n",
      "    The analysis of the input and completion\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='__main__.GPTReviewAnalyzer_v1._prompt_template', description='def _prompt_template'>>,\n",
      "name.signature: _prompt_template(input: str, completion: str) -> str,\n",
      "name.docstring: _prompt_template(input: str, completion: str) -> str\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='openai.OpenAI', description='class OpenAI'>>,\n",
      "name.signature: Type[OpenAI],\n",
      "name.docstring: OpenAI(*, api_key: str | None=None, organization: str | None=None, base_url: str | httpx.URL | None=None, timeout: Union[float, Timeout, None, NotGiven]=NOT_GIVEN, max_retries: int=DEFAULT_MAX_RETRIES, default_headers: Mapping[str, str] | None=None, default_query: Mapping[str, object] | None=None, http_client: httpx.Client | None=None, _strict_response_validation: bool=False)\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='llmcoder.analyze.Analyzer.Analyzer', description='class Analyzer'>>,\n",
      "name.signature: Type[Analyzer],\n",
      "name.docstring: Analyzer(verbose: bool=False)\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='llmcoder.utils.get_openai_key', description='def get_openai_key'>>,\n",
      "name.signature: get_openai_key(key: str = \"\") -> str,\n",
      "name.docstring: get_openai_key(key: str=\"\") -> str\n",
      "\n",
      "Get OpenAI API key. Try to interpret the key as a key first, then as a path to a file containing the key.\n",
      "Finally, fall back to the default key.txt file or the OPENAI_KEY environment variable.\n",
      "\n",
      "Parameters\n",
      "----------\n",
      "key : str\n",
      "    The key or path to the key file.\n",
      "\n",
      "Returns\n",
      "-------\n",
      "str\n",
      "    The key.\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='llmcoder.utils.get_system_prompt', description='def get_system_prompt'>>,\n",
      "name.signature: get_system_prompt(name: str = \"2023-11-15_GPT-Builder.txt\") -> str,\n",
      "name.docstring: get_system_prompt(name: str=\"2023-11-15_GPT-Builder.txt\") -> str\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='llmcoder.utils.get_system_prompt_dir', description='def get_system_prompt_dir'>>,\n",
      "name.signature: get_system_prompt_dir(*args: str, create: bool = False) -> str,\n",
      "name.docstring: get_system_prompt_dir(*, create: bool=False) -> str\n",
      "\n",
      "Get the path to the system prompts directory.\n",
      "\n",
      "Parameters\n",
      "----------\n",
      "args : str\n",
      "    The path to the system prompts directory.\n",
      "create : bool\n",
      "    Whether to create the directory if it does not exist.\n",
      "\n",
      "Returns\n",
      "-------\n",
      "str\n",
      "    The path to the system prompts directory.\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='__main__.GPTReviewAnalyzer_v1', description='class GPTReviewAnalyzer_v1'>>,\n",
      "name.signature: Type[GPTReviewAnalyzer_v1],\n",
      "name.docstring: GPTReviewAnalyzer_v1(model: str=\"gpt-3.5-turbo\", system_prompt: str | None=None, min_score: int=6, temperature: float=0.2)\n",
      "\n",
      "Concise, professional Python code advisor for targeted feedback.\n",
      "\n",
      "Parameters\n",
      "----------\n",
      "model : str, optional\n",
      "    The model to use, by default \"gpt-3.5-turbo\"\n",
      "system_prompt : str, optional\n",
      "    The system prompt to use, by default `2023-12-02_GPTReviewAnalyzer_v4.txt`, created by GPTBuilder\n",
      "min_score : int, optional\n",
      "    The minimum score to pass the review, by default 6\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='__main__.GPTReviewAnalyzer_v1.__init__', description='def __init__'>>,\n",
      "name.signature: __init__(self, model: str=\"gpt-3.5-turbo\", system_prompt: Optional[str]=None, min_score: int=6, temperature: float=0.2),\n",
      "name.docstring: __init__(self, model: str=\"gpt-3.5-turbo\", system_prompt: str | None=None, min_score: int=6, temperature: float=0.2)\n",
      "\n",
      "Initialize the GPTReviewAnalyzer\n",
      "\n",
      "Parameters\n",
      "----------\n",
      "model : str, optional\n",
      "    The model to use, by default \"gpt-3.5-turbo\"\n",
      "system_prompt : str, optional\n",
      "    The system prompt to use, by default `2023-12-02_GPTReviewAnalyzer_v4.txt`, created by GPTBuilder\n",
      "min_score : int, optional\n",
      "    The minimum score to pass the review, by default 6\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='__main__.GPTReviewAnalyzer_v1.analyze', description='def analyze'>>,\n",
      "name.signature: analyze(self, input: str, completion: str, context: dict[str, dict[str, bool | str]] | None = None) -> dict,\n",
      "name.docstring: analyze(self, input: str, completion: str, context: dict[str, dict[str, bool | str]] | None=None) -> dict\n",
      "\n",
      "Analyze the input and completion\n",
      "\n",
      "Parameters\n",
      "----------\n",
      "input : str\n",
      "    The input to analyze\n",
      "completion : str\n",
      "    The completion to analyze\n",
      "\n",
      "Returns\n",
      "-------\n",
      "dict\n",
      "    The analysis of the input and completion\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='__main__.GPTReviewAnalyzer_v1._prompt_template', description='def _prompt_template'>>,\n",
      "name.signature: _prompt_template(input: str, completion: str) -> str,\n",
      "name.docstring: _prompt_template(input: str, completion: str) -> str\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='openai.OpenAI', description='class OpenAI'>>,\n",
      "name.signature: Type[OpenAI],\n",
      "name.docstring: OpenAI(*, api_key: str | None=None, organization: str | None=None, base_url: str | httpx.URL | None=None, timeout: Union[float, Timeout, None, NotGiven]=NOT_GIVEN, max_retries: int=DEFAULT_MAX_RETRIES, default_headers: Mapping[str, str] | None=None, default_query: Mapping[str, object] | None=None, http_client: httpx.Client | None=None, _strict_response_validation: bool=False)\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='llmcoder.analyze.Analyzer.Analyzer', description='class Analyzer'>>,\n",
      "name.signature: Type[Analyzer],\n",
      "name.docstring: Analyzer(verbose: bool=False)\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='llmcoder.utils.get_openai_key', description='def get_openai_key'>>,\n",
      "name.signature: get_openai_key(key: str = \"\") -> str,\n",
      "name.docstring: get_openai_key(key: str=\"\") -> str\n",
      "\n",
      "Get OpenAI API key. Try to interpret the key as a key first, then as a path to a file containing the key.\n",
      "Finally, fall back to the default key.txt file or the OPENAI_KEY environment variable.\n",
      "\n",
      "Parameters\n",
      "----------\n",
      "key : str\n",
      "    The key or path to the key file.\n",
      "\n",
      "Returns\n",
      "-------\n",
      "str\n",
      "    The key.\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='llmcoder.utils.get_system_prompt', description='def get_system_prompt'>>,\n",
      "name.signature: get_system_prompt(name: str = \"2023-11-15_GPT-Builder.txt\") -> str,\n",
      "name.docstring: get_system_prompt(name: str=\"2023-11-15_GPT-Builder.txt\") -> str\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='llmcoder.utils.get_system_prompt_dir', description='def get_system_prompt_dir'>>,\n",
      "name.signature: get_system_prompt_dir(*args: str, create: bool = False) -> str,\n",
      "name.docstring: get_system_prompt_dir(*, create: bool=False) -> str\n",
      "\n",
      "Get the path to the system prompts directory.\n",
      "\n",
      "Parameters\n",
      "----------\n",
      "args : str\n",
      "    The path to the system prompts directory.\n",
      "create : bool\n",
      "    Whether to create the directory if it does not exist.\n",
      "\n",
      "Returns\n",
      "-------\n",
      "str\n",
      "    The path to the system prompts directory.\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='__main__.GPTReviewAnalyzer_v1', description='class GPTReviewAnalyzer_v1'>>,\n",
      "name.signature: Type[GPTReviewAnalyzer_v1],\n",
      "name.docstring: GPTReviewAnalyzer_v1(model: str=\"gpt-3.5-turbo\", system_prompt: str | None=None, min_score: int=6, temperature: float=0.2)\n",
      "\n",
      "Concise, professional Python code advisor for targeted feedback.\n",
      "\n",
      "Parameters\n",
      "----------\n",
      "model : str, optional\n",
      "    The model to use, by default \"gpt-3.5-turbo\"\n",
      "system_prompt : str, optional\n",
      "    The system prompt to use, by default `2023-12-02_GPTReviewAnalyzer_v4.txt`, created by GPTBuilder\n",
      "min_score : int, optional\n",
      "    The minimum score to pass the review, by default 6\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='__main__.GPTReviewAnalyzer_v1.__init__', description='def __init__'>>,\n",
      "name.signature: __init__(self, model: str=\"gpt-3.5-turbo\", system_prompt: Optional[str]=None, min_score: int=6, temperature: float=0.2),\n",
      "name.docstring: __init__(self, model: str=\"gpt-3.5-turbo\", system_prompt: str | None=None, min_score: int=6, temperature: float=0.2)\n",
      "\n",
      "Initialize the GPTReviewAnalyzer\n",
      "\n",
      "Parameters\n",
      "----------\n",
      "model : str, optional\n",
      "    The model to use, by default \"gpt-3.5-turbo\"\n",
      "system_prompt : str, optional\n",
      "    The system prompt to use, by default `2023-12-02_GPTReviewAnalyzer_v4.txt`, created by GPTBuilder\n",
      "min_score : int, optional\n",
      "    The minimum score to pass the review, by default 6\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='__main__.GPTReviewAnalyzer_v1.analyze', description='def analyze'>>,\n",
      "name.signature: analyze(self, input: str, completion: str, context: dict[str, dict[str, bool | str]] | None = None) -> dict,\n",
      "name.docstring: analyze(self, input: str, completion: str, context: dict[str, dict[str, bool | str]] | None=None) -> dict\n",
      "\n",
      "Analyze the input and completion\n",
      "\n",
      "Parameters\n",
      "----------\n",
      "input : str\n",
      "    The input to analyze\n",
      "completion : str\n",
      "    The completion to analyze\n",
      "\n",
      "Returns\n",
      "-------\n",
      "dict\n",
      "    The analysis of the input and completion\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='__main__.GPTReviewAnalyzer_v1._prompt_template', description='def _prompt_template'>>,\n",
      "name.signature: _prompt_template(input: str, completion: str) -> str,\n",
      "name.docstring: _prompt_template(input: str, completion: str) -> str\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='openai.OpenAI', description='class OpenAI'>>,\n",
      "name.signature: Type[OpenAI],\n",
      "name.docstring: OpenAI(*, api_key: str | None=None, organization: str | None=None, base_url: str | httpx.URL | None=None, timeout: Union[float, Timeout, None, NotGiven]=NOT_GIVEN, max_retries: int=DEFAULT_MAX_RETRIES, default_headers: Mapping[str, str] | None=None, default_query: Mapping[str, object] | None=None, http_client: httpx.Client | None=None, _strict_response_validation: bool=False)\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='llmcoder.analyze.Analyzer.Analyzer', description='class Analyzer'>>,\n",
      "name.signature: Type[Analyzer],\n",
      "name.docstring: Analyzer(verbose: bool=False)\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='llmcoder.utils.get_openai_key', description='def get_openai_key'>>,\n",
      "name.signature: get_openai_key(key: str = \"\") -> str,\n",
      "name.docstring: get_openai_key(key: str=\"\") -> str\n",
      "\n",
      "Get OpenAI API key. Try to interpret the key as a key first, then as a path to a file containing the key.\n",
      "Finally, fall back to the default key.txt file or the OPENAI_KEY environment variable.\n",
      "\n",
      "Parameters\n",
      "----------\n",
      "key : str\n",
      "    The key or path to the key file.\n",
      "\n",
      "Returns\n",
      "-------\n",
      "str\n",
      "    The key.\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='llmcoder.utils.get_system_prompt', description='def get_system_prompt'>>,\n",
      "name.signature: get_system_prompt(name: str = \"2023-11-15_GPT-Builder.txt\") -> str,\n",
      "name.docstring: get_system_prompt(name: str=\"2023-11-15_GPT-Builder.txt\") -> str\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='llmcoder.utils.get_system_prompt_dir', description='def get_system_prompt_dir'>>,\n",
      "name.signature: get_system_prompt_dir(*args: str, create: bool = False) -> str,\n",
      "name.docstring: get_system_prompt_dir(*, create: bool=False) -> str\n",
      "\n",
      "Get the path to the system prompts directory.\n",
      "\n",
      "Parameters\n",
      "----------\n",
      "args : str\n",
      "    The path to the system prompts directory.\n",
      "create : bool\n",
      "    Whether to create the directory if it does not exist.\n",
      "\n",
      "Returns\n",
      "-------\n",
      "str\n",
      "    The path to the system prompts directory.\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='__main__.GPTReviewAnalyzer_v1', description='class GPTReviewAnalyzer_v1'>>,\n",
      "name.signature: Type[GPTReviewAnalyzer_v1],\n",
      "name.docstring: GPTReviewAnalyzer_v1(model: str=\"gpt-3.5-turbo\", system_prompt: str | None=None, min_score: int=6, temperature: float=0.2)\n",
      "\n",
      "Concise, professional Python code advisor for targeted feedback.\n",
      "\n",
      "Parameters\n",
      "----------\n",
      "model : str, optional\n",
      "    The model to use, by default \"gpt-3.5-turbo\"\n",
      "system_prompt : str, optional\n",
      "    The system prompt to use, by default `2023-12-02_GPTReviewAnalyzer_v4.txt`, created by GPTBuilder\n",
      "min_score : int, optional\n",
      "    The minimum score to pass the review, by default 6\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='__main__.GPTReviewAnalyzer_v1.__init__', description='def __init__'>>,\n",
      "name.signature: __init__(self, model: str=\"gpt-3.5-turbo\", system_prompt: Optional[str]=None, min_score: int=6, temperature: float=0.2),\n",
      "name.docstring: __init__(self, model: str=\"gpt-3.5-turbo\", system_prompt: str | None=None, min_score: int=6, temperature: float=0.2)\n",
      "\n",
      "Initialize the GPTReviewAnalyzer\n",
      "\n",
      "Parameters\n",
      "----------\n",
      "model : str, optional\n",
      "    The model to use, by default \"gpt-3.5-turbo\"\n",
      "system_prompt : str, optional\n",
      "    The system prompt to use, by default `2023-12-02_GPTReviewAnalyzer_v4.txt`, created by GPTBuilder\n",
      "min_score : int, optional\n",
      "    The minimum score to pass the review, by default 6\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='__main__.GPTReviewAnalyzer_v1.analyze', description='def analyze'>>,\n",
      "name.signature: analyze(self, input: str, completion: str, context: dict[str, dict[str, bool | str]] | None = None) -> dict,\n",
      "name.docstring: analyze(self, input: str, completion: str, context: dict[str, dict[str, bool | str]] | None=None) -> dict\n",
      "\n",
      "Analyze the input and completion\n",
      "\n",
      "Parameters\n",
      "----------\n",
      "input : str\n",
      "    The input to analyze\n",
      "completion : str\n",
      "    The completion to analyze\n",
      "\n",
      "Returns\n",
      "-------\n",
      "dict\n",
      "    The analysis of the input and completion\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='__main__.GPTReviewAnalyzer_v1._prompt_template', description='def _prompt_template'>>,\n",
      "name.signature: _prompt_template(input: str, completion: str) -> str,\n",
      "name.docstring: _prompt_template(input: str, completion: str) -> str\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='openai.OpenAI', description='class OpenAI'>>,\n",
      "name.signature: Type[OpenAI],\n",
      "name.docstring: OpenAI(*, api_key: str | None=None, organization: str | None=None, base_url: str | httpx.URL | None=None, timeout: Union[float, Timeout, None, NotGiven]=NOT_GIVEN, max_retries: int=DEFAULT_MAX_RETRIES, default_headers: Mapping[str, str] | None=None, default_query: Mapping[str, object] | None=None, http_client: httpx.Client | None=None, _strict_response_validation: bool=False)\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='llmcoder.analyze.Analyzer.Analyzer', description='class Analyzer'>>,\n",
      "name.signature: Type[Analyzer],\n",
      "name.docstring: Analyzer(verbose: bool=False)\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='llmcoder.utils.get_openai_key', description='def get_openai_key'>>,\n",
      "name.signature: get_openai_key(key: str = \"\") -> str,\n",
      "name.docstring: get_openai_key(key: str=\"\") -> str\n",
      "\n",
      "Get OpenAI API key. Try to interpret the key as a key first, then as a path to a file containing the key.\n",
      "Finally, fall back to the default key.txt file or the OPENAI_KEY environment variable.\n",
      "\n",
      "Parameters\n",
      "----------\n",
      "key : str\n",
      "    The key or path to the key file.\n",
      "\n",
      "Returns\n",
      "-------\n",
      "str\n",
      "    The key.\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='llmcoder.utils.get_system_prompt', description='def get_system_prompt'>>,\n",
      "name.signature: get_system_prompt(name: str = \"2023-11-15_GPT-Builder.txt\") -> str,\n",
      "name.docstring: get_system_prompt(name: str=\"2023-11-15_GPT-Builder.txt\") -> str\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='llmcoder.utils.get_system_prompt_dir', description='def get_system_prompt_dir'>>,\n",
      "name.signature: get_system_prompt_dir(*args: str, create: bool = False) -> str,\n",
      "name.docstring: get_system_prompt_dir(*, create: bool=False) -> str\n",
      "\n",
      "Get the path to the system prompts directory.\n",
      "\n",
      "Parameters\n",
      "----------\n",
      "args : str\n",
      "    The path to the system prompts directory.\n",
      "create : bool\n",
      "    Whether to create the directory if it does not exist.\n",
      "\n",
      "Returns\n",
      "-------\n",
      "str\n",
      "    The path to the system prompts directory.\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='__main__.GPTReviewAnalyzer_v1', description='class GPTReviewAnalyzer_v1'>>,\n",
      "name.signature: Type[GPTReviewAnalyzer_v1],\n",
      "name.docstring: GPTReviewAnalyzer_v1(model: str=\"gpt-3.5-turbo\", system_prompt: str | None=None, min_score: int=6, temperature: float=0.2)\n",
      "\n",
      "Concise, professional Python code advisor for targeted feedback.\n",
      "\n",
      "Parameters\n",
      "----------\n",
      "model : str, optional\n",
      "    The model to use, by default \"gpt-3.5-turbo\"\n",
      "system_prompt : str, optional\n",
      "    The system prompt to use, by default `2023-12-02_GPTReviewAnalyzer_v4.txt`, created by GPTBuilder\n",
      "min_score : int, optional\n",
      "    The minimum score to pass the review, by default 6\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='__main__.GPTReviewAnalyzer_v1.__init__', description='def __init__'>>,\n",
      "name.signature: __init__(self, model: str=\"gpt-3.5-turbo\", system_prompt: Optional[str]=None, min_score: int=6, temperature: float=0.2),\n",
      "name.docstring: __init__(self, model: str=\"gpt-3.5-turbo\", system_prompt: str | None=None, min_score: int=6, temperature: float=0.2)\n",
      "\n",
      "Initialize the GPTReviewAnalyzer\n",
      "\n",
      "Parameters\n",
      "----------\n",
      "model : str, optional\n",
      "    The model to use, by default \"gpt-3.5-turbo\"\n",
      "system_prompt : str, optional\n",
      "    The system prompt to use, by default `2023-12-02_GPTReviewAnalyzer_v4.txt`, created by GPTBuilder\n",
      "min_score : int, optional\n",
      "    The minimum score to pass the review, by default 6\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='__main__.GPTReviewAnalyzer_v1.analyze', description='def analyze'>>,\n",
      "name.signature: analyze(self, input: str, completion: str, context: dict[str, dict[str, bool | str]] | None = None) -> dict,\n",
      "name.docstring: analyze(self, input: str, completion: str, context: dict[str, dict[str, bool | str]] | None=None) -> dict\n",
      "\n",
      "Analyze the input and completion\n",
      "\n",
      "Parameters\n",
      "----------\n",
      "input : str\n",
      "    The input to analyze\n",
      "completion : str\n",
      "    The completion to analyze\n",
      "\n",
      "Returns\n",
      "-------\n",
      "dict\n",
      "    The analysis of the input and completion\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='__main__.GPTReviewAnalyzer_v1._prompt_template', description='def _prompt_template'>>,\n",
      "name.signature: _prompt_template(input: str, completion: str) -> str,\n",
      "name.docstring: _prompt_template(input: str, completion: str) -> str\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='openai.OpenAI', description='class OpenAI'>>,\n",
      "name.signature: Type[OpenAI],\n",
      "name.docstring: OpenAI(*, api_key: str | None=None, organization: str | None=None, base_url: str | httpx.URL | None=None, timeout: Union[float, Timeout, None, NotGiven]=NOT_GIVEN, max_retries: int=DEFAULT_MAX_RETRIES, default_headers: Mapping[str, str] | None=None, default_query: Mapping[str, object] | None=None, http_client: httpx.Client | None=None, _strict_response_validation: bool=False)\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='llmcoder.analyze.Analyzer.Analyzer', description='class Analyzer'>>,\n",
      "name.signature: Type[Analyzer],\n",
      "name.docstring: Analyzer(verbose: bool=False)\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='llmcoder.utils.get_openai_key', description='def get_openai_key'>>,\n",
      "name.signature: get_openai_key(key: str = \"\") -> str,\n",
      "name.docstring: get_openai_key(key: str=\"\") -> str\n",
      "\n",
      "Get OpenAI API key. Try to interpret the key as a key first, then as a path to a file containing the key.\n",
      "Finally, fall back to the default key.txt file or the OPENAI_KEY environment variable.\n",
      "\n",
      "Parameters\n",
      "----------\n",
      "key : str\n",
      "    The key or path to the key file.\n",
      "\n",
      "Returns\n",
      "-------\n",
      "str\n",
      "    The key.\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='llmcoder.utils.get_system_prompt', description='def get_system_prompt'>>,\n",
      "name.signature: get_system_prompt(name: str = \"2023-11-15_GPT-Builder.txt\") -> str,\n",
      "name.docstring: get_system_prompt(name: str=\"2023-11-15_GPT-Builder.txt\") -> str\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='llmcoder.utils.get_system_prompt_dir', description='def get_system_prompt_dir'>>,\n",
      "name.signature: get_system_prompt_dir(*args: str, create: bool = False) -> str,\n",
      "name.docstring: get_system_prompt_dir(*, create: bool=False) -> str\n",
      "\n",
      "Get the path to the system prompts directory.\n",
      "\n",
      "Parameters\n",
      "----------\n",
      "args : str\n",
      "    The path to the system prompts directory.\n",
      "create : bool\n",
      "    Whether to create the directory if it does not exist.\n",
      "\n",
      "Returns\n",
      "-------\n",
      "str\n",
      "    The path to the system prompts directory.\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='__main__.GPTReviewAnalyzer_v1', description='class GPTReviewAnalyzer_v1'>>,\n",
      "name.signature: Type[GPTReviewAnalyzer_v1],\n",
      "name.docstring: GPTReviewAnalyzer_v1(model: str=\"gpt-3.5-turbo\", system_prompt: str | None=None, min_score: int=6, temperature: float=0.2)\n",
      "\n",
      "Concise, professional Python code advisor for targeted feedback.\n",
      "\n",
      "Parameters\n",
      "----------\n",
      "model : str, optional\n",
      "    The model to use, by default \"gpt-3.5-turbo\"\n",
      "system_prompt : str, optional\n",
      "    The system prompt to use, by default `2023-12-02_GPTReviewAnalyzer_v4.txt`, created by GPTBuilder\n",
      "min_score : int, optional\n",
      "    The minimum score to pass the review, by default 6\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='__main__.GPTReviewAnalyzer_v1.__init__', description='def __init__'>>,\n",
      "name.signature: __init__(self, model: str=\"gpt-3.5-turbo\", system_prompt: Optional[str]=None, min_score: int=6, temperature: float=0.2),\n",
      "name.docstring: __init__(self, model: str=\"gpt-3.5-turbo\", system_prompt: str | None=None, min_score: int=6, temperature: float=0.2)\n",
      "\n",
      "Initialize the GPTReviewAnalyzer\n",
      "\n",
      "Parameters\n",
      "----------\n",
      "model : str, optional\n",
      "    The model to use, by default \"gpt-3.5-turbo\"\n",
      "system_prompt : str, optional\n",
      "    The system prompt to use, by default `2023-12-02_GPTReviewAnalyzer_v4.txt`, created by GPTBuilder\n",
      "min_score : int, optional\n",
      "    The minimum score to pass the review, by default 6\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='__main__.GPTReviewAnalyzer_v1.analyze', description='def analyze'>>,\n",
      "name.signature: analyze(self, input: str, completion: str, context: dict[str, dict[str, bool | str]] | None = None) -> dict,\n",
      "name.docstring: analyze(self, input: str, completion: str, context: dict[str, dict[str, bool | str]] | None=None) -> dict\n",
      "\n",
      "Analyze the input and completion\n",
      "\n",
      "Parameters\n",
      "----------\n",
      "input : str\n",
      "    The input to analyze\n",
      "completion : str\n",
      "    The completion to analyze\n",
      "\n",
      "Returns\n",
      "-------\n",
      "dict\n",
      "    The analysis of the input and completion\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='__main__.GPTReviewAnalyzer_v1._prompt_template', description='def _prompt_template'>>,\n",
      "name.signature: _prompt_template(input: str, completion: str) -> str,\n",
      "name.docstring: _prompt_template(input: str, completion: str) -> str\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='openai.OpenAI', description='class OpenAI'>>,\n",
      "name.signature: Type[OpenAI],\n",
      "name.docstring: OpenAI(*, api_key: str | None=None, organization: str | None=None, base_url: str | httpx.URL | None=None, timeout: Union[float, Timeout, None, NotGiven]=NOT_GIVEN, max_retries: int=DEFAULT_MAX_RETRIES, default_headers: Mapping[str, str] | None=None, default_query: Mapping[str, object] | None=None, http_client: httpx.Client | None=None, _strict_response_validation: bool=False)\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='llmcoder.analyze.Analyzer.Analyzer', description='class Analyzer'>>,\n",
      "name.signature: Type[Analyzer],\n",
      "name.docstring: Analyzer(verbose: bool=False)\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='llmcoder.utils.get_openai_key', description='def get_openai_key'>>,\n",
      "name.signature: get_openai_key(key: str = \"\") -> str,\n",
      "name.docstring: get_openai_key(key: str=\"\") -> str\n",
      "\n",
      "Get OpenAI API key. Try to interpret the key as a key first, then as a path to a file containing the key.\n",
      "Finally, fall back to the default key.txt file or the OPENAI_KEY environment variable.\n",
      "\n",
      "Parameters\n",
      "----------\n",
      "key : str\n",
      "    The key or path to the key file.\n",
      "\n",
      "Returns\n",
      "-------\n",
      "str\n",
      "    The key.\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='llmcoder.utils.get_system_prompt', description='def get_system_prompt'>>,\n",
      "name.signature: get_system_prompt(name: str = \"2023-11-15_GPT-Builder.txt\") -> str,\n",
      "name.docstring: get_system_prompt(name: str=\"2023-11-15_GPT-Builder.txt\") -> str\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='llmcoder.utils.get_system_prompt_dir', description='def get_system_prompt_dir'>>,\n",
      "name.signature: get_system_prompt_dir(*args: str, create: bool = False) -> str,\n",
      "name.docstring: get_system_prompt_dir(*, create: bool=False) -> str\n",
      "\n",
      "Get the path to the system prompts directory.\n",
      "\n",
      "Parameters\n",
      "----------\n",
      "args : str\n",
      "    The path to the system prompts directory.\n",
      "create : bool\n",
      "    Whether to create the directory if it does not exist.\n",
      "\n",
      "Returns\n",
      "-------\n",
      "str\n",
      "    The path to the system prompts directory.\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='__main__.GPTReviewAnalyzer_v1', description='class GPTReviewAnalyzer_v1'>>,\n",
      "name.signature: Type[GPTReviewAnalyzer_v1],\n",
      "name.docstring: GPTReviewAnalyzer_v1(model: str=\"gpt-3.5-turbo\", system_prompt: str | None=None, min_score: int=6, temperature: float=0.2)\n",
      "\n",
      "Concise, professional Python code advisor for targeted feedback.\n",
      "\n",
      "Parameters\n",
      "----------\n",
      "model : str, optional\n",
      "    The model to use, by default \"gpt-3.5-turbo\"\n",
      "system_prompt : str, optional\n",
      "    The system prompt to use, by default `2023-12-02_GPTReviewAnalyzer_v4.txt`, created by GPTBuilder\n",
      "min_score : int, optional\n",
      "    The minimum score to pass the review, by default 6\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='__main__.GPTReviewAnalyzer_v1.__init__', description='def __init__'>>,\n",
      "name.signature: __init__(self, model: str=\"gpt-3.5-turbo\", system_prompt: Optional[str]=None, min_score: int=6, temperature: float=0.2),\n",
      "name.docstring: __init__(self, model: str=\"gpt-3.5-turbo\", system_prompt: str | None=None, min_score: int=6, temperature: float=0.2)\n",
      "\n",
      "Initialize the GPTReviewAnalyzer\n",
      "\n",
      "Parameters\n",
      "----------\n",
      "model : str, optional\n",
      "    The model to use, by default \"gpt-3.5-turbo\"\n",
      "system_prompt : str, optional\n",
      "    The system prompt to use, by default `2023-12-02_GPTReviewAnalyzer_v4.txt`, created by GPTBuilder\n",
      "min_score : int, optional\n",
      "    The minimum score to pass the review, by default 6\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='__main__.GPTReviewAnalyzer_v1.analyze', description='def analyze'>>,\n",
      "name.signature: analyze(self, input: str, completion: str, context: dict[str, dict[str, bool | str]] | None = None) -> dict,\n",
      "name.docstring: analyze(self, input: str, completion: str, context: dict[str, dict[str, bool | str]] | None=None) -> dict\n",
      "\n",
      "Analyze the input and completion\n",
      "\n",
      "Parameters\n",
      "----------\n",
      "input : str\n",
      "    The input to analyze\n",
      "completion : str\n",
      "    The completion to analyze\n",
      "\n",
      "Returns\n",
      "-------\n",
      "dict\n",
      "    The analysis of the input and completion\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='__main__.GPTReviewAnalyzer_v1._prompt_template', description='def _prompt_template'>>,\n",
      "name.signature: _prompt_template(input: str, completion: str) -> str,\n",
      "name.docstring: _prompt_template(input: str, completion: str) -> str\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='openai.OpenAI', description='class OpenAI'>>,\n",
      "name.signature: Type[OpenAI],\n",
      "name.docstring: OpenAI(*, api_key: str | None=None, organization: str | None=None, base_url: str | httpx.URL | None=None, timeout: Union[float, Timeout, None, NotGiven]=NOT_GIVEN, max_retries: int=DEFAULT_MAX_RETRIES, default_headers: Mapping[str, str] | None=None, default_query: Mapping[str, object] | None=None, http_client: httpx.Client | None=None, _strict_response_validation: bool=False)\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='llmcoder.analyze.Analyzer.Analyzer', description='class Analyzer'>>,\n",
      "name.signature: Type[Analyzer],\n",
      "name.docstring: Analyzer(verbose: bool=False)\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='llmcoder.utils.get_openai_key', description='def get_openai_key'>>,\n",
      "name.signature: get_openai_key(key: str = \"\") -> str,\n",
      "name.docstring: get_openai_key(key: str=\"\") -> str\n",
      "\n",
      "Get OpenAI API key. Try to interpret the key as a key first, then as a path to a file containing the key.\n",
      "Finally, fall back to the default key.txt file or the OPENAI_KEY environment variable.\n",
      "\n",
      "Parameters\n",
      "----------\n",
      "key : str\n",
      "    The key or path to the key file.\n",
      "\n",
      "Returns\n",
      "-------\n",
      "str\n",
      "    The key.\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='llmcoder.utils.get_system_prompt', description='def get_system_prompt'>>,\n",
      "name.signature: get_system_prompt(name: str = \"2023-11-15_GPT-Builder.txt\") -> str,\n",
      "name.docstring: get_system_prompt(name: str=\"2023-11-15_GPT-Builder.txt\") -> str\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='llmcoder.utils.get_system_prompt_dir', description='def get_system_prompt_dir'>>,\n",
      "name.signature: get_system_prompt_dir(*args: str, create: bool = False) -> str,\n",
      "name.docstring: get_system_prompt_dir(*, create: bool=False) -> str\n",
      "\n",
      "Get the path to the system prompts directory.\n",
      "\n",
      "Parameters\n",
      "----------\n",
      "args : str\n",
      "    The path to the system prompts directory.\n",
      "create : bool\n",
      "    Whether to create the directory if it does not exist.\n",
      "\n",
      "Returns\n",
      "-------\n",
      "str\n",
      "    The path to the system prompts directory.\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='__main__.GPTReviewAnalyzer_v1', description='class GPTReviewAnalyzer_v1'>>,\n",
      "name.signature: Type[GPTReviewAnalyzer_v1],\n",
      "name.docstring: GPTReviewAnalyzer_v1(model: str=\"gpt-3.5-turbo\", system_prompt: str | None=None, min_score: int=6, temperature: float=0.2)\n",
      "\n",
      "Concise, professional Python code advisor for targeted feedback.\n",
      "\n",
      "Parameters\n",
      "----------\n",
      "model : str, optional\n",
      "    The model to use, by default \"gpt-3.5-turbo\"\n",
      "system_prompt : str, optional\n",
      "    The system prompt to use, by default `2023-12-02_GPTReviewAnalyzer_v4.txt`, created by GPTBuilder\n",
      "min_score : int, optional\n",
      "    The minimum score to pass the review, by default 6\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='__main__.GPTReviewAnalyzer_v1.__init__', description='def __init__'>>,\n",
      "name.signature: __init__(self, model: str=\"gpt-3.5-turbo\", system_prompt: Optional[str]=None, min_score: int=6, temperature: float=0.2),\n",
      "name.docstring: __init__(self, model: str=\"gpt-3.5-turbo\", system_prompt: str | None=None, min_score: int=6, temperature: float=0.2)\n",
      "\n",
      "Initialize the GPTReviewAnalyzer\n",
      "\n",
      "Parameters\n",
      "----------\n",
      "model : str, optional\n",
      "    The model to use, by default \"gpt-3.5-turbo\"\n",
      "system_prompt : str, optional\n",
      "    The system prompt to use, by default `2023-12-02_GPTReviewAnalyzer_v4.txt`, created by GPTBuilder\n",
      "min_score : int, optional\n",
      "    The minimum score to pass the review, by default 6\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='__main__.GPTReviewAnalyzer_v1.analyze', description='def analyze'>>,\n",
      "name.signature: analyze(self, input: str, completion: str, context: dict[str, dict[str, bool | str]] | None = None) -> dict,\n",
      "name.docstring: analyze(self, input: str, completion: str, context: dict[str, dict[str, bool | str]] | None=None) -> dict\n",
      "\n",
      "Analyze the input and completion\n",
      "\n",
      "Parameters\n",
      "----------\n",
      "input : str\n",
      "    The input to analyze\n",
      "completion : str\n",
      "    The completion to analyze\n",
      "\n",
      "Returns\n",
      "-------\n",
      "dict\n",
      "    The analysis of the input and completion\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='__main__.GPTReviewAnalyzer_v1._prompt_template', description='def _prompt_template'>>,\n",
      "name.signature: _prompt_template(input: str, completion: str) -> str,\n",
      "name.docstring: _prompt_template(input: str, completion: str) -> str\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='openai.OpenAI', description='class OpenAI'>>,\n",
      "name.signature: Type[OpenAI],\n",
      "name.docstring: OpenAI(*, api_key: str | None=None, organization: str | None=None, base_url: str | httpx.URL | None=None, timeout: Union[float, Timeout, None, NotGiven]=NOT_GIVEN, max_retries: int=DEFAULT_MAX_RETRIES, default_headers: Mapping[str, str] | None=None, default_query: Mapping[str, object] | None=None, http_client: httpx.Client | None=None, _strict_response_validation: bool=False)\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='llmcoder.analyze.Analyzer.Analyzer', description='class Analyzer'>>,\n",
      "name.signature: Type[Analyzer],\n",
      "name.docstring: Analyzer(verbose: bool=False)\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='llmcoder.utils.get_openai_key', description='def get_openai_key'>>,\n",
      "name.signature: get_openai_key(key: str = \"\") -> str,\n",
      "name.docstring: get_openai_key(key: str=\"\") -> str\n",
      "\n",
      "Get OpenAI API key. Try to interpret the key as a key first, then as a path to a file containing the key.\n",
      "Finally, fall back to the default key.txt file or the OPENAI_KEY environment variable.\n",
      "\n",
      "Parameters\n",
      "----------\n",
      "key : str\n",
      "    The key or path to the key file.\n",
      "\n",
      "Returns\n",
      "-------\n",
      "str\n",
      "    The key.\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='llmcoder.utils.get_system_prompt', description='def get_system_prompt'>>,\n",
      "name.signature: get_system_prompt(name: str = \"2023-11-15_GPT-Builder.txt\") -> str,\n",
      "name.docstring: get_system_prompt(name: str=\"2023-11-15_GPT-Builder.txt\") -> str\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='llmcoder.utils.get_system_prompt_dir', description='def get_system_prompt_dir'>>,\n",
      "name.signature: get_system_prompt_dir(*args: str, create: bool = False) -> str,\n",
      "name.docstring: get_system_prompt_dir(*, create: bool=False) -> str\n",
      "\n",
      "Get the path to the system prompts directory.\n",
      "\n",
      "Parameters\n",
      "----------\n",
      "args : str\n",
      "    The path to the system prompts directory.\n",
      "create : bool\n",
      "    Whether to create the directory if it does not exist.\n",
      "\n",
      "Returns\n",
      "-------\n",
      "str\n",
      "    The path to the system prompts directory.\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='__main__.GPTReviewAnalyzer_v1', description='class GPTReviewAnalyzer_v1'>>,\n",
      "name.signature: Type[GPTReviewAnalyzer_v1],\n",
      "name.docstring: GPTReviewAnalyzer_v1(model: str=\"gpt-3.5-turbo\", system_prompt: str | None=None, min_score: int=6, temperature: float=0.2)\n",
      "\n",
      "Concise, professional Python code advisor for targeted feedback.\n",
      "\n",
      "Parameters\n",
      "----------\n",
      "model : str, optional\n",
      "    The model to use, by default \"gpt-3.5-turbo\"\n",
      "system_prompt : str, optional\n",
      "    The system prompt to use, by default `2023-12-02_GPTReviewAnalyzer_v4.txt`, created by GPTBuilder\n",
      "min_score : int, optional\n",
      "    The minimum score to pass the review, by default 6\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='__main__.GPTReviewAnalyzer_v1.__init__', description='def __init__'>>,\n",
      "name.signature: __init__(self, model: str=\"gpt-3.5-turbo\", system_prompt: Optional[str]=None, min_score: int=6, temperature: float=0.2),\n",
      "name.docstring: __init__(self, model: str=\"gpt-3.5-turbo\", system_prompt: str | None=None, min_score: int=6, temperature: float=0.2)\n",
      "\n",
      "Initialize the GPTReviewAnalyzer\n",
      "\n",
      "Parameters\n",
      "----------\n",
      "model : str, optional\n",
      "    The model to use, by default \"gpt-3.5-turbo\"\n",
      "system_prompt : str, optional\n",
      "    The system prompt to use, by default `2023-12-02_GPTReviewAnalyzer_v4.txt`, created by GPTBuilder\n",
      "min_score : int, optional\n",
      "    The minimum score to pass the review, by default 6\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='__main__.GPTReviewAnalyzer_v1.analyze', description='def analyze'>>,\n",
      "name.signature: analyze(self, input: str, completion: str, context: dict[str, dict[str, bool | str]] | None = None) -> dict,\n",
      "name.docstring: analyze(self, input: str, completion: str, context: dict[str, dict[str, bool | str]] | None=None) -> dict\n",
      "\n",
      "Analyze the input and completion\n",
      "\n",
      "Parameters\n",
      "----------\n",
      "input : str\n",
      "    The input to analyze\n",
      "completion : str\n",
      "    The completion to analyze\n",
      "\n",
      "Returns\n",
      "-------\n",
      "dict\n",
      "    The analysis of the input and completion\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='__main__.GPTReviewAnalyzer_v1._prompt_template', description='def _prompt_template'>>,\n",
      "name.signature: _prompt_template(input: str, completion: str) -> str,\n",
      "name.docstring: _prompt_template(input: str, completion: str) -> str\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='openai.OpenAI', description='class OpenAI'>>,\n",
      "name.signature: Type[OpenAI],\n",
      "name.docstring: OpenAI(*, api_key: str | None=None, organization: str | None=None, base_url: str | httpx.URL | None=None, timeout: Union[float, Timeout, None, NotGiven]=NOT_GIVEN, max_retries: int=DEFAULT_MAX_RETRIES, default_headers: Mapping[str, str] | None=None, default_query: Mapping[str, object] | None=None, http_client: httpx.Client | None=None, _strict_response_validation: bool=False)\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='llmcoder.analyze.Analyzer.Analyzer', description='class Analyzer'>>,\n",
      "name.signature: Type[Analyzer],\n",
      "name.docstring: Analyzer(verbose: bool=False)\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='llmcoder.utils.get_openai_key', description='def get_openai_key'>>,\n",
      "name.signature: get_openai_key(key: str = \"\") -> str,\n",
      "name.docstring: get_openai_key(key: str=\"\") -> str\n",
      "\n",
      "Get OpenAI API key. Try to interpret the key as a key first, then as a path to a file containing the key.\n",
      "Finally, fall back to the default key.txt file or the OPENAI_KEY environment variable.\n",
      "\n",
      "Parameters\n",
      "----------\n",
      "key : str\n",
      "    The key or path to the key file.\n",
      "\n",
      "Returns\n",
      "-------\n",
      "str\n",
      "    The key.\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='llmcoder.utils.get_system_prompt', description='def get_system_prompt'>>,\n",
      "name.signature: get_system_prompt(name: str = \"2023-11-15_GPT-Builder.txt\") -> str,\n",
      "name.docstring: get_system_prompt(name: str=\"2023-11-15_GPT-Builder.txt\") -> str\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='llmcoder.utils.get_system_prompt_dir', description='def get_system_prompt_dir'>>,\n",
      "name.signature: get_system_prompt_dir(*args: str, create: bool = False) -> str,\n",
      "name.docstring: get_system_prompt_dir(*, create: bool=False) -> str\n",
      "\n",
      "Get the path to the system prompts directory.\n",
      "\n",
      "Parameters\n",
      "----------\n",
      "args : str\n",
      "    The path to the system prompts directory.\n",
      "create : bool\n",
      "    Whether to create the directory if it does not exist.\n",
      "\n",
      "Returns\n",
      "-------\n",
      "str\n",
      "    The path to the system prompts directory.\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='__main__.GPTReviewAnalyzer_v1', description='class GPTReviewAnalyzer_v1'>>,\n",
      "name.signature: Type[GPTReviewAnalyzer_v1],\n",
      "name.docstring: GPTReviewAnalyzer_v1(model: str=\"gpt-3.5-turbo\", system_prompt: str | None=None, min_score: int=6, temperature: float=0.2)\n",
      "\n",
      "Concise, professional Python code advisor for targeted feedback.\n",
      "\n",
      "Parameters\n",
      "----------\n",
      "model : str, optional\n",
      "    The model to use, by default \"gpt-3.5-turbo\"\n",
      "system_prompt : str, optional\n",
      "    The system prompt to use, by default `2023-12-02_GPTReviewAnalyzer_v4.txt`, created by GPTBuilder\n",
      "min_score : int, optional\n",
      "    The minimum score to pass the review, by default 6\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='__main__.GPTReviewAnalyzer_v1.__init__', description='def __init__'>>,\n",
      "name.signature: __init__(self, model: str=\"gpt-3.5-turbo\", system_prompt: Optional[str]=None, min_score: int=6, temperature: float=0.2),\n",
      "name.docstring: __init__(self, model: str=\"gpt-3.5-turbo\", system_prompt: str | None=None, min_score: int=6, temperature: float=0.2)\n",
      "\n",
      "Initialize the GPTReviewAnalyzer\n",
      "\n",
      "Parameters\n",
      "----------\n",
      "model : str, optional\n",
      "    The model to use, by default \"gpt-3.5-turbo\"\n",
      "system_prompt : str, optional\n",
      "    The system prompt to use, by default `2023-12-02_GPTReviewAnalyzer_v4.txt`, created by GPTBuilder\n",
      "min_score : int, optional\n",
      "    The minimum score to pass the review, by default 6\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='__main__.GPTReviewAnalyzer_v1.analyze', description='def analyze'>>,\n",
      "name.signature: analyze(self, input: str, completion: str, context: dict[str, dict[str, bool | str]] | None = None) -> dict,\n",
      "name.docstring: analyze(self, input: str, completion: str, context: dict[str, dict[str, bool | str]] | None=None) -> dict\n",
      "\n",
      "Analyze the input and completion\n",
      "\n",
      "Parameters\n",
      "----------\n",
      "input : str\n",
      "    The input to analyze\n",
      "completion : str\n",
      "    The completion to analyze\n",
      "\n",
      "Returns\n",
      "-------\n",
      "dict\n",
      "    The analysis of the input and completion\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='__main__.GPTReviewAnalyzer_v1._prompt_template', description='def _prompt_template'>>,\n",
      "name.signature: _prompt_template(input: str, completion: str) -> str,\n",
      "name.docstring: _prompt_template(input: str, completion: str) -> str\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='openai.OpenAI', description='class OpenAI'>>,\n",
      "name.signature: Type[OpenAI],\n",
      "name.docstring: OpenAI(*, api_key: str | None=None, organization: str | None=None, base_url: str | httpx.URL | None=None, timeout: Union[float, Timeout, None, NotGiven]=NOT_GIVEN, max_retries: int=DEFAULT_MAX_RETRIES, default_headers: Mapping[str, str] | None=None, default_query: Mapping[str, object] | None=None, http_client: httpx.Client | None=None, _strict_response_validation: bool=False)\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='llmcoder.analyze.Analyzer.Analyzer', description='class Analyzer'>>,\n",
      "name.signature: Type[Analyzer],\n",
      "name.docstring: Analyzer(verbose: bool=False)\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='llmcoder.utils.get_openai_key', description='def get_openai_key'>>,\n",
      "name.signature: get_openai_key(key: str = \"\") -> str,\n",
      "name.docstring: get_openai_key(key: str=\"\") -> str\n",
      "\n",
      "Get OpenAI API key. Try to interpret the key as a key first, then as a path to a file containing the key.\n",
      "Finally, fall back to the default key.txt file or the OPENAI_KEY environment variable.\n",
      "\n",
      "Parameters\n",
      "----------\n",
      "key : str\n",
      "    The key or path to the key file.\n",
      "\n",
      "Returns\n",
      "-------\n",
      "str\n",
      "    The key.\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='llmcoder.utils.get_system_prompt', description='def get_system_prompt'>>,\n",
      "name.signature: get_system_prompt(name: str = \"2023-11-15_GPT-Builder.txt\") -> str,\n",
      "name.docstring: get_system_prompt(name: str=\"2023-11-15_GPT-Builder.txt\") -> str\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='llmcoder.utils.get_system_prompt_dir', description='def get_system_prompt_dir'>>,\n",
      "name.signature: get_system_prompt_dir(*args: str, create: bool = False) -> str,\n",
      "name.docstring: get_system_prompt_dir(*, create: bool=False) -> str\n",
      "\n",
      "Get the path to the system prompts directory.\n",
      "\n",
      "Parameters\n",
      "----------\n",
      "args : str\n",
      "    The path to the system prompts directory.\n",
      "create : bool\n",
      "    Whether to create the directory if it does not exist.\n",
      "\n",
      "Returns\n",
      "-------\n",
      "str\n",
      "    The path to the system prompts directory.\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='__main__.GPTReviewAnalyzer_v1', description='class GPTReviewAnalyzer_v1'>>,\n",
      "name.signature: Type[GPTReviewAnalyzer_v1],\n",
      "name.docstring: GPTReviewAnalyzer_v1(model: str=\"gpt-3.5-turbo\", system_prompt: str | None=None, min_score: int=6, temperature: float=0.2)\n",
      "\n",
      "Concise, professional Python code advisor for targeted feedback.\n",
      "\n",
      "Parameters\n",
      "----------\n",
      "model : str, optional\n",
      "    The model to use, by default \"gpt-3.5-turbo\"\n",
      "system_prompt : str, optional\n",
      "    The system prompt to use, by default `2023-12-02_GPTReviewAnalyzer_v4.txt`, created by GPTBuilder\n",
      "min_score : int, optional\n",
      "    The minimum score to pass the review, by default 6\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='__main__.GPTReviewAnalyzer_v1.__init__', description='def __init__'>>,\n",
      "name.signature: __init__(self, model: str=\"gpt-3.5-turbo\", system_prompt: Optional[str]=None, min_score: int=6, temperature: float=0.2),\n",
      "name.docstring: __init__(self, model: str=\"gpt-3.5-turbo\", system_prompt: str | None=None, min_score: int=6, temperature: float=0.2)\n",
      "\n",
      "Initialize the GPTReviewAnalyzer\n",
      "\n",
      "Parameters\n",
      "----------\n",
      "model : str, optional\n",
      "    The model to use, by default \"gpt-3.5-turbo\"\n",
      "system_prompt : str, optional\n",
      "    The system prompt to use, by default `2023-12-02_GPTReviewAnalyzer_v4.txt`, created by GPTBuilder\n",
      "min_score : int, optional\n",
      "    The minimum score to pass the review, by default 6\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='__main__.GPTReviewAnalyzer_v1.analyze', description='def analyze'>>,\n",
      "name.signature: analyze(self, input: str, completion: str, context: dict[str, dict[str, bool | str]] | None = None) -> dict,\n",
      "name.docstring: analyze(self, input: str, completion: str, context: dict[str, dict[str, bool | str]] | None=None) -> dict\n",
      "\n",
      "Analyze the input and completion\n",
      "\n",
      "Parameters\n",
      "----------\n",
      "input : str\n",
      "    The input to analyze\n",
      "completion : str\n",
      "    The completion to analyze\n",
      "\n",
      "Returns\n",
      "-------\n",
      "dict\n",
      "    The analysis of the input and completion\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='__main__.GPTReviewAnalyzer_v1._prompt_template', description='def _prompt_template'>>,\n",
      "name.signature: _prompt_template(input: str, completion: str) -> str,\n",
      "name.docstring: _prompt_template(input: str, completion: str) -> str\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='openai.OpenAI', description='class OpenAI'>>,\n",
      "name.signature: Type[OpenAI],\n",
      "name.docstring: OpenAI(*, api_key: str | None=None, organization: str | None=None, base_url: str | httpx.URL | None=None, timeout: Union[float, Timeout, None, NotGiven]=NOT_GIVEN, max_retries: int=DEFAULT_MAX_RETRIES, default_headers: Mapping[str, str] | None=None, default_query: Mapping[str, object] | None=None, http_client: httpx.Client | None=None, _strict_response_validation: bool=False)\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='llmcoder.analyze.Analyzer.Analyzer', description='class Analyzer'>>,\n",
      "name.signature: Type[Analyzer],\n",
      "name.docstring: Analyzer(verbose: bool=False)\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='llmcoder.utils.get_openai_key', description='def get_openai_key'>>,\n",
      "name.signature: get_openai_key(key: str = \"\") -> str,\n",
      "name.docstring: get_openai_key(key: str=\"\") -> str\n",
      "\n",
      "Get OpenAI API key. Try to interpret the key as a key first, then as a path to a file containing the key.\n",
      "Finally, fall back to the default key.txt file or the OPENAI_KEY environment variable.\n",
      "\n",
      "Parameters\n",
      "----------\n",
      "key : str\n",
      "    The key or path to the key file.\n",
      "\n",
      "Returns\n",
      "-------\n",
      "str\n",
      "    The key.\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='llmcoder.utils.get_system_prompt', description='def get_system_prompt'>>,\n",
      "name.signature: get_system_prompt(name: str = \"2023-11-15_GPT-Builder.txt\") -> str,\n",
      "name.docstring: get_system_prompt(name: str=\"2023-11-15_GPT-Builder.txt\") -> str\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='llmcoder.utils.get_system_prompt_dir', description='def get_system_prompt_dir'>>,\n",
      "name.signature: get_system_prompt_dir(*args: str, create: bool = False) -> str,\n",
      "name.docstring: get_system_prompt_dir(*, create: bool=False) -> str\n",
      "\n",
      "Get the path to the system prompts directory.\n",
      "\n",
      "Parameters\n",
      "----------\n",
      "args : str\n",
      "    The path to the system prompts directory.\n",
      "create : bool\n",
      "    Whether to create the directory if it does not exist.\n",
      "\n",
      "Returns\n",
      "-------\n",
      "str\n",
      "    The path to the system prompts directory.\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='__main__.GPTReviewAnalyzer_v1', description='class GPTReviewAnalyzer_v1'>>,\n",
      "name.signature: Type[GPTReviewAnalyzer_v1],\n",
      "name.docstring: GPTReviewAnalyzer_v1(model: str=\"gpt-3.5-turbo\", system_prompt: str | None=None, min_score: int=6, temperature: float=0.2)\n",
      "\n",
      "Concise, professional Python code advisor for targeted feedback.\n",
      "\n",
      "Parameters\n",
      "----------\n",
      "model : str, optional\n",
      "    The model to use, by default \"gpt-3.5-turbo\"\n",
      "system_prompt : str, optional\n",
      "    The system prompt to use, by default `2023-12-02_GPTReviewAnalyzer_v4.txt`, created by GPTBuilder\n",
      "min_score : int, optional\n",
      "    The minimum score to pass the review, by default 6\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='__main__.GPTReviewAnalyzer_v1.__init__', description='def __init__'>>,\n",
      "name.signature: __init__(self, model: str=\"gpt-3.5-turbo\", system_prompt: Optional[str]=None, min_score: int=6, temperature: float=0.2),\n",
      "name.docstring: __init__(self, model: str=\"gpt-3.5-turbo\", system_prompt: str | None=None, min_score: int=6, temperature: float=0.2)\n",
      "\n",
      "Initialize the GPTReviewAnalyzer\n",
      "\n",
      "Parameters\n",
      "----------\n",
      "model : str, optional\n",
      "    The model to use, by default \"gpt-3.5-turbo\"\n",
      "system_prompt : str, optional\n",
      "    The system prompt to use, by default `2023-12-02_GPTReviewAnalyzer_v4.txt`, created by GPTBuilder\n",
      "min_score : int, optional\n",
      "    The minimum score to pass the review, by default 6\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='__main__.GPTReviewAnalyzer_v1.analyze', description='def analyze'>>,\n",
      "name.signature: analyze(self, input: str, completion: str, context: dict[str, dict[str, bool | str]] | None = None) -> dict,\n",
      "name.docstring: analyze(self, input: str, completion: str, context: dict[str, dict[str, bool | str]] | None=None) -> dict\n",
      "\n",
      "Analyze the input and completion\n",
      "\n",
      "Parameters\n",
      "----------\n",
      "input : str\n",
      "    The input to analyze\n",
      "completion : str\n",
      "    The completion to analyze\n",
      "\n",
      "Returns\n",
      "-------\n",
      "dict\n",
      "    The analysis of the input and completion\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='__main__.GPTReviewAnalyzer_v1._prompt_template', description='def _prompt_template'>>,\n",
      "name.signature: _prompt_template(input: str, completion: str) -> str,\n",
      "name.docstring: _prompt_template(input: str, completion: str) -> str\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='openai.OpenAI', description='class OpenAI'>>,\n",
      "name.signature: Type[OpenAI],\n",
      "name.docstring: OpenAI(*, api_key: str | None=None, organization: str | None=None, base_url: str | httpx.URL | None=None, timeout: Union[float, Timeout, None, NotGiven]=NOT_GIVEN, max_retries: int=DEFAULT_MAX_RETRIES, default_headers: Mapping[str, str] | None=None, default_query: Mapping[str, object] | None=None, http_client: httpx.Client | None=None, _strict_response_validation: bool=False)\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='llmcoder.analyze.Analyzer.Analyzer', description='class Analyzer'>>,\n",
      "name.signature: Type[Analyzer],\n",
      "name.docstring: Analyzer(verbose: bool=False)\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='llmcoder.utils.get_openai_key', description='def get_openai_key'>>,\n",
      "name.signature: get_openai_key(key: str = \"\") -> str,\n",
      "name.docstring: get_openai_key(key: str=\"\") -> str\n",
      "\n",
      "Get OpenAI API key. Try to interpret the key as a key first, then as a path to a file containing the key.\n",
      "Finally, fall back to the default key.txt file or the OPENAI_KEY environment variable.\n",
      "\n",
      "Parameters\n",
      "----------\n",
      "key : str\n",
      "    The key or path to the key file.\n",
      "\n",
      "Returns\n",
      "-------\n",
      "str\n",
      "    The key.\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='llmcoder.utils.get_system_prompt', description='def get_system_prompt'>>,\n",
      "name.signature: get_system_prompt(name: str = \"2023-11-15_GPT-Builder.txt\") -> str,\n",
      "name.docstring: get_system_prompt(name: str=\"2023-11-15_GPT-Builder.txt\") -> str\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='llmcoder.utils.get_system_prompt_dir', description='def get_system_prompt_dir'>>,\n",
      "name.signature: get_system_prompt_dir(*args: str, create: bool = False) -> str,\n",
      "name.docstring: get_system_prompt_dir(*, create: bool=False) -> str\n",
      "\n",
      "Get the path to the system prompts directory.\n",
      "\n",
      "Parameters\n",
      "----------\n",
      "args : str\n",
      "    The path to the system prompts directory.\n",
      "create : bool\n",
      "    Whether to create the directory if it does not exist.\n",
      "\n",
      "Returns\n",
      "-------\n",
      "str\n",
      "    The path to the system prompts directory.\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='__main__.GPTReviewAnalyzer_v1', description='class GPTReviewAnalyzer_v1'>>,\n",
      "name.signature: Type[GPTReviewAnalyzer_v1],\n",
      "name.docstring: GPTReviewAnalyzer_v1(model: str=\"gpt-3.5-turbo\", system_prompt: str | None=None, min_score: int=6, temperature: float=0.2)\n",
      "\n",
      "Concise, professional Python code advisor for targeted feedback.\n",
      "\n",
      "Parameters\n",
      "----------\n",
      "model : str, optional\n",
      "    The model to use, by default \"gpt-3.5-turbo\"\n",
      "system_prompt : str, optional\n",
      "    The system prompt to use, by default `2023-12-02_GPTReviewAnalyzer_v4.txt`, created by GPTBuilder\n",
      "min_score : int, optional\n",
      "    The minimum score to pass the review, by default 6\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='__main__.GPTReviewAnalyzer_v1.__init__', description='def __init__'>>,\n",
      "name.signature: __init__(self, model: str=\"gpt-3.5-turbo\", system_prompt: Optional[str]=None, min_score: int=6, temperature: float=0.2),\n",
      "name.docstring: __init__(self, model: str=\"gpt-3.5-turbo\", system_prompt: str | None=None, min_score: int=6, temperature: float=0.2)\n",
      "\n",
      "Initialize the GPTReviewAnalyzer\n",
      "\n",
      "Parameters\n",
      "----------\n",
      "model : str, optional\n",
      "    The model to use, by default \"gpt-3.5-turbo\"\n",
      "system_prompt : str, optional\n",
      "    The system prompt to use, by default `2023-12-02_GPTReviewAnalyzer_v4.txt`, created by GPTBuilder\n",
      "min_score : int, optional\n",
      "    The minimum score to pass the review, by default 6\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='__main__.GPTReviewAnalyzer_v1.analyze', description='def analyze'>>,\n",
      "name.signature: analyze(self, input: str, completion: str, context: dict[str, dict[str, bool | str]] | None = None) -> dict,\n",
      "name.docstring: analyze(self, input: str, completion: str, context: dict[str, dict[str, bool | str]] | None=None) -> dict\n",
      "\n",
      "Analyze the input and completion\n",
      "\n",
      "Parameters\n",
      "----------\n",
      "input : str\n",
      "    The input to analyze\n",
      "completion : str\n",
      "    The completion to analyze\n",
      "\n",
      "Returns\n",
      "-------\n",
      "dict\n",
      "    The analysis of the input and completion\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='__main__.GPTReviewAnalyzer_v1._prompt_template', description='def _prompt_template'>>,\n",
      "name.signature: _prompt_template(input: str, completion: str) -> str,\n",
      "name.docstring: _prompt_template(input: str, completion: str) -> str\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='openai.OpenAI', description='class OpenAI'>>,\n",
      "name.signature: Type[OpenAI],\n",
      "name.docstring: OpenAI(*, api_key: str | None=None, organization: str | None=None, base_url: str | httpx.URL | None=None, timeout: Union[float, Timeout, None, NotGiven]=NOT_GIVEN, max_retries: int=DEFAULT_MAX_RETRIES, default_headers: Mapping[str, str] | None=None, default_query: Mapping[str, object] | None=None, http_client: httpx.Client | None=None, _strict_response_validation: bool=False)\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='llmcoder.analyze.Analyzer.Analyzer', description='class Analyzer'>>,\n",
      "name.signature: Type[Analyzer],\n",
      "name.docstring: Analyzer(verbose: bool=False)\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='llmcoder.utils.get_openai_key', description='def get_openai_key'>>,\n",
      "name.signature: get_openai_key(key: str = \"\") -> str,\n",
      "name.docstring: get_openai_key(key: str=\"\") -> str\n",
      "\n",
      "Get OpenAI API key. Try to interpret the key as a key first, then as a path to a file containing the key.\n",
      "Finally, fall back to the default key.txt file or the OPENAI_KEY environment variable.\n",
      "\n",
      "Parameters\n",
      "----------\n",
      "key : str\n",
      "    The key or path to the key file.\n",
      "\n",
      "Returns\n",
      "-------\n",
      "str\n",
      "    The key.\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='llmcoder.utils.get_system_prompt', description='def get_system_prompt'>>,\n",
      "name.signature: get_system_prompt(name: str = \"2023-11-15_GPT-Builder.txt\") -> str,\n",
      "name.docstring: get_system_prompt(name: str=\"2023-11-15_GPT-Builder.txt\") -> str\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='llmcoder.utils.get_system_prompt_dir', description='def get_system_prompt_dir'>>,\n",
      "name.signature: get_system_prompt_dir(*args: str, create: bool = False) -> str,\n",
      "name.docstring: get_system_prompt_dir(*, create: bool=False) -> str\n",
      "\n",
      "Get the path to the system prompts directory.\n",
      "\n",
      "Parameters\n",
      "----------\n",
      "args : str\n",
      "    The path to the system prompts directory.\n",
      "create : bool\n",
      "    Whether to create the directory if it does not exist.\n",
      "\n",
      "Returns\n",
      "-------\n",
      "str\n",
      "    The path to the system prompts directory.\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='__main__.GPTReviewAnalyzer_v1', description='class GPTReviewAnalyzer_v1'>>,\n",
      "name.signature: Type[GPTReviewAnalyzer_v1],\n",
      "name.docstring: GPTReviewAnalyzer_v1(model: str=\"gpt-3.5-turbo\", system_prompt: str | None=None, min_score: int=6, temperature: float=0.2)\n",
      "\n",
      "Concise, professional Python code advisor for targeted feedback.\n",
      "\n",
      "Parameters\n",
      "----------\n",
      "model : str, optional\n",
      "    The model to use, by default \"gpt-3.5-turbo\"\n",
      "system_prompt : str, optional\n",
      "    The system prompt to use, by default `2023-12-02_GPTReviewAnalyzer_v4.txt`, created by GPTBuilder\n",
      "min_score : int, optional\n",
      "    The minimum score to pass the review, by default 6\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='__main__.GPTReviewAnalyzer_v1.__init__', description='def __init__'>>,\n",
      "name.signature: __init__(self, model: str=\"gpt-3.5-turbo\", system_prompt: Optional[str]=None, min_score: int=6, temperature: float=0.2),\n",
      "name.docstring: __init__(self, model: str=\"gpt-3.5-turbo\", system_prompt: str | None=None, min_score: int=6, temperature: float=0.2)\n",
      "\n",
      "Initialize the GPTReviewAnalyzer\n",
      "\n",
      "Parameters\n",
      "----------\n",
      "model : str, optional\n",
      "    The model to use, by default \"gpt-3.5-turbo\"\n",
      "system_prompt : str, optional\n",
      "    The system prompt to use, by default `2023-12-02_GPTReviewAnalyzer_v4.txt`, created by GPTBuilder\n",
      "min_score : int, optional\n",
      "    The minimum score to pass the review, by default 6\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='__main__.GPTReviewAnalyzer_v1.analyze', description='def analyze'>>,\n",
      "name.signature: analyze(self, input: str, completion: str, context: dict[str, dict[str, bool | str]] | None = None) -> dict,\n",
      "name.docstring: analyze(self, input: str, completion: str, context: dict[str, dict[str, bool | str]] | None=None) -> dict\n",
      "\n",
      "Analyze the input and completion\n",
      "\n",
      "Parameters\n",
      "----------\n",
      "input : str\n",
      "    The input to analyze\n",
      "completion : str\n",
      "    The completion to analyze\n",
      "\n",
      "Returns\n",
      "-------\n",
      "dict\n",
      "    The analysis of the input and completion\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='__main__.GPTReviewAnalyzer_v1._prompt_template', description='def _prompt_template'>>,\n",
      "name.signature: _prompt_template(input: str, completion: str) -> str,\n",
      "name.docstring: _prompt_template(input: str, completion: str) -> str\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='openai.OpenAI', description='class OpenAI'>>,\n",
      "name.signature: Type[OpenAI],\n",
      "name.docstring: OpenAI(*, api_key: str | None=None, organization: str | None=None, base_url: str | httpx.URL | None=None, timeout: Union[float, Timeout, None, NotGiven]=NOT_GIVEN, max_retries: int=DEFAULT_MAX_RETRIES, default_headers: Mapping[str, str] | None=None, default_query: Mapping[str, object] | None=None, http_client: httpx.Client | None=None, _strict_response_validation: bool=False)\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='llmcoder.analyze.Analyzer.Analyzer', description='class Analyzer'>>,\n",
      "name.signature: Type[Analyzer],\n",
      "name.docstring: Analyzer(verbose: bool=False)\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='llmcoder.utils.get_openai_key', description='def get_openai_key'>>,\n",
      "name.signature: get_openai_key(key: str = \"\") -> str,\n",
      "name.docstring: get_openai_key(key: str=\"\") -> str\n",
      "\n",
      "Get OpenAI API key. Try to interpret the key as a key first, then as a path to a file containing the key.\n",
      "Finally, fall back to the default key.txt file or the OPENAI_KEY environment variable.\n",
      "\n",
      "Parameters\n",
      "----------\n",
      "key : str\n",
      "    The key or path to the key file.\n",
      "\n",
      "Returns\n",
      "-------\n",
      "str\n",
      "    The key.\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='llmcoder.utils.get_system_prompt', description='def get_system_prompt'>>,\n",
      "name.signature: get_system_prompt(name: str = \"2023-11-15_GPT-Builder.txt\") -> str,\n",
      "name.docstring: get_system_prompt(name: str=\"2023-11-15_GPT-Builder.txt\") -> str\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='llmcoder.utils.get_system_prompt_dir', description='def get_system_prompt_dir'>>,\n",
      "name.signature: get_system_prompt_dir(*args: str, create: bool = False) -> str,\n",
      "name.docstring: get_system_prompt_dir(*, create: bool=False) -> str\n",
      "\n",
      "Get the path to the system prompts directory.\n",
      "\n",
      "Parameters\n",
      "----------\n",
      "args : str\n",
      "    The path to the system prompts directory.\n",
      "create : bool\n",
      "    Whether to create the directory if it does not exist.\n",
      "\n",
      "Returns\n",
      "-------\n",
      "str\n",
      "    The path to the system prompts directory.\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='__main__.GPTReviewAnalyzer_v1', description='class GPTReviewAnalyzer_v1'>>,\n",
      "name.signature: Type[GPTReviewAnalyzer_v1],\n",
      "name.docstring: GPTReviewAnalyzer_v1(model: str=\"gpt-3.5-turbo\", system_prompt: str | None=None, min_score: int=6, temperature: float=0.2)\n",
      "\n",
      "Concise, professional Python code advisor for targeted feedback.\n",
      "\n",
      "Parameters\n",
      "----------\n",
      "model : str, optional\n",
      "    The model to use, by default \"gpt-3.5-turbo\"\n",
      "system_prompt : str, optional\n",
      "    The system prompt to use, by default `2023-12-02_GPTReviewAnalyzer_v4.txt`, created by GPTBuilder\n",
      "min_score : int, optional\n",
      "    The minimum score to pass the review, by default 6\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='__main__.GPTReviewAnalyzer_v1.__init__', description='def __init__'>>,\n",
      "name.signature: __init__(self, model: str=\"gpt-3.5-turbo\", system_prompt: Optional[str]=None, min_score: int=6, temperature: float=0.2),\n",
      "name.docstring: __init__(self, model: str=\"gpt-3.5-turbo\", system_prompt: str | None=None, min_score: int=6, temperature: float=0.2)\n",
      "\n",
      "Initialize the GPTReviewAnalyzer\n",
      "\n",
      "Parameters\n",
      "----------\n",
      "model : str, optional\n",
      "    The model to use, by default \"gpt-3.5-turbo\"\n",
      "system_prompt : str, optional\n",
      "    The system prompt to use, by default `2023-12-02_GPTReviewAnalyzer_v4.txt`, created by GPTBuilder\n",
      "min_score : int, optional\n",
      "    The minimum score to pass the review, by default 6\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='__main__.GPTReviewAnalyzer_v1.analyze', description='def analyze'>>,\n",
      "name.signature: analyze(self, input: str, completion: str, context: dict[str, dict[str, bool | str]] | None = None) -> dict,\n",
      "name.docstring: analyze(self, input: str, completion: str, context: dict[str, dict[str, bool | str]] | None=None) -> dict\n",
      "\n",
      "Analyze the input and completion\n",
      "\n",
      "Parameters\n",
      "----------\n",
      "input : str\n",
      "    The input to analyze\n",
      "completion : str\n",
      "    The completion to analyze\n",
      "\n",
      "Returns\n",
      "-------\n",
      "dict\n",
      "    The analysis of the input and completion\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='__main__.GPTReviewAnalyzer_v1._prompt_template', description='def _prompt_template'>>,\n",
      "name.signature: _prompt_template(input: str, completion: str) -> str,\n",
      "name.docstring: _prompt_template(input: str, completion: str) -> str\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='openai.OpenAI', description='class OpenAI'>>,\n",
      "name.signature: Type[OpenAI],\n",
      "name.docstring: OpenAI(*, api_key: str | None=None, organization: str | None=None, base_url: str | httpx.URL | None=None, timeout: Union[float, Timeout, None, NotGiven]=NOT_GIVEN, max_retries: int=DEFAULT_MAX_RETRIES, default_headers: Mapping[str, str] | None=None, default_query: Mapping[str, object] | None=None, http_client: httpx.Client | None=None, _strict_response_validation: bool=False)\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='llmcoder.analyze.Analyzer.Analyzer', description='class Analyzer'>>,\n",
      "name.signature: Type[Analyzer],\n",
      "name.docstring: Analyzer(verbose: bool=False)\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='llmcoder.utils.get_openai_key', description='def get_openai_key'>>,\n",
      "name.signature: get_openai_key(key: str = \"\") -> str,\n",
      "name.docstring: get_openai_key(key: str=\"\") -> str\n",
      "\n",
      "Get OpenAI API key. Try to interpret the key as a key first, then as a path to a file containing the key.\n",
      "Finally, fall back to the default key.txt file or the OPENAI_KEY environment variable.\n",
      "\n",
      "Parameters\n",
      "----------\n",
      "key : str\n",
      "    The key or path to the key file.\n",
      "\n",
      "Returns\n",
      "-------\n",
      "str\n",
      "    The key.\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='llmcoder.utils.get_system_prompt', description='def get_system_prompt'>>,\n",
      "name.signature: get_system_prompt(name: str = \"2023-11-15_GPT-Builder.txt\") -> str,\n",
      "name.docstring: get_system_prompt(name: str=\"2023-11-15_GPT-Builder.txt\") -> str\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='llmcoder.utils.get_system_prompt_dir', description='def get_system_prompt_dir'>>,\n",
      "name.signature: get_system_prompt_dir(*args: str, create: bool = False) -> str,\n",
      "name.docstring: get_system_prompt_dir(*, create: bool=False) -> str\n",
      "\n",
      "Get the path to the system prompts directory.\n",
      "\n",
      "Parameters\n",
      "----------\n",
      "args : str\n",
      "    The path to the system prompts directory.\n",
      "create : bool\n",
      "    Whether to create the directory if it does not exist.\n",
      "\n",
      "Returns\n",
      "-------\n",
      "str\n",
      "    The path to the system prompts directory.\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='__main__.GPTReviewAnalyzer_v1', description='class GPTReviewAnalyzer_v1'>>,\n",
      "name.signature: Type[GPTReviewAnalyzer_v1],\n",
      "name.docstring: GPTReviewAnalyzer_v1(model: str=\"gpt-3.5-turbo\", system_prompt: str | None=None, min_score: int=6, temperature: float=0.2)\n",
      "\n",
      "Concise, professional Python code advisor for targeted feedback.\n",
      "\n",
      "Parameters\n",
      "----------\n",
      "model : str, optional\n",
      "    The model to use, by default \"gpt-3.5-turbo\"\n",
      "system_prompt : str, optional\n",
      "    The system prompt to use, by default `2023-12-02_GPTReviewAnalyzer_v4.txt`, created by GPTBuilder\n",
      "min_score : int, optional\n",
      "    The minimum score to pass the review, by default 6\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='__main__.GPTReviewAnalyzer_v1.__init__', description='def __init__'>>,\n",
      "name.signature: __init__(self, model: str=\"gpt-3.5-turbo\", system_prompt: Optional[str]=None, min_score: int=6, temperature: float=0.2),\n",
      "name.docstring: __init__(self, model: str=\"gpt-3.5-turbo\", system_prompt: str | None=None, min_score: int=6, temperature: float=0.2)\n",
      "\n",
      "Initialize the GPTReviewAnalyzer\n",
      "\n",
      "Parameters\n",
      "----------\n",
      "model : str, optional\n",
      "    The model to use, by default \"gpt-3.5-turbo\"\n",
      "system_prompt : str, optional\n",
      "    The system prompt to use, by default `2023-12-02_GPTReviewAnalyzer_v4.txt`, created by GPTBuilder\n",
      "min_score : int, optional\n",
      "    The minimum score to pass the review, by default 6\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='__main__.GPTReviewAnalyzer_v1.analyze', description='def analyze'>>,\n",
      "name.signature: analyze(self, input: str, completion: str, context: dict[str, dict[str, bool | str]] | None = None) -> dict,\n",
      "name.docstring: analyze(self, input: str, completion: str, context: dict[str, dict[str, bool | str]] | None=None) -> dict\n",
      "\n",
      "Analyze the input and completion\n",
      "\n",
      "Parameters\n",
      "----------\n",
      "input : str\n",
      "    The input to analyze\n",
      "completion : str\n",
      "    The completion to analyze\n",
      "\n",
      "Returns\n",
      "-------\n",
      "dict\n",
      "    The analysis of the input and completion\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='__main__.GPTReviewAnalyzer_v1._prompt_template', description='def _prompt_template'>>,\n",
      "name.signature: _prompt_template(input: str, completion: str) -> str,\n",
      "name.docstring: _prompt_template(input: str, completion: str) -> str\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='openai.OpenAI', description='class OpenAI'>>,\n",
      "name.signature: Type[OpenAI],\n",
      "name.docstring: OpenAI(*, api_key: str | None=None, organization: str | None=None, base_url: str | httpx.URL | None=None, timeout: Union[float, Timeout, None, NotGiven]=NOT_GIVEN, max_retries: int=DEFAULT_MAX_RETRIES, default_headers: Mapping[str, str] | None=None, default_query: Mapping[str, object] | None=None, http_client: httpx.Client | None=None, _strict_response_validation: bool=False)\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='llmcoder.analyze.Analyzer.Analyzer', description='class Analyzer'>>,\n",
      "name.signature: Type[Analyzer],\n",
      "name.docstring: Analyzer(verbose: bool=False)\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='llmcoder.utils.get_openai_key', description='def get_openai_key'>>,\n",
      "name.signature: get_openai_key(key: str = \"\") -> str,\n",
      "name.docstring: get_openai_key(key: str=\"\") -> str\n",
      "\n",
      "Get OpenAI API key. Try to interpret the key as a key first, then as a path to a file containing the key.\n",
      "Finally, fall back to the default key.txt file or the OPENAI_KEY environment variable.\n",
      "\n",
      "Parameters\n",
      "----------\n",
      "key : str\n",
      "    The key or path to the key file.\n",
      "\n",
      "Returns\n",
      "-------\n",
      "str\n",
      "    The key.\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='llmcoder.utils.get_system_prompt', description='def get_system_prompt'>>,\n",
      "name.signature: get_system_prompt(name: str = \"2023-11-15_GPT-Builder.txt\") -> str,\n",
      "name.docstring: get_system_prompt(name: str=\"2023-11-15_GPT-Builder.txt\") -> str\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='llmcoder.utils.get_system_prompt_dir', description='def get_system_prompt_dir'>>,\n",
      "name.signature: get_system_prompt_dir(*args: str, create: bool = False) -> str,\n",
      "name.docstring: get_system_prompt_dir(*, create: bool=False) -> str\n",
      "\n",
      "Get the path to the system prompts directory.\n",
      "\n",
      "Parameters\n",
      "----------\n",
      "args : str\n",
      "    The path to the system prompts directory.\n",
      "create : bool\n",
      "    Whether to create the directory if it does not exist.\n",
      "\n",
      "Returns\n",
      "-------\n",
      "str\n",
      "    The path to the system prompts directory.\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='__main__.GPTReviewAnalyzer_v1', description='class GPTReviewAnalyzer_v1'>>,\n",
      "name.signature: Type[GPTReviewAnalyzer_v1],\n",
      "name.docstring: GPTReviewAnalyzer_v1(model: str=\"gpt-3.5-turbo\", system_prompt: str | None=None, min_score: int=6, temperature: float=0.2)\n",
      "\n",
      "Concise, professional Python code advisor for targeted feedback.\n",
      "\n",
      "Parameters\n",
      "----------\n",
      "model : str, optional\n",
      "    The model to use, by default \"gpt-3.5-turbo\"\n",
      "system_prompt : str, optional\n",
      "    The system prompt to use, by default `2023-12-02_GPTReviewAnalyzer_v4.txt`, created by GPTBuilder\n",
      "min_score : int, optional\n",
      "    The minimum score to pass the review, by default 6\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='__main__.GPTReviewAnalyzer_v1.__init__', description='def __init__'>>,\n",
      "name.signature: __init__(self, model: str=\"gpt-3.5-turbo\", system_prompt: Optional[str]=None, min_score: int=6, temperature: float=0.2),\n",
      "name.docstring: __init__(self, model: str=\"gpt-3.5-turbo\", system_prompt: str | None=None, min_score: int=6, temperature: float=0.2)\n",
      "\n",
      "Initialize the GPTReviewAnalyzer\n",
      "\n",
      "Parameters\n",
      "----------\n",
      "model : str, optional\n",
      "    The model to use, by default \"gpt-3.5-turbo\"\n",
      "system_prompt : str, optional\n",
      "    The system prompt to use, by default `2023-12-02_GPTReviewAnalyzer_v4.txt`, created by GPTBuilder\n",
      "min_score : int, optional\n",
      "    The minimum score to pass the review, by default 6\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='__main__.GPTReviewAnalyzer_v1.analyze', description='def analyze'>>,\n",
      "name.signature: analyze(self, input: str, completion: str, context: dict[str, dict[str, bool | str]] | None = None) -> dict,\n",
      "name.docstring: analyze(self, input: str, completion: str, context: dict[str, dict[str, bool | str]] | None=None) -> dict\n",
      "\n",
      "Analyze the input and completion\n",
      "\n",
      "Parameters\n",
      "----------\n",
      "input : str\n",
      "    The input to analyze\n",
      "completion : str\n",
      "    The completion to analyze\n",
      "\n",
      "Returns\n",
      "-------\n",
      "dict\n",
      "    The analysis of the input and completion\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='__main__.GPTReviewAnalyzer_v1._prompt_template', description='def _prompt_template'>>,\n",
      "name.signature: _prompt_template(input: str, completion: str) -> str,\n",
      "name.docstring: _prompt_template(input: str, completion: str) -> str\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='openai.OpenAI', description='class OpenAI'>>,\n",
      "name.signature: Type[OpenAI],\n",
      "name.docstring: OpenAI(*, api_key: str | None=None, organization: str | None=None, base_url: str | httpx.URL | None=None, timeout: Union[float, Timeout, None, NotGiven]=NOT_GIVEN, max_retries: int=DEFAULT_MAX_RETRIES, default_headers: Mapping[str, str] | None=None, default_query: Mapping[str, object] | None=None, http_client: httpx.Client | None=None, _strict_response_validation: bool=False)\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='llmcoder.analyze.Analyzer.Analyzer', description='class Analyzer'>>,\n",
      "name.signature: Type[Analyzer],\n",
      "name.docstring: Analyzer(verbose: bool=False)\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='llmcoder.utils.get_openai_key', description='def get_openai_key'>>,\n",
      "name.signature: get_openai_key(key: str = \"\") -> str,\n",
      "name.docstring: get_openai_key(key: str=\"\") -> str\n",
      "\n",
      "Get OpenAI API key. Try to interpret the key as a key first, then as a path to a file containing the key.\n",
      "Finally, fall back to the default key.txt file or the OPENAI_KEY environment variable.\n",
      "\n",
      "Parameters\n",
      "----------\n",
      "key : str\n",
      "    The key or path to the key file.\n",
      "\n",
      "Returns\n",
      "-------\n",
      "str\n",
      "    The key.\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='llmcoder.utils.get_system_prompt', description='def get_system_prompt'>>,\n",
      "name.signature: get_system_prompt(name: str = \"2023-11-15_GPT-Builder.txt\") -> str,\n",
      "name.docstring: get_system_prompt(name: str=\"2023-11-15_GPT-Builder.txt\") -> str\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='llmcoder.utils.get_system_prompt_dir', description='def get_system_prompt_dir'>>,\n",
      "name.signature: get_system_prompt_dir(*args: str, create: bool = False) -> str,\n",
      "name.docstring: get_system_prompt_dir(*, create: bool=False) -> str\n",
      "\n",
      "Get the path to the system prompts directory.\n",
      "\n",
      "Parameters\n",
      "----------\n",
      "args : str\n",
      "    The path to the system prompts directory.\n",
      "create : bool\n",
      "    Whether to create the directory if it does not exist.\n",
      "\n",
      "Returns\n",
      "-------\n",
      "str\n",
      "    The path to the system prompts directory.\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='__main__.GPTReviewAnalyzer_v1', description='class GPTReviewAnalyzer_v1'>>,\n",
      "name.signature: Type[GPTReviewAnalyzer_v1],\n",
      "name.docstring: GPTReviewAnalyzer_v1(model: str=\"gpt-3.5-turbo\", system_prompt: str | None=None, min_score: int=6, temperature: float=0.2)\n",
      "\n",
      "Concise, professional Python code advisor for targeted feedback.\n",
      "\n",
      "Parameters\n",
      "----------\n",
      "model : str, optional\n",
      "    The model to use, by default \"gpt-3.5-turbo\"\n",
      "system_prompt : str, optional\n",
      "    The system prompt to use, by default `2023-12-02_GPTReviewAnalyzer_v4.txt`, created by GPTBuilder\n",
      "min_score : int, optional\n",
      "    The minimum score to pass the review, by default 6\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='__main__.GPTReviewAnalyzer_v1.__init__', description='def __init__'>>,\n",
      "name.signature: __init__(self, model: str=\"gpt-3.5-turbo\", system_prompt: Optional[str]=None, min_score: int=6, temperature: float=0.2),\n",
      "name.docstring: __init__(self, model: str=\"gpt-3.5-turbo\", system_prompt: str | None=None, min_score: int=6, temperature: float=0.2)\n",
      "\n",
      "Initialize the GPTReviewAnalyzer\n",
      "\n",
      "Parameters\n",
      "----------\n",
      "model : str, optional\n",
      "    The model to use, by default \"gpt-3.5-turbo\"\n",
      "system_prompt : str, optional\n",
      "    The system prompt to use, by default `2023-12-02_GPTReviewAnalyzer_v4.txt`, created by GPTBuilder\n",
      "min_score : int, optional\n",
      "    The minimum score to pass the review, by default 6\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='__main__.GPTReviewAnalyzer_v1.analyze', description='def analyze'>>,\n",
      "name.signature: analyze(self, input: str, completion: str, context: dict[str, dict[str, bool | str]] | None = None) -> dict,\n",
      "name.docstring: analyze(self, input: str, completion: str, context: dict[str, dict[str, bool | str]] | None=None) -> dict\n",
      "\n",
      "Analyze the input and completion\n",
      "\n",
      "Parameters\n",
      "----------\n",
      "input : str\n",
      "    The input to analyze\n",
      "completion : str\n",
      "    The completion to analyze\n",
      "\n",
      "Returns\n",
      "-------\n",
      "dict\n",
      "    The analysis of the input and completion\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='__main__.GPTReviewAnalyzer_v1._prompt_template', description='def _prompt_template'>>,\n",
      "name.signature: _prompt_template(input: str, completion: str) -> str,\n",
      "name.docstring: _prompt_template(input: str, completion: str) -> str\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='openai.OpenAI', description='class OpenAI'>>,\n",
      "name.signature: Type[OpenAI],\n",
      "name.docstring: OpenAI(*, api_key: str | None=None, organization: str | None=None, base_url: str | httpx.URL | None=None, timeout: Union[float, Timeout, None, NotGiven]=NOT_GIVEN, max_retries: int=DEFAULT_MAX_RETRIES, default_headers: Mapping[str, str] | None=None, default_query: Mapping[str, object] | None=None, http_client: httpx.Client | None=None, _strict_response_validation: bool=False)\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='llmcoder.analyze.Analyzer.Analyzer', description='class Analyzer'>>,\n",
      "name.signature: Type[Analyzer],\n",
      "name.docstring: Analyzer(verbose: bool=False)\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='llmcoder.utils.get_openai_key', description='def get_openai_key'>>,\n",
      "name.signature: get_openai_key(key: str = \"\") -> str,\n",
      "name.docstring: get_openai_key(key: str=\"\") -> str\n",
      "\n",
      "Get OpenAI API key. Try to interpret the key as a key first, then as a path to a file containing the key.\n",
      "Finally, fall back to the default key.txt file or the OPENAI_KEY environment variable.\n",
      "\n",
      "Parameters\n",
      "----------\n",
      "key : str\n",
      "    The key or path to the key file.\n",
      "\n",
      "Returns\n",
      "-------\n",
      "str\n",
      "    The key.\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='llmcoder.utils.get_system_prompt', description='def get_system_prompt'>>,\n",
      "name.signature: get_system_prompt(name: str = \"2023-11-15_GPT-Builder.txt\") -> str,\n",
      "name.docstring: get_system_prompt(name: str=\"2023-11-15_GPT-Builder.txt\") -> str\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='llmcoder.utils.get_system_prompt_dir', description='def get_system_prompt_dir'>>,\n",
      "name.signature: get_system_prompt_dir(*args: str, create: bool = False) -> str,\n",
      "name.docstring: get_system_prompt_dir(*, create: bool=False) -> str\n",
      "\n",
      "Get the path to the system prompts directory.\n",
      "\n",
      "Parameters\n",
      "----------\n",
      "args : str\n",
      "    The path to the system prompts directory.\n",
      "create : bool\n",
      "    Whether to create the directory if it does not exist.\n",
      "\n",
      "Returns\n",
      "-------\n",
      "str\n",
      "    The path to the system prompts directory.\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='__main__.GPTReviewAnalyzer_v1', description='class GPTReviewAnalyzer_v1'>>,\n",
      "name.signature: Type[GPTReviewAnalyzer_v1],\n",
      "name.docstring: GPTReviewAnalyzer_v1(model: str=\"gpt-3.5-turbo\", system_prompt: str | None=None, min_score: int=6, temperature: float=0.2)\n",
      "\n",
      "Concise, professional Python code advisor for targeted feedback.\n",
      "\n",
      "Parameters\n",
      "----------\n",
      "model : str, optional\n",
      "    The model to use, by default \"gpt-3.5-turbo\"\n",
      "system_prompt : str, optional\n",
      "    The system prompt to use, by default `2023-12-02_GPTReviewAnalyzer_v4.txt`, created by GPTBuilder\n",
      "min_score : int, optional\n",
      "    The minimum score to pass the review, by default 6\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='__main__.GPTReviewAnalyzer_v1.__init__', description='def __init__'>>,\n",
      "name.signature: __init__(self, model: str=\"gpt-3.5-turbo\", system_prompt: Optional[str]=None, min_score: int=6, temperature: float=0.2),\n",
      "name.docstring: __init__(self, model: str=\"gpt-3.5-turbo\", system_prompt: str | None=None, min_score: int=6, temperature: float=0.2)\n",
      "\n",
      "Initialize the GPTReviewAnalyzer\n",
      "\n",
      "Parameters\n",
      "----------\n",
      "model : str, optional\n",
      "    The model to use, by default \"gpt-3.5-turbo\"\n",
      "system_prompt : str, optional\n",
      "    The system prompt to use, by default `2023-12-02_GPTReviewAnalyzer_v4.txt`, created by GPTBuilder\n",
      "min_score : int, optional\n",
      "    The minimum score to pass the review, by default 6\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='__main__.GPTReviewAnalyzer_v1.analyze', description='def analyze'>>,\n",
      "name.signature: analyze(self, input: str, completion: str, context: dict[str, dict[str, bool | str]] | None = None) -> dict,\n",
      "name.docstring: analyze(self, input: str, completion: str, context: dict[str, dict[str, bool | str]] | None=None) -> dict\n",
      "\n",
      "Analyze the input and completion\n",
      "\n",
      "Parameters\n",
      "----------\n",
      "input : str\n",
      "    The input to analyze\n",
      "completion : str\n",
      "    The completion to analyze\n",
      "\n",
      "Returns\n",
      "-------\n",
      "dict\n",
      "    The analysis of the input and completion\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='__main__.GPTReviewAnalyzer_v1._prompt_template', description='def _prompt_template'>>,\n",
      "name.signature: _prompt_template(input: str, completion: str) -> str,\n",
      "name.docstring: _prompt_template(input: str, completion: str) -> str\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='openai.OpenAI', description='class OpenAI'>>,\n",
      "name.signature: Type[OpenAI],\n",
      "name.docstring: OpenAI(*, api_key: str | None=None, organization: str | None=None, base_url: str | httpx.URL | None=None, timeout: Union[float, Timeout, None, NotGiven]=NOT_GIVEN, max_retries: int=DEFAULT_MAX_RETRIES, default_headers: Mapping[str, str] | None=None, default_query: Mapping[str, object] | None=None, http_client: httpx.Client | None=None, _strict_response_validation: bool=False)\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='llmcoder.analyze.Analyzer.Analyzer', description='class Analyzer'>>,\n",
      "name.signature: Type[Analyzer],\n",
      "name.docstring: Analyzer(verbose: bool=False)\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='llmcoder.utils.get_openai_key', description='def get_openai_key'>>,\n",
      "name.signature: get_openai_key(key: str = \"\") -> str,\n",
      "name.docstring: get_openai_key(key: str=\"\") -> str\n",
      "\n",
      "Get OpenAI API key. Try to interpret the key as a key first, then as a path to a file containing the key.\n",
      "Finally, fall back to the default key.txt file or the OPENAI_KEY environment variable.\n",
      "\n",
      "Parameters\n",
      "----------\n",
      "key : str\n",
      "    The key or path to the key file.\n",
      "\n",
      "Returns\n",
      "-------\n",
      "str\n",
      "    The key.\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='llmcoder.utils.get_system_prompt', description='def get_system_prompt'>>,\n",
      "name.signature: get_system_prompt(name: str = \"2023-11-15_GPT-Builder.txt\") -> str,\n",
      "name.docstring: get_system_prompt(name: str=\"2023-11-15_GPT-Builder.txt\") -> str\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='llmcoder.utils.get_system_prompt_dir', description='def get_system_prompt_dir'>>,\n",
      "name.signature: get_system_prompt_dir(*args: str, create: bool = False) -> str,\n",
      "name.docstring: get_system_prompt_dir(*, create: bool=False) -> str\n",
      "\n",
      "Get the path to the system prompts directory.\n",
      "\n",
      "Parameters\n",
      "----------\n",
      "args : str\n",
      "    The path to the system prompts directory.\n",
      "create : bool\n",
      "    Whether to create the directory if it does not exist.\n",
      "\n",
      "Returns\n",
      "-------\n",
      "str\n",
      "    The path to the system prompts directory.\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='__main__.GPTReviewAnalyzer_v1', description='class GPTReviewAnalyzer_v1'>>,\n",
      "name.signature: Type[GPTReviewAnalyzer_v1],\n",
      "name.docstring: GPTReviewAnalyzer_v1(model: str=\"gpt-3.5-turbo\", system_prompt: str | None=None, min_score: int=6, temperature: float=0.2)\n",
      "\n",
      "Concise, professional Python code advisor for targeted feedback.\n",
      "\n",
      "Parameters\n",
      "----------\n",
      "model : str, optional\n",
      "    The model to use, by default \"gpt-3.5-turbo\"\n",
      "system_prompt : str, optional\n",
      "    The system prompt to use, by default `2023-12-02_GPTReviewAnalyzer_v4.txt`, created by GPTBuilder\n",
      "min_score : int, optional\n",
      "    The minimum score to pass the review, by default 6\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='__main__.GPTReviewAnalyzer_v1.__init__', description='def __init__'>>,\n",
      "name.signature: __init__(self, model: str=\"gpt-3.5-turbo\", system_prompt: Optional[str]=None, min_score: int=6, temperature: float=0.2),\n",
      "name.docstring: __init__(self, model: str=\"gpt-3.5-turbo\", system_prompt: str | None=None, min_score: int=6, temperature: float=0.2)\n",
      "\n",
      "Initialize the GPTReviewAnalyzer\n",
      "\n",
      "Parameters\n",
      "----------\n",
      "model : str, optional\n",
      "    The model to use, by default \"gpt-3.5-turbo\"\n",
      "system_prompt : str, optional\n",
      "    The system prompt to use, by default `2023-12-02_GPTReviewAnalyzer_v4.txt`, created by GPTBuilder\n",
      "min_score : int, optional\n",
      "    The minimum score to pass the review, by default 6\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='__main__.GPTReviewAnalyzer_v1.analyze', description='def analyze'>>,\n",
      "name.signature: analyze(self, input: str, completion: str, context: dict[str, dict[str, bool | str]] | None = None) -> dict,\n",
      "name.docstring: analyze(self, input: str, completion: str, context: dict[str, dict[str, bool | str]] | None=None) -> dict\n",
      "\n",
      "Analyze the input and completion\n",
      "\n",
      "Parameters\n",
      "----------\n",
      "input : str\n",
      "    The input to analyze\n",
      "completion : str\n",
      "    The completion to analyze\n",
      "\n",
      "Returns\n",
      "-------\n",
      "dict\n",
      "    The analysis of the input and completion\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='__main__.GPTReviewAnalyzer_v1._prompt_template', description='def _prompt_template'>>,\n",
      "name.signature: _prompt_template(input: str, completion: str) -> str,\n",
      "name.docstring: _prompt_template(input: str, completion: str) -> str\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='openai.OpenAI', description='class OpenAI'>>,\n",
      "name.signature: Type[OpenAI],\n",
      "name.docstring: OpenAI(*, api_key: str | None=None, organization: str | None=None, base_url: str | httpx.URL | None=None, timeout: Union[float, Timeout, None, NotGiven]=NOT_GIVEN, max_retries: int=DEFAULT_MAX_RETRIES, default_headers: Mapping[str, str] | None=None, default_query: Mapping[str, object] | None=None, http_client: httpx.Client | None=None, _strict_response_validation: bool=False)\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='llmcoder.analyze.Analyzer.Analyzer', description='class Analyzer'>>,\n",
      "name.signature: Type[Analyzer],\n",
      "name.docstring: Analyzer(verbose: bool=False)\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='llmcoder.utils.get_openai_key', description='def get_openai_key'>>,\n",
      "name.signature: get_openai_key(key: str = \"\") -> str,\n",
      "name.docstring: get_openai_key(key: str=\"\") -> str\n",
      "\n",
      "Get OpenAI API key. Try to interpret the key as a key first, then as a path to a file containing the key.\n",
      "Finally, fall back to the default key.txt file or the OPENAI_KEY environment variable.\n",
      "\n",
      "Parameters\n",
      "----------\n",
      "key : str\n",
      "    The key or path to the key file.\n",
      "\n",
      "Returns\n",
      "-------\n",
      "str\n",
      "    The key.\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='llmcoder.utils.get_system_prompt', description='def get_system_prompt'>>,\n",
      "name.signature: get_system_prompt(name: str = \"2023-11-15_GPT-Builder.txt\") -> str,\n",
      "name.docstring: get_system_prompt(name: str=\"2023-11-15_GPT-Builder.txt\") -> str\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='llmcoder.utils.get_system_prompt_dir', description='def get_system_prompt_dir'>>,\n",
      "name.signature: get_system_prompt_dir(*args: str, create: bool = False) -> str,\n",
      "name.docstring: get_system_prompt_dir(*, create: bool=False) -> str\n",
      "\n",
      "Get the path to the system prompts directory.\n",
      "\n",
      "Parameters\n",
      "----------\n",
      "args : str\n",
      "    The path to the system prompts directory.\n",
      "create : bool\n",
      "    Whether to create the directory if it does not exist.\n",
      "\n",
      "Returns\n",
      "-------\n",
      "str\n",
      "    The path to the system prompts directory.\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='__main__.GPTReviewAnalyzer_v1', description='class GPTReviewAnalyzer_v1'>>,\n",
      "name.signature: Type[GPTReviewAnalyzer_v1],\n",
      "name.docstring: GPTReviewAnalyzer_v1(model: str=\"gpt-3.5-turbo\", system_prompt: str | None=None, min_score: int=6, temperature: float=0.2)\n",
      "\n",
      "Concise, professional Python code advisor for targeted feedback.\n",
      "\n",
      "Parameters\n",
      "----------\n",
      "model : str, optional\n",
      "    The model to use, by default \"gpt-3.5-turbo\"\n",
      "system_prompt : str, optional\n",
      "    The system prompt to use, by default `2023-12-02_GPTReviewAnalyzer_v4.txt`, created by GPTBuilder\n",
      "min_score : int, optional\n",
      "    The minimum score to pass the review, by default 6\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='__main__.GPTReviewAnalyzer_v1.__init__', description='def __init__'>>,\n",
      "name.signature: __init__(self, model: str=\"gpt-3.5-turbo\", system_prompt: Optional[str]=None, min_score: int=6, temperature: float=0.2),\n",
      "name.docstring: __init__(self, model: str=\"gpt-3.5-turbo\", system_prompt: str | None=None, min_score: int=6, temperature: float=0.2)\n",
      "\n",
      "Initialize the GPTReviewAnalyzer\n",
      "\n",
      "Parameters\n",
      "----------\n",
      "model : str, optional\n",
      "    The model to use, by default \"gpt-3.5-turbo\"\n",
      "system_prompt : str, optional\n",
      "    The system prompt to use, by default `2023-12-02_GPTReviewAnalyzer_v4.txt`, created by GPTBuilder\n",
      "min_score : int, optional\n",
      "    The minimum score to pass the review, by default 6\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='__main__.GPTReviewAnalyzer_v1.analyze', description='def analyze'>>,\n",
      "name.signature: analyze(self, input: str, completion: str, context: dict[str, dict[str, bool | str]] | None = None) -> dict,\n",
      "name.docstring: analyze(self, input: str, completion: str, context: dict[str, dict[str, bool | str]] | None=None) -> dict\n",
      "\n",
      "Analyze the input and completion\n",
      "\n",
      "Parameters\n",
      "----------\n",
      "input : str\n",
      "    The input to analyze\n",
      "completion : str\n",
      "    The completion to analyze\n",
      "\n",
      "Returns\n",
      "-------\n",
      "dict\n",
      "    The analysis of the input and completion\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='__main__.GPTReviewAnalyzer_v1._prompt_template', description='def _prompt_template'>>,\n",
      "name.signature: _prompt_template(input: str, completion: str) -> str,\n",
      "name.docstring: _prompt_template(input: str, completion: str) -> str\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='openai.OpenAI', description='class OpenAI'>>,\n",
      "name.signature: Type[OpenAI],\n",
      "name.docstring: OpenAI(*, api_key: str | None=None, organization: str | None=None, base_url: str | httpx.URL | None=None, timeout: Union[float, Timeout, None, NotGiven]=NOT_GIVEN, max_retries: int=DEFAULT_MAX_RETRIES, default_headers: Mapping[str, str] | None=None, default_query: Mapping[str, object] | None=None, http_client: httpx.Client | None=None, _strict_response_validation: bool=False)\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='llmcoder.analyze.Analyzer.Analyzer', description='class Analyzer'>>,\n",
      "name.signature: Type[Analyzer],\n",
      "name.docstring: Analyzer(verbose: bool=False)\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='llmcoder.utils.get_openai_key', description='def get_openai_key'>>,\n",
      "name.signature: get_openai_key(key: str = \"\") -> str,\n",
      "name.docstring: get_openai_key(key: str=\"\") -> str\n",
      "\n",
      "Get OpenAI API key. Try to interpret the key as a key first, then as a path to a file containing the key.\n",
      "Finally, fall back to the default key.txt file or the OPENAI_KEY environment variable.\n",
      "\n",
      "Parameters\n",
      "----------\n",
      "key : str\n",
      "    The key or path to the key file.\n",
      "\n",
      "Returns\n",
      "-------\n",
      "str\n",
      "    The key.\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='llmcoder.utils.get_system_prompt', description='def get_system_prompt'>>,\n",
      "name.signature: get_system_prompt(name: str = \"2023-11-15_GPT-Builder.txt\") -> str,\n",
      "name.docstring: get_system_prompt(name: str=\"2023-11-15_GPT-Builder.txt\") -> str\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='llmcoder.utils.get_system_prompt_dir', description='def get_system_prompt_dir'>>,\n",
      "name.signature: get_system_prompt_dir(*args: str, create: bool = False) -> str,\n",
      "name.docstring: get_system_prompt_dir(*, create: bool=False) -> str\n",
      "\n",
      "Get the path to the system prompts directory.\n",
      "\n",
      "Parameters\n",
      "----------\n",
      "args : str\n",
      "    The path to the system prompts directory.\n",
      "create : bool\n",
      "    Whether to create the directory if it does not exist.\n",
      "\n",
      "Returns\n",
      "-------\n",
      "str\n",
      "    The path to the system prompts directory.\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='__main__.GPTReviewAnalyzer_v1', description='class GPTReviewAnalyzer_v1'>>,\n",
      "name.signature: Type[GPTReviewAnalyzer_v1],\n",
      "name.docstring: GPTReviewAnalyzer_v1(model: str=\"gpt-3.5-turbo\", system_prompt: str | None=None, min_score: int=6, temperature: float=0.2)\n",
      "\n",
      "Concise, professional Python code advisor for targeted feedback.\n",
      "\n",
      "Parameters\n",
      "----------\n",
      "model : str, optional\n",
      "    The model to use, by default \"gpt-3.5-turbo\"\n",
      "system_prompt : str, optional\n",
      "    The system prompt to use, by default `2023-12-02_GPTReviewAnalyzer_v4.txt`, created by GPTBuilder\n",
      "min_score : int, optional\n",
      "    The minimum score to pass the review, by default 6\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='__main__.GPTReviewAnalyzer_v1.__init__', description='def __init__'>>,\n",
      "name.signature: __init__(self, model: str=\"gpt-3.5-turbo\", system_prompt: Optional[str]=None, min_score: int=6, temperature: float=0.2),\n",
      "name.docstring: __init__(self, model: str=\"gpt-3.5-turbo\", system_prompt: str | None=None, min_score: int=6, temperature: float=0.2)\n",
      "\n",
      "Initialize the GPTReviewAnalyzer\n",
      "\n",
      "Parameters\n",
      "----------\n",
      "model : str, optional\n",
      "    The model to use, by default \"gpt-3.5-turbo\"\n",
      "system_prompt : str, optional\n",
      "    The system prompt to use, by default `2023-12-02_GPTReviewAnalyzer_v4.txt`, created by GPTBuilder\n",
      "min_score : int, optional\n",
      "    The minimum score to pass the review, by default 6\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='__main__.GPTReviewAnalyzer_v1.analyze', description='def analyze'>>,\n",
      "name.signature: analyze(self, input: str, completion: str, context: dict[str, dict[str, bool | str]] | None = None) -> dict,\n",
      "name.docstring: analyze(self, input: str, completion: str, context: dict[str, dict[str, bool | str]] | None=None) -> dict\n",
      "\n",
      "Analyze the input and completion\n",
      "\n",
      "Parameters\n",
      "----------\n",
      "input : str\n",
      "    The input to analyze\n",
      "completion : str\n",
      "    The completion to analyze\n",
      "\n",
      "Returns\n",
      "-------\n",
      "dict\n",
      "    The analysis of the input and completion\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='__main__.GPTReviewAnalyzer_v1._prompt_template', description='def _prompt_template'>>,\n",
      "name.signature: _prompt_template(input: str, completion: str) -> str,\n",
      "name.docstring: _prompt_template(input: str, completion: str) -> str\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='openai.OpenAI', description='class OpenAI'>>,\n",
      "name.signature: Type[OpenAI],\n",
      "name.docstring: OpenAI(*, api_key: str | None=None, organization: str | None=None, base_url: str | httpx.URL | None=None, timeout: Union[float, Timeout, None, NotGiven]=NOT_GIVEN, max_retries: int=DEFAULT_MAX_RETRIES, default_headers: Mapping[str, str] | None=None, default_query: Mapping[str, object] | None=None, http_client: httpx.Client | None=None, _strict_response_validation: bool=False)\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='llmcoder.analyze.Analyzer.Analyzer', description='class Analyzer'>>,\n",
      "name.signature: Type[Analyzer],\n",
      "name.docstring: Analyzer(verbose: bool=False)\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='llmcoder.utils.get_openai_key', description='def get_openai_key'>>,\n",
      "name.signature: get_openai_key(key: str = \"\") -> str,\n",
      "name.docstring: get_openai_key(key: str=\"\") -> str\n",
      "\n",
      "Get OpenAI API key. Try to interpret the key as a key first, then as a path to a file containing the key.\n",
      "Finally, fall back to the default key.txt file or the OPENAI_KEY environment variable.\n",
      "\n",
      "Parameters\n",
      "----------\n",
      "key : str\n",
      "    The key or path to the key file.\n",
      "\n",
      "Returns\n",
      "-------\n",
      "str\n",
      "    The key.\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='llmcoder.utils.get_system_prompt', description='def get_system_prompt'>>,\n",
      "name.signature: get_system_prompt(name: str = \"2023-11-15_GPT-Builder.txt\") -> str,\n",
      "name.docstring: get_system_prompt(name: str=\"2023-11-15_GPT-Builder.txt\") -> str\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='llmcoder.utils.get_system_prompt_dir', description='def get_system_prompt_dir'>>,\n",
      "name.signature: get_system_prompt_dir(*args: str, create: bool = False) -> str,\n",
      "name.docstring: get_system_prompt_dir(*, create: bool=False) -> str\n",
      "\n",
      "Get the path to the system prompts directory.\n",
      "\n",
      "Parameters\n",
      "----------\n",
      "args : str\n",
      "    The path to the system prompts directory.\n",
      "create : bool\n",
      "    Whether to create the directory if it does not exist.\n",
      "\n",
      "Returns\n",
      "-------\n",
      "str\n",
      "    The path to the system prompts directory.\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='__main__.GPTReviewAnalyzer_v1', description='class GPTReviewAnalyzer_v1'>>,\n",
      "name.signature: Type[GPTReviewAnalyzer_v1],\n",
      "name.docstring: GPTReviewAnalyzer_v1(model: str=\"gpt-3.5-turbo\", system_prompt: str | None=None, min_score: int=6, temperature: float=0.2)\n",
      "\n",
      "Concise, professional Python code advisor for targeted feedback.\n",
      "\n",
      "Parameters\n",
      "----------\n",
      "model : str, optional\n",
      "    The model to use, by default \"gpt-3.5-turbo\"\n",
      "system_prompt : str, optional\n",
      "    The system prompt to use, by default `2023-12-02_GPTReviewAnalyzer_v4.txt`, created by GPTBuilder\n",
      "min_score : int, optional\n",
      "    The minimum score to pass the review, by default 6\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='__main__.GPTReviewAnalyzer_v1.__init__', description='def __init__'>>,\n",
      "name.signature: __init__(self, model: str=\"gpt-3.5-turbo\", system_prompt: Optional[str]=None, min_score: int=6, temperature: float=0.2),\n",
      "name.docstring: __init__(self, model: str=\"gpt-3.5-turbo\", system_prompt: str | None=None, min_score: int=6, temperature: float=0.2)\n",
      "\n",
      "Initialize the GPTReviewAnalyzer\n",
      "\n",
      "Parameters\n",
      "----------\n",
      "model : str, optional\n",
      "    The model to use, by default \"gpt-3.5-turbo\"\n",
      "system_prompt : str, optional\n",
      "    The system prompt to use, by default `2023-12-02_GPTReviewAnalyzer_v4.txt`, created by GPTBuilder\n",
      "min_score : int, optional\n",
      "    The minimum score to pass the review, by default 6\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='__main__.GPTReviewAnalyzer_v1.analyze', description='def analyze'>>,\n",
      "name.signature: analyze(self, input: str, completion: str, context: dict[str, dict[str, bool | str]] | None = None) -> dict,\n",
      "name.docstring: analyze(self, input: str, completion: str, context: dict[str, dict[str, bool | str]] | None=None) -> dict\n",
      "\n",
      "Analyze the input and completion\n",
      "\n",
      "Parameters\n",
      "----------\n",
      "input : str\n",
      "    The input to analyze\n",
      "completion : str\n",
      "    The completion to analyze\n",
      "\n",
      "Returns\n",
      "-------\n",
      "dict\n",
      "    The analysis of the input and completion\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='__main__.GPTReviewAnalyzer_v1._prompt_template', description='def _prompt_template'>>,\n",
      "name.signature: _prompt_template(input: str, completion: str) -> str,\n",
      "name.docstring: _prompt_template(input: str, completion: str) -> str\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='openai.OpenAI', description='class OpenAI'>>,\n",
      "name.signature: Type[OpenAI],\n",
      "name.docstring: OpenAI(*, api_key: str | None=None, organization: str | None=None, base_url: str | httpx.URL | None=None, timeout: Union[float, Timeout, None, NotGiven]=NOT_GIVEN, max_retries: int=DEFAULT_MAX_RETRIES, default_headers: Mapping[str, str] | None=None, default_query: Mapping[str, object] | None=None, http_client: httpx.Client | None=None, _strict_response_validation: bool=False)\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='llmcoder.analyze.Analyzer.Analyzer', description='class Analyzer'>>,\n",
      "name.signature: Type[Analyzer],\n",
      "name.docstring: Analyzer(verbose: bool=False)\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='llmcoder.utils.get_openai_key', description='def get_openai_key'>>,\n",
      "name.signature: get_openai_key(key: str = \"\") -> str,\n",
      "name.docstring: get_openai_key(key: str=\"\") -> str\n",
      "\n",
      "Get OpenAI API key. Try to interpret the key as a key first, then as a path to a file containing the key.\n",
      "Finally, fall back to the default key.txt file or the OPENAI_KEY environment variable.\n",
      "\n",
      "Parameters\n",
      "----------\n",
      "key : str\n",
      "    The key or path to the key file.\n",
      "\n",
      "Returns\n",
      "-------\n",
      "str\n",
      "    The key.\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='llmcoder.utils.get_system_prompt', description='def get_system_prompt'>>,\n",
      "name.signature: get_system_prompt(name: str = \"2023-11-15_GPT-Builder.txt\") -> str,\n",
      "name.docstring: get_system_prompt(name: str=\"2023-11-15_GPT-Builder.txt\") -> str\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='llmcoder.utils.get_system_prompt_dir', description='def get_system_prompt_dir'>>,\n",
      "name.signature: get_system_prompt_dir(*args: str, create: bool = False) -> str,\n",
      "name.docstring: get_system_prompt_dir(*, create: bool=False) -> str\n",
      "\n",
      "Get the path to the system prompts directory.\n",
      "\n",
      "Parameters\n",
      "----------\n",
      "args : str\n",
      "    The path to the system prompts directory.\n",
      "create : bool\n",
      "    Whether to create the directory if it does not exist.\n",
      "\n",
      "Returns\n",
      "-------\n",
      "str\n",
      "    The path to the system prompts directory.\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='__main__.GPTReviewAnalyzer_v1', description='class GPTReviewAnalyzer_v1'>>,\n",
      "name.signature: Type[GPTReviewAnalyzer_v1],\n",
      "name.docstring: GPTReviewAnalyzer_v1(model: str=\"gpt-3.5-turbo\", system_prompt: str | None=None, min_score: int=6, temperature: float=0.2)\n",
      "\n",
      "Concise, professional Python code advisor for targeted feedback.\n",
      "\n",
      "Parameters\n",
      "----------\n",
      "model : str, optional\n",
      "    The model to use, by default \"gpt-3.5-turbo\"\n",
      "system_prompt : str, optional\n",
      "    The system prompt to use, by default `2023-12-02_GPTReviewAnalyzer_v4.txt`, created by GPTBuilder\n",
      "min_score : int, optional\n",
      "    The minimum score to pass the review, by default 6\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='__main__.GPTReviewAnalyzer_v1.__init__', description='def __init__'>>,\n",
      "name.signature: __init__(self, model: str=\"gpt-3.5-turbo\", system_prompt: Optional[str]=None, min_score: int=6, temperature: float=0.2),\n",
      "name.docstring: __init__(self, model: str=\"gpt-3.5-turbo\", system_prompt: str | None=None, min_score: int=6, temperature: float=0.2)\n",
      "\n",
      "Initialize the GPTReviewAnalyzer\n",
      "\n",
      "Parameters\n",
      "----------\n",
      "model : str, optional\n",
      "    The model to use, by default \"gpt-3.5-turbo\"\n",
      "system_prompt : str, optional\n",
      "    The system prompt to use, by default `2023-12-02_GPTReviewAnalyzer_v4.txt`, created by GPTBuilder\n",
      "min_score : int, optional\n",
      "    The minimum score to pass the review, by default 6\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='__main__.GPTReviewAnalyzer_v1.analyze', description='def analyze'>>,\n",
      "name.signature: analyze(self, input: str, completion: str, context: dict[str, dict[str, bool | str]] | None = None) -> dict,\n",
      "name.docstring: analyze(self, input: str, completion: str, context: dict[str, dict[str, bool | str]] | None=None) -> dict\n",
      "\n",
      "Analyze the input and completion\n",
      "\n",
      "Parameters\n",
      "----------\n",
      "input : str\n",
      "    The input to analyze\n",
      "completion : str\n",
      "    The completion to analyze\n",
      "\n",
      "Returns\n",
      "-------\n",
      "dict\n",
      "    The analysis of the input and completion\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='__main__.GPTReviewAnalyzer_v1._prompt_template', description='def _prompt_template'>>,\n",
      "name.signature: _prompt_template(input: str, completion: str) -> str,\n",
      "name.docstring: _prompt_template(input: str, completion: str) -> str\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='openai.OpenAI', description='class OpenAI'>>,\n",
      "name.signature: Type[OpenAI],\n",
      "name.docstring: OpenAI(*, api_key: str | None=None, organization: str | None=None, base_url: str | httpx.URL | None=None, timeout: Union[float, Timeout, None, NotGiven]=NOT_GIVEN, max_retries: int=DEFAULT_MAX_RETRIES, default_headers: Mapping[str, str] | None=None, default_query: Mapping[str, object] | None=None, http_client: httpx.Client | None=None, _strict_response_validation: bool=False)\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='llmcoder.analyze.Analyzer.Analyzer', description='class Analyzer'>>,\n",
      "name.signature: Type[Analyzer],\n",
      "name.docstring: Analyzer(verbose: bool=False)\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='llmcoder.utils.get_openai_key', description='def get_openai_key'>>,\n",
      "name.signature: get_openai_key(key: str = \"\") -> str,\n",
      "name.docstring: get_openai_key(key: str=\"\") -> str\n",
      "\n",
      "Get OpenAI API key. Try to interpret the key as a key first, then as a path to a file containing the key.\n",
      "Finally, fall back to the default key.txt file or the OPENAI_KEY environment variable.\n",
      "\n",
      "Parameters\n",
      "----------\n",
      "key : str\n",
      "    The key or path to the key file.\n",
      "\n",
      "Returns\n",
      "-------\n",
      "str\n",
      "    The key.\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='llmcoder.utils.get_system_prompt', description='def get_system_prompt'>>,\n",
      "name.signature: get_system_prompt(name: str = \"2023-11-15_GPT-Builder.txt\") -> str,\n",
      "name.docstring: get_system_prompt(name: str=\"2023-11-15_GPT-Builder.txt\") -> str\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='llmcoder.utils.get_system_prompt_dir', description='def get_system_prompt_dir'>>,\n",
      "name.signature: get_system_prompt_dir(*args: str, create: bool = False) -> str,\n",
      "name.docstring: get_system_prompt_dir(*, create: bool=False) -> str\n",
      "\n",
      "Get the path to the system prompts directory.\n",
      "\n",
      "Parameters\n",
      "----------\n",
      "args : str\n",
      "    The path to the system prompts directory.\n",
      "create : bool\n",
      "    Whether to create the directory if it does not exist.\n",
      "\n",
      "Returns\n",
      "-------\n",
      "str\n",
      "    The path to the system prompts directory.\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='__main__.GPTReviewAnalyzer_v1', description='class GPTReviewAnalyzer_v1'>>,\n",
      "name.signature: Type[GPTReviewAnalyzer_v1],\n",
      "name.docstring: GPTReviewAnalyzer_v1(model: str=\"gpt-3.5-turbo\", system_prompt: str | None=None, min_score: int=6, temperature: float=0.2)\n",
      "\n",
      "Concise, professional Python code advisor for targeted feedback.\n",
      "\n",
      "Parameters\n",
      "----------\n",
      "model : str, optional\n",
      "    The model to use, by default \"gpt-3.5-turbo\"\n",
      "system_prompt : str, optional\n",
      "    The system prompt to use, by default `2023-12-02_GPTReviewAnalyzer_v4.txt`, created by GPTBuilder\n",
      "min_score : int, optional\n",
      "    The minimum score to pass the review, by default 6\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='__main__.GPTReviewAnalyzer_v1.__init__', description='def __init__'>>,\n",
      "name.signature: __init__(self, model: str=\"gpt-3.5-turbo\", system_prompt: Optional[str]=None, min_score: int=6, temperature: float=0.2),\n",
      "name.docstring: __init__(self, model: str=\"gpt-3.5-turbo\", system_prompt: str | None=None, min_score: int=6, temperature: float=0.2)\n",
      "\n",
      "Initialize the GPTReviewAnalyzer\n",
      "\n",
      "Parameters\n",
      "----------\n",
      "model : str, optional\n",
      "    The model to use, by default \"gpt-3.5-turbo\"\n",
      "system_prompt : str, optional\n",
      "    The system prompt to use, by default `2023-12-02_GPTReviewAnalyzer_v4.txt`, created by GPTBuilder\n",
      "min_score : int, optional\n",
      "    The minimum score to pass the review, by default 6\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='__main__.GPTReviewAnalyzer_v1.analyze', description='def analyze'>>,\n",
      "name.signature: analyze(self, input: str, completion: str, context: dict[str, dict[str, bool | str]] | None = None) -> dict,\n",
      "name.docstring: analyze(self, input: str, completion: str, context: dict[str, dict[str, bool | str]] | None=None) -> dict\n",
      "\n",
      "Analyze the input and completion\n",
      "\n",
      "Parameters\n",
      "----------\n",
      "input : str\n",
      "    The input to analyze\n",
      "completion : str\n",
      "    The completion to analyze\n",
      "\n",
      "Returns\n",
      "-------\n",
      "dict\n",
      "    The analysis of the input and completion\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='__main__.GPTReviewAnalyzer_v1._prompt_template', description='def _prompt_template'>>,\n",
      "name.signature: _prompt_template(input: str, completion: str) -> str,\n",
      "name.docstring: _prompt_template(input: str, completion: str) -> str\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='openai.OpenAI', description='class OpenAI'>>,\n",
      "name.signature: Type[OpenAI],\n",
      "name.docstring: OpenAI(*, api_key: str | None=None, organization: str | None=None, base_url: str | httpx.URL | None=None, timeout: Union[float, Timeout, None, NotGiven]=NOT_GIVEN, max_retries: int=DEFAULT_MAX_RETRIES, default_headers: Mapping[str, str] | None=None, default_query: Mapping[str, object] | None=None, http_client: httpx.Client | None=None, _strict_response_validation: bool=False)\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='llmcoder.analyze.Analyzer.Analyzer', description='class Analyzer'>>,\n",
      "name.signature: Type[Analyzer],\n",
      "name.docstring: Analyzer(verbose: bool=False)\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='llmcoder.utils.get_openai_key', description='def get_openai_key'>>,\n",
      "name.signature: get_openai_key(key: str = \"\") -> str,\n",
      "name.docstring: get_openai_key(key: str=\"\") -> str\n",
      "\n",
      "Get OpenAI API key. Try to interpret the key as a key first, then as a path to a file containing the key.\n",
      "Finally, fall back to the default key.txt file or the OPENAI_KEY environment variable.\n",
      "\n",
      "Parameters\n",
      "----------\n",
      "key : str\n",
      "    The key or path to the key file.\n",
      "\n",
      "Returns\n",
      "-------\n",
      "str\n",
      "    The key.\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='llmcoder.utils.get_system_prompt', description='def get_system_prompt'>>,\n",
      "name.signature: get_system_prompt(name: str = \"2023-11-15_GPT-Builder.txt\") -> str,\n",
      "name.docstring: get_system_prompt(name: str=\"2023-11-15_GPT-Builder.txt\") -> str\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='llmcoder.utils.get_system_prompt_dir', description='def get_system_prompt_dir'>>,\n",
      "name.signature: get_system_prompt_dir(*args: str, create: bool = False) -> str,\n",
      "name.docstring: get_system_prompt_dir(*, create: bool=False) -> str\n",
      "\n",
      "Get the path to the system prompts directory.\n",
      "\n",
      "Parameters\n",
      "----------\n",
      "args : str\n",
      "    The path to the system prompts directory.\n",
      "create : bool\n",
      "    Whether to create the directory if it does not exist.\n",
      "\n",
      "Returns\n",
      "-------\n",
      "str\n",
      "    The path to the system prompts directory.\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='__main__.GPTReviewAnalyzer_v1', description='class GPTReviewAnalyzer_v1'>>,\n",
      "name.signature: Type[GPTReviewAnalyzer_v1],\n",
      "name.docstring: GPTReviewAnalyzer_v1(model: str=\"gpt-3.5-turbo\", system_prompt: str | None=None, min_score: int=6, temperature: float=0.2)\n",
      "\n",
      "Concise, professional Python code advisor for targeted feedback.\n",
      "\n",
      "Parameters\n",
      "----------\n",
      "model : str, optional\n",
      "    The model to use, by default \"gpt-3.5-turbo\"\n",
      "system_prompt : str, optional\n",
      "    The system prompt to use, by default `2023-12-02_GPTReviewAnalyzer_v4.txt`, created by GPTBuilder\n",
      "min_score : int, optional\n",
      "    The minimum score to pass the review, by default 6\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='__main__.GPTReviewAnalyzer_v1.__init__', description='def __init__'>>,\n",
      "name.signature: __init__(self, model: str=\"gpt-3.5-turbo\", system_prompt: Optional[str]=None, min_score: int=6, temperature: float=0.2),\n",
      "name.docstring: __init__(self, model: str=\"gpt-3.5-turbo\", system_prompt: str | None=None, min_score: int=6, temperature: float=0.2)\n",
      "\n",
      "Initialize the GPTReviewAnalyzer\n",
      "\n",
      "Parameters\n",
      "----------\n",
      "model : str, optional\n",
      "    The model to use, by default \"gpt-3.5-turbo\"\n",
      "system_prompt : str, optional\n",
      "    The system prompt to use, by default `2023-12-02_GPTReviewAnalyzer_v4.txt`, created by GPTBuilder\n",
      "min_score : int, optional\n",
      "    The minimum score to pass the review, by default 6\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='__main__.GPTReviewAnalyzer_v1.analyze', description='def analyze'>>,\n",
      "name.signature: analyze(self, input: str, completion: str, context: dict[str, dict[str, bool | str]] | None = None) -> dict,\n",
      "name.docstring: analyze(self, input: str, completion: str, context: dict[str, dict[str, bool | str]] | None=None) -> dict\n",
      "\n",
      "Analyze the input and completion\n",
      "\n",
      "Parameters\n",
      "----------\n",
      "input : str\n",
      "    The input to analyze\n",
      "completion : str\n",
      "    The completion to analyze\n",
      "\n",
      "Returns\n",
      "-------\n",
      "dict\n",
      "    The analysis of the input and completion\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='__main__.GPTReviewAnalyzer_v1._prompt_template', description='def _prompt_template'>>,\n",
      "name.signature: _prompt_template(input: str, completion: str) -> str,\n",
      "name.docstring: _prompt_template(input: str, completion: str) -> str\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='openai.OpenAI', description='class OpenAI'>>,\n",
      "name.signature: Type[OpenAI],\n",
      "name.docstring: OpenAI(*, api_key: str | None=None, organization: str | None=None, base_url: str | httpx.URL | None=None, timeout: Union[float, Timeout, None, NotGiven]=NOT_GIVEN, max_retries: int=DEFAULT_MAX_RETRIES, default_headers: Mapping[str, str] | None=None, default_query: Mapping[str, object] | None=None, http_client: httpx.Client | None=None, _strict_response_validation: bool=False)\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='llmcoder.analyze.Analyzer.Analyzer', description='class Analyzer'>>,\n",
      "name.signature: Type[Analyzer],\n",
      "name.docstring: Analyzer(verbose: bool=False)\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='llmcoder.utils.get_openai_key', description='def get_openai_key'>>,\n",
      "name.signature: get_openai_key(key: str = \"\") -> str,\n",
      "name.docstring: get_openai_key(key: str=\"\") -> str\n",
      "\n",
      "Get OpenAI API key. Try to interpret the key as a key first, then as a path to a file containing the key.\n",
      "Finally, fall back to the default key.txt file or the OPENAI_KEY environment variable.\n",
      "\n",
      "Parameters\n",
      "----------\n",
      "key : str\n",
      "    The key or path to the key file.\n",
      "\n",
      "Returns\n",
      "-------\n",
      "str\n",
      "    The key.\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='llmcoder.utils.get_system_prompt', description='def get_system_prompt'>>,\n",
      "name.signature: get_system_prompt(name: str = \"2023-11-15_GPT-Builder.txt\") -> str,\n",
      "name.docstring: get_system_prompt(name: str=\"2023-11-15_GPT-Builder.txt\") -> str\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='llmcoder.utils.get_system_prompt_dir', description='def get_system_prompt_dir'>>,\n",
      "name.signature: get_system_prompt_dir(*args: str, create: bool = False) -> str,\n",
      "name.docstring: get_system_prompt_dir(*, create: bool=False) -> str\n",
      "\n",
      "Get the path to the system prompts directory.\n",
      "\n",
      "Parameters\n",
      "----------\n",
      "args : str\n",
      "    The path to the system prompts directory.\n",
      "create : bool\n",
      "    Whether to create the directory if it does not exist.\n",
      "\n",
      "Returns\n",
      "-------\n",
      "str\n",
      "    The path to the system prompts directory.\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='__main__.GPTReviewAnalyzer_v1', description='class GPTReviewAnalyzer_v1'>>,\n",
      "name.signature: Type[GPTReviewAnalyzer_v1],\n",
      "name.docstring: GPTReviewAnalyzer_v1(model: str=\"gpt-3.5-turbo\", system_prompt: str | None=None, min_score: int=6, temperature: float=0.2)\n",
      "\n",
      "Concise, professional Python code advisor for targeted feedback.\n",
      "\n",
      "Parameters\n",
      "----------\n",
      "model : str, optional\n",
      "    The model to use, by default \"gpt-3.5-turbo\"\n",
      "system_prompt : str, optional\n",
      "    The system prompt to use, by default `2023-12-02_GPTReviewAnalyzer_v4.txt`, created by GPTBuilder\n",
      "min_score : int, optional\n",
      "    The minimum score to pass the review, by default 6\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='__main__.GPTReviewAnalyzer_v1.__init__', description='def __init__'>>,\n",
      "name.signature: __init__(self, model: str=\"gpt-3.5-turbo\", system_prompt: Optional[str]=None, min_score: int=6, temperature: float=0.2),\n",
      "name.docstring: __init__(self, model: str=\"gpt-3.5-turbo\", system_prompt: str | None=None, min_score: int=6, temperature: float=0.2)\n",
      "\n",
      "Initialize the GPTReviewAnalyzer\n",
      "\n",
      "Parameters\n",
      "----------\n",
      "model : str, optional\n",
      "    The model to use, by default \"gpt-3.5-turbo\"\n",
      "system_prompt : str, optional\n",
      "    The system prompt to use, by default `2023-12-02_GPTReviewAnalyzer_v4.txt`, created by GPTBuilder\n",
      "min_score : int, optional\n",
      "    The minimum score to pass the review, by default 6\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='__main__.GPTReviewAnalyzer_v1.analyze', description='def analyze'>>,\n",
      "name.signature: analyze(self, input: str, completion: str, context: dict[str, dict[str, bool | str]] | None = None) -> dict,\n",
      "name.docstring: analyze(self, input: str, completion: str, context: dict[str, dict[str, bool | str]] | None=None) -> dict\n",
      "\n",
      "Analyze the input and completion\n",
      "\n",
      "Parameters\n",
      "----------\n",
      "input : str\n",
      "    The input to analyze\n",
      "completion : str\n",
      "    The completion to analyze\n",
      "\n",
      "Returns\n",
      "-------\n",
      "dict\n",
      "    The analysis of the input and completion\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='__main__.GPTReviewAnalyzer_v1._prompt_template', description='def _prompt_template'>>,\n",
      "name.signature: _prompt_template(input: str, completion: str) -> str,\n",
      "name.docstring: _prompt_template(input: str, completion: str) -> str\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='openai.OpenAI', description='class OpenAI'>>,\n",
      "name.signature: Type[OpenAI],\n",
      "name.docstring: OpenAI(*, api_key: str | None=None, organization: str | None=None, base_url: str | httpx.URL | None=None, timeout: Union[float, Timeout, None, NotGiven]=NOT_GIVEN, max_retries: int=DEFAULT_MAX_RETRIES, default_headers: Mapping[str, str] | None=None, default_query: Mapping[str, object] | None=None, http_client: httpx.Client | None=None, _strict_response_validation: bool=False)\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='llmcoder.analyze.Analyzer.Analyzer', description='class Analyzer'>>,\n",
      "name.signature: Type[Analyzer],\n",
      "name.docstring: Analyzer(verbose: bool=False)\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='llmcoder.utils.get_openai_key', description='def get_openai_key'>>,\n",
      "name.signature: get_openai_key(key: str = \"\") -> str,\n",
      "name.docstring: get_openai_key(key: str=\"\") -> str\n",
      "\n",
      "Get OpenAI API key. Try to interpret the key as a key first, then as a path to a file containing the key.\n",
      "Finally, fall back to the default key.txt file or the OPENAI_KEY environment variable.\n",
      "\n",
      "Parameters\n",
      "----------\n",
      "key : str\n",
      "    The key or path to the key file.\n",
      "\n",
      "Returns\n",
      "-------\n",
      "str\n",
      "    The key.\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='llmcoder.utils.get_system_prompt', description='def get_system_prompt'>>,\n",
      "name.signature: get_system_prompt(name: str = \"2023-11-15_GPT-Builder.txt\") -> str,\n",
      "name.docstring: get_system_prompt(name: str=\"2023-11-15_GPT-Builder.txt\") -> str\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='llmcoder.utils.get_system_prompt_dir', description='def get_system_prompt_dir'>>,\n",
      "name.signature: get_system_prompt_dir(*args: str, create: bool = False) -> str,\n",
      "name.docstring: get_system_prompt_dir(*, create: bool=False) -> str\n",
      "\n",
      "Get the path to the system prompts directory.\n",
      "\n",
      "Parameters\n",
      "----------\n",
      "args : str\n",
      "    The path to the system prompts directory.\n",
      "create : bool\n",
      "    Whether to create the directory if it does not exist.\n",
      "\n",
      "Returns\n",
      "-------\n",
      "str\n",
      "    The path to the system prompts directory.\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='__main__.GPTReviewAnalyzer_v1', description='class GPTReviewAnalyzer_v1'>>,\n",
      "name.signature: Type[GPTReviewAnalyzer_v1],\n",
      "name.docstring: GPTReviewAnalyzer_v1(model: str=\"gpt-3.5-turbo\", system_prompt: str | None=None, min_score: int=6, temperature: float=0.2)\n",
      "\n",
      "Concise, professional Python code advisor for targeted feedback.\n",
      "\n",
      "Parameters\n",
      "----------\n",
      "model : str, optional\n",
      "    The model to use, by default \"gpt-3.5-turbo\"\n",
      "system_prompt : str, optional\n",
      "    The system prompt to use, by default `2023-12-02_GPTReviewAnalyzer_v4.txt`, created by GPTBuilder\n",
      "min_score : int, optional\n",
      "    The minimum score to pass the review, by default 6\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='__main__.GPTReviewAnalyzer_v1.__init__', description='def __init__'>>,\n",
      "name.signature: __init__(self, model: str=\"gpt-3.5-turbo\", system_prompt: Optional[str]=None, min_score: int=6, temperature: float=0.2),\n",
      "name.docstring: __init__(self, model: str=\"gpt-3.5-turbo\", system_prompt: str | None=None, min_score: int=6, temperature: float=0.2)\n",
      "\n",
      "Initialize the GPTReviewAnalyzer\n",
      "\n",
      "Parameters\n",
      "----------\n",
      "model : str, optional\n",
      "    The model to use, by default \"gpt-3.5-turbo\"\n",
      "system_prompt : str, optional\n",
      "    The system prompt to use, by default `2023-12-02_GPTReviewAnalyzer_v4.txt`, created by GPTBuilder\n",
      "min_score : int, optional\n",
      "    The minimum score to pass the review, by default 6\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='__main__.GPTReviewAnalyzer_v1.analyze', description='def analyze'>>,\n",
      "name.signature: analyze(self, input: str, completion: str, context: dict[str, dict[str, bool | str]] | None = None) -> dict,\n",
      "name.docstring: analyze(self, input: str, completion: str, context: dict[str, dict[str, bool | str]] | None=None) -> dict\n",
      "\n",
      "Analyze the input and completion\n",
      "\n",
      "Parameters\n",
      "----------\n",
      "input : str\n",
      "    The input to analyze\n",
      "completion : str\n",
      "    The completion to analyze\n",
      "\n",
      "Returns\n",
      "-------\n",
      "dict\n",
      "    The analysis of the input and completion\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='__main__.GPTReviewAnalyzer_v1._prompt_template', description='def _prompt_template'>>,\n",
      "name.signature: _prompt_template(input: str, completion: str) -> str,\n",
      "name.docstring: _prompt_template(input: str, completion: str) -> str\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='openai.OpenAI', description='class OpenAI'>>,\n",
      "name.signature: Type[OpenAI],\n",
      "name.docstring: OpenAI(*, api_key: str | None=None, organization: str | None=None, base_url: str | httpx.URL | None=None, timeout: Union[float, Timeout, None, NotGiven]=NOT_GIVEN, max_retries: int=DEFAULT_MAX_RETRIES, default_headers: Mapping[str, str] | None=None, default_query: Mapping[str, object] | None=None, http_client: httpx.Client | None=None, _strict_response_validation: bool=False)\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='llmcoder.analyze.Analyzer.Analyzer', description='class Analyzer'>>,\n",
      "name.signature: Type[Analyzer],\n",
      "name.docstring: Analyzer(verbose: bool=False)\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='llmcoder.utils.get_openai_key', description='def get_openai_key'>>,\n",
      "name.signature: get_openai_key(key: str = \"\") -> str,\n",
      "name.docstring: get_openai_key(key: str=\"\") -> str\n",
      "\n",
      "Get OpenAI API key. Try to interpret the key as a key first, then as a path to a file containing the key.\n",
      "Finally, fall back to the default key.txt file or the OPENAI_KEY environment variable.\n",
      "\n",
      "Parameters\n",
      "----------\n",
      "key : str\n",
      "    The key or path to the key file.\n",
      "\n",
      "Returns\n",
      "-------\n",
      "str\n",
      "    The key.\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='llmcoder.utils.get_system_prompt', description='def get_system_prompt'>>,\n",
      "name.signature: get_system_prompt(name: str = \"2023-11-15_GPT-Builder.txt\") -> str,\n",
      "name.docstring: get_system_prompt(name: str=\"2023-11-15_GPT-Builder.txt\") -> str\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='llmcoder.utils.get_system_prompt_dir', description='def get_system_prompt_dir'>>,\n",
      "name.signature: get_system_prompt_dir(*args: str, create: bool = False) -> str,\n",
      "name.docstring: get_system_prompt_dir(*, create: bool=False) -> str\n",
      "\n",
      "Get the path to the system prompts directory.\n",
      "\n",
      "Parameters\n",
      "----------\n",
      "args : str\n",
      "    The path to the system prompts directory.\n",
      "create : bool\n",
      "    Whether to create the directory if it does not exist.\n",
      "\n",
      "Returns\n",
      "-------\n",
      "str\n",
      "    The path to the system prompts directory.\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='__main__.GPTReviewAnalyzer_v1', description='class GPTReviewAnalyzer_v1'>>,\n",
      "name.signature: Type[GPTReviewAnalyzer_v1],\n",
      "name.docstring: GPTReviewAnalyzer_v1(model: str=\"gpt-3.5-turbo\", system_prompt: str | None=None, min_score: int=6, temperature: float=0.2)\n",
      "\n",
      "Concise, professional Python code advisor for targeted feedback.\n",
      "\n",
      "Parameters\n",
      "----------\n",
      "model : str, optional\n",
      "    The model to use, by default \"gpt-3.5-turbo\"\n",
      "system_prompt : str, optional\n",
      "    The system prompt to use, by default `2023-12-02_GPTReviewAnalyzer_v4.txt`, created by GPTBuilder\n",
      "min_score : int, optional\n",
      "    The minimum score to pass the review, by default 6\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='__main__.GPTReviewAnalyzer_v1.__init__', description='def __init__'>>,\n",
      "name.signature: __init__(self, model: str=\"gpt-3.5-turbo\", system_prompt: Optional[str]=None, min_score: int=6, temperature: float=0.2),\n",
      "name.docstring: __init__(self, model: str=\"gpt-3.5-turbo\", system_prompt: str | None=None, min_score: int=6, temperature: float=0.2)\n",
      "\n",
      "Initialize the GPTReviewAnalyzer\n",
      "\n",
      "Parameters\n",
      "----------\n",
      "model : str, optional\n",
      "    The model to use, by default \"gpt-3.5-turbo\"\n",
      "system_prompt : str, optional\n",
      "    The system prompt to use, by default `2023-12-02_GPTReviewAnalyzer_v4.txt`, created by GPTBuilder\n",
      "min_score : int, optional\n",
      "    The minimum score to pass the review, by default 6\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='__main__.GPTReviewAnalyzer_v1.analyze', description='def analyze'>>,\n",
      "name.signature: analyze(self, input: str, completion: str, context: dict[str, dict[str, bool | str]] | None = None) -> dict,\n",
      "name.docstring: analyze(self, input: str, completion: str, context: dict[str, dict[str, bool | str]] | None=None) -> dict\n",
      "\n",
      "Analyze the input and completion\n",
      "\n",
      "Parameters\n",
      "----------\n",
      "input : str\n",
      "    The input to analyze\n",
      "completion : str\n",
      "    The completion to analyze\n",
      "\n",
      "Returns\n",
      "-------\n",
      "dict\n",
      "    The analysis of the input and completion\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='__main__.GPTReviewAnalyzer_v1._prompt_template', description='def _prompt_template'>>,\n",
      "name.signature: _prompt_template(input: str, completion: str) -> str,\n",
      "name.docstring: _prompt_template(input: str, completion: str) -> str\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='openai.OpenAI', description='class OpenAI'>>,\n",
      "name.signature: Type[OpenAI],\n",
      "name.docstring: OpenAI(*, api_key: str | None=None, organization: str | None=None, base_url: str | httpx.URL | None=None, timeout: Union[float, Timeout, None, NotGiven]=NOT_GIVEN, max_retries: int=DEFAULT_MAX_RETRIES, default_headers: Mapping[str, str] | None=None, default_query: Mapping[str, object] | None=None, http_client: httpx.Client | None=None, _strict_response_validation: bool=False)\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='llmcoder.analyze.Analyzer.Analyzer', description='class Analyzer'>>,\n",
      "name.signature: Type[Analyzer],\n",
      "name.docstring: Analyzer(verbose: bool=False)\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='llmcoder.utils.get_openai_key', description='def get_openai_key'>>,\n",
      "name.signature: get_openai_key(key: str = \"\") -> str,\n",
      "name.docstring: get_openai_key(key: str=\"\") -> str\n",
      "\n",
      "Get OpenAI API key. Try to interpret the key as a key first, then as a path to a file containing the key.\n",
      "Finally, fall back to the default key.txt file or the OPENAI_KEY environment variable.\n",
      "\n",
      "Parameters\n",
      "----------\n",
      "key : str\n",
      "    The key or path to the key file.\n",
      "\n",
      "Returns\n",
      "-------\n",
      "str\n",
      "    The key.\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='llmcoder.utils.get_system_prompt', description='def get_system_prompt'>>,\n",
      "name.signature: get_system_prompt(name: str = \"2023-11-15_GPT-Builder.txt\") -> str,\n",
      "name.docstring: get_system_prompt(name: str=\"2023-11-15_GPT-Builder.txt\") -> str\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='llmcoder.utils.get_system_prompt_dir', description='def get_system_prompt_dir'>>,\n",
      "name.signature: get_system_prompt_dir(*args: str, create: bool = False) -> str,\n",
      "name.docstring: get_system_prompt_dir(*, create: bool=False) -> str\n",
      "\n",
      "Get the path to the system prompts directory.\n",
      "\n",
      "Parameters\n",
      "----------\n",
      "args : str\n",
      "    The path to the system prompts directory.\n",
      "create : bool\n",
      "    Whether to create the directory if it does not exist.\n",
      "\n",
      "Returns\n",
      "-------\n",
      "str\n",
      "    The path to the system prompts directory.\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='__main__.GPTReviewAnalyzer_v1', description='class GPTReviewAnalyzer_v1'>>,\n",
      "name.signature: Type[GPTReviewAnalyzer_v1],\n",
      "name.docstring: GPTReviewAnalyzer_v1(model: str=\"gpt-3.5-turbo\", system_prompt: str | None=None, min_score: int=6, temperature: float=0.2)\n",
      "\n",
      "Concise, professional Python code advisor for targeted feedback.\n",
      "\n",
      "Parameters\n",
      "----------\n",
      "model : str, optional\n",
      "    The model to use, by default \"gpt-3.5-turbo\"\n",
      "system_prompt : str, optional\n",
      "    The system prompt to use, by default `2023-12-02_GPTReviewAnalyzer_v4.txt`, created by GPTBuilder\n",
      "min_score : int, optional\n",
      "    The minimum score to pass the review, by default 6\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='__main__.GPTReviewAnalyzer_v1.__init__', description='def __init__'>>,\n",
      "name.signature: __init__(self, model: str=\"gpt-3.5-turbo\", system_prompt: Optional[str]=None, min_score: int=6, temperature: float=0.2),\n",
      "name.docstring: __init__(self, model: str=\"gpt-3.5-turbo\", system_prompt: str | None=None, min_score: int=6, temperature: float=0.2)\n",
      "\n",
      "Initialize the GPTReviewAnalyzer\n",
      "\n",
      "Parameters\n",
      "----------\n",
      "model : str, optional\n",
      "    The model to use, by default \"gpt-3.5-turbo\"\n",
      "system_prompt : str, optional\n",
      "    The system prompt to use, by default `2023-12-02_GPTReviewAnalyzer_v4.txt`, created by GPTBuilder\n",
      "min_score : int, optional\n",
      "    The minimum score to pass the review, by default 6\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='__main__.GPTReviewAnalyzer_v1.analyze', description='def analyze'>>,\n",
      "name.signature: analyze(self, input: str, completion: str, context: dict[str, dict[str, bool | str]] | None = None) -> dict,\n",
      "name.docstring: analyze(self, input: str, completion: str, context: dict[str, dict[str, bool | str]] | None=None) -> dict\n",
      "\n",
      "Analyze the input and completion\n",
      "\n",
      "Parameters\n",
      "----------\n",
      "input : str\n",
      "    The input to analyze\n",
      "completion : str\n",
      "    The completion to analyze\n",
      "\n",
      "Returns\n",
      "-------\n",
      "dict\n",
      "    The analysis of the input and completion\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='__main__.GPTReviewAnalyzer_v1._prompt_template', description='def _prompt_template'>>,\n",
      "name.signature: _prompt_template(input: str, completion: str) -> str,\n",
      "name.docstring: _prompt_template(input: str, completion: str) -> str\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='openai.OpenAI', description='class OpenAI'>>,\n",
      "name.signature: Type[OpenAI],\n",
      "name.docstring: OpenAI(*, api_key: str | None=None, organization: str | None=None, base_url: str | httpx.URL | None=None, timeout: Union[float, Timeout, None, NotGiven]=NOT_GIVEN, max_retries: int=DEFAULT_MAX_RETRIES, default_headers: Mapping[str, str] | None=None, default_query: Mapping[str, object] | None=None, http_client: httpx.Client | None=None, _strict_response_validation: bool=False)\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='llmcoder.analyze.Analyzer.Analyzer', description='class Analyzer'>>,\n",
      "name.signature: Type[Analyzer],\n",
      "name.docstring: Analyzer(verbose: bool=False)\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='llmcoder.utils.get_openai_key', description='def get_openai_key'>>,\n",
      "name.signature: get_openai_key(key: str = \"\") -> str,\n",
      "name.docstring: get_openai_key(key: str=\"\") -> str\n",
      "\n",
      "Get OpenAI API key. Try to interpret the key as a key first, then as a path to a file containing the key.\n",
      "Finally, fall back to the default key.txt file or the OPENAI_KEY environment variable.\n",
      "\n",
      "Parameters\n",
      "----------\n",
      "key : str\n",
      "    The key or path to the key file.\n",
      "\n",
      "Returns\n",
      "-------\n",
      "str\n",
      "    The key.\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='llmcoder.utils.get_system_prompt', description='def get_system_prompt'>>,\n",
      "name.signature: get_system_prompt(name: str = \"2023-11-15_GPT-Builder.txt\") -> str,\n",
      "name.docstring: get_system_prompt(name: str=\"2023-11-15_GPT-Builder.txt\") -> str\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='llmcoder.utils.get_system_prompt_dir', description='def get_system_prompt_dir'>>,\n",
      "name.signature: get_system_prompt_dir(*args: str, create: bool = False) -> str,\n",
      "name.docstring: get_system_prompt_dir(*, create: bool=False) -> str\n",
      "\n",
      "Get the path to the system prompts directory.\n",
      "\n",
      "Parameters\n",
      "----------\n",
      "args : str\n",
      "    The path to the system prompts directory.\n",
      "create : bool\n",
      "    Whether to create the directory if it does not exist.\n",
      "\n",
      "Returns\n",
      "-------\n",
      "str\n",
      "    The path to the system prompts directory.\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='__main__.GPTReviewAnalyzer_v1', description='class GPTReviewAnalyzer_v1'>>,\n",
      "name.signature: Type[GPTReviewAnalyzer_v1],\n",
      "name.docstring: GPTReviewAnalyzer_v1(model: str=\"gpt-3.5-turbo\", system_prompt: str | None=None, min_score: int=6, temperature: float=0.2)\n",
      "\n",
      "Concise, professional Python code advisor for targeted feedback.\n",
      "\n",
      "Parameters\n",
      "----------\n",
      "model : str, optional\n",
      "    The model to use, by default \"gpt-3.5-turbo\"\n",
      "system_prompt : str, optional\n",
      "    The system prompt to use, by default `2023-12-02_GPTReviewAnalyzer_v4.txt`, created by GPTBuilder\n",
      "min_score : int, optional\n",
      "    The minimum score to pass the review, by default 6\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='__main__.GPTReviewAnalyzer_v1.__init__', description='def __init__'>>,\n",
      "name.signature: __init__(self, model: str=\"gpt-3.5-turbo\", system_prompt: Optional[str]=None, min_score: int=6, temperature: float=0.2),\n",
      "name.docstring: __init__(self, model: str=\"gpt-3.5-turbo\", system_prompt: str | None=None, min_score: int=6, temperature: float=0.2)\n",
      "\n",
      "Initialize the GPTReviewAnalyzer\n",
      "\n",
      "Parameters\n",
      "----------\n",
      "model : str, optional\n",
      "    The model to use, by default \"gpt-3.5-turbo\"\n",
      "system_prompt : str, optional\n",
      "    The system prompt to use, by default `2023-12-02_GPTReviewAnalyzer_v4.txt`, created by GPTBuilder\n",
      "min_score : int, optional\n",
      "    The minimum score to pass the review, by default 6\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='__main__.GPTReviewAnalyzer_v1.analyze', description='def analyze'>>,\n",
      "name.signature: analyze(self, input: str, completion: str, context: dict[str, dict[str, bool | str]] | None = None) -> dict,\n",
      "name.docstring: analyze(self, input: str, completion: str, context: dict[str, dict[str, bool | str]] | None=None) -> dict\n",
      "\n",
      "Analyze the input and completion\n",
      "\n",
      "Parameters\n",
      "----------\n",
      "input : str\n",
      "    The input to analyze\n",
      "completion : str\n",
      "    The completion to analyze\n",
      "\n",
      "Returns\n",
      "-------\n",
      "dict\n",
      "    The analysis of the input and completion\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='__main__.GPTReviewAnalyzer_v1._prompt_template', description='def _prompt_template'>>,\n",
      "name.signature: _prompt_template(input: str, completion: str) -> str,\n",
      "name.docstring: _prompt_template(input: str, completion: str) -> str\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='openai.OpenAI', description='class OpenAI'>>,\n",
      "name.signature: Type[OpenAI],\n",
      "name.docstring: OpenAI(*, api_key: str | None=None, organization: str | None=None, base_url: str | httpx.URL | None=None, timeout: Union[float, Timeout, None, NotGiven]=NOT_GIVEN, max_retries: int=DEFAULT_MAX_RETRIES, default_headers: Mapping[str, str] | None=None, default_query: Mapping[str, object] | None=None, http_client: httpx.Client | None=None, _strict_response_validation: bool=False)\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='llmcoder.analyze.Analyzer.Analyzer', description='class Analyzer'>>,\n",
      "name.signature: Type[Analyzer],\n",
      "name.docstring: Analyzer(verbose: bool=False)\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='llmcoder.utils.get_openai_key', description='def get_openai_key'>>,\n",
      "name.signature: get_openai_key(key: str = \"\") -> str,\n",
      "name.docstring: get_openai_key(key: str=\"\") -> str\n",
      "\n",
      "Get OpenAI API key. Try to interpret the key as a key first, then as a path to a file containing the key.\n",
      "Finally, fall back to the default key.txt file or the OPENAI_KEY environment variable.\n",
      "\n",
      "Parameters\n",
      "----------\n",
      "key : str\n",
      "    The key or path to the key file.\n",
      "\n",
      "Returns\n",
      "-------\n",
      "str\n",
      "    The key.\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='llmcoder.utils.get_system_prompt', description='def get_system_prompt'>>,\n",
      "name.signature: get_system_prompt(name: str = \"2023-11-15_GPT-Builder.txt\") -> str,\n",
      "name.docstring: get_system_prompt(name: str=\"2023-11-15_GPT-Builder.txt\") -> str\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='llmcoder.utils.get_system_prompt_dir', description='def get_system_prompt_dir'>>,\n",
      "name.signature: get_system_prompt_dir(*args: str, create: bool = False) -> str,\n",
      "name.docstring: get_system_prompt_dir(*, create: bool=False) -> str\n",
      "\n",
      "Get the path to the system prompts directory.\n",
      "\n",
      "Parameters\n",
      "----------\n",
      "args : str\n",
      "    The path to the system prompts directory.\n",
      "create : bool\n",
      "    Whether to create the directory if it does not exist.\n",
      "\n",
      "Returns\n",
      "-------\n",
      "str\n",
      "    The path to the system prompts directory.\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='__main__.GPTReviewAnalyzer_v1', description='class GPTReviewAnalyzer_v1'>>,\n",
      "name.signature: Type[GPTReviewAnalyzer_v1],\n",
      "name.docstring: GPTReviewAnalyzer_v1(model: str=\"gpt-3.5-turbo\", system_prompt: str | None=None, min_score: int=6, temperature: float=0.2)\n",
      "\n",
      "Concise, professional Python code advisor for targeted feedback.\n",
      "\n",
      "Parameters\n",
      "----------\n",
      "model : str, optional\n",
      "    The model to use, by default \"gpt-3.5-turbo\"\n",
      "system_prompt : str, optional\n",
      "    The system prompt to use, by default `2023-12-02_GPTReviewAnalyzer_v4.txt`, created by GPTBuilder\n",
      "min_score : int, optional\n",
      "    The minimum score to pass the review, by default 6\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='__main__.GPTReviewAnalyzer_v1.__init__', description='def __init__'>>,\n",
      "name.signature: __init__(self, model: str=\"gpt-3.5-turbo\", system_prompt: Optional[str]=None, min_score: int=6, temperature: float=0.2),\n",
      "name.docstring: __init__(self, model: str=\"gpt-3.5-turbo\", system_prompt: str | None=None, min_score: int=6, temperature: float=0.2)\n",
      "\n",
      "Initialize the GPTReviewAnalyzer\n",
      "\n",
      "Parameters\n",
      "----------\n",
      "model : str, optional\n",
      "    The model to use, by default \"gpt-3.5-turbo\"\n",
      "system_prompt : str, optional\n",
      "    The system prompt to use, by default `2023-12-02_GPTReviewAnalyzer_v4.txt`, created by GPTBuilder\n",
      "min_score : int, optional\n",
      "    The minimum score to pass the review, by default 6\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='__main__.GPTReviewAnalyzer_v1.analyze', description='def analyze'>>,\n",
      "name.signature: analyze(self, input: str, completion: str, context: dict[str, dict[str, bool | str]] | None = None) -> dict,\n",
      "name.docstring: analyze(self, input: str, completion: str, context: dict[str, dict[str, bool | str]] | None=None) -> dict\n",
      "\n",
      "Analyze the input and completion\n",
      "\n",
      "Parameters\n",
      "----------\n",
      "input : str\n",
      "    The input to analyze\n",
      "completion : str\n",
      "    The completion to analyze\n",
      "\n",
      "Returns\n",
      "-------\n",
      "dict\n",
      "    The analysis of the input and completion\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='__main__.GPTReviewAnalyzer_v1._prompt_template', description='def _prompt_template'>>,\n",
      "name.signature: _prompt_template(input: str, completion: str) -> str,\n",
      "name.docstring: _prompt_template(input: str, completion: str) -> str\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='openai.OpenAI', description='class OpenAI'>>,\n",
      "name.signature: Type[OpenAI],\n",
      "name.docstring: OpenAI(*, api_key: str | None=None, organization: str | None=None, base_url: str | httpx.URL | None=None, timeout: Union[float, Timeout, None, NotGiven]=NOT_GIVEN, max_retries: int=DEFAULT_MAX_RETRIES, default_headers: Mapping[str, str] | None=None, default_query: Mapping[str, object] | None=None, http_client: httpx.Client | None=None, _strict_response_validation: bool=False)\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='llmcoder.analyze.Analyzer.Analyzer', description='class Analyzer'>>,\n",
      "name.signature: Type[Analyzer],\n",
      "name.docstring: Analyzer(verbose: bool=False)\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='llmcoder.utils.get_openai_key', description='def get_openai_key'>>,\n",
      "name.signature: get_openai_key(key: str = \"\") -> str,\n",
      "name.docstring: get_openai_key(key: str=\"\") -> str\n",
      "\n",
      "Get OpenAI API key. Try to interpret the key as a key first, then as a path to a file containing the key.\n",
      "Finally, fall back to the default key.txt file or the OPENAI_KEY environment variable.\n",
      "\n",
      "Parameters\n",
      "----------\n",
      "key : str\n",
      "    The key or path to the key file.\n",
      "\n",
      "Returns\n",
      "-------\n",
      "str\n",
      "    The key.\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='llmcoder.utils.get_system_prompt', description='def get_system_prompt'>>,\n",
      "name.signature: get_system_prompt(name: str = \"2023-11-15_GPT-Builder.txt\") -> str,\n",
      "name.docstring: get_system_prompt(name: str=\"2023-11-15_GPT-Builder.txt\") -> str\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='llmcoder.utils.get_system_prompt_dir', description='def get_system_prompt_dir'>>,\n",
      "name.signature: get_system_prompt_dir(*args: str, create: bool = False) -> str,\n",
      "name.docstring: get_system_prompt_dir(*, create: bool=False) -> str\n",
      "\n",
      "Get the path to the system prompts directory.\n",
      "\n",
      "Parameters\n",
      "----------\n",
      "args : str\n",
      "    The path to the system prompts directory.\n",
      "create : bool\n",
      "    Whether to create the directory if it does not exist.\n",
      "\n",
      "Returns\n",
      "-------\n",
      "str\n",
      "    The path to the system prompts directory.\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='__main__.GPTReviewAnalyzer_v1', description='class GPTReviewAnalyzer_v1'>>,\n",
      "name.signature: Type[GPTReviewAnalyzer_v1],\n",
      "name.docstring: GPTReviewAnalyzer_v1(model: str=\"gpt-3.5-turbo\", system_prompt: str | None=None, min_score: int=6, temperature: float=0.2)\n",
      "\n",
      "Concise, professional Python code advisor for targeted feedback.\n",
      "\n",
      "Parameters\n",
      "----------\n",
      "model : str, optional\n",
      "    The model to use, by default \"gpt-3.5-turbo\"\n",
      "system_prompt : str, optional\n",
      "    The system prompt to use, by default `2023-12-02_GPTReviewAnalyzer_v4.txt`, created by GPTBuilder\n",
      "min_score : int, optional\n",
      "    The minimum score to pass the review, by default 6\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='__main__.GPTReviewAnalyzer_v1.__init__', description='def __init__'>>,\n",
      "name.signature: __init__(self, model: str=\"gpt-3.5-turbo\", system_prompt: Optional[str]=None, min_score: int=6, temperature: float=0.2),\n",
      "name.docstring: __init__(self, model: str=\"gpt-3.5-turbo\", system_prompt: str | None=None, min_score: int=6, temperature: float=0.2)\n",
      "\n",
      "Initialize the GPTReviewAnalyzer\n",
      "\n",
      "Parameters\n",
      "----------\n",
      "model : str, optional\n",
      "    The model to use, by default \"gpt-3.5-turbo\"\n",
      "system_prompt : str, optional\n",
      "    The system prompt to use, by default `2023-12-02_GPTReviewAnalyzer_v4.txt`, created by GPTBuilder\n",
      "min_score : int, optional\n",
      "    The minimum score to pass the review, by default 6\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='__main__.GPTReviewAnalyzer_v1.analyze', description='def analyze'>>,\n",
      "name.signature: analyze(self, input: str, completion: str, context: dict[str, dict[str, bool | str]] | None = None) -> dict,\n",
      "name.docstring: analyze(self, input: str, completion: str, context: dict[str, dict[str, bool | str]] | None=None) -> dict\n",
      "\n",
      "Analyze the input and completion\n",
      "\n",
      "Parameters\n",
      "----------\n",
      "input : str\n",
      "    The input to analyze\n",
      "completion : str\n",
      "    The completion to analyze\n",
      "\n",
      "Returns\n",
      "-------\n",
      "dict\n",
      "    The analysis of the input and completion\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='__main__.GPTReviewAnalyzer_v1._prompt_template', description='def _prompt_template'>>,\n",
      "name.signature: _prompt_template(input: str, completion: str) -> str,\n",
      "name.docstring: _prompt_template(input: str, completion: str) -> str\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='openai.OpenAI', description='class OpenAI'>>,\n",
      "name.signature: Type[OpenAI],\n",
      "name.docstring: OpenAI(*, api_key: str | None=None, organization: str | None=None, base_url: str | httpx.URL | None=None, timeout: Union[float, Timeout, None, NotGiven]=NOT_GIVEN, max_retries: int=DEFAULT_MAX_RETRIES, default_headers: Mapping[str, str] | None=None, default_query: Mapping[str, object] | None=None, http_client: httpx.Client | None=None, _strict_response_validation: bool=False)\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='llmcoder.analyze.Analyzer.Analyzer', description='class Analyzer'>>,\n",
      "name.signature: Type[Analyzer],\n",
      "name.docstring: Analyzer(verbose: bool=False)\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='llmcoder.utils.get_openai_key', description='def get_openai_key'>>,\n",
      "name.signature: get_openai_key(key: str = \"\") -> str,\n",
      "name.docstring: get_openai_key(key: str=\"\") -> str\n",
      "\n",
      "Get OpenAI API key. Try to interpret the key as a key first, then as a path to a file containing the key.\n",
      "Finally, fall back to the default key.txt file or the OPENAI_KEY environment variable.\n",
      "\n",
      "Parameters\n",
      "----------\n",
      "key : str\n",
      "    The key or path to the key file.\n",
      "\n",
      "Returns\n",
      "-------\n",
      "str\n",
      "    The key.\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='llmcoder.utils.get_system_prompt', description='def get_system_prompt'>>,\n",
      "name.signature: get_system_prompt(name: str = \"2023-11-15_GPT-Builder.txt\") -> str,\n",
      "name.docstring: get_system_prompt(name: str=\"2023-11-15_GPT-Builder.txt\") -> str\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='llmcoder.utils.get_system_prompt_dir', description='def get_system_prompt_dir'>>,\n",
      "name.signature: get_system_prompt_dir(*args: str, create: bool = False) -> str,\n",
      "name.docstring: get_system_prompt_dir(*, create: bool=False) -> str\n",
      "\n",
      "Get the path to the system prompts directory.\n",
      "\n",
      "Parameters\n",
      "----------\n",
      "args : str\n",
      "    The path to the system prompts directory.\n",
      "create : bool\n",
      "    Whether to create the directory if it does not exist.\n",
      "\n",
      "Returns\n",
      "-------\n",
      "str\n",
      "    The path to the system prompts directory.\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='__main__.GPTReviewAnalyzer_v1', description='class GPTReviewAnalyzer_v1'>>,\n",
      "name.signature: Type[GPTReviewAnalyzer_v1],\n",
      "name.docstring: GPTReviewAnalyzer_v1(model: str=\"gpt-3.5-turbo\", system_prompt: str | None=None, min_score: int=6, temperature: float=0.2)\n",
      "\n",
      "Concise, professional Python code advisor for targeted feedback.\n",
      "\n",
      "Parameters\n",
      "----------\n",
      "model : str, optional\n",
      "    The model to use, by default \"gpt-3.5-turbo\"\n",
      "system_prompt : str, optional\n",
      "    The system prompt to use, by default `2023-12-02_GPTReviewAnalyzer_v4.txt`, created by GPTBuilder\n",
      "min_score : int, optional\n",
      "    The minimum score to pass the review, by default 6\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='__main__.GPTReviewAnalyzer_v1.__init__', description='def __init__'>>,\n",
      "name.signature: __init__(self, model: str=\"gpt-3.5-turbo\", system_prompt: Optional[str]=None, min_score: int=6, temperature: float=0.2),\n",
      "name.docstring: __init__(self, model: str=\"gpt-3.5-turbo\", system_prompt: str | None=None, min_score: int=6, temperature: float=0.2)\n",
      "\n",
      "Initialize the GPTReviewAnalyzer\n",
      "\n",
      "Parameters\n",
      "----------\n",
      "model : str, optional\n",
      "    The model to use, by default \"gpt-3.5-turbo\"\n",
      "system_prompt : str, optional\n",
      "    The system prompt to use, by default `2023-12-02_GPTReviewAnalyzer_v4.txt`, created by GPTBuilder\n",
      "min_score : int, optional\n",
      "    The minimum score to pass the review, by default 6\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='__main__.GPTReviewAnalyzer_v1.analyze', description='def analyze'>>,\n",
      "name.signature: analyze(self, input: str, completion: str, context: dict[str, dict[str, bool | str]] | None = None) -> dict,\n",
      "name.docstring: analyze(self, input: str, completion: str, context: dict[str, dict[str, bool | str]] | None=None) -> dict\n",
      "\n",
      "Analyze the input and completion\n",
      "\n",
      "Parameters\n",
      "----------\n",
      "input : str\n",
      "    The input to analyze\n",
      "completion : str\n",
      "    The completion to analyze\n",
      "\n",
      "Returns\n",
      "-------\n",
      "dict\n",
      "    The analysis of the input and completion\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='__main__.GPTReviewAnalyzer_v1._prompt_template', description='def _prompt_template'>>,\n",
      "name.signature: _prompt_template(input: str, completion: str) -> str,\n",
      "name.docstring: _prompt_template(input: str, completion: str) -> str\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='openai.OpenAI', description='class OpenAI'>>,\n",
      "name.signature: Type[OpenAI],\n",
      "name.docstring: OpenAI(*, api_key: str | None=None, organization: str | None=None, base_url: str | httpx.URL | None=None, timeout: Union[float, Timeout, None, NotGiven]=NOT_GIVEN, max_retries: int=DEFAULT_MAX_RETRIES, default_headers: Mapping[str, str] | None=None, default_query: Mapping[str, object] | None=None, http_client: httpx.Client | None=None, _strict_response_validation: bool=False)\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='llmcoder.analyze.Analyzer.Analyzer', description='class Analyzer'>>,\n",
      "name.signature: Type[Analyzer],\n",
      "name.docstring: Analyzer(verbose: bool=False)\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='llmcoder.utils.get_openai_key', description='def get_openai_key'>>,\n",
      "name.signature: get_openai_key(key: str = \"\") -> str,\n",
      "name.docstring: get_openai_key(key: str=\"\") -> str\n",
      "\n",
      "Get OpenAI API key. Try to interpret the key as a key first, then as a path to a file containing the key.\n",
      "Finally, fall back to the default key.txt file or the OPENAI_KEY environment variable.\n",
      "\n",
      "Parameters\n",
      "----------\n",
      "key : str\n",
      "    The key or path to the key file.\n",
      "\n",
      "Returns\n",
      "-------\n",
      "str\n",
      "    The key.\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='llmcoder.utils.get_system_prompt', description='def get_system_prompt'>>,\n",
      "name.signature: get_system_prompt(name: str = \"2023-11-15_GPT-Builder.txt\") -> str,\n",
      "name.docstring: get_system_prompt(name: str=\"2023-11-15_GPT-Builder.txt\") -> str\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='llmcoder.utils.get_system_prompt_dir', description='def get_system_prompt_dir'>>,\n",
      "name.signature: get_system_prompt_dir(*args: str, create: bool = False) -> str,\n",
      "name.docstring: get_system_prompt_dir(*, create: bool=False) -> str\n",
      "\n",
      "Get the path to the system prompts directory.\n",
      "\n",
      "Parameters\n",
      "----------\n",
      "args : str\n",
      "    The path to the system prompts directory.\n",
      "create : bool\n",
      "    Whether to create the directory if it does not exist.\n",
      "\n",
      "Returns\n",
      "-------\n",
      "str\n",
      "    The path to the system prompts directory.\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='__main__.GPTReviewAnalyzer_v1', description='class GPTReviewAnalyzer_v1'>>,\n",
      "name.signature: Type[GPTReviewAnalyzer_v1],\n",
      "name.docstring: GPTReviewAnalyzer_v1(model: str=\"gpt-3.5-turbo\", system_prompt: str | None=None, min_score: int=6, temperature: float=0.2)\n",
      "\n",
      "Concise, professional Python code advisor for targeted feedback.\n",
      "\n",
      "Parameters\n",
      "----------\n",
      "model : str, optional\n",
      "    The model to use, by default \"gpt-3.5-turbo\"\n",
      "system_prompt : str, optional\n",
      "    The system prompt to use, by default `2023-12-02_GPTReviewAnalyzer_v4.txt`, created by GPTBuilder\n",
      "min_score : int, optional\n",
      "    The minimum score to pass the review, by default 6\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='__main__.GPTReviewAnalyzer_v1.__init__', description='def __init__'>>,\n",
      "name.signature: __init__(self, model: str=\"gpt-3.5-turbo\", system_prompt: Optional[str]=None, min_score: int=6, temperature: float=0.2),\n",
      "name.docstring: __init__(self, model: str=\"gpt-3.5-turbo\", system_prompt: str | None=None, min_score: int=6, temperature: float=0.2)\n",
      "\n",
      "Initialize the GPTReviewAnalyzer\n",
      "\n",
      "Parameters\n",
      "----------\n",
      "model : str, optional\n",
      "    The model to use, by default \"gpt-3.5-turbo\"\n",
      "system_prompt : str, optional\n",
      "    The system prompt to use, by default `2023-12-02_GPTReviewAnalyzer_v4.txt`, created by GPTBuilder\n",
      "min_score : int, optional\n",
      "    The minimum score to pass the review, by default 6\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='__main__.GPTReviewAnalyzer_v1.analyze', description='def analyze'>>,\n",
      "name.signature: analyze(self, input: str, completion: str, context: dict[str, dict[str, bool | str]] | None = None) -> dict,\n",
      "name.docstring: analyze(self, input: str, completion: str, context: dict[str, dict[str, bool | str]] | None=None) -> dict\n",
      "\n",
      "Analyze the input and completion\n",
      "\n",
      "Parameters\n",
      "----------\n",
      "input : str\n",
      "    The input to analyze\n",
      "completion : str\n",
      "    The completion to analyze\n",
      "\n",
      "Returns\n",
      "-------\n",
      "dict\n",
      "    The analysis of the input and completion\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='__main__.GPTReviewAnalyzer_v1._prompt_template', description='def _prompt_template'>>,\n",
      "name.signature: _prompt_template(input: str, completion: str) -> str,\n",
      "name.docstring: _prompt_template(input: str, completion: str) -> str\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='openai.OpenAI', description='class OpenAI'>>,\n",
      "name.signature: Type[OpenAI],\n",
      "name.docstring: OpenAI(*, api_key: str | None=None, organization: str | None=None, base_url: str | httpx.URL | None=None, timeout: Union[float, Timeout, None, NotGiven]=NOT_GIVEN, max_retries: int=DEFAULT_MAX_RETRIES, default_headers: Mapping[str, str] | None=None, default_query: Mapping[str, object] | None=None, http_client: httpx.Client | None=None, _strict_response_validation: bool=False)\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='llmcoder.analyze.Analyzer.Analyzer', description='class Analyzer'>>,\n",
      "name.signature: Type[Analyzer],\n",
      "name.docstring: Analyzer(verbose: bool=False)\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='llmcoder.utils.get_openai_key', description='def get_openai_key'>>,\n",
      "name.signature: get_openai_key(key: str = \"\") -> str,\n",
      "name.docstring: get_openai_key(key: str=\"\") -> str\n",
      "\n",
      "Get OpenAI API key. Try to interpret the key as a key first, then as a path to a file containing the key.\n",
      "Finally, fall back to the default key.txt file or the OPENAI_KEY environment variable.\n",
      "\n",
      "Parameters\n",
      "----------\n",
      "key : str\n",
      "    The key or path to the key file.\n",
      "\n",
      "Returns\n",
      "-------\n",
      "str\n",
      "    The key.\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='llmcoder.utils.get_system_prompt', description='def get_system_prompt'>>,\n",
      "name.signature: get_system_prompt(name: str = \"2023-11-15_GPT-Builder.txt\") -> str,\n",
      "name.docstring: get_system_prompt(name: str=\"2023-11-15_GPT-Builder.txt\") -> str\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='llmcoder.utils.get_system_prompt_dir', description='def get_system_prompt_dir'>>,\n",
      "name.signature: get_system_prompt_dir(*args: str, create: bool = False) -> str,\n",
      "name.docstring: get_system_prompt_dir(*, create: bool=False) -> str\n",
      "\n",
      "Get the path to the system prompts directory.\n",
      "\n",
      "Parameters\n",
      "----------\n",
      "args : str\n",
      "    The path to the system prompts directory.\n",
      "create : bool\n",
      "    Whether to create the directory if it does not exist.\n",
      "\n",
      "Returns\n",
      "-------\n",
      "str\n",
      "    The path to the system prompts directory.\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='__main__.GPTReviewAnalyzer_v1', description='class GPTReviewAnalyzer_v1'>>,\n",
      "name.signature: Type[GPTReviewAnalyzer_v1],\n",
      "name.docstring: GPTReviewAnalyzer_v1(model: str=\"gpt-3.5-turbo\", system_prompt: str | None=None, min_score: int=6, temperature: float=0.2)\n",
      "\n",
      "Concise, professional Python code advisor for targeted feedback.\n",
      "\n",
      "Parameters\n",
      "----------\n",
      "model : str, optional\n",
      "    The model to use, by default \"gpt-3.5-turbo\"\n",
      "system_prompt : str, optional\n",
      "    The system prompt to use, by default `2023-12-02_GPTReviewAnalyzer_v4.txt`, created by GPTBuilder\n",
      "min_score : int, optional\n",
      "    The minimum score to pass the review, by default 6\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='__main__.GPTReviewAnalyzer_v1.__init__', description='def __init__'>>,\n",
      "name.signature: __init__(self, model: str=\"gpt-3.5-turbo\", system_prompt: Optional[str]=None, min_score: int=6, temperature: float=0.2),\n",
      "name.docstring: __init__(self, model: str=\"gpt-3.5-turbo\", system_prompt: str | None=None, min_score: int=6, temperature: float=0.2)\n",
      "\n",
      "Initialize the GPTReviewAnalyzer\n",
      "\n",
      "Parameters\n",
      "----------\n",
      "model : str, optional\n",
      "    The model to use, by default \"gpt-3.5-turbo\"\n",
      "system_prompt : str, optional\n",
      "    The system prompt to use, by default `2023-12-02_GPTReviewAnalyzer_v4.txt`, created by GPTBuilder\n",
      "min_score : int, optional\n",
      "    The minimum score to pass the review, by default 6\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='__main__.GPTReviewAnalyzer_v1.analyze', description='def analyze'>>,\n",
      "name.signature: analyze(self, input: str, completion: str, context: dict[str, dict[str, bool | str]] | None = None) -> dict,\n",
      "name.docstring: analyze(self, input: str, completion: str, context: dict[str, dict[str, bool | str]] | None=None) -> dict\n",
      "\n",
      "Analyze the input and completion\n",
      "\n",
      "Parameters\n",
      "----------\n",
      "input : str\n",
      "    The input to analyze\n",
      "completion : str\n",
      "    The completion to analyze\n",
      "\n",
      "Returns\n",
      "-------\n",
      "dict\n",
      "    The analysis of the input and completion\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='__main__.GPTReviewAnalyzer_v1._prompt_template', description='def _prompt_template'>>,\n",
      "name.signature: _prompt_template(input: str, completion: str) -> str,\n",
      "name.docstring: _prompt_template(input: str, completion: str) -> str\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='openai.OpenAI', description='class OpenAI'>>,\n",
      "name.signature: Type[OpenAI],\n",
      "name.docstring: OpenAI(*, api_key: str | None=None, organization: str | None=None, base_url: str | httpx.URL | None=None, timeout: Union[float, Timeout, None, NotGiven]=NOT_GIVEN, max_retries: int=DEFAULT_MAX_RETRIES, default_headers: Mapping[str, str] | None=None, default_query: Mapping[str, object] | None=None, http_client: httpx.Client | None=None, _strict_response_validation: bool=False)\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='llmcoder.analyze.Analyzer.Analyzer', description='class Analyzer'>>,\n",
      "name.signature: Type[Analyzer],\n",
      "name.docstring: Analyzer(verbose: bool=False)\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='llmcoder.utils.get_openai_key', description='def get_openai_key'>>,\n",
      "name.signature: get_openai_key(key: str = \"\") -> str,\n",
      "name.docstring: get_openai_key(key: str=\"\") -> str\n",
      "\n",
      "Get OpenAI API key. Try to interpret the key as a key first, then as a path to a file containing the key.\n",
      "Finally, fall back to the default key.txt file or the OPENAI_KEY environment variable.\n",
      "\n",
      "Parameters\n",
      "----------\n",
      "key : str\n",
      "    The key or path to the key file.\n",
      "\n",
      "Returns\n",
      "-------\n",
      "str\n",
      "    The key.\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='llmcoder.utils.get_system_prompt', description='def get_system_prompt'>>,\n",
      "name.signature: get_system_prompt(name: str = \"2023-11-15_GPT-Builder.txt\") -> str,\n",
      "name.docstring: get_system_prompt(name: str=\"2023-11-15_GPT-Builder.txt\") -> str\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='llmcoder.utils.get_system_prompt_dir', description='def get_system_prompt_dir'>>,\n",
      "name.signature: get_system_prompt_dir(*args: str, create: bool = False) -> str,\n",
      "name.docstring: get_system_prompt_dir(*, create: bool=False) -> str\n",
      "\n",
      "Get the path to the system prompts directory.\n",
      "\n",
      "Parameters\n",
      "----------\n",
      "args : str\n",
      "    The path to the system prompts directory.\n",
      "create : bool\n",
      "    Whether to create the directory if it does not exist.\n",
      "\n",
      "Returns\n",
      "-------\n",
      "str\n",
      "    The path to the system prompts directory.\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='__main__.GPTReviewAnalyzer_v1', description='class GPTReviewAnalyzer_v1'>>,\n",
      "name.signature: Type[GPTReviewAnalyzer_v1],\n",
      "name.docstring: GPTReviewAnalyzer_v1(model: str=\"gpt-3.5-turbo\", system_prompt: str | None=None, min_score: int=6, temperature: float=0.2)\n",
      "\n",
      "Concise, professional Python code advisor for targeted feedback.\n",
      "\n",
      "Parameters\n",
      "----------\n",
      "model : str, optional\n",
      "    The model to use, by default \"gpt-3.5-turbo\"\n",
      "system_prompt : str, optional\n",
      "    The system prompt to use, by default `2023-12-02_GPTReviewAnalyzer_v4.txt`, created by GPTBuilder\n",
      "min_score : int, optional\n",
      "    The minimum score to pass the review, by default 6\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='__main__.GPTReviewAnalyzer_v1.__init__', description='def __init__'>>,\n",
      "name.signature: __init__(self, model: str=\"gpt-3.5-turbo\", system_prompt: Optional[str]=None, min_score: int=6, temperature: float=0.2),\n",
      "name.docstring: __init__(self, model: str=\"gpt-3.5-turbo\", system_prompt: str | None=None, min_score: int=6, temperature: float=0.2)\n",
      "\n",
      "Initialize the GPTReviewAnalyzer\n",
      "\n",
      "Parameters\n",
      "----------\n",
      "model : str, optional\n",
      "    The model to use, by default \"gpt-3.5-turbo\"\n",
      "system_prompt : str, optional\n",
      "    The system prompt to use, by default `2023-12-02_GPTReviewAnalyzer_v4.txt`, created by GPTBuilder\n",
      "min_score : int, optional\n",
      "    The minimum score to pass the review, by default 6\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='__main__.GPTReviewAnalyzer_v1.analyze', description='def analyze'>>,\n",
      "name.signature: analyze(self, input: str, completion: str, context: dict[str, dict[str, bool | str]] | None = None) -> dict,\n",
      "name.docstring: analyze(self, input: str, completion: str, context: dict[str, dict[str, bool | str]] | None=None) -> dict\n",
      "\n",
      "Analyze the input and completion\n",
      "\n",
      "Parameters\n",
      "----------\n",
      "input : str\n",
      "    The input to analyze\n",
      "completion : str\n",
      "    The completion to analyze\n",
      "\n",
      "Returns\n",
      "-------\n",
      "dict\n",
      "    The analysis of the input and completion\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='__main__.GPTReviewAnalyzer_v1._prompt_template', description='def _prompt_template'>>,\n",
      "name.signature: _prompt_template(input: str, completion: str) -> str,\n",
      "name.docstring: _prompt_template(input: str, completion: str) -> str\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='openai.OpenAI', description='class OpenAI'>>,\n",
      "name.signature: Type[OpenAI],\n",
      "name.docstring: OpenAI(*, api_key: str | None=None, organization: str | None=None, base_url: str | httpx.URL | None=None, timeout: Union[float, Timeout, None, NotGiven]=NOT_GIVEN, max_retries: int=DEFAULT_MAX_RETRIES, default_headers: Mapping[str, str] | None=None, default_query: Mapping[str, object] | None=None, http_client: httpx.Client | None=None, _strict_response_validation: bool=False)\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='llmcoder.analyze.Analyzer.Analyzer', description='class Analyzer'>>,\n",
      "name.signature: Type[Analyzer],\n",
      "name.docstring: Analyzer(verbose: bool=False)\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='llmcoder.utils.get_openai_key', description='def get_openai_key'>>,\n",
      "name.signature: get_openai_key(key: str = \"\") -> str,\n",
      "name.docstring: get_openai_key(key: str=\"\") -> str\n",
      "\n",
      "Get OpenAI API key. Try to interpret the key as a key first, then as a path to a file containing the key.\n",
      "Finally, fall back to the default key.txt file or the OPENAI_KEY environment variable.\n",
      "\n",
      "Parameters\n",
      "----------\n",
      "key : str\n",
      "    The key or path to the key file.\n",
      "\n",
      "Returns\n",
      "-------\n",
      "str\n",
      "    The key.\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='llmcoder.utils.get_system_prompt', description='def get_system_prompt'>>,\n",
      "name.signature: get_system_prompt(name: str = \"2023-11-15_GPT-Builder.txt\") -> str,\n",
      "name.docstring: get_system_prompt(name: str=\"2023-11-15_GPT-Builder.txt\") -> str\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='llmcoder.utils.get_system_prompt_dir', description='def get_system_prompt_dir'>>,\n",
      "name.signature: get_system_prompt_dir(*args: str, create: bool = False) -> str,\n",
      "name.docstring: get_system_prompt_dir(*, create: bool=False) -> str\n",
      "\n",
      "Get the path to the system prompts directory.\n",
      "\n",
      "Parameters\n",
      "----------\n",
      "args : str\n",
      "    The path to the system prompts directory.\n",
      "create : bool\n",
      "    Whether to create the directory if it does not exist.\n",
      "\n",
      "Returns\n",
      "-------\n",
      "str\n",
      "    The path to the system prompts directory.\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='__main__.GPTReviewAnalyzer_v1', description='class GPTReviewAnalyzer_v1'>>,\n",
      "name.signature: Type[GPTReviewAnalyzer_v1],\n",
      "name.docstring: GPTReviewAnalyzer_v1(model: str=\"gpt-3.5-turbo\", system_prompt: str | None=None, min_score: int=6, temperature: float=0.2)\n",
      "\n",
      "Concise, professional Python code advisor for targeted feedback.\n",
      "\n",
      "Parameters\n",
      "----------\n",
      "model : str, optional\n",
      "    The model to use, by default \"gpt-3.5-turbo\"\n",
      "system_prompt : str, optional\n",
      "    The system prompt to use, by default `2023-12-02_GPTReviewAnalyzer_v4.txt`, created by GPTBuilder\n",
      "min_score : int, optional\n",
      "    The minimum score to pass the review, by default 6\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='__main__.GPTReviewAnalyzer_v1.__init__', description='def __init__'>>,\n",
      "name.signature: __init__(self, model: str=\"gpt-3.5-turbo\", system_prompt: Optional[str]=None, min_score: int=6, temperature: float=0.2),\n",
      "name.docstring: __init__(self, model: str=\"gpt-3.5-turbo\", system_prompt: str | None=None, min_score: int=6, temperature: float=0.2)\n",
      "\n",
      "Initialize the GPTReviewAnalyzer\n",
      "\n",
      "Parameters\n",
      "----------\n",
      "model : str, optional\n",
      "    The model to use, by default \"gpt-3.5-turbo\"\n",
      "system_prompt : str, optional\n",
      "    The system prompt to use, by default `2023-12-02_GPTReviewAnalyzer_v4.txt`, created by GPTBuilder\n",
      "min_score : int, optional\n",
      "    The minimum score to pass the review, by default 6\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='__main__.GPTReviewAnalyzer_v1.analyze', description='def analyze'>>,\n",
      "name.signature: analyze(self, input: str, completion: str, context: dict[str, dict[str, bool | str]] | None = None) -> dict,\n",
      "name.docstring: analyze(self, input: str, completion: str, context: dict[str, dict[str, bool | str]] | None=None) -> dict\n",
      "\n",
      "Analyze the input and completion\n",
      "\n",
      "Parameters\n",
      "----------\n",
      "input : str\n",
      "    The input to analyze\n",
      "completion : str\n",
      "    The completion to analyze\n",
      "\n",
      "Returns\n",
      "-------\n",
      "dict\n",
      "    The analysis of the input and completion\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='__main__.GPTReviewAnalyzer_v1._prompt_template', description='def _prompt_template'>>,\n",
      "name.signature: _prompt_template(input: str, completion: str) -> str,\n",
      "name.docstring: _prompt_template(input: str, completion: str) -> str\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='openai.OpenAI', description='class OpenAI'>>,\n",
      "name.signature: Type[OpenAI],\n",
      "name.docstring: OpenAI(*, api_key: str | None=None, organization: str | None=None, base_url: str | httpx.URL | None=None, timeout: Union[float, Timeout, None, NotGiven]=NOT_GIVEN, max_retries: int=DEFAULT_MAX_RETRIES, default_headers: Mapping[str, str] | None=None, default_query: Mapping[str, object] | None=None, http_client: httpx.Client | None=None, _strict_response_validation: bool=False)\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='llmcoder.analyze.Analyzer.Analyzer', description='class Analyzer'>>,\n",
      "name.signature: Type[Analyzer],\n",
      "name.docstring: Analyzer(verbose: bool=False)\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='llmcoder.utils.get_openai_key', description='def get_openai_key'>>,\n",
      "name.signature: get_openai_key(key: str = \"\") -> str,\n",
      "name.docstring: get_openai_key(key: str=\"\") -> str\n",
      "\n",
      "Get OpenAI API key. Try to interpret the key as a key first, then as a path to a file containing the key.\n",
      "Finally, fall back to the default key.txt file or the OPENAI_KEY environment variable.\n",
      "\n",
      "Parameters\n",
      "----------\n",
      "key : str\n",
      "    The key or path to the key file.\n",
      "\n",
      "Returns\n",
      "-------\n",
      "str\n",
      "    The key.\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='llmcoder.utils.get_system_prompt', description='def get_system_prompt'>>,\n",
      "name.signature: get_system_prompt(name: str = \"2023-11-15_GPT-Builder.txt\") -> str,\n",
      "name.docstring: get_system_prompt(name: str=\"2023-11-15_GPT-Builder.txt\") -> str\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='llmcoder.utils.get_system_prompt_dir', description='def get_system_prompt_dir'>>,\n",
      "name.signature: get_system_prompt_dir(*args: str, create: bool = False) -> str,\n",
      "name.docstring: get_system_prompt_dir(*, create: bool=False) -> str\n",
      "\n",
      "Get the path to the system prompts directory.\n",
      "\n",
      "Parameters\n",
      "----------\n",
      "args : str\n",
      "    The path to the system prompts directory.\n",
      "create : bool\n",
      "    Whether to create the directory if it does not exist.\n",
      "\n",
      "Returns\n",
      "-------\n",
      "str\n",
      "    The path to the system prompts directory.\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='__main__.GPTReviewAnalyzer_v1', description='class GPTReviewAnalyzer_v1'>>,\n",
      "name.signature: Type[GPTReviewAnalyzer_v1],\n",
      "name.docstring: GPTReviewAnalyzer_v1(model: str=\"gpt-3.5-turbo\", system_prompt: str | None=None, min_score: int=6, temperature: float=0.2)\n",
      "\n",
      "Concise, professional Python code advisor for targeted feedback.\n",
      "\n",
      "Parameters\n",
      "----------\n",
      "model : str, optional\n",
      "    The model to use, by default \"gpt-3.5-turbo\"\n",
      "system_prompt : str, optional\n",
      "    The system prompt to use, by default `2023-12-02_GPTReviewAnalyzer_v4.txt`, created by GPTBuilder\n",
      "min_score : int, optional\n",
      "    The minimum score to pass the review, by default 6\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='__main__.GPTReviewAnalyzer_v1.__init__', description='def __init__'>>,\n",
      "name.signature: __init__(self, model: str=\"gpt-3.5-turbo\", system_prompt: Optional[str]=None, min_score: int=6, temperature: float=0.2),\n",
      "name.docstring: __init__(self, model: str=\"gpt-3.5-turbo\", system_prompt: str | None=None, min_score: int=6, temperature: float=0.2)\n",
      "\n",
      "Initialize the GPTReviewAnalyzer\n",
      "\n",
      "Parameters\n",
      "----------\n",
      "model : str, optional\n",
      "    The model to use, by default \"gpt-3.5-turbo\"\n",
      "system_prompt : str, optional\n",
      "    The system prompt to use, by default `2023-12-02_GPTReviewAnalyzer_v4.txt`, created by GPTBuilder\n",
      "min_score : int, optional\n",
      "    The minimum score to pass the review, by default 6\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='__main__.GPTReviewAnalyzer_v1.analyze', description='def analyze'>>,\n",
      "name.signature: analyze(self, input: str, completion: str, context: dict[str, dict[str, bool | str]] | None = None) -> dict,\n",
      "name.docstring: analyze(self, input: str, completion: str, context: dict[str, dict[str, bool | str]] | None=None) -> dict\n",
      "\n",
      "Analyze the input and completion\n",
      "\n",
      "Parameters\n",
      "----------\n",
      "input : str\n",
      "    The input to analyze\n",
      "completion : str\n",
      "    The completion to analyze\n",
      "\n",
      "Returns\n",
      "-------\n",
      "dict\n",
      "    The analysis of the input and completion\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='__main__.GPTReviewAnalyzer_v1._prompt_template', description='def _prompt_template'>>,\n",
      "name.signature: _prompt_template(input: str, completion: str) -> str,\n",
      "name.docstring: _prompt_template(input: str, completion: str) -> str\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='openai.OpenAI', description='class OpenAI'>>,\n",
      "name.signature: Type[OpenAI],\n",
      "name.docstring: OpenAI(*, api_key: str | None=None, organization: str | None=None, base_url: str | httpx.URL | None=None, timeout: Union[float, Timeout, None, NotGiven]=NOT_GIVEN, max_retries: int=DEFAULT_MAX_RETRIES, default_headers: Mapping[str, str] | None=None, default_query: Mapping[str, object] | None=None, http_client: httpx.Client | None=None, _strict_response_validation: bool=False)\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='llmcoder.analyze.Analyzer.Analyzer', description='class Analyzer'>>,\n",
      "name.signature: Type[Analyzer],\n",
      "name.docstring: Analyzer(verbose: bool=False)\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='llmcoder.utils.get_openai_key', description='def get_openai_key'>>,\n",
      "name.signature: get_openai_key(key: str = \"\") -> str,\n",
      "name.docstring: get_openai_key(key: str=\"\") -> str\n",
      "\n",
      "Get OpenAI API key. Try to interpret the key as a key first, then as a path to a file containing the key.\n",
      "Finally, fall back to the default key.txt file or the OPENAI_KEY environment variable.\n",
      "\n",
      "Parameters\n",
      "----------\n",
      "key : str\n",
      "    The key or path to the key file.\n",
      "\n",
      "Returns\n",
      "-------\n",
      "str\n",
      "    The key.\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='llmcoder.utils.get_system_prompt', description='def get_system_prompt'>>,\n",
      "name.signature: get_system_prompt(name: str = \"2023-11-15_GPT-Builder.txt\") -> str,\n",
      "name.docstring: get_system_prompt(name: str=\"2023-11-15_GPT-Builder.txt\") -> str\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='llmcoder.utils.get_system_prompt_dir', description='def get_system_prompt_dir'>>,\n",
      "name.signature: get_system_prompt_dir(*args: str, create: bool = False) -> str,\n",
      "name.docstring: get_system_prompt_dir(*, create: bool=False) -> str\n",
      "\n",
      "Get the path to the system prompts directory.\n",
      "\n",
      "Parameters\n",
      "----------\n",
      "args : str\n",
      "    The path to the system prompts directory.\n",
      "create : bool\n",
      "    Whether to create the directory if it does not exist.\n",
      "\n",
      "Returns\n",
      "-------\n",
      "str\n",
      "    The path to the system prompts directory.\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='__main__.GPTReviewAnalyzer_v1', description='class GPTReviewAnalyzer_v1'>>,\n",
      "name.signature: Type[GPTReviewAnalyzer_v1],\n",
      "name.docstring: GPTReviewAnalyzer_v1(model: str=\"gpt-3.5-turbo\", system_prompt: str | None=None, min_score: int=6, temperature: float=0.2)\n",
      "\n",
      "Concise, professional Python code advisor for targeted feedback.\n",
      "\n",
      "Parameters\n",
      "----------\n",
      "model : str, optional\n",
      "    The model to use, by default \"gpt-3.5-turbo\"\n",
      "system_prompt : str, optional\n",
      "    The system prompt to use, by default `2023-12-02_GPTReviewAnalyzer_v4.txt`, created by GPTBuilder\n",
      "min_score : int, optional\n",
      "    The minimum score to pass the review, by default 6\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='__main__.GPTReviewAnalyzer_v1.__init__', description='def __init__'>>,\n",
      "name.signature: __init__(self, model: str=\"gpt-3.5-turbo\", system_prompt: Optional[str]=None, min_score: int=6, temperature: float=0.2),\n",
      "name.docstring: __init__(self, model: str=\"gpt-3.5-turbo\", system_prompt: str | None=None, min_score: int=6, temperature: float=0.2)\n",
      "\n",
      "Initialize the GPTReviewAnalyzer\n",
      "\n",
      "Parameters\n",
      "----------\n",
      "model : str, optional\n",
      "    The model to use, by default \"gpt-3.5-turbo\"\n",
      "system_prompt : str, optional\n",
      "    The system prompt to use, by default `2023-12-02_GPTReviewAnalyzer_v4.txt`, created by GPTBuilder\n",
      "min_score : int, optional\n",
      "    The minimum score to pass the review, by default 6\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='__main__.GPTReviewAnalyzer_v1.analyze', description='def analyze'>>,\n",
      "name.signature: analyze(self, input: str, completion: str, context: dict[str, dict[str, bool | str]] | None = None) -> dict,\n",
      "name.docstring: analyze(self, input: str, completion: str, context: dict[str, dict[str, bool | str]] | None=None) -> dict\n",
      "\n",
      "Analyze the input and completion\n",
      "\n",
      "Parameters\n",
      "----------\n",
      "input : str\n",
      "    The input to analyze\n",
      "completion : str\n",
      "    The completion to analyze\n",
      "\n",
      "Returns\n",
      "-------\n",
      "dict\n",
      "    The analysis of the input and completion\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='__main__.GPTReviewAnalyzer_v1._prompt_template', description='def _prompt_template'>>,\n",
      "name.signature: _prompt_template(input: str, completion: str) -> str,\n",
      "name.docstring: _prompt_template(input: str, completion: str) -> str\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='openai.OpenAI', description='class OpenAI'>>,\n",
      "name.signature: Type[OpenAI],\n",
      "name.docstring: OpenAI(*, api_key: str | None=None, organization: str | None=None, base_url: str | httpx.URL | None=None, timeout: Union[float, Timeout, None, NotGiven]=NOT_GIVEN, max_retries: int=DEFAULT_MAX_RETRIES, default_headers: Mapping[str, str] | None=None, default_query: Mapping[str, object] | None=None, http_client: httpx.Client | None=None, _strict_response_validation: bool=False)\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='llmcoder.analyze.Analyzer.Analyzer', description='class Analyzer'>>,\n",
      "name.signature: Type[Analyzer],\n",
      "name.docstring: Analyzer(verbose: bool=False)\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='llmcoder.utils.get_openai_key', description='def get_openai_key'>>,\n",
      "name.signature: get_openai_key(key: str = \"\") -> str,\n",
      "name.docstring: get_openai_key(key: str=\"\") -> str\n",
      "\n",
      "Get OpenAI API key. Try to interpret the key as a key first, then as a path to a file containing the key.\n",
      "Finally, fall back to the default key.txt file or the OPENAI_KEY environment variable.\n",
      "\n",
      "Parameters\n",
      "----------\n",
      "key : str\n",
      "    The key or path to the key file.\n",
      "\n",
      "Returns\n",
      "-------\n",
      "str\n",
      "    The key.\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='llmcoder.utils.get_system_prompt', description='def get_system_prompt'>>,\n",
      "name.signature: get_system_prompt(name: str = \"2023-11-15_GPT-Builder.txt\") -> str,\n",
      "name.docstring: get_system_prompt(name: str=\"2023-11-15_GPT-Builder.txt\") -> str\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='llmcoder.utils.get_system_prompt_dir', description='def get_system_prompt_dir'>>,\n",
      "name.signature: get_system_prompt_dir(*args: str, create: bool = False) -> str,\n",
      "name.docstring: get_system_prompt_dir(*, create: bool=False) -> str\n",
      "\n",
      "Get the path to the system prompts directory.\n",
      "\n",
      "Parameters\n",
      "----------\n",
      "args : str\n",
      "    The path to the system prompts directory.\n",
      "create : bool\n",
      "    Whether to create the directory if it does not exist.\n",
      "\n",
      "Returns\n",
      "-------\n",
      "str\n",
      "    The path to the system prompts directory.\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='__main__.GPTReviewAnalyzer_v1', description='class GPTReviewAnalyzer_v1'>>,\n",
      "name.signature: Type[GPTReviewAnalyzer_v1],\n",
      "name.docstring: GPTReviewAnalyzer_v1(model: str=\"gpt-3.5-turbo\", system_prompt: str | None=None, min_score: int=6, temperature: float=0.2)\n",
      "\n",
      "Concise, professional Python code advisor for targeted feedback.\n",
      "\n",
      "Parameters\n",
      "----------\n",
      "model : str, optional\n",
      "    The model to use, by default \"gpt-3.5-turbo\"\n",
      "system_prompt : str, optional\n",
      "    The system prompt to use, by default `2023-12-02_GPTReviewAnalyzer_v4.txt`, created by GPTBuilder\n",
      "min_score : int, optional\n",
      "    The minimum score to pass the review, by default 6\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='__main__.GPTReviewAnalyzer_v1.__init__', description='def __init__'>>,\n",
      "name.signature: __init__(self, model: str=\"gpt-3.5-turbo\", system_prompt: Optional[str]=None, min_score: int=6, temperature: float=0.2),\n",
      "name.docstring: __init__(self, model: str=\"gpt-3.5-turbo\", system_prompt: str | None=None, min_score: int=6, temperature: float=0.2)\n",
      "\n",
      "Initialize the GPTReviewAnalyzer\n",
      "\n",
      "Parameters\n",
      "----------\n",
      "model : str, optional\n",
      "    The model to use, by default \"gpt-3.5-turbo\"\n",
      "system_prompt : str, optional\n",
      "    The system prompt to use, by default `2023-12-02_GPTReviewAnalyzer_v4.txt`, created by GPTBuilder\n",
      "min_score : int, optional\n",
      "    The minimum score to pass the review, by default 6\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='__main__.GPTReviewAnalyzer_v1.analyze', description='def analyze'>>,\n",
      "name.signature: analyze(self, input: str, completion: str, context: dict[str, dict[str, bool | str]] | None = None) -> dict,\n",
      "name.docstring: analyze(self, input: str, completion: str, context: dict[str, dict[str, bool | str]] | None=None) -> dict\n",
      "\n",
      "Analyze the input and completion\n",
      "\n",
      "Parameters\n",
      "----------\n",
      "input : str\n",
      "    The input to analyze\n",
      "completion : str\n",
      "    The completion to analyze\n",
      "\n",
      "Returns\n",
      "-------\n",
      "dict\n",
      "    The analysis of the input and completion\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='__main__.GPTReviewAnalyzer_v1._prompt_template', description='def _prompt_template'>>,\n",
      "name.signature: _prompt_template(input: str, completion: str) -> str,\n",
      "name.docstring: _prompt_template(input: str, completion: str) -> str\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='openai.OpenAI', description='class OpenAI'>>,\n",
      "name.signature: Type[OpenAI],\n",
      "name.docstring: OpenAI(*, api_key: str | None=None, organization: str | None=None, base_url: str | httpx.URL | None=None, timeout: Union[float, Timeout, None, NotGiven]=NOT_GIVEN, max_retries: int=DEFAULT_MAX_RETRIES, default_headers: Mapping[str, str] | None=None, default_query: Mapping[str, object] | None=None, http_client: httpx.Client | None=None, _strict_response_validation: bool=False)\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='llmcoder.analyze.Analyzer.Analyzer', description='class Analyzer'>>,\n",
      "name.signature: Type[Analyzer],\n",
      "name.docstring: Analyzer(verbose: bool=False)\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='llmcoder.utils.get_openai_key', description='def get_openai_key'>>,\n",
      "name.signature: get_openai_key(key: str = \"\") -> str,\n",
      "name.docstring: get_openai_key(key: str=\"\") -> str\n",
      "\n",
      "Get OpenAI API key. Try to interpret the key as a key first, then as a path to a file containing the key.\n",
      "Finally, fall back to the default key.txt file or the OPENAI_KEY environment variable.\n",
      "\n",
      "Parameters\n",
      "----------\n",
      "key : str\n",
      "    The key or path to the key file.\n",
      "\n",
      "Returns\n",
      "-------\n",
      "str\n",
      "    The key.\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='llmcoder.utils.get_system_prompt', description='def get_system_prompt'>>,\n",
      "name.signature: get_system_prompt(name: str = \"2023-11-15_GPT-Builder.txt\") -> str,\n",
      "name.docstring: get_system_prompt(name: str=\"2023-11-15_GPT-Builder.txt\") -> str\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='llmcoder.utils.get_system_prompt_dir', description='def get_system_prompt_dir'>>,\n",
      "name.signature: get_system_prompt_dir(*args: str, create: bool = False) -> str,\n",
      "name.docstring: get_system_prompt_dir(*, create: bool=False) -> str\n",
      "\n",
      "Get the path to the system prompts directory.\n",
      "\n",
      "Parameters\n",
      "----------\n",
      "args : str\n",
      "    The path to the system prompts directory.\n",
      "create : bool\n",
      "    Whether to create the directory if it does not exist.\n",
      "\n",
      "Returns\n",
      "-------\n",
      "str\n",
      "    The path to the system prompts directory.\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='__main__.GPTReviewAnalyzer_v1', description='class GPTReviewAnalyzer_v1'>>,\n",
      "name.signature: Type[GPTReviewAnalyzer_v1],\n",
      "name.docstring: GPTReviewAnalyzer_v1(model: str=\"gpt-3.5-turbo\", system_prompt: str | None=None, min_score: int=6, temperature: float=0.2)\n",
      "\n",
      "Concise, professional Python code advisor for targeted feedback.\n",
      "\n",
      "Parameters\n",
      "----------\n",
      "model : str, optional\n",
      "    The model to use, by default \"gpt-3.5-turbo\"\n",
      "system_prompt : str, optional\n",
      "    The system prompt to use, by default `2023-12-02_GPTReviewAnalyzer_v4.txt`, created by GPTBuilder\n",
      "min_score : int, optional\n",
      "    The minimum score to pass the review, by default 6\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='__main__.GPTReviewAnalyzer_v1.__init__', description='def __init__'>>,\n",
      "name.signature: __init__(self, model: str=\"gpt-3.5-turbo\", system_prompt: Optional[str]=None, min_score: int=6, temperature: float=0.2),\n",
      "name.docstring: __init__(self, model: str=\"gpt-3.5-turbo\", system_prompt: str | None=None, min_score: int=6, temperature: float=0.2)\n",
      "\n",
      "Initialize the GPTReviewAnalyzer\n",
      "\n",
      "Parameters\n",
      "----------\n",
      "model : str, optional\n",
      "    The model to use, by default \"gpt-3.5-turbo\"\n",
      "system_prompt : str, optional\n",
      "    The system prompt to use, by default `2023-12-02_GPTReviewAnalyzer_v4.txt`, created by GPTBuilder\n",
      "min_score : int, optional\n",
      "    The minimum score to pass the review, by default 6\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='__main__.GPTReviewAnalyzer_v1.analyze', description='def analyze'>>,\n",
      "name.signature: analyze(self, input: str, completion: str, context: dict[str, dict[str, bool | str]] | None = None) -> dict,\n",
      "name.docstring: analyze(self, input: str, completion: str, context: dict[str, dict[str, bool | str]] | None=None) -> dict\n",
      "\n",
      "Analyze the input and completion\n",
      "\n",
      "Parameters\n",
      "----------\n",
      "input : str\n",
      "    The input to analyze\n",
      "completion : str\n",
      "    The completion to analyze\n",
      "\n",
      "Returns\n",
      "-------\n",
      "dict\n",
      "    The analysis of the input and completion\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='__main__.GPTReviewAnalyzer_v1._prompt_template', description='def _prompt_template'>>,\n",
      "name.signature: _prompt_template(input: str, completion: str) -> str,\n",
      "name.docstring: _prompt_template(input: str, completion: str) -> str\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='openai.OpenAI', description='class OpenAI'>>,\n",
      "name.signature: Type[OpenAI],\n",
      "name.docstring: OpenAI(*, api_key: str | None=None, organization: str | None=None, base_url: str | httpx.URL | None=None, timeout: Union[float, Timeout, None, NotGiven]=NOT_GIVEN, max_retries: int=DEFAULT_MAX_RETRIES, default_headers: Mapping[str, str] | None=None, default_query: Mapping[str, object] | None=None, http_client: httpx.Client | None=None, _strict_response_validation: bool=False)\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='llmcoder.analyze.Analyzer.Analyzer', description='class Analyzer'>>,\n",
      "name.signature: Type[Analyzer],\n",
      "name.docstring: Analyzer(verbose: bool=False)\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='llmcoder.utils.get_openai_key', description='def get_openai_key'>>,\n",
      "name.signature: get_openai_key(key: str = \"\") -> str,\n",
      "name.docstring: get_openai_key(key: str=\"\") -> str\n",
      "\n",
      "Get OpenAI API key. Try to interpret the key as a key first, then as a path to a file containing the key.\n",
      "Finally, fall back to the default key.txt file or the OPENAI_KEY environment variable.\n",
      "\n",
      "Parameters\n",
      "----------\n",
      "key : str\n",
      "    The key or path to the key file.\n",
      "\n",
      "Returns\n",
      "-------\n",
      "str\n",
      "    The key.\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='llmcoder.utils.get_system_prompt', description='def get_system_prompt'>>,\n",
      "name.signature: get_system_prompt(name: str = \"2023-11-15_GPT-Builder.txt\") -> str,\n",
      "name.docstring: get_system_prompt(name: str=\"2023-11-15_GPT-Builder.txt\") -> str\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='llmcoder.utils.get_system_prompt_dir', description='def get_system_prompt_dir'>>,\n",
      "name.signature: get_system_prompt_dir(*args: str, create: bool = False) -> str,\n",
      "name.docstring: get_system_prompt_dir(*, create: bool=False) -> str\n",
      "\n",
      "Get the path to the system prompts directory.\n",
      "\n",
      "Parameters\n",
      "----------\n",
      "args : str\n",
      "    The path to the system prompts directory.\n",
      "create : bool\n",
      "    Whether to create the directory if it does not exist.\n",
      "\n",
      "Returns\n",
      "-------\n",
      "str\n",
      "    The path to the system prompts directory.\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='__main__.GPTReviewAnalyzer_v1', description='class GPTReviewAnalyzer_v1'>>,\n",
      "name.signature: Type[GPTReviewAnalyzer_v1],\n",
      "name.docstring: GPTReviewAnalyzer_v1(model: str=\"gpt-3.5-turbo\", system_prompt: str | None=None, min_score: int=6, temperature: float=0.2)\n",
      "\n",
      "Concise, professional Python code advisor for targeted feedback.\n",
      "\n",
      "Parameters\n",
      "----------\n",
      "model : str, optional\n",
      "    The model to use, by default \"gpt-3.5-turbo\"\n",
      "system_prompt : str, optional\n",
      "    The system prompt to use, by default `2023-12-02_GPTReviewAnalyzer_v4.txt`, created by GPTBuilder\n",
      "min_score : int, optional\n",
      "    The minimum score to pass the review, by default 6\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='__main__.GPTReviewAnalyzer_v1.__init__', description='def __init__'>>,\n",
      "name.signature: __init__(self, model: str=\"gpt-3.5-turbo\", system_prompt: Optional[str]=None, min_score: int=6, temperature: float=0.2),\n",
      "name.docstring: __init__(self, model: str=\"gpt-3.5-turbo\", system_prompt: str | None=None, min_score: int=6, temperature: float=0.2)\n",
      "\n",
      "Initialize the GPTReviewAnalyzer\n",
      "\n",
      "Parameters\n",
      "----------\n",
      "model : str, optional\n",
      "    The model to use, by default \"gpt-3.5-turbo\"\n",
      "system_prompt : str, optional\n",
      "    The system prompt to use, by default `2023-12-02_GPTReviewAnalyzer_v4.txt`, created by GPTBuilder\n",
      "min_score : int, optional\n",
      "    The minimum score to pass the review, by default 6\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='__main__.GPTReviewAnalyzer_v1.analyze', description='def analyze'>>,\n",
      "name.signature: analyze(self, input: str, completion: str, context: dict[str, dict[str, bool | str]] | None = None) -> dict,\n",
      "name.docstring: analyze(self, input: str, completion: str, context: dict[str, dict[str, bool | str]] | None=None) -> dict\n",
      "\n",
      "Analyze the input and completion\n",
      "\n",
      "Parameters\n",
      "----------\n",
      "input : str\n",
      "    The input to analyze\n",
      "completion : str\n",
      "    The completion to analyze\n",
      "\n",
      "Returns\n",
      "-------\n",
      "dict\n",
      "    The analysis of the input and completion\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='__main__.GPTReviewAnalyzer_v1._prompt_template', description='def _prompt_template'>>,\n",
      "name.signature: _prompt_template(input: str, completion: str) -> str,\n",
      "name.docstring: _prompt_template(input: str, completion: str) -> str\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='openai.OpenAI', description='class OpenAI'>>,\n",
      "name.signature: Type[OpenAI],\n",
      "name.docstring: OpenAI(*, api_key: str | None=None, organization: str | None=None, base_url: str | httpx.URL | None=None, timeout: Union[float, Timeout, None, NotGiven]=NOT_GIVEN, max_retries: int=DEFAULT_MAX_RETRIES, default_headers: Mapping[str, str] | None=None, default_query: Mapping[str, object] | None=None, http_client: httpx.Client | None=None, _strict_response_validation: bool=False)\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='llmcoder.analyze.Analyzer.Analyzer', description='class Analyzer'>>,\n",
      "name.signature: Type[Analyzer],\n",
      "name.docstring: Analyzer(verbose: bool=False)\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='llmcoder.utils.get_openai_key', description='def get_openai_key'>>,\n",
      "name.signature: get_openai_key(key: str = \"\") -> str,\n",
      "name.docstring: get_openai_key(key: str=\"\") -> str\n",
      "\n",
      "Get OpenAI API key. Try to interpret the key as a key first, then as a path to a file containing the key.\n",
      "Finally, fall back to the default key.txt file or the OPENAI_KEY environment variable.\n",
      "\n",
      "Parameters\n",
      "----------\n",
      "key : str\n",
      "    The key or path to the key file.\n",
      "\n",
      "Returns\n",
      "-------\n",
      "str\n",
      "    The key.\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='llmcoder.utils.get_system_prompt', description='def get_system_prompt'>>,\n",
      "name.signature: get_system_prompt(name: str = \"2023-11-15_GPT-Builder.txt\") -> str,\n",
      "name.docstring: get_system_prompt(name: str=\"2023-11-15_GPT-Builder.txt\") -> str\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='llmcoder.utils.get_system_prompt_dir', description='def get_system_prompt_dir'>>,\n",
      "name.signature: get_system_prompt_dir(*args: str, create: bool = False) -> str,\n",
      "name.docstring: get_system_prompt_dir(*, create: bool=False) -> str\n",
      "\n",
      "Get the path to the system prompts directory.\n",
      "\n",
      "Parameters\n",
      "----------\n",
      "args : str\n",
      "    The path to the system prompts directory.\n",
      "create : bool\n",
      "    Whether to create the directory if it does not exist.\n",
      "\n",
      "Returns\n",
      "-------\n",
      "str\n",
      "    The path to the system prompts directory.\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='__main__.GPTReviewAnalyzer_v1', description='class GPTReviewAnalyzer_v1'>>,\n",
      "name.signature: Type[GPTReviewAnalyzer_v1],\n",
      "name.docstring: GPTReviewAnalyzer_v1(model: str=\"gpt-3.5-turbo\", system_prompt: str | None=None, min_score: int=6, temperature: float=0.2)\n",
      "\n",
      "Concise, professional Python code advisor for targeted feedback.\n",
      "\n",
      "Parameters\n",
      "----------\n",
      "model : str, optional\n",
      "    The model to use, by default \"gpt-3.5-turbo\"\n",
      "system_prompt : str, optional\n",
      "    The system prompt to use, by default `2023-12-02_GPTReviewAnalyzer_v4.txt`, created by GPTBuilder\n",
      "min_score : int, optional\n",
      "    The minimum score to pass the review, by default 6\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='__main__.GPTReviewAnalyzer_v1.__init__', description='def __init__'>>,\n",
      "name.signature: __init__(self, model: str=\"gpt-3.5-turbo\", system_prompt: Optional[str]=None, min_score: int=6, temperature: float=0.2),\n",
      "name.docstring: __init__(self, model: str=\"gpt-3.5-turbo\", system_prompt: str | None=None, min_score: int=6, temperature: float=0.2)\n",
      "\n",
      "Initialize the GPTReviewAnalyzer\n",
      "\n",
      "Parameters\n",
      "----------\n",
      "model : str, optional\n",
      "    The model to use, by default \"gpt-3.5-turbo\"\n",
      "system_prompt : str, optional\n",
      "    The system prompt to use, by default `2023-12-02_GPTReviewAnalyzer_v4.txt`, created by GPTBuilder\n",
      "min_score : int, optional\n",
      "    The minimum score to pass the review, by default 6\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='__main__.GPTReviewAnalyzer_v1.analyze', description='def analyze'>>,\n",
      "name.signature: analyze(self, input: str, completion: str, context: dict[str, dict[str, bool | str]] | None = None) -> dict,\n",
      "name.docstring: analyze(self, input: str, completion: str, context: dict[str, dict[str, bool | str]] | None=None) -> dict\n",
      "\n",
      "Analyze the input and completion\n",
      "\n",
      "Parameters\n",
      "----------\n",
      "input : str\n",
      "    The input to analyze\n",
      "completion : str\n",
      "    The completion to analyze\n",
      "\n",
      "Returns\n",
      "-------\n",
      "dict\n",
      "    The analysis of the input and completion\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='__main__.GPTReviewAnalyzer_v1._prompt_template', description='def _prompt_template'>>,\n",
      "name.signature: _prompt_template(input: str, completion: str) -> str,\n",
      "name.docstring: _prompt_template(input: str, completion: str) -> str\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='openai.OpenAI', description='class OpenAI'>>,\n",
      "name.signature: Type[OpenAI],\n",
      "name.docstring: OpenAI(*, api_key: str | None=None, organization: str | None=None, base_url: str | httpx.URL | None=None, timeout: Union[float, Timeout, None, NotGiven]=NOT_GIVEN, max_retries: int=DEFAULT_MAX_RETRIES, default_headers: Mapping[str, str] | None=None, default_query: Mapping[str, object] | None=None, http_client: httpx.Client | None=None, _strict_response_validation: bool=False)\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='llmcoder.analyze.Analyzer.Analyzer', description='class Analyzer'>>,\n",
      "name.signature: Type[Analyzer],\n",
      "name.docstring: Analyzer(verbose: bool=False)\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='llmcoder.utils.get_openai_key', description='def get_openai_key'>>,\n",
      "name.signature: get_openai_key(key: str = \"\") -> str,\n",
      "name.docstring: get_openai_key(key: str=\"\") -> str\n",
      "\n",
      "Get OpenAI API key. Try to interpret the key as a key first, then as a path to a file containing the key.\n",
      "Finally, fall back to the default key.txt file or the OPENAI_KEY environment variable.\n",
      "\n",
      "Parameters\n",
      "----------\n",
      "key : str\n",
      "    The key or path to the key file.\n",
      "\n",
      "Returns\n",
      "-------\n",
      "str\n",
      "    The key.\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='llmcoder.utils.get_system_prompt', description='def get_system_prompt'>>,\n",
      "name.signature: get_system_prompt(name: str = \"2023-11-15_GPT-Builder.txt\") -> str,\n",
      "name.docstring: get_system_prompt(name: str=\"2023-11-15_GPT-Builder.txt\") -> str\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='llmcoder.utils.get_system_prompt_dir', description='def get_system_prompt_dir'>>,\n",
      "name.signature: get_system_prompt_dir(*args: str, create: bool = False) -> str,\n",
      "name.docstring: get_system_prompt_dir(*, create: bool=False) -> str\n",
      "\n",
      "Get the path to the system prompts directory.\n",
      "\n",
      "Parameters\n",
      "----------\n",
      "args : str\n",
      "    The path to the system prompts directory.\n",
      "create : bool\n",
      "    Whether to create the directory if it does not exist.\n",
      "\n",
      "Returns\n",
      "-------\n",
      "str\n",
      "    The path to the system prompts directory.\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='__main__.GPTReviewAnalyzer_v1', description='class GPTReviewAnalyzer_v1'>>,\n",
      "name.signature: Type[GPTReviewAnalyzer_v1],\n",
      "name.docstring: GPTReviewAnalyzer_v1(model: str=\"gpt-3.5-turbo\", system_prompt: str | None=None, min_score: int=6, temperature: float=0.2)\n",
      "\n",
      "Concise, professional Python code advisor for targeted feedback.\n",
      "\n",
      "Parameters\n",
      "----------\n",
      "model : str, optional\n",
      "    The model to use, by default \"gpt-3.5-turbo\"\n",
      "system_prompt : str, optional\n",
      "    The system prompt to use, by default `2023-12-02_GPTReviewAnalyzer_v4.txt`, created by GPTBuilder\n",
      "min_score : int, optional\n",
      "    The minimum score to pass the review, by default 6\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='__main__.GPTReviewAnalyzer_v1.__init__', description='def __init__'>>,\n",
      "name.signature: __init__(self, model: str=\"gpt-3.5-turbo\", system_prompt: Optional[str]=None, min_score: int=6, temperature: float=0.2),\n",
      "name.docstring: __init__(self, model: str=\"gpt-3.5-turbo\", system_prompt: str | None=None, min_score: int=6, temperature: float=0.2)\n",
      "\n",
      "Initialize the GPTReviewAnalyzer\n",
      "\n",
      "Parameters\n",
      "----------\n",
      "model : str, optional\n",
      "    The model to use, by default \"gpt-3.5-turbo\"\n",
      "system_prompt : str, optional\n",
      "    The system prompt to use, by default `2023-12-02_GPTReviewAnalyzer_v4.txt`, created by GPTBuilder\n",
      "min_score : int, optional\n",
      "    The minimum score to pass the review, by default 6\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='__main__.GPTReviewAnalyzer_v1.analyze', description='def analyze'>>,\n",
      "name.signature: analyze(self, input: str, completion: str, context: dict[str, dict[str, bool | str]] | None = None) -> dict,\n",
      "name.docstring: analyze(self, input: str, completion: str, context: dict[str, dict[str, bool | str]] | None=None) -> dict\n",
      "\n",
      "Analyze the input and completion\n",
      "\n",
      "Parameters\n",
      "----------\n",
      "input : str\n",
      "    The input to analyze\n",
      "completion : str\n",
      "    The completion to analyze\n",
      "\n",
      "Returns\n",
      "-------\n",
      "dict\n",
      "    The analysis of the input and completion\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='__main__.GPTReviewAnalyzer_v1._prompt_template', description='def _prompt_template'>>,\n",
      "name.signature: _prompt_template(input: str, completion: str) -> str,\n",
      "name.docstring: _prompt_template(input: str, completion: str) -> str\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='openai.OpenAI', description='class OpenAI'>>,\n",
      "name.signature: Type[OpenAI],\n",
      "name.docstring: OpenAI(*, api_key: str | None=None, organization: str | None=None, base_url: str | httpx.URL | None=None, timeout: Union[float, Timeout, None, NotGiven]=NOT_GIVEN, max_retries: int=DEFAULT_MAX_RETRIES, default_headers: Mapping[str, str] | None=None, default_query: Mapping[str, object] | None=None, http_client: httpx.Client | None=None, _strict_response_validation: bool=False)\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='llmcoder.analyze.Analyzer.Analyzer', description='class Analyzer'>>,\n",
      "name.signature: Type[Analyzer],\n",
      "name.docstring: Analyzer(verbose: bool=False)\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='llmcoder.utils.get_openai_key', description='def get_openai_key'>>,\n",
      "name.signature: get_openai_key(key: str = \"\") -> str,\n",
      "name.docstring: get_openai_key(key: str=\"\") -> str\n",
      "\n",
      "Get OpenAI API key. Try to interpret the key as a key first, then as a path to a file containing the key.\n",
      "Finally, fall back to the default key.txt file or the OPENAI_KEY environment variable.\n",
      "\n",
      "Parameters\n",
      "----------\n",
      "key : str\n",
      "    The key or path to the key file.\n",
      "\n",
      "Returns\n",
      "-------\n",
      "str\n",
      "    The key.\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='llmcoder.utils.get_system_prompt', description='def get_system_prompt'>>,\n",
      "name.signature: get_system_prompt(name: str = \"2023-11-15_GPT-Builder.txt\") -> str,\n",
      "name.docstring: get_system_prompt(name: str=\"2023-11-15_GPT-Builder.txt\") -> str\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='llmcoder.utils.get_system_prompt_dir', description='def get_system_prompt_dir'>>,\n",
      "name.signature: get_system_prompt_dir(*args: str, create: bool = False) -> str,\n",
      "name.docstring: get_system_prompt_dir(*, create: bool=False) -> str\n",
      "\n",
      "Get the path to the system prompts directory.\n",
      "\n",
      "Parameters\n",
      "----------\n",
      "args : str\n",
      "    The path to the system prompts directory.\n",
      "create : bool\n",
      "    Whether to create the directory if it does not exist.\n",
      "\n",
      "Returns\n",
      "-------\n",
      "str\n",
      "    The path to the system prompts directory.\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='__main__.GPTReviewAnalyzer_v1', description='class GPTReviewAnalyzer_v1'>>,\n",
      "name.signature: Type[GPTReviewAnalyzer_v1],\n",
      "name.docstring: GPTReviewAnalyzer_v1(model: str=\"gpt-3.5-turbo\", system_prompt: str | None=None, min_score: int=6, temperature: float=0.2)\n",
      "\n",
      "Concise, professional Python code advisor for targeted feedback.\n",
      "\n",
      "Parameters\n",
      "----------\n",
      "model : str, optional\n",
      "    The model to use, by default \"gpt-3.5-turbo\"\n",
      "system_prompt : str, optional\n",
      "    The system prompt to use, by default `2023-12-02_GPTReviewAnalyzer_v4.txt`, created by GPTBuilder\n",
      "min_score : int, optional\n",
      "    The minimum score to pass the review, by default 6\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='__main__.GPTReviewAnalyzer_v1.__init__', description='def __init__'>>,\n",
      "name.signature: __init__(self, model: str=\"gpt-3.5-turbo\", system_prompt: Optional[str]=None, min_score: int=6, temperature: float=0.2),\n",
      "name.docstring: __init__(self, model: str=\"gpt-3.5-turbo\", system_prompt: str | None=None, min_score: int=6, temperature: float=0.2)\n",
      "\n",
      "Initialize the GPTReviewAnalyzer\n",
      "\n",
      "Parameters\n",
      "----------\n",
      "model : str, optional\n",
      "    The model to use, by default \"gpt-3.5-turbo\"\n",
      "system_prompt : str, optional\n",
      "    The system prompt to use, by default `2023-12-02_GPTReviewAnalyzer_v4.txt`, created by GPTBuilder\n",
      "min_score : int, optional\n",
      "    The minimum score to pass the review, by default 6\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='__main__.GPTReviewAnalyzer_v1.analyze', description='def analyze'>>,\n",
      "name.signature: analyze(self, input: str, completion: str, context: dict[str, dict[str, bool | str]] | None = None) -> dict,\n",
      "name.docstring: analyze(self, input: str, completion: str, context: dict[str, dict[str, bool | str]] | None=None) -> dict\n",
      "\n",
      "Analyze the input and completion\n",
      "\n",
      "Parameters\n",
      "----------\n",
      "input : str\n",
      "    The input to analyze\n",
      "completion : str\n",
      "    The completion to analyze\n",
      "\n",
      "Returns\n",
      "-------\n",
      "dict\n",
      "    The analysis of the input and completion\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='__main__.GPTReviewAnalyzer_v1._prompt_template', description='def _prompt_template'>>,\n",
      "name.signature: _prompt_template(input: str, completion: str) -> str,\n",
      "name.docstring: _prompt_template(input: str, completion: str) -> str\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='openai.OpenAI', description='class OpenAI'>>,\n",
      "name.signature: Type[OpenAI],\n",
      "name.docstring: OpenAI(*, api_key: str | None=None, organization: str | None=None, base_url: str | httpx.URL | None=None, timeout: Union[float, Timeout, None, NotGiven]=NOT_GIVEN, max_retries: int=DEFAULT_MAX_RETRIES, default_headers: Mapping[str, str] | None=None, default_query: Mapping[str, object] | None=None, http_client: httpx.Client | None=None, _strict_response_validation: bool=False)\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='llmcoder.analyze.Analyzer.Analyzer', description='class Analyzer'>>,\n",
      "name.signature: Type[Analyzer],\n",
      "name.docstring: Analyzer(verbose: bool=False)\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='llmcoder.utils.get_openai_key', description='def get_openai_key'>>,\n",
      "name.signature: get_openai_key(key: str = \"\") -> str,\n",
      "name.docstring: get_openai_key(key: str=\"\") -> str\n",
      "\n",
      "Get OpenAI API key. Try to interpret the key as a key first, then as a path to a file containing the key.\n",
      "Finally, fall back to the default key.txt file or the OPENAI_KEY environment variable.\n",
      "\n",
      "Parameters\n",
      "----------\n",
      "key : str\n",
      "    The key or path to the key file.\n",
      "\n",
      "Returns\n",
      "-------\n",
      "str\n",
      "    The key.\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='llmcoder.utils.get_system_prompt', description='def get_system_prompt'>>,\n",
      "name.signature: get_system_prompt(name: str = \"2023-11-15_GPT-Builder.txt\") -> str,\n",
      "name.docstring: get_system_prompt(name: str=\"2023-11-15_GPT-Builder.txt\") -> str\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='llmcoder.utils.get_system_prompt_dir', description='def get_system_prompt_dir'>>,\n",
      "name.signature: get_system_prompt_dir(*args: str, create: bool = False) -> str,\n",
      "name.docstring: get_system_prompt_dir(*, create: bool=False) -> str\n",
      "\n",
      "Get the path to the system prompts directory.\n",
      "\n",
      "Parameters\n",
      "----------\n",
      "args : str\n",
      "    The path to the system prompts directory.\n",
      "create : bool\n",
      "    Whether to create the directory if it does not exist.\n",
      "\n",
      "Returns\n",
      "-------\n",
      "str\n",
      "    The path to the system prompts directory.\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='__main__.GPTReviewAnalyzer_v1', description='class GPTReviewAnalyzer_v1'>>,\n",
      "name.signature: Type[GPTReviewAnalyzer_v1],\n",
      "name.docstring: GPTReviewAnalyzer_v1(model: str=\"gpt-3.5-turbo\", system_prompt: str | None=None, min_score: int=6, temperature: float=0.2)\n",
      "\n",
      "Concise, professional Python code advisor for targeted feedback.\n",
      "\n",
      "Parameters\n",
      "----------\n",
      "model : str, optional\n",
      "    The model to use, by default \"gpt-3.5-turbo\"\n",
      "system_prompt : str, optional\n",
      "    The system prompt to use, by default `2023-12-02_GPTReviewAnalyzer_v4.txt`, created by GPTBuilder\n",
      "min_score : int, optional\n",
      "    The minimum score to pass the review, by default 6\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='__main__.GPTReviewAnalyzer_v1.__init__', description='def __init__'>>,\n",
      "name.signature: __init__(self, model: str=\"gpt-3.5-turbo\", system_prompt: Optional[str]=None, min_score: int=6, temperature: float=0.2),\n",
      "name.docstring: __init__(self, model: str=\"gpt-3.5-turbo\", system_prompt: str | None=None, min_score: int=6, temperature: float=0.2)\n",
      "\n",
      "Initialize the GPTReviewAnalyzer\n",
      "\n",
      "Parameters\n",
      "----------\n",
      "model : str, optional\n",
      "    The model to use, by default \"gpt-3.5-turbo\"\n",
      "system_prompt : str, optional\n",
      "    The system prompt to use, by default `2023-12-02_GPTReviewAnalyzer_v4.txt`, created by GPTBuilder\n",
      "min_score : int, optional\n",
      "    The minimum score to pass the review, by default 6\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='__main__.GPTReviewAnalyzer_v1.analyze', description='def analyze'>>,\n",
      "name.signature: analyze(self, input: str, completion: str, context: dict[str, dict[str, bool | str]] | None = None) -> dict,\n",
      "name.docstring: analyze(self, input: str, completion: str, context: dict[str, dict[str, bool | str]] | None=None) -> dict\n",
      "\n",
      "Analyze the input and completion\n",
      "\n",
      "Parameters\n",
      "----------\n",
      "input : str\n",
      "    The input to analyze\n",
      "completion : str\n",
      "    The completion to analyze\n",
      "\n",
      "Returns\n",
      "-------\n",
      "dict\n",
      "    The analysis of the input and completion\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='__main__.GPTReviewAnalyzer_v1._prompt_template', description='def _prompt_template'>>,\n",
      "name.signature: _prompt_template(input: str, completion: str) -> str,\n",
      "name.docstring: _prompt_template(input: str, completion: str) -> str\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='openai.OpenAI', description='class OpenAI'>>,\n",
      "name.signature: Type[OpenAI],\n",
      "name.docstring: OpenAI(*, api_key: str | None=None, organization: str | None=None, base_url: str | httpx.URL | None=None, timeout: Union[float, Timeout, None, NotGiven]=NOT_GIVEN, max_retries: int=DEFAULT_MAX_RETRIES, default_headers: Mapping[str, str] | None=None, default_query: Mapping[str, object] | None=None, http_client: httpx.Client | None=None, _strict_response_validation: bool=False)\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='llmcoder.analyze.Analyzer.Analyzer', description='class Analyzer'>>,\n",
      "name.signature: Type[Analyzer],\n",
      "name.docstring: Analyzer(verbose: bool=False)\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='llmcoder.utils.get_openai_key', description='def get_openai_key'>>,\n",
      "name.signature: get_openai_key(key: str = \"\") -> str,\n",
      "name.docstring: get_openai_key(key: str=\"\") -> str\n",
      "\n",
      "Get OpenAI API key. Try to interpret the key as a key first, then as a path to a file containing the key.\n",
      "Finally, fall back to the default key.txt file or the OPENAI_KEY environment variable.\n",
      "\n",
      "Parameters\n",
      "----------\n",
      "key : str\n",
      "    The key or path to the key file.\n",
      "\n",
      "Returns\n",
      "-------\n",
      "str\n",
      "    The key.\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='llmcoder.utils.get_system_prompt', description='def get_system_prompt'>>,\n",
      "name.signature: get_system_prompt(name: str = \"2023-11-15_GPT-Builder.txt\") -> str,\n",
      "name.docstring: get_system_prompt(name: str=\"2023-11-15_GPT-Builder.txt\") -> str\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='llmcoder.utils.get_system_prompt_dir', description='def get_system_prompt_dir'>>,\n",
      "name.signature: get_system_prompt_dir(*args: str, create: bool = False) -> str,\n",
      "name.docstring: get_system_prompt_dir(*, create: bool=False) -> str\n",
      "\n",
      "Get the path to the system prompts directory.\n",
      "\n",
      "Parameters\n",
      "----------\n",
      "args : str\n",
      "    The path to the system prompts directory.\n",
      "create : bool\n",
      "    Whether to create the directory if it does not exist.\n",
      "\n",
      "Returns\n",
      "-------\n",
      "str\n",
      "    The path to the system prompts directory.\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='__main__.GPTReviewAnalyzer_v1', description='class GPTReviewAnalyzer_v1'>>,\n",
      "name.signature: Type[GPTReviewAnalyzer_v1],\n",
      "name.docstring: GPTReviewAnalyzer_v1(model: str=\"gpt-3.5-turbo\", system_prompt: str | None=None, min_score: int=6, temperature: float=0.2)\n",
      "\n",
      "Concise, professional Python code advisor for targeted feedback.\n",
      "\n",
      "Parameters\n",
      "----------\n",
      "model : str, optional\n",
      "    The model to use, by default \"gpt-3.5-turbo\"\n",
      "system_prompt : str, optional\n",
      "    The system prompt to use, by default `2023-12-02_GPTReviewAnalyzer_v4.txt`, created by GPTBuilder\n",
      "min_score : int, optional\n",
      "    The minimum score to pass the review, by default 6\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='__main__.GPTReviewAnalyzer_v1.__init__', description='def __init__'>>,\n",
      "name.signature: __init__(self, model: str=\"gpt-3.5-turbo\", system_prompt: Optional[str]=None, min_score: int=6, temperature: float=0.2),\n",
      "name.docstring: __init__(self, model: str=\"gpt-3.5-turbo\", system_prompt: str | None=None, min_score: int=6, temperature: float=0.2)\n",
      "\n",
      "Initialize the GPTReviewAnalyzer\n",
      "\n",
      "Parameters\n",
      "----------\n",
      "model : str, optional\n",
      "    The model to use, by default \"gpt-3.5-turbo\"\n",
      "system_prompt : str, optional\n",
      "    The system prompt to use, by default `2023-12-02_GPTReviewAnalyzer_v4.txt`, created by GPTBuilder\n",
      "min_score : int, optional\n",
      "    The minimum score to pass the review, by default 6\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='__main__.GPTReviewAnalyzer_v1.analyze', description='def analyze'>>,\n",
      "name.signature: analyze(self, input: str, completion: str, context: dict[str, dict[str, bool | str]] | None = None) -> dict,\n",
      "name.docstring: analyze(self, input: str, completion: str, context: dict[str, dict[str, bool | str]] | None=None) -> dict\n",
      "\n",
      "Analyze the input and completion\n",
      "\n",
      "Parameters\n",
      "----------\n",
      "input : str\n",
      "    The input to analyze\n",
      "completion : str\n",
      "    The completion to analyze\n",
      "\n",
      "Returns\n",
      "-------\n",
      "dict\n",
      "    The analysis of the input and completion\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='__main__.GPTReviewAnalyzer_v1._prompt_template', description='def _prompt_template'>>,\n",
      "name.signature: _prompt_template(input: str, completion: str) -> str,\n",
      "name.docstring: _prompt_template(input: str, completion: str) -> str\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='openai.OpenAI', description='class OpenAI'>>,\n",
      "name.signature: Type[OpenAI],\n",
      "name.docstring: OpenAI(*, api_key: str | None=None, organization: str | None=None, base_url: str | httpx.URL | None=None, timeout: Union[float, Timeout, None, NotGiven]=NOT_GIVEN, max_retries: int=DEFAULT_MAX_RETRIES, default_headers: Mapping[str, str] | None=None, default_query: Mapping[str, object] | None=None, http_client: httpx.Client | None=None, _strict_response_validation: bool=False)\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='llmcoder.analyze.Analyzer.Analyzer', description='class Analyzer'>>,\n",
      "name.signature: Type[Analyzer],\n",
      "name.docstring: Analyzer(verbose: bool=False)\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='llmcoder.utils.get_openai_key', description='def get_openai_key'>>,\n",
      "name.signature: get_openai_key(key: str = \"\") -> str,\n",
      "name.docstring: get_openai_key(key: str=\"\") -> str\n",
      "\n",
      "Get OpenAI API key. Try to interpret the key as a key first, then as a path to a file containing the key.\n",
      "Finally, fall back to the default key.txt file or the OPENAI_KEY environment variable.\n",
      "\n",
      "Parameters\n",
      "----------\n",
      "key : str\n",
      "    The key or path to the key file.\n",
      "\n",
      "Returns\n",
      "-------\n",
      "str\n",
      "    The key.\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='llmcoder.utils.get_system_prompt', description='def get_system_prompt'>>,\n",
      "name.signature: get_system_prompt(name: str = \"2023-11-15_GPT-Builder.txt\") -> str,\n",
      "name.docstring: get_system_prompt(name: str=\"2023-11-15_GPT-Builder.txt\") -> str\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='llmcoder.utils.get_system_prompt_dir', description='def get_system_prompt_dir'>>,\n",
      "name.signature: get_system_prompt_dir(*args: str, create: bool = False) -> str,\n",
      "name.docstring: get_system_prompt_dir(*, create: bool=False) -> str\n",
      "\n",
      "Get the path to the system prompts directory.\n",
      "\n",
      "Parameters\n",
      "----------\n",
      "args : str\n",
      "    The path to the system prompts directory.\n",
      "create : bool\n",
      "    Whether to create the directory if it does not exist.\n",
      "\n",
      "Returns\n",
      "-------\n",
      "str\n",
      "    The path to the system prompts directory.\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='__main__.GPTReviewAnalyzer_v1', description='class GPTReviewAnalyzer_v1'>>,\n",
      "name.signature: Type[GPTReviewAnalyzer_v1],\n",
      "name.docstring: GPTReviewAnalyzer_v1(model: str=\"gpt-3.5-turbo\", system_prompt: str | None=None, min_score: int=6, temperature: float=0.2)\n",
      "\n",
      "Concise, professional Python code advisor for targeted feedback.\n",
      "\n",
      "Parameters\n",
      "----------\n",
      "model : str, optional\n",
      "    The model to use, by default \"gpt-3.5-turbo\"\n",
      "system_prompt : str, optional\n",
      "    The system prompt to use, by default `2023-12-02_GPTReviewAnalyzer_v4.txt`, created by GPTBuilder\n",
      "min_score : int, optional\n",
      "    The minimum score to pass the review, by default 6\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='__main__.GPTReviewAnalyzer_v1.__init__', description='def __init__'>>,\n",
      "name.signature: __init__(self, model: str=\"gpt-3.5-turbo\", system_prompt: Optional[str]=None, min_score: int=6, temperature: float=0.2),\n",
      "name.docstring: __init__(self, model: str=\"gpt-3.5-turbo\", system_prompt: str | None=None, min_score: int=6, temperature: float=0.2)\n",
      "\n",
      "Initialize the GPTReviewAnalyzer\n",
      "\n",
      "Parameters\n",
      "----------\n",
      "model : str, optional\n",
      "    The model to use, by default \"gpt-3.5-turbo\"\n",
      "system_prompt : str, optional\n",
      "    The system prompt to use, by default `2023-12-02_GPTReviewAnalyzer_v4.txt`, created by GPTBuilder\n",
      "min_score : int, optional\n",
      "    The minimum score to pass the review, by default 6\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='__main__.GPTReviewAnalyzer_v1.analyze', description='def analyze'>>,\n",
      "name.signature: analyze(self, input: str, completion: str, context: dict[str, dict[str, bool | str]] | None = None) -> dict,\n",
      "name.docstring: analyze(self, input: str, completion: str, context: dict[str, dict[str, bool | str]] | None=None) -> dict\n",
      "\n",
      "Analyze the input and completion\n",
      "\n",
      "Parameters\n",
      "----------\n",
      "input : str\n",
      "    The input to analyze\n",
      "completion : str\n",
      "    The completion to analyze\n",
      "\n",
      "Returns\n",
      "-------\n",
      "dict\n",
      "    The analysis of the input and completion\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='__main__.GPTReviewAnalyzer_v1._prompt_template', description='def _prompt_template'>>,\n",
      "name.signature: _prompt_template(input: str, completion: str) -> str,\n",
      "name.docstring: _prompt_template(input: str, completion: str) -> str\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='openai.OpenAI', description='class OpenAI'>>,\n",
      "name.signature: Type[OpenAI],\n",
      "name.docstring: OpenAI(*, api_key: str | None=None, organization: str | None=None, base_url: str | httpx.URL | None=None, timeout: Union[float, Timeout, None, NotGiven]=NOT_GIVEN, max_retries: int=DEFAULT_MAX_RETRIES, default_headers: Mapping[str, str] | None=None, default_query: Mapping[str, object] | None=None, http_client: httpx.Client | None=None, _strict_response_validation: bool=False)\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='llmcoder.analyze.Analyzer.Analyzer', description='class Analyzer'>>,\n",
      "name.signature: Type[Analyzer],\n",
      "name.docstring: Analyzer(verbose: bool=False)\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='llmcoder.utils.get_openai_key', description='def get_openai_key'>>,\n",
      "name.signature: get_openai_key(key: str = \"\") -> str,\n",
      "name.docstring: get_openai_key(key: str=\"\") -> str\n",
      "\n",
      "Get OpenAI API key. Try to interpret the key as a key first, then as a path to a file containing the key.\n",
      "Finally, fall back to the default key.txt file or the OPENAI_KEY environment variable.\n",
      "\n",
      "Parameters\n",
      "----------\n",
      "key : str\n",
      "    The key or path to the key file.\n",
      "\n",
      "Returns\n",
      "-------\n",
      "str\n",
      "    The key.\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='llmcoder.utils.get_system_prompt', description='def get_system_prompt'>>,\n",
      "name.signature: get_system_prompt(name: str = \"2023-11-15_GPT-Builder.txt\") -> str,\n",
      "name.docstring: get_system_prompt(name: str=\"2023-11-15_GPT-Builder.txt\") -> str\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='llmcoder.utils.get_system_prompt_dir', description='def get_system_prompt_dir'>>,\n",
      "name.signature: get_system_prompt_dir(*args: str, create: bool = False) -> str,\n",
      "name.docstring: get_system_prompt_dir(*, create: bool=False) -> str\n",
      "\n",
      "Get the path to the system prompts directory.\n",
      "\n",
      "Parameters\n",
      "----------\n",
      "args : str\n",
      "    The path to the system prompts directory.\n",
      "create : bool\n",
      "    Whether to create the directory if it does not exist.\n",
      "\n",
      "Returns\n",
      "-------\n",
      "str\n",
      "    The path to the system prompts directory.\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='__main__.GPTReviewAnalyzer_v1', description='class GPTReviewAnalyzer_v1'>>,\n",
      "name.signature: Type[GPTReviewAnalyzer_v1],\n",
      "name.docstring: GPTReviewAnalyzer_v1(model: str=\"gpt-3.5-turbo\", system_prompt: str | None=None, min_score: int=6, temperature: float=0.2)\n",
      "\n",
      "Concise, professional Python code advisor for targeted feedback.\n",
      "\n",
      "Parameters\n",
      "----------\n",
      "model : str, optional\n",
      "    The model to use, by default \"gpt-3.5-turbo\"\n",
      "system_prompt : str, optional\n",
      "    The system prompt to use, by default `2023-12-02_GPTReviewAnalyzer_v4.txt`, created by GPTBuilder\n",
      "min_score : int, optional\n",
      "    The minimum score to pass the review, by default 6\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='__main__.GPTReviewAnalyzer_v1.__init__', description='def __init__'>>,\n",
      "name.signature: __init__(self, model: str=\"gpt-3.5-turbo\", system_prompt: Optional[str]=None, min_score: int=6, temperature: float=0.2),\n",
      "name.docstring: __init__(self, model: str=\"gpt-3.5-turbo\", system_prompt: str | None=None, min_score: int=6, temperature: float=0.2)\n",
      "\n",
      "Initialize the GPTReviewAnalyzer\n",
      "\n",
      "Parameters\n",
      "----------\n",
      "model : str, optional\n",
      "    The model to use, by default \"gpt-3.5-turbo\"\n",
      "system_prompt : str, optional\n",
      "    The system prompt to use, by default `2023-12-02_GPTReviewAnalyzer_v4.txt`, created by GPTBuilder\n",
      "min_score : int, optional\n",
      "    The minimum score to pass the review, by default 6\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='__main__.GPTReviewAnalyzer_v1.analyze', description='def analyze'>>,\n",
      "name.signature: analyze(self, input: str, completion: str, context: dict[str, dict[str, bool | str]] | None = None) -> dict,\n",
      "name.docstring: analyze(self, input: str, completion: str, context: dict[str, dict[str, bool | str]] | None=None) -> dict\n",
      "\n",
      "Analyze the input and completion\n",
      "\n",
      "Parameters\n",
      "----------\n",
      "input : str\n",
      "    The input to analyze\n",
      "completion : str\n",
      "    The completion to analyze\n",
      "\n",
      "Returns\n",
      "-------\n",
      "dict\n",
      "    The analysis of the input and completion\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='__main__.GPTReviewAnalyzer_v1._prompt_template', description='def _prompt_template'>>,\n",
      "name.signature: _prompt_template(input: str, completion: str) -> str,\n",
      "name.docstring: _prompt_template(input: str, completion: str) -> str\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='openai.OpenAI', description='class OpenAI'>>,\n",
      "name.signature: Type[OpenAI],\n",
      "name.docstring: OpenAI(*, api_key: str | None=None, organization: str | None=None, base_url: str | httpx.URL | None=None, timeout: Union[float, Timeout, None, NotGiven]=NOT_GIVEN, max_retries: int=DEFAULT_MAX_RETRIES, default_headers: Mapping[str, str] | None=None, default_query: Mapping[str, object] | None=None, http_client: httpx.Client | None=None, _strict_response_validation: bool=False)\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='llmcoder.analyze.Analyzer.Analyzer', description='class Analyzer'>>,\n",
      "name.signature: Type[Analyzer],\n",
      "name.docstring: Analyzer(verbose: bool=False)\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='llmcoder.utils.get_openai_key', description='def get_openai_key'>>,\n",
      "name.signature: get_openai_key(key: str = \"\") -> str,\n",
      "name.docstring: get_openai_key(key: str=\"\") -> str\n",
      "\n",
      "Get OpenAI API key. Try to interpret the key as a key first, then as a path to a file containing the key.\n",
      "Finally, fall back to the default key.txt file or the OPENAI_KEY environment variable.\n",
      "\n",
      "Parameters\n",
      "----------\n",
      "key : str\n",
      "    The key or path to the key file.\n",
      "\n",
      "Returns\n",
      "-------\n",
      "str\n",
      "    The key.\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='llmcoder.utils.get_system_prompt', description='def get_system_prompt'>>,\n",
      "name.signature: get_system_prompt(name: str = \"2023-11-15_GPT-Builder.txt\") -> str,\n",
      "name.docstring: get_system_prompt(name: str=\"2023-11-15_GPT-Builder.txt\") -> str\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='llmcoder.utils.get_system_prompt_dir', description='def get_system_prompt_dir'>>,\n",
      "name.signature: get_system_prompt_dir(*args: str, create: bool = False) -> str,\n",
      "name.docstring: get_system_prompt_dir(*, create: bool=False) -> str\n",
      "\n",
      "Get the path to the system prompts directory.\n",
      "\n",
      "Parameters\n",
      "----------\n",
      "args : str\n",
      "    The path to the system prompts directory.\n",
      "create : bool\n",
      "    Whether to create the directory if it does not exist.\n",
      "\n",
      "Returns\n",
      "-------\n",
      "str\n",
      "    The path to the system prompts directory.\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='__main__.GPTReviewAnalyzer_v1', description='class GPTReviewAnalyzer_v1'>>,\n",
      "name.signature: Type[GPTReviewAnalyzer_v1],\n",
      "name.docstring: GPTReviewAnalyzer_v1(model: str=\"gpt-3.5-turbo\", system_prompt: str | None=None, min_score: int=6, temperature: float=0.2)\n",
      "\n",
      "Concise, professional Python code advisor for targeted feedback.\n",
      "\n",
      "Parameters\n",
      "----------\n",
      "model : str, optional\n",
      "    The model to use, by default \"gpt-3.5-turbo\"\n",
      "system_prompt : str, optional\n",
      "    The system prompt to use, by default `2023-12-02_GPTReviewAnalyzer_v4.txt`, created by GPTBuilder\n",
      "min_score : int, optional\n",
      "    The minimum score to pass the review, by default 6\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='__main__.GPTReviewAnalyzer_v1.__init__', description='def __init__'>>,\n",
      "name.signature: __init__(self, model: str=\"gpt-3.5-turbo\", system_prompt: Optional[str]=None, min_score: int=6, temperature: float=0.2),\n",
      "name.docstring: __init__(self, model: str=\"gpt-3.5-turbo\", system_prompt: str | None=None, min_score: int=6, temperature: float=0.2)\n",
      "\n",
      "Initialize the GPTReviewAnalyzer\n",
      "\n",
      "Parameters\n",
      "----------\n",
      "model : str, optional\n",
      "    The model to use, by default \"gpt-3.5-turbo\"\n",
      "system_prompt : str, optional\n",
      "    The system prompt to use, by default `2023-12-02_GPTReviewAnalyzer_v4.txt`, created by GPTBuilder\n",
      "min_score : int, optional\n",
      "    The minimum score to pass the review, by default 6\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='__main__.GPTReviewAnalyzer_v1.analyze', description='def analyze'>>,\n",
      "name.signature: analyze(self, input: str, completion: str, context: dict[str, dict[str, bool | str]] | None = None) -> dict,\n",
      "name.docstring: analyze(self, input: str, completion: str, context: dict[str, dict[str, bool | str]] | None=None) -> dict\n",
      "\n",
      "Analyze the input and completion\n",
      "\n",
      "Parameters\n",
      "----------\n",
      "input : str\n",
      "    The input to analyze\n",
      "completion : str\n",
      "    The completion to analyze\n",
      "\n",
      "Returns\n",
      "-------\n",
      "dict\n",
      "    The analysis of the input and completion\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='__main__.GPTReviewAnalyzer_v1._prompt_template', description='def _prompt_template'>>,\n",
      "name.signature: _prompt_template(input: str, completion: str) -> str,\n",
      "name.docstring: _prompt_template(input: str, completion: str) -> str\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='openai.OpenAI', description='class OpenAI'>>,\n",
      "name.signature: Type[OpenAI],\n",
      "name.docstring: OpenAI(*, api_key: str | None=None, organization: str | None=None, base_url: str | httpx.URL | None=None, timeout: Union[float, Timeout, None, NotGiven]=NOT_GIVEN, max_retries: int=DEFAULT_MAX_RETRIES, default_headers: Mapping[str, str] | None=None, default_query: Mapping[str, object] | None=None, http_client: httpx.Client | None=None, _strict_response_validation: bool=False)\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='llmcoder.analyze.Analyzer.Analyzer', description='class Analyzer'>>,\n",
      "name.signature: Type[Analyzer],\n",
      "name.docstring: Analyzer(verbose: bool=False)\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='llmcoder.utils.get_openai_key', description='def get_openai_key'>>,\n",
      "name.signature: get_openai_key(key: str = \"\") -> str,\n",
      "name.docstring: get_openai_key(key: str=\"\") -> str\n",
      "\n",
      "Get OpenAI API key. Try to interpret the key as a key first, then as a path to a file containing the key.\n",
      "Finally, fall back to the default key.txt file or the OPENAI_KEY environment variable.\n",
      "\n",
      "Parameters\n",
      "----------\n",
      "key : str\n",
      "    The key or path to the key file.\n",
      "\n",
      "Returns\n",
      "-------\n",
      "str\n",
      "    The key.\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='llmcoder.utils.get_system_prompt', description='def get_system_prompt'>>,\n",
      "name.signature: get_system_prompt(name: str = \"2023-11-15_GPT-Builder.txt\") -> str,\n",
      "name.docstring: get_system_prompt(name: str=\"2023-11-15_GPT-Builder.txt\") -> str\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='llmcoder.utils.get_system_prompt_dir', description='def get_system_prompt_dir'>>,\n",
      "name.signature: get_system_prompt_dir(*args: str, create: bool = False) -> str,\n",
      "name.docstring: get_system_prompt_dir(*, create: bool=False) -> str\n",
      "\n",
      "Get the path to the system prompts directory.\n",
      "\n",
      "Parameters\n",
      "----------\n",
      "args : str\n",
      "    The path to the system prompts directory.\n",
      "create : bool\n",
      "    Whether to create the directory if it does not exist.\n",
      "\n",
      "Returns\n",
      "-------\n",
      "str\n",
      "    The path to the system prompts directory.\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='__main__.GPTReviewAnalyzer_v1', description='class GPTReviewAnalyzer_v1'>>,\n",
      "name.signature: Type[GPTReviewAnalyzer_v1],\n",
      "name.docstring: GPTReviewAnalyzer_v1(model: str=\"gpt-3.5-turbo\", system_prompt: str | None=None, min_score: int=6, temperature: float=0.2)\n",
      "\n",
      "Concise, professional Python code advisor for targeted feedback.\n",
      "\n",
      "Parameters\n",
      "----------\n",
      "model : str, optional\n",
      "    The model to use, by default \"gpt-3.5-turbo\"\n",
      "system_prompt : str, optional\n",
      "    The system prompt to use, by default `2023-12-02_GPTReviewAnalyzer_v4.txt`, created by GPTBuilder\n",
      "min_score : int, optional\n",
      "    The minimum score to pass the review, by default 6\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='__main__.GPTReviewAnalyzer_v1.__init__', description='def __init__'>>,\n",
      "name.signature: __init__(self, model: str=\"gpt-3.5-turbo\", system_prompt: Optional[str]=None, min_score: int=6, temperature: float=0.2),\n",
      "name.docstring: __init__(self, model: str=\"gpt-3.5-turbo\", system_prompt: str | None=None, min_score: int=6, temperature: float=0.2)\n",
      "\n",
      "Initialize the GPTReviewAnalyzer\n",
      "\n",
      "Parameters\n",
      "----------\n",
      "model : str, optional\n",
      "    The model to use, by default \"gpt-3.5-turbo\"\n",
      "system_prompt : str, optional\n",
      "    The system prompt to use, by default `2023-12-02_GPTReviewAnalyzer_v4.txt`, created by GPTBuilder\n",
      "min_score : int, optional\n",
      "    The minimum score to pass the review, by default 6\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='__main__.GPTReviewAnalyzer_v1.analyze', description='def analyze'>>,\n",
      "name.signature: analyze(self, input: str, completion: str, context: dict[str, dict[str, bool | str]] | None = None) -> dict,\n",
      "name.docstring: analyze(self, input: str, completion: str, context: dict[str, dict[str, bool | str]] | None=None) -> dict\n",
      "\n",
      "Analyze the input and completion\n",
      "\n",
      "Parameters\n",
      "----------\n",
      "input : str\n",
      "    The input to analyze\n",
      "completion : str\n",
      "    The completion to analyze\n",
      "\n",
      "Returns\n",
      "-------\n",
      "dict\n",
      "    The analysis of the input and completion\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='__main__.GPTReviewAnalyzer_v1._prompt_template', description='def _prompt_template'>>,\n",
      "name.signature: _prompt_template(input: str, completion: str) -> str,\n",
      "name.docstring: _prompt_template(input: str, completion: str) -> str\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='openai.OpenAI', description='class OpenAI'>>,\n",
      "name.signature: Type[OpenAI],\n",
      "name.docstring: OpenAI(*, api_key: str | None=None, organization: str | None=None, base_url: str | httpx.URL | None=None, timeout: Union[float, Timeout, None, NotGiven]=NOT_GIVEN, max_retries: int=DEFAULT_MAX_RETRIES, default_headers: Mapping[str, str] | None=None, default_query: Mapping[str, object] | None=None, http_client: httpx.Client | None=None, _strict_response_validation: bool=False)\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='llmcoder.analyze.Analyzer.Analyzer', description='class Analyzer'>>,\n",
      "name.signature: Type[Analyzer],\n",
      "name.docstring: Analyzer(verbose: bool=False)\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='llmcoder.utils.get_openai_key', description='def get_openai_key'>>,\n",
      "name.signature: get_openai_key(key: str = \"\") -> str,\n",
      "name.docstring: get_openai_key(key: str=\"\") -> str\n",
      "\n",
      "Get OpenAI API key. Try to interpret the key as a key first, then as a path to a file containing the key.\n",
      "Finally, fall back to the default key.txt file or the OPENAI_KEY environment variable.\n",
      "\n",
      "Parameters\n",
      "----------\n",
      "key : str\n",
      "    The key or path to the key file.\n",
      "\n",
      "Returns\n",
      "-------\n",
      "str\n",
      "    The key.\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='llmcoder.utils.get_system_prompt', description='def get_system_prompt'>>,\n",
      "name.signature: get_system_prompt(name: str = \"2023-11-15_GPT-Builder.txt\") -> str,\n",
      "name.docstring: get_system_prompt(name: str=\"2023-11-15_GPT-Builder.txt\") -> str\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='llmcoder.utils.get_system_prompt_dir', description='def get_system_prompt_dir'>>,\n",
      "name.signature: get_system_prompt_dir(*args: str, create: bool = False) -> str,\n",
      "name.docstring: get_system_prompt_dir(*, create: bool=False) -> str\n",
      "\n",
      "Get the path to the system prompts directory.\n",
      "\n",
      "Parameters\n",
      "----------\n",
      "args : str\n",
      "    The path to the system prompts directory.\n",
      "create : bool\n",
      "    Whether to create the directory if it does not exist.\n",
      "\n",
      "Returns\n",
      "-------\n",
      "str\n",
      "    The path to the system prompts directory.\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='__main__.GPTReviewAnalyzer_v1', description='class GPTReviewAnalyzer_v1'>>,\n",
      "name.signature: Type[GPTReviewAnalyzer_v1],\n",
      "name.docstring: GPTReviewAnalyzer_v1(model: str=\"gpt-3.5-turbo\", system_prompt: str | None=None, min_score: int=6, temperature: float=0.2)\n",
      "\n",
      "Concise, professional Python code advisor for targeted feedback.\n",
      "\n",
      "Parameters\n",
      "----------\n",
      "model : str, optional\n",
      "    The model to use, by default \"gpt-3.5-turbo\"\n",
      "system_prompt : str, optional\n",
      "    The system prompt to use, by default `2023-12-02_GPTReviewAnalyzer_v4.txt`, created by GPTBuilder\n",
      "min_score : int, optional\n",
      "    The minimum score to pass the review, by default 6\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='__main__.GPTReviewAnalyzer_v1.__init__', description='def __init__'>>,\n",
      "name.signature: __init__(self, model: str=\"gpt-3.5-turbo\", system_prompt: Optional[str]=None, min_score: int=6, temperature: float=0.2),\n",
      "name.docstring: __init__(self, model: str=\"gpt-3.5-turbo\", system_prompt: str | None=None, min_score: int=6, temperature: float=0.2)\n",
      "\n",
      "Initialize the GPTReviewAnalyzer\n",
      "\n",
      "Parameters\n",
      "----------\n",
      "model : str, optional\n",
      "    The model to use, by default \"gpt-3.5-turbo\"\n",
      "system_prompt : str, optional\n",
      "    The system prompt to use, by default `2023-12-02_GPTReviewAnalyzer_v4.txt`, created by GPTBuilder\n",
      "min_score : int, optional\n",
      "    The minimum score to pass the review, by default 6\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='__main__.GPTReviewAnalyzer_v1.analyze', description='def analyze'>>,\n",
      "name.signature: analyze(self, input: str, completion: str, context: dict[str, dict[str, bool | str]] | None = None) -> dict,\n",
      "name.docstring: analyze(self, input: str, completion: str, context: dict[str, dict[str, bool | str]] | None=None) -> dict\n",
      "\n",
      "Analyze the input and completion\n",
      "\n",
      "Parameters\n",
      "----------\n",
      "input : str\n",
      "    The input to analyze\n",
      "completion : str\n",
      "    The completion to analyze\n",
      "\n",
      "Returns\n",
      "-------\n",
      "dict\n",
      "    The analysis of the input and completion\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='__main__.GPTReviewAnalyzer_v1._prompt_template', description='def _prompt_template'>>,\n",
      "name.signature: _prompt_template(input: str, completion: str) -> str,\n",
      "name.docstring: _prompt_template(input: str, completion: str) -> str\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='openai.OpenAI', description='class OpenAI'>>,\n",
      "name.signature: Type[OpenAI],\n",
      "name.docstring: OpenAI(*, api_key: str | None=None, organization: str | None=None, base_url: str | httpx.URL | None=None, timeout: Union[float, Timeout, None, NotGiven]=NOT_GIVEN, max_retries: int=DEFAULT_MAX_RETRIES, default_headers: Mapping[str, str] | None=None, default_query: Mapping[str, object] | None=None, http_client: httpx.Client | None=None, _strict_response_validation: bool=False)\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='llmcoder.analyze.Analyzer.Analyzer', description='class Analyzer'>>,\n",
      "name.signature: Type[Analyzer],\n",
      "name.docstring: Analyzer(verbose: bool=False)\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='llmcoder.utils.get_openai_key', description='def get_openai_key'>>,\n",
      "name.signature: get_openai_key(key: str = \"\") -> str,\n",
      "name.docstring: get_openai_key(key: str=\"\") -> str\n",
      "\n",
      "Get OpenAI API key. Try to interpret the key as a key first, then as a path to a file containing the key.\n",
      "Finally, fall back to the default key.txt file or the OPENAI_KEY environment variable.\n",
      "\n",
      "Parameters\n",
      "----------\n",
      "key : str\n",
      "    The key or path to the key file.\n",
      "\n",
      "Returns\n",
      "-------\n",
      "str\n",
      "    The key.\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='llmcoder.utils.get_system_prompt', description='def get_system_prompt'>>,\n",
      "name.signature: get_system_prompt(name: str = \"2023-11-15_GPT-Builder.txt\") -> str,\n",
      "name.docstring: get_system_prompt(name: str=\"2023-11-15_GPT-Builder.txt\") -> str\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='llmcoder.utils.get_system_prompt_dir', description='def get_system_prompt_dir'>>,\n",
      "name.signature: get_system_prompt_dir(*args: str, create: bool = False) -> str,\n",
      "name.docstring: get_system_prompt_dir(*, create: bool=False) -> str\n",
      "\n",
      "Get the path to the system prompts directory.\n",
      "\n",
      "Parameters\n",
      "----------\n",
      "args : str\n",
      "    The path to the system prompts directory.\n",
      "create : bool\n",
      "    Whether to create the directory if it does not exist.\n",
      "\n",
      "Returns\n",
      "-------\n",
      "str\n",
      "    The path to the system prompts directory.\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='__main__.GPTReviewAnalyzer_v1', description='class GPTReviewAnalyzer_v1'>>,\n",
      "name.signature: Type[GPTReviewAnalyzer_v1],\n",
      "name.docstring: GPTReviewAnalyzer_v1(model: str=\"gpt-3.5-turbo\", system_prompt: str | None=None, min_score: int=6, temperature: float=0.2)\n",
      "\n",
      "Concise, professional Python code advisor for targeted feedback.\n",
      "\n",
      "Parameters\n",
      "----------\n",
      "model : str, optional\n",
      "    The model to use, by default \"gpt-3.5-turbo\"\n",
      "system_prompt : str, optional\n",
      "    The system prompt to use, by default `2023-12-02_GPTReviewAnalyzer_v4.txt`, created by GPTBuilder\n",
      "min_score : int, optional\n",
      "    The minimum score to pass the review, by default 6\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='__main__.GPTReviewAnalyzer_v1.__init__', description='def __init__'>>,\n",
      "name.signature: __init__(self, model: str=\"gpt-3.5-turbo\", system_prompt: Optional[str]=None, min_score: int=6, temperature: float=0.2),\n",
      "name.docstring: __init__(self, model: str=\"gpt-3.5-turbo\", system_prompt: str | None=None, min_score: int=6, temperature: float=0.2)\n",
      "\n",
      "Initialize the GPTReviewAnalyzer\n",
      "\n",
      "Parameters\n",
      "----------\n",
      "model : str, optional\n",
      "    The model to use, by default \"gpt-3.5-turbo\"\n",
      "system_prompt : str, optional\n",
      "    The system prompt to use, by default `2023-12-02_GPTReviewAnalyzer_v4.txt`, created by GPTBuilder\n",
      "min_score : int, optional\n",
      "    The minimum score to pass the review, by default 6\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='__main__.GPTReviewAnalyzer_v1.analyze', description='def analyze'>>,\n",
      "name.signature: analyze(self, input: str, completion: str, context: dict[str, dict[str, bool | str]] | None = None) -> dict,\n",
      "name.docstring: analyze(self, input: str, completion: str, context: dict[str, dict[str, bool | str]] | None=None) -> dict\n",
      "\n",
      "Analyze the input and completion\n",
      "\n",
      "Parameters\n",
      "----------\n",
      "input : str\n",
      "    The input to analyze\n",
      "completion : str\n",
      "    The completion to analyze\n",
      "\n",
      "Returns\n",
      "-------\n",
      "dict\n",
      "    The analysis of the input and completion\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='__main__.GPTReviewAnalyzer_v1._prompt_template', description='def _prompt_template'>>,\n",
      "name.signature: _prompt_template(input: str, completion: str) -> str,\n",
      "name.docstring: _prompt_template(input: str, completion: str) -> str\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='openai.OpenAI', description='class OpenAI'>>,\n",
      "name.signature: Type[OpenAI],\n",
      "name.docstring: OpenAI(*, api_key: str | None=None, organization: str | None=None, base_url: str | httpx.URL | None=None, timeout: Union[float, Timeout, None, NotGiven]=NOT_GIVEN, max_retries: int=DEFAULT_MAX_RETRIES, default_headers: Mapping[str, str] | None=None, default_query: Mapping[str, object] | None=None, http_client: httpx.Client | None=None, _strict_response_validation: bool=False)\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='llmcoder.analyze.Analyzer.Analyzer', description='class Analyzer'>>,\n",
      "name.signature: Type[Analyzer],\n",
      "name.docstring: Analyzer(verbose: bool=False)\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='llmcoder.utils.get_openai_key', description='def get_openai_key'>>,\n",
      "name.signature: get_openai_key(key: str = \"\") -> str,\n",
      "name.docstring: get_openai_key(key: str=\"\") -> str\n",
      "\n",
      "Get OpenAI API key. Try to interpret the key as a key first, then as a path to a file containing the key.\n",
      "Finally, fall back to the default key.txt file or the OPENAI_KEY environment variable.\n",
      "\n",
      "Parameters\n",
      "----------\n",
      "key : str\n",
      "    The key or path to the key file.\n",
      "\n",
      "Returns\n",
      "-------\n",
      "str\n",
      "    The key.\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='llmcoder.utils.get_system_prompt', description='def get_system_prompt'>>,\n",
      "name.signature: get_system_prompt(name: str = \"2023-11-15_GPT-Builder.txt\") -> str,\n",
      "name.docstring: get_system_prompt(name: str=\"2023-11-15_GPT-Builder.txt\") -> str\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='llmcoder.utils.get_system_prompt_dir', description='def get_system_prompt_dir'>>,\n",
      "name.signature: get_system_prompt_dir(*args: str, create: bool = False) -> str,\n",
      "name.docstring: get_system_prompt_dir(*, create: bool=False) -> str\n",
      "\n",
      "Get the path to the system prompts directory.\n",
      "\n",
      "Parameters\n",
      "----------\n",
      "args : str\n",
      "    The path to the system prompts directory.\n",
      "create : bool\n",
      "    Whether to create the directory if it does not exist.\n",
      "\n",
      "Returns\n",
      "-------\n",
      "str\n",
      "    The path to the system prompts directory.\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='__main__.GPTReviewAnalyzer_v1', description='class GPTReviewAnalyzer_v1'>>,\n",
      "name.signature: Type[GPTReviewAnalyzer_v1],\n",
      "name.docstring: GPTReviewAnalyzer_v1(model: str=\"gpt-3.5-turbo\", system_prompt: str | None=None, min_score: int=6, temperature: float=0.2)\n",
      "\n",
      "Concise, professional Python code advisor for targeted feedback.\n",
      "\n",
      "Parameters\n",
      "----------\n",
      "model : str, optional\n",
      "    The model to use, by default \"gpt-3.5-turbo\"\n",
      "system_prompt : str, optional\n",
      "    The system prompt to use, by default `2023-12-02_GPTReviewAnalyzer_v4.txt`, created by GPTBuilder\n",
      "min_score : int, optional\n",
      "    The minimum score to pass the review, by default 6\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='__main__.GPTReviewAnalyzer_v1.__init__', description='def __init__'>>,\n",
      "name.signature: __init__(self, model: str=\"gpt-3.5-turbo\", system_prompt: Optional[str]=None, min_score: int=6, temperature: float=0.2),\n",
      "name.docstring: __init__(self, model: str=\"gpt-3.5-turbo\", system_prompt: str | None=None, min_score: int=6, temperature: float=0.2)\n",
      "\n",
      "Initialize the GPTReviewAnalyzer\n",
      "\n",
      "Parameters\n",
      "----------\n",
      "model : str, optional\n",
      "    The model to use, by default \"gpt-3.5-turbo\"\n",
      "system_prompt : str, optional\n",
      "    The system prompt to use, by default `2023-12-02_GPTReviewAnalyzer_v4.txt`, created by GPTBuilder\n",
      "min_score : int, optional\n",
      "    The minimum score to pass the review, by default 6\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='__main__.GPTReviewAnalyzer_v1.analyze', description='def analyze'>>,\n",
      "name.signature: analyze(self, input: str, completion: str, context: dict[str, dict[str, bool | str]] | None = None) -> dict,\n",
      "name.docstring: analyze(self, input: str, completion: str, context: dict[str, dict[str, bool | str]] | None=None) -> dict\n",
      "\n",
      "Analyze the input and completion\n",
      "\n",
      "Parameters\n",
      "----------\n",
      "input : str\n",
      "    The input to analyze\n",
      "completion : str\n",
      "    The completion to analyze\n",
      "\n",
      "Returns\n",
      "-------\n",
      "dict\n",
      "    The analysis of the input and completion\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='__main__.GPTReviewAnalyzer_v1._prompt_template', description='def _prompt_template'>>,\n",
      "name.signature: _prompt_template(input: str, completion: str) -> str,\n",
      "name.docstring: _prompt_template(input: str, completion: str) -> str\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='openai.OpenAI', description='class OpenAI'>>,\n",
      "name.signature: Type[OpenAI],\n",
      "name.docstring: OpenAI(*, api_key: str | None=None, organization: str | None=None, base_url: str | httpx.URL | None=None, timeout: Union[float, Timeout, None, NotGiven]=NOT_GIVEN, max_retries: int=DEFAULT_MAX_RETRIES, default_headers: Mapping[str, str] | None=None, default_query: Mapping[str, object] | None=None, http_client: httpx.Client | None=None, _strict_response_validation: bool=False)\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='llmcoder.analyze.Analyzer.Analyzer', description='class Analyzer'>>,\n",
      "name.signature: Type[Analyzer],\n",
      "name.docstring: Analyzer(verbose: bool=False)\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='llmcoder.utils.get_openai_key', description='def get_openai_key'>>,\n",
      "name.signature: get_openai_key(key: str = \"\") -> str,\n",
      "name.docstring: get_openai_key(key: str=\"\") -> str\n",
      "\n",
      "Get OpenAI API key. Try to interpret the key as a key first, then as a path to a file containing the key.\n",
      "Finally, fall back to the default key.txt file or the OPENAI_KEY environment variable.\n",
      "\n",
      "Parameters\n",
      "----------\n",
      "key : str\n",
      "    The key or path to the key file.\n",
      "\n",
      "Returns\n",
      "-------\n",
      "str\n",
      "    The key.\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='llmcoder.utils.get_system_prompt', description='def get_system_prompt'>>,\n",
      "name.signature: get_system_prompt(name: str = \"2023-11-15_GPT-Builder.txt\") -> str,\n",
      "name.docstring: get_system_prompt(name: str=\"2023-11-15_GPT-Builder.txt\") -> str\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='llmcoder.utils.get_system_prompt_dir', description='def get_system_prompt_dir'>>,\n",
      "name.signature: get_system_prompt_dir(*args: str, create: bool = False) -> str,\n",
      "name.docstring: get_system_prompt_dir(*, create: bool=False) -> str\n",
      "\n",
      "Get the path to the system prompts directory.\n",
      "\n",
      "Parameters\n",
      "----------\n",
      "args : str\n",
      "    The path to the system prompts directory.\n",
      "create : bool\n",
      "    Whether to create the directory if it does not exist.\n",
      "\n",
      "Returns\n",
      "-------\n",
      "str\n",
      "    The path to the system prompts directory.\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='__main__.GPTReviewAnalyzer_v1', description='class GPTReviewAnalyzer_v1'>>,\n",
      "name.signature: Type[GPTReviewAnalyzer_v1],\n",
      "name.docstring: GPTReviewAnalyzer_v1(model: str=\"gpt-3.5-turbo\", system_prompt: str | None=None, min_score: int=6, temperature: float=0.2)\n",
      "\n",
      "Concise, professional Python code advisor for targeted feedback.\n",
      "\n",
      "Parameters\n",
      "----------\n",
      "model : str, optional\n",
      "    The model to use, by default \"gpt-3.5-turbo\"\n",
      "system_prompt : str, optional\n",
      "    The system prompt to use, by default `2023-12-02_GPTReviewAnalyzer_v4.txt`, created by GPTBuilder\n",
      "min_score : int, optional\n",
      "    The minimum score to pass the review, by default 6\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='__main__.GPTReviewAnalyzer_v1.__init__', description='def __init__'>>,\n",
      "name.signature: __init__(self, model: str=\"gpt-3.5-turbo\", system_prompt: Optional[str]=None, min_score: int=6, temperature: float=0.2),\n",
      "name.docstring: __init__(self, model: str=\"gpt-3.5-turbo\", system_prompt: str | None=None, min_score: int=6, temperature: float=0.2)\n",
      "\n",
      "Initialize the GPTReviewAnalyzer\n",
      "\n",
      "Parameters\n",
      "----------\n",
      "model : str, optional\n",
      "    The model to use, by default \"gpt-3.5-turbo\"\n",
      "system_prompt : str, optional\n",
      "    The system prompt to use, by default `2023-12-02_GPTReviewAnalyzer_v4.txt`, created by GPTBuilder\n",
      "min_score : int, optional\n",
      "    The minimum score to pass the review, by default 6\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='__main__.GPTReviewAnalyzer_v1.analyze', description='def analyze'>>,\n",
      "name.signature: analyze(self, input: str, completion: str, context: dict[str, dict[str, bool | str]] | None = None) -> dict,\n",
      "name.docstring: analyze(self, input: str, completion: str, context: dict[str, dict[str, bool | str]] | None=None) -> dict\n",
      "\n",
      "Analyze the input and completion\n",
      "\n",
      "Parameters\n",
      "----------\n",
      "input : str\n",
      "    The input to analyze\n",
      "completion : str\n",
      "    The completion to analyze\n",
      "\n",
      "Returns\n",
      "-------\n",
      "dict\n",
      "    The analysis of the input and completion\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='__main__.GPTReviewAnalyzer_v1._prompt_template', description='def _prompt_template'>>,\n",
      "name.signature: _prompt_template(input: str, completion: str) -> str,\n",
      "name.docstring: _prompt_template(input: str, completion: str) -> str\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='openai.OpenAI', description='class OpenAI'>>,\n",
      "name.signature: Type[OpenAI],\n",
      "name.docstring: OpenAI(*, api_key: str | None=None, organization: str | None=None, base_url: str | httpx.URL | None=None, timeout: Union[float, Timeout, None, NotGiven]=NOT_GIVEN, max_retries: int=DEFAULT_MAX_RETRIES, default_headers: Mapping[str, str] | None=None, default_query: Mapping[str, object] | None=None, http_client: httpx.Client | None=None, _strict_response_validation: bool=False)\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='llmcoder.analyze.Analyzer.Analyzer', description='class Analyzer'>>,\n",
      "name.signature: Type[Analyzer],\n",
      "name.docstring: Analyzer(verbose: bool=False)\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='llmcoder.utils.get_openai_key', description='def get_openai_key'>>,\n",
      "name.signature: get_openai_key(key: str = \"\") -> str,\n",
      "name.docstring: get_openai_key(key: str=\"\") -> str\n",
      "\n",
      "Get OpenAI API key. Try to interpret the key as a key first, then as a path to a file containing the key.\n",
      "Finally, fall back to the default key.txt file or the OPENAI_KEY environment variable.\n",
      "\n",
      "Parameters\n",
      "----------\n",
      "key : str\n",
      "    The key or path to the key file.\n",
      "\n",
      "Returns\n",
      "-------\n",
      "str\n",
      "    The key.\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='llmcoder.utils.get_system_prompt', description='def get_system_prompt'>>,\n",
      "name.signature: get_system_prompt(name: str = \"2023-11-15_GPT-Builder.txt\") -> str,\n",
      "name.docstring: get_system_prompt(name: str=\"2023-11-15_GPT-Builder.txt\") -> str\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='llmcoder.utils.get_system_prompt_dir', description='def get_system_prompt_dir'>>,\n",
      "name.signature: get_system_prompt_dir(*args: str, create: bool = False) -> str,\n",
      "name.docstring: get_system_prompt_dir(*, create: bool=False) -> str\n",
      "\n",
      "Get the path to the system prompts directory.\n",
      "\n",
      "Parameters\n",
      "----------\n",
      "args : str\n",
      "    The path to the system prompts directory.\n",
      "create : bool\n",
      "    Whether to create the directory if it does not exist.\n",
      "\n",
      "Returns\n",
      "-------\n",
      "str\n",
      "    The path to the system prompts directory.\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='__main__.GPTReviewAnalyzer_v1', description='class GPTReviewAnalyzer_v1'>>,\n",
      "name.signature: Type[GPTReviewAnalyzer_v1],\n",
      "name.docstring: GPTReviewAnalyzer_v1(model: str=\"gpt-3.5-turbo\", system_prompt: str | None=None, min_score: int=6, temperature: float=0.2)\n",
      "\n",
      "Concise, professional Python code advisor for targeted feedback.\n",
      "\n",
      "Parameters\n",
      "----------\n",
      "model : str, optional\n",
      "    The model to use, by default \"gpt-3.5-turbo\"\n",
      "system_prompt : str, optional\n",
      "    The system prompt to use, by default `2023-12-02_GPTReviewAnalyzer_v4.txt`, created by GPTBuilder\n",
      "min_score : int, optional\n",
      "    The minimum score to pass the review, by default 6\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='__main__.GPTReviewAnalyzer_v1.__init__', description='def __init__'>>,\n",
      "name.signature: __init__(self, model: str=\"gpt-3.5-turbo\", system_prompt: Optional[str]=None, min_score: int=6, temperature: float=0.2),\n",
      "name.docstring: __init__(self, model: str=\"gpt-3.5-turbo\", system_prompt: str | None=None, min_score: int=6, temperature: float=0.2)\n",
      "\n",
      "Initialize the GPTReviewAnalyzer\n",
      "\n",
      "Parameters\n",
      "----------\n",
      "model : str, optional\n",
      "    The model to use, by default \"gpt-3.5-turbo\"\n",
      "system_prompt : str, optional\n",
      "    The system prompt to use, by default `2023-12-02_GPTReviewAnalyzer_v4.txt`, created by GPTBuilder\n",
      "min_score : int, optional\n",
      "    The minimum score to pass the review, by default 6\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='__main__.GPTReviewAnalyzer_v1.analyze', description='def analyze'>>,\n",
      "name.signature: analyze(self, input: str, completion: str, context: dict[str, dict[str, bool | str]] | None = None) -> dict,\n",
      "name.docstring: analyze(self, input: str, completion: str, context: dict[str, dict[str, bool | str]] | None=None) -> dict\n",
      "\n",
      "Analyze the input and completion\n",
      "\n",
      "Parameters\n",
      "----------\n",
      "input : str\n",
      "    The input to analyze\n",
      "completion : str\n",
      "    The completion to analyze\n",
      "\n",
      "Returns\n",
      "-------\n",
      "dict\n",
      "    The analysis of the input and completion\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='__main__.GPTReviewAnalyzer_v1._prompt_template', description='def _prompt_template'>>,\n",
      "name.signature: _prompt_template(input: str, completion: str) -> str,\n",
      "name.docstring: _prompt_template(input: str, completion: str) -> str\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='openai.OpenAI', description='class OpenAI'>>,\n",
      "name.signature: Type[OpenAI],\n",
      "name.docstring: OpenAI(*, api_key: str | None=None, organization: str | None=None, base_url: str | httpx.URL | None=None, timeout: Union[float, Timeout, None, NotGiven]=NOT_GIVEN, max_retries: int=DEFAULT_MAX_RETRIES, default_headers: Mapping[str, str] | None=None, default_query: Mapping[str, object] | None=None, http_client: httpx.Client | None=None, _strict_response_validation: bool=False)\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='llmcoder.analyze.Analyzer.Analyzer', description='class Analyzer'>>,\n",
      "name.signature: Type[Analyzer],\n",
      "name.docstring: Analyzer(verbose: bool=False)\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='llmcoder.utils.get_openai_key', description='def get_openai_key'>>,\n",
      "name.signature: get_openai_key(key: str = \"\") -> str,\n",
      "name.docstring: get_openai_key(key: str=\"\") -> str\n",
      "\n",
      "Get OpenAI API key. Try to interpret the key as a key first, then as a path to a file containing the key.\n",
      "Finally, fall back to the default key.txt file or the OPENAI_KEY environment variable.\n",
      "\n",
      "Parameters\n",
      "----------\n",
      "key : str\n",
      "    The key or path to the key file.\n",
      "\n",
      "Returns\n",
      "-------\n",
      "str\n",
      "    The key.\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='llmcoder.utils.get_system_prompt', description='def get_system_prompt'>>,\n",
      "name.signature: get_system_prompt(name: str = \"2023-11-15_GPT-Builder.txt\") -> str,\n",
      "name.docstring: get_system_prompt(name: str=\"2023-11-15_GPT-Builder.txt\") -> str\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='llmcoder.utils.get_system_prompt_dir', description='def get_system_prompt_dir'>>,\n",
      "name.signature: get_system_prompt_dir(*args: str, create: bool = False) -> str,\n",
      "name.docstring: get_system_prompt_dir(*, create: bool=False) -> str\n",
      "\n",
      "Get the path to the system prompts directory.\n",
      "\n",
      "Parameters\n",
      "----------\n",
      "args : str\n",
      "    The path to the system prompts directory.\n",
      "create : bool\n",
      "    Whether to create the directory if it does not exist.\n",
      "\n",
      "Returns\n",
      "-------\n",
      "str\n",
      "    The path to the system prompts directory.\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='__main__.GPTReviewAnalyzer_v1', description='class GPTReviewAnalyzer_v1'>>,\n",
      "name.signature: Type[GPTReviewAnalyzer_v1],\n",
      "name.docstring: GPTReviewAnalyzer_v1(model: str=\"gpt-3.5-turbo\", system_prompt: str | None=None, min_score: int=6, temperature: float=0.2)\n",
      "\n",
      "Concise, professional Python code advisor for targeted feedback.\n",
      "\n",
      "Parameters\n",
      "----------\n",
      "model : str, optional\n",
      "    The model to use, by default \"gpt-3.5-turbo\"\n",
      "system_prompt : str, optional\n",
      "    The system prompt to use, by default `2023-12-02_GPTReviewAnalyzer_v4.txt`, created by GPTBuilder\n",
      "min_score : int, optional\n",
      "    The minimum score to pass the review, by default 6\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='__main__.GPTReviewAnalyzer_v1.__init__', description='def __init__'>>,\n",
      "name.signature: __init__(self, model: str=\"gpt-3.5-turbo\", system_prompt: Optional[str]=None, min_score: int=6, temperature: float=0.2),\n",
      "name.docstring: __init__(self, model: str=\"gpt-3.5-turbo\", system_prompt: str | None=None, min_score: int=6, temperature: float=0.2)\n",
      "\n",
      "Initialize the GPTReviewAnalyzer\n",
      "\n",
      "Parameters\n",
      "----------\n",
      "model : str, optional\n",
      "    The model to use, by default \"gpt-3.5-turbo\"\n",
      "system_prompt : str, optional\n",
      "    The system prompt to use, by default `2023-12-02_GPTReviewAnalyzer_v4.txt`, created by GPTBuilder\n",
      "min_score : int, optional\n",
      "    The minimum score to pass the review, by default 6\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='__main__.GPTReviewAnalyzer_v1.analyze', description='def analyze'>>,\n",
      "name.signature: analyze(self, input: str, completion: str, context: dict[str, dict[str, bool | str]] | None = None) -> dict,\n",
      "name.docstring: analyze(self, input: str, completion: str, context: dict[str, dict[str, bool | str]] | None=None) -> dict\n",
      "\n",
      "Analyze the input and completion\n",
      "\n",
      "Parameters\n",
      "----------\n",
      "input : str\n",
      "    The input to analyze\n",
      "completion : str\n",
      "    The completion to analyze\n",
      "\n",
      "Returns\n",
      "-------\n",
      "dict\n",
      "    The analysis of the input and completion\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='__main__.GPTReviewAnalyzer_v1._prompt_template', description='def _prompt_template'>>,\n",
      "name.signature: _prompt_template(input: str, completion: str) -> str,\n",
      "name.docstring: _prompt_template(input: str, completion: str) -> str\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='openai.OpenAI', description='class OpenAI'>>,\n",
      "name.signature: Type[OpenAI],\n",
      "name.docstring: OpenAI(*, api_key: str | None=None, organization: str | None=None, base_url: str | httpx.URL | None=None, timeout: Union[float, Timeout, None, NotGiven]=NOT_GIVEN, max_retries: int=DEFAULT_MAX_RETRIES, default_headers: Mapping[str, str] | None=None, default_query: Mapping[str, object] | None=None, http_client: httpx.Client | None=None, _strict_response_validation: bool=False)\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='llmcoder.analyze.Analyzer.Analyzer', description='class Analyzer'>>,\n",
      "name.signature: Type[Analyzer],\n",
      "name.docstring: Analyzer(verbose: bool=False)\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='llmcoder.utils.get_openai_key', description='def get_openai_key'>>,\n",
      "name.signature: get_openai_key(key: str = \"\") -> str,\n",
      "name.docstring: get_openai_key(key: str=\"\") -> str\n",
      "\n",
      "Get OpenAI API key. Try to interpret the key as a key first, then as a path to a file containing the key.\n",
      "Finally, fall back to the default key.txt file or the OPENAI_KEY environment variable.\n",
      "\n",
      "Parameters\n",
      "----------\n",
      "key : str\n",
      "    The key or path to the key file.\n",
      "\n",
      "Returns\n",
      "-------\n",
      "str\n",
      "    The key.\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='llmcoder.utils.get_system_prompt', description='def get_system_prompt'>>,\n",
      "name.signature: get_system_prompt(name: str = \"2023-11-15_GPT-Builder.txt\") -> str,\n",
      "name.docstring: get_system_prompt(name: str=\"2023-11-15_GPT-Builder.txt\") -> str\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='llmcoder.utils.get_system_prompt_dir', description='def get_system_prompt_dir'>>,\n",
      "name.signature: get_system_prompt_dir(*args: str, create: bool = False) -> str,\n",
      "name.docstring: get_system_prompt_dir(*, create: bool=False) -> str\n",
      "\n",
      "Get the path to the system prompts directory.\n",
      "\n",
      "Parameters\n",
      "----------\n",
      "args : str\n",
      "    The path to the system prompts directory.\n",
      "create : bool\n",
      "    Whether to create the directory if it does not exist.\n",
      "\n",
      "Returns\n",
      "-------\n",
      "str\n",
      "    The path to the system prompts directory.\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='__main__.GPTReviewAnalyzer_v1', description='class GPTReviewAnalyzer_v1'>>,\n",
      "name.signature: Type[GPTReviewAnalyzer_v1],\n",
      "name.docstring: GPTReviewAnalyzer_v1(model: str=\"gpt-3.5-turbo\", system_prompt: str | None=None, min_score: int=6, temperature: float=0.2)\n",
      "\n",
      "Concise, professional Python code advisor for targeted feedback.\n",
      "\n",
      "Parameters\n",
      "----------\n",
      "model : str, optional\n",
      "    The model to use, by default \"gpt-3.5-turbo\"\n",
      "system_prompt : str, optional\n",
      "    The system prompt to use, by default `2023-12-02_GPTReviewAnalyzer_v4.txt`, created by GPTBuilder\n",
      "min_score : int, optional\n",
      "    The minimum score to pass the review, by default 6\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='__main__.GPTReviewAnalyzer_v1.__init__', description='def __init__'>>,\n",
      "name.signature: __init__(self, model: str=\"gpt-3.5-turbo\", system_prompt: Optional[str]=None, min_score: int=6, temperature: float=0.2),\n",
      "name.docstring: __init__(self, model: str=\"gpt-3.5-turbo\", system_prompt: str | None=None, min_score: int=6, temperature: float=0.2)\n",
      "\n",
      "Initialize the GPTReviewAnalyzer\n",
      "\n",
      "Parameters\n",
      "----------\n",
      "model : str, optional\n",
      "    The model to use, by default \"gpt-3.5-turbo\"\n",
      "system_prompt : str, optional\n",
      "    The system prompt to use, by default `2023-12-02_GPTReviewAnalyzer_v4.txt`, created by GPTBuilder\n",
      "min_score : int, optional\n",
      "    The minimum score to pass the review, by default 6\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='__main__.GPTReviewAnalyzer_v1.analyze', description='def analyze'>>,\n",
      "name.signature: analyze(self, input: str, completion: str, context: dict[str, dict[str, bool | str]] | None = None) -> dict,\n",
      "name.docstring: analyze(self, input: str, completion: str, context: dict[str, dict[str, bool | str]] | None=None) -> dict\n",
      "\n",
      "Analyze the input and completion\n",
      "\n",
      "Parameters\n",
      "----------\n",
      "input : str\n",
      "    The input to analyze\n",
      "completion : str\n",
      "    The completion to analyze\n",
      "\n",
      "Returns\n",
      "-------\n",
      "dict\n",
      "    The analysis of the input and completion\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='__main__.GPTReviewAnalyzer_v1._prompt_template', description='def _prompt_template'>>,\n",
      "name.signature: _prompt_template(input: str, completion: str) -> str,\n",
      "name.docstring: _prompt_template(input: str, completion: str) -> str\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='openai.OpenAI', description='class OpenAI'>>,\n",
      "name.signature: Type[OpenAI],\n",
      "name.docstring: OpenAI(*, api_key: str | None=None, organization: str | None=None, base_url: str | httpx.URL | None=None, timeout: Union[float, Timeout, None, NotGiven]=NOT_GIVEN, max_retries: int=DEFAULT_MAX_RETRIES, default_headers: Mapping[str, str] | None=None, default_query: Mapping[str, object] | None=None, http_client: httpx.Client | None=None, _strict_response_validation: bool=False)\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='llmcoder.analyze.Analyzer.Analyzer', description='class Analyzer'>>,\n",
      "name.signature: Type[Analyzer],\n",
      "name.docstring: Analyzer(verbose: bool=False)\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='llmcoder.utils.get_openai_key', description='def get_openai_key'>>,\n",
      "name.signature: get_openai_key(key: str = \"\") -> str,\n",
      "name.docstring: get_openai_key(key: str=\"\") -> str\n",
      "\n",
      "Get OpenAI API key. Try to interpret the key as a key first, then as a path to a file containing the key.\n",
      "Finally, fall back to the default key.txt file or the OPENAI_KEY environment variable.\n",
      "\n",
      "Parameters\n",
      "----------\n",
      "key : str\n",
      "    The key or path to the key file.\n",
      "\n",
      "Returns\n",
      "-------\n",
      "str\n",
      "    The key.\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='llmcoder.utils.get_system_prompt', description='def get_system_prompt'>>,\n",
      "name.signature: get_system_prompt(name: str = \"2023-11-15_GPT-Builder.txt\") -> str,\n",
      "name.docstring: get_system_prompt(name: str=\"2023-11-15_GPT-Builder.txt\") -> str\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='llmcoder.utils.get_system_prompt_dir', description='def get_system_prompt_dir'>>,\n",
      "name.signature: get_system_prompt_dir(*args: str, create: bool = False) -> str,\n",
      "name.docstring: get_system_prompt_dir(*, create: bool=False) -> str\n",
      "\n",
      "Get the path to the system prompts directory.\n",
      "\n",
      "Parameters\n",
      "----------\n",
      "args : str\n",
      "    The path to the system prompts directory.\n",
      "create : bool\n",
      "    Whether to create the directory if it does not exist.\n",
      "\n",
      "Returns\n",
      "-------\n",
      "str\n",
      "    The path to the system prompts directory.\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='__main__.GPTReviewAnalyzer_v1', description='class GPTReviewAnalyzer_v1'>>,\n",
      "name.signature: Type[GPTReviewAnalyzer_v1],\n",
      "name.docstring: GPTReviewAnalyzer_v1(model: str=\"gpt-3.5-turbo\", system_prompt: str | None=None, min_score: int=6, temperature: float=0.2)\n",
      "\n",
      "Concise, professional Python code advisor for targeted feedback.\n",
      "\n",
      "Parameters\n",
      "----------\n",
      "model : str, optional\n",
      "    The model to use, by default \"gpt-3.5-turbo\"\n",
      "system_prompt : str, optional\n",
      "    The system prompt to use, by default `2023-12-02_GPTReviewAnalyzer_v4.txt`, created by GPTBuilder\n",
      "min_score : int, optional\n",
      "    The minimum score to pass the review, by default 6\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='__main__.GPTReviewAnalyzer_v1.__init__', description='def __init__'>>,\n",
      "name.signature: __init__(self, model: str=\"gpt-3.5-turbo\", system_prompt: Optional[str]=None, min_score: int=6, temperature: float=0.2),\n",
      "name.docstring: __init__(self, model: str=\"gpt-3.5-turbo\", system_prompt: str | None=None, min_score: int=6, temperature: float=0.2)\n",
      "\n",
      "Initialize the GPTReviewAnalyzer\n",
      "\n",
      "Parameters\n",
      "----------\n",
      "model : str, optional\n",
      "    The model to use, by default \"gpt-3.5-turbo\"\n",
      "system_prompt : str, optional\n",
      "    The system prompt to use, by default `2023-12-02_GPTReviewAnalyzer_v4.txt`, created by GPTBuilder\n",
      "min_score : int, optional\n",
      "    The minimum score to pass the review, by default 6\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='__main__.GPTReviewAnalyzer_v1.analyze', description='def analyze'>>,\n",
      "name.signature: analyze(self, input: str, completion: str, context: dict[str, dict[str, bool | str]] | None = None) -> dict,\n",
      "name.docstring: analyze(self, input: str, completion: str, context: dict[str, dict[str, bool | str]] | None=None) -> dict\n",
      "\n",
      "Analyze the input and completion\n",
      "\n",
      "Parameters\n",
      "----------\n",
      "input : str\n",
      "    The input to analyze\n",
      "completion : str\n",
      "    The completion to analyze\n",
      "\n",
      "Returns\n",
      "-------\n",
      "dict\n",
      "    The analysis of the input and completion\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='__main__.GPTReviewAnalyzer_v1._prompt_template', description='def _prompt_template'>>,\n",
      "name.signature: _prompt_template(input: str, completion: str) -> str,\n",
      "name.docstring: _prompt_template(input: str, completion: str) -> str\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='openai.OpenAI', description='class OpenAI'>>,\n",
      "name.signature: Type[OpenAI],\n",
      "name.docstring: OpenAI(*, api_key: str | None=None, organization: str | None=None, base_url: str | httpx.URL | None=None, timeout: Union[float, Timeout, None, NotGiven]=NOT_GIVEN, max_retries: int=DEFAULT_MAX_RETRIES, default_headers: Mapping[str, str] | None=None, default_query: Mapping[str, object] | None=None, http_client: httpx.Client | None=None, _strict_response_validation: bool=False)\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='llmcoder.analyze.Analyzer.Analyzer', description='class Analyzer'>>,\n",
      "name.signature: Type[Analyzer],\n",
      "name.docstring: Analyzer(verbose: bool=False)\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='llmcoder.utils.get_openai_key', description='def get_openai_key'>>,\n",
      "name.signature: get_openai_key(key: str = \"\") -> str,\n",
      "name.docstring: get_openai_key(key: str=\"\") -> str\n",
      "\n",
      "Get OpenAI API key. Try to interpret the key as a key first, then as a path to a file containing the key.\n",
      "Finally, fall back to the default key.txt file or the OPENAI_KEY environment variable.\n",
      "\n",
      "Parameters\n",
      "----------\n",
      "key : str\n",
      "    The key or path to the key file.\n",
      "\n",
      "Returns\n",
      "-------\n",
      "str\n",
      "    The key.\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='llmcoder.utils.get_system_prompt', description='def get_system_prompt'>>,\n",
      "name.signature: get_system_prompt(name: str = \"2023-11-15_GPT-Builder.txt\") -> str,\n",
      "name.docstring: get_system_prompt(name: str=\"2023-11-15_GPT-Builder.txt\") -> str\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='llmcoder.utils.get_system_prompt_dir', description='def get_system_prompt_dir'>>,\n",
      "name.signature: get_system_prompt_dir(*args: str, create: bool = False) -> str,\n",
      "name.docstring: get_system_prompt_dir(*, create: bool=False) -> str\n",
      "\n",
      "Get the path to the system prompts directory.\n",
      "\n",
      "Parameters\n",
      "----------\n",
      "args : str\n",
      "    The path to the system prompts directory.\n",
      "create : bool\n",
      "    Whether to create the directory if it does not exist.\n",
      "\n",
      "Returns\n",
      "-------\n",
      "str\n",
      "    The path to the system prompts directory.\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='__main__.GPTReviewAnalyzer_v1', description='class GPTReviewAnalyzer_v1'>>,\n",
      "name.signature: Type[GPTReviewAnalyzer_v1],\n",
      "name.docstring: GPTReviewAnalyzer_v1(model: str=\"gpt-3.5-turbo\", system_prompt: str | None=None, min_score: int=6, temperature: float=0.2)\n",
      "\n",
      "Concise, professional Python code advisor for targeted feedback.\n",
      "\n",
      "Parameters\n",
      "----------\n",
      "model : str, optional\n",
      "    The model to use, by default \"gpt-3.5-turbo\"\n",
      "system_prompt : str, optional\n",
      "    The system prompt to use, by default `2023-12-02_GPTReviewAnalyzer_v4.txt`, created by GPTBuilder\n",
      "min_score : int, optional\n",
      "    The minimum score to pass the review, by default 6\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='__main__.GPTReviewAnalyzer_v1.__init__', description='def __init__'>>,\n",
      "name.signature: __init__(self, model: str=\"gpt-3.5-turbo\", system_prompt: Optional[str]=None, min_score: int=6, temperature: float=0.2),\n",
      "name.docstring: __init__(self, model: str=\"gpt-3.5-turbo\", system_prompt: str | None=None, min_score: int=6, temperature: float=0.2)\n",
      "\n",
      "Initialize the GPTReviewAnalyzer\n",
      "\n",
      "Parameters\n",
      "----------\n",
      "model : str, optional\n",
      "    The model to use, by default \"gpt-3.5-turbo\"\n",
      "system_prompt : str, optional\n",
      "    The system prompt to use, by default `2023-12-02_GPTReviewAnalyzer_v4.txt`, created by GPTBuilder\n",
      "min_score : int, optional\n",
      "    The minimum score to pass the review, by default 6\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='__main__.GPTReviewAnalyzer_v1.analyze', description='def analyze'>>,\n",
      "name.signature: analyze(self, input: str, completion: str, context: dict[str, dict[str, bool | str]] | None = None) -> dict,\n",
      "name.docstring: analyze(self, input: str, completion: str, context: dict[str, dict[str, bool | str]] | None=None) -> dict\n",
      "\n",
      "Analyze the input and completion\n",
      "\n",
      "Parameters\n",
      "----------\n",
      "input : str\n",
      "    The input to analyze\n",
      "completion : str\n",
      "    The completion to analyze\n",
      "\n",
      "Returns\n",
      "-------\n",
      "dict\n",
      "    The analysis of the input and completion\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='__main__.GPTReviewAnalyzer_v1._prompt_template', description='def _prompt_template'>>,\n",
      "name.signature: _prompt_template(input: str, completion: str) -> str,\n",
      "name.docstring: _prompt_template(input: str, completion: str) -> str\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='openai.OpenAI', description='class OpenAI'>>,\n",
      "name.signature: Type[OpenAI],\n",
      "name.docstring: OpenAI(*, api_key: str | None=None, organization: str | None=None, base_url: str | httpx.URL | None=None, timeout: Union[float, Timeout, None, NotGiven]=NOT_GIVEN, max_retries: int=DEFAULT_MAX_RETRIES, default_headers: Mapping[str, str] | None=None, default_query: Mapping[str, object] | None=None, http_client: httpx.Client | None=None, _strict_response_validation: bool=False)\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='llmcoder.analyze.Analyzer.Analyzer', description='class Analyzer'>>,\n",
      "name.signature: Type[Analyzer],\n",
      "name.docstring: Analyzer(verbose: bool=False)\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='llmcoder.utils.get_openai_key', description='def get_openai_key'>>,\n",
      "name.signature: get_openai_key(key: str = \"\") -> str,\n",
      "name.docstring: get_openai_key(key: str=\"\") -> str\n",
      "\n",
      "Get OpenAI API key. Try to interpret the key as a key first, then as a path to a file containing the key.\n",
      "Finally, fall back to the default key.txt file or the OPENAI_KEY environment variable.\n",
      "\n",
      "Parameters\n",
      "----------\n",
      "key : str\n",
      "    The key or path to the key file.\n",
      "\n",
      "Returns\n",
      "-------\n",
      "str\n",
      "    The key.\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='llmcoder.utils.get_system_prompt', description='def get_system_prompt'>>,\n",
      "name.signature: get_system_prompt(name: str = \"2023-11-15_GPT-Builder.txt\") -> str,\n",
      "name.docstring: get_system_prompt(name: str=\"2023-11-15_GPT-Builder.txt\") -> str\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='llmcoder.utils.get_system_prompt_dir', description='def get_system_prompt_dir'>>,\n",
      "name.signature: get_system_prompt_dir(*args: str, create: bool = False) -> str,\n",
      "name.docstring: get_system_prompt_dir(*, create: bool=False) -> str\n",
      "\n",
      "Get the path to the system prompts directory.\n",
      "\n",
      "Parameters\n",
      "----------\n",
      "args : str\n",
      "    The path to the system prompts directory.\n",
      "create : bool\n",
      "    Whether to create the directory if it does not exist.\n",
      "\n",
      "Returns\n",
      "-------\n",
      "str\n",
      "    The path to the system prompts directory.\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='__main__.GPTReviewAnalyzer_v1', description='class GPTReviewAnalyzer_v1'>>,\n",
      "name.signature: Type[GPTReviewAnalyzer_v1],\n",
      "name.docstring: GPTReviewAnalyzer_v1(model: str=\"gpt-3.5-turbo\", system_prompt: str | None=None, min_score: int=6, temperature: float=0.2)\n",
      "\n",
      "Concise, professional Python code advisor for targeted feedback.\n",
      "\n",
      "Parameters\n",
      "----------\n",
      "model : str, optional\n",
      "    The model to use, by default \"gpt-3.5-turbo\"\n",
      "system_prompt : str, optional\n",
      "    The system prompt to use, by default `2023-12-02_GPTReviewAnalyzer_v4.txt`, created by GPTBuilder\n",
      "min_score : int, optional\n",
      "    The minimum score to pass the review, by default 6\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='__main__.GPTReviewAnalyzer_v1.__init__', description='def __init__'>>,\n",
      "name.signature: __init__(self, model: str=\"gpt-3.5-turbo\", system_prompt: Optional[str]=None, min_score: int=6, temperature: float=0.2),\n",
      "name.docstring: __init__(self, model: str=\"gpt-3.5-turbo\", system_prompt: str | None=None, min_score: int=6, temperature: float=0.2)\n",
      "\n",
      "Initialize the GPTReviewAnalyzer\n",
      "\n",
      "Parameters\n",
      "----------\n",
      "model : str, optional\n",
      "    The model to use, by default \"gpt-3.5-turbo\"\n",
      "system_prompt : str, optional\n",
      "    The system prompt to use, by default `2023-12-02_GPTReviewAnalyzer_v4.txt`, created by GPTBuilder\n",
      "min_score : int, optional\n",
      "    The minimum score to pass the review, by default 6\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='__main__.GPTReviewAnalyzer_v1.analyze', description='def analyze'>>,\n",
      "name.signature: analyze(self, input: str, completion: str, context: dict[str, dict[str, bool | str]] | None = None) -> dict,\n",
      "name.docstring: analyze(self, input: str, completion: str, context: dict[str, dict[str, bool | str]] | None=None) -> dict\n",
      "\n",
      "Analyze the input and completion\n",
      "\n",
      "Parameters\n",
      "----------\n",
      "input : str\n",
      "    The input to analyze\n",
      "completion : str\n",
      "    The completion to analyze\n",
      "\n",
      "Returns\n",
      "-------\n",
      "dict\n",
      "    The analysis of the input and completion\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='__main__.GPTReviewAnalyzer_v1._prompt_template', description='def _prompt_template'>>,\n",
      "name.signature: _prompt_template(input: str, completion: str) -> str,\n",
      "name.docstring: _prompt_template(input: str, completion: str) -> str\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='openai.OpenAI', description='class OpenAI'>>,\n",
      "name.signature: Type[OpenAI],\n",
      "name.docstring: OpenAI(*, api_key: str | None=None, organization: str | None=None, base_url: str | httpx.URL | None=None, timeout: Union[float, Timeout, None, NotGiven]=NOT_GIVEN, max_retries: int=DEFAULT_MAX_RETRIES, default_headers: Mapping[str, str] | None=None, default_query: Mapping[str, object] | None=None, http_client: httpx.Client | None=None, _strict_response_validation: bool=False)\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='llmcoder.analyze.Analyzer.Analyzer', description='class Analyzer'>>,\n",
      "name.signature: Type[Analyzer],\n",
      "name.docstring: Analyzer(verbose: bool=False)\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='llmcoder.utils.get_openai_key', description='def get_openai_key'>>,\n",
      "name.signature: get_openai_key(key: str = \"\") -> str,\n",
      "name.docstring: get_openai_key(key: str=\"\") -> str\n",
      "\n",
      "Get OpenAI API key. Try to interpret the key as a key first, then as a path to a file containing the key.\n",
      "Finally, fall back to the default key.txt file or the OPENAI_KEY environment variable.\n",
      "\n",
      "Parameters\n",
      "----------\n",
      "key : str\n",
      "    The key or path to the key file.\n",
      "\n",
      "Returns\n",
      "-------\n",
      "str\n",
      "    The key.\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='llmcoder.utils.get_system_prompt', description='def get_system_prompt'>>,\n",
      "name.signature: get_system_prompt(name: str = \"2023-11-15_GPT-Builder.txt\") -> str,\n",
      "name.docstring: get_system_prompt(name: str=\"2023-11-15_GPT-Builder.txt\") -> str\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='llmcoder.utils.get_system_prompt_dir', description='def get_system_prompt_dir'>>,\n",
      "name.signature: get_system_prompt_dir(*args: str, create: bool = False) -> str,\n",
      "name.docstring: get_system_prompt_dir(*, create: bool=False) -> str\n",
      "\n",
      "Get the path to the system prompts directory.\n",
      "\n",
      "Parameters\n",
      "----------\n",
      "args : str\n",
      "    The path to the system prompts directory.\n",
      "create : bool\n",
      "    Whether to create the directory if it does not exist.\n",
      "\n",
      "Returns\n",
      "-------\n",
      "str\n",
      "    The path to the system prompts directory.\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='__main__.GPTReviewAnalyzer_v1', description='class GPTReviewAnalyzer_v1'>>,\n",
      "name.signature: Type[GPTReviewAnalyzer_v1],\n",
      "name.docstring: GPTReviewAnalyzer_v1(model: str=\"gpt-3.5-turbo\", system_prompt: str | None=None, min_score: int=6, temperature: float=0.2)\n",
      "\n",
      "Concise, professional Python code advisor for targeted feedback.\n",
      "\n",
      "Parameters\n",
      "----------\n",
      "model : str, optional\n",
      "    The model to use, by default \"gpt-3.5-turbo\"\n",
      "system_prompt : str, optional\n",
      "    The system prompt to use, by default `2023-12-02_GPTReviewAnalyzer_v4.txt`, created by GPTBuilder\n",
      "min_score : int, optional\n",
      "    The minimum score to pass the review, by default 6\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='__main__.GPTReviewAnalyzer_v1.__init__', description='def __init__'>>,\n",
      "name.signature: __init__(self, model: str=\"gpt-3.5-turbo\", system_prompt: Optional[str]=None, min_score: int=6, temperature: float=0.2),\n",
      "name.docstring: __init__(self, model: str=\"gpt-3.5-turbo\", system_prompt: str | None=None, min_score: int=6, temperature: float=0.2)\n",
      "\n",
      "Initialize the GPTReviewAnalyzer\n",
      "\n",
      "Parameters\n",
      "----------\n",
      "model : str, optional\n",
      "    The model to use, by default \"gpt-3.5-turbo\"\n",
      "system_prompt : str, optional\n",
      "    The system prompt to use, by default `2023-12-02_GPTReviewAnalyzer_v4.txt`, created by GPTBuilder\n",
      "min_score : int, optional\n",
      "    The minimum score to pass the review, by default 6\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='__main__.GPTReviewAnalyzer_v1.analyze', description='def analyze'>>,\n",
      "name.signature: analyze(self, input: str, completion: str, context: dict[str, dict[str, bool | str]] | None = None) -> dict,\n",
      "name.docstring: analyze(self, input: str, completion: str, context: dict[str, dict[str, bool | str]] | None=None) -> dict\n",
      "\n",
      "Analyze the input and completion\n",
      "\n",
      "Parameters\n",
      "----------\n",
      "input : str\n",
      "    The input to analyze\n",
      "completion : str\n",
      "    The completion to analyze\n",
      "\n",
      "Returns\n",
      "-------\n",
      "dict\n",
      "    The analysis of the input and completion\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='__main__.GPTReviewAnalyzer_v1._prompt_template', description='def _prompt_template'>>,\n",
      "name.signature: _prompt_template(input: str, completion: str) -> str,\n",
      "name.docstring: _prompt_template(input: str, completion: str) -> str\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='openai.OpenAI', description='class OpenAI'>>,\n",
      "name.signature: Type[OpenAI],\n",
      "name.docstring: OpenAI(*, api_key: str | None=None, organization: str | None=None, base_url: str | httpx.URL | None=None, timeout: Union[float, Timeout, None, NotGiven]=NOT_GIVEN, max_retries: int=DEFAULT_MAX_RETRIES, default_headers: Mapping[str, str] | None=None, default_query: Mapping[str, object] | None=None, http_client: httpx.Client | None=None, _strict_response_validation: bool=False)\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='llmcoder.analyze.Analyzer.Analyzer', description='class Analyzer'>>,\n",
      "name.signature: Type[Analyzer],\n",
      "name.docstring: Analyzer(verbose: bool=False)\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='llmcoder.utils.get_openai_key', description='def get_openai_key'>>,\n",
      "name.signature: get_openai_key(key: str = \"\") -> str,\n",
      "name.docstring: get_openai_key(key: str=\"\") -> str\n",
      "\n",
      "Get OpenAI API key. Try to interpret the key as a key first, then as a path to a file containing the key.\n",
      "Finally, fall back to the default key.txt file or the OPENAI_KEY environment variable.\n",
      "\n",
      "Parameters\n",
      "----------\n",
      "key : str\n",
      "    The key or path to the key file.\n",
      "\n",
      "Returns\n",
      "-------\n",
      "str\n",
      "    The key.\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='llmcoder.utils.get_system_prompt', description='def get_system_prompt'>>,\n",
      "name.signature: get_system_prompt(name: str = \"2023-11-15_GPT-Builder.txt\") -> str,\n",
      "name.docstring: get_system_prompt(name: str=\"2023-11-15_GPT-Builder.txt\") -> str\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='llmcoder.utils.get_system_prompt_dir', description='def get_system_prompt_dir'>>,\n",
      "name.signature: get_system_prompt_dir(*args: str, create: bool = False) -> str,\n",
      "name.docstring: get_system_prompt_dir(*, create: bool=False) -> str\n",
      "\n",
      "Get the path to the system prompts directory.\n",
      "\n",
      "Parameters\n",
      "----------\n",
      "args : str\n",
      "    The path to the system prompts directory.\n",
      "create : bool\n",
      "    Whether to create the directory if it does not exist.\n",
      "\n",
      "Returns\n",
      "-------\n",
      "str\n",
      "    The path to the system prompts directory.\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='__main__.GPTReviewAnalyzer_v1', description='class GPTReviewAnalyzer_v1'>>,\n",
      "name.signature: Type[GPTReviewAnalyzer_v1],\n",
      "name.docstring: GPTReviewAnalyzer_v1(model: str=\"gpt-3.5-turbo\", system_prompt: str | None=None, min_score: int=6, temperature: float=0.2)\n",
      "\n",
      "Concise, professional Python code advisor for targeted feedback.\n",
      "\n",
      "Parameters\n",
      "----------\n",
      "model : str, optional\n",
      "    The model to use, by default \"gpt-3.5-turbo\"\n",
      "system_prompt : str, optional\n",
      "    The system prompt to use, by default `2023-12-02_GPTReviewAnalyzer_v4.txt`, created by GPTBuilder\n",
      "min_score : int, optional\n",
      "    The minimum score to pass the review, by default 6\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='__main__.GPTReviewAnalyzer_v1.__init__', description='def __init__'>>,\n",
      "name.signature: __init__(self, model: str=\"gpt-3.5-turbo\", system_prompt: Optional[str]=None, min_score: int=6, temperature: float=0.2),\n",
      "name.docstring: __init__(self, model: str=\"gpt-3.5-turbo\", system_prompt: str | None=None, min_score: int=6, temperature: float=0.2)\n",
      "\n",
      "Initialize the GPTReviewAnalyzer\n",
      "\n",
      "Parameters\n",
      "----------\n",
      "model : str, optional\n",
      "    The model to use, by default \"gpt-3.5-turbo\"\n",
      "system_prompt : str, optional\n",
      "    The system prompt to use, by default `2023-12-02_GPTReviewAnalyzer_v4.txt`, created by GPTBuilder\n",
      "min_score : int, optional\n",
      "    The minimum score to pass the review, by default 6\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='__main__.GPTReviewAnalyzer_v1.analyze', description='def analyze'>>,\n",
      "name.signature: analyze(self, input: str, completion: str, context: dict[str, dict[str, bool | str]] | None = None) -> dict,\n",
      "name.docstring: analyze(self, input: str, completion: str, context: dict[str, dict[str, bool | str]] | None=None) -> dict\n",
      "\n",
      "Analyze the input and completion\n",
      "\n",
      "Parameters\n",
      "----------\n",
      "input : str\n",
      "    The input to analyze\n",
      "completion : str\n",
      "    The completion to analyze\n",
      "\n",
      "Returns\n",
      "-------\n",
      "dict\n",
      "    The analysis of the input and completion\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='__main__.GPTReviewAnalyzer_v1._prompt_template', description='def _prompt_template'>>,\n",
      "name.signature: _prompt_template(input: str, completion: str) -> str,\n",
      "name.docstring: _prompt_template(input: str, completion: str) -> str\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='openai.OpenAI', description='class OpenAI'>>,\n",
      "name.signature: Type[OpenAI],\n",
      "name.docstring: OpenAI(*, api_key: str | None=None, organization: str | None=None, base_url: str | httpx.URL | None=None, timeout: Union[float, Timeout, None, NotGiven]=NOT_GIVEN, max_retries: int=DEFAULT_MAX_RETRIES, default_headers: Mapping[str, str] | None=None, default_query: Mapping[str, object] | None=None, http_client: httpx.Client | None=None, _strict_response_validation: bool=False)\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='llmcoder.analyze.Analyzer.Analyzer', description='class Analyzer'>>,\n",
      "name.signature: Type[Analyzer],\n",
      "name.docstring: Analyzer(verbose: bool=False)\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='llmcoder.utils.get_openai_key', description='def get_openai_key'>>,\n",
      "name.signature: get_openai_key(key: str = \"\") -> str,\n",
      "name.docstring: get_openai_key(key: str=\"\") -> str\n",
      "\n",
      "Get OpenAI API key. Try to interpret the key as a key first, then as a path to a file containing the key.\n",
      "Finally, fall back to the default key.txt file or the OPENAI_KEY environment variable.\n",
      "\n",
      "Parameters\n",
      "----------\n",
      "key : str\n",
      "    The key or path to the key file.\n",
      "\n",
      "Returns\n",
      "-------\n",
      "str\n",
      "    The key.\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='llmcoder.utils.get_system_prompt', description='def get_system_prompt'>>,\n",
      "name.signature: get_system_prompt(name: str = \"2023-11-15_GPT-Builder.txt\") -> str,\n",
      "name.docstring: get_system_prompt(name: str=\"2023-11-15_GPT-Builder.txt\") -> str\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='llmcoder.utils.get_system_prompt_dir', description='def get_system_prompt_dir'>>,\n",
      "name.signature: get_system_prompt_dir(*args: str, create: bool = False) -> str,\n",
      "name.docstring: get_system_prompt_dir(*, create: bool=False) -> str\n",
      "\n",
      "Get the path to the system prompts directory.\n",
      "\n",
      "Parameters\n",
      "----------\n",
      "args : str\n",
      "    The path to the system prompts directory.\n",
      "create : bool\n",
      "    Whether to create the directory if it does not exist.\n",
      "\n",
      "Returns\n",
      "-------\n",
      "str\n",
      "    The path to the system prompts directory.\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='__main__.GPTReviewAnalyzer_v1', description='class GPTReviewAnalyzer_v1'>>,\n",
      "name.signature: Type[GPTReviewAnalyzer_v1],\n",
      "name.docstring: GPTReviewAnalyzer_v1(model: str=\"gpt-3.5-turbo\", system_prompt: str | None=None, min_score: int=6, temperature: float=0.2)\n",
      "\n",
      "Concise, professional Python code advisor for targeted feedback.\n",
      "\n",
      "Parameters\n",
      "----------\n",
      "model : str, optional\n",
      "    The model to use, by default \"gpt-3.5-turbo\"\n",
      "system_prompt : str, optional\n",
      "    The system prompt to use, by default `2023-12-02_GPTReviewAnalyzer_v4.txt`, created by GPTBuilder\n",
      "min_score : int, optional\n",
      "    The minimum score to pass the review, by default 6\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='__main__.GPTReviewAnalyzer_v1.__init__', description='def __init__'>>,\n",
      "name.signature: __init__(self, model: str=\"gpt-3.5-turbo\", system_prompt: Optional[str]=None, min_score: int=6, temperature: float=0.2),\n",
      "name.docstring: __init__(self, model: str=\"gpt-3.5-turbo\", system_prompt: str | None=None, min_score: int=6, temperature: float=0.2)\n",
      "\n",
      "Initialize the GPTReviewAnalyzer\n",
      "\n",
      "Parameters\n",
      "----------\n",
      "model : str, optional\n",
      "    The model to use, by default \"gpt-3.5-turbo\"\n",
      "system_prompt : str, optional\n",
      "    The system prompt to use, by default `2023-12-02_GPTReviewAnalyzer_v4.txt`, created by GPTBuilder\n",
      "min_score : int, optional\n",
      "    The minimum score to pass the review, by default 6\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='__main__.GPTReviewAnalyzer_v1.analyze', description='def analyze'>>,\n",
      "name.signature: analyze(self, input: str, completion: str, context: dict[str, dict[str, bool | str]] | None = None) -> dict,\n",
      "name.docstring: analyze(self, input: str, completion: str, context: dict[str, dict[str, bool | str]] | None=None) -> dict\n",
      "\n",
      "Analyze the input and completion\n",
      "\n",
      "Parameters\n",
      "----------\n",
      "input : str\n",
      "    The input to analyze\n",
      "completion : str\n",
      "    The completion to analyze\n",
      "\n",
      "Returns\n",
      "-------\n",
      "dict\n",
      "    The analysis of the input and completion\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='__main__.GPTReviewAnalyzer_v1._prompt_template', description='def _prompt_template'>>,\n",
      "name.signature: _prompt_template(input: str, completion: str) -> str,\n",
      "name.docstring: _prompt_template(input: str, completion: str) -> str\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='openai.OpenAI', description='class OpenAI'>>,\n",
      "name.signature: Type[OpenAI],\n",
      "name.docstring: OpenAI(*, api_key: str | None=None, organization: str | None=None, base_url: str | httpx.URL | None=None, timeout: Union[float, Timeout, None, NotGiven]=NOT_GIVEN, max_retries: int=DEFAULT_MAX_RETRIES, default_headers: Mapping[str, str] | None=None, default_query: Mapping[str, object] | None=None, http_client: httpx.Client | None=None, _strict_response_validation: bool=False)\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='llmcoder.analyze.Analyzer.Analyzer', description='class Analyzer'>>,\n",
      "name.signature: Type[Analyzer],\n",
      "name.docstring: Analyzer(verbose: bool=False)\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='llmcoder.utils.get_openai_key', description='def get_openai_key'>>,\n",
      "name.signature: get_openai_key(key: str = \"\") -> str,\n",
      "name.docstring: get_openai_key(key: str=\"\") -> str\n",
      "\n",
      "Get OpenAI API key. Try to interpret the key as a key first, then as a path to a file containing the key.\n",
      "Finally, fall back to the default key.txt file or the OPENAI_KEY environment variable.\n",
      "\n",
      "Parameters\n",
      "----------\n",
      "key : str\n",
      "    The key or path to the key file.\n",
      "\n",
      "Returns\n",
      "-------\n",
      "str\n",
      "    The key.\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='llmcoder.utils.get_system_prompt', description='def get_system_prompt'>>,\n",
      "name.signature: get_system_prompt(name: str = \"2023-11-15_GPT-Builder.txt\") -> str,\n",
      "name.docstring: get_system_prompt(name: str=\"2023-11-15_GPT-Builder.txt\") -> str\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='llmcoder.utils.get_system_prompt_dir', description='def get_system_prompt_dir'>>,\n",
      "name.signature: get_system_prompt_dir(*args: str, create: bool = False) -> str,\n",
      "name.docstring: get_system_prompt_dir(*, create: bool=False) -> str\n",
      "\n",
      "Get the path to the system prompts directory.\n",
      "\n",
      "Parameters\n",
      "----------\n",
      "args : str\n",
      "    The path to the system prompts directory.\n",
      "create : bool\n",
      "    Whether to create the directory if it does not exist.\n",
      "\n",
      "Returns\n",
      "-------\n",
      "str\n",
      "    The path to the system prompts directory.\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='__main__.GPTReviewAnalyzer_v1', description='class GPTReviewAnalyzer_v1'>>,\n",
      "name.signature: Type[GPTReviewAnalyzer_v1],\n",
      "name.docstring: GPTReviewAnalyzer_v1(model: str=\"gpt-3.5-turbo\", system_prompt: str | None=None, min_score: int=6, temperature: float=0.2)\n",
      "\n",
      "Concise, professional Python code advisor for targeted feedback.\n",
      "\n",
      "Parameters\n",
      "----------\n",
      "model : str, optional\n",
      "    The model to use, by default \"gpt-3.5-turbo\"\n",
      "system_prompt : str, optional\n",
      "    The system prompt to use, by default `2023-12-02_GPTReviewAnalyzer_v4.txt`, created by GPTBuilder\n",
      "min_score : int, optional\n",
      "    The minimum score to pass the review, by default 6\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='__main__.GPTReviewAnalyzer_v1.__init__', description='def __init__'>>,\n",
      "name.signature: __init__(self, model: str=\"gpt-3.5-turbo\", system_prompt: Optional[str]=None, min_score: int=6, temperature: float=0.2),\n",
      "name.docstring: __init__(self, model: str=\"gpt-3.5-turbo\", system_prompt: str | None=None, min_score: int=6, temperature: float=0.2)\n",
      "\n",
      "Initialize the GPTReviewAnalyzer\n",
      "\n",
      "Parameters\n",
      "----------\n",
      "model : str, optional\n",
      "    The model to use, by default \"gpt-3.5-turbo\"\n",
      "system_prompt : str, optional\n",
      "    The system prompt to use, by default `2023-12-02_GPTReviewAnalyzer_v4.txt`, created by GPTBuilder\n",
      "min_score : int, optional\n",
      "    The minimum score to pass the review, by default 6\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='__main__.GPTReviewAnalyzer_v1.analyze', description='def analyze'>>,\n",
      "name.signature: analyze(self, input: str, completion: str, context: dict[str, dict[str, bool | str]] | None = None) -> dict,\n",
      "name.docstring: analyze(self, input: str, completion: str, context: dict[str, dict[str, bool | str]] | None=None) -> dict\n",
      "\n",
      "Analyze the input and completion\n",
      "\n",
      "Parameters\n",
      "----------\n",
      "input : str\n",
      "    The input to analyze\n",
      "completion : str\n",
      "    The completion to analyze\n",
      "\n",
      "Returns\n",
      "-------\n",
      "dict\n",
      "    The analysis of the input and completion\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='__main__.GPTReviewAnalyzer_v1._prompt_template', description='def _prompt_template'>>,\n",
      "name.signature: _prompt_template(input: str, completion: str) -> str,\n",
      "name.docstring: _prompt_template(input: str, completion: str) -> str\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='openai.OpenAI', description='class OpenAI'>>,\n",
      "name.signature: Type[OpenAI],\n",
      "name.docstring: OpenAI(*, api_key: str | None=None, organization: str | None=None, base_url: str | httpx.URL | None=None, timeout: Union[float, Timeout, None, NotGiven]=NOT_GIVEN, max_retries: int=DEFAULT_MAX_RETRIES, default_headers: Mapping[str, str] | None=None, default_query: Mapping[str, object] | None=None, http_client: httpx.Client | None=None, _strict_response_validation: bool=False)\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='llmcoder.analyze.Analyzer.Analyzer', description='class Analyzer'>>,\n",
      "name.signature: Type[Analyzer],\n",
      "name.docstring: Analyzer(verbose: bool=False)\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='llmcoder.utils.get_openai_key', description='def get_openai_key'>>,\n",
      "name.signature: get_openai_key(key: str = \"\") -> str,\n",
      "name.docstring: get_openai_key(key: str=\"\") -> str\n",
      "\n",
      "Get OpenAI API key. Try to interpret the key as a key first, then as a path to a file containing the key.\n",
      "Finally, fall back to the default key.txt file or the OPENAI_KEY environment variable.\n",
      "\n",
      "Parameters\n",
      "----------\n",
      "key : str\n",
      "    The key or path to the key file.\n",
      "\n",
      "Returns\n",
      "-------\n",
      "str\n",
      "    The key.\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='llmcoder.utils.get_system_prompt', description='def get_system_prompt'>>,\n",
      "name.signature: get_system_prompt(name: str = \"2023-11-15_GPT-Builder.txt\") -> str,\n",
      "name.docstring: get_system_prompt(name: str=\"2023-11-15_GPT-Builder.txt\") -> str\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='llmcoder.utils.get_system_prompt_dir', description='def get_system_prompt_dir'>>,\n",
      "name.signature: get_system_prompt_dir(*args: str, create: bool = False) -> str,\n",
      "name.docstring: get_system_prompt_dir(*, create: bool=False) -> str\n",
      "\n",
      "Get the path to the system prompts directory.\n",
      "\n",
      "Parameters\n",
      "----------\n",
      "args : str\n",
      "    The path to the system prompts directory.\n",
      "create : bool\n",
      "    Whether to create the directory if it does not exist.\n",
      "\n",
      "Returns\n",
      "-------\n",
      "str\n",
      "    The path to the system prompts directory.\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='__main__.GPTReviewAnalyzer_v1', description='class GPTReviewAnalyzer_v1'>>,\n",
      "name.signature: Type[GPTReviewAnalyzer_v1],\n",
      "name.docstring: GPTReviewAnalyzer_v1(model: str=\"gpt-3.5-turbo\", system_prompt: str | None=None, min_score: int=6, temperature: float=0.2)\n",
      "\n",
      "Concise, professional Python code advisor for targeted feedback.\n",
      "\n",
      "Parameters\n",
      "----------\n",
      "model : str, optional\n",
      "    The model to use, by default \"gpt-3.5-turbo\"\n",
      "system_prompt : str, optional\n",
      "    The system prompt to use, by default `2023-12-02_GPTReviewAnalyzer_v4.txt`, created by GPTBuilder\n",
      "min_score : int, optional\n",
      "    The minimum score to pass the review, by default 6\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='__main__.GPTReviewAnalyzer_v1.__init__', description='def __init__'>>,\n",
      "name.signature: __init__(self, model: str=\"gpt-3.5-turbo\", system_prompt: Optional[str]=None, min_score: int=6, temperature: float=0.2),\n",
      "name.docstring: __init__(self, model: str=\"gpt-3.5-turbo\", system_prompt: str | None=None, min_score: int=6, temperature: float=0.2)\n",
      "\n",
      "Initialize the GPTReviewAnalyzer\n",
      "\n",
      "Parameters\n",
      "----------\n",
      "model : str, optional\n",
      "    The model to use, by default \"gpt-3.5-turbo\"\n",
      "system_prompt : str, optional\n",
      "    The system prompt to use, by default `2023-12-02_GPTReviewAnalyzer_v4.txt`, created by GPTBuilder\n",
      "min_score : int, optional\n",
      "    The minimum score to pass the review, by default 6\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='__main__.GPTReviewAnalyzer_v1.analyze', description='def analyze'>>,\n",
      "name.signature: analyze(self, input: str, completion: str, context: dict[str, dict[str, bool | str]] | None = None) -> dict,\n",
      "name.docstring: analyze(self, input: str, completion: str, context: dict[str, dict[str, bool | str]] | None=None) -> dict\n",
      "\n",
      "Analyze the input and completion\n",
      "\n",
      "Parameters\n",
      "----------\n",
      "input : str\n",
      "    The input to analyze\n",
      "completion : str\n",
      "    The completion to analyze\n",
      "\n",
      "Returns\n",
      "-------\n",
      "dict\n",
      "    The analysis of the input and completion\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='__main__.GPTReviewAnalyzer_v1._prompt_template', description='def _prompt_template'>>,\n",
      "name.signature: _prompt_template(input: str, completion: str) -> str,\n",
      "name.docstring: _prompt_template(input: str, completion: str) -> str\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='openai.OpenAI', description='class OpenAI'>>,\n",
      "name.signature: Type[OpenAI],\n",
      "name.docstring: OpenAI(*, api_key: str | None=None, organization: str | None=None, base_url: str | httpx.URL | None=None, timeout: Union[float, Timeout, None, NotGiven]=NOT_GIVEN, max_retries: int=DEFAULT_MAX_RETRIES, default_headers: Mapping[str, str] | None=None, default_query: Mapping[str, object] | None=None, http_client: httpx.Client | None=None, _strict_response_validation: bool=False)\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='llmcoder.analyze.Analyzer.Analyzer', description='class Analyzer'>>,\n",
      "name.signature: Type[Analyzer],\n",
      "name.docstring: Analyzer(verbose: bool=False)\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='llmcoder.utils.get_openai_key', description='def get_openai_key'>>,\n",
      "name.signature: get_openai_key(key: str = \"\") -> str,\n",
      "name.docstring: get_openai_key(key: str=\"\") -> str\n",
      "\n",
      "Get OpenAI API key. Try to interpret the key as a key first, then as a path to a file containing the key.\n",
      "Finally, fall back to the default key.txt file or the OPENAI_KEY environment variable.\n",
      "\n",
      "Parameters\n",
      "----------\n",
      "key : str\n",
      "    The key or path to the key file.\n",
      "\n",
      "Returns\n",
      "-------\n",
      "str\n",
      "    The key.\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='llmcoder.utils.get_system_prompt', description='def get_system_prompt'>>,\n",
      "name.signature: get_system_prompt(name: str = \"2023-11-15_GPT-Builder.txt\") -> str,\n",
      "name.docstring: get_system_prompt(name: str=\"2023-11-15_GPT-Builder.txt\") -> str\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='llmcoder.utils.get_system_prompt_dir', description='def get_system_prompt_dir'>>,\n",
      "name.signature: get_system_prompt_dir(*args: str, create: bool = False) -> str,\n",
      "name.docstring: get_system_prompt_dir(*, create: bool=False) -> str\n",
      "\n",
      "Get the path to the system prompts directory.\n",
      "\n",
      "Parameters\n",
      "----------\n",
      "args : str\n",
      "    The path to the system prompts directory.\n",
      "create : bool\n",
      "    Whether to create the directory if it does not exist.\n",
      "\n",
      "Returns\n",
      "-------\n",
      "str\n",
      "    The path to the system prompts directory.\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='__main__.GPTReviewAnalyzer_v1', description='class GPTReviewAnalyzer_v1'>>,\n",
      "name.signature: Type[GPTReviewAnalyzer_v1],\n",
      "name.docstring: GPTReviewAnalyzer_v1(model: str=\"gpt-3.5-turbo\", system_prompt: str | None=None, min_score: int=6, temperature: float=0.2)\n",
      "\n",
      "Concise, professional Python code advisor for targeted feedback.\n",
      "\n",
      "Parameters\n",
      "----------\n",
      "model : str, optional\n",
      "    The model to use, by default \"gpt-3.5-turbo\"\n",
      "system_prompt : str, optional\n",
      "    The system prompt to use, by default `2023-12-02_GPTReviewAnalyzer_v4.txt`, created by GPTBuilder\n",
      "min_score : int, optional\n",
      "    The minimum score to pass the review, by default 6\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='__main__.GPTReviewAnalyzer_v1.__init__', description='def __init__'>>,\n",
      "name.signature: __init__(self, model: str=\"gpt-3.5-turbo\", system_prompt: Optional[str]=None, min_score: int=6, temperature: float=0.2),\n",
      "name.docstring: __init__(self, model: str=\"gpt-3.5-turbo\", system_prompt: str | None=None, min_score: int=6, temperature: float=0.2)\n",
      "\n",
      "Initialize the GPTReviewAnalyzer\n",
      "\n",
      "Parameters\n",
      "----------\n",
      "model : str, optional\n",
      "    The model to use, by default \"gpt-3.5-turbo\"\n",
      "system_prompt : str, optional\n",
      "    The system prompt to use, by default `2023-12-02_GPTReviewAnalyzer_v4.txt`, created by GPTBuilder\n",
      "min_score : int, optional\n",
      "    The minimum score to pass the review, by default 6\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='__main__.GPTReviewAnalyzer_v1.analyze', description='def analyze'>>,\n",
      "name.signature: analyze(self, input: str, completion: str, context: dict[str, dict[str, bool | str]] | None = None) -> dict,\n",
      "name.docstring: analyze(self, input: str, completion: str, context: dict[str, dict[str, bool | str]] | None=None) -> dict\n",
      "\n",
      "Analyze the input and completion\n",
      "\n",
      "Parameters\n",
      "----------\n",
      "input : str\n",
      "    The input to analyze\n",
      "completion : str\n",
      "    The completion to analyze\n",
      "\n",
      "Returns\n",
      "-------\n",
      "dict\n",
      "    The analysis of the input and completion\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='__main__.GPTReviewAnalyzer_v1._prompt_template', description='def _prompt_template'>>,\n",
      "name.signature: _prompt_template(input: str, completion: str) -> str,\n",
      "name.docstring: _prompt_template(input: str, completion: str) -> str\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='openai.OpenAI', description='class OpenAI'>>,\n",
      "name.signature: Type[OpenAI],\n",
      "name.docstring: OpenAI(*, api_key: str | None=None, organization: str | None=None, base_url: str | httpx.URL | None=None, timeout: Union[float, Timeout, None, NotGiven]=NOT_GIVEN, max_retries: int=DEFAULT_MAX_RETRIES, default_headers: Mapping[str, str] | None=None, default_query: Mapping[str, object] | None=None, http_client: httpx.Client | None=None, _strict_response_validation: bool=False)\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='llmcoder.analyze.Analyzer.Analyzer', description='class Analyzer'>>,\n",
      "name.signature: Type[Analyzer],\n",
      "name.docstring: Analyzer(verbose: bool=False)\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='llmcoder.utils.get_openai_key', description='def get_openai_key'>>,\n",
      "name.signature: get_openai_key(key: str = \"\") -> str,\n",
      "name.docstring: get_openai_key(key: str=\"\") -> str\n",
      "\n",
      "Get OpenAI API key. Try to interpret the key as a key first, then as a path to a file containing the key.\n",
      "Finally, fall back to the default key.txt file or the OPENAI_KEY environment variable.\n",
      "\n",
      "Parameters\n",
      "----------\n",
      "key : str\n",
      "    The key or path to the key file.\n",
      "\n",
      "Returns\n",
      "-------\n",
      "str\n",
      "    The key.\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='llmcoder.utils.get_system_prompt', description='def get_system_prompt'>>,\n",
      "name.signature: get_system_prompt(name: str = \"2023-11-15_GPT-Builder.txt\") -> str,\n",
      "name.docstring: get_system_prompt(name: str=\"2023-11-15_GPT-Builder.txt\") -> str\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='llmcoder.utils.get_system_prompt_dir', description='def get_system_prompt_dir'>>,\n",
      "name.signature: get_system_prompt_dir(*args: str, create: bool = False) -> str,\n",
      "name.docstring: get_system_prompt_dir(*, create: bool=False) -> str\n",
      "\n",
      "Get the path to the system prompts directory.\n",
      "\n",
      "Parameters\n",
      "----------\n",
      "args : str\n",
      "    The path to the system prompts directory.\n",
      "create : bool\n",
      "    Whether to create the directory if it does not exist.\n",
      "\n",
      "Returns\n",
      "-------\n",
      "str\n",
      "    The path to the system prompts directory.\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='__main__.GPTReviewAnalyzer_v1', description='class GPTReviewAnalyzer_v1'>>,\n",
      "name.signature: Type[GPTReviewAnalyzer_v1],\n",
      "name.docstring: GPTReviewAnalyzer_v1(model: str=\"gpt-3.5-turbo\", system_prompt: str | None=None, min_score: int=6, temperature: float=0.2)\n",
      "\n",
      "Concise, professional Python code advisor for targeted feedback.\n",
      "\n",
      "Parameters\n",
      "----------\n",
      "model : str, optional\n",
      "    The model to use, by default \"gpt-3.5-turbo\"\n",
      "system_prompt : str, optional\n",
      "    The system prompt to use, by default `2023-12-02_GPTReviewAnalyzer_v4.txt`, created by GPTBuilder\n",
      "min_score : int, optional\n",
      "    The minimum score to pass the review, by default 6\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='__main__.GPTReviewAnalyzer_v1.__init__', description='def __init__'>>,\n",
      "name.signature: __init__(self, model: str=\"gpt-3.5-turbo\", system_prompt: Optional[str]=None, min_score: int=6, temperature: float=0.2),\n",
      "name.docstring: __init__(self, model: str=\"gpt-3.5-turbo\", system_prompt: str | None=None, min_score: int=6, temperature: float=0.2)\n",
      "\n",
      "Initialize the GPTReviewAnalyzer\n",
      "\n",
      "Parameters\n",
      "----------\n",
      "model : str, optional\n",
      "    The model to use, by default \"gpt-3.5-turbo\"\n",
      "system_prompt : str, optional\n",
      "    The system prompt to use, by default `2023-12-02_GPTReviewAnalyzer_v4.txt`, created by GPTBuilder\n",
      "min_score : int, optional\n",
      "    The minimum score to pass the review, by default 6\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='__main__.GPTReviewAnalyzer_v1.analyze', description='def analyze'>>,\n",
      "name.signature: analyze(self, input: str, completion: str, context: dict[str, dict[str, bool | str]] | None = None) -> dict,\n",
      "name.docstring: analyze(self, input: str, completion: str, context: dict[str, dict[str, bool | str]] | None=None) -> dict\n",
      "\n",
      "Analyze the input and completion\n",
      "\n",
      "Parameters\n",
      "----------\n",
      "input : str\n",
      "    The input to analyze\n",
      "completion : str\n",
      "    The completion to analyze\n",
      "\n",
      "Returns\n",
      "-------\n",
      "dict\n",
      "    The analysis of the input and completion\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='__main__.GPTReviewAnalyzer_v1._prompt_template', description='def _prompt_template'>>,\n",
      "name.signature: _prompt_template(input: str, completion: str) -> str,\n",
      "name.docstring: _prompt_template(input: str, completion: str) -> str\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='openai.OpenAI', description='class OpenAI'>>,\n",
      "name.signature: Type[OpenAI],\n",
      "name.docstring: OpenAI(*, api_key: str | None=None, organization: str | None=None, base_url: str | httpx.URL | None=None, timeout: Union[float, Timeout, None, NotGiven]=NOT_GIVEN, max_retries: int=DEFAULT_MAX_RETRIES, default_headers: Mapping[str, str] | None=None, default_query: Mapping[str, object] | None=None, http_client: httpx.Client | None=None, _strict_response_validation: bool=False)\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='llmcoder.analyze.Analyzer.Analyzer', description='class Analyzer'>>,\n",
      "name.signature: Type[Analyzer],\n",
      "name.docstring: Analyzer(verbose: bool=False)\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='llmcoder.utils.get_openai_key', description='def get_openai_key'>>,\n",
      "name.signature: get_openai_key(key: str = \"\") -> str,\n",
      "name.docstring: get_openai_key(key: str=\"\") -> str\n",
      "\n",
      "Get OpenAI API key. Try to interpret the key as a key first, then as a path to a file containing the key.\n",
      "Finally, fall back to the default key.txt file or the OPENAI_KEY environment variable.\n",
      "\n",
      "Parameters\n",
      "----------\n",
      "key : str\n",
      "    The key or path to the key file.\n",
      "\n",
      "Returns\n",
      "-------\n",
      "str\n",
      "    The key.\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='llmcoder.utils.get_system_prompt', description='def get_system_prompt'>>,\n",
      "name.signature: get_system_prompt(name: str = \"2023-11-15_GPT-Builder.txt\") -> str,\n",
      "name.docstring: get_system_prompt(name: str=\"2023-11-15_GPT-Builder.txt\") -> str\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='llmcoder.utils.get_system_prompt_dir', description='def get_system_prompt_dir'>>,\n",
      "name.signature: get_system_prompt_dir(*args: str, create: bool = False) -> str,\n",
      "name.docstring: get_system_prompt_dir(*, create: bool=False) -> str\n",
      "\n",
      "Get the path to the system prompts directory.\n",
      "\n",
      "Parameters\n",
      "----------\n",
      "args : str\n",
      "    The path to the system prompts directory.\n",
      "create : bool\n",
      "    Whether to create the directory if it does not exist.\n",
      "\n",
      "Returns\n",
      "-------\n",
      "str\n",
      "    The path to the system prompts directory.\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='__main__.GPTReviewAnalyzer_v1', description='class GPTReviewAnalyzer_v1'>>,\n",
      "name.signature: Type[GPTReviewAnalyzer_v1],\n",
      "name.docstring: GPTReviewAnalyzer_v1(model: str=\"gpt-3.5-turbo\", system_prompt: str | None=None, min_score: int=6, temperature: float=0.2)\n",
      "\n",
      "Concise, professional Python code advisor for targeted feedback.\n",
      "\n",
      "Parameters\n",
      "----------\n",
      "model : str, optional\n",
      "    The model to use, by default \"gpt-3.5-turbo\"\n",
      "system_prompt : str, optional\n",
      "    The system prompt to use, by default `2023-12-02_GPTReviewAnalyzer_v4.txt`, created by GPTBuilder\n",
      "min_score : int, optional\n",
      "    The minimum score to pass the review, by default 6\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='__main__.GPTReviewAnalyzer_v1.__init__', description='def __init__'>>,\n",
      "name.signature: __init__(self, model: str=\"gpt-3.5-turbo\", system_prompt: Optional[str]=None, min_score: int=6, temperature: float=0.2),\n",
      "name.docstring: __init__(self, model: str=\"gpt-3.5-turbo\", system_prompt: str | None=None, min_score: int=6, temperature: float=0.2)\n",
      "\n",
      "Initialize the GPTReviewAnalyzer\n",
      "\n",
      "Parameters\n",
      "----------\n",
      "model : str, optional\n",
      "    The model to use, by default \"gpt-3.5-turbo\"\n",
      "system_prompt : str, optional\n",
      "    The system prompt to use, by default `2023-12-02_GPTReviewAnalyzer_v4.txt`, created by GPTBuilder\n",
      "min_score : int, optional\n",
      "    The minimum score to pass the review, by default 6\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='__main__.GPTReviewAnalyzer_v1.analyze', description='def analyze'>>,\n",
      "name.signature: analyze(self, input: str, completion: str, context: dict[str, dict[str, bool | str]] | None = None) -> dict,\n",
      "name.docstring: analyze(self, input: str, completion: str, context: dict[str, dict[str, bool | str]] | None=None) -> dict\n",
      "\n",
      "Analyze the input and completion\n",
      "\n",
      "Parameters\n",
      "----------\n",
      "input : str\n",
      "    The input to analyze\n",
      "completion : str\n",
      "    The completion to analyze\n",
      "\n",
      "Returns\n",
      "-------\n",
      "dict\n",
      "    The analysis of the input and completion\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='__main__.GPTReviewAnalyzer_v1._prompt_template', description='def _prompt_template'>>,\n",
      "name.signature: _prompt_template(input: str, completion: str) -> str,\n",
      "name.docstring: _prompt_template(input: str, completion: str) -> str\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='openai.OpenAI', description='class OpenAI'>>,\n",
      "name.signature: Type[OpenAI],\n",
      "name.docstring: OpenAI(*, api_key: str | None=None, organization: str | None=None, base_url: str | httpx.URL | None=None, timeout: Union[float, Timeout, None, NotGiven]=NOT_GIVEN, max_retries: int=DEFAULT_MAX_RETRIES, default_headers: Mapping[str, str] | None=None, default_query: Mapping[str, object] | None=None, http_client: httpx.Client | None=None, _strict_response_validation: bool=False)\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='llmcoder.analyze.Analyzer.Analyzer', description='class Analyzer'>>,\n",
      "name.signature: Type[Analyzer],\n",
      "name.docstring: Analyzer(verbose: bool=False)\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='llmcoder.utils.get_openai_key', description='def get_openai_key'>>,\n",
      "name.signature: get_openai_key(key: str = \"\") -> str,\n",
      "name.docstring: get_openai_key(key: str=\"\") -> str\n",
      "\n",
      "Get OpenAI API key. Try to interpret the key as a key first, then as a path to a file containing the key.\n",
      "Finally, fall back to the default key.txt file or the OPENAI_KEY environment variable.\n",
      "\n",
      "Parameters\n",
      "----------\n",
      "key : str\n",
      "    The key or path to the key file.\n",
      "\n",
      "Returns\n",
      "-------\n",
      "str\n",
      "    The key.\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='llmcoder.utils.get_system_prompt', description='def get_system_prompt'>>,\n",
      "name.signature: get_system_prompt(name: str = \"2023-11-15_GPT-Builder.txt\") -> str,\n",
      "name.docstring: get_system_prompt(name: str=\"2023-11-15_GPT-Builder.txt\") -> str\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='llmcoder.utils.get_system_prompt_dir', description='def get_system_prompt_dir'>>,\n",
      "name.signature: get_system_prompt_dir(*args: str, create: bool = False) -> str,\n",
      "name.docstring: get_system_prompt_dir(*, create: bool=False) -> str\n",
      "\n",
      "Get the path to the system prompts directory.\n",
      "\n",
      "Parameters\n",
      "----------\n",
      "args : str\n",
      "    The path to the system prompts directory.\n",
      "create : bool\n",
      "    Whether to create the directory if it does not exist.\n",
      "\n",
      "Returns\n",
      "-------\n",
      "str\n",
      "    The path to the system prompts directory.\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='__main__.GPTReviewAnalyzer_v1', description='class GPTReviewAnalyzer_v1'>>,\n",
      "name.signature: Type[GPTReviewAnalyzer_v1],\n",
      "name.docstring: GPTReviewAnalyzer_v1(model: str=\"gpt-3.5-turbo\", system_prompt: str | None=None, min_score: int=6, temperature: float=0.2)\n",
      "\n",
      "Concise, professional Python code advisor for targeted feedback.\n",
      "\n",
      "Parameters\n",
      "----------\n",
      "model : str, optional\n",
      "    The model to use, by default \"gpt-3.5-turbo\"\n",
      "system_prompt : str, optional\n",
      "    The system prompt to use, by default `2023-12-02_GPTReviewAnalyzer_v4.txt`, created by GPTBuilder\n",
      "min_score : int, optional\n",
      "    The minimum score to pass the review, by default 6\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='__main__.GPTReviewAnalyzer_v1.__init__', description='def __init__'>>,\n",
      "name.signature: __init__(self, model: str=\"gpt-3.5-turbo\", system_prompt: Optional[str]=None, min_score: int=6, temperature: float=0.2),\n",
      "name.docstring: __init__(self, model: str=\"gpt-3.5-turbo\", system_prompt: str | None=None, min_score: int=6, temperature: float=0.2)\n",
      "\n",
      "Initialize the GPTReviewAnalyzer\n",
      "\n",
      "Parameters\n",
      "----------\n",
      "model : str, optional\n",
      "    The model to use, by default \"gpt-3.5-turbo\"\n",
      "system_prompt : str, optional\n",
      "    The system prompt to use, by default `2023-12-02_GPTReviewAnalyzer_v4.txt`, created by GPTBuilder\n",
      "min_score : int, optional\n",
      "    The minimum score to pass the review, by default 6\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='__main__.GPTReviewAnalyzer_v1.analyze', description='def analyze'>>,\n",
      "name.signature: analyze(self, input: str, completion: str, context: dict[str, dict[str, bool | str]] | None = None) -> dict,\n",
      "name.docstring: analyze(self, input: str, completion: str, context: dict[str, dict[str, bool | str]] | None=None) -> dict\n",
      "\n",
      "Analyze the input and completion\n",
      "\n",
      "Parameters\n",
      "----------\n",
      "input : str\n",
      "    The input to analyze\n",
      "completion : str\n",
      "    The completion to analyze\n",
      "\n",
      "Returns\n",
      "-------\n",
      "dict\n",
      "    The analysis of the input and completion\n",
      "[JediAnalyzer] name.fullname: <bound method BaseName.docstring of <Name full_name='__main__.GPTReviewAnalyzer_v1._prompt_template', description='def _prompt_template'>>,\n",
      "name.signature: _prompt_template(input: str, completion: str) -> str,\n",
      "name.docstring: _prompt_template(input: str, completion: str) -> str\n",
      "84.5 ms ± 4.04 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "jedi = JediAnalyzer()\n",
    "jedi.analyze(code, completion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "mypy = MypyAnalyzer()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "58.6 µs ± 2.32 µs per loop (mean ± std. dev. of 7 runs, 10,000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "sig = SignatureAnalyzer()\n",
    "sig.analyze(code, completion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llmcoder.analyze import MypyAnalyzer, JediAnalyzer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mypy = MypyAnalyzer(code, completion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jedi = JediAnalyzer(code, completion)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llmcoder.env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
