{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Have GitHub copilot completions in\n",
    "# level_0/eval/github_copilot/completion*.txt\n",
    "\n",
    "# Need to create level_0/github_copilot/results.json with\n",
    "# \"0\": {\n",
    "#         \"messages\": [\n",
    "#             {\n",
    "#                 \"role\": \"user\",\n",
    "#                 \"content\": \"<USER_CODE>\"\n",
    "#             },\n",
    "#             {\n",
    "#                 \"role\": \"assistant\",\n",
    "#                 \"content\": \"<COMPLETION>\"\n",
    "#             }\n",
    "#         ],\n",
    "#         \"analyzer_results\": [\n",
    "#             <ANALYZER_RESULTS>\n",
    "#         ],\n",
    "#         \"log\": \"\",\n",
    "#         \"time\": -1,\n",
    "#         \"n_tokens_generated\": -1\n",
    "#     },\n",
    "#\n",
    "# for each completion in level_0/eval/github_copilot/completion*.txt and user code in level_0/pairs/pair*/input.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import re\n",
    "from tqdm import tqdm\n",
    "import datetime\n",
    "\n",
    "from llmcoder.utils import get_data_dir\n",
    "from llmcoder.analyze import MypyAnalyzer, GPTScoreAnalyzer\n",
    "\n",
    "import tiktoken"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Format Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "levels = [0, 1, 2]\n",
    "\n",
    "enc = tiktoken.get_encoding('p50k_base')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_inputs =  {f'level_{level}': {} for level in levels}\n",
    "completions = {f'level_{level}': {} for level in levels}\n",
    "for level in levels:\n",
    "    for run in os.listdir(get_data_dir('LLMcoder-Eval', f'level_{level}', 'eval', f'level_{level}__github_copilot')):\n",
    "        completions[f'level_{level}'][run] = {}\n",
    "        user_inputs[f'level_{level}'][run] = {}\n",
    "\n",
    "        for completion in os.listdir(get_data_dir('LLMcoder-Eval', f'level_{level}', 'eval', f'level_{level}__github_copilot', run, 'completions')):\n",
    "\n",
    "            if not completion.startswith('completion'):  # Skip other files (results.json for example)\n",
    "                continue\n",
    "            id = int(re.match(r'completion(\\d+).txt', completion).group(1)) - 1  # 0-indexed\n",
    "\n",
    "            with open(os.path.join(get_data_dir('LLMcoder-Eval', f'level_{level}', 'eval', f'level_{level}__github_copilot', run, 'completions', completion))) as f:\n",
    "                completions[f'level_{level}'][run][f'{id}'] = f.read()\n",
    "\n",
    "            with open(os.path.join(get_data_dir('LLMcoder-Eval', f'level_{level}', 'pairs', f'pair{id + 1}', 'input.txt'))) as f:\n",
    "                user_inputs[f'level_{level}'][run][f'{id}'] = f.read()\n",
    "\n",
    "# Sort the completions by and user inputs by id\n",
    "for level in levels:\n",
    "    for run in completions[f'level_{level}']:\n",
    "        completions[f'level_{level}'][run] = {k: v for k, v in sorted(completions[f'level_{level}'][run].items(), key=lambda item: int(item[0]))}\n",
    "        user_inputs[f'level_{level}'][run] = {k: v for k, v in sorted(user_inputs[f'level_{level}'][run].items(), key=lambda item: int(item[0]))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:06<00:00,  1.52s/it]\n",
      "100%|██████████| 9/9 [00:23<00:00,  2.65s/it]\n",
      "100%|██████████| 11/11 [00:19<00:00,  1.75s/it]\n"
     ]
    }
   ],
   "source": [
    "json_results = {f'level_{level}': {} for level in levels}\n",
    "\n",
    "for level in levels:\n",
    "    for run in completions[f'level_{level}']:\n",
    "        json_results[f'level_{level}'][run] = {}\n",
    "\n",
    "        for id, user_input in tqdm(user_inputs[f'level_{level}'][run].items()):\n",
    "            json_results[f'level_{level}'][run][f'{id}'] = {\n",
    "                \"messages\": [\n",
    "                    {\n",
    "                        \"role\": \"user\",\n",
    "                        \"content\": user_input\n",
    "                    },\n",
    "                    {\n",
    "                        \"role\": \"assistant\",\n",
    "                        \"content\": completions[f'level_{level}'][run][f'{id}']\n",
    "                    }\n",
    "                ],\n",
    "                \"analyzer_results\": [\n",
    "                    {\n",
    "                        \"mypy_analyzer_v1\": MypyAnalyzer().analyze(input=user_input, completion=completions[f'level_{level}'][run][f'{id}']),\n",
    "                        \"gpt_score_analyzer_v1\": GPTScoreAnalyzer(verbose=True).analyze(input=user_input, completion=completions[f'level_{level}'][run][f'{id}'])\n",
    "                    }\n",
    "                ],\n",
    "                \"log\": \"\",\n",
    "                \"time\": -1,\n",
    "                \"n_tokens_generated\": len(enc.encode(completions[f'level_{level}'][run][f'{id}']))\n",
    "            }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save results\n",
    "current_date = datetime.datetime.now().strftime('%Y-%m-%d_%H-%M-%S')\n",
    "for level in levels:\n",
    "    for run in completions[f'level_{level}']:\n",
    "        os.makedirs(os.path.join(get_data_dir('LLMcoder-Eval', f'level_{level}', 'eval', f'level_{level}__github_copilot', run)), exist_ok=True)\n",
    "        with open(os.path.join(get_data_dir('LLMcoder-Eval', f'level_{level}', 'eval', f'level_{level}__github_copilot', run, 'results.json')), 'w') as f:\n",
    "            json.dump(json_results[f'level_{level}'][run], f, indent=4, ensure_ascii=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llmcoder.eval.evaluate import Metrics\n",
    "from dynaconf import Dynaconf\n",
    "\n",
    "levels = [0, 1, 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "configs = [Dynaconf(\n",
    "        environments=True,\n",
    "        analyzers=[\"mypy_analyzer_v1\", \"signature_analyzer_v1\", \"gpt_score_analyzer_v1\"],\n",
    "        model_first=\"ft:gpt-3.5-turbo-1106:personal::8LCi9Q0d\",\n",
    "        model_feedback=\"ft:gpt-3.5-turbo-1106:personal::8LCi9Q0d\",\n",
    "        feedback_variant=\"coworker\",\n",
    "        system_prompt=\"2023-11-15_GPT-Builder.txt\",\n",
    "        dataset=f\"LLMcoder-Eval/level_{i}\",\n",
    "        max_iter=5,\n",
    "        log_conversation=True,\n",
    "        scores=[\n",
    "            \"extrinsic.levenshtein_distance_score\",\n",
    "            \"extrinsic.bleu_score\",\n",
    "            \"extrinsic.trf_similarity_score\",\n",
    "            \"extrinsic.sequence_matcher_score\",\n",
    "            \"extrinsic.gpt_reviewer_score\",\n",
    "            \"intrinsic.loops_required_score\",\n",
    "            \"intrinsic.tokens_used_score\",\n",
    "            \"intrinsic.agility_score\",\n",
    "            \"intrinsic.time_score\",\n",
    "            \"intrinsic.all_analyzers_passed_score\",\n",
    "            \"intrinsic.total_tokens_generated_score\"\n",
    "        ],\n",
    "        n_choices=3,\n",
    "        n_procs=3,\n",
    "        backtracking=True,\n",
    "        settings_file=[f'level_{i}__github_copilot.yaml']\n",
    "    ) for i in levels]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Set up metrics with configurations:\n",
      "\t- level_0__github_copilot.yaml\n",
      "Analyzing results for configuration: level_0__github_copilot.yaml\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Analysis: total_tokens_generated_score: 100%|██████████| 4/4 [00:20<00:00,  5.10s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Set up metrics with configurations:\n",
      "\t- level_1__github_copilot.yaml\n",
      "Analyzing results for configuration: level_1__github_copilot.yaml\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Analysis: total_tokens_generated_score: 100%|██████████| 9/9 [00:43<00:00,  4.88s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Set up metrics with configurations:\n",
      "\t- level_2__github_copilot.yaml\n",
      "Analyzing results for configuration: level_2__github_copilot.yaml\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Analysis: total_tokens_generated_score: 100%|██████████| 11/11 [00:59<00:00,  5.44s/it]\n"
     ]
    }
   ],
   "source": [
    "for config in configs:\n",
    "    metrics = Metrics(config)\n",
    "    metrics.run(store=True, index=None, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llmcoder",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
