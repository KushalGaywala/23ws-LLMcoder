{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "from llmcoder.utils import get_openai_key, get_system_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bertopic import BERTopic\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = OpenAI(api_key=get_openai_key())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "code = \"\"\"# General imports\n",
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import spacy\n",
    "import matplotlib\n",
    "from wordcloud import WordCloud\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "# Custom imports\n",
    "from tqdm import tqdm\n",
    "from collections import Counter\n",
    "\n",
    "# Ensure matplotlib works correctly with Jupyter\n",
    "%matplotlib inline\n",
    "\n",
    "df_characters = pd.read_csv('data/simpsons_characters.csv').reset_index(inplace=False, drop=True)\n",
    "df_locations = pd.read_csv('data/simpsons_locations.csv').reset_index(inplace=False, drop=True)\n",
    "df_script = pd.read_csv('data/simpsons_script_lines.csv').reset_index(inplace=False, drop=True)\n",
    "df_episodes = pd.read_csv('data/simpsons_episodes.csv').reset_index(inplace=False, drop=True)\n",
    "\n",
    "# \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [{\n",
    "    \"role\": \"system\",\n",
    "    \"content\": get_system_prompt(),\n",
    "}, {\n",
    "    \"role\": \"user\",\n",
    "    \"content\": code\n",
    "}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_SAMPLES = 10_000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [04:59<00:00, 32.01it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [05:10<00:00, 32.01it/s]"
     ]
    }
   ],
   "source": [
    "assert N_SAMPLES <= 10000  # Otherwise this will get very expensive\n",
    "\n",
    "chat_completions = []\n",
    "\n",
    "pbar = tqdm(total=N_SAMPLES)\n",
    "while len(chat_completions) < N_SAMPLES:\n",
    "    chat_completion = client.chat.completions.create(messages=messages, model='ft:gpt-3.5-turbo-1106:personal::8LCi9Q0d', n=min(128, N_SAMPLES - len(chat_completions)))\n",
    "    chat_completions.extend(chat_completion.choices)\n",
    "    pbar.update(len(chat_completion.choices))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer_list = [choice.message.content for choice in chat_completions]\n",
    "\n",
    "len(answer_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store the completions\n",
    "with open('multi-choice-completions.json', 'w') as f:\n",
    "    json.dump(answer_list, f, ensure_ascii=False, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "from umap import UMAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "embeddings = sentence_model.encode(answer_list, show_progress_bar=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bertopic.representation import OpenAI\n",
    "\n",
    "representation_model = OpenAI(client, model=\"gpt-3.5-turbo\", delay_in_seconds=5, chat=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-08 09:26:52,073 - BERTopic - Dimensionality - Fitting the dimensionality reduction algorithm\n",
      "2023-12-08 09:27:11,133 - BERTopic - Dimensionality - Completed ✓\n",
      "2023-12-08 09:27:11,134 - BERTopic - Cluster - Start clustering the reduced embeddings\n",
      "2023-12-08 09:27:11,271 - BERTopic - Cluster - Completed ✓\n",
      "2023-12-08 09:27:11,275 - BERTopic - Representation - Extracting topics from clusters using representation models.\n",
      "100%|██████████| 269/269 [27:02<00:00,  6.03s/it]\n",
      "2023-12-08 09:54:13,810 - BERTopic - Representation - Completed ✓\n"
     ]
    }
   ],
   "source": [
    "# Train BERTopic\n",
    "topic_model = BERTopic(verbose=True, representation_model=representation_model).fit(answer_list, embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reduce dimensionality of embeddings, this step is optional but much faster to perform iteratively:\n",
    "reduced_embeddings = UMAP(n_neighbors=10, n_components=2, min_dist=1, metric='cosine').fit_transform(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_representations = [topic_model.get_topic(topic_id) for topic_id in range(len(topic_model.get_topic_freq()))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_model.set_topic_labels(topic_representations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "hoverinfo": "text",
         "hovertext": [
          "spacy.prefer_gpu()",
          "\n# Gensim\nimport gensim\nimport gensim.corpora as corpora\nfrom gensim.utils import simple_preprocess\nfrom gensim.models import CoherenceModel",
          " View a few example rows from each DataFrame to understand its structure\nprint(\"\\nCharacters DataFrame:\")\nprint(df_characters.head(3))\nprint(\"\\nLocations DataFrame:\")\nprint(df_locations.head(3))\nprint(\"\\nScript DataFrame:\")\nprint(df_script.head(3))\nprint(\"\\nEpisodes DataFrame:\")\nprint(df_episodes.head(3))",
          "Show the first lines of all the DataFrames\nprint(\"Characters DataFrame - shape\", df_characters.shape)\nprint(df_characters.head())\nprint(\"\\nLocations DataFrame - shape\", df_locations.shape)\nprint(df_locations.head())\nprint(\"\\nScript DataFrame - shape\", df_script.shape)\nprint(df_script.head())\nprint(\"\\nEpisodes DataFrame - shape\", df_episodes.shape)\nprint(df_episodes.head())",
          "Matplotlib improvements\nmatplotlib.use('TkAgg')",
          "Set the path for the visuals.",
          " Set environment variable for gensim word2vec model path\nos.environ[\"GENSIM_DATA_DIR\"] = \".\"",
          "# Split dataset into train, validation and test datasets\ntrain_dataset = dataset.sample(frac=0.6, random_state=0).reset_index(drop=True)\nvalid_dataset = dataset.drop(train_dataset.index).reset_index(drop=True)\ntest_dataset = valid_dataset.sample(frac=0.5, random_state=0).reset_index(drop=True)\nvalid_dataset = valid_dataset.drop(test_dataset.index).reset_index(drop=True)",
          "Optional: A sneek peek into the data helps understanding the contents.",
          "Merge with characters and drop nans for speaking_character_id\ndf_script = df_script.merge(df_characters, left_on='character_id', right_on='id').dropna(subset=['speaking_character_id'])",
          "We'll start by looking at some examples from the dataset `df_characters`.",
          " Check if we have empty rows or NaN values",
          "Drop columns with over 50% missing data\ndf_script = df_script.drop(columns=['normalized_text', 'word_count'])",
          " Visualize the character and location dataframes",
          "Replace nans with ''\ndf_script_filtered = df_script[['character_id', 'location_id', 'normalized_text']].fillna('')",
          "Check loaded dataframes\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()",
          " Define file paths for storing visualizations",
          "Let's see the structure of the data.",
          "Inspect the dataframes to get a better sense of the data.",
          "Joining datasets",
          " Display the head of each dataset to get an overview of their structure\nprint(\"Characters:\")\nprint(df_characters.head())",
          "Explore the structure of the characters DataFrame\nprint(df_characters.head())",
          "Check the first 5 records of each CSV",
          "Display first few rows of the characters dataframe\ndf_characters.head()",
          "Merge episodes with their corresponding scripts\ndf_episodes_with_scripts = pd.merge(\n    df_script, \n    df_episodes, \n    how='inner', \n    left_on='episode_id', \n    right_on='id'\n).drop(columns=['id_y']).rename(columns={'id_x': 'script_id'})\n\n# Merge characters to non-location scripts\ndf_episodes_with_scripts_and_characters = pd.merge(\n    df_episodes_with_scripts, \n    df_characters, \n    how='inner', \n    left_on='character_id', \n    right_on='id'\n).drop(columns='id').rename(columns={'name': 'character_name'})\n\n# Sanitize the location data\nlocation_alias_map = {\n    r'(Moe\\'s|moes)': 'MOE_S_TAVERN',\n    r'(Simpson House|the house|simpson home|our house|their house)': 'SIMPSON_HOME',\n    r'(elementary|school|detention|principal|lunchlady)': 'SPRINGFIELD_ELEMENTARY_SCHOOL',\n}",
          "Clean dataframe so that only lines of dialogue are kept\ndf_script = df_script[df_script['speaking_line'] == True]\n\n# Merge dataframes\ndf_merged = df_script.merge(df_episodes, on='episode_id', how='left')\n\n# Remove unnecessary columns\ndf_merged.drop(['imdb_rating', 'imdb_votes', 'video_url', 'image_url', 'production_code'], axis=1, inplace=True)\n\n# Drop rows with NaN values in 'normalized_text' column\ndf_merged.dropna(subset=['normalized_text'], inplace=True)\n\n# Display first few rows of dataframe\ndf_merged.head()",
          "Preview the data\nprint('Characters:')\nprint(df_characters.head(3))\nprint('\\nLocations:')\nprint(df_locations.head(3))\nprint('\\nEpisodes:')\nprint(df_episodes.head(3))\nprint('\\nLines:')\nprint(df_script.head(3))",
          "Check the df_scripts dataframe",
          "Create a meta DataFrame with all the characters in the script, and the total number of spoken words for each character.",
          "View first 5 rows of the characters dataframe\ndf_characters.head()",
          "Get all the speakers from the script\nspeakers = df_script['character_id']\n\n# Count the number of dialogues per speaker\nspeaker_counts = speakers.value_counts()\n\n# Display dataframe of speaker counts\ndf_speaker_counts = pd.DataFrame(speaker_counts)\ndf_speaker_counts.columns = ['dialogue_count']\ndf_speaker_counts.index.names = ['character_id']\ndf_speaker_counts.reset_index(inplace=True)",
          "Displaying the number of entries in each dataset",
          "Inspect the data structure and contents to understand the data better",
          "Check the first five rows of the `df_characters` DataFrame",
          "Check, that everything went right \nprint('Number of characters: ', df_characters.shape[0])\nprint('Number of locations: ', df_locations.shape[0])\nprint('Number of episodes: ', df_episodes.shape[0])\nprint('Number of lines: ', df_script.shape[0])",
          "Join the necessary DataFrames to get a single DataFrame with the following columns: episode_id, raw_text, character_name, location_id, name.",
          "For more information on what each dataframe holds, check notebook 1.",
          "To view the first few rows of each DataFrame, we can simply use the head() method.",
          " Set seeds\nnp.random.seed(0)",
          "Remove any blank/NaN/Null values in the raw script data",
          " Join the datasets using their respective keys",
          "Check the \"?\" column in the table.",
          "Select the key elements and only a subset of columns in the script table",
          "Display maximum 20 columns when displaying dataframes\npd.set_option('max_columns', 20)",
          " Filter columns and merge the 4 datasets",
          "Check the loaded datasets\nprint(df_characters.head())\nprint(df_locations.head())\nprint(df_script.head())\nprint(df_episodes.head())",
          "Prerequisite: we need to remove characters that don't have a description and locations without a note.",
          "Filtered out the rows that are not script lines or do not have any spoken words in the \"spoken_words\" column.",
          "Filter the script for the provided episode ID and drop rows with no character ID",
          " This line ensures that the plots we generate with matplotlib use the 'dark_background' style for a better appearance.",
          "Checking if any script lines have Common Core information\ndf_script[df_script[\"norm_id\"].str.contains(\"CZ\", na=False)]",
          "We then split our dataset into two, an 80% subset for training and a 20% subset for testing.",
          "View the head of the characters data\ndf_characters.head()",
          "Consultando los primeros registros del dataset df_characters.",
          "\ndef count_words(text):\n    return len(text.split())",
          "Applying Title to each columns",
          "Train test split the data",
          "Optionnally, since the dataset is large, we can retrieve just a subset of the data, for instance by using the code below:\n'''\ndf_characters = df_characters.head(100).copy()\ndf_locations = df_locations.head(100).copy()\ndf_script = df_script.head(1000).copy()\ndf_episodes = df_episodes.head(100).copy()\n'''",
          "Inspect the data types of each column\ndf_script.dtypes",
          "As the dataset is too large for this course, a subset will be used instead.",
          "List the first 5 records of the specific data set",
          "Merge simpsons_characters.csv and simpsons_script_lines.csv on character_id\ndf_characters_script = pd.merge(df_characters, df_script, on='character_id', how='inner')",
          "Import the data and inspect the first few rows to understand its structure\ndf_script.head()",
          "To ensure the data has been loaded correctly, we can use the `head()` function to display the first few rows of each DataFrame.",
          "Merge episodes and characters datasets\ndf_merged = df_episodes.merge(df_characters, how='left', left_on='id', right_on='episode_id')",
          " We set word clouds parameters\nmatplotlib.rcParams['figure.figsize'] = (16.0, 12.0)\nmatplotlib.style.use('ggplot')",
          " Remove nulls values in the script\ndf_script = df_script[df_script.raw_location_text.notnull()]\ndf_script = df_script[df_script.raw_character_text.notnull()]",
          "# Define a function to display full dataframes\ndef display_all(df):\n    with pd.option_context(\"display.max_rows\", 1000, \"display.max_columns\", 1000):\n        display(df)",
          "Separate each sentence into a list of words",
          "display(df_characters.head())\ndisplay(df_locations.head())\ndisplay(df_script.head())\ndisplay(df_episodes.head())",
          "Let's display the first few rows of each of the datasets to understand their structure and contents.",
          " Import gensim and show its version\nimport gensim\ngensim.__version__",
          "Note: The 'data' folder is expected to be in the same directory as this Jupyter Notebook.",
          "Quick look at the \"Characters\" table\nprint(df_characters.head())",
          "'Type' of each df\nprint(\"df_characters:\", type(df_characters))\nprint(\"df_locations:\", type(df_locations))\nprint(\"df_script:\", type(df_script))\nprint(\"df_episodes:\", type(df_episodes))",
          " Show head of dataset\ndf_script.head()",
          "Keep the original DataFrames unmodified\ndf_characters_orig = df_characters.copy()\ndf_locations_orig = df_locations.copy()\ndf_script_orig = df_script.copy()\ndf_episodes_orig = df_episodes.copy()",
          "Looks good! Now we can continue with our analysis.",
          "Check how the dataframes look like\ndf_characters.head(3)",
          "Explore the first few rows of each dataframe to understand the data.",
          " Check the first few rows of each DataFrame\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()",
          "quick check and shape of dataframe",
          "Concatenate and replace utterance id with string\r\ndf_final = pd.concat([df_script, df_characters, df_locations, df_episodes], axis=1, join='inner')",
          " Display general information on the datasets\nprint('Characters dataframe:', df_characters.shape)\nprint('Locations dataframe:', df_locations.shape)\nprint('Script lines dataframe:', df_script.shape)\nprint('Episodes dataframe:', df_episodes.shape)",
          "Merge character and location names\nunique_character_names = df_characters.raw_character_text.tolist()\nunique_location_names = df_locations.raw_location_text.tolist()\n\n# Get unique character and location names\nunique_character_names = list(set(unique_character_names))\nunique_location_names = list(set(unique_location_names))\n\n# Replace slashes in character and location names\nunique_character_names = [name.replace('/', '_') for name in unique_character_names]\nunique_location_names = [name.replace('/', '_') for name in unique_location_names]",
          " Generate a list of dialogue for each character",
          "Get the list of seasons\nseasons = df_episodes['season'].unique()",
          "Select one episode from the Simpsons and display its script lines.",
          "Check the size of the datasets\nprint(df_characters.shape)\nprint(df_locations.shape)\nprint(df_script.shape)\nprint(df_episodes.shape)",
          "Filter characters that appear in at least 100 episodes\ncharacter_ep_counts = df_script['raw_character_text'].value_counts()\nfrequent_characters = character_ep_counts[character_ep_counts > 100].index.to_list()\ndf_script = df_script[df_script['raw_character_text'].isin(frequent_characters)]",
          "Merge script dataframe with episode df",
          "Setting up the Spacy NLP model\nnlp = spacy.load('en_core_web_sm')",
          "Display first five rows of characters dataset\ndf_characters.head()",
          "dsfd",
          "Inspect first few rows of each dataframes\nprint(df_characters.head())\nprint(df_locations.head())\nprint(df_script.head())\nprint(df_episodes.head())",
          " Display the first few rows of each dataframe to understand what kind of data is available\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()",
          "Create a sample of the Episodes dataframe to validate the data.",
          "Ensure the corpus is loaded.",
          "Ensure script line data types are correct\ndf_script['character_id'] = df_script['character_id'].astype('Int64')\ndf_script['location_id'] = df_script['location_id'].astype('Int64')\ndf_script['raw_text'] = df_script['raw_text'].astype(str)",
          " Visualization function to plot word clouds",
          " Optionally, you can display the top 5 rows of all these DataFrames to see what they look like",
          "Check the head of the dataset\ndf_script.head()",
          "Set random seed for reproduction of results\nnp.random.seed(0)",
          "Check the content of the records in the dataframes to understand the potential features at hand.\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()",
          " Check the data types and null values of the datasets\ndf_characters.info()",
          "Create a basic wordcloud for all of the Simpsons scripts\nscript_words = ' '.join(df_script['spoken_words'].fillna(''))\nwordcloud = WordCloud(width = 800, height = 400,\n                background_color ='black',\n                stopwords = STOPWORDS,\n                min_font_size = 10).generate(script_words)\n\n# plot the WordCloud image\nplt.figure(figsize = (8, 8), facecolor = None)\nplt.imshow(wordcloud)\nplt.axis(\"off\")\nplt.tight_layout(pad = 0)\n\nplt.show()",
          "Download the larger English model for spaCy, which is needed for the named entity recognition (NER) functionality.\n!python -m spacy download en_core_web_lg",
          "Convert raw_text newline characters to html <br> tag\ndf_script['spoken_words'] = df_script['spoken_words'].str.replace('\\n', '<br>')",
          " Preprocessing the script dataset by keeping only the spoken lines, and normalizing the character names and locations for consistency.",
          "Check the first few lines of each dataframe\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()",
          "Show the first 5 rows of each dataset to understand its structure\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()",
          "We'll start by taking a look at the structure of the datasets and splicing the data.",
          "Display the data\ndf_script",
          "Bart in script dataframe\ndf_script_bart = df_script[df_script['raw_character_text'] == 'Bart']\n\n# Most common words in the Bart lines\ncounter = Counter(\" \".join(df_script_bart[\"spoken_words\"]).split())\ncounter.most_common(10)",
          "# Only interested in characters with a known location\ndf_characters = df_characters[df_characters['location_id'].notnull()]",
          "Clean data\n# Remove rows with empty strings or NA's from the script\ndf_script.dropna(inplace=True)\ndf_script = df_script[df_script['raw_text'] != '']\n# Remove faulty episode\ndf_episodes.drop([281], inplace=True)\n\n# Top 10 characters that appear in the scripts\ntop10_characters = df_script.character_id.value_counts().head(10)\ntop10_characters = df_characters.loc[top10_characters.indices].reset_index(drop=True)\n\n# Top 10 locations that appear in the scripts\ntop10_locations = df_script.raw_location_text.value_counts().head(10).reset_index()\ntop10_locations.columns = ['raw_location_text', 'count']",
          "Filter out miscellaneous characters",
          " We will preprocess the data to remove missing values and merge the relevant columns.",
          "Display the first 5 rows of the characters dataset\ndf_characters.head()",
          "Quick overview of the data\nprint(\"DF Characters\")\nprint(df_characters.head())",
          " Merge dataset\ndf_characters.drop(['slug'], axis=1, inplace=True)\ndf_episodes.drop(['image_url', 'video_url'], axis=1, inplace=True)",
          "# Remove rows that contain empty strings in columns of interest\ncolumns_of_interest = ['character_id', 'normalized_text', 'location_id', 'episode_id']\ndf_script = df_script.replace('', np.nan)\ndf_script.dropna(subset=columns_of_interest, inplace=True)",
          "Create characters x location dataframe\nlocations = []\ncharacters = []\nlines_count = []\n\n\nfor idx, l in df_script.iterrows():\n    if (l['raw_character_text'] in df_characters.raw_character_text.values and\n        l['raw_location_text'] in df_locations.raw_location_text.values):\n        if (l['raw_character_text'], l['raw_location_text']) in zip(characters, locations):\n            lines_count[characters.index(l['raw_character_text'])][locations.index(l['raw_location_text'])] += 1\n        else:\n            characters.append(l['raw_character_text'])\n            locations.append(l['raw_location_text'])\n            lines_count.append(np.zeros(len(df_locations), dtype=np.int32))\n            lines_count[-1][locations.index(l['raw_location_text'])] = 1\n\ndf_x_locations = pd.DataFrame(data=lines_count, index=characters, columns=locations)\n\ndf_x_locations.to_csv('data/simpsons_characters_x_locations.csv')",
          "#head of the dataframe\ndf_script.head()",
          "Setting seed for reproducibility\nnp.random.seed(0)",
          "Create synonym dictionary to improve consistency in location names",
          "Set global plot styles and settings for consistent looks across all visualizations\nmatplotlib.rc_file_defaults()",
          "Preview the dataframes\nprint('Characters:')\ndisplay(df_characters.head(5))\nprint('Locations:')\ndisplay(df_locations.head(5))\nprint('Script:')\ndisplay(df_script.head(5))\nprint('Episodes:')\ndisplay(df_episodes.head(5))",
          "Now, let's take a look at the first few rows of each dataframe to understand the data better.",
          "Join script lines with character and episode information\ndf_script['character_name'] = df_script['character_id'].apply(lambda x: df_characters.loc[df_characters['id'] == x, 'name'].values[0] if len(df_characters.loc[df_characters['id'] == x, 'name'].values) > 0 else '')\ndf_script['location_name'] = df_script['raw_location_id'].apply(lambda x: df_locations.loc[df_locations['id'] == x, 'name'].values[0] if len(df_locations.loc[df_locations['id'] == x, 'name'].values) > 0 else '')\ndf_script['episode_title'] = df_script['episode_id'].apply(lambda x: df_episodes.loc[df_episodes['id'] == x, 'title'].values[0] if len(df_episodes.loc[df_episodes['id'] == x, 'title'].values) > 0 else '')\ndf_script['imdb_rating'] = df_script['episode_id'].apply(lambda x: df_episodes.loc[df_episodes['id'] == x, 'imdb_rating'].values[0] if len(df_episodes.loc[df_episodes['id'] == x, 'imdb_rating'].values) > 0 else '')",
          "# Display basic information about the loaded datasets\nfor df, name in zip([df_characters, df_locations, df_script, df_episodes], \n                    ['Characters', 'Locations', 'Script', 'Episodes']):\n    print(f'Dataset: {name}\\n')\n    print(df.info())\n    display(df.head(5))\n    print('\\n' + '='*90 + '\\n')",
          "Check the dataset\ndf_script.head()",
          ".against general memory issues\nprint(\"Characters:\", df_characters.memory_usage().sum() / 1024**2, \"MB\")\nprint(\"Locations:\", df_locations.memory_usage().sum() / 1024**2, \"MB\")\nprint(\"Script lines:\", df_script.memory_usage().sum() / 1024**2, \"MB\")\nprint(\"Episodes:\", df_episodes.memory_usage().sum() / 1024**2, \"MB\")",
          "Normalize the data - make everything lowercase in the required columns",
          "View the first few rows of the characters data\ndf_characters.head()",
          "Clean names from locations dataset and assign an unique identifier for each name",
          "Filter out characters, locations and episodes not used in the script\nall_characters_in_script = df_script['raw_character_text'].value_counts().index.tolist()\nall_locations_in_script = df_script['raw_location_text'].value_counts().index.tolist()\nall_episodes_in_script = df_script['episode_id'].value_counts().index.tolist()\n\ndf_characters = df_characters[df_characters['raw_character_text'].isin(all_characters_in_script)].reset_index(inplace=False, drop=True)\ndf_locations = df_locations[df_locations['raw_location_text'].isin(all_locations_in_script)].reset_index(inplace=False, drop=True)\ndf_episodes = df_episodes[df_episodes['id'].isin(all_episodes_in_script)].reset_index(inplace=False, drop=True)",
          "Select only relevant columns\ndf_script = df_script[['episode_id', 'number', 'raw_text', 'timestamp_in_ms','speaking_line', 'character_id', 'location_id']]\n\n# Remove NaNs\ndf_script = df_script.dropna(subset=['raw_text', 'speaking_line', 'character_id', 'location_id'])\n\n# Reset indexes\ndf_script = df_script.reset_index(drop=True)",
          "Display the first 5 rows of each dataframe\nprint(df_characters.head(5))\nprint(df_locations.head(5))\nprint(df_script.head(5))\nprint(df_episodes.head(5))",
          "Check that everythong is working as intended\nprint('Characters:')\ndisplay(df_characters.head())\nprint('Locations:')\ndisplay(df_locations.head())\nprint('Script:')\ndisplay(df_script.head())\nprint('Episodes:')\ndisplay(df_episodes.head())",
          "Set random seed for reproducibility\nnp.random.seed(0)",
          "pre-processing\ndf_script = df_script[df_script[\"normalized_text\"].notnull()]",
          "Due to space limitations, I'll be skipping the code segment that contains repetitive assignments to dataframes",
          "Select the lines that are spoken by a specific character, e.g., Homer, Marge, Bart, Lisa, or Maggie.",
          "Checking the top 3 rows of the characters dataframe",
          "Inspect first 5 rows of each table\nfor df, name in zip([df_characters, df_locations, df_script, df_episodes],\n                    ['Characters', 'Locations', 'Script', 'Episodes']):\n    print(f'First 5 rows of {name} table:')\n    display(df.head())\n    print('\\n\\n')",
          "Split name and surname\ndf_characters['name'] = df_characters['name'].apply(lambda x: x.split(' ', 1)[0])\ndf_characters.head()",
          " Display how the datasets look",
          "Print the characters dataframe to understand its structure\nprint(df_characters.head())\n\n# Print the locations dataframe to understand its structure\nprint(df_locations.head())\n\n# Print the script dataframe to understand its structure\nprint(df_script.head())\n\n# Print the episodes dataframe to understand its structure\nprint(df_episodes.head())",
          " Verify the size and structure of the DataFrames\nprint('Characters', df_characters.shape)\nprint('Locations', df_locations.shape)\nprint('Script', df_script.shape)\nprint('Episodes', df_episodes.shape)\n\ndf_characters.head()",
          "Display the data head to understand the structure and types of data",
          " show the scripts dataset\ndf_script.head()",
          "Preview the data to understand its structure and contents\nprint(df_characters.head())\nprint(df_locations.head())\nprint(df_script.head())\nprint(df_episodes.head())",
          "Display first 5 rows of each dataframe\ndf_list = [df_characters, df_locations, df_script, df_episodes]\ndf_names = ['Characters', 'Locations', 'Script', 'Episodes']\nfor i, df in enumerate(df_list):\n    print(f\"First 5 rows of {df_names[i]}\")\n    display(df.head())",
          "# The full text of the scripts is too large to load here. We'll be working with a slice of the data\nprint(df_script.shape)\ndf_script.head()",
          "Limit the number of cast members on one-off roles\ndf1 = df_script[df_script['normalized_text'].isin(df_characters[df_characters['n_lines'] > 100]['raw_character_text'])]\ndf1.head()",
          "Function to clean the scripts",
          "Remove `Unnamed: 0` column from `df_characters`\ndf_characters.drop(columns='Unnamed: 0', inplace=True)",
          "# various sources cite various names for the character \"moe\"\n# also drop characters that don't have any specific lines (i.e. only hears lines from others)\ndrop_chars = [\"mo\", \"Moe_Syszlak\", \"Carl_Carlson\", \"C._Montgomery_Burns\"]",
          "Introduction_Implementation cleaned up some of this data and store it in\n# separate files so that these would load faster in Jupyter\n\n# Head of the characters df\nprint(df_characters.head())",
          "Remove unncessary columns that have 90% or more of missing values",
          "Check the number of records\nprint(f'Number of records in df_characters: {df_characters.shape[0]}')\nprint(f'Number of records in df_locations: {df_locations.shape[0]}')\nprint(f'Number of records in df_script: {df_script.shape[0]}')\nprint(f'Number of records in df_episodes: {df_episodes.shape[0]}')",
          " I can help you on anything you want about the dataset after you load it.",
          "# Remove non-character lines from the script\ndf_script = df_script[df_script.normalized_text != ''].copy()\ndf_script.reset_index(inplace=True, drop=True)",
          "Filter out the data we're interested in and avoid Join operations.",
          " Show first 3 character rows\ndf_characters.head(3)",
          "Check the content of the dataset \"Characters\" and the first five rows of the dataframe\nprint(\"Printing the dataframe structure to understand it better\")\nprint(df_characters.head().to_string())",
          "Merge df_script with df_episodes to get more details in the same df",
          "rename the columns in the DataFrames to make them more legible.\ndf_characters.columns = ['character_id', 'name']\ndf_locations.columns = ['location_id', 'name']\ndf_script.columns = ['index', 'episode_id', 'number', 'raw_text', 'timestamp_in_ms', 'speaking_line', 'character_id', 'location_id', 'raw_character_text', 'raw_location_text', 'spoken_words', 'normalized_text', 'word_count']\ndf_episodes.columns = ['id', 'title', 'original_air_date', 'production_code', 'season', 'number_in_season', 'number_in_series', 'us_viewers_in_millions', 'views', 'imdb_rating', 'imdb_votes', 'image_url', 'video_url']",
          "Filter only the 'Springfield Elementary School' location\ndf_script_springfield_school = df_script[\n    df_script['raw_location_text'] == 'Springfield Elementary School'\n]",
          "plexico characters by the number of lines of speech\ncounts = df_script['raw_character_text'].value_counts()\n\nif 'simpsons' in counts.index:\n    counts.drop('simpsons', inplace=True)\n\n# Label\ncounts.index.name = 'character'\ncounts.name = 'lines'",
          "Uncomment the following lines to debug if something in this notebook goes wrong\n# import pixiedust\n# %%pixie_debugger",
          "to check if the profane words are in the script out of curiosity.\nprofane_words = set([\"ass\", \"asshole\", \"bastard\", \"bitch\", \"crap\", \"damn\", \"dick\", \"douche\", \"fag\", \"fuck\"])\nscript_profanity = []\n\nfor i in tqdm(range(len(df_script))):\n    text = df_script.loc[i, 'raw_text']\n    words = set([word.lower().strip() for word in text.split()])\n    profane = bool(words & profane_words)\n    script_profanity.append(profane)\n\ndf_script['profane'] = script_profanity",
          "Exploring the structure of the data",
          "Setting up the pipeline and processing the text data",
          "Display head of all datasets to understand the data",
          " We define the default style for matplotlib visualizations.",
          "Inspect the structure of the dataframes\n(df_characters.head(), df_locations.head(), \n df_script.head(), df_episodes.head())",
          "# Visualization function\ndef cloud(text):\n    # Create and generate a word cloud image:\n    wordcloud = WordCloud().generate(text)\n\n    # Display the generated image:\n    plt.imshow(wordcloud, interpolation='bilinear')\n    plt.axis(\"off\")\n    plt.show()\n\n# Initialize spacy 'en' model, keeping only tagger component needed for lemmatization\nnlp = spacy.load('en', disable=['parser', 'ner'])",
          "Importing all necessary libraries and datasets for analysis.",
          "Some lines contain Bhutanese writing. Let's clean the data by removing them.",
          " Check data\nprint('Characters:', df_characters.shape)\nprint('Locations:', df_locations.shape)\nprint('Script lines:', df_script.shape)\nprint('Episodes:', df_episodes.shape)",
          "Data organization\ndf_episodes = df_episodes.dropna(subset=['id']).set_index('id')\ndf_script = df_script.dropna(subset=['episode_id']).set_index('episode_id')\ndf_characters = df_characters.dropna(subset=['id']).set_index('id')\ndf_locations = df_locations.dropna(subset=['id']).set_index('id')",
          " Remove all characters that did not appear in any script line\nto_remove = df_script[~df_script.raw_character_text.isin(df_characters.raw_character_text) & ~df_script.raw_character_text.isna()].raw_character_text.unique()\ndisplay(len(df_script))\ndf_script = df_script[~df_script.raw_character_text.isin(to_remove)]\ndisplay(len(df_script))",
          "# Set local environment to use VADER\nos.environ['VADER_COMPOUND'] = '1'",
          "Filtering only those records which have been spoken by a character (non-null value)",
          " Print the first few rows of the dataframes\nprint(df_characters.head())\nprint(df_locations.head())\nprint(df_script.head())\nprint(df_episodes.head())",
          "We can display the first few rows of each dataset to get a sense of their structure.",
          " Displaying the scripts dataset\ndf_script",
          "# Merge script with characters and locations\ndf_script_characters = df_script.merge(df_characters, on='character_id')\ndf_script_characters_locations = df_script_characters.merge(df_locations, on='location_id')\n\n# Remove unwanted columns\ndf_script_characters_locations = df_script_characters_locations.drop([\n    'number',\n    'raw_text',\n    'timestamp_in_ms',\n    'speaking_line',\n    'character_id',\n    'location_id'\n], axis=1)",
          " Display the first few records of the dataframe\ndf_script.head()",
          " Check the first few rows of each dataframe\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()",
          "Visualize the number of episodes in the dataset\nepisodes_per_season = df_episodes['season'].value_counts().sort_index()\n\nplt.figure(figsize=(10, 6))\nplt.bar(episodes_per_season.index, episodes_per_season.values, color='skyblue')\nplt.title('Number of episodes per season')\nplt.xlabel('Season')\nplt.ylabel('Number of episodes')\nplt.show()",
          "Preview dataframes\nprint(df_characters.head(5))\nprint(df_locations.head(5))\nprint(df_script.head(5))\nprint(df_episodes.head(5))",
          "Extract main characters\nmain_characters = df_script.raw_character_text.value_counts().head(17).index.tolist()",
          "# Define constants\nSEASON_COLORS = ['#56B4E9', '#009E73', '#E69F00', '#CC79A7', '#0072B2', '#D55E00']",
          "Lets print the first 5 rows of the dataset and analyze the data",
          "Check a few lines of each DataFrame to understand how the data looks like\ndf_characters.head()",
          "Example character\ndf_characters.iloc[6]",
          "Clean up dataframe columns\ndf_characters.columns = df_characters.columns.str.lower().str.replace(' ', '_')\ndf_characters = df_characters.set_index('id')\n",
          "Print the first rows of each dataset to understand the structure of the data\nprint(df_characters.head())\nprint(df_locations.head())\nprint(df_script.head())\nprint(df_episodes.head())",
          "Columns in the lines dataframe that we'll use:\n## Speaking character\n## Spoken text\n## Season\n## Episode\n## Location\n## Character gender",
          "# Display first 5 rows of characters dataframe\ndf_characters.head()",
          "Get an overview of our datasets\nprint('Characters dataset:')\nprint(df_characters.head())\nprint('\\nLocations dataset:')\nprint(df_locations.head())\nprint('\\nScript lines dataset:')\nprint(df_script.head())\nprint('\\nEpisodes dataset:')\nprint(df_episodes.head())",
          " Define the path to your data folder in 'simpsons_path'",
          "Inspect the dataframes to understand their structure and the information they contain.",
          "Filter unnecessary columns in the episodes dataframe",
          "Check one of the dataset to see what it looks like\ndf_locations.head()",
          "Check the structure of each dataframe\nprint(\"Characters\")\nprint(df_characters.head())\nprint()\nprint(\"Locations\")\nprint(df_locations.head())\nprint()\nprint(\"Script\")\nprint(df_script.head())\nprint()\nprint(\"Episodes\")\nprint(df_episodes.head())",
          " Quick overview of each dataframe\nfor name, df in {'characters': df_characters, 'locations': df_locations, 'script': df_script, 'episodes': df_episodes}.items():\n    print(f'\\n{name.upper()}')\n    display(df.head(2))",
          "Set random seed for reproducibility\nnp.random.seed(13)",
          "Data loading",
          "Setting the directory path for the Simpsons dataset",
          "Basics for all of them\ndf_script['word_count'] = df_script['spoken_words'].apply(lambda x: len(x.split()))\ndf_script['title'] = df_episodes['title'][df_script['episode_id']-1].values\n\n# Display the conversation\ndf_script.head()",
          "Characters count\nprint(f'There are {df_characters.shape[0]} characters.')",
          "Checking the data type of each column in df_script",
          "Let's take a look at the first 5 rows of each dataframe.",
          "Checking the first few entities in each dataset.",
          "checking the head of each dataframe to understand its structure and what fields are available.",
          "Display top 3 rows of each dataframe\ndf_characters.head(3)",
          "Visualise the first rows of the characters, locations, script and epidoses tables",
          "Define the path to the data folder\nsimpsons_data_path = 'data/'",
          "Show the first 5 lines of each dataframe\nfor df, name in zip([df_characters, df_locations, df_script, df_episodes], ['Characters', 'Locations', 'Script', 'Episodes']):\n    print(name)\n    with pd.option_context('display.max_columns', None):\n        display(df.head(5))\n    print('\\n')",
          "Checking size of the dataframes\ndf_episodes.shape, df_script.shape, df_characters.shape, df_locations.shape",
          "Data pertaining to the lines spoken by characters and that location are contained in specific tables.",
          "# Extracting the main script from the data and dropping the columns not needed\ndf_main = df_script[['episode_id', 'number', 'raw_text', 'timestamp_in_ms']]\ndf_main.sort_values(['episode_id', 'number'], inplace=True)\ndf_main = df_main[df_main['timestamp_in_ms'] > 0]",
          "Inspect top 10 rows of each DataFrame\nprint('Characters')\ndisplay(df_characters.head())\n\nprint('Locations')\ndisplay(df_locations.head())\n\nprint('Script')\ndisplay(df_script.head())\n\nprint('Episodes')\ndisplay(df_episodes.head())",
          " We fixed the index during loading, so we don't have to reset them here",
          "Combining the data into one dataframe",
          "Filter out unnecessary characters from the script dataframe\ncharacters = df_characters['id']\nmask = df_script['character_id'].apply(lambda x: x in characters.to_list())\ndf_script = df_script[mask]",
          "Creating a single frame containing only the episodes that are both in df_script and df_episodes",
          "We'll begin by examining the first few rows of each dataframe using the `head()` function.",
          "# Ensure the Episode data is unique on id\ndf_episodes = df_episodes.drop_duplicates(subset=['id'])",
          "Filter by gold quality and main characters",
          "Building dataset from these input dataframes.",
          " Check the three datasets\nprint(df_characters.head())\nprint(df_locations.head())\nprint(df_script.head())",
          "Check memory usage before cleaning\nmem_usage = df_script.memory_usage(deep=True).sum() / 1024**2  # convert bytes to megabytes\nprint('Memory usage of dataframe is {:.2f} MB'.format(mem_usage))\n\n# Create a dictionary to store the optimal data types for each column to reduce memory usage\ndtypes = {'id': 'int32',\n          'episode_id': 'int32',\n          'number': 'int16',\n          'character_id': 'float32',  # NaN values\n          'location_id': 'float32',   # NaN values\n          'raw_text': 'string',       # special data type StringDtype\n          'timestamp_in_ms': 'int64',\n          'speaking_line': 'string',  # special data type StringDtype\n          'character_image_url': 'string',  # special data type StringDtype\n          'location_image_url': 'string',   # special data type StringDtype\n          'spoken_words': 'string',         # special data type StringDtype\n          'normalized_text': 'string',      # special data type StringDtype\n          'word_count': 'int16'}",
          "Display first few rows of the characters dataframe\ndf_characters.head()",
          "Check the data in each dataframe\nprint('Characters')\nprint(df_characters.info())\nprint(df_characters.head())\n\nprint('Locations')\nprint(df_locations.info())\nprint(df_locations.head())\n\nprint('Script')\nprint(df_script.info())\nprint(df_script.head())\n\nprint('Episodes')\nprint(df_episodes.info())\nprint(df_episodes.head())",
          "Exctract the content of the `raw_text` column and make it the variable `raw_text`",
          "Display the first few lines of each dataframe to understand their structure\nprint(\"Characters DataFrame:\")\nprint(df_characters.head())\nprint(\"\\nLocations DataFrame:\")\nprint(df_locations.head())\nprint(\"\\nScript DataFrame:\")\nprint(df_script.head())\nprint(\"\\nEpisodes DataFrame:\")\nprint(df_episodes.head())",
          "Plot the 10 characters with the most dialogue",
          "select main characters that have at least 1000 lines\nmain_characters = df_script.character.value_counts()\nmain_characters = main_characters[main_characters > 1000]",
          "Replace NaN values with '' in the script dataframe\ndf_script['normalized_text'] = df_script['normalized_text'].map(lambda x: '' if pd.isnull(x) else x)",
          "Print the first few lines of each dataframe\nprint(df_characters.head())\nprint(df_locations.head())\nprint(df_script.head())\nprint(df_episodes.head())",
          "Checking dimensions of each dataframe",
          "Reloading Franky's functions correctly.\nimport sys\nsys.path.append('..')\n\nfrom nlpFunctions import *",
          "Get the most common utterances (which character speaks which words)",
          "Inspecting the first 5 rows of each dataframe to understand the structure of the data.",
          "Let's have a look at some data first.",
          "First, let's take a look at the first few rows of each dataframe to understand what kind of data we're working with.",
          "\n# Data has been read into dataframes. Can start analysis and visualization.",
          "from scripts.data_cleaning import clean_script, align_lines",
          "Visualize first few rows of the dataframe\ndf_script.head()",
          "Data cleaning: Missing values",
          "Display first few rows of the characters dataframe\ndf_characters.head()",
          "Creation of the \"simpsons_episodes\" table",
          "The script includes multiple dataset which shows the information for each episode, such as the annotated script lines, the characters, the locations, and the main events.",
          "Discard unnecessary columns from df_episodes\ndf_episodes = df_episodes[['id', 'title', 'original_air_date']]",
          "Check the content of the characters CSV file in order to understand if there are inconsistencies or special cases to consider.",
          "Create a useful directory structure",
          "Filter out the bad data points from our data set and keep the examples that are actually usuable.",
          "@click.command()",
          "Filtering for the first episode as an example\ndf_episode_1 = df_script[(df_script['episode_id'] == 1)].copy()\ndf_episode_1.rename(columns={'raw_text':'text'}, inplace=True)",
          "Check the size of the dataframes\nprint(df_characters.shape)\nprint(df_locations.shape)\nprint(df_script.shape)\nprint(df_episodes.shape)",
          "Set random seed for reproducibility\nnp.random.seed(0)",
          "Looking at the data structure of each to find how to merge the files and how to work with them.",
          "display(df_characters.head())\ndisplay(df_locations.head())\ndisplay(df_script.head())\ndisplay(df_episodes.head())",
          "Add missing columns to df_script\ndf_script['full_text'] = df_script['raw_text'] + \" \" + df_script['normalized_text'].fillna(\"\")",
          "Combine script lines with corresponding character and episode information\ndf = df_script.merge(df_characters, on='id_number', how='inner')\ndf = df.merge(df_episodes, on='episode_id', how='inner')",
          "Display the dataframe containing the characters/actors information",
          " Merge the script lines with the characters and locations information\ndf_script_char = df_script.merge(df_characters, how=\"left\", left_on=\"character_id\", right_on=\"id\", suffixes=(\"_script\", \"_char\")).drop(\"id_char\", axis=1)\ndf_script_loc = df_script_char.merge(df_locations, how=\"left\", left_on=\"location_id\", right_on=\"id\", suffixes=(\"_script\", \"_loc\")).drop(\"id\", axis=1)\n\n# Filter the main characters and locations\nmain_characters = [\"Lisa Simpson\", \"Bart Simpson\", \"Marge Simpson\", \"Homer Simpson\", \"C. Montgomery Burns\", \"Moe Szyslak\", \"Seymour Skinner\", \"Ned Flanders\", \"Grampa Simpson\", \"Milhouse Van Houten\"]\nmain_locations = [\"Simpson Living Room\", \"Simpson Kitchen\", \"Moe's Tavern\", \"Springfield Elementary School\", \"Kwik-E-Mart\", \"Simpson Backyard\", \"Simpson Car\"]\ndf_main = df_script_loc[df_script_loc[\"raw_character_text\"].isin(main_characters)]\ndf_main = df_main[df_main[\"raw_location_text\"].isin(main_locations)]",
          "Create a set of all episode ids",
          " Check the import\nprint(\"Datasets loaded successfully.\")",
          "Join lines with df_episodes to find out show details",
          "Checking if pickle files already exists",
          "Save the script data details for the prediction script and delete script data from memory after saving it",
          "# Merge tables\ndf = df_script.merge(df_characters[['id', 'name']], left_on='character_id', right_on='id', suffixes=('_script', '_character'))\ndf = df.merge(df_locations[['id', 'name']], left_on='location_id', right_on='id', suffixes=('_df', '_location'))\ndf = df.merge(df_episodes[['id', 'title', 'original_air_date']], left_on='episode_id', right_on='id', suffixes=('_df', '_episode'))\n\n# Drop redundant columns\ndf.drop(columns=['id_script', 'id_character', 'id_df', 'id_location', 'id_episode'], inplace=True)",
          "Merge datasets in order to get the character and location names for each line in the script\ndf_episodes = df_episodes[['id', 'title', 'original_air_date']]\ndf_script = df_script.merge(df_episodes, how='inner', left_on='episode_id', right_on='id')\n\ndf_script = df_script[['episode_id', 'number', 'raw_text', 'title', 'original_air_date']]\ndf_script = df_script.rename(columns={'episode_id': 'episode_id', 'number': 'episode_number', 'raw_text': 'text',\n                                     'title': 'episode_title', 'original_air_date': 'air_date'})\n\n# Remove lines for which the character isn't specified\ndf_script = df_script.loc[df_script.character_id.notnull()]\n\ndf_script = df_script.merge(df_characters, how='inner', left_on='character_id', right_on='id')\ndf_script = df_script.merge(df_locations, how='left', left_on='location_id', right_on='id')\n\ndf_script = df_script[['episode_id', 'episode_number', 'episode_title', 'text', 'air_date', 'name',\n                       'normalized_name', 'alignment_id', 'alignment', 'image_url', 'id_y',\n                       'name_y']]",
          "Now that we have imported the necessary libraries and loaded the datasets, we can proceed with the data analysis and visualization.",
          "Preview the data\nprint('Characters:')\ndisplay(df_characters.head(2))\nprint('Locations:')\ndisplay(df_locations.head(2))\nprint('Script:')\ndisplay(df_script.head(2))\nprint('Episodes:')\ndisplay(df_episodes.head(2))",
          " Extract the first few lines of the script to get a feeling of the data structure\ndf_script.head()",
          " Display the size of the DataFrames to have an overview of the data available",
          "Displaying the script lines dataset\ndf_script.head()",
          "display first 5 rows of each dataframe\ndfs = [df_characters, df_locations, df_script, df_episodes]\nfor i, df in enumerate(dfs):\n    print(f\"\\nDataframe df_{i} :\")\n    print(df.head())",
          " Show the top entries of each DataFrame\ndisplay(df_characters.head())\ndisplay(df_locations.head())\ndisplay(df_script.head())\ndisplay(df_episodes.head())",
          " Define a function to compute the word frequency",
          "Show the first 3 examples of df_characters dataframe\ndf_characters.head(3)",
          "Check the structure of the datasets\ndf_characters.head()",
          "Setting seed for reproducibility\nnp.random.seed(0)",
          "Check that the csv files have been correctly located and loaded.",
          "Dramatization of the characters and locations\ndramatic_characters = df_script.character.str.upper()  # This project is not case sensitive\ndramatic_locations = df_script.raw_location_text.str.upper()  # Same here",
          "Replace indicated speciees names for easier manipulation in the future\ndf_script.replace({\n    'simpsons': 'species_simpsons'\n}, inplace=True, regex=True)",
          " Clean the data\ndf_script = df_script[df_script[\"utterance\"].notna()]\ndf_script = df_script[df_script[\"raw_text\"].notna()]\ndf_script = df_script[df_script[\"character_id\"].notna()]\ndf_script = df_script[df_script[\"location_id\"].notna()]\ndf_script = df_script[df_script[\"episode_id\"].notna()]",
          "Exploratory data analysis and data preprocessing",
          "Clone the dataframes to avoid any SettingwithCopyWarnings in the future",
          "Rename the raw columns from the script dataframe for readability and binary gender\n# 0 for male, 1 for female in the gender column",
          "Check if the episodes' raw data is complete.",
          "Get rid of experimental and unsued file that may still be in the workspace",
          "We merge dialogues from the scripts and the respective speakers by using left join on character_id field and index field, we finally consider only\nthose episode whose script is complete.",
          "Take a peak at what the dataframes looks like\nprint(df_characters.head())\nprint(df_locations.head())\nprint(df_script.head())\nprint(df_episodes.head())",
          "Inspector\ndf_script.inspect()",
          "Inspect the characters dataframe to understand its structure and columns\nprint(df_characters.head())\n# List unique values in the df_characters dataframe, and count the number of unique characters\nprint(df_characters.nunique())",
          "Compute and display the number of characters, locations, and lines in the dataset",
          "Ensure reproductibility of the results\nnp.random.seed(0)",
          "Show the first five rows of df_locations\ndf_locations.head()",
          " Merge character and location in script\ndf_script_with_character = pd.merge(df_script, \n                                    df_characters,\n                                    left_on='character_id', \n                                    right_on='id').drop(['id'], axis=1).rename({'name': 'character_name'}, axis=1)",
          "Inspect the dataframes head\nprint(df_characters.head())\nprint(df_locations.head())\nprint(df_script.head())\nprint(df_episodes.head())",
          "Create a single dataframe's column with the whole script",
          "Inspect the head of each dataframe\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()",
          " Show tables\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()",
          "Show the dataframes to gain an overview of the columns and data types.",
          " Set index to character_id for better handling\ndf_characters.set_index('character_id', inplace=True)",
          "Check main DataFrames' structure\nprint(df_characters)\nprint(df_locations)\nprint(df_script)\nprint(df_episodes)",
          "Preview the first few rows of each DataFrame\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()",
          "Remove information about Simpsons' episode title and whether its dataset\n# Song does not have any meaningful information\ndf_script.pop('episode_title')\ndf_script.pop('number')",
          " Read the file containing distinct word and their word type",
          "Display all dataframe columns\npd.set_option('display.max_columns', None)\n\n# Show first rows of each dataframe\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()",
          "Extracting the characters who appear in the script\ncharacters_list = df_script[\"raw_character_text\"].value_counts().keys().tolist()\n\n# Merging the dataframe with the script lines and the one with unique characters\ndf_characters = df_characters.merge(pd.DataFrame(characters_list, columns=[\"character_name\"]), on=\"character_name\")",
          " Create an nlp object\nnlp = spacy.load('en_core_web_sm')",
          "Clean data\ndf_script_clean = df_script[\n    (df_script.raw_character_text != ' ') & (df_script.raw_character_text != 'Miss Hoover') & (df_script.raw_character_text != 'Miss Hoover & Martin') & \\\n    (df_script.raw_character_text != 'Miss Hoover & Terri & Martin') & \\\n    (df_script.raw_character_id != 8) & (df_script.raw_location_text != 'nan')\n]",
          "Print the dataframes to understand their structure\nprint(df_characters.head())\nprint(df_locations.head())\nprint(df_script.head())\nprint(df_episodes.head())",
          "Let's explore the data to see what it looks like.",
          "'Read' is not defined",
          "Filter out bad data from the dataset",
          "Let's see the first lines of those dataframes",
          "Create is_simpsons column, filter and subset script lines",
          " Display the progress bar by setting the pandas options\ntqdm.pandas()",
          "display general information about the datasets",
          "# IPython-cache\n%load_ext jupyter_cache\n\n# Caching\n%cache df_characters df_locations df_script df_episodes",
          "Inspect each dataframe to understand its structure and content",
          "Displaying the sample of dataframe of script lines\ndf_script.head(10)",
          "Show a few samples of the characters dataframe",
          "Lets start with simple statistics of dataframes",
          "Organize each data frame by their IDs as shown below",
          "Let's start by examining the contents of each dataset.",
          "Let's first take a look at the structure of the data frames.",
          " For more details about the dataset, read 'description.txt'",
          " Limit the script data to only the characters in df_characters\ndf_script_lim = df_script[df_script[\"raw_character_text\"].isin(df_characters.character_text)]",
          "Merges and filters data",
          "Split locations, removes duplicates, and assigns a unique identifier",
          "Check the first rows of each dataset\nprint('Characters')\nprint(df_characters.head())\nprint('\\nLocations')\nprint(df_locations.head())\nprint('\\nScript')\nprint(df_script.head())\nprint('\\nEpisodes')\nprint(df_episodes.head())",
          "Remove unnecessary columns and fill NaN values with empty strings\ndf_script = df_script[['episode_id', 'id', 'character_id', 'location_id', 'raw_text']]\ndf_script = df_script.fillna('')",
          " Viewing memory usage of each dataframe\nprint(\"Memory usage of each dataframe:\")\nprint(df_characters.memory_usage().sum())\nprint(df_locations.memory_usage().sum())\nprint(df_script.memory_usage().sum())\nprint(df_episodes.memory_usage().sum())",
          "create dictionary for character locations\ncharacter_to_locations = {}\n\nfor i, row in df_script.iterrows():\n    # If character hasn't been added to the dictionary yet, add it\n    if row['raw_character_text'] not in character_to_locations.keys():\n        character_to_locations[row['raw_character_text']] = []\n    \n    # If character location hasn't been added to the list yet, add it\n    if row['raw_location_text'] not in character_to_locations[row['raw_character_text']]:\n        character_to_locations[row['raw_character_text']].append(row['raw_location_text'])",
          "Visualize the number of lines per episode\ndf_episodes['id'] = df_episodes['id'].apply(str)\ndf_script['episode_id'] = df_script['episode_id'].apply(str)\n\nlines_per_episode = df_script['episode_id'].value_counts().reset_index()\nlines_per_episode.columns = ['episode_id', 'num_lines']\n\nlines_per_episode = lines_per_episode.merge(df_episodes, left_on='episode_id', right_on='id')\nlines_per_episode = lines_per_episode.sort_values(by='original_air_date')\nlines_per_episode['episode_id'] = lines_per_episode['id']  # Rename because there is another column with the same name, and we need it for the next step.",
          "Read data head",
          "Check the first 5 lines of each dataframe to understand the data",
          "Separate the quotes from the script in test/training",
          "Display the first few lines of each dataframe to understand its structure\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()",
          "Merge the specified dataframe with the scripts dataframe",
          " Exploratory Data Analysis",
          "Inspect the first few rows of the script dataset to understand its structure\ndf_script.head()",
          "Check information of the script dataset\nprint(df_script.head())\nprint(df_script.info())",
          "Check the three base datasets\ndf_characters.head()",
          "Cleaning up the mess from the stupid Pandas.",
          "check files in directory",
          "Preview the first 5 records of each dataset\nprint(df_characters.head(5))\nprint(df_locations.head(5))\nprint(df_script.head(5))\nprint(df_episodes.head(5))",
          " Print size of datasets\nprint(\"Characters Shape:\", df_characters.shape)\nprint(\"Locations Shape:\", df_locations.shape)\nprint(\"Script Shape:\", df_script.shape)\nprint(\"Episodes Shape:\", df_episodes.shape)",
          "Tutorials will typically use this to make the resulting data frames simpler to work with\ndf_characters.simpsons_character_id = df_characters.simpsons_character_id.astype('int32')\ndf_locations.simpsons_location_id = df_locations.simpsons_location_id.astype('int32')\ndf_episodes.simpsons_episode_id = df_episodes.simpsons_episode_id.astype('int32')\ndf_script.simpsons_script_line_id = df_script.simpsons_script_line_id.astype('int32')\ndf_script.simpsons_character_id = df_script.simpsons_character_id.astype('int32')\ndf_script.simpsons_location_id = df_script.simpsons_location_id.astype('Int32')\ndf_script.simpsons_location_id = df_script.simpsons_location_id.astype('Int32')",
          " Combine df_script with df_episodes and filter out non-Simpsons lines",
          "Merge the tables to contain all necessary information needed for the analysis.",
          "display complete dataframe for a quick look\ndf_script",
          "Set random seed for reproducibility\nnp.random.seed(0)",
          "Convert stringified lists into lists",
          "Setting path for the to be saved wordclouds for each episode, character and location\nwordcloud_path = os.path.dirname(os.path.realpath(__file__))+'/wordclouds/'",
          "Confirm everything looks good so far\ndisplay(df_characters.head())\ndisplay(df_locations.head())\ndisplay(df_script.head())\ndisplay(df_episodes.head())",
          "For the sake of simplicity, we will remove unncessary columns from specific tables and save them into a new CSV which we will inport later on.",
          "Preview the data to quickly gather the main information and have a general view of the structure and content.",
          "Create a copy of the \"simpsons_script_lines\" dataframe and drop the \"id\" and \"episode_id\" columns\ndf = df_script.copy()\ndf.drop(columns=['id', 'episode_id'], inplace=True)",
          " Remove unwanted column\ndf_script = df_script.drop('id', axis=1)",
          "Print the shape of the dfs\ndf_characters.shape, df_locations.shape, df_script.shape, df_episodes.shape",
          "Check for any empty cells in a column",
          "Check the data shape\nprint(df_characters.shape)",
          "Merge the dataframes to obtain a single dataframe containing all the information about the scripts.",
          "Create the NLP object and add vectors for the entity linking model\nnlp = spacy.load('en_core_web_sm')\nlinker = nlp.get_pipe('entity_linker')\nfor i, row in df_characters.iterrows():\n    linker.add_Entity(entity=row['raw_name'], freq=0, entity_vector=nlp(row['raw_name']).vector)\nfor i, row in df_locations.iterrows():\n    linker.add_Entity(entity=row['raw_location'], freq=0, entity_vector=nlp(row['raw_location']).vector)",
          " Creating a corpus of documents, we select some particular collection of documents as our data source.",
          "Explore the dataframe shape (columns and samples)",
          " Quick look at the character dataset\nprint(\"Shape of the data:\", df_characters.shape)\ndf_characters.head()",
          " Viewing first ten records of the dataframe which contains the script for the scenes of all the episodes",
          "Covert character_id and location id to int\ndf_script['character_id'] = df_script['character_id'].astype('Int64')\ndf_script['location_id'] = df_script['location_id'].astype('Int64')",
          "Get the characters played by the actors (not from the script)",
          " Do work on df_characters, df_locations, df_script, and df_episodes.",
          "Copy the original dataframe into a new variable (in order to avoid reloading it from the CSV)",
          "# Total script lines\nprint('Total script lines:', df_script.shape[0])",
          "Inspect the dataframes by printing the first few rows of each dataframe\nprint('Characters:')\nprint(df_characters.head())\n\nprint('Locations:')\nprint(df_locations.head())\n\nprint('Script:')\nprint(df_script.head())\n\nprint('Episodes:')\nprint(df_episodes.head())",
          "Define a function to load the SpaCy model for named entity recognition (NER) and attach it to the pandas dataframe.",
          "View first 5 rows of characters dataframe\ndf_characters.head()",
          "# Making sure data has been loaded properly\nprint('Characters - num rows : ', df_characters.shape[0])\nprint('Locations - num rows : ', df_locations.shape[0])\nprint('Script lines - num rows : ', df_script.shape[0])\nprint('Episodes - num rows : ', df_episodes.shape[0])",
          "Extract the file_name and line_text columns\ndf_script = df_script[['file_name', 'normalized_text']]",
          "Remove erroneous information on Lisa having the most lines ever",
          "Finding every location mentioned in every one of the scripts in this season",
          " Print out the first few rows of each dataframe to understand their structure\nprint(df_characters.head())\nprint(df_locations.head())\nprint(df_script.head())\nprint(df_episodes.head())",
          "Remove the second index column that appeared from the file",
          "Inspect the first 3 rows of the main dataset (i.e., df_script)\ndf_script.head(3)",
          "Check the head of each dataset to understand its structure\nprint(df_characters.head())\n\nprint(df_locations.head())\n\nprint(df_script.head())\n\nprint(df_episodes.head())",
          " Examine the structure of the data frames",
          " Let's save the fruit of the EDA using the pickle format\ndf_characters.to_pickle(\"data/simpsons_characters.pkl\")\ndf_locations.to_pickle(\"data/simpsons_locations.pkl\")\ndf_script.to_pickle(\"data/simpsons_script.pkl\")\ndf_episodes.to_pickle(\"data/simpsons_episodes.pkl\")",
          "Modify episode id to be zero-indexed in order to facilitate join operations\ndf_episodes['id'] = df_episodes['id'] - 1",
          "View basic data info\nprint('characters: ', df_characters.shape, df_characters.columns)\nprint('locations: ', df_locations.shape, df_locations.columns)\nprint('script: ', df_script.shape, df_script.columns)\nprint('episodes: ', df_episodes.shape, df_episodes.columns)",
          "Look at the list of episodes\nfor i, row in df_episodes.iterrows():\n    print(row['title'], row['original_air_date'])",
          "Consider displaying the data to understand its structure and available columns.",
          " Pre-processing and Feature Generation",
          "Look at the head of the table to understand the data.",
          "Find the names of all the columns in the dataframe",
          "Create an 'id' for each episode and character ID\ndf_script['episode_id'] = df_script['episode_id'].apply(str)\ndf_script['id'] = df_script.index.astype(str)\ndf_characters['id'] = df_characters.index.astype(str)\ndf_locations['id'] = df_locations.index.astype(str)\ndf_episodes['id'] = df_episodes['id'].astype(str)",
          "Create a list for each episode containing all its lines\nepisode_2_lines = []\nfor episode in df_episodes[df_episodes['id']==3]['episode_id']:\n    episode_lines = df_script[df_script['episode_id']==episode]\n    episode_2_lines.append(' '.join(episode_lines['raw_text']))",
          " Convert columns containing json data into dataframes\nimport json\nfrom pandas.io.json import json_normalize\n\n# convert to json\ndf_script[\"episode_id\"] = df_script[\"episode_id\"].apply(lambda x: json.loads(x.replace(\"'\", \"\\\"\")))\ndf_script[\"character_id\"] = df_script[\"character_id\"].apply(lambda x: json.loads(x.replace(\"'\", \"\\\"\")))\ndf_script[\"location_id\"] = df_script[\"location_id\"].apply(lambda x: json.loads(x.replace(\"'\", \"\\\"\")))\ndf_script[\"spoken_words\"] = df_script[\"spoken_words\"].apply(lambda x: json.loads(x.replace(\"'\", \"\\\"\")))\ndf_script[\"normalized_text\"] = df_script[\"normalized_text\"].apply(lambda x: json.loads(x.replace(\"'\", \"\\\"\")))\n\n# Transform json into individual lines\ndf_script_eid = df_script.explode('episode_id').reset_index(inplace=False, drop=True)\ndf_script_cid = df_script.explode('character_id').reset_index(inplace=False, drop=True)\ndf_script_lid = df_script.explode('location_id').reset_index(inplace=False, drop=True)\ndf_script_spoken = df_script.explode('spoken_words').reset_index(inplace=False, drop=True)\ndf_script_normalized = df_script.explode('normalized_text').reset_index(inplace=False, drop=True)",
          " Merge episodes and locations dataframes\ndf_episodes_locations = df_episodes.merge(df_locations, left_on='id', right_on='episode_id').drop('episode_id', axis=1)",
          "Show the first few lines of each dataframe to understand their structure\ndf_episodes.head(), df_characters.head(), df_locations.head(), df_script.head()",
          "Check the data schema",
          " Good job! Now we have successfully imported the necessary datasets for our analysis.",
          "Tokenize, lemmatize, remove stopwords and punctuation, and lowercase the text\nnlp = spacy.load('en_core_web_sm')\n\n# Remove unwanted characters, stopwords, and make everything lowercase\nstopwords = spacy.lang.en.stop_words.STOP_WORDS",
          " Join all datasets",
          "# Function to load data from CSV files\ndef load_data(file_name):\n    return pd.read_csv(file_name).reset_index(inplace=False, drop=True)",
          "change columns to lower case and replace ' ' by '_'\ndf_characters.columns = [col.lower().replace(' ', '_') for col in df_characters.columns]\ndf_locations.columns = [col.lower().replace(' ', '_') for col in df_locations.columns]\ndf_script.columns = [col.lower().replace(' ', '_') for col in df_script.columns]\ndf_episodes.columns = [col.lower().replace(' ', '_') for col in df_episodes.columns]",
          "# Cleaning Strings\ndf_characters = df_characters.dropna(subset=['name', 'normalized_name'])\ndf_locations = df_locations.dropna(subset=['name', 'normalized_name'])\ndf_script = df_script.dropna(subset=['character_id', 'location_id', 'raw_text'])\ndf_episodes = df_episodes.dropna(subset=['title'])",
          "Load the necessary data files for analysis and processing.",
          "##### Section 1: DataFrame Cleaning and Preparation #####\n",
          "Show sample lines from the script\ndf_script.head()",
          "Count the number of unique characters in the dataset\nlen(df_characters['character_id'].unique())",
          "Inspect the scripts DataFrame\ns = [i / len(df_script) for i in range(len(df_script))]\nsample = df_script.sample(frac=0.1)\nseries = sample.groupby('episode_id').count()['id']",
          "Join the datasets on the numeric column.",
          "Print the head of the 'script' dataset\ndf_script.head()",
          "Just ensure that the path to the data files is correct.",
          "sampling data\ndf_characters = df_characters.sample(20)\ndf_locations = df_locations.sample(5)\ndf_episodes = df_episodes.sample(20)",
          "Load Spacy large library on disk\nnlp = spacy.load('en_core_web_lg', disable=['ner', 'parser'])",
          "Let's see the first rows of each one of the files to better understand them.\n\nprint(\"Characters:\")\nprint(df_characters.head())\nprint(\"Locations:\")\nprint(df_locations.head())\nprint(\"Script:\")\nprint(df_script.head())\nprint(\"Episodes:\")\nprint(df_episodes.head())",
          "Look at the first few rows of df_script\ndf_script.head()",
          "Display the dataframe types\nprint(df_characters.dtypes)\nprint(df_locations.dtypes)\nprint(df_script.dtypes)\nprint(df_episodes.dtypes)",
          "Display the first rows of the table containing the simpsons scripts.",
          "Resize the amount of data we are going to work with. For this version, our machine learning model will be trained with 20,000 lines of dialogue.",
          " Display the pandas dataframe containing the scripts of the Simpsons episodes\ndf_script",
          "Merge the datasets together to create a unified view of the data.",
          "# Helper functions\ndef clean_text(text):\n    # For now, we simply remove non-alphanumeric characters and multiple spaces\n    return re.sub(r'[^A-Za-z0-9 ]+', '', text).lower().replace('  ', ' ').strip()\n\ndef get_episode_name(df, episode_id):\n    episode = df[df.id == episode_id]\n    if len(episode) > 0:\n        return episode.iloc[0].title\n    return ''",
          "take a look at the available columns in the dataset\nprint(df_script.columns)",
          "# create a column for every episode/character combination and populate it with line_index\nep_char_comb = pd.merge(df_script[['episode_id', 'character_id','line_index']],\n                        pd.crosstab(df_script['line_index'], df_script['character_id'])\n                                .reset_index(inplace=False),\n                        on='line_index',\n                        how='left')",
          "# shows the first 5 lines of each dataframe\nprint(df_characters.head())\nprint(df_locations.head())\nprint(df_script.head())\nprint(df_episodes.head())",
          "Some functions from the script\ndef get_entity_text(text, entities):\n    '''Return text of the entites in the text'''\n    entities = eval(entities)\n    text = str(text)\n    new_txt = text\n    shifts = 0\n    for entity in entities:\n        if entity[0]+shifts != entity[1]+1+shifts:\n            new_txt = new_txt[:entity[0]+shifts] + '`' + text[entity[0]+shifts:entity[1]+1+shifts] + '`' + new_txt[entity[1]+1+shifts:]\n            shifts += 2\n        else:\n            new_txt = new_txt[:entity[0]+shifts] + '`' + '`' + new_txt[entity[0]+shifts:]\n            shifts += 1\n    return new_txt",
          "Setting index on 'id' column for easy reference",
          "print('Script dataframe: -' + str(len(df_script)) + \"- entries, \"+ str(len(df_script['episode_id'].unique())) + \" unique episodes.\" )",
          "Check our datasets\ndf_characters.head()",
          "Filter characters whose names contain last_name or first_name\nmain_characters = [name for name in df_characters.character_name.unique() if ((last_name in name) or (first_name in name))]",
          "Remove trailing whitespace from columns\ndf_characters.columns = df_characters.columns.str.strip()\ndf_locations.columns = df_locations.columns.str.strip()\ndf_script.columns = df_script.columns.str.strip()\ndf_episodes.columns = df_episodes.columns.str.strip()",
          "Print the shape of the datasets\nprint(df_characters.shape, df_locations.shape, df_script.shape, df_episodes.shape)",
          "Define the characters' speech as the features, and the characters as the target.",
          "Combine Episodes and Script dataframes.",
          "Merge the data into one dataframe",
          "Split text into words using SpaCy's English tokenizer.",
          "Merge script with episodes\ndf = df_script.merge(df_episodes, on='episode_id')\n# Create a date field\ndf['date'] = pd.to_datetime(df['original_air_date'])\n# BeautifulSoup is cleaner\ndf['raw_text_clean'] = df['raw_text'].str.replace('<.*>', '')",
          " Set context\n# I usually do it in this way to not mess with the original df\ndf = df_script",
          " Defines characters as main characters only",
          "Clean the script of incorrect or empty values and reset index afterward.",
          "Extract data requirements for specific questions",
          " Set the relevant columns to string, we don't want to perform numeric operations on them\ndf_script['raw_character_text'] = df_script['raw_character_text'].astype(str)\ndf_script['spoken_words'] = df_script['spoken_words'].astype(str)\ndf_script['raw_location_text'] = df_script['raw_location_text'].astype(str)\ndf_episodes['title'] = df_episodes['title'].astype(str)",
          "Let's take a look at each of the datasets and determine if any preprocessing is necessary.",
          " Check datasets \ndf_characters.head()",
          "Quickly displaying basic information about the datasets",
          "Filter the script data to only keep the rows from the training set and the characters and locations available in the corresponding dataframes.",
          "Get an overview of the characters dataset\nprint(df_characters.head())\n\n# Get an overview of the locations dataset\nprint(df_locations.head())\n\n# Get an overview of the script lines dataset\nprint(df_script.head())\n\n# Get an overview of the episodes dataset\nprint(df_episodes.head())",
          "Let's take a quick look at the first few rows in each DataFrame to understand the data better.",
          "Set filepath here\nfilepath = \"data/episodes\"",
          "Import of Dataframes successfully executed",
          "Cleaning the column names\ndf_episodes.columns = [e.lower().replace(' ', '_') for e in df_episodes.columns]\ndf_script.columns = [e.lower().replace(' ', '_') for e in df_script.columns]\ndf_characters.columns = [e.lower().replace(' ', '_') for e in df_characters.columns]\ndf_locations.columns = [e.lower().replace(' ', '_') for e in df_locations.columns]",
          "Preview of the first 5 rows of each dataframe\nprint(\"df_characters:\")\nprint(df_characters.head())\nprint(\"df_locations:\")\nprint(df_locations.head())\nprint(\"df_script:\")\nprint(df_script.head())\nprint(\"df_episodes:\")\nprint(df_episodes.head())",
          "Lets see what the contents look like",
          "Optional (this script is designed to select a sub-dataset to reduce memory consumption.\n# scripts for visualizations)",
          "Check the first few rows of the episodes dataframe",
          "Check if these work correctly",
          "# Get all lines and characters of an episode\ndef get_episode_lines_chars(season, episode):\n    df_episode = df_script[(df_script[\"season\"]==season) & (df_script[\"episode\"]==episode)]\n    df_episode_chars = df_episode[\"character_id\"].value_counts().to_frame().merge(df_characters, left_index=True, right_on=\"id\")\n    df_episode_chars.columns = [\"count\", \"character_id\", \"name\", \"normalized_name\", \"gender\", \"description\", \"color\", \"image\"]\n    \n    return df_episode, df_episode_chars",
          "Clean the script data\ndf_script_cleaned = df_script[(df_script['speaking_line'] == True) & (df_script['character_id'] != 0)]\n\n# Join character information\ndf_script_cleaned = df_script_cleaned.merge(df_characters, how='left', on='character_id')\n\n# Join location information\ndf_script_cleaned = df_script_cleaned.merge(df_locations, how='left', on='location_id')\n\n# Join episode information\ndf_script_cleaned = df_script_cleaned.merge(df_episodes, how='left', on='episode_id')\n\n# Display the first few rows of the cleaned script data\ndf_script_cleaned.head()",
          "Check the contents of the dataset\ndf_script.head()",
          " Remove rows where the episode id, character id, or location id are empty/null\ndf_script = df_script[df_script['episode_id'].notna()]\ndf_script = df_script[df_script['character_id'].notna()]\ndf_script = df_script[df_script['location_id'].notna()]",
          "Some adjustments\npd.options.display.max_columns = None",
          "Sample of how the data looks like\nprint(\"Characters data sample\")\nprint(df_characters.head(n=5))",
          "Create a copy of the script data to work with\nscript_lines_copy = df_script.copy()",
          "Change size of the `script` column.\n\ndf_script['raw_text'] = df_script['raw_text'].astype('string')",
          "Create a directory to store visualizations if not present",
          "Clean the script and the character names",
          " visualize\nfrom spacy import displacy",
          "Create a \"Scripted_line\" that join the \"spoken_words\" of each character and each location",
          "# Display the data to understand the structure\ndf_script.head()",
          "Create test sets that have the same items but in a different order\ntest_set1 = {1, 2, 3}\ntest_set2 = {3, 1, 2}",
          "Merge the dataframe tables `df_script`, `df_locations`, `df_characters` and `df_episodes` on the common columns.",
          "Printing the first few lines of each dataframe to see what they look like\nprint(df_characters.head())\nprint(df_locations.head())\nprint(df_script.head())\nprint(df_episodes.head())",
          "Set plot style\nplt.style.use('fivethirtyeight')",
          "Remove character ids which are continuous and start which 1 and are present in the charcater csv from the scripts dataframe",
          "Sample the dataframe by printing each distinct value and it's frequency\nfor idx, value_count in df_characters.nunique().iteritems():\n    print(idx, value_count)",
          "Check the 5 characters in the df_characters dataframe",
          "Set OS encoding to UTF-8",
          "Inspects the first few rows of the scripts dataframe\ndf_script.head()",
          " Let's take a look at the first few rows from each dataframe to understand the data better.",
          "Let's take a look at the first few rows of each dataframe to understand the data better.",
          "For full transparency I will provide the first few rows of the dataframe",
          "check the first row for each dataframe\nprint(df_characters.head(1))\nprint(df_locations.head(1))\nprint(df_script.head(1))\nprint(df_episodes.head(1))",
          "Create a new column in df_script with the number of words in the utterance.",
          "Check the first few lines of the characters dataframe.",
          "Check the first few rows of each dataframe\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()",
          "Visualize number of lines per season",
          "The columns we are interested in are:\ndf_script: \"episode_id\", \"number\", \"raw_text\"\ndf_episodes: \"id\", \"title\", \"original_air_date\"\ndf_locations: \"id\", \"name\"\ndf_characters: \"id\", \"name\"",
          "Check the downloaded dataito see what we are working with\nprint('characters:', df_characters.shape)\nprint('locations:', df_locations.shape)\nprint('script:', df_script.shape)\nprint('episodes:', df_episodes.shape)",
          "To ensure the data is loaded properly, let's print out the first few rows of each dataframe.",
          "Remove nonsense lines with length of less than 10 from the dataset",
          "Setting correct datatypes for the dataframes",
          " Visualize episodes per season\ndf_episodes.groupby('season')['id'].count().plot(kind='bar', color='skyblue', figsize=(15, 7))",
          "Checking few records\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()",
          "# Show first rows of the characters table\ndf_characters.head()",
          " Check the list of transcript's columns to use the one we want to.",
          "Display a sample of the dataframe containing the script lines",
          "Preview data files\nprint(df_characters.head())\nprint(df_locations.head())\nprint(df_script.head())\nprint(df_episodes.head())",
          "TODO: Add description",
          "Check the loaded dataframes\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()",
          "Just look up the head of all the dataframe to see everything looks fine\nfor df in [df_characters, df_locations, df_script, df_episodes]:\n    print(df.head())",
          "Set up matplotlib.rcParams, then make all plots.",
          "Rename columns to lowercase and replace spaces with underscores\ndf_characters.columns = [col.lower().replace(' ', '_') for col in df_characters.columns]\ndf_locations.columns = [col.lower().replace(' ', '_') for col in df_locations.columns]\ndf_script.columns = [col.lower().replace(' ', '_') for col in df_script.columns]\ndf_episodes.columns = [col.lower().replace(' ', '_') for col in df_episodes.columns]",
          " Check the data types of each column\ndf_script.dtypes",
          " Clean up the datasets\ndf_locations = df_locations.drop(columns=['id', 'normalized_name'])\ndf_characters = df_characters.drop(columns=['id', 'normalized_name'])\ndf_episodes = df_episodes.drop(columns=['id'])\n\n# Filter script to only load rows from the first 8 seasons",
          "Check the content of the loaded DataFrames\nprint(df_characters.head())\nprint(df_locations.head())\nprint(df_script.head())\nprint(df_episodes.head())",
          "Since we already have the scripts, characters, and locations data, we will focus on text preprocessing, including part-of-speech tagging and named entity recognition.",
          "Displaying the data and checking dtypes to understand the data better\nprint(df_characters.head())\nprint(df_characters.dtypes)\n\nprint(df_locations.head())\nprint(df_locations.dtypes)\n\nprint(df_script.head())\nprint(df_script.dtypes)\n\nprint(df_episodes.head())\nprint(df_episodes.dtypes)",
          "We can start by exploring the first rows of each dataframe to understand the structure and contents of the data we are dealing with.",
          "NLP model for Named Entity Recognition (NER)\nnlp = spacy.load('en_core_web_sm')",
          "Display the first few rows of the table to check the proper loading of data\ndf_characters.head()",
          "Visualizing the distribution of character genders.",
          " Merge character information\ndf_episodes_characters = (\n    df_episodes.merge(df_script, how='left', on='episode_id')\n    .merge(df_characters, how='left', on='character_id', suffixes=['_ep', '_ch'])\n    .sort_values(by=['id_ep', 'timestamp_in_ms'])\n)",
          "Check the first few rows of each dataset\nprint(\"Characters:\")\nprint(df_characters.head())\n\nprint(\"\\nLocations:\")\nprint(df_locations.head())\n\nprint(\"\\nScript:\")\nprint(df_script.head())\n\nprint(\"\\nEpisodes:\")\nprint(df_episodes.head())",
          "Check to see if the imports and data were loaded correctly\n# Display the first few rows of each dataframe\nprint('Characters dataframe shape:', df_characters.shape)\nprint(df_characters.head(3))\nprint('\\n')\n\nprint('Locations dataframe shape:', df_locations.shape)\nprint(df_locations.head(3))\nprint('\\n')\n\nprint('Script dataframe shape:', df_script.shape)\nprint(df_script.head(3))\nprint('\\n')\n\nprint('Episodes dataframe shape:', df_episodes.shape)\nprint(df_episodes.head(3))",
          " Selecting the season from \"df_episodes\" dataframe.",
          "Create a spacy nlp object\nnlp = spacy.load('en_core_web_sm')",
          "Check dimensions of the datasets to make sure nothing is misaligned\nprint(\n    \"Characters:\\t\", df_characters.shape,\n    \"\\nLocations:\\t\", df_locations.shape,\n    \"\\nScript:\\t\\t\", df_script.shape,\n    \"\\nEpisodes:\\t\",  df_episodes.shape\n)",
          "We will now begin exploring the dataset to understand its structure and contents.",
          "Set up colors for plotting\ncolors = {\n    'other': '#adb0ff',\n    'male': '#ffb3e6',\n    'female': '#90d595'\n}",
          "Creating a full dataframeумент with all the columns together",
          "def preprocess_dialogue(dialogue):\n    \"\"\"\n    Function to preprocess dialogue text data\n    \n    Args:\n    dialogue - A string containing the dialogue\n    \n    Returns:\n    clean_dialogue - The preprocessed and cleaned dialogue\n    \"\"\"\n    # Convert to lowercase\n    dialogue = dialogue.lower()\n    \n    # Remove extra whitespaces\n    dialogue = ' '.join(dialogue.split())\n    \n    # Replace 'uh-huh' with 'yes'\n    dialogue = dialogue.replace('uh-huh', 'yes')\n    \n    # Replace 'uh-uh' with 'no'\n    dialogue = dialogue.replace('uh-uh', 'no')\n    \n    # Remove laughter 'haha', 'hahaha', 'hahahaha', etc\n    dialogue = dialogue.replace('ha', '')\n    \n    return dialogue",
          " We will leave the Timestamp as it is, we will drop the other character_colums, and the raw text, we will leave the spoken_words since that's the one we will make embeddings about",
          "Clean the script dataframe",
          "Data overview",
          "Join the data frames to make the master data set",
          "Set up working directory\nos.chdir('C:/Users/novir/github/simpsons_analysis')",
          "Let's focus on script lines for this part of the analysis, specifically the spoken words.",
          " Set the display columns for the DataFrame to avoid truncation of the data",
          "Enable the tqdm \"notebook\" extension\ntqdm.pandas()",
          "# remove unused columns\ndf_script.drop(columns=['number', 'raw_text', 'timestamp_in_ms'], inplace=True)",
          "Compute values for training samples.",
          "Define a function to create a word cloud from a given text",
          "Display all the columns and the first five rows of the df_characters dataframe\ndf_characters.head()",
          "Visualize data\ndf_script.head()",
          "Display data\nwith pd.option_context('display.max_rows', None):\n    display(df_characters.describe())\n    display(df_locations.describe())\n    display(df_script.describe())\n    display(df_episodes.describe())",
          "Join all data.",
          "Create a directory within the data directory\ndirectory = 'data/wordclouds/'\nif not os.path.exists(directory):\n    os.makedirs(directory)",
          "Generate word cloud of the entire Simpsons script\nscript = \" \".join(df_script['spoken_words'].fillna(\"\"))",
          "View first 5 rows of characters DataFrame\ndf_characters.head()",
          " Clean character names\ndf_characters.character_id = df_characters.character_id.apply(str)\ndf_script.character_id = df_script.character_id.apply(str)",
          "Inspecting the character data\nprint(df_characters.head())",
          "instantiate spacy\nnlp = spacy.load('en_core_web_sm')\n\n# function to preprocess the data\ndef process(text, model=nlp, max_length=1000000):\n    text = text[:max_length]\n    doc = model(text)\n    return [ent.text for ent in doc.ents]",
          " Setting the seed for reproducibility\nnp.random.seed(0)",
          "We will remove the first column, which is the index column, and start by displaying a few lines from each dataframe.",
          "Print the shape and column names of the loaded data\nprint(\"Characters\")\nprint(df_characters.shape, df_characters.columns)\nprint('--'*24)\nprint(\"Locations\")\nprint(df_locations.shape, df_locations.columns)\nprint('--'*24)\nprint(\"Script\")\nprint(df_script.shape, df_script.columns)\nprint('--'*24)\nprint(\"Episodes\")\nprint(df_episodes.shape, df_episodes.columns)\nprint('--'*24)",
          "\n# Small prepossessing of the csv files\ndf_script = df_script.dropna(subset=['normalized_text'])\ndf_script['character_id'] = df_script['character_id'].fillna(-1).astype(int)",
          "Read all the datasets and reset the index to ensure the data is properly formatted.",
          "Extract the main fields and linking key from the script dataframe.",
          "Display the dataframes to check they have been loaded correctly\ndf_characters",
          "Merge Simpsons scripts with character info\ndf = pd.merge(df_script, df_characters, on='character_id', how='inner')\n\n# Show the first few rows of the dataframe\ndf.head()",
          "Let's have a look at one of our datasets, `df_script`.",
          "Display the dataframe once more to ensure the data has been loaded correctly",
          "Filter by character\ndf_script['character_id'] = df_script['character_id'].astype(str)  # convert to str for consistency\ndf_characters['id'] = df_characters['id'].astype(str)  # convert to str for consistency",
          "Filter for only the Simpsons family members, remove stage directions, and only include the speaking lines",
          "Exploratory data analysis",
          "Test if characters and locations are in the script dataframe\ncharacters_in_script = [char.lower() for char in df_script['raw_character_text'].unique()]\nlocations_in_script = [loc.lower() for loc in df_script['raw_location_text'].unique()]",
          "List of unique characters\nprint(\"Number of characters: {}\".format(len(df_characters.character_id.unique())))\ndf_characters.head()",
          "# Ensure the scripts are in order\ndf_script.sort_values(['episode_id', 'timestamp_in_ms'], inplace=True)",
          "Extract the lines from the episode where Homer says 'doh'",
          " Reading word frequency data",
          " Explore the dataframes sizes and first rows\nprint(\"Characters dataframe - rows:\", df_characters.shape[0], \"columns:\", df_characters.shape[1])\nprint(\"Locations dataframe - rows:\", df_locations.shape[0], \"columns:\", df_locations.shape[1])\nprint(\"Script dataframe - rows:\", df_script.shape[0], \"columns:\", df_script.shape[1])\nprint(\"Episodes dataframe - rows:\", df_episodes.shape[0], \"columns:\", df_episodes.shape[1])\n\ndf_script.head()",
          "Show all available data\npd.set_option('display.max_columns', None)\npd.set_option('display.max_colwidth', -1)\n\nprint('\\ndf_characters:', df_characters.shape)\ndisplay(df_characters.head(3))\n\nprint('\\ndf_locations:', df_locations.shape)\ndisplay(df_locations.head(3))\n\nprint('\\ndf_script:', df_script.shape)\ndisplay(df_script.head(3))\n\nprint('\\ndf_episodes:', df_episodes.shape)\ndisplay(df_episodes.head(3))",
          "What is the most relevant information in the datasets?",
          " check the datasets\nprint(df_characters.head(5))\nprint(df_locations.head(5))\nprint(df_script.head(5))\nprint(df_episodes.head(5))",
          " Remove duplicate lines and keep the last version of the line",
          "Preview the first 5 rows of each dataframes\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()",
          "Preview the first few lines of each table to understand what we are dealing with\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()",
          "ensure data consistency\ndf_script = df_script[df_script['episode_id'].isin(df_episodes['id'])]\ndf_locations = df_locations[df_locations['id'].isin(df_script['location_id'])]\ndf_characters = df_characters[df_characters['id'].isin(df_script['character_id'])]",
          "Merge the lines with the others DataFrames. This way we can have access to the episode information within the lines dataframe.",
          " Each dataset contains:",
          "NLP Library\nnlp = spacy.load('en_core_web_sm')",
          "Create a pandas series with the base names, surnames and full names of the characters.",
          "Inspect dataframe shapes\nprint(df_characters.shape)\nprint(df_locations.shape)\nprint(df_script.shape)\nprint(df_episodes.shape)",
          "Inspect first few rows of each dataset\nprint(df_characters.head())\nprint(df_locations.head())\nprint(df_script.head())\nprint(df_episodes.head())",
          "Fixing some data problems here",
          "Check if GPU is available\nimport tensorflow as tf\nprint(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))",
          "Ensure data is as expected\ndisplay(df_characters.head(5))\ndisplay(df_locations.head(5))\ndisplay(df_script.head(5))\ndisplay(df_episodes.head(5))",
          "Use the following line to remove the script line used for talks:\n# (by putting it in the footer and then reading the CSV)",
          "# Strip leading and trailing whitespaces from string columns\ndf_script = df_script.apply(lambda x: x.str.strip() if x.dtype == \"object\" else x)",
          " We'll also set the appropriate data types for each of the columns and perform other necessary data cleaning steps.",
          " GloVe embeddings\nembeddings_index = {}\nf = open(os.path.join('data/glove.6B.100d.txt'), encoding=\"utf-8\")\nfor line in f:\n    values = line.split()\n    word = values[0]\n    coefs = np.asarray(values[1:], dtype='float32')\n    embeddings_index[word] = coefs\nf.close()",
          " filter to keep only one character_location\ndf_filtered_locations = df_locations[df_locations['raw_location_text'].str.lower().isin(df_script['raw_location_text'].str.lower().unique())].copy()",
          "View all datasets\ndisplay(df_characters.head(3))\ndisplay(df_locations.head(3))\ndisplay(df_script.head(3))\ndisplay(df_episodes.head(3))",
          " Optional (if you want visible changes in your word cloud)\nmatplotlib.rcParams['figure.figsize'] = [10, 8]",
          " Filter nulls from location and characters dataframes\ndf_characters = df_characters.dropna(subset=['normalized_name']).reset_index(inplace=False, drop=True)",
          "# Display the number of lines we have for each character\nlines_by_character = df_script['raw_character_text'].value_counts()\nlines_by_character",
          " Display basic information about the datasets",
          "The simpsons script is a flattened version of the episodes where each line is a new entry in the table.",
          "Print the first few rows of the dataset for sanity check\nprint(df_characters.head())\nprint(df_locations.head())\nprint(df_script.head())\nprint(df_episodes.head())",
          "to retain the original dataframes unchanged, let's make copies of them for data processing:",
          "Extract lines from the script that absolutely fit in the simpsons_episodes DataFrame",
          "Create new column with the script's length for each character and unite the data into a single DataFrame",
          "Initial filtering and cleanup\n# Basic cleanup. Most important, we convert the column type of episode_id to int, further below we need that for filtering.\ndf_script_filtered = df_script.dropna(subset=['raw_text', 'character_id'])\n\n# Merge duplicates and do other cleanup operations\ndf_characters = df_characters.set_index('id').sort_index()\ndf_characters['name'] = df_characters['name'].str.lower()",
          "def_prune_dataset(df_script=df_script,\n                    df_characters=df_characters,\n                    df_locations=df_locations,\n                    df_episodes=df_episodes,\n                    list_lowercase_stopwords=['the', 'and', 'a', 'in', 'to', 'of', 'on', 'for', 'is', 'that',\n                                              'with', 'as', 'by', 'at', 'from', 'up', 'down', 'into', 'out', 'over',\n                                              'off', 'be', 'are', 'were', 'we', 'you', 'your', 'they', 'their', 'them'],\n                    list_successful_episodes=list_successful_episodes)",
          "VIEW ALL AVAILABLE DATA\ndf_script",
          "\n# Display the first 5 rows of the Characters dataframe\ndf_characters.head()",
          "Setting ambiguous caharacters_id to -9\ndf_script['character_id'].fillna(-9, inplace=True)",
          " Print shape of each dataframe\nprint(f'Characters dataframe: {df_characters.shape}')\nprint(f'Locations dataframe: {df_locations.shape}')\nprint(f'Script dataframe: {df_script.shape}')\nprint(f'Episodes dataframe: {df_episodes.shape}')",
          "Enrich Data: Characters, Locations, and Scripts\n# Sort episodes by id\ndf_episodes = df_episodes.sort_values(by='id').reset_index(drop=True)\n\n# Filter the dataframes\ndf_script_en = df_script[df_script['raw_character_text'].notnull()]\ndf_script_en = df_script_en[df_script_en['raw_location_text'].notnull()]\n\n# Removing duplicates\ndf_script_en = df_script_en.drop_duplicates()\n\n# ensure `episode_id` column is integer\ndf_script_en['episode_id'] = df_script_en['episode_id'].astype(int)\n\n# merging the episode to the script\ndf_script_meta = df_script_en.merge(df_episodes[['id', 'title', 'original_air_date', 'production_code']], left_on='episode_id', right_on='id', how='right')\n\n# remove when `episode_id` is null\ndf_script_meta = df_script_meta[~df_script_meta['episode_id'].isnull()]\ndf_script_meta = df_script_meta.drop(['id', 'number', 'timestamp_in_ms'], axis=1)\ndf_script_meta = df_script_meta.sort_values(by=['episode_id', 'id']).reset_index(drop=True)\n\n# install spacy model\n!python -m spacy download en_core_web_sm",
          " View available data\nprint(\"Characters\")\nprint(df_characters.head())\nprint(\"Locations\")\nprint(df_locations.head())\nprint(\"Script\")\nprint(df_script.head())\nprint(\"Episodes\")\nprint(df_episodes.head())",
          "Create an entity recognizer and add it to the pipeline",
          "With `inplace=False` we reset the index of the dataframe, and we avoid creating a new dataframe.",
          "Select only the lines with a speaking character and a proper location\ndf_script = df_script[(~df_script.raw_location_text.isna()) & (~df_script.character_id.isna())]",
          "Set maximum display rows/columns for better visual inspection",
          " We'll start by cleaning the dataset.",
          "Checking for correct import and dataframe display",
          "For the rest of the article, we'll focus only on the `df_script` DataFrame.",
          "Check the first few entries of each dataframe\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()",
          "Clean quotes\ndf_script['raw_character_text'] = df_script['raw_character_text'].apply(lambda x: \"\".join(i for i in x if ord(i)<128))",
          "Set the constants for matplotlib and spacy models.",
          "Examine the dataframes to see what we are working with",
          "Remove bad data from the lines dataset\ndf_script = df_script.astype({'timestamp_in_ms':'float64'}).dropna(subset=['timestamp_in_ms']).astype({'timestamp_in_ms':'int64'})\ndf_script = df_script.dropna(subset=['raw_text']).reset_index(drop=True)\n# df_script.info()",
          " Quick exploration of the tables to understand the structure of the data\ndisplay(df_characters.head())\ndisplay(df_locations.head())\ndisplay(df_script.head())\ndisplay(df_episodes.head())",
          "Merge script lines, characters and episodes\ndf_all = (\n    df_script[['episode_id', 'character_id', 'id']]\n    .merge(\n        df_episodes[['id', 'season', 'number']],\n        how='inner',\n        left_on='episode_id',\n        right_on='id'\n    )\n    .merge(\n        df_characters[['id', 'name']],\n        how='inner',\n        left_on='character_id',\n        right_on='id'\n    )\n    .drop(['id_x', 'id_y', 'episode_id', 'character_id'], axis=1)\n)\n\n# Add 'season_episode' column\ndf_all['season_episode'] = df_all['season'].astype(str) + '-' + df_all['number'].astype(str)\n\n# Replace character_id=-1 by character name 'unknown'\ndf_all['name'] = df_all['name'].mask(df_all['name'] == 'not said', 'unknown')\n\n# Display the final dataframe\ndf_all.head()",
          "Display all columns to decide which ones I want\npd.set_option('display.max_columns', None)\n\ndisplay(df_episodes.head(5))\ndisplay(df_characters.head(5))\ndisplay(df_locations.head(5))\ndf_script.head(5)",
          "Filter out bad data",
          " Create an empty DataFrame to store the statistics of each character\ndf_characters_statistics = pd.DataFrame(columns=['id', 'word_count'])",
          "Create a new dataframe with the episode title, character speaking, and spoken text.",
          "Prepare data for time-sliced analysis.",
          " Check if installation of spaCy worked\n# Also needs the model \"en_core_web_sm\" to be installed\nnlp = spacy.load('en_core_web_sm')",
          "Merge scripts with character information\ndf_script_extended = pd.merge(df_script, df_characters, how='left', left_on='character_id', right_on='id')\n\n# Create a list with all unique episode titles\nepisode_titles = df_episodes['title'].unique()\n\n# Create a dictionary with episode transcripts\nepisode_transcripts = {title: df_script[df_script['episode_id'] == id_]['normalized_text'].str.cat(sep=' ') \n                       for title, id_ in zip(episode_titles, df_episodes['id'])}",
          "Displaying one of the datasets to observe its structure\ndf_script.head()",
          "Filter script lines to eliminate bad data",
          " Look at data format, read a few lines",
          "Adds a few useful columns to df_script, such as \"spoken_words_count\", \"character_name\".",
          " Keep only the lines that contain any number of characters greater than 0\ndf_script = df_script[df_script['normalized_text'].str.len() > 0]",
          "Process the script to get the characters and locations that appear in each episode",
          "We will quickly have a look at the data to figure how we can proceed further.",
          "Check the size of each dataset\nprint(df_characters.shape)\nprint(df_locations.shape)\nprint(df_script.shape)\nprint(df_episodes.shape)",
          "Check if GPU is available\n# torch.cuda.is_available()",
          " Optionally set explore_mode to retrieve smaller random sample instead\nexplore_mode = False",
          "#Limiting characters and locations data to what is available in the script\nvalid_characters = df_script.character_id.unique()\ndf_characters = df_characters[df_characters.character_id.isin(valid_characters)]\nvalid_locations = df_script.location_id.unique()\ndf_locations = df_locations[df_locations.location_id.isin(valid_locations)]",
          "Create a directory to save the wordclouds if it does not exist\nwordcloud_dir = 'wordclouds'\nif not os.path.exists(wordcloud_dir):\n    os.makedirs(wordcloud_dir)",
          "Display the first 5 rows of each dataframe\ndfs = [df_characters, df_locations, df_script, df_episodes]\nfor df in dfs:\n    display(df.head())",
          "Filter only script line from the simpsons script file and get the character who says it, the episode id it is in and the text",
          "Display dataframes' shape and head\ndf_characters.shape, df_locations.shape, df_script.shape, df_episodes.shape",
          "Check first lines of the dataframes\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()",
          "# Convert raw text into word frequency representation\ndef word_frequency(text):\n    words = [word.text.lower() for word in nlp(text) if word.is_alpha and not word.is_stop]\n    word_freq = Counter(words)\n    return word_freq",
          "General properties\nprint(f\"Number of unique characters: {df_characters.shape[0]}\")\nprint(f\"Number of unique locations:  {df_locations.shape[0]}\")\nprint(f\"Number of episodes:           {df_episodes.shape[0]}\")",
          "Define some constants to make the scripts easier to read\nMIN_LINES = 50\nMIN_DIALOG_LEN = 4",
          "Set the date for the simpson_episodes dataframe",
          "Display the data\ndf_characters.head()",
          "\n# Fix some inconsistencies in the script dataset\n# Filter the data to remove unwanted records\n# Generate new features",
          "# Display how many unique characters and locations there are in The Simpsons\nprint(f\"Number of unique characters: {df_characters.shape[0]}\")\nprint(f\"Number of unique locations: {df_locations.shape[0]}\")",
          "Filter US only characters",
          " Split each line into words and stem each word\nscript_stemmed = [nlp(line) for line in tqdm(df_script['raw_text'])]",
          "erequisites for spacy's language model\nnlp = spacy.load('en_core_web_sm')\n\n# Since spacy's language model does not recognize simpsons words, we need to add simpsons vocabulary\nsimpsons_vocab = [\n    \"simpson\", \"hommer\", \"homer\", \"marge\", \"bart\", \"lisa\", \"magie\", \"krusty\", \"milhouse\", \"moe\",\n    \"burns\", \"skinner\", \"ned\", \"flanders\", \"apu\", \"barney\", \"lenny\", \"carl\", \"duff\", \"kang\", \"kodos\",\n    \"fat\", \"tony\", \"snake\", \"gil\", \"willie\", \"abe\", \"ralph\", \"jasper\", \"patty\", \"selma\", \"duffman\", \"troy\", \n    \"lionel\", \"hutz\", \"gil\",\n]",
          "We'll filter only the lines from Lisa.",
          "Drop useless columns that contain only NaN.\ndf_episodes = df_episodes.dropna(axis=1, how='all')",
          "Set script data types explicitly",
          "Checking shapes of dataframes",
          "Using driver function to parse the datasets for us\ndf_tuples = (\"Characters\", df_characters), (\"Locations\", df_locations), (\"Script\", df_script), (\"Episodes\", df_episodes)\nfor name, df in df_tuples:\n    print(name)\n    print(df.head())\n    print('\\n')",
          "Filter episodes\ndf_episodes_filtered = df_episodes[(df_episodes['original_air_year'] > 1989) & (df_episodes['original_air_year'] < 2000)]",
          "Fix line_break and initial spaces at the beginning and end of spoken words",
          "Filtering the script dataset to only keep the lines spoken by the main characters",
          " Filter the script to keep only the dialogue lines",
          "Function to remove irrelevant script information",
          " Character's names written in other languages to ignore\nsimps_char_names_ignore = ['Eliza Simpson', 'Spanish Homer', 'Harv Bannister', 'Grady Little', 'Roger Meyers', 'Lil\\' Hitler', 'Sylvester Stallone\\'s head', 'Mahatma Gandhi', 'Leon Kompowsky', 'Frankie the Squealer', 'English judge']",
          "### Data exploration and cleaning",
          "Check the shape and sample of the dataset\ndf_script.shape",
          " Check the shape of the imported data\nprint('Number of characters:', df_characters.shape[0])\nprint('Number of locations:', df_locations.shape[0])\nprint('Number of script lines:', df_script.shape[0])\nprint('Number of episodes:', df_episodes.shape[0])",
          "Inspecting the first 5 rows of the df_script dataframe",
          "Apply some fixes to the dataset and clean the text for further analyisis",
          "Selecting all the lines spoken by Homer Simpson and the name of the episode the lines belong to",
          "Replace nans in speaking line with empty string\ndf_script['normalized_text'] = df_script['normalized_text'].fillna('')",
          "Inspect the contents of the characters dataframe for any obvious issues\ndf_characters.head()",
          "Merge and print a sample of the data",
          "# Add episode number to the original dataframe\ndf_script['episode'] = df_script.apply(lambda x: df_episodes[(df_episodes['original_air_year'] == x['year']) & \n                                                             (df_episodes['season']==x['season'])]['number'].values[0] if len(df_episodes[(df_episodes['original_air_year'] == x['year']) & \n                                                                                                                                    (df_episodes['season']==x['season'])]['number'].values) > 0 else -1, axis=1)",
          "display(df_characters.head())\n#display(df_locations.head())\n#display(df_script.head())\n#display(df_episodes.head())",
          "Functions\ndef get_top_n_words(corpus, n=None):\n    vec = CountVectorizer(stop_words='english').fit(corpus)\n    bag_of_words = vec.transform(corpus)\n    sum_words = bag_of_words.sum(axis=0) \n    words_freq = [(word, sum_words[0, idx]) for word, idx in     vec.vocabulary_.items()]\n    words_freq =sorted(words_freq, key = lambda x: x[1], reverse=True)\n    return words_freq[:n]",
          "Inspect information of each dataframe\nprint('Characters dataframe')\ndisplay(df_characters.info())\ndisplay(df_characters.head())",
          "change this line if the script should be executed in Jupyter\nsns.set()",
          "[\"added\", \"chapter\", \"overview\", \"front\"]",
          "Define some utility functions for cleaning text and counting occurences of entities in each field",
          "# Extract scripts by characters\nlisa_lines = df_script[(df_script['normalized_name'] == 'lisa simpson') & (df_script['spoken_words'].notnull())]['spoken_words'].values\nmarge_lines = df_script[(df_script['normalized_name'] == 'marge simpson') & (df_script['spoken_words'].notnull())]['spoken_words'].values\nhomer_lines = df_script[(df_script['normalized_name'] == 'homer simpson') & (df_script['spoken_words'].notnull())]['spoken_words'].values\nbart_lines = df_script[(df_script['normalized_name'] == 'bart simpson') & (df_script['spoken_words'].notnull())]['spoken_words'].values",
          "Print out the head of each dataframe to explore the data\nprint(df_characters.head())\nprint(df_locations.head())\nprint(df_script.head())\nprint(df_episodes.head())",
          " Merge script and episodes\ndf_script_episodes = pd.merge(df_script, df_episodes, how='left', on='episode_id')\n\n# Clean\ndf_script_episodes_clean = df_script_episodes[\n    (df_script_episodes.raw_location_text != '')\n    & (df_script_episodes.raw_character_text != '')\n    & (df_script_episodes.spoken_words != '')\n].copy()",
          "Let's display the first few lines of each dataframe to see what they look like.",
          "iterate over character names that should be casted with actors.",
          "Let's check the size of the datasets",
          "# Define the evaluating function\ndef evaluate_representation(text_data, representation):\n    \"\"\"\n    Args:\n        text_data (string, pd.Series): The input text data\n        representation (spacy.tokens.doc.Doc): The representation we want to compare with the data\n    Returns:\n        pandas.core.series.Series: The similarity score for each data point\n    \"\"\"\n    return text_data.apply(lambda x: representation.similarity(nlp(str(x))))",
          "Import the data and show the first 5 rows",
          "# Helper class to create a dataset\nclass Dataset:\n    script_columns = ['id', 'episode_id', 'number', 'raw_text', 'timestamp_in_ms',\n                      'speaking_line', 'character_id', 'location_id', 'raw_character_text',\n                      'raw_location_text', 'spoken_words', 'normalized_text', 'word_count']\n\n    character_columns = ['id', 'name', 'normalized_name', 'gender']\n\n    location_columns = ['id', 'name', 'normalized_name']\n\n    episode_columns = ['id', 'title', 'original_air_date', 'production_code',\n                       'season', 'number_in_season', 'number_in_series',\n                       'us_viewers_in_millions', 'views', 'imdb_rating', 'imdb_votes']\n\n    def __init__(self, episodes_df, characters_df, locations_df, script_df):\n        self.episodes_df = episodes_df\n        self.characters_df = characters_df\n        self.locations_df = locations_df\n        self.script_df = script_df\n        self.script_df['normalized_text'] = self.script_df.normalized_text.astype(str)",
          "Set random seed\nnp.random.seed(0)",
          "Look at the first rows of the characters dataset\nprint(df_characters.head())",
          "Constants\navg_sentence_len = 100  # each element is smaller than average sentence length, i.e is smaller than 100",
          "Add encoding argument to read_csv calls to fix UnicodeDecodeError",
          "Tokenize the script lines to run some analysis on it\nnlp = spacy.load(\"en_core_web_sm\")",
          " Check dimensions of the datasets\nprint(\"Characters: \", df_characters.shape)\nprint(\"Locations: \", df_locations.shape)\nprint(\"Script: \", df_script.shape)\nprint(\"Episodes: \", df_episodes.shape)",
          "# Count the number of lines spoken by each character\nlines_per_character = df_script['character_id'].value_counts()\n\n# Count the number of locations where each character appears\nlocations_per_character = df_script.drop_duplicates(subset=['location_id', 'character_id'])['character_id'].value_counts()",
          "Filter out the 'simpsons_script_lines' and keep only the spoken lines",
          "Inspect the first 5 rows of each dataframe to understand its structure and data.",
          "function to tokenize a script line and remove stopwords",
          " We can see some simple statistics, as well as the top 10 first tokens.",
          "Check if GPU is there and the available RAM",
          "Add custom named entities to spaCy\nnlp = spacy.load('en_core_web_sm')\n\n# Function to add custom named entities to spaCy\ndef add_custom_named_entities(nlp, labeled_data):\n    for entry in labeled_data:\n        for token in entry[0].split(' '):\n            nlp.tokenizer.add_special_case(token, [{'ORTH': token}])\n    return nlp",
          "Visualizamos la primeras lineas de cada dataframe",
          "Iterate through all including folders and files",
          "Start by using the describe method to get a sense of the statistics for each variable.",
          "Find the main characters for each episode",
          "# Smaller dataset with male and female\ndf_script_small = df_script[(df_script['gender'] == 'm') | (df_script['gender'] == 'f')]\ndf_script_small = df_script_small.sample(10000, random_state=42)\n\n# \"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\n# \"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\n# Get word counter for each character\n",
          " Define constant colors\ncolors = {\n    'red': '#FF5733',\n    'light red': '#FF8566',\n    'green': '#59955C',\n    'blue': '#3559FF',\n    'yellow': '#E5CC00',\n    'light yellow': '#FFEB4D',\n    'secondary blue': '#33CCFF',\n    'purple': '#A239CA',\n    'orange': '#FF8C1A',\n    'black': '#1A1A1A',\n    'dark grey': '#333333',\n    'grey': '#808080',\n    'light grey': '#B3B3B3',\n    'white': '#FFFFFF'\n}",
          "Opt into using `resume_parser_ner_wiki_large` when using `spacy.load` as this one has the NER model loaded",
          " Sample data\ndf_script.head(), df_locations.head()",
          " Merge Echo and Hero columns in case they contain complementary information",
          "Transforming the script dataframe to include more useful information\ndf_script['episode_id'] = df_script.apply(lambda row: int(row['raw_text'].split('\\t')[1]), axis=1)\ndf_script['character'] = df_script.apply(lambda row: row['raw_text'].split('\\t')[2] if len(row['raw_text'].split('\\t')) > 2 else '', axis=1)\ndf_script['text'] = df_script.apply(lambda row: row['raw_text'].split('\\t')[-1], axis=1)\ndf_script = df_script.merge(df_episodes[['id', 'season', 'number', 'air_date', 'title']], how='left', left_on='episode_id', right_on='id')",
          "Detect entities and sentiment from the script using SpaCy.",
          "#number of script lines\nlen(df_script)",
          "Set randon seed for reproducibility\nnp.random.seed(0)",
          " Tokenize the script lines for later use",
          " Validate the import of the dataframes\ndisplay(df_characters.head(2))\ndisplay(df_locations.head(2))\ndisplay(df_script.head(2))\ndisplay(df_episodes.head(2))",
          " Split lines into a list",
          "Print the head of the dataframe to get an overview of the data\nprint(df_script.head())",
          "Merge script with characters and keep only necessary columns\ndf_lines = df_script.merge(df_characters, left_on='character_id', right_on='id', suffixes=('', '_char'))\ndf_lines = df_lines[['id', 'season', 'episode_id', 'number', 'raw_text', 'name']]\n\n# ",
          " Display a preview of each Data Frame\nprint('Characters Data Frame:')\nprint(df_characters.head())\nprint('\\nLocations Data Frame:')\nprint(df_locations.head())\nprint('\\nScript Data Frame:')\nprint(df_script.head())\nprint('\\nEpisodes Data Frame:')\nprint(df_episodes.head())",
          " Set up spacy\nnlp = spacy.load('en_core_web_sm', disable=['parser', 'tagger', 'ner'])\n\n# Setup pandas\npd.set_option('display.max_columns', None)",
          " Supprimer les script_lines qui ne sont pas dans simpsons_episodes",
          " Merge the necessary columns",
          "Visualize the characters dataset\ndf_characters.head()",
          "Sample the script dataframe",
          " Display a preview of each dataframe\nprint('Characters:')\ndisplay(df_characters.head())\nprint('\\nLocations:')\ndisplay(df_locations.head())\nprint('\\nScript:')\ndisplay(df_script.head())\nprint('\\nEpisodes:')\ndisplay(df_episodes.head())",
          "Printing the first five rows of each dataframe\nprint(df_characters.head())\nprint(df_locations.head())\nprint(df_script.head())\nprint(df_episodes.head())",
          "\nscripts = df_script[['normalized_text']].copy()",
          "Print number of characters and number of lines in the script\nprint(df_characters.shape[0])\nprint(df_script.shape[0])",
          "\n# Define helper functions and objects\nnlp = spacy.load('en_core_web_sm')",
          "Let's see the first few rows of each dataframe to understand the data better.",
          "Example of finished data loading and basic data information",
          "Let's start by examining the contents of each of the datasets.",
          "Checking data types and exploring missing values\nprint(df_script.info())",
          "# Do some data exploration to get a feel for the data\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()",
          "Memory usage of each DataFrame\nprint(\"Memory usage of each DataFrame\")\nprint(df_characters.info(memory_usage='deep'))\nprint(df_locations.info(memory_usage='deep'))\nprint(df_script.info(memory_usage='deep'))\nprint(df_episodes.info(memory_usage='deep'))",
          "# Let's check if the data has been correctly loaded\nprint('Characters:', df_characters.shape)\nprint('Locations:', df_locations.shape)\nprint('Scripts:', df_script.shape)\nprint('Episodes:', df_episodes.shape)",
          "Declare the plot style and color palette",
          " Display heads of all files to understand the data",
          "Check the contents of the characters dataset\nprint('Number of characters:', len(df_characters))\ndf_characters.head()",
          "Visualize the dataframe scripts using a treemap",
          "Let make sure we join the datasets correctly:",
          "Check the dataframes' dimensions",
          "Visual (Bar) representation of the split between female and male characters in the Simpsons",
          " Enable the TQDM notebook extension in order to display a progress bar for data processing tasks\ntqdm.pandas()",
          "Display script lines dataset\ndf_script.head()",
          "Check if the dataframe creation is successful\ndf_characters",
          "Verify that the datasets have been loaded correctly\nprint(df_characters.head())\nprint(df_locations.head())\nprint(df_script.head())\nprint(df_episodes.head())",
          "Check the contents of the characters table\ndf_characters.head()",
          "Display top 5 rows of each dataset to understand the data",
          "Change directory to the correct path\nos.chdir('./simpsons_dataset/')",
          " Now, we can take a look at the content of each dataset.",
          "Get the main characters from the script\nmain_characters = df_characters[df_characters['is_main_character'] == True]\nmain_characters_names = list(main_characters['name'].values)",
          "Create columns to easily identify character and location speaking or spoken about",
          "Create 'simpsons_corpus' and store path to Markovify chain JSON file\nsimpsons_corp_path = 'data/simpsons_corpus.json'",
          "Split the data into training and test sets",
          " Let's begin by taking a closer look at the data.",
          "How many unique characters are there in the dataset?\ndf_script['character_id'].nunique()",
          "View data head\ndf_script.head()",
          "Estimate size of each data frame\ndf_sizes = {'characters': df_characters.memory_usage().sum(),\n            'locations': df_locations.memory_usage().sum(),\n            'script': df_script.memory_usage().sum(),\n            'episodes': df_episodes.memory_usage().sum()}\ndf_sizes",
          "Print the head of each dataset to understand what kind of data we are working with.",
          " Display top 10 rows of each dataframe\nprint('Characters\\n')\nprint(df_characters.head(), '\\n\\n')\n\nprint('Locations\\n')\nprint(df_locations.head(), '\\n\\n')\n\nprint('Script\\n')\nprint(df_script.head(), '\\n\\n')\n\nprint('Episodes\\n')\nprint(df_episodes.head())",
          "Extract the main characters\nmain_characters = [\n    'marge', 'homer', 'bart', 'lisa', 'maggie', \n    'milhouse', 'krusty', 'burns', 'smithers', 'moe', \n    'ned', 'apu', 'barney', 'skinner', 'ralph', 'kent', \n    'gary', 'carl', 'lenny', 'chief', 'edna', 'selma', 'patty', \n    'maggie', 'todd', 'marty', 'rod', 'troy', 'lionel', 'patty'\n]\n\n# Load the spaCy model\nnlp = spacy.load('en_core_web_sm')",
          " Enable f-strings in Python 2.7\nfrom future.builtins import (bytes, str, open, super, range,\n                           zip, round, input, int, pow, object)",
          " Load the spacy model for preprocessing the text.",
          "Explore the contents of the dataset\nprint(df_characters.head())\nprint(df_locations.head())\nprint(df_script.head())\nprint(df_episodes.head())",
          "We can remove some entries from df_characters that do not contribute to our analysis.",
          "check loaded csvs\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()",
          "Filter the data to the characters of interest.",
          "Extract the characters only from the first 1000 episodes\ncharacter_names = df_characters[0]['detect_name']\ndf_episodes_top_1000 = df_script[df_script['episode_id'] <= 1000]\nscript_characters = df_episodes_top_1000['character_id'].unique()\nscript_df_characters = pd.DataFrame(script_characters, columns=['character_id'])",
          "Set dataset type and name\ndf_characters.name = 'characters'\ndf_locations.name = 'locations'\ndf_script.name = 'script'\ndf_episodes.name = 'episodes'",
          "Merge data and visualize the counts of character mentions in the script data\ndf_script = df_script.merge(df_episodes, on='episode_id', how='left')\ndf_script = df_script.merge(df_characters, on='character_id', how='left')\nchar_mention_cnts = df_script['name'].value_counts()\n\nplt.bar(char_mention_cnts.index, char_mention_cnts.values)\nplt.xlabel('Character Name')\nplt.ylabel('Number of Mentions')\nplt.title('Number of Mentions of Each Character in the Script')\nplt.xticks(rotation=90)\nplt.show()",
          "Drop unnecessary columns from characters dataframe\ndf_characters = df_characters.drop(columns=['Unnamed: 0'])",
          "Remove rows with empty lines and strip white spaces from any columns containing strings\nfor df in [df_characters, df_locations, df_script, df_episodes]:\n    starting_shape = df.shape\n    for col in df.columns:\n        if df[col].dtype == object:  # dtype 'object' means it's a string\n            df[col] = df[col].str.strip()  # Remove leading/trailing white spaces\n            df = df[df[col].notna()]  # Remove rows with empty strings\n    print(f\"Before removal - {df} shape: {starting_shape}, after removal: {df.shape}\")",
          "Explore the data - Have a look at the five first rows",
          " Set the seed for numpy random number generator for reproducibility\nnp.random.seed(5)",
          "View first 5 rows of the characters dataframe\ndf_characters.head()",
          "Set custom color palette\ncolors = ['#FF8C00', '#FF4500', '#FF0000', '#DC143C', '#B22222', '#8B0000', '#FFA07A', '#FA8072', '#E9967A', '#F08080', '#CD5C5C', '#DC143C']",
          "Print the shapes of the datasets\nprint(df_characters.shape)\nprint(df_locations.shape)\nprint(df_script.shape)\nprint(df_episodes.shape)",
          "Limiting script to the first character's line",
          "\n# Method to remove Special characters, URLs, and mentions\n",
          "Inspect each dataframe using the .info() and .head() methods to understand the data",
          "Check for missing data\ndf_characters.info()",
          " optional: inspect the datasets\ndf_characters.head()",
          "Check if we're in the correct folder",
          "Set random seed for reproducibility\nnp.random.seed(0)",
          "Simple view of the datasets",
          "# Convert speaker_id from string to int to match id in characters\ndf_script['character_id'] = pd.to_numeric(df_script['character_id'], errors='coerce').fillna(0).astype(int)",
          "Let's first take a look at how the data looks like.",
          "# Display first 5 rows of each dataframe to verify data has been loaded correctly\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()",
          "Apply the long version to the script dataframe",
          "Ensure target folders for visualization exist in the filesystem",
          "Select only the title, original_air_date, and us_viewers_in_millions columns from df_episodes.",
          "Add a column for the number of words in each script line",
          "We have successfully imported the necessary libraries and data.",
          "Column `episode_id` and `id` are common between `df_episodes` and `df_script`",
          "Inspect the first few rows of each dataframe to understand its structure and the kind of data we have",
          "Merge episodes and script datasets based on the episode id",
          "Explore the first lines of the characters dataset\ndf_characters.head()",
          "Display the shape of each dataframe to understand the dataset.",
          "Remove duplicates in the datasets",
          "Remove rows where the `ding_count` column is greater than 0",
          " Select only script lines in English\ndf_script_en = df_script[df_script['raw_text'].str.startswith('- ')]",
          "Let's take a glance at what's inside each DataFrame by displaying the first few rows.",
          "Display maximum columns and rows in dataframes\npd.set_option('display.max_columns', None)\npd.set_option('display.max_rows', None)",
          "Take a look at the first 5 rows of df_characters.\ndf_characters.head()",
          "Initial data overview",
          "Ignore data necessary for testing during production\ndf_script = df_script[df_script[\"episode_id\"].isin(df_episodes[df_episodes[\"production_code\"] != \"\"].index)]\ndf_script = df_script[df_script[\"character_id\"].isin(df_characters[df_characters[\"name\"] != \"\"].index)]\ndf_script = df_script[df_script[\"location_id\"].isin(df_locations[df_locations[\"name\"] != \"\"].index)]",
          "Properties of the dataset\nprint(f\"Number of characters: {df_characters.shape[0]}\")\nprint(df_characters.head())",
          "Exploring the structure of our data.",
          "Remove bad data in script, episodes and characters\ndf_characters = df_characters[(df_characters['name'] != '?') & (df_characters['normalized_name'] != '')].reset_index(inplace=False, drop=True)\ndf_locations = df_locations[(df_locations['name'] != '?') & (df_locations['normalized_name'] != '')].reset_index(inplace=False, drop=True)\ndf_episodes = df_episodes[(df_episodes['title'] != '?')].reset_index(inplace=False, drop=True)\ndf_script = df_script[df_script['character_id'].isin(df_characters['id'])]\ndf_script = df_script[df_script['location_id'].isin(df_locations['id'])]\ndf_script = df_script[df_script['episode_id'].isin(df_episodes['id'])]",
          "# Checking whether the df_characters dataframe has been loaded correctly\ndf_characters.head()",
          "\n# Join the main table with the character and location information\ndf = df_script.merge(df_characters, on='character_id', how='left')\ndf = df.merge(df_locations, on='location_id', how='left')\n\n# Remove script lines with no spoken words and associate them to a given episode\ndf = df[~df.raw_text.isna()]\ndf = df.merge(df_episodes, on='episode_id', how='left')",
          "Explore the first 5 rows of each of the DataFrames to understand the structure of the data.",
          "Select the main characters and the locations, which are those that have more than 500 lines spoken.",
          "Check the data format for each dataframe\nprint(df_characters.dtypes)\nprint(df_locations.dtypes)\nprint(df_script.dtypes)\nprint(df_episodes.dtypes)",
          "Define feature engineering pipeline using Transformers\nfrom sklearn.base import BaseEstimator, TransformerMixin\n\nclass BasicProcessing(BaseEstimator, TransformerMixin):\n    def fit(self, X, y=None):\n        return self\n\n    def transform(self, X, y=None):\n        X['usertagvalue'] = X['url'].apply(lambda x: x.split(':')[1] if isinstance(x, str) else '')\n        X['UUID'] = X['usertagvalue'].apply(lambda x: x.split('/')[0] if isinstance(x, str) else '')\n        return X",
          " Use tqdm to visualize progression of pandas apply\ntqdm.pandas()",
          "In order for this code to run, make sure you have the necessary data files in the specified paths or change the paths to match the location of the data files on your system.",
          "The dataset contains the following tables:",
          "Setting a dataframe as global will make it available in the entire script.",
          "Drop rows where gender data is incorrect (1 row) and duplicate index column",
          "In the dataset, the following fields are available:\n# - Characters\n# -- id: character id\n# -- name: character name\n# -- normalized_name: normalized character name\n# -- gender: character gender\n# -- normalized_gender: normalized character gender\n# -- number_of_dialogues: number of dialogues the character has\n# -- first_appearance: character's first appearance in the series\n# -- id: location id\n# -- name: location name\n# -- normalized_name: normalized location name\n# -- frequency: frequency of the location\n# - Script Lines\n# -- id: script line id\n# -- episode_id: episode id\n# -- number: line number in the episode\n# -- raw_text: raw text of the line\n# -- timestamp_in_ms: timestamp of the line\n# -- speaking_line: a boolean that indicates whether a character speaks the line\n# -- character_id: character id\n# -- location_id: location id\n# -- normalized_text: normalized line text\n# -- word_count: word count of the line text\n# - Episodes\n# -- id: episode id\n# -- title: episode title\n# -- original_air_date: original air date of the episode\n# -- production_code: production code of the episode\n# -- season: season in which the episode is\n# -- number_in_season: episode number in the season\n# -- number_in_series: episode number in the series\n# -- us_viewers_in_millions: number of US viewers, in millions, when the episode aired\n# -- views: number of views, in thousands\n# -- imdb_rating: imdb rating of the episode\n# -- imdb_votes: number of imdb votes for the episode\n# -- image_url: image url of the episode",
          "Read embeddings created by glove-python\ndf_embeddings = pd.read_csv('data/word_embeddings.csv')",
          "Display the first few lines of each dataframe to get an idea of its structure\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()",
          " Display the first few rows of each dataframe to get an idea of what the data looks like\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()",
          "merge the script and episodes into a single dataframe",
          "Check if the script contains lines of dialog_physically painful",
          "Displaying dataset samples\ndf_script.sample(10)",
          "Add newline character in the end",
          "# Show head of characters data\ndf_characters.head()",
          "# Definition of preprocessing function to remove time from the dialogue\ndef remove_scene_description(text):\n    return text.split(':')[-1]",
          "Filter non-ascii characters to avoid encoding issues\ndf_script = df_script[df_script['raw_character_text'].apply(lambda x: x.isascii())]\ndf_script = df_script[df_script['raw_location_text'].apply(lambda x: x.isascii())]",
          "Check for corrupted data\ndf_script.info()",
          "# For this notebook, we are going to look at the script DataFrame\ndf_script.head()",
          "View first 5 rows of the characters dataframe\ndf_characters.head()",
          " Define the character models to use for NER (Named Entity Recognition)",
          "Combien y a-t-il de personnages dans la table `df_characters` ?",
          "Creating a virtual environment",
          "Extract the training and test set",
          "Make a copy of each dataframe",
          "Visualize the number of episodes per season\ndf_episodes['season'].value_counts().sort_index().plot(kind='bar', figsize=(15, 10), color='skyblue')",
          "Compute total number of words spoken by each character\ndf_characters_spoken_words = df_script.groupby('character_id')['spoken_words'].sum()\ndf_characters_spoken_words.sort_values(ascending=False, inplace=True)",
          " GloVe word vectors\n!pip install -U gensim\n\nimport gensim.downloader as api\n\nword_vectors = api.load(\"glove-wiki-gigaword-100\")",
          "Filter out incomplete script lines and join the tables",
          "Checking if all the DataFrames have been loaded successfully\nprint(f'Simpsons Characters: {df_characters.shape}')\nprint(f'Simpsons Locations: {df_locations.shape}')\nprint(f'Simpsons Script: {df_script.shape}')\nprint(f'Simpsons Episodes: {df_episodes.shape}')",
          "Fix character names (for joins)",
          "Let's start by checking the first rows of each dataset to become familiar with the data.",
          "Lowercase the name fields for better linking",
          "Filter df_characters, df_locations and df_script to the main characters and locations",
          " It's important to reset the index after reading the dataframes.",
          "# Joining dataframes\ndf_episodes['id'] = df_episodes['id'].astype(int)\ndf_script['episode_id'] = df_script['episode_id'].astype(int)\n\ndf = pd.merge(df_script, df_episodes, left_on='episode_id', right_on='id', suffixes=('_script', '_episodes'))\ndf = df[['id_script', 'episode_id', 'number', 'raw_text', 'timestamp_in_seconds',\n         'id_episodes', 'title', 'original_air_date', 'production_code', 'season', 'number_in_season',\n         'number_in_series', 'us_viewers_in_millions', 'views', 'imdb_rating', 'imdb_votes']]",
          "Split the script into Story and coaching content.",
          "Inspect the dataframes for any necessary cleaning or preprocessing.",
          "Join datasets",
          " Load model from spacy\nnlp = spacy.load('en_core_web_sm')\n\n# Spacy pipeline\nnlp.add_pipe('sentencizer')",
          "\n# Create dictionary to map locations to characters\nlocation_to_characters = {\n    location: set(df_script[df_script['raw_location_text'] == location]['raw_character_text'])\n    for location in df_script['raw_location_text'].unique()\n}",
          "Check what kind of data we have for characters, locations, scripts, and episodes\nprint('Characters')\nprint(df_characters.head(), end='\\n\\n')\n\nprint('Locations')\nprint(df_locations.head(), end='\\n\\n')\n\nprint('Script')\nprint(df_script.head(), end='\\n\\n')\n\nprint('Episodes')\nprint(df_episodes.head(), end='\\n\\n')",
          " Show All Data for df_characters\nwith pd.option_context('display.max_rows', None, 'display.max_columns', None):\n    display(df_characters.head(5))",
          " Remove characters and locations not mentioned in script\nmentioned_chars = df_script_raw.name.str.lower().unique()\nmentioned_locs = df_script_raw.raw_location_text.str.lower().unique()\n\ndf_characters = df_characters[df_characters.normalized_name.str.lower().isin(mentioned_chars)]\ndf_locations = df_locations[df_locations.normalized_name.str.lower().isin(mentioned_locs)]",
          "Check the first 5 lines of each dataframe",
          " Remove all mode of address and suffixes from aggregation.",
          " Check datatypes and null values\ndf_script.info()",
          "Remove rows with null characters ID\ndf_script = df_script[df_script['character_id'].notnull()]",
          "Look at the first 5 rows of each dataframe.",
          "pre-processing\n# Parse JSON columns in script and characters DataFrames\ndf_characters_gr = pd.DataFrame(list(df_characters['character'].apply(json.loads)))\ndf_locations_gr = pd.DataFrame(list(df_locations['location_text'].apply(json.loads))\ndf_script_td = pd.merge(df_script, df_episodes, left_on='episode_id', right_on='id')\n\n# Override the 'name' error from 'name' column from script DataFrame\ndf_script_td[\"name\"]= df_script_td[\"name\"].fillna(df_script_td[\"normalized_text\"])\ndf_script_td.drop(columns='normalized_text' , inplace=True)",
          " Take a peek at the df_characters dataframe\ndf_characters.head()",
          " Add decade to episodes dataframe\ndf_episodes['decade_id'] = np.floor(df_episodes['original_air_year'] / 10) * 10",
          "# Quick look at the characters dataframe\nprint(df_characters.head())",
          "Load initial versions of datasets and reset index to ensure correct functionality",
          "Check the first few rows of each dataframe\ndf_script.head(), df_characters.head(), df_locations.head(), df_episodes.head()",
          "This dataset is designed for educational approaches, by no means do I own this data nor am Iancer at Fox.",
          "Add some useful features as additional columns to the script DataFrame",
          "Merge location metadata into script dataframe\ndf_script = df_script.merge(\n    df_episodes.loc[:, ['id', 'title', 'original_air_date', 'production_code', 'season', 'number_in_season']].add_prefix('episode_'),\n    left_on='episode_id',\n    right_on='episode_id'\n)",
          "Visualize the dataframe(s)",
          "Display the word cloud for the top 25 characters.",
          " Check the number of different characters and locations",
          "Join dataframes on the character, location, episode and season fields, and reset index",
          "# Let's display some basic information from the dataset to get a better\n# understanding of the data. Let's start with all the datasets in general.",
          "Let's check out the structure of the data.",
          "Count the number of words spoken by each character\ndf_character_word_count = df_script.groupby('character_id')['word_count'].sum().reset_index()\n\n# Merge with characters and limit the top 20\ndf_character_word_count = (pd\n    .merge(df_characters, df_character_word_count, how='inner', left_on='id', right_on='character_id')\n    .sort_values('word_count', ascending=False)\n    .head(20))\n\n# Plot\nfig, ax = plt.subplots(figsize=(10,8))\nplt.barh(np.arange(len(df_character_word_count)), df_character_word_count['word_count'])\nplt.yticks(np.arange(len(df_character_word_count)), df_character_word_count['name'], rotation=0, ha='right')\nplt.xlabel('Word count')\nplt.title('Number of words spoken by character')\nplt.gca().invert_yaxis()",
          "Print a few lines of each dataset to demonstrate what kind of data is included.",
          "Simple Preprocessing\n# Make sure the text is indeed a string\ndf_script['raw_text'] = df_script['raw_text'].astype(str)\n\n# Simple text cleaning\ndf_script['raw_text'] = df_script['raw_text'].str.replace('\\n', ' ')  # Removing newlines\ndf_script['raw_text'] = df_script['raw_text'].str.replace('\\r', ' ')  # Removing carriage returns\ndf_script['raw_text'] = df_script['raw_text'].str.replace('\\t', ' ')  # Removing tabs\n\ndf_script['word_count'] = df_script['raw_text'].apply(lambda x: len(x.split(' ')))  # Getting word count",
          " Remove special characters from character names, locations, and script lines and episode titles.",
          "Check the loaded dataset\nfor name, data in (\n    ('Characters', df_characters), \n    ('Locations', df_locations), \n    ('Script lines', df_script), \n    ('Episodes', df_episodes)\n):\n    print(f'{name}:')\n    print(data.info())\n    display(data.head())\n    print('\\n\\n')",
          "We'll use a pre-trained NER model from spaCy to assign named entities to the text.",
          " to show the first few rows of the dataframe, which can be helpful in understanding the data.",
          "We will now take a look at the imported dataframes to understand their structure and contents.",
          "Explore the data and find an interesting question to answer",
          "Create columns scenes and text length, for each line in the script.",
          " Check if the following fields will have null values:\n# 'character_id': always filled / integer\n# 'episode_id': always filled / integer\n# 'location_id': always filled / integer\n# 'id': always filled / integer\n# 'text': always filled / string",
          "Select main cast (based on how many sentences they have)",
          "Remove rows with missing values because the missing values might affect the analysis.",
          "Train a model for named entity recognition (NER) with spaCy.",
          "Inspect the structure of the datasets\nprint(f'Characters: {len(df_characters)}')\ndf_characters.head()",
          "check the data extracted from the characters dataset\ndf_characters.head()",
          "Let's first inspect the first lines for each of these dataframes.",
          "Display all dataframes\ndisplay(df_characters.head())\ndisplay(df_locations.head())\ndisplay(df_script.head())\ndisplay(df_episodes.head())",
          "Set plot style\nplt.style.use('fivethirtyeight')",
          " View the first rows of the characters dataframe\ndf_characters.head()",
          "Set a default value for the number of elements.",
          " Limit the number of rows printed in the notebook\npd.options.display.max_rows = 5",
          "Display some data to have an overview\ndf_script.head()",
          "Load the script and episodes dataframe\ndf_script_id = df_script.join(df_episodes, on='episode_id', rsuffix='_ep')",
          "Let's preview the datasets and look at some basic statistics.",
          " Look at the first 5 rows of each CSV file",
          " Print data examples",
          " Display the first 5 rows of each DataFrame to verify they were loaded correctly\ndisplay(df_characters.head())\ndisplay(df_locations.head())",
          "optional: set a threshold for script lines length to filter out the long script lines\nthreshold = 500",
          " Extract all the sentences in the script and column to a list\nsentences = df_script['raw_text'].tolist()",
          " Convert id columns to int to enable merges",
          " Visualize the columns of the dataset\nprint(df_characters.columns.tolist())",
          "Data sets memory usage\nprint('Character datatypes:')\nprint(df_characters.dtypes)\nprint(\"\")\n\nprint('Locations datatypes:')\nprint(df_locations.dtypes)\nprint(\"\")\n\nprint('Script datatypes:')\nprint(df_script.dtypes)\nprint(\"\")\n\nprint('Episodes datatypes:')\nprint(df_episodes.dtypes)",
          " These dataframes contain self-contained data, including both raw and pre-processed data as well as metadata about the datasets.",
          "Create a pandas series based on the script list of speakers.",
          "Creating necessary folder structure for saving models and tokenizers",
          "Filtering the seasons that only consider episodes of the TV show, and not others.",
          "Building a word cloud for the entire Simpsons script\nscript = \" \".join(df_script['raw_text'])",
          " Extract all locations\nlocations = df_locations.loc[:,'normalized_text']\nlocations = locations.dropna()\n\n# Extract all script lines\nscript = df_script.loc[:,'normalized_text']\nscript = script.dropna()\n\nscript.head()",
          "Only keep characters IDs that appear in df_characters\ndf_script = df_script[df_script[\"character_id\"].isin(df_characters.character_id.unique())]",
          "Check the first few rows of the dataframe to understand its structure\ndf_script.head()",
          "To get a feel for the data, let's take a look at the first few rows of each dataframe.",
          "Create \"simpsons_script_lines\" table from \"script_lines\" table\ndf_script_new = df_script.join(df_episodes, on='episode_id', rsuffix='_ep')\ndf_script_new = df_script_new.join(df_characters, on='character_id', rsuffix='_char')\ndf_script_new = df_script_new.join(df_locations, on='location_id', rsuffix='_loc').drop(\n                       ['episode_id', 'number', 'raw_text', 'timestamp_in_ms', 'speaking_line', 'character_id', \n                        'location_id', 'raw_text', 'normalized_text', 'timestamp_in_ms', 'word_count', \"image_id\", \n                        \"production_code\", \"original_air_date\", \"id\", \"video_url\", \"show_id\", \"imdb_title_id\", \n                        \"imdb_id\" , \"script_id\", \"production_code\", \"image_id_char\", \"url_char\", \"filter\", \"license\", \n                        \"image_id_loc\", \"url_loc\"], axis=1).reset_index(inplace=False, drop=True)",
          " Load custom NLP pipeline from disk",
          "We can now take a lookt at the head of each DataFrame to understand better their structure",
          "Display columns to have a sense of the data",
          " Select only the \"The Simpons\" TV show\ndf_episodes_subset = df_episodes.query('original_air_date > \"1989-12-01\"').reset_index(inplace=False, drop=True)",
          "Preview the first 5 rows of each dataframe\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()",
          "Set up environment for spaCy and Word Clouds",
          "Some small adjustments to the dataframes\ndf_characters.drop(columns=['normalized_name'], inplace=True)\ndf_characters = df_characters.dropna(subset=['name'])\n\ndf_locations = df_locations.dropna(subset=['normalized_name'])\n\ndf_episodes = df_episodes.dropna(subset=['title'])\n\ndf_script = df_script.dropna(subset=['raw_character_text', 'spoken_words'])",
          "Create a dataframe keeping only the line with their episode's data",
          "Setting current directory\nos.chdir('SIMPSONS_DATASET/')",
          "Print the first 10 rows of each DataFrame to have a quick look at their structure.\nprint('Characters:')\nprint(df_characters.head(5))\n\nprint('\\nLocations:')\nprint(df_locations.head(5))\n\nprint('\\nScript:')\nprint(df_script.head(5))\n\nprint('\\nEpisodes:')\nprint(df_episodes.head(5))",
          "Check what's inside df_script\ndf_script.head()",
          "Print quick statistics about our datasets",
          "Inspecting the schema of these DataFrames will help us understand the data better.",
          "Check our datasets",
          "Load the scripts and select season 1\ndf_script_s1 = df_script.loc[df_script['episode_id'] <= 13].copy()",
          " Remove the following dataframes since they are not used in this code snippet.\ndel df_characters, df_locations, df_episodes",
          "Checking data integrity\nprint(df_characters.shape, df_characters.character_id.nunique())",
          " show the first few rows of the table, for easier understanding\ndf_script.head()",
          "Helper function to pretty print a JSON object\nimport json\n\ndef pp_json(json_thing, sort=True, indents=4):\n    if type(json_thing) is str:\n        print(json.dumps(json.loads(json_thing), sort_keys=sort, indent=indents))\n    else:\n        print(json.dumps(json_thing, sort_keys=sort, indent=indents))",
          " Display first few rows of the characters dataframe\ndf_characters.head()",
          "display(df_characters.head())\ndisplay(df_locations.head())\ndisplay(df_script.head())\ndisplay(df_episodes.head())",
          " Merge episodes, script and characters\ndf = pd.merge(df_episodes, df_script, on='episode_id')\ndf = pd.merge(df, df_characters, on='character_id')",
          "Make use of the full dataset\npd.set_option('display.max_columns', None)",
          "Display examples from each DataFrame\nfor name, df in {'Characters': df_characters, 'Locations': df_locations, 'Script': df_script, 'Episodes': df_episodes}.items():\n    print(f'--- {name} ---')\n    display(df.head(3))",
          "Ensure consistent character naming across dataframes\ndf_script['raw_character_text'] = df_script['raw_character_text'].replace({\n    'lenny': 'Lenny',\n    'carl': 'Carl',\n    'moe_szyslak': 'Moe Szyslak',\n    'charles_montgomery_burns': 'Mr. Burns',\n    'chief_wiggum': 'Chief Wiggum',\n    'homer_simpson': 'Homer Simpson',\n    'kent_brockman': 'Kent Brockman',\n    'marge_simpson': 'Marge Simpson',\n    'bart_simpson': 'Bart Simpson',\n    'lisa_simpson': 'Lisa Simpson',\n    'krusty_the_clown': 'Krusty the Clown',\n    'edna_krabappel': 'Edna Krabappel',\n    'nelson_muntz': 'Nelson Muntz',\n    'apu_nahasapeemapetilon': 'Apu Nahasapeemapetilon',\n    'seymour_skinner': 'Seymour Skinner',\n    'milhouse_van_houten': 'Milhouse Van Houten',\n    'maggie_simpson': 'Maggie Simpson',\n    'scratchy': 'Scratchy',\n    'barney_gumble': 'Barney Gumble',\n    'moe_szyslak': 'Moe Szyslak',\n    'rainier_wolfcastle': 'Rainier Wolfcastle',\n    'waylon_smithers': 'Waylon Smithers',\n    'ned_flanders': 'Ned Flanders',\n    'fat_tony': 'Fat Tony'\n})",
          " Cleaning the comma from column name\ndf_characters = df_characters.rename(columns={x: x.replace(',', '') for x in df_characters.columns})\ndf_locations = df_locations.rename(columns={x: x.replace(',', '') for x in df_locations.columns})\ndf_script = df_script.rename(columns={x: x.replace(',', '') for x in df_script.columns})\ndf_episodes = df_episodes.rename(columns={x: x.replace(',', '') for x in df_episodes.columns})",
          "Create a corpus of documents, i.e. seasons, episodes, scripts\ncorpus = { row[1][\"id\"]: \"\" for row in df_episodes.iterrows() }\n\n# Append all the lines from a given episode to the same document\nfor row in tqdm(df_script.iterrows(), total=df_script.shape[0]):\n    episode_id = row[1]['episode_id']\n    corpus[episode_id] += row[1]['raw_text']",
          "Create a directory for saving plots if it does not exist",
          "Check data imported correctly\ndf_characters.head()",
          "To start off, let's take a look at the first few rows of each dataframe to understand what kind of data we are working with.",
          " Display the first 5 rows of each table\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()",
          "Let's start by taking a quick look at the structure of our datasets.",
          "Convert information gain to mutual information",
          "Print the first 5 lines of the script dataset to inspect its structure\ndf_script.head()",
          "Display df_characters's shape\nprint(\"df_characters has\", df_characters.shape[0], \"rows and\", df_characters.shape[1], \"column\")",
          "Build a dataframe with episodes and their scripted lines\nlines = []\nfor _, episode in df_episodes.iterrows():\n    episode_id = episode['id']\n    episode_lines = df_script[df_script['episode_id'] == episode_id]\n    lines.append({\n        \"id\": episode_id,\n        \"title\": episode['title'],\n        \"original_air_date\": episode['original_air_date'],\n        \"number_in_series\": episode['number_in_series'],\n        \"number_in_season\": episode['number_in_season'],\n        \"season\": episode['season'],\n        \"lines\": episode_lines\n    })\n\ndf_episodes_lines = pd.DataFrame(lines)",
          " Find seasons in the data\ndf_episodes['season'].unique()",
          "Filter unspecified locations, replace ~140 duplicates by hand\ndf_locations = df_locations[~df_locations['normalized_text'].isin(['*unspecified location', 'unspecified'])]",
          " We always want to create a copy of the original data\ndf_script_cleaned = df_script.copy()",
          "Set index to make filtering more explicit",
          "Encode lines by key and title.",
          "Ensure dataframes work correctly with Jupyter\ntqdm.pandas()",
          "Inspect the first few rows of each dataframe to understand the data.",
          "Func to split the data to moby_dick chunks, args: window=n, overlap=0\ndef split_to_chunks(input_str, window, overlap=0):\n    return [input_str[i:i + window] for i in range(0, len(input_str), window - overlap)]",
          "Declare the NLP pipeline\nnlp = spacy.load('en_core_web_sm')",
          "Making sure the size of the data is handled",
          " Explore the datasets\nprint(df_characters.head())\nprint(df_locations.head())\nprint(df_script.head())\nprint(df_episodes.head())",
          "Inspect df_characters\ndf_characters.head()",
          "Create identifiers to set index from 1",
          "Build nlp model to use\nnlp = spacy.load(\"en_core_web_sm\")",
          " Function to select the main character of an episode\ndef get_main_character(speaker):\n    main_characters = df_characters[df_characters.main_character == 1].character.tolist()\n    if speaker in main_characters:\n        return speaker\n    return 'other'",
          "# Let's take a look at the script data\ndf_script.head()",
          "# Let's start by cleaning the script dataframe\ndf_script.info()",
          "Visualize the script lines DataFrame head\ndf_script.head()",
          "Convert stringified list to list",
          "Extract all the character names\ncharacters = df_characters.character_name.unique()",
          "Filtering lines with character and location information from the script\ndf_script_filtered = df_script[\n    df_script['raw_character_text'].isin(df_characters['name']) &\n    df_script['raw_location_text'].isin(df_locations['name'])\n].copy()",
          " Split the `raw_character_text` column into a list of characters, regexing to remove ambiguities",
          "Join script with characters and locations names\ndf_script_characters = df_script.join(df_characters, on='character_id', rsuffix='_character')\ndf_script_locations = df_script_characters.join(df_locations, on='location_id', rsuffix='_location')\n\n# Move data to new columns, and fill NaN values with empty strings\ndf_script_locations['raw_character_name'] = df_script_locations['name']\ndf_script_locations['raw_location_name'] = df_script_locations['name_location']\ndf_script_locations['raw_text'] = df_script_locations['normalized_text']\ndf_script_locations['spoken_words'] = df_script_locations['raw_text']",
          "Merge multiple dataframes into a single one based on 'episode_id' column and create a boolean mask for a sample episode",
          "View the script data\ndf_script.head()",
          "Visualizing the number of lines per episode\nlines_per_episode = df_script.groupby('episode_id').size()\nlines_per_episode.name = 'lines'\nlines_per_episode = lines_per_episode.reset_index()\n\nplt.figure(figsize=(15, 5))\nplt.plot(lines_per_episode.index, lines_per_episode.lines, marker='o', linestyle='-')\nplt.title('Number of lines per episode')\nplt.xlabel('Episode')\nplt.ylabel('Number of lines')\nplt.show()",
          " prepare nltk's stop words\nnlp = spacy.load(\"en_core_web_sm\")",
          "Check that all tables have been correctly loaded\nprint('Characters:', df_characters.shape)\nprint('Locations:', df_locations.shape)\nprint('Script:', df_script.shape)\nprint('Episodes:', df_episodes.shape)",
          "Remove the script lines mentioned prior to the first episode of The Simpsons",
          "Drop useless columns and contents from the dataset",
          "Set random seed for reproducibility\nnp.random.seed(0)",
          "Let's take a look at the data by displaying the first few rows of each DataFrame.",
          "Explore datasets\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()",
          " Sample the script data\ndf_script.head()",
          "Inspect the dataframes to understand their structure and the kind of information they contain.",
          "Select only the normalized text column from the script dataframe\ndf_script = df_script['normalized_text']",
          " Set the index of the script to be the episode_id",
          "Display maximum columns when displaying the dataframe\npd.set_option('display.max_columns', None)",
          "Representing text data as numbers with bag of words model\n# We are going to represent each document as a vector with the word frequencies\n# First, we need to tokenise the documents\n\n# Tokenising documents\n# Load the large model to get the vectors\nnlp = spacy.load('en_core_web_lg')\n\n# We have 158276 documents in the dataset which is quite a lot. \n# We can speed up this process and make it more efficient if we use the nlp.pipe for the tokenization.\n\n# Since the tokenisation takes some time, we can save the tokenized documents to a file, \n# such that we won´t need to do the tokenisation again, in case we close the notebook or shut down the computer.",
          "Check the first few lines of each dataframe\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()",
          "How many entries do we have for each dataset?",
          "Check first 5 rows of each dataset\nprint(\"Characters\\n\", df_characters.head(), \"\\n\\n\")\nprint(\"Locations\\n\", df_locations.head(), \"\\n\\n\")\nprint(\"Script\\n\", df_script.head(), \"\\n\\n\")\nprint(\"Episodes\\n\", df_episodes.head(), \"\\n\\n\")",
          "Cleanup and preprocess the data",
          "Check data shape\nprint(f\"Characters: {df_characters.shape[0]}\")\nprint(f\"Locations: {df_locations.shape[0]}\")\nprint(f\"Script lines: {df_script.shape[0]}\")\nprint(f\"Episodes: {df_episodes.shape[0]}\")",
          " Strip whitespaces around episode names to avoid duplicates\ndf_episodes['normalized_name'] = df_episodes['normalized_name'].str.strip()",
          "Check few if the dataframes to get an idea of the data.",
          "Merge scripts with characters and locations\ndf_raw = df_script.merge(df_characters, how='inner', left_on='character_id', right_on='id')\ndf_raw = df_raw.merge(df_locations, how='inner', left_on='location_id', right_on='id')\n\n# Save the raw merged dataframe\ndf_raw.to_csv('data/simpsons_script_merged_raw.csv', index=False)",
          "Set up lists of characters, locations, episodes, and seasons for later use\ncharacters = df_characters['name'].values.tolist()\nlocations = df_locations['name'].values.tolist()\nepisodes = df_episodes['title'].values.tolist()\nseasons = df_episodes['season'].drop_duplicates().values.tolist()",
          "Print the size of the dataframes to ensure they were loaded successfully\nprint(f\"Characters: {df_characters.shape}\")\nprint(f\"Locations: {df_locations.shape}\")\nprint(f\"Script: {df_script.shape}\")\nprint(f\"Episodes: {df_episodes.shape}\")",
          "First, let's take a look at the structure of the datasets.",
          "Check the content of the episodes.csv file",
          " VISUALIZING SCRIPT DATA\ndf_script.head()",
          "Create a dictionary mapping episode_id to episode title.",
          "Filter out script lines that have not been assigned to any character\ndf_script = df_script[df_script['character_id'].isin(df_characters['id'])]\n\n# Counting the number of lines spoken by each character\nlines_per_character = df_script['character_id'].value_counts().reset_index()\nlines_per_character.columns = ['id', 'num_lines']\n\n# Merging this information into the characters dataframe\ndf_characters = pd.merge(df_characters, lines_per_character, on='id', how='left')",
          " Calculate how many occurrences of words there are in all the lines of the scripts",
          "Filter the dialogues with the main characters",
          " Preprocess the data\n# Remove NaN values\ndf_characters.dropna(inplace=True)\ndf_locations.dropna(inplace=True)\ndf_script.dropna(inplace=True)\ndf_episodes.dropna(inplace=True)",
          "def load_word_label_dictionary(filename):\n    result = {}\n    with open(filename, 'r') as file:\n        for line in file:\n            (key, val) = line.split()\n            result[key] = val\n    return result",
          "Detectron2\nimport detectron2\nfrom detectron2.utils.logger import setup_logger\n\nsetup_logger()\n\nimport numpy as np\nimport os, json, cv2, random\n\nfrom detectron2 import model_zoo\nfrom detectron2.engine import DefaultPredictor\nfrom detectron2.config import get_cfg\nfrom detectron2.utils.visualizer import Visualizer\nfrom detectron2.data import MetadataCatalog, DatasetCatalog",
          "Filter out the newline characters from raw_script column in the script dataset to avoid any problems.",
          "Change these to {inplace = True}",
          "Print a first few rows of the first DataFrames, to get a feeling of their structure.\nprint(df_characters.head())\nprint(df_locations.head())\nprint(df_script.head())\nprint(df_episodes.head())",
          "check info in the imported data files\nprint(df_characters.info())\nprint(df_locations.info())\nprint(df_script.info())\nprint(df_episodes.info())",
          "Print the first few lines of each dataframe\nprint(df_characters.head())\nprint(df_locations.head())\nprint(df_script.head())\nprint(df_episodes.head())",
          "Basic sanity checks",
          "Cut the data to match the observations we have",
          "cleaning NaN values\ndf_script = df_script[(df_script['episode_id'].notna()) & (df_script['character_id'].notna()) & (df_script['location_id'].notna())\n                     & (df_script['raw_text'].notna())]",
          "Visualize the number of lines per character\ndf_script['character_id'].value_counts().hist()",
          "Extract all the unique locations from the scripts\nall_lines = list(df_script['raw_text'])\nall_locations = []\nfor line in all_lines:\n    try:\n        line = line.split(' ')\n        line = list(filter(lambda x: x != '', line)) # Remove spaces\n        all_locations.append(line[1])\n    except:\n        pass",
          " Check the import of datasets\nprint(\"Characters dataset:\")\ndisplay(df_characters.head())\n\n\nprint(\"\\nLocations dataset:\")\ndisplay(df_locations.head())\n\nprint(\"\\nScript dataset:\")\ndisplay(df_script.head())\n\nprint(\"\\nEpisodes dataset:\")\ndisplay(df_episodes.head())",
          " Length of the dataset\nlen(df_script)",
          "Merge script csv with characters and locations\ndf_merged = pd.merge(df_script, df_characters, how='left', left_on=['character_id'], right_on=['id'])",
          " Calculate the number of unique locations and characters in the dataset\nnum_unique_locations = df_locations['name'].nunique()\nnum_unique_characters = df_characters['name'].nunique()\n\nprint(f'There are {num_unique_locations} unique locations in the dataset')\nprint(f'There are {num_unique_characters} unique characters in the dataset')",
          "Previously, we imported necessary libraries and datasets for our analysis.",
          "Let's start!",
          "Make sure ObjectId is of type int\ndf_script['episode_id'] = df_script['episode_id'].astype(int)",
          "Join episodes to the script on the 'episode_id' field\n# (two dataframes, episodes and script)\ndf = df_episodes.set_index('id').join(\n    df_script.set_index('episode_id')\n).reset_index()\n\n# Join the resulting dataframe to the characters and locations tables.\n# (characters/locations and episodes/script now)\ndf = df.set_index('character_id').join(\n    df_characters.set_index('id')\n).reset_index().set_index('location_id').join(\n    df_locations.set_index('id')\n).reset_index()",
          "Filter characters from main family",
          "Create empty DataFrame for capturing entities\ndf_entities = pd.DataFrame(columns=['id', 'text', 'label'])\n\nnlp = spacy.load('en_core_web_sm')",
          "Split the dataset into test and training sets",
          " The first five rows of each dataframe\nprint(df_characters.head())\nprint(df_locations.head())",
          "Helper function to split array values into rows while duplicating the rest of the columns\ndef splitDataFrameList(df, target_column):\n    '''\n    Accepts a column with multiple types of delimited data and returns a \n    DataFrame with each entry for the target column separated out.\n    '''\n    #DataFrame containing multiple type of columns as a single column\n    row_accumulator = []\n\n    def splitListToRows(row, row_accumulator, target_column):\n        split_row = row[target_column]\n        if isinstance(split_row, list) and len(split_row) > 0:\n            for s in split_row:\n                new_row = row.to_dict()\n                new_row[target_column] = s\n                row_accumulator.append(new_row)\n        else:\n            new_row = row.to_dict()\n            new_row[target_column] = split_row\n            row_accumulator.append(new_row)\n\n    df.apply(splitListToRows, axis=1, args=(row_accumulator, target_column))\n    new_df = pd.DataFrame(row_accumulator)\n    return new_df",
          "To avoid cache memory error and reload nlp, this nlp pipe can be persisted using disk\n# Also, then it can easily be loaded with `spacy.load()` function\n\n# pip install dill\nimport dill",
          " Remove unwanted columns and rows from DataFrames to reduce memory usage and increase speed.",
          "Display the three first rows for the characters dataframe\ndf_characters.head(3)",
          "check whether dataframe is imported correctly",
          "Quick look at the data types and null values",
          "Inspect the dataframes to understand their structure and contents",
          " Extracting the names of the characters.",
          "Enable f-strings in python 3.5, 3.6, and 3.7",
          "Combine the tables to form one large dataset to work with",
          "# Print dataset's shape and first rows\nprint(\"Characters dataset's shape:\")\nprint(df_characters.shape)\nprint(\"\\nCharacters dataset's initial rows:\")\nprint(df_characters.head())",
          "Display general information about the script dataset\nprint(df_script.shape)\nprint(df_script.dtypes)",
          "Check the data shape and format",
          "Add custom colors for the plot\ncolors = ['lightskyblue', 'lightcoral']\nmatplotlib.rcParams['axes.prop_cycle'] = matplotlib.cycler(color=colors)",
          " -*-*-*-*-*-* Transform the database -*-*-*-*-*-*-\n# Remove entries with unidentified speaker, locations, or without a proper script\ndf_script = df_script[df_script[\"raw_text\"] != ''][[\"episode_id\", \"id\", \"character_id\", \"raw_text\"]]",
          "def load_pipeline():\n    # Load the multi-task NER model\n    nlp = spacy.load('en_core_web_sm')\n\n    # Add labels for the NER 'Character' and 'Location'\n\n    # Character labels\n    for character in df_characters['name']:\n        nlp.entity.add_label(character)\n\n    # Location labels\n    for location in df_locations['name']:\n        nlp.entity.add_label(location)\n\n    return nlp",
          "Explore the content of each dataframe",
          "Check a few columns in the script data, as well as extract the character having the most lines and the location in which these lines were delivered",
          "Filter the data to only include character and location information that is in the script data\ncharacters_in_scripts = df_script[\"raw_character_text\"].unique()\nlocations_in_scripts = df_script[\"raw_location_text\"].unique()\n\ndf_characters = df_characters[df_characters[\"name\"].isin(characters_in_scripts)].reset_index(drop=True)\ndf_locations = df_locations[df_locations[\"name\"].isin(locations_in_scripts)].reset_index(drop=True)",
          "tqdm.pandas()",
          "Print the first 5 rows of the script dataset to understand its structure\ndf_script.head()",
          "Define pre-processing functions",
          "Merge data into one dataframe",
          "Utility function\ndef expand_contractions(text, contraction_mapping=CONTRACTION_MAP):\n    contractions_pattern = re.compile('({})'.format('|'.join(contraction_mapping.keys())), \n                                      flags=re.IGNORECASE|re.DOTALL)\n    def expand_match(contraction):\n        match = contraction.group(0)\n        first_char = match[0]\n        expanded_contraction = contraction_mapping.get(match)\\\n                                if contraction_mapping.get(match)\\\n                                else contraction_mapping.get(match.lower())                       \n        expanded_contraction = first_char+expanded_contraction[1:]\n        return expanded_contraction\n        \n    expanded_text = contractions_pattern.sub(expand_match, text)\n    expanded_text = re.sub(\"'\", \"\", expanded_text)\n    return expanded_text",
          " Optionally, you can remove the quotation marks if it starts to be difficult to manage in your local language.",
          "Define the length of the dataset for the purpose of interactive exploration\ndata_length = len(df_script)",
          "df_script['raw_character_text'].value_counts()",
          "Check out the first 5 characters' dataframe.",
          "Drop unnecessary columns\ndf_characters = df_characters.drop(columns=['Normalized Name','Normalized Role'])\ndf_locations = df_locations.drop(columns=['Normalized Name'])\ndf_episodes = df_episodes.drop(columns=['Image URL','Production Company','US Viewers In Millions','Unnamed: 7','Video URL'])\n\n# Remove the last row which contains meta-information\n\n# Enumerating each dataframe\nfor idx, df in enumerate([df_characters, df_locations, df_script, df_episodes]):\n    # Adding the index as a column\n    df['DataFrame Index'] = idx\n\n    # Set index as DataFrame Index\n    df.set_index(['DataFrame Index','id'], inplace=True)\n\n# Reassign the new column ordered\ndf_script = df_script[['episode_id','number','character_id','location_id','raw_text',\"spoken_words\",\"timestamp_in_ms\"]]\n\ndf_script.head()",
          "Species the type of data in the datasets\nprint('Characters dataset:')\nprint(df_characters.dtypes)\nprint('\\nLocations dataset:')\nprint(df_locations.dtypes)\nprint('\\nScript dataset:')\nprint(df_script.dtypes)\nprint('\\nEpisodes dataset:')\nprint(df_episodes.dtypes)",
          "Print the first few rows of the characters dataframe\nprint(df_characters.head())\n# Print the first few rows of the locations dataframe\nprint(df_locations.head())",
          "Print the first few lines of the script data to inspect the structure\nprint(f'Shape: {df_script.shape}')\ndf_script.head()",
          "Display dataset shapes\nprint(\"Characters (rows, columns):\", df_characters.shape)\nprint(\"Locations (rows, columns):\", df_locations.shape)\nprint(\"Script lines (rows, columns):\", df_script.shape)\nprint(\"Episodes (rows, columns):\", df_episodes.shape)",
          " Create a column with the raw tokenized text",
          "Visualize the first few rows of the script data\ndf_script.head()",
          "TODO: Add content here",
          "Here we load the datasets we'll be using for the analysis.",
          "Select only the columns that we're interested in:\n- character_id\n- raw_character_text\n- raw_location_text",
          " Look at the first rows of the dataframe to better understand its structure\ndf_script.head()",
          "Set 'id' as index for quick search",
          "Familiarize ourselves with one of the dataset.",
          "Download spacy's transformer model \"en_core_web_trf\" to be able to tokenize words.",
          "Clean data\n#script with na characters or na locations\n\ndf_script = df_script[df_script.character_id.notna() & df_script.location_id.notna()]",
          "Configure TQDM for pandas\ntqdm.pandas()",
          " Let's take a look at the structure and contents of each data type.",
          "Explore data distributions and format before implementing nlp tools",
          "Ensure script data is sorted by index\ndf_script = df_script.sort_values(by='index')",
          "First, let's take a look at the contents of these datasets to understand their structure and the type of information they contain.",
          "\"\"\"Data statistics\"\"\"",
          "appearances = df_script['raw_character_text'].value_counts().reset_index()\nappearances.columns = ['raw_character_text', 'num_appearances']",
          "Create a copy to avoid loading the data again and again\ndf = df_script.copy()",
          "Load the pre-processed data from the Pickle files",
          " Measure total spoken lines per character\nlines_per_character = df_script.character_id.value_counts().reset_index()\nlines_per_character.columns = ['character_id', 'number_of_lines']\nlines_per_character = lines_per_character.merge(df_characters, on='character_id')\nlines_per_character = lines_per_character.sort_values(by='number_of_lines', ascending=False)\n\n# Show data\nlines_per_character.head()",
          "Filtering Data\n# --------------------------------------------------\n# Step 2: Cleaning Lines, Spans, and Characters\n# --------------------------------------------------",
          "Check out the first few rows of the characters dataset\ndf_characters.head()",
          "Remove useless columns from characters and locations DataFrames\ndf_characters = df_characters[['id', 'name', 'normalized_name']]\ndf_locations = df_locations[['id', 'name', 'normalized_name']]",
          "Inspect the first few rows of the script data\ndf_script.head()",
          " Display the first 5 characters of the characters DataFrame\ndf_characters.head()",
          "Joining datasets",
          " We re-use some utilities for pre-processing.",
          "ner.load('en_core_web_sm')",
          "Set environment variables for PySpark\nos.environ['PYSPARK_PYTHON'] = '/usr/bin/python3'\nos.environ['PYSPARK_DRIVER_PYTHON'] = '/usr/bin/python3'",
          "\n# Character interactions\ninteractions = df_script.groupby(['character_id', 'utterance_id']).size().groupby('character_id').size()\n\n# Now we have to map the characters in interactions to their real names\ninteractions = interactions.to_frame().join(df_characters.set_index('character_id'))\n\n# Sort the interactions\ninteractions.sort_values(by=0, ascending=False, inplace=True)",
          "Creates a new 'simpsons_script_lines' dataframe that contains the 'normalized_text' and 'character_id' columns\ndf_episodes.drop(['image_url'], axis=1, inplace=True)",
          " Check the content of df_characters\ndf_characters.head()",
          " Display first few rows of characters dataframe\ndf_characters.head()",
          " The path to the data is currently wrong. Let's fix that by modifying the path to the data.",
          "Total number of rows in the dataset\nscript_rows = df_script.shape[0]",
          "Displays all the dataframes\ndisplay(df_characters.head(3))\ndisplay(df_locations.head(3))\ndisplay(df_script.head(3))\ndisplay(df_episodes.head(3))",
          "Remove duplicate locations and characters",
          "Extracting main characters\nmain_characters = df_characters[df_characters['is_main_cast']]\nprint(main_characters)",
          "Make previews of each dataset",
          "Merge data using the common keys",
          "set up the random state for replication of results\nnp.random.seed(42)",
          "Create `date` and `time` columns, and merge with `df_script` \ndf_script = df_script.assign(\n    date=pd.to_datetime(df_script.timestamp_in_ms, unit='ms').dt.date,\n    time=pd.to_datetime(df_script.timestamp_in_ms, unit='ms').dt.time\n)\n\n# Merge\ndf_script = df_script.merge(\n    df_episodes[['id', 'season', 'number', 'title', 'original_air_date']],\n    left_on='episode_id', right_on='id'\n)\n\n# Column re-ordering for their better visualization\ndf_script = df_script[\n    [\n        'id', 'season', 'number', 'title', 'original_air_date', 'timestamp_in_ms', 'date', 'time', 'raw_text', 'speaking_line',\n        'character_id', 'location_id', 'raw_character_text', 'raw_location_text', 'spoken_words', 'normalized_text'\n    ]\n]\n\n# The first `n` rows\ndf_script.head()",
          "Check the loaded datasets\ndf_script.head()",
          "Text preprocessing\n# Stop words\nnlp = spacy.load(\"en_core_web_sm\")\nstop_words = spacy.lang.en.stop_words.STOP_WORDS",
          "Check the first 5 rows of each of the datasets",
          "Check the content of the characters dataset\ndf_characters.head()",
          "Changing the shape of all datasets\na = df_characters.shape\nb = df_locations.shape\nc = df_script.shape\nd = df_episodes.shape",
          "Checking the first few rows of each dataset to get an idea of the information available.",
          "View first 10 rows of each DataFrame\nfor df, name in zip([df_characters, df_locations, df_episodes, df_script], \n                    ['Characters', 'Locations', 'Episodes', 'Script']):\n    display(HTML(f\"<h2>{name}</h2>\"))\n    display(df.head(10))",
          "Check if the dataframes are successfully loaded\nprint(f'Characters dataframe: {df_characters.shape[0]} rows')\nprint(f'Locations dataframe: {df_locations.shape[0]} rows')\nprint(f'Script lines dataframe: {df_script.shape[0]} rows')\nprint(f'Episodes dataframe: {df_episodes.shape[0]} rows')",
          "Looking at the first 5 rows of each dataframe.",
          "View the first few entries of the characters dataframe\ndf_characters.head()",
          "Preview the first 5 rows of each dataframe to understand their structure\nprint(df_characters.head())\nprint(df_locations.head())\nprint(df_script.head())\nprint(df_episodes.head())",
          " Visualizations of the datasets",
          "Path to Simpsons dataset\npath = \"/content/drive/MyDrive/Colab Notebooks/NLP/simpsons/\"\n\n# Visualize dataset\nprint(\">> Raw datasets:\")\nprint(f\"df_characters: {df_characters.shape}\")\nprint(f\"df_locations: {df_locations.shape}\")\nprint(f\"df_script: {df_script.shape}\")\nprint(f\"df_episodes: {df_episodes.shape}\")",
          " Hide progress bars when running loops\ntqdm.pandas()",
          " Check the dfs",
          " We need to move string-based features to lowercase for later uses in case sensitive searches",
          "Optional: use all columns\npd.set_option('display.max_columns', None)",
          ".concat([df_characters, df_locations, df_script, df_episodes], keys=['characters', 'locations', 'script', 'episodes'], axis=1)",
          "Checking the head of the dataframe to make sure all the data was imported correctly.",
          "Create some directories to store graphs and data",
          "Check shapes of DataFrames",
          "Check the data size and structure\nprint(\"Characters:\", df_characters.shape)\nprint(\"Locations:\", df_locations.shape)\nprint(\"Script:\", df_script.shape)\nprint(\"Episodes:\", df_episodes.shape)",
          "\n# Join episode and script data\ndf_script_episodes = df_script.join(df_episodes, on='episode_id', rsuffix='_episode')\n\n# Print the first five rows\ndf_script_episodes.head()",
          "Create copies of these dataframes",
          " Look at the unique values for season and episode\n(df_episodes\n .loc[lambda df: df.season == 1]\n .episode\n .unique())",
          " Display the first 3 rows of the characters dataframe\ndf_characters.head(3)",
          "Inspect the dataframes to understand their structure and contents",
          "Collect all spoken lines of a character\nlines = []\nfor index, row in tqdm(df_characters.iterrows(), total=df_characters.shape[0]):\n    character_name = row['name']\n",
          " Plotting the number of locations per episode",
          "Merge characters\ndf_characters_ep = df_characters.merge(df_script, left_on='id', right_on='character_id').merge(df_episodes, on='episode_id')",
          "To show the top few rows and understand the data's structure for each dataframe, we will use the head function for each dataframe.",
          "Now you can start with the current assignments and any analysis or code snippet you want to work on.",
          "Inspect the content of the episodes data frame",
          "Check the first few rows of the dataframe to see what it looks like.",
          "Let's take a look at the first few rows (and columns) of our data.",
          " Look at first couple of records for the characters, locations and script dataframes to understand what kind of data they contain\ndf_characters.head()",
          "Subset of characters that spoke over than 10 times\nmain_characters = df_script['raw_character_text'].value_counts()[df_script['raw_character_text'].value_counts()>10].index.values\ndf_script = df_script[df_script['raw_character_text'].isin(main_characters)]\n\n# replacing blank values\ndf_script = df_script.replace(\"\", np.nan)",
          "Get scripts for the first 5 seasons",
          "Explore the dataset\n#df_script.info()",
          "Simple EDA to \"get to know\" the data\nprint(\"Characters sample:\")\nprint(df_characters.head(2))\nprint(\"Locations sample:\")\nprint(df_locations.head(2))\nprint(\"Script sample:\")\nprint(df_script.head(5))",
          "Define ordering of seasons and episodes\nseason_episode_order = {\n    (1, 1): 1,   (1, 2): 2,   (1, 3): 3,   (1, 4): 4,\n    (2, 1): 5,   (2, 2): 6,   (2, 3): 7,   (2, 4): 8,\n    (3, 1): 9,   (3, 2): 10,  (3, 3): 11,  (3, 4): 12,\n    (4, 1): 13,  (4, 2): 14,  (4, 3): 15,  (4, 4): 16,\n    (5, 1): 17,  (5, 2): 18,  (5, 3): 19,  (5, 4): 20,\n    (6, 1): 21,  (6, 2): 22,  (6, 3): 23,  (6, 4): 24,\n    (7, 1): 25,  (7, 2): 26,  (7, 3): 27,  (7, 4): 28,\n    (8, 1): 29,  (8, 2): 30,  (8, 3): 31,  (8, 4): 32,\n    (9, 1): 33,  (9, 2): 34,  (9, 3): 35,  (9, 4): 36,\n    (10, 1): 37, (10, 2): 38, (10, 3): 39, (10, 4): 40,\n    (11, 1): 41, (11, 2): 42, (11, 3): 43, (11, 4): 44,\n    (12, 1): 45, (12, 2): 46, (12, 3): 47, (12, 4): 48,\n    (13, 1): 49, (13, 2): 50, (13, 3): 51, (13, 4): 52,\n    (14, 1): 53, (14, 2): 54, (14, 3): 55, (14, 4): 56,\n    (15, 1): 57, (15, 2): 58, (15, 3): 59, (15, 4): 60,\n    (16, 1): 61, (16, 2): 62, (16, 3): 63, (16, 4): 64,\n    (17, 1): 65, (17, 2): 66, (17, 3): 67, (17, 4): 68,\n    (18, 1): 69, (18, 2): 70, (18, 3): 71, (18, 4): 72,\n    (19, 1): 73, (19, 2): 74, (19, 3): 75, (19, 4): 76,\n    (20, 1): 77, (20, 2): 78, (20, 3): 79, (20, 4): 80,\n    (21, 1): 81, (21, 2): 82, (21, 3): 83, (21, 4): 84,\n    (22, 1): 85, (22, 2): 86, (22, 3): 87, (22, 4): 88,\n    (23, 1): 89, (23, 2): 90, (23, 3): 91, (23, 4): 92,\n    (24, 1): 93, (24, 2): 94, (24, 3): 95, (24, 4): 96,\n    (25, 1): 97, (25, 2): 98, (25, 3): 99, (25, 4): 100,\n    (26, 1): 101, (26, 2): 102, (26, 3): 103, (26, 4): 104,\n    (27, 1): 105, (27, 2): 106, (27, 3): 107, (27, 4): 108,\n    (28, 1): 109, (28, 2): 110, (28, 3): 111, (28, 4): 112,\n    (29, 1): 113, (29, 2): 114, (29, 3): 115, (29, 4): 116,\n    (30, 1): 117, (30, 2): 118, (30, 3): 119, (30, 4): 120,\n    (31, 1): 121, (31, 2): 122, (31, 3): 123, (31, 4): 124,\n    (32, 1): 125, (32, 2): 126, (32, 3): 127, (32, 4): 128\n}",
          " View the structure of the script data\ndf_script.head()",
          "Set seed for numpy\nnp.random.seed(0)",
          "# an example of a simple query\ndf_script[df_script['normalized_text'].str.contains('coffe')].head()",
          "This will read the four datasets provided.",
          " Merge the script lines with episode and characters data\ndf_script_lines = df_script.merge(df_episodes, on='episode_id')\ndf_script_lines = df_script_lines.merge(df_characters, left_on='character_id', right_on='id')\ndf_script_lines.rename(columns={'name': 'character_name'}, inplace=True)\ndf_script_lines = df_script_lines[['id', 'episode_id', 'number', 'raw_text', 'timestamp_in_ms',\n                                   'season', 'episode_name', 'character_id', 'character_name',\n                                   'location_id', 'spoken_words']]\ndf_script_lines = df_script_lines.merge(df_locations, left_on='location_id', right_on='id')\ndf_script_lines.rename(columns={'name': 'location_name'}, inplace=True)\ndf_script_lines = df_script_lines[['id', 'episode_id', 'number', 'raw_text', 'timestamp_in_ms',\n                                   'season', 'episode_name', 'character_id', 'character_name',\n                                   'location_id', 'location_name',\n                                   'spoken_words']]",
          "Compatibility with new pandas versions\nif pd.__version__>='1.0.0':\n    df_characters.rename(columns={'id': 'char_id'}, inplace=True)\n    df_locations.rename(columns={'id': 'loc_id'}, inplace=True)\n    df_script.rename(columns={'id': 'line_id', 'episode_id': 'ep_id', 'character_id': 'char_id', 'location_id': 'loc_id'}, inplace=True)\n    df_episodes.rename(columns={'id': 'ep_id'}, inplace=True)",
          "Print the header of each dataframe\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()",
          " Plot histogram of the episode lengths\ndf_episodes.length.hist(bins=50, alpha=0.5, color='r', edgecolor='black')",
          " Checking dataframe shapes",
          " Display each of the dataframe to understand the structure and the data inside it.",
          "Let's see what the data looks like.",
          "Show full column and row information:",
          " Filter the dataset to only consider speaking lines",
          "Ensure proper file separator for both Windows and Unix-based systems\nfile_separator = os.sep",
          "Let's take a look at the dimensions of our dataframes.\nprint('Characters df shape:', df_characters.shape)\nprint('Locations df shape:', df_locations.shape)\nprint('Script df shape:', df_script.shape)\nprint('Episodes df shape:', df_episodes.shape)",
          "preview data\nprint(\"Characters:\")\nprint(df_characters.head())\nprint(\"Locations:\")\nprint(df_locations.head())\nprint(\"Script:\")\nprint(df_script.head())\nprint(\"Episodes:\")\nprint(df_episodes.head())",
          "\n#{'characters': df_characters, 'locations': df_locations, 'script': df_script, 'episodes': df_episodes}",
          "Display a preview of each dataset\nprint(\"Characters dataset preview\")\nprint(df_characters.head(3))\nprint(\"Locations dataset preview\")\nprint(df_locations.head(3))\nprint(\"Script dataset preview\")\nprint(df_script.head(3))\nprint(\"Episodes dataset preview\")\nprint(df_episodes.head(3))",
          "Merge dialog with character information\ndf_dialog = (\n    df_script\n    .merge(df_characters, how='left', left_on='character_id', right_on='id', suffixes=('','_character'))\n    .merge(df_locations, how='left', left_on='location_id', right_on='id', suffixes=('','_location'))\n    .merge(df_episodes, how='left', left_on='episode_id', right_on='id', suffixes=('','_episode'))\n)",
          "Create a copy of the dataframe with the script lines\ndf_script_filtered = df_script.copy()",
          " Filter the characters that are actually speaking",
          "utf-8'decode' codec can't decode byte 0x89 in position 0: invalid start byte",
          "Display top 10 rows of each dataframe to understand structure and information.",
          "Constants\nnlp = spacy.load('en_core_web_lg')\nstopwords = spacy.lang.en.STOP_WORDS",
          "Filter episodes with location_id and character_id\ndf_script = df_script[(df_script['location_id'].notnull()) & (df_script['character_id'].notnull())].reset_index(inplace=False, drop=True)",
          "# Let's work first on a very basic visual exploration of the data:\n# Let's look at the number of lines per episode\n\n# Clean the episode column\ndf_script['episode_id'] = df_script['episode_id'].str.extract('(\\d+)').astype(int)\n\n# Count the number of lines per episode\nlines_per_episode = df_script.groupby('episode_id').size()\nlines_per_episode.plot(kind='bar', figsize=(15, 7))",
          "Then, we have to filter the script data to remove rows with missing or invalid values and keep only the dialogue lines.",
          " Split the raw text script into its components.",
          "Find and replace the ids of the speaking character, location, episode, and season in the script lines dataframe.",
          "Remove lines without character id and without quotes\ndf_script = df_script.loc[df_script['character_id'].notna() & df_script['quote'].notna()]",
          "Configuration for preprocessing and analysis\nnlp = spacy.load('en_core_web_lg')\nnlp.max_length = 2000000",
          "Print head of each dataframe\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()",
          "Drop broken entries\ndf_script = df_script.drop(df_script[df_script[\"id\"] == 17837].index)\ndf_script = df_script.drop(df_script[df_script[\"id\"] == 53270].index)",
          " Research question: \"What are the most frequent words used by each character across all episodes?\"\n\n# Create a dataset with the characters' lines and speaker\ndf_characters['character_lines'] = df_script[df_script.character_id.isin(df_characters.id)].groupby('character_id').apply(lambda x: ' '.join(x['character_words'].str.lower().fillna(' ')))\ndf_characters['n_words'] = df_characters.character_lines.str.split(' ').apply(len)\n\n# Eliminate characters with less than 1000 words\ndf_filtered_characters = df_characters[df_characters.n_words>1000]\n\n# Create a list of lines for each character\ncharacter_lines_list = df_filtered_characters.character_lines.str.split('\\.').tolist()\ncharacter_lines_speakers = df_filtered_characters.character_name.tolist()\n\n# Count words\ncharacter_words_count = list(map(lambda x: Counter(x.split(\" \")), character_lines_list))\n\n# Removing stop words\nnlp = spacy.load('en_core_web_sm')\nfor i in range(len(character_words_count)):\n    print('Filtering stop words - character {}'.format(character_lines_speakers[i]))\n    words = list(character_words_count[i].keys())\n    words = list(filter(lambda x: nlp(x)[0].is_stop, words))\n    character_words_count[i] = {k:v for k,v in character_words_count[i].items() if k not in words}\n    print('number of words after filtering: {}'.format(len(character_words_count[i])))",
          "Clean up memory\ndel df_characters, df_locations, df_episodes",
          "Check segments of the dataframes to understand their contents\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()",
          "Let's see how the data looks like",
          "Check first 5 rows of `df_script`",
          " Print the first few lines of each dataframe to understand its structure\nprint(df_characters.head())\nprint(df_locations.head())\nprint(df_script.head())\nprint(df_episodes.head())",
          "Select main characters\nmain_characters = [\n    'marge_simpson', 'homer_simpson', 'bart_simpson',\n    'lisa_simpson', 'maggie_simpson', 'skinner'\n]\n\n# Filter out lines by main characters\ndf_main_characters = df_script[\n    df_script['raw_character_text'].isin(main_characters)\n].copy()\n\n# Cleanup and drop NaN values\ndf_main_characters['normalized_text'] = (\n    df_main_characters['spoken_words']\n    .str.lower()\n    .str.replace(r'[^\\w\\s]', '', regex=True)\n    .str.replace(r' +', ' ', regex=True)\n    .str.strip()\n)\ndf_main_characters['word_count'] = (\n    df_main_characters['normalized_text'].str.split().str.len()\n)\ndf_main_characters['word_count'] = (\n    df_main_characters['word_count']\n    .where(df_main_characters['word_count'] < 100, 100)\n)\n\ndf_main_characters = df_main_characters.dropna(subset=['normalized_text'])\n\n# Inspect\ndf_main_characters.head()",
          " Function to filter non-ascii characters in a string",
          "Optional: Display and explore the data to understand its structure and the available features and columns.",
          "From the script dataset, we will use the following columns: character_id, episode_id, location_id, raw_text.",
          "Convert character_id and location_id from float to int",
          "Checking the data in df_characters dataframe.",
          " Intialize spaCy model\nnlp = spacy.load(\"en_core_web_sm\")",
          "# Print size of the script dataframe\nprint('Number of dialogue lines in the dataset: ', df_script.shape[0])",
          "Create an instance of the spacy class\nnlp = spacy.load('en_core_web_sm')",
          " Use the \"utf-8\" encoding to avoid issues with special characters",
          "Exploratory Data Analysis",
          " Checking dimensionality of the data\nprint('Characters: ', df_characters.shape)\nprint('Locations: ', df_locations.shape)\nprint('Script: ', df_script.shape)\nprint('Episodes: ', df_episodes.shape)",
          "Let's print the shape of the all dataset and the head of the script dataset.",
          "Subset the script dataframe to only include the first 10 episodes.",
          "Inspect the first few rows of each dataframe to understand its structure and content.\nprint(df_characters.head())\nprint(df_locations.head())\nprint(df_script.head())\nprint(df_episodes.head())",
          "Check a few lines of the `df_characters` dataframe",
          " Display top rows of the dataframes\nprint(df_characters.head())\nprint(df_locations.head())\nprint(df_script.head())\nprint(df_episodes.head())",
          "Check the loaded datasets\ndf_script.head()",
          "Check out the first few rows of our datasets\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()",
          "Inspect the dataframes to understand their structure and contents",
          "Get an overview of the datasets\ndf_script",
          "Let's see how the data looks like",
          "Inspect the dataframe shapes",
          "# Display at a glance the first 5 rows of a dataframe\ndf_characters.head()",
          "Filter characters from the script\nmain_characters = df_characters[df_characters['raw_character_text'].isin(df_script['raw_character_text'].unique())]\nprint(f'Number of unique characters with lines in the script: {len(main_characters)}')",
          "# Concatenate location names\nlocation_names = '|'.join([location.lower() for location in df_locations['raw_location_text'].unique()])\nlocation_names",
          "Choose a subset of the data to speed up the computation",
          "Extracting just the dialogues and the respective character name from the original dataframe.",
          " Set some parameters for better visualization in matplotlib",
          "Display the first 3 rows of the characters dataframe\ndf_characters.head(3)",
          "# Display the first 5 rows of each table\ndisplay(df_characters.head())\ndisplay(df_locations.head())\ndisplay(df_script.head())\ndisplay(df_episodes.head())",
          "display(df_characters.head())\ndisplay(df_locations.head())\ndisplay(df_script.head())\ndisplay(df_episodes.head())",
          "Display the top 5 rows of each dataframe\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()",
          "Check the size of each dataframe\nprint('Characters:', df_characters.shape)\nprint('Locations:', df_locations.shape)\nprint('Script:', df_script.shape)\nprint('Episodes:', df_episodes.shape)",
          " Filter to keep only characters with more than 300 lines",
          "Inspect each DataFrame to understand its structure and content",
          "Subset df_episodes to only take episodes from the first 12 seasons (up to 2001)",
          " Filter lines with a specific character_id\ndf_character_1 = df_script[df_script['character_id'] == 1]\ndf_character_1.head()",
          " Display the first 5 rows of each table\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()",
          "Remove bad characters and extra white spaces from the character names\ndf_script.raw_character_text = df_script.raw_character_text.str.strip()\ndf_characters.character_name = df_characters.character_name.str.strip()",
          "# Display maximum columns and rows when displaying dataframes\npd.set_option('display.max_columns', None)\npd.set_option('display.max_rows', None)",
          "Print some statistics about the data.",
          " We will create a single dataframe which includes episodes, locations, characters and script lines information.",
          "\n# Display the first 5 script lines\ndf_script.head()",
          "View dimensions of dataframes",
          "Display datasheets header",
          "Check the shape of each dataframe to gain a first understanding of the data",
          "Preview the datasets",
          "Check the data types for each column\ndf_script.info(verbose=True)",
          " #encoding=utf-8",
          "Join episodes with scripts\ndf_episodes_scripts = df_episodes.set_index('id').join(df_script.set_index('episode_id')).reset_index()\n\n# Join characters with scripts\ndf_characters_scripts = df_characters.set_index('id').join(df_script.set_index('character_id'))\n\n# Join locations with scripts\ndf_locations_scripts = df_locations.set_index('id').join(df_script.set_index('location_id'))",
          " remove unwanted white spaces form `simpson_characters.csv`\ndf_characters = df_characters.apply(lambda x: x.str.strip() if x.dtype == \"object\" else x)",
          "\n# Display options\npd.set_option('display.max_columns', None)\npd.set_option('display.expand_frame_repr', False)",
          "Load pre-trained spacy model\nnlp = spacy.load(\"en_core_web_sm\")",
          "Let's first explore the data to see what information we have available.",
          "Number of script lines in the dataset\nlen(df_script)",
          "nlp = spacy.load(\"en_core_web_sm\")\n\n# Path to where the wordcloud images will be saved\nWORDCLOUD_DIR = \"wordclouds\"\n\n# Create output directory if it does not exist\nos.makedirs(WORDCLOUD_DIR, exist_ok=True)",
          "Check dataframes are loaded successfully\nprint('Characters:', df_characters.shape)\nprint('Locations:', df_locations.shape)\nprint('Script:', df_script.shape)\nprint('Episodes:', df_episodes.shape)",
          "Visualize the episode count distribution by season",
          " This is the first model to start early exploration of the dataset.",
          "Sample the dataframes to visualize their structure\ndf_characters.head(3)",
          "Check the number of rows and columns for each dataframe\nprint(f'Characters: {df_characters.shape}')\nprint(f'Locations: {df_locations.shape}')\nprint(f'Script: {df_script.shape}')\nprint(f'Episodes: {df_episodes.shape}')",
          "In case of small datasets, pandas is smart enough to infer the correct data type of each column, however, it's best to be explicit to avoid ambiguity and noisy type warnings in case of larger datasets.",
          "Limit script to certain episode_id.\nepisode_id = 1",
          "Optional: choose the tallest characters and include others that have the same height, then inspect the names and heights",
          " Merge the dataframes with the episode and character info",
          " Set 'id' as the index for quick access",
          " Display the first 3 rows of each dataframe\ndf_characters.head(3)",
          "Quick look at the data and its structure",
          "Merge script with episodes and strip the data\ndf_episodes['id'] = df_episodes.id.astype(str)  # ensure alignment on merge\ndf_script_lines_with_episode = df_script.merge(\n    df_episodes,\n    left_on='episode_id',\n    right_on='id',\n    suffixes=('_script', '_episode')).copy()\n\n# simplify\ndf_script_lines_with_episode.drop(\n    ['id_episode','image_url','id_script','number_in_season','number_in_series','original_air_date','id_script',\n     'title', 'us_viewers_in_millions','views', 'imdb_votes', 'imdb_rating','video_url'],\n    axis=1,\n    inplace=True)",
          "Merge the datasets to have all the information on the script lines",
          "Let's display the first few records of each dataset to understand what we're working with.",
          "Create a copy of df_script to work with",
          "What steps should I take to clean the data in the script dataframe?",
          "Data cleanup\n# Keep only non-empty lines\ndf_script = df_script[df_script['raw_text'].notna()]\n\n# Keep only lines related to an episode\ndf_script = df_script[df_script['episode_id'].notna()]\n\n# Set NaT values to the pandas NaT type\ndf_episodes['original_air_date'] = df_episodes['original_air_date'].apply(lambda x: pd.NaT if pd.isna(x) else pd.to_datetime(x))\n\n# Limit the number of rows for faster execution\nsample_size = 98000\ndf_script = df_script.loc[:sample_size]",
          "Remove some special features of the datasets",
          "To find the top characters according to number of mentions.\n# Getting only the lines of the script that are spoken by characters that exist in the characters dataframe.\ndf_script = df_script[df_script.raw_character_text.isin(df_characters.raw_character_text)]",
          "Remove text data with incorrect or missing values",
          "Merge the datasets 'df_script' and 'df_episodes'",
          "Prepare sklearn vectorier with the correct tensor shape\nfrom sklearn.feature_extraction.text import CountVectorizer\nvectorizer = CountVectorizer()",
          " Display data\nwith pd.option_context('display.max_rows', 10, 'display.max_columns', None, 'display.max_colwidth', 30):\n    display(df_characters, df_locations, df_script, df_episodes)",
          "Create a shallow copy\ndf_script_work = df_script.copy()",
          " Join structures",
          "Display some information about the characters dataframe\nprint('Number of entries: ', df_characters.shape[0])\nprint('Number of columns: ', df_characters.shape[1])\nprint('\\nColumns with their datatypes:')\nprint(df_characters.dtypes)\nprint('\\nColumn names:')\nprint(df_characters.columns)\nprint('\\n')",
          "We can see the top of each dataframe by using the .head display method.",
          "Display spacy's name entity recognizer for a given sentence on adequate log level.",
          "Change the dataframe name for clarity\ndf_episodes_copy = df_episodes.copy()",
          "Creating a backup of the script dataframe\ndf_script_original = df_script.copy()",
          "# Display options\npd.set_option('display.max_columns', None)",
          "Exploratory data analysis",
          "Let's look at an example to understand our data better.",
          "General configuration of library settings\npd.set_option('display.max_columns', 50)\nnlp = spacy.load('en_core_web_sm')",
          "By resetting the index, we ensure that our DataFrames start with index 0 and increase by 1 for each row.",
          "RP - Carga de módulos adiconales",
          "Set plotting style\nplt.style.use('fivethirtyeight')",
          "Split the raw data to train and test sets.",
          "Choose a specific dataframe to work with (e.g. df_characters, df_locations, df_script, df_episodes)",
          "Combining lines in a single message\ndf_script['spoken_words'] = df_script.groupby('timestamp_in_ms')['spoken_words'].transform(lambda x: ' '.join(x))\ndf_script = df_script.drop_duplicates(subset='timestamp_in_ms').reset_index(drop=True)",
          "Let's have a look at a snapshot of one of the datasets to understand its structure.",
          " Display the head of the script lines dataset\ndf_script.head()",
          "Preview of the data\nprint(df_script.head())\nprint(df_characters.head())\nprint(df_locations.head())\nprint(df_episodes.head())",
          " Cleaning and merging the data",
          " First, let's take a look at the structure of the datasets.",
          " drop first column (Unnamed: 0) of all DataFrames\ndf_characters.drop(columns=['Unnamed: 0'], inplace=True)\ndf_locations.drop(columns=['Unnamed: 0'], inplace=True)\ndf_script.drop(columns=['Unnamed: 0'], inplace=True)\ndf_episodes.drop(columns=['Unnamed: 0'], inplace=True)",
          "Remove unused dataframes, clean script, save dataframe",
          "Choose a series of columns to use as metadata for our lines of dialogue.",
          "Enable f-strings in Python 3.6 and 3.7\nfrom __future__ import annotations",
          "Infer the list of seasons based on the script\nseasons = sorted(df_script['raw_text'].map(lambda x: int(x.split('_')[1])).unique())\nseasons",
          " Checking how many script lines contain the word \"d'oh\"",
          "Set plot style\nplt.style.use('fivethirtyeight')",
          "function to get the main character of an episode",
          "We will explore the dataset to understand the data better before we start working with it.",
          "Check fewesr phrases in a string\nfewest_phrases_count = 3",
          "View first 5 rows of characters data\ndf_characters.head()",
          "Filter out characters who have not been assigned to a location\nvalid_characters = df_characters[df_characters['character_id'].isin(df_script['character_id'])]['name']\ndf_script = df_script[df_script['character_id'].isin(df_characters['character_id'])]",
          "For the word cloud, we'll use spaCy for pre-processing and then Matplotlib for rendering.",
          "Check data shapes\nprint(df_characters.shape)",
          "Merge script line with characters and locations\ndf_script = df_script.merge(df_episodes[['id', 'season', 'number', 'title']], on='id', how='left')",
          "Initial examination of the data",
          "Declare tasks using TQDM\ntqdm.pandas()",
          "Let's start by looking at some general statistics for our datasets.",
          "Merge the data into one dataframe for better visualization",
          "Define a function to print the n topics that we have fit in the model\ndef print_topics(model, vectorizer, top_n=10):\n    for idx, topic in enumerate(model.components_):\n        print(\"Topic %d:\" % (idx))\n        print([(vectorizer.get_feature_names_out()[i], topic[i])\n                        for i in topic.argsort()[:-top_n - 1:-1]])",
          "Check the first few rows of each dataframe\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()",
          "Remove all invalid schedule\ndf_episodes = df_episods.dropna(subset=['original_air_date'])",
          " Merging data into one dataframe",
          " Visualize the number of episodes per season\ndf_episodes['season'].value_counts().sort_index().plot(kind='bar')",
          " as we have large datasets at our disposal, we will print out the sizes of them so that we get the sense of how many records we have for each entity.",
          "import spacy\n\n# Load the large English NLP model\nnlp = spacy.load('en_core_web_lg')",
          " The character that speaks the most\ndf_script['character_id'].value_counts().idxmax()",
          "Preview our datasets\nprint(df_characters.head())\nprint(df_locations.head())\nprint(df_script.head())\nprint(df_episodes.head())",
          " Show the data from the top 3 datasets\ndf_characters.head(), df_locations.head(), df_script.head()",
          "Checking the first 5 rows of each dataset",
          "Quick look at dataframe shape\ndf_characters.shape, df_locations.shape, df_script.shape, df_episodes.shape",
          " Display a few basic details about the datasets.",
          "We will load and explore the data to get a first impression of the datasets.",
          "Create random forest classifier",
          "Merge the scripts with the speaker names and locations",
          "Preview the first 5 rows of each dataframe\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()",
          "Start by cleaning the script lines data by removing any 'nan' values.",
          "Drop completely empty columns\ndf_script = df_script.dropna(axis=1, how='all')",
          "Merge the 'simpsons_script_lines' dataframe ('df_script') with the 'simpsons_episodes' dataframe ('df_episodes') on the 'episode_id' column.",
          " Merge script lines with episodes and selected only the relevant columns\ndf_merged = df_script.merge(df_episodes, on='episode_id')\ndf_merged = df_merged[['id', 'episode_id', 'number', 'timestamp_in_ms', 'raw_text', 'spoken_words', 'timestamp_in_ms', 'character_id']]\n\n# Add the character and location names to the merged dataset\ndf_merged = df_merged.merge(df_characters, left_on='character_id', right_on='id', suffixes=('_script', '_character'))\ndf_merged = df_merged.merge(df_locations, left_on='location_id', right_on='id', suffixes=('_script', '_location'))",
          "let's take a look at the content of the first 5 lines (5 rows and all columns) of the lines dataset.\ndf_script.head()",
          "Check the first few lines of each table",
          "Pandas default behavior is to do partial matches, so we need to be rigorous\n# about the columns we in order to avoid ambiguity.\ndf_characters = df_characters.filter(items=['index', 'real_name', 'real_name'])\ndf_locations = df_locations.filter(items=['index', 'name'])\ndf_episodes = df_episodes.filter(items=['id', 'title'])",
          " Now concatenate all individual episode dataframes into one dataframe for easier access and management.",
          "Check the dataframe shapes",
          "Clean up the scripts dataframe\n# Remove unwanted columns\ndf_script.drop(['id', 'episode_id', 'number', 'raw_text'], axis=1, inplace=True)\n\n# Missing dialogues\ndf_script.dropna(subset=['character_id', 'location_id'], how='all', inplace=True)\n\n# Convert character_id and location_id to int\ndf_script['character_id'] = df_script['character_id'].astype('Int64')\ndf_script['location_id'] = df_script['location_id'].astype('Int64')\n\n# Reorder columns\ndf_script = df_script[['character_id', 'location_id', 'timestamp_in_ms', 'speaking_line', 'spoken_words']]",
          "First, we start by making some basic \"exploratory data analysis\" (EDA) of the dataset.",
          "Check dataframe sizes\ndf_episodes.shape, df_characters.shape, df_script.shape, df_locations.shape",
          "# Display the head of the dataframe to have a first look at its content\ndf_script.head()",
          "View the shape of these dataframe",
          " Let's inspect the head of each dataframe to make sure all the columns were read in correctly.",
          " Some configurations for displaying datasets in an easily readable way\npd.set_option('display.max_columns', None)",
          "hint: use the first few rows of the dataframe again to refresh your memory\ndf_characters.head()",
          "Merge Simpsons script lines with character information\ndf_script['character_name'] = df_script['character_id'].map(df_characters['name'])\ndf_script.head()",
          "Let's take a look at the first few rows of each dataframe to understand what kind of data we are dealing with.",
          "characters = df_characters.copy()\nlocations = df_locations.copy()\nscript = df_script.copy()\nepisodes = df_episodes.copy()",
          "Display the first 5 rows of the characters dataset\ndf_characters.head()",
          "Print the number of script lines in the dataset\nprint(f\"Number of script lines: {df_script.shape[0]}\")",
          " Set option to display all columns in dfs\npd.set_option('display.max_columns', None)",
          "from gensim.test.utils import common_texts\nfrom gensim.corpora.dictionary import Dictionary",
          "Store the raw data as a global variable for easier access later on\nRAW_DATA = {\n    'characters': df_characters,\n    'locations': df_locations,\n    'script': df_script,\n    'episodes': df_episodes\n}",
          "replace all regular expression matches with '\\n';\ndf_script['speaking_line'] = df_script['raw_text'].str.replace('[^\\w\\s]','\\n').str.lower();",
          "Merge Simpsons script lines with character and location information\ndf_script_char = df_script.merge(df_characters, on='character_id', suffixes=('', '_char'))\ndf_script_loc = df_script_char.join(df_locations.rename({'location_id':'raw_location_text'}, axis=1).set_index('raw_location_text'), on='raw_location_text')",
          "Let's preview the data in each DataFrame to ensure everything loads correctly.",
          "Associate spoken lines to characters and merge with episode information\nmask = df_script['character_id'].isin(df_characters['id'])\ndf_script = df_script[mask]\n\ndf_script = df_script.merge(\n    df_episodes,\n    how='left',\n    left_on='episode_id',\n    right_on='id')",
          "Join the data frames",
          "Check the style of the dataframes' columns for DataFrame df_script",
          "Print something in a random cell",
          "Inspect the first few lines of each dataframe to understand their structure and the type of data they contain.",
          " First, to understand the data, we want to show the first and last row of each dataframe.",
          "Check the files have been loaded correctly\nprint(\"Characters: \\t\", df_characters.shape)\nprint(\"Locations: \\t\", df_locations.shape)\nprint(\"Script: \\t\", df_script.shape)\nprint(\"Episodes: \\t\", df_episodes.shape)",
          " Remove columns without a name\ndf_characters = df_characters[df_characters.character_name.notnull()]\ndf_locations = df_locations[df_locations.location_name.notnull()]",
          "Checking first rows for each file\nprint(df_characters.head())\nprint(df_locations.head())\nprint(df_script.head())\nprint(df_episodes.head())",
          "Let's start by examining the data.",
          " View the first rows of the characters dataframe\ndf_characters.head()",
          "Check the first few rows of each dataframe in the dataset\nprint(\"Character dataset\")\nprint(df_characters.head())\nprint(\"\")\nprint(\"Locations dataset\")\nprint(df_locations.head())\nprint(\"\")\nprint(\"Script lines dataset\")\nprint(df_script.head())\nprint(\"\")\nprint(\"Episodes dataset\")\nprint(df_episodes.head())",
          "Check if the imports and data are loaded properly\nprint('Characters:', df_characters.shape)\nprint('Locations:', df_locations.shape)\nprint('Script:', df_script.shape)\nprint('Episodes:', df_episodes.shape)",
          "Drop rows with empty or missing dialogue in df_script\ndf_script = df_script.dropna(subset=['normalized_text'])\ndf_script = df_script[df_script['normalized_text']!='']\n# (Optional: drop some other columns we won't use in this example to save memory)\ncolumns_to_drop = ['id', 'episode_id', 'number', 'raw_text', 'timestamp_in_ms', 'speaking_line', 'character_id', 'location_id', 'original_text', 'raw_character_text', 'raw_location_text', 'spoken_words', 'normalized_text', 'word_count']\ndf_script = df_script.drop(columns=columns_to_drop)",
          "Inspect the dataframes to understand the structure and content of the data.",
          "Show some script lines\ndf_script.head(10)",
          "Create a new column containing the full name of the character",
          "Filter out transcriptions that doesn't have the characters' name.",
          "Check the basic info of the datasets\nprint(\"Characters : \", df_characters.shape)\nprint(\"Locations : \", df_locations.shape)\nprint(\"Script : \", df_script.shape)\nprint(\"Episodes : \", df_episodes.shape)",
          "remove the duplicates from the characters and locations dataframes since these are tables that map to the scripts dataframe and the episodes dataframe",
          "Define the base directory where the NLP model is saved\nnlp_base_dir = \"C:/nlp_model\"",
          "\n# Convert character_id to int\ndf_script['character_id'] = df_script['character_id'].astype('Int64')\n\n# Create a column containing only the year of the episode\ndf_episodes['year'] = df_episodes['original_air_date'].str[:4]",
          " Drop dialogues in scenes as the same scene can be in multiple episodes",
          "quick look at the characters dataframe\nprint(f'Size of the dataframe: {len(df_characters)}')\ndf_characters.head()",
          "Split the script into individual lines, i.e. split the script into lines and append them to a list",
          "Let's start by looking at the structure of the databases we have just loaded.",
          "Character level analysis\n# Let's try to identify who talks the most\n\n# Count characters\ndf_script['character_id'].value_counts().head(10)",
          "Filtering the data to retain only the lines from the Simpsons character named 'Marge'",
          "Check the size of the dataframes\ndf_characters.shape, df_locations.shape, df_script.shape, df_episodes.shape",
          "Filter only 10 most common locations\ntop10locations = ['Simpson Home', 'Moe\\'s Tavern', 'Springfield Elementary School', 'Kwik-E-Mart', 'Power Plant', \n                  'Springfield Nuclear Power Plant', 'Springfield Town', 'First Church of Springfield', \n                  'Simpson Living Room', 'Springfield Street']\ndf_script_top10locations = df_script[df_script.raw_location_text.isin(top10locations)]",
          "# Dataframes first glance\nprint(df_characters.head())\nprint(df_locations.head())\nprint(df_script.head())\nprint(df_episodes.head())",
          "ast values to check the data loaded correctly\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()",
          " show first 5 lines of each dataframe\nfor name, df in zip(['Characters', 'Locations', 'Script', 'Episodes'], [df_characters, df_locations, df_script, df_episodes]):\n    print(name)\n    print(df.head(), '\\n\\n')",
          "What's inside each dataset?",
          "Data overview",
          " Check out the first entries for each dataframe\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()",
          "Selecting relevant columns and dropping rows with NaN\ndf_script = df_script[['episode_id', 'number', 'raw_text']].dropna()",
          "df_script = df_script.drop(['index'], axis=1)",
          "Renaming user columns",
          "Clean the script data\ndf_script_cleaned = df_script[\n    (df_script['springfield_id'] <= df_locations.shape[0]) &\n    (df_script['id'] < 200000) &\n    (df_script['location_id'] <= df_locations.shape[0]) &\n    (df_script['normalized_text'].apply(lambda x: isinstance(x, str))) &\n    (df_script['character_id'] <= df_characters.shape[0])\n]",
          "Check the first few rows of each dataframe to see what data they contain.",
          "Drop the \"id\" column, this will be redundant since we will use the index as identifier",
          " You can install or update required packages as per the context.",
          "Let's start by displaying some general information about the datasets.",
          "Extract main characters\nmain_characters = df_characters[df_characters['normalized_name'].notnull()].copy()\nmain_characters = main_characters['normalized_name'].str.lower().values.tolist()",
          "We'll first take a look at the structure and the first few rows of these datasets.",
          "Count the characters that have spoken in the show.",
          "Checking the data types for each dataframe",
          " Merge simpsons_script_lines with simpsons_episodes and simpsons_characters\ndf_script['id'] = range(df_script.shape[0])\ndf_episodes_script = pd.merge(df_script, df_episodes, on=\"episode_id\")\ndf_episodes_script_characters = pd.merge(df_episodes_script, df_characters, left_on=\"raw_character_text\", right_on=\"name\")",
          "Display first few rows of the characters dataframe\ndf_characters.head()",
          "acketed text is placeholder content from the original Python file.",
          " Check the format of the datasets\nprint(\"Characters dataset:\")\nprint(df_characters.head())\nprint(\"\\nLocations dataset:\")\nprint(df_locations.head())\nprint(\"\\nScript dataset:\")\nprint(df_script.head())\nprint(\"\\nEpisodes dataset:\")\nprint(df_episodes.head())",
          "The three first DataFrame have an unwanted column\ndel df_characters['Unnamed: 0']\ndel df_locations['Unnamed: 0']\ndel df_script['Unnamed: 0']",
          "Getting rid of the NaN values for both `location_id` and `normalized_text`",
          "Load the pre-trained spaCy model for English language\nnlp = spacy.load(\"en_core_web_sm\")",
          "Merge the character and location information into the script dataframe\ndf_script = df_script.join(df_characters.set_index('id'), on='character_id')\ndf_script = df_script.join(df_locations.set_index('id'), on='location_id')",
          " Let's display the head of each dataframe to get a sense of its structure.",
          "Inspect the characters dataset\nprint(df_characters.shape)\ndf_characters.head()",
          "It would be helpful to display the first few rows of each dataframe to get an idea of the data.",
          "Set GPU usage to 30% to limit the resources used\nos.environ['CUDA_VISIBLE_DEVICES'] = '0'",
          " Split the text in a list of words\nwords = script_lines[1].str.split(\" \")",
          "Check if all data has been imported correctly\ndf_characters.head()",
          "EDA\n\n# Investigate the number of unique characters, locations and episodes\nnum_characters = df_characters['name'].nunique()\nnum_locations = df_locations['name'].nunique()\nnum_episodes = df_episodes['title'].nunique()\n\nnum_characters, num_locations, num_episodes",
          "check the data types in each column\ndf_script.dtypes",
          "Setting the index of the datasets",
          "Check the first records of df_characters, df_locations, df_script and df_episodes to see what kind of data we are dealing with",
          "Detect which episode each line of the script is from\nepisodes_list = []\n\nfor index, row in tqdm(df_script.iterrows()):\n    mask = df_episodes['id'] == row['episode_id']\n    episode = df_episodes[mask]\n    episode = episode.to_dict(orient='records')[0]\n    episodes_list.append(episode)",
          "Check the first entries of each DataFrame\ndisplay(df_characters.head())\ndisplay(df_locations.head())\ndisplay(df_script.head())\ndisplay(df_episodes.head())",
          " Check of the data\nprint(df_episodes.head())\nprint(df_script.head())",
          "Create a smaller dataframe, capturing only the season 1, episode 1 rows.",
          "Checking the first 5 rows of the script DataFrame\ndf_script.head()",
          "Display first few rows of the characters dataframe\ndf_characters.head()",
          "Create a spaCy nlp object\nnlp = spacy.load('en_core_web_sm')",
          " Display first few rows of characters data\ndf_characters.head()",
          "Data\ndf_characters.head()",
          "Function to display the Word Clouds",
          "Define the relationship between: df_script <-> df_episodes <-> df_characters",
          "Install the spacy 'en' model to preprocess the text.",
          "Let's check the content of the dataset",
          "Filter list of characters in the scripts to only include the main characters",
          "Load data and display overview",
          "Feature selection\ndf_script = df_script[['episode_id', 'number', 'raw_text', 'character_id', 'location_id']]\ndf_episodes = df_episodes[['id', 'title', 'original_air_date']]",
          "Inspect the first 5 rows of each dataframe to understand what kind of information it contains.",
          "Funnel script dataset into more manageable dataframe",
          "Extract and display characters, locations, episodes and script data\nprint(\"\\n-- Characters --\")\nprint(df_characters.head())\n\nprint(\"\\n-- Locations --\")\nprint(df_locations.head())\n\nprint(\"\\n-- Episodes --\")\nprint(df_episodes.head())\n\nprint(\"\\n-- Script Lines --\")\nprint(df_script.head())",
          "convert character_id to integer\ndf_script['character_id'] = pd.to_numeric(df_script['character_id'], errors='coerce').astype('Int64')",
          "We can begin by exploring the different datasets and understanding their structure and content.",
          "Create a mapping of characters to their gender.",
          "Check first 5 rows of each dataset",
          " Join the data together\ndf_script = df_script.join(df_episodes, on='episode_id', rsuffix='_episode', how='left')\ndf_script = df_script.join(df_characters, on='character_id', rsuffix='_character', how='left')\ndf_script = df_script.join(df_locations, on='location_id', rsuffix='_location', how='left')\n\n# Keep relevant columns\ndf_script = df_script[['id', 'number', 'raw_text', 'timestamp_in_ms', 'speaking_line',\n                       'episode_id', 'name_episode', 'original_air_date', 'production_code',\n                       'season', 'number_in_season', 'number_in_series',\n                       'character_id', 'name_character', 'normalized_name_character', 'gender',\n                       'location_id', 'name_location', 'normalized_name_location']]",
          " After importing the necessary libraries and loading the datasets, we can start examining the data to understand its structure and contents.",
          "# Show first 5 rows of the characters dataframe\ndf_characters.head()",
          "Print the first 3 rows of the characters dataset\nprint(df_characters.head(3))",
          " Remove bad data points\ndf_script = df_script[df_script.sentence.str.len() > 1]",
          " Remove problematic series clone (due to successive manipulations)\nif 'Unnamed: 0' in df_characters:\n    df_characters = df_characters.drop(columns=['Unnamed: 0'])",
          "Extract Locations and Character locations from script lines\nlocations = df_script.raw_location_text.dropna().tolist()\ncharacters = df_script.raw_character_text.dropna().tolist()",
          " Display a sample of the data in each dataframe to understand its structure and the kind of data it contains\nprint(\"Characters\")\nprint(df_characters.head(5))\nprint(\"Locations\")\nprint(df_locations.head(5))\nprint(\"Script\")\nprint(df_script.head(5))\nprint(\"Episodes\")\nprint(df_episodes.head(5))",
          "Limiting the amount of characters to load, for performance reasons\nMAX_CHARACTER = 50\n\n#Some lines have NAs, let's get read of them\ndf_script = df_script.dropna(subset=['raw_character_text', 'spoken_words'])\n\n# Distribution of characters\nchar_counter = Counter(df_script['raw_character_text'])\n\n# Make sure that the most common characters are valid ones\nfor k in char_counter:\n    if k not in df_characters[\"Character\"].values:\n        print(k)",
          "Turn: sample the data\npd.set_option('display.max_columns', None)\nprint(df_characters.head())\nprint(df_locations.head())\nprint(df_script.head())\nprint(df_episodes.head())",
          "\nscript_simpsons = df_script.copy()",
          "Start by filtering only the dialogues by Homer Simpson.",
          "Remove unnecessary large strings from the loaded objects\ndf_script = df_script.drop('text', axis=1)",
          " Merge episodes with script\ndf_episodes_script = df_episodes.set_index('id').join(df_script['episode_id'].value_counts().sort_index(), how='outer').rename(columns={'episode_id': 'script_lines_count'})",
          "View the script dataframe\ndf_script.head()",
          "Fix character_id datatype\ndf_script['character_id'] = pd.to_numeric(df_script['character_id'], errors='coerce').astype('Int64')",
          " Observe first entries of the provided data\ndfs = {\n    \"Characters\": df_characters,\n    \"Locations\": df_locations,\n    \"Script lines\": df_script,\n    \"Episodes\": df_episodes\n}",
          "Find the top 10 characters which are most active in the dialogue.",
          "Selecting relevant columns and renaming index column",
          " Check the size and structure of each dataframe\nprint(\"Characters:\", df_characters.shape)\nprint(\"Locations:\", df_locations.shape)\nprint(\"Script:\", df_script.shape)\nprint(\"Episodes:\", df_episodes.shape)",
          "Create the list of documents (each document is a line of the script)\ndocuments = df_script['raw_text'].fillna('xxx').values",
          "Explore the data and generate statistics",
          "Check the size of our datasets",
          "Create the nlp object\nnlp = spacy.load('en_core_web_sm')",
          "First five rows of the dataset\ndf_script.head(), df_characters.head(), df_locations.head()",
          "View the structure of the data.",
          "\n# Filter non-English lines\ndf_script_en = df_script[df_script['raw_character_text'].notnull()\n                        & df_script['raw_location_text'].notnull()\n                        & df_script['spoken_words'].notnull()  \n                       ].copy()\n\n# keep only lines by English-speaking characters in English locations\nlocation_en = df_locations[df_locations['normalized_name'].str.contains('[A-Za-z]', na=False)].copy()\ncharacters_en = df_characters[df_characters['normalized_name'].str.contains('[A-Za-z]', na=False)].copy()",
          " Displaying the number of unique values in each column",
          "Inspect the head of the dataframes to understand their structure and contents\nprint(df_characters.head())\nprint(df_locations.head())\nprint(df_script.head())\nprint(df_episodes.head())",
          "Merge the dialogues with the characters and episodes",
          "Visualizations\n# Number of words per character\nword_counts = {\n    character: len(dialog.split())\n    for character, dialog in zip(df_script.raw_character_text, df_script.raw_text)\n}\n\n# Number of words per location\nlocation_word_counts = {\n    location: sum(len(dialog.split()) for dialog in df_script[df_script.raw_location_text == location].raw_text)\n    for location in df_script.raw_location_text.unique()\n}",
          "Simplify episode titles\ndef clean_title(title):\n    return (\n        title.lower()\n        .replace(\"the simpsons\", \"\")\n        .replace(\": part \", \" \")\n        .replace(\":\", \" \")\n        .replace(\"(\", \"\")\n        .replace(\")\", \"\")\n        .strip()\n    )\n\ndf_episodes['clean_title'] = df_episodes['title'].apply(clean_title)",
          "to make it easier to join on the episode\ndf_script['id'] = df_script['episode_id']",
          "Select only rows with canonical values of 1\ndf_script = df_script[df_script[\"raw_text\"].notna()]",
          "Merge the script data with the episode data\ndf_merged = df_script.merge(df_episodes, on='episode_id')\n\n# Filter out the bad rows and columns\ndf_merged = df_merged[(df_merged.notnull().all(axis=1)) & (df_merged['word_count'].notnull())]\ndf_merged = df_merged.query('word_count > 0')\n\n# Filter out rows where the character is not a Simpson\ndf_merged = df_merged[df_merged['raw_character_text'].map(lambda x: 'simpson' in x.lower())]",
          "Attributes types to columns\ndf_script['id'] = df_script['id'].astype('string')\ndf_script['episode_id'] = df_script['episode_id'].astype('string')\ndf_script['number'] = df_script['number'].replace('?', np.nan).astype(float)\ndf_script['raw_text'] = df_script['raw_text'].astype('string')\ndf_script['timestamp_in_ms'] = df_script['timestamp_in_ms'].replace('?', np.nan).astype(float)",
          "Convert string representation of list of episodes into a list of integers\ndf_episodes['us_viewers_in_millions'] = df_episodes['us_viewers_in_millions'].apply(lambda x: float(x) if x != 'na' else np.nan)\ndf_episodes['views'] = df_episodes['views'].apply(lambda x: x if x != 'na' else np.nan)",
          "Import the necessary pre-processing and feature extraction libraries.",
          "Simplify DataFrames for better this tutorial\ndf_script = df_script[[\"episode_id\", \"character_id\", \"location_id\", \"normalized_text\"]].dropna()",
          "Check the contents and sizes of each dataframe\nprint(\"Characters\")\nprint(df_characters.head())\nprint(df_characters.shape)\n\nprint(\"Locations\")\nprint(df_locations.head())\nprint(df_locations.shape)\n\nprint(\"Script\")\nprint(df_script.head())\nprint(df_script.shape)\n\nprint(\"Episodes\")\nprint(df_episodes.head())\nprint(df_episodes.shape)",
          "Display first rows of the characters table\ndf_characters.head()",
          " Split the \"raw_text\" column according to dialogue_BEGIN and _END",
          "Quick look at the dataframes\ndf_characters.head(3)",
          "First, let's start by looking at some general information about the datasets.",
          "Inspecting these DataFrames will help us understand what kind of information is available and how it is structured.",
          "Remove useless df_script columns\ndf_script = df_script.drop(columns=[\n    'id',  # id is useless\n    'norm_id',  # not sure what this is\n    'episode_id',  # seems to be irrelevant as it corresponds to the index\n    'number',  # seems to be the same than index without 1\n    'raw_text',  # is already in text and speaking_line\n    'timestamp_in_ms',  # not interested in time\n    'speaking_line',  # we don't want to keep 1 because simpsons always have speaking lines\n    'character_id',  # not interested in the ID\n    'location_id',  # not interested in the ID\n    'raw_text',  # is already in text and speaking_line\n    'spoken_words',  # not interested in having the actual text._pla\n    'word_count'  # we will calculate it ourselves\n])",
          " Merge episodes in each dataframe for consistency",
          "Create syntax highlighting across all text and not just strings\nmatplotlib.rcParams['syntax.note_color']='#AA0000'",
          "Let's start by doing some basic data exploration to get a better understanding of the datasets.",
          " Check the first few rows for each dataframe\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()",
          "Extract information\nseasons = df_episodes['season'].unique()",
          "Merge the tables to have more information in one table",
          "Extract the list of main characters from the DataFrame",
          "Check the CSV files have been read correctly, view them, and if needed, drop columns indices with inplace = True and reset column indices.",
          "Fix ids\ndf_script['character_id'] = df_script['character_id'].fillna(-1).astype(int)\ndf_script['location_id'] = df_script['location_id'].fillna(-1).astype(int)",
          "Explore the first few rows of each dataframe\nprint(df_characters.head())\nprint(df_locations.head())\nprint(df_script.head())\nprint(df_episodes.head())",
          "Split data into training and testing sets\ndf_script['split'] = np.random.randn(df_script.shape[0], 1)\n\n# 80% train, 20% test\nm = np.percentile(df_script['split'], 80)\ndf_train = df_script[df_script['split'] < m]\ndf_test = df_script[df_script['split'] >= m]",
          " Join all data frames into a single one.",
          "Merge the datasets and display the first few rows",
          " Limit the number of rows in the dataframes for faster processing during development\n# If processing power is not an issue, these lines can be commented out\ndf_characters = df_characters.head(500)\ndf_locations = df_locations.head(500)\ndf_script = df_script.head(500)\ndf_episodes = df_episodes.head(500)",
          "Test print of the first few lines of each imported dataframe\nprint(df_characters.head())\nprint(df_locations.head())\nprint(df_script.head())\nprint(df_episodes.head())",
          "Clean gcs authentication so it doesn't throw a user warning because we are not going to use GCS in this example\nos.environ['GOOGLE_APPLICATION_CREDENTIALS'] = ''",
          " Let's check the structure of the datasets",
          "Declare the path where the spacy model will be saved\nnlp_path = 'data/spacy_model'",
          "display all columns of the dataframe\npd.set_option('display.max_columns', None)",
          "Explore the datasets to understand their structure and the information they contain.",
          " Import the Gensim summarization module\nfrom gensim.summarization import summarize",
          "View the first few rows of the characters data\ndf_characters.head()",
          "To avoid potential confusion and potential performance issues in your code, it is recommended to use the .copy() method when creating the new dataframes to avoid having views on the original dataframes.",
          "Variable declaration\nnlp = spacy.load(\"en_core_web_sm\")\n\ntqdm.pandas()",
          "Let's take a look at the first few rows of each dataframe to understand the data better.",
          " set random seed for consistency\nnp.random.seed(0)",
          "Drop the first column, which is just the row index.",
          "Set the style of matplotlib plots",
          " Setting the environments seed for reproducibility\nnp.random.seed(1)",
          "You can also check the first couple of lines of each dataframe to have an idea of what kind of data they contain:",
          "Remove unnecessary columns\ndf_characters = df_characters[['id', 'name']]\ndf_locations = df_locations[['id', 'name']]\ndf_episodes = df_episodes[['id', 'title', 'original_air_date']]",
          " Preview each loaded dataset",
          "Display settings for large data\npd.set_option('display.max_columns', None)",
          "Optional: Display the first few lines of each dataset to understand its structure\ndf_characters.head()",
          "function that generate a word cloud from a given text",
          " Display a sample of the dataset\ndf_script.head()",
          "Filter the dataset to keep only the standard episodes (Simpsons TV show)",
          "to do\n# - Take into account the compound name of some characters/locations in the script\n# - apply the above points to the script\n# - count which characters appear in the most locations & vice versa\n# - sentiment analysis for reviews\n# - topic analysis for the reviews",
          "Explorating the first 5 rows of the characters dataset\ndf_characters.head(5)",
          "Visualize the distribution of characters' genders in the dataset",
          " Display the first few records of the dataframe\ndf_script.head()",
          "Merge episodes and script dataframes",
          "Set current directory\nos.chdir('C:/Users/Nicolas/Google Drive/0 - Udacity/7 - Data Engineering Capstone/')",
          "1. Load Data and get an overview",
          "Check the correct loading of the `characters` dataframe\ndf_characters.head()",
          "Displays the first 5 entries for each table\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()",
          "Check availability of GPU\nimport tensorflow as tf\nfrom tensorflow.python.client import device_lib\n\n# Check all available devices if GPU is available\nprint(device_lib.list_local_devices())",
          " Select only the lines with characters\ndf_script_with_characters_info = df_script.loc[~df_script[\"normalized_text\"].isna()].merge(\n    df_characters,\n    how=\"inner\",\n    left_on=\"raw_character_text\",\n    right_on=\"raw_character_text\"\n)",
          "Set matplotlib style\nmatplotlib.rcParams['font.size'] = 18\nmatplotlib.rcParams['figure.figsize'] = (15, 10)",
          "## Initial inspection of the data",
          "Setting seed for reproducibility\nnp.random.seed(0)",
          " Show the first 5 rows of each dataframe to verify that everything has been loaded properly\nprint(df_characters.head())\nprint(df_locations.head())\nprint(df_script.head())\nprint(df_episodes.head())",
          "Check if the dataframes were imported correctly\ndf_characters.head()",
          " Create a list with all tag types.\ntag_list = list(df_script['raw_character_text'])\n\n# Remove duplicates.\ntag_set = set(tag_list)\n\n# Output the number of tag types.\nnum_tag_types = len(tag_set)\nprint(f'Number of unique character tags: {num_tag_types}')",
          " Characters present in the script\ncharacters_present = df_script['character_id'].unique()",
          "Inspecting the first entries of the dataset",
          " Remove non-dialogue rows and unnecessary columns\ndf_script_filtered = df_script[df_script['speaking_line'] == True].reset_index(inplace=False, drop=True)\ndf_script_filtered = df_script_filtered[['episode_id', 'character_id', 'location_id', 'raw_text']]",
          " I'm going to start by showing the first 5 rows of the 4 dataframes to get an understanding of the data.",
          "Count number of lines by character ID and script ID.\nlines = df_script.groupby(['character_id', 'episode_id']).apply(lambda x: ' '.join(x['spoken_words'].astype(str)))",
          "Remove the rows with missing values.",
          "We define the data as \"raw\" since it has not been processed.\nraw_script = df_script.copy()",
          "Display all the tables in the dataset\nwith pd.option_context('display.max_rows', None, 'display.max_columns', None):\n    print(df_characters.head())\n    print(df_locations.head())\n    print(df_script.head())\n    print(df_episodes.head())",
          "Discover and display some basic informations about the data",
          " We'll start with loading the datasets and understanding their structure, before moving on to the NLP analysis.",
          "Inspect items\ndf_script['raw_character_text'].value_counts()",
          "# Dress dataset",
          "Start by exploring the content of the dataset.",
          "Set up the matplotlib figure",
          "This assumes that the folder `data` is located in the same directory as this notebook.",
          "Create a new directory called \"visualizations\" to store the visualizations we will create",
          "Merge 'simpsons_script_lines.csv' with 'simpsons_characters.csv' based on `character_id`\ndf = df_script.merge(df_characters, on='character_id', how='left')",
          "Merge location and episode data with the script data\ndf_merged = df_script.merge(df_episodes, on='episode_id').merge(df_locations, on='location_id')\n\n# Show a preview\ndf_merged.head()",
          "Select rows where \"raw_text\" contains \"donut\"\ndf_script_donuts = df_script[df_script['raw_text'].str.contains('donut')]",
          "First, let's take a look at the first few rows of each of these dataframes to understand the kind of data we are dealing with.",
          "The data is now loaded into dataframes, let's take a quick look at the structure of each dataframe.",
          "Ensure the episode_id is a string\ndf_script['episode_id'] = df_script['episode_id'].astype(str)",
          "What are the shapes of the datasets?",
          "Count the number of times each character speaks and plot the 10 most common ones.",
          "Let's take a look at the structure of the dataframes and the first few rows:",
          "Let's start by displaying a sample of each dataframe.",
          "Previewing the data.",
          "Display some sample data",
          "Lets check how the data looks like.",
          "View first 5 rows of the characters dataframe\ndf_characters.head()",
          "Install the nlargest package if you haven't yet.\n# You can do this in your terminal with the command `pip install nlargest`.\nfrom nlargest import NLargest",
          " Seems good, let's move on.",
          "Character names\ncharactersdf = [name.lower() for name in list(df_characters['character_name'])]",
          "Create a WordCloud of the script_lines in the field spoken_words.",
          "Character name and season columns are currently camel case, let's standardize to snake case by renaming the columns",
          "# Using spaCy's pre-built NLP model\nnlp = spacy.load(\"en_core_web_sm\")",
          "Preview datasets structure\nprint('Characters')\nprint(\"shape:\", df_characters.shape)\nprint(df_characters.head())\nprint('---------------------------------------')\n\nprint('Locations')\nprint(\"shape:\", df_locations.shape)\nprint(df_locations.head())\nprint('---------------------------------------')\n\nprint('Episodes')\nprint(\"shape:\", df_episodes.shape)\nprint(df_episodes.head())\nprint('---------------------------------------')\n\nprint('Script lines')\nprint(\"shape:\", df_script.shape)\nprint(df_script.head())",
          " Visualizations for different parts of the dataset\nfig, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize=(15, 5))\ndf_script.groupby('character_id').size().sort_values(ascending=False).head(10).plot(kind='bar', ax=ax1, title='Top 10 most lines spoken')\ndf_script.groupby('location_id').size().sort_values(ascending=False).head(10).plot(kind='bar', ax=ax2, title='Top 10 locations with most lines')\ndf_script.groupby('episode_id').size().plot(kind='bar', ax=ax3, title='Number of lines per episode')\n\n# Remove last xlabel as it is overlapping with the next plot\nax1.set_xlabel('')\nax2.set_xlabel('')\nfig.tight_layout()",
          "Set basic configurations for visualization\nmatplotlib.rcParams['figure.figsize'] = [12, 8]\nmatplotlib.rcParams['font.size'] = 12",
          "Rename some of the columns for clarification.",
          "Setting the path to the Simpsons dataset folder",
          "Display settings\npd.options.display.max_columns = 50",
          "First we will need to do a bit of cleanup of the dataset in order to work with it.",
          "Show the first 5 lines of the \"df_script\" dataframe.",
          "Inspect the first few rows of each dataframe to understand the data better.",
          " Print the first few rows of each dataframe to understand their structure\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()",
          "# Merge lines and character df; only keep lines by Simpsons characters\ndf_character_lines = df_script.merge(df_characters, how='inner', on='character_id')",
          "Select episode of interest\nepisode_of_interest = 'Simpsoncalifragilisticexpiala(AnnoyedGrunt)cious'",
          " Display the first few rows of the datasets\nprint(\"Characters Dataset\")\ndisplay(df_characters.head())\n\nprint(\"Locations Dataset\")\ndisplay(df_locations.head())\n\nprint(\"Script Dataset\")\ndisplay(df_script.head())\n\nprint(\"Episodes Dataset\")\ndisplay(df_episodes.head())",
          "Create a list of documents, one per episode, and a dataframe containing each episode title",
          "Show all available columns, including the index",
          "check dataframe shape\ndf_characters.shape",
          "# Ensure the script dataframe is not holding a lot of memory.\ndf_script.drop(['norm_text', 'timestamp_in_ms', 'speaking_line'], axis=1, inplace=True)",
          "This is a csv file that contains meta information about episodes.",
          "# merge tables to have access to all the information contained in the different files\ndf_script_location = pd.merge(df_script, df_locations, left_on='location_id', right_on='id')\ndf_script_location_character = pd.merge(df_script_location, df_characters, left_on='character_id', right_on='id')\ndf_script_location_character_episode = pd.merge(df_script_location_character, df_episodes, left_on='episode_id', right_on='id')\n\n# remove rows with missing lines\ndf_script_location_character_episode = df_script_location_character_episode.dropna(subset=['normalized_text'])\n\n# Sort lines by original air date\ndf_script_location_character_episode['original_air_date'] = pd.to_datetime(df_script_location_character_episode['original_air_date'])\ndf_script_location_character_episode = df_script_location_character_episode.sort_values('original_air_date')\n\n# Print the first few rows\ndf_script_location_character_episode.head()",
          "Get recent records from single episode per row\ndf_script = df_script.sort_values('id', ascending=True)",
          "# Display the dataframe\n\nprint(df_characters.head())",
          "Add some additional cleaning and encoding steps to our dataframes",
          "Limiting to the lines with valid character and location ids\ndf_script = df_script[df_script.character_id.isin(df_characters.id) & \n                      df_script.location_id.isin(df_locations.id)]",
          " Check the first 5 rows of the script dataframe\ndf_script.head()",
          "Joining the datasets on the common columns to be able to analyze the text based on other columns is an important step in this data pre-processing.",
          "Replace NaN values with appropriate ones",
          " View table top to understand data\ndf_characters.head()",
          "Combining script data with other datasets",
          "Merge df_script, df_episodes and df_characters to provide all the necessary data in one DataFrame",
          "Keep only some locales from the script lines dataframe",
          " Examine the script data to get more familiar with it\ndf_script.head()",
          "Create client for speech recognition service.",
          " Remove badly formatted rows from episodes and script tables",
          " Show dataframe shapes\ndf_characters.shape, df_locations.shape, df_script.shape, df_episodes.shape",
          "Check what the dataset looks like\nprint(df_characters.head())\nprint(df_locations.head())\nprint(df_script.head())\nprint(df_episodes.head())",
          "Display the first few rows of each dataframe to verify that the data was loaded correctly\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()",
          "Get a list of all the regular characters in the show.",
          "Display the first 5 rows of each dataframe\ndfs = [df_characters, df_locations, df_script, df_episodes]\nfor df in dfs:\n    display(df.head())",
          "Color for the different characters\ncolors = ['hsl('+str(h)+',50%'+',50%)' for h in np.linspace(0, 360, df_characters.shape[0])]",
          "Drop rows containing NaN values\ndf_character_nonull = df_script[df_script.speaking_line == True][['id', 'episode_id', 'number', 'raw_character_text']].dropna()\ndf_location_nonull = df_script[df_script.speaking_line == True][['id', 'episode_id', 'number', 'raw_location_text']].dropna()\ndf_script_nonull = df_script[df_script.speaking_line == True][['id', 'episode_id', 'number', 'raw_text']].dropna()\n# clean_short_lowertnl\ndf_episode_nonull = df_episodes.dropna()",
          "Split the text of every script line into individual words.",
          "See the first entries of the characters dataset\nprint(df_characters.head())",
          "# Names of the characters\ncharacters = df_characters.character_name.values\n\n# Names of the locations\nlocations = df_locations.location_name.values",
          "Tagging the variables that we will be using to create the corpus.",
          "View the first few rows of each dataframe to understand the data",
          " Viewing the first few rows of the character data\ndf_characters.head()",
          "Fix dataset inconsistencies and errors",
          "Merge characters, locations and episodes information into script data\ndf_script['character_name'] = df_script['character_id'].apply(lambda x: df_characters[df_characters['id'] == x]['name'].values[0])\ndf_script['location_name'] = df_script['location_id'].apply(lambda x: df_locations[df_locations['id'] == x]['name'].values[0])\ndf_script['episode_title'] = df_script['episode_id'].apply(lambda x: df_episodes[df_episodes['id'] == x]['title'].values[0])\ndf_script['episode_season'] = df_script['episode_id'].apply(lambda x: df_episodes[df_episodes['id'] == x]['season'].values[0])\ndf_script['episode_number'] = df_script['episode_id'].apply(lambda x: df_episodes[df_episodes['id'] == x]['number_in_season'].values[0])",
          "Merge dataframes on 'script_id' if we want to have all the information in one dataframe.",
          "Define directory path for wordcloud output\nwordcloud_dir = \"wordclouds\"",
          " Displaying the head of the tables to understand the data",
          "Select dialouges from episode one\nep1_id = 3\ndf_ep1 = df_script[df_script['episode_id'] == ep1_id].copy()\n\n# Display the first few rows of the dataframe\ndf_ep1.head()",
          "Import custom classes, functions and variables\nfrom nlp_pipeline import NLPPipeline\nfrom bokeh_helper import generate_chart_markup\n\nnlp = spacy.load('en_core_web_sm')",
          "Limit rows\ndf_script = df_script.sample(100000, random_state=42)\n\n# Issue with characters and locations\ndf_script.loc[df_script.raw_character_text.str.contains('explosion', case=False, na=False, regex=False), 'raw_character_text'] = 'explosion'\ndf_script.loc[df_script.raw_location_text.str.contains('explosion', case=False, na=False, regex=False), 'raw_location_text'] = 'explosion'",
          "Visualize the most mentioned characters in the script\n# Count the most mentioned characters in the script\ntop_characters = Counter(df_script.loc[df_script['speaking_line'] == 'true', 'character_id'])\ntop_characters = pd.DataFrame(top_characters.most_common(), columns=['character_id', 'count'])\n\n# Convert character_id to merge with df_characters\ntop_characters['character_id'] = top_characters['character_id'].astype(int)\ndf_characters['character_id'] = df_characters['character_id'].astype(int)\n\n# Merge the dataframes\ntop_characters = top_characters.merge(df_characters, on='character_id')\n\ntop_characters.head()",
          "Inspect the dataframes to understand their structure and what kind of information they contain.",
          "Remove episodes with missing data\ndf_episodes = df_episodes.dropna(subset=['original_air_date'])",
          "Drop rows which do not have any lines or location\ndf_script = df_script.dropna(subset=['raw_location_text', 'spoken_words'])\n\n\n# How many different locations are there in the script\ndf_script['raw_location_text'] = df_script['raw_location_text'].str.lower()\ndf_script['raw_location_text'] = df_script['raw_location_text'].str.replace('springfield','')\ndf_script['raw_location_text'] = df_script['raw_location_text'].str.replace('the simpson home','home')\ndf_script['raw_location_text'] = df_script['raw_location_text'].str.replace('the simpson house','home')\ndf_script['raw_location_text'] = df_script['raw_location_text'].str.replace(\"moe's tavern\",\"moes tavern\")\ndf_script['raw_location_text'] = df_script['raw_location_text'].str.replace(\"moe's\",\"moes tavern\")\ndf_script['raw_location_text'] = df_script['raw_location_text'].str.strip()\n\nlen(df_script['raw_location_text'].value_counts())",
          "first, let's cleanup the data.",
          "Wordcloud on all the characters lines",
          "Github link: https://github.com/alexkenan/simpsons_scripts_analysis\n# Quick dataframe shaping\nprint('Shape:')\nprint(f'Characters: {df_characters.shape}')\nprint(f'Locations: {df_locations.shape}')\nprint(f'Script: {df_script.shape}')\nprint(f'Episodes: {df_episodes.shape}')\n\n# Display insteresting attributes about the data\nprint(f'Sample characters:')\nprint(df_characters.sample(5))\nprint(f'Sample locations:')\nprint(df_locations.sample(5))\nprint(f'Sample episodes:')\nprint(df_episodes.sample(5))",
          "Displaying the output of the last code xpression in Jupyter doesn't print the dataframe, \n# but calling the dataframe which we will do for each of them later does\ndf_characters",
          "Top of the \"Episode list\" table",
          "Remove whitespaces from headers and make them lowercase\ndf_characters.columns = df_characters.columns.str.strip().str.lower().str.replace(' ', '_')\ndf_locations.columns = df_locations.columns.str.strip().str.lower().str.replace(' ', '_')\ndf_script.columns = df_script.columns.str.strip().str.lower().str.replace(' ', '_')\ndf_episodes.columns = df_episodes.columns.str.strip().str.lower().str.replace(' ', '_')",
          "Ensure the script is sorted by episode and id\ndf_script = df_script.sort_values(by=['episode_id', 'id']).reset_index(inplace=False, drop=True)",
          "Print the head of each DataFrame to inspect them\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()",
          "Print how many episodes our dataset contains",
          "Setting environment variable for CUDA\nos.environ[\"CUDA_VISIBLE_DEVICES\"] = \"\"",
          "Set plot style\nplt.style.use('fivethirtyeight')",
          " Display top rows of each dataframe\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()",
          "clean the script dataframe by dropping useless data",
          "Removing rows having - and NaN values in `script_text` column\ndf_script = df_script[df_script['raw_character_text'] != '-']\ndf_script = df_script[df_script['raw_character_text'].notna()]\ndf_script = df_script[df_script['speaking_line'] == True]",
          "Quick look at the structure of the datasets",
          "np.random.seed(0)",
          "Check the data\nprint(\"The characters:\")\ndisplay(df_characters.head())\nprint(\"The locations:\")\ndisplay(df_locations.head())\nprint(\"The script:\")\ndisplay(df_script.head())\nprint(\"The episodes:\")\ndisplay(df_episodes.head())",
          "Lets see what each dataframe looks like",
          " Display an overview of the data in the datasets",
          "Check the size of the dataframes\ndf_characters.shape, df_locations.shape, df_script.shape, df_episodes.shape",
          "# Shows the first rows of the table in a Jupyter\ndf_characters.head()",
          " Specify data types for each column in the episodes dataframe for space efficiency\ndtypes = {\n    'id': 'uint32',\n    'title': 'category',\n    'original_air_date': 'datetime64',\n    'production_code': 'object',\n    'season': 'uint8',\n    'number_in_season': 'uint8',\n    'number_in_series': 'uint16',\n    'us_viewers_in_millions': 'float32',\n    'views': 'uint32',\n    'imdb_rating': 'float32',\n    'imdb_votes': 'uint32',\n    'image_url': 'object',\n    'video_url': 'object',\n    'special_features': 'object',\n    'writers': 'object',\n    'directors': 'object',\n    'guest_stars': 'object'\n}\n\n# Apply the data types to the episodes dataframe\ndf_episodes = df_episodes.astype(dtypes)",
          "Filter the dataframe to only include rows where the speaking line is associated with a character and a location.\ndf_script_char_loc = df_script[df_script['raw_character_text'].apply(lambda x: x in df_characters['character_name'].values)]\ndf_script_char_loc = df_script_char_loc[df_script_char_loc['raw_location_text'].apply(lambda x: x in df_locations['normalized_name'].values)]",
          " Visualize the first few rows of each dataframe\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()",
          "Separate lines into dialogues from the same scene and speaker.",
          "Merge with mapping files",
          "Remove spaces from column names\ndf_characters.columns = df_characters.columns.str.replace(' ', '_')\ndf_locations.columns = df_locations.columns.str.replace(' ', '_')\ndf_script.columns = df_script.columns.str.replace(' ', '_')\ndf_episodes.columns = df_episodes.columns.str.replace(' ', '_')",
          "Transform character_id, location_id and episode_id to integers for every line\ndf_script['character_id'] = pd.to_numeric(df_script['character_id'], errors='coerce').fillna(0).astype(np.int64)\ndf_script['location_id'] = pd.to_numeric(df_script['location_id'], errors='coerce').fillna(0).astype(np.int64)\ndf_script['episode_id'] = pd.to_numeric(df_script['episode_id'], errors='coerce').fillna(0).astype(np.int64)",
          "Display series lists two column names.",
          "Open the script lines dataset and join with relevant others",
          "Select only these characters with known locations:\nknown_characters = df_characters[df_characters['location_id'].notnull()]['character_id'].values\n\n# Filter the lines only to those spoken by known characters\ndf_script_known = df_script[df_script['character_id'].isin(known_characters)]\n\nprint(f'The dataset contains {len(df_script_known)} lines of {len(known_characters)} characters with known locations')",
          "Set which cast member has which gender.",
          "Display the first few characters of the datasets\nprint('Characters:')\ndisplay(df_characters.head())\nprint('Locations:')\ndisplay(df_locations.head())\nprint('Script:')\ndisplay(df_script.head())\nprint('Episodes:')\ndisplay(df_episodes.head())",
          "View basic info about the dataframes\nprint(df_characters.head())",
          "Visualisation du nombre de lignes par saison\ndf_episodes['production_season'].value_counts().sort_index().plot(kind='bar', figsize=(15, 5))\nplt.title('Nombre de lignes par saison')\nplt.xlabel('Saison')\nplt.ylabel('Nombre de lignes')\nplt.grid(axis='y', linestyle='--', alpha=0.7)\nplt.show()",
          "Preview the first few rows of each dataframe\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()",
          "Print the number of available script lines\nprint(f'Number of script lines: {df_script.shape[0]:,}')",
          "Inspect the dataframes to understand the data",
          "\n# Let's take a look at the content of these files\nprint('Characters\\n', df_characters.head())\nprint('\\n\\nLocations\\n', df_locations.head())\nprint('\\n\\nScript\\n', df_script.head())\nprint('\\n\\nEpisodes\\n', df_episodes.head())",
          "Visualize the percentage of lines spoken by each character\nlines_spoken = df_script['raw_character_text'].value_counts(normalize=True) * 100\nlines_spoken = lines_spoken[df_characters['character_id'].values]\nlines_spoken = lines_spoken.sort_values(ascending=True)\n\nplt.figure(figsize=(10, 25))\nplt.barh(lines_spoken.index, lines_spoken.values, color='skyblue')",
          "Filter out all the non-Simpsons lines from the dataframe",
          "Merge datasets to simplify the data analysis process and have various attributes of the script lines in the same DataFrame.",
          "Let's start by examining the structure of `df_characters`.",
          "The script that computes the length of each line in words is given below:",
          "Setting Python to print a large number of columns\npd.options.display.max_columns = 50",
          "Changing column names for consistency with annotations",
          "Visualize the distribution of the line_count column in the df_script dataframe",
          "Visualize distribution of script line lengths",
          "Remove the rows having NaN values in certain columns from the dataframe df_script",
          "Limit the data for analysis for now: top 4 characters and top 4 locations.\ncharacters = ['Homer Simpson', 'Marge Simpson', 'Bart Simpson', 'Lisa Simpson']\nlocations = ['Simpson Home', \"Moe's Tavern\", 'Kwik-E-Mart', 'Springfield Elementary School']\n\n# Specific scripts / lines with the characters and locations:\ndf_script_character_limited = df_script[df_script.character_id.isin(df_characters[df_characters.raw_character_text.isin(characters)].index)]\ndf_script_location_limited = df_script[df_script.location_id.isin(df_locations[df_locations.raw_location_text.isin(locations)].index)]",
          "We will start by loading the necessary datasets for our analysis.",
          "Display the first few lines of the dataframes to understand their structure\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()",
          " These will be the sources of data we will be working with.",
          "Check if GPU is available\nspacy.prefer_gpu()",
          " Clean the dataset\ndf_script = df_script[df_script.raw_location_text.notnull()]\ndf_script = df_script[df_script.raw_character_text.notnull()]\ndf_script = df_script[df_script.raw_character_text.str.strip() != '']\ndf_script = df_script[df_script.raw_location_text.str.strip() != '']\ndf_script.reset_index(drop=True, inplace=True)",
          " extract characters, locations and script\ncharacters = df_characters['normalized_text'].values.tolist()\nlocations = df_locations['normalized_text'].values.tolist()\nscript = df_script['normalized_text'].values.tolist()",
          "Load NLP model\nnlp = spacy.load('en_core_web_sm')\n\n# Check if the NLP model is loaded successfully\nnlp.vocab.length",
          "Ensure matplotlib uses the default style\nmatplotlib.style.use('default')",
          "Show how the dataset look\ndf_script.head()",
          " Set random seed for deterministic results\nnp.random.seed(0)",
          " We use the spaCy library for named entity recognition. Let's load the English language model for spaCy.",
          "ensure scriptLine order\ndf_script = df_script.sort_values(by=['episode_id', 'timestamp_in_ms']).reset_index(inplace=False, drop=True)",
          " Display first rows of the characters data\ndf_characters.head()",
          "Show the first 3 rows of the `df_characters` dataframe\ndf_characters.head(3)",
          "Look at the head of the lines DataFrame",
          "If you have a different file path, please modify it accordingly.",
          "Combine script lines and episodes data into a single dataframe",
          " Viewing content first rows\ndf_characters.head()",
          "We set the index as \"id\" because the field is unique.",
          "# Checking the first lines of the dataframe\nprint(\"\\nData: Characters\")\nprint(df_characters)\nprint(\"\\nData: Locations\")\nprint(df_locations)\nprint(\"\\nData: Script\")\nprint(df_script)\nprint(\"\\nData: Episodes\")\nprint(df_episodes)",
          "Let us take a look at each dataframe to better understand the kind of data we have.",
          "Prints datasets' head",
          "We will start by loading the datasets we'll use for the analysis.",
          "Check the content for each dataframe\nprint(\"\\nContent of characters dataframe\")\nprint(df_characters.head())\n\nprint(\"\\nContent of locations dataframe\")\nprint(df_locations.head())\n\nprint(\"\\nContent of script dataframe\")\nprint(df_script.head())\n\nprint(\"\\nContent of episodes dataframe\")\nprint(df_episodes.head())",
          "Optional: Uncomment and reproduce the sample code to rename column names for easier referencing in the subsequent sections\n\ndf_script.columns = df_script.columns.str.lower()\ndf_episodes.columns = df_episodes.columns.str.lower()\ndf_characters.columns = df_characters.columns.str.lower()\ndf_locations.columns = df_locations.columns.str.lower()",
          "Directly print the length of each dataframe",
          "Merge the data to get a single dataframe containing all information about each line of script.",
          "Replace NaN values with empty strings\ndf_script['normalized_text'] = df_script['normalized_text'].fillna('')",
          "Inspect the structure of the data:",
          "Set the random seed for numpy to have the same results for multiple runs\nnp.random.seed(0)",
          "Displaying the dataframe types to start understanding their structures\nprint(df_characters.dtypes)\nprint(df_locations.dtypes)\nprint(df_script.dtypes)\nprint(df_episodes.dtypes)",
          " Feature Engineering",
          " Preview the first 5 rows of each dataframe\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()",
          "Check our data\nprint(f'Characters: {df_characters.shape[0]}')\nprint(f'Locations: {df_locations.shape[0]}')\nprint(f'Script lines: {df_script.shape[0]}')",
          "Downloading the large English model for spaCy, please wait...",
          "Check the first 5 rows for each dataset.",
          "Display the first few rows of the characters data\ndf_characters.head()",
          "Filter the character list to remove non-character names or add missing characters\ncharacters_to_remove = ['narrator']\n\ndf_characters_filtered = df_characters[~df_characters['name'].str.lower().isin(characters_to_remove)]\ndf_characters_filtered.reset_index(drop=True, inplace=True)",
          "Setting up the basic configuration for the spaCy library",
          "The lines and their structure is in df_script dataset. Let's add a column to it that has the text, each line was referencing, added and then we can do the same thing as above.",
          "Print some statistics about the data",
          "Print the first rows of each dataframe to better understand the data structure\n\nprint(df_characters.head())\nprint(df_locations.head())\nprint(df_script.head())\nprint(df_episodes.head())",
          "Showing the dataframe shape\nprint ('Characters dataframe shape: {}'.format(df_characters.shape))\nprint ('Locations dataframe shape: {}'.format(df_locations.shape))\nprint ('Script dataframe shape: {}'.format(df_script.shape))\nprint ('Episodes dataframe shape: {}'.format(df_episodes.shape))",
          "check missing data\ndf_script.info()",
          "Setting seed for reproducibility\nnp.random.seed(0)",
          "Extract top speakers from the data\ntop_speakers = df_script.raw_character_text.value_counts(normalize=True).round(2)\ntop_speakers = top_speakers[0:20]\n\n# Plot top speakers\ntop_speakers.plot(kind='barh')",
          "Check shape of all the dataframes",
          "D(**df_characters.head(2))\n# display(df_locations.head(2))\n# display(df_script.head(2))\n# display(df_episodes.head(2))",
          "Fetch a subset of the data and decrease it for efficiency",
          "Clean Script DataFrame\ndf_script = df_script.drop(columns=[\n    'number', 'raw_text', 'timestamp_in_ms', '_heartbeat_', \n    'speaking_line', 'character_id', 'location_id', 'raw_character_text',\n    'raw_location_text', 'spoken_words', 'normalized_text'\n])",
          "Check import\nprint(df_characters.head())",
          "\n# Preprocess script lines\n# Remove unwanted columns\ndf_script = df_script.drop(['id', 'image_url'], axis=1)",
          "#   display(df_characters.head())\n#   display(df_locations.head())\n#   display(df_script.head())\n#   display(df_episodes.head())",
          "\n# Sample data\ndf_script.head()",
          "Show how the script data looks like\ndf_script.head()",
          " Look at the dimension of dataframes",
          "Ensure that we only use 1/4 of every element of the dataset as a temporary measure.",
          " Print header\nprint(df_episodes.head())\n\n# Prints number of lines per episode\nprint(df_script.groupby('episode_id')['id'].count())",
          "Show the first few characters of the main datasets\nprint(df_characters.head())\nprint(df_locations.head())\nprint(df_script.head())\nprint(df_episodes.head())",
          "Display basic info for each of the datasets",
          " Ensure the correct encoding of the dataframes\ndf_characters = df_characters.applymap(lambda x: x.encode('unicode_escape').\n              decode('utf-8') if isinstance(x, str) else x)\ndf_locations = df_locations.applymap(lambda x: x.encode('unicode_escape').\n             decode('utf-8') if isinstance(x, str) else x)\ndf_script = df_script.applymap(lambda x: x.encode('unicode_escape').\n            decode('utf-8') if isinstance(x, str) else x)\ndf_episodes = df_episodes.applymap(lambda x: x.encode('unicode_escape').\n              decode('utf-8') if isinstance(x, str) else x)",
          "Keep a copy of the original dataset just in case\ndf_characters_orig = df_characters.copy()\ndf_locations_orig = df_locations.copy()\ndf_script_orig = df_script.copy()\ndf_episodes_orig = df_episodes.copy()",
          " Add a setting to allow pandas to display the right number of columns\npd.set_option('display.max_columns', 8)",
          "Create backup copies of the datasets\ndf_characters_bk = df_characters.copy()\ndf_locations_bk = df_locations.copy()\ndf_script_bk = df_script.copy()\ndf_episodes_bk = df_episodes.copy()",
          "Let's quickly inspect and clean the data to get an overview.",
          "What are the dtypes that each dataframe is storing?",
          "Set the indexing of the DataFrames to be the index column, as the index will be useful manipulate the DataFrames.",
          " Inspect the first few rows of each dataframe\ndisplay(df_characters.head())\ndisplay(df_locations.head())\ndisplay(df_script.head())\ndisplay(df_episodes.head())",
          "Check the size of the dataframes",
          "Time to look at the files we have loaded!",
          "CORRECT INCORRECT COLUMNS IN script LINES DATAFRAME",
          "A take on entity extraction.\n# Tokenizing the description of Lisa at the start\nnlp = spacy.load(\"en_core_web_sm\")\ndoc = nlp(df_characters[0:1]['description'][0])\nfor token in doc:\n    print(token, token.pos_, token.dep_)",
          "Create counting dictionaries",
          "Remove some irrelevant columns to enhance readability\ndf_script.drop(columns=['norm_text', 'word_count', 'location_id', 'timestamp_in_ms', 'speaking_line', 'raw_text', 'timestamp_in_ms', 'raw_character_text', 'spoken_words', 'normalized_text', 'representation'], inplace=True)",
          "Display top 5 records of each data frame to understand the fields",
          "Merge lines with episode info\ndf_all = df_script.merge(df_episodes, on='episode_id', suffixes=('_script', '_episode'))",
          "View the structure of the characters dataframe\ndf_characters.head()",
          "Join all on 'episode_id' and 'id' to get a full dataframe",
          "\ndef get_script_character(script_id):\n    '''\n    INPUT\n    script_id: int - the id of the script\n    \n    OUTPUT\n    A string representing the character\n    \n    Given a script id, returns the simpson character of the line.\n    '''\n    return df_script['character_id'][df_script['id'] == script_id].values[0]",
          "modules=BERTComponents(embedding_dim=768)",
          "Check that the script dataframe has the correct columsолучить список столбцов в dataframe.",
          "Define a variable with the path to the directory containing the seasons\ndirname = 'data/simpsons_episodes/'",
          "start by preliminary analysis of the dataset, let's get an overview of the data.",
          " Check the dataframe entries count, dataframe columns and null values with pandas utilities.",
          "Concatenate the spoken words for each episode and speaker\ndf_script_concatenated = df_script.groupby(['episode_id', 'character_id']).agg({'spoken_words': ' '.join}).reset_index()",
          " Check if we have NaN values in the dataset, True means that we have NaN values, False means that we don't.",
          "Let's take a peek at our datasets\ndf_episodes.head(), df_characters.head(), df_locations.head(), df_script.head()",
          "Remove invalid script lines and merge tables",
          "## Data Cleaning and Exploration",
          "Combine the text from all the script lines into a single string for wordcloud generation\nscript_text = \" \".join(df_script['normalized_text'].fillna(''))",
          "Load the data",
          "Check the number of data points \nprint(\"Number of data points: \", df_script.shape[0])",
          " Let's check the first lines of each dataframe.",
          " display the first 5 script lines\ndf_script.head()",
          " Set the display name for each character and location based on the columns shown above",
          " Group the script by episodes and join the lines for each speaker",
          "###############\n# Data Analysis\n###############",
          "Let's display the content of the dataframes to assess their structure and the data they contain.",
          "Check the number of records in each dataframe\nprint(df_characters.shape)\nprint(df_locations.shape)\nprint(df_script.shape)\nprint(df_episodes.shape)",
          "Let's display the head of these DataFrames to understand the data better.",
          "Merge dataset\ndf_script.info()",
          "Check the first few entries for each of the dataframes to understand the structure of the data",
          " Filter characters with non-resolved names\ndf_characters = df_characters[df_characters.raw_character_text.str.contains('Simpson') | df_characters.raw_character_text.str.contains('simpson')].reset_index(inplace=False, drop=True)",
          "Extract only 1% of the rows for a reasonable runtime during the analysis\ndf_script = df_script.sample(frac=0.01, random_state=1).reset_index(inplace=False, drop=True)",
          "Count the number of episodes where \"Bart\" is mentioned\ndf_script[df_script['raw_text'].str.contains('Bart')]['episode_id'].nunique()",
          " Demonstrating the data structure and number of entries in each dataset",
          "Reduce the amount of memory used by the dataframes.",
          " Analyze the characters data\nprint(df_characters.head())",
          "Setting up Spacy\n# For illustrative purposes, we will only look at the first 10000 script lines.\nnlp = spacy.load(\"en_core_web_sm\")\n\n# Here we use parallelization to make the Spacy NLP tests faster\ntqdm.pandas()",
          "Let's check the size of these Dataframes",
          "Remove duplicate values from characters, locations and episodes dataframes\n# We need to do this before merging to avoid duplication issues",
          "Explore the data\npd.set_option('display.max_columns', None)",
          "Exploratory Data Analysis",
          "# Join script database with characters\ndf_characters_info = df_script.join(df_characters.set_index('id'), on='character_id')\n\n# Join characters info database with locations\ndf_locations_info = df_characters_info.join(df_locations.set_index('id'), on='location_id')",
          "Count the number of lines in df_script\nlen(df_script)",
          "Set the random seed for numpy for reproducible results\nnp.random.seed(0)",
          "\n# Display the first few rows of the characters table\ndf_characters.head()",
          "Calculate the number of spoken words per gender\nspoken_words_per_gender = df_script.groupby(['spoken_by', 'gender']).agg({'word_count': 'sum'}).reset_index()\nspoken_words_per_gender['spoken_by'] = spoken_words_per_gender['spoken_by'].str.lower()\n\n# Speeches of the 4 main characters\nspoken_words_per_gender[spoken_words_per_gender['spoken_by'].str.contains('homer|marge|bart|lisa')]",
          "Check the imported datasets\ndf_characters.head()",
          "Text vectorization of the series names",
          "Prepare for data exploration\n# Show all columns\npd.options.display.max_columns = 50",
          "View some records\nprint(df_characters.head())",
          "Check column names",
          "Check a few entries from each dataframes to understand the structure of the data.",
          "Load locally saved stop words, to use common stop word list\nwith open('data/stopwords.txt', 'r') as f:\n    stopwords = f.read().split('\\n')",
          "Remove annoying characters from character names",
          " Clean characters\n# Remediate duplicate/empty rows\ndf_characters = df_characters.drop_duplicates(subset='id')\ndf_characters = df_characters.dropna(subset=['name'])\n\n# Ensure case-insensitive matching\ndf_characters['name_lowercase'] = df_characters['name'].str.lower()",
          "Get rid of some unnamed columns\ndf_characters.columns = df_characters.columns.str.replace('Unnamed: [0-9]+', '')",
          "Set random_state for reproducible results\nnp.random.seed(0)",
          " Concatenate the names and surnames of the characters for easier identification\ndf_characters['full_name'] = df_characters['name'] + ' ' + df_characters['surname']",
          "Create a copy of the columns that will be modified",
          " Display the dataframe containing the script\ndf_script",
          "Some more exploratory data analysis ...\n# Filter out non-episode, non-dialogue script lines\ndf_script = df_script[\n    (df_script['episode_id'] != -1) & \n    (df_script['character_id'] != -1)\n].reset_index(inplace=False, drop=True)",
          "Check character ID 8 lines in the script dataset\ndf_script[df_script.raw_character_text.str.contains('marge', case=False, na=False)].raw_character_text.unique()",
          "GC.collect()  # Garbage collection",
          "Function to remove accents from characters",
          " Ensure that all datasets have loaded correctly\nprint(f'Characters data shape: {df_characters.shape}')\nprint(f'Locations data shape: {df_locations.shape}')\nprint(f'Script data shape: {df_script.shape}')\nprint(f'Episodes data shape: {df_episodes.shape}')",
          "Remove special character from episode titles and transform to lowercase\ndf_episodes['title'] = df_episodes['title'].str.replace('[^A-Za-z0-9 ]+', '').str.lower()",
          "List available datasets\ndatasets = [df_characters, df_locations, df_script, df_episodes]",
          " Remove rare characters from the data\ncharacter_counts = df_script.raw_character_text.value_counts()\nmask = (character_counts >= 50)\ncharacter_list = character_counts.index[mask].tolist()\ndf_script = df_script[df_script['raw_character_text'].isin(character_list)]",
          "Merging the dataframes to get more comprehensive information for each line of the script.",
          "Counting the number of words in the script line and storing the count in a separate column",
          " Drop one column because the indexcol is exported as a column",
          "Merge episodes data to get the name of the episodes along with the script data\ndf_script = pd.merge(df_script, df_episodes[['id', 'title', 'original_air_date']], left_on='episode_id', right_on='id')",
          "Set path to Simpsons data folder\npath = 'data'",
          "Display first few rows of the characters dataframe\ndf_characters.head()",
          "Apply basic preprocessing\ndf_script = df_script[df_script['episode_id'] != 464]  # Removing faulty lines\ndf_script = df_script[df_script.notnull()]  # Dropping NaN values in all columns",
          "Visualizing the most popular characters",
          "Displaying a few rows of the script data\ndf_script.head()",
          " Now that we have our dataframes loaded, let's take a look at the first few rows of each dataframe to familiarize ourselves with the data.",
          "Check the structure of the dataframes and display their first few rows\nprint(\"Characters\")\nprint(df_characters.head())\nprint(\"Locations\")\nprint(df_locations.head())\nprint(\"Script\")\nprint(df_script.head())\nprint(\"Episodes\")\nprint(df_episodes.head())",
          "Inspect data types and missing values\ndf_script.info()",
          "Function to display some lines around a given line index\ndef show_context(idx, nbL=2):\n    for i in range(nbL, 0, -1):\n        print(f'{df_script.iloc[idx - i].raw_character_text} - {df_script.iloc[idx - i].spoken_words}')\n    print('## -------------------------------------------------- ##')\n    print(f'{df_script.iloc[idx].raw_character_text} - {df_script.iloc[idx].spoken_words}')\n    print('## -------------------------------------------------- ##')\n    for i in range(1, nbL+1):\n        print(f'{df_script.iloc[idx + i].raw_character_text} - {df_script.iloc[idx + i].spoken_words}')",
          "\n# Print the first lines of the table related to the characters present in the series\ndf_characters.head()",
          " Strip whitespaces in character_id column\ndf_script['character_id'] = df_script['character_id'].str.strip()",
          "Quick display of the character dataframe\ndf_characters.head()",
          "cos when print statements appear in the middle of my sentence I can think of nothing better so say.",
          "Select right episodes and keep only right columns",
          " Let's display some basic information about the dataframes.",
          " Visualize quick informations about datasets",
          " Check the size of each dataframe",
          " Show the modules.",
          "Ensure correct data types for script and episodes\ndf_episodes['id'] = df_episodes['id'].astype(int)\ndf_script['episode_id'] = df_script['episode_id'].astype(int)",
          "remove the 'text' column from df_script to speed up processing, if needed\n# df_script = df_script.drop(columns=['text'])",
          "We will load the preprocessed data (to be precise, the cleaned data that we just created) to start with the text analysis process.",
          "clean the character lines by dropping duplicate lines and removing special chars\ndf_script = df_script.drop_duplicates('raw_text').reset_index(inplace=False, drop=True)",
          "View the content of all the datasets\nprint('[INFO] Number of characters:', df_characters.shape[0])\ndf_characters.head()",
          "Filter the data to only include the lines from the 10 main characters.",
          "Code\n# Data exploration\nprint('Characteres:')\nprint(df_characters.info())\nprint(df_characters.describe())\nprint(df_characters.head())\nprint(df_characters.tail())",
          "Check that the datasets were loaded correctly\nprint(\"Characters:\")\nprint(df_characters.head())\n\nprint(\"\\nLocations:\")\nprint(df_locations.head())\n\nprint(\"\\nScript:\")\nprint(df_script.head())\n\nprint(\"\\nEpisodes:\")\nprint(df_episodes.head())",
          "Let's see how the data looks by displaying the first few rows of each dataframe.",
          "Clean and pre-process the data\n# Eliminate the rows with any nan values\ndf_script = df_script.dropna()\n\n# Keep only the required columns\ndf_script = df_script[['episode_id', 'number', 'raw_text', 'speaking_line', 'character_id', 'location_id']]",
          "In the root directory, create a `visualizations` directory if it does not exist.",
          "The next section replaces speaker's names, locations, and special expressions by\n# VALUE_NOT_USED. We also store each replacement in separate csv files.\n\nfrom preprocess import *",
          "Remove unwanted columns from characters, locations and episodes dataframes",
          "Tokenize the text data of each script line using SpaCy.",
          "Setting to display all columns of the dataframes in the notebook\npd.set_option('display.max_columns', None)",
          "Converting 'raw_text' column into string type",
          "Displays the first 3 rows from the characters dataframe\ndf_characters.head(3)",
          "Separate the string with main and secondary characters into lists.",
          "Display the top 5 rows of each dataframe\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()",
          "Extract main characters from characters df\nmain_characters = df_characters[df_characters['raw_character_text'].str.contains('simpson', case=False)]['raw_character_text']\n\n# Prepare name matching (case insensitive & remove leading/trailing white space)\nmain_characters = main_characters.apply(lambda x: x.lower().strip())\n\n# Extract locations\nlocations = df_locations['name']\n\n# Extract episodes titles\nepisodes_titles = df_episodes['title']",
          "Create a pandas series with the top characters and create a word cloud.",
          "Name columns consistently across datasets.",
          "Method to display shape of DataFrame\ndef display_shape(df, name):\n    print(f'{name} shape:', df.shape)",
          " Start by getting an overview of the data",
          "Check if GPU is available\nimport tensorflow as tf\nprint(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))",
          " Visualize top characters",
          "Setting a seed for reproducibility\nnp.random.seed(123)",
          " Check the imported data\nprint(df_characters.head())",
          "Clean episode titles\ndf_episodes['clean_title'] = df_episodes['title'].str.replace('\\\".*\\\"', '', regex=True)\ndf_episodes['clean_title'] = df_episodes['clean_title'].str.replace('\\[.*\\]', '', regex=True)",
          "Let's first start by exploring the dataset and understanding its structure.",
          "Display dataframe\ndf_script",
          "Let's first take a look at the structure of the data and have a peak at the first few rows.",
          "Clean the data: Some characters and many locations have the honorific \"The\" in their name, which can confuse the API.",
          "Check out the contents of each of the dataframes",
          "Check the head of each dataframe to understand the available data.",
          "Remove the lines which does not have character, location, and raw_text information.",
          " Let's take a quick look at the contents of the data frames to understand the data structure.",
          "Join all data together\ndf = df_script.copy()",
          " Preprocess the text data and merge the relevant columns",
          "Sample data to understand the structure and contents of the data frames that have been created",
          null
         ],
         "marker": {
          "color": "#CFD8DC",
          "opacity": 0.5,
          "size": 5
         },
         "mode": "markers+text",
         "name": "other",
         "showlegend": false,
         "type": "scattergl",
         "x": [
          16.9243221282959,
          14.718270301818848,
          -0.8336579203605652,
          -2.177931070327759,
          20.15520668029785,
          17.322364807128906,
          14.67169189453125,
          9.869457244873047,
          15.903987884521484,
          6.4692702293396,
          5.989692211151123,
          7.360758304595947,
          7.08561372756958,
          8.886017799377441,
          6.049485683441162,
          -3.4788761138916016,
          16.545398712158203,
          17.15036964416504,
          10.111028671264648,
          8.49087142944336,
          5.214050769805908,
          5.68009090423584,
          13.474016189575195,
          -0.6481894254684448,
          2.325862169265747,
          2.997718095779419,
          -0.988429844379425,
          7.992311477661133,
          8.911310195922852,
          0.008761550299823284,
          7.236743927001953,
          13.819196701049805,
          15.366663932800293,
          9.556113243103027,
          -0.4469754993915558,
          4.430975437164307,
          9.311653137207031,
          12.114006042480469,
          30.746170043945312,
          6.87487268447876,
          8.518831253051758,
          12.947912216186523,
          9.139147758483887,
          21.985530853271484,
          9.456504821777344,
          -1.8000965118408203,
          10.450263023376465,
          8.433788299560547,
          6.489278316497803,
          20.390716552734375,
          7.644186973571777,
          10.791735649108887,
          6.98927116394043,
          6.202446937561035,
          9.578252792358398,
          9.240758895874023,
          10.390137672424316,
          -0.8038867115974426,
          7.698911190032959,
          14.646024703979492,
          13.538538932800293,
          3.180870771408081,
          3.309229850769043,
          12.682348251342773,
          1.2232052087783813,
          13.891250610351562,
          6.214249610900879,
          21.522937774658203,
          12.457348823547363,
          -4.087405681610107,
          14.00266170501709,
          14.51982593536377,
          16.645483016967773,
          5.5332441329956055,
          -1.2555804252624512,
          5.652230262756348,
          0.6610632538795471,
          17.597442626953125,
          5.200153350830078,
          12.65225601196289,
          -4.933899402618408,
          10.793487548828125,
          2.8200371265411377,
          -1.0648342370986938,
          5.886332988739014,
          9.110855102539062,
          3.9190919399261475,
          8.63736629486084,
          0.23890817165374756,
          6.42510986328125,
          4.215158462524414,
          16.095701217651367,
          -1.1337443590164185,
          6.286603927612305,
          -3.1261539459228516,
          -3.7587156295776367,
          3.7881999015808105,
          13.06179141998291,
          4.646895885467529,
          12.60918140411377,
          11.914948463439941,
          4.235408782958984,
          31.567659378051758,
          -4.60615348815918,
          6.0328874588012695,
          10.839269638061523,
          14.94227123260498,
          7.150223731994629,
          9.5671968460083,
          -4.111253261566162,
          -2.793278932571411,
          15.176627159118652,
          6.4316205978393555,
          8.929344177246094,
          5.790907859802246,
          4.4488525390625,
          9.928444862365723,
          10.131715774536133,
          -0.854511022567749,
          5.946830749511719,
          3.645364284515381,
          5.824234485626221,
          5.799569129943848,
          6.376007080078125,
          29.847248077392578,
          8.055859565734863,
          20.16061019897461,
          -1.8677341938018799,
          10.187285423278809,
          2.81534481048584,
          -0.48978525400161743,
          4.370922088623047,
          0.9938110113143921,
          10.213842391967773,
          1.406701922416687,
          6.9876861572265625,
          4.6774444580078125,
          5.563868999481201,
          -1.3984097242355347,
          -1.9600123167037964,
          32.16411209106445,
          6.174610614776611,
          9.48128604888916,
          9.236414909362793,
          9.868586540222168,
          -1.6803404092788696,
          6.517873764038086,
          14.273958206176758,
          -2.865072250366211,
          -0.4857722818851471,
          14.07190227508545,
          5.795305252075195,
          -1.8042432069778442,
          -1.0978882312774658,
          5.554062843322754,
          5.848244667053223,
          10.690573692321777,
          6.831393718719482,
          9.785330772399902,
          4.194214820861816,
          9.644404411315918,
          1.0401544570922852,
          15.470597267150879,
          6.410184383392334,
          9.688921928405762,
          3.1584713459014893,
          5.814417839050293,
          3.7195422649383545,
          3.5834338665008545,
          4.968713760375977,
          8.142632484436035,
          16.067052841186523,
          7.680747985839844,
          16.422971725463867,
          13.848480224609375,
          13.83864974975586,
          20.059478759765625,
          -4.03093147277832,
          13.58855152130127,
          14.223444938659668,
          10.830208778381348,
          -0.19925355911254883,
          3.7097487449645996,
          5.834193706512451,
          17.32294273376465,
          9.855690956115723,
          -2.798356533050537,
          14.32436466217041,
          6.502053737640381,
          4.641762733459473,
          2.527655839920044,
          -4.786866664886475,
          8.032916069030762,
          -2.433722972869873,
          6.64772891998291,
          21.26239776611328,
          13.647790908813477,
          5.291292190551758,
          6.3295769691467285,
          5.018490314483643,
          -2.8054449558258057,
          7.114659309387207,
          -2.7439122200012207,
          -0.44818541407585144,
          14.148777961730957,
          10.231600761413574,
          6.630489826202393,
          3.858828544616699,
          -1.2344900369644165,
          -0.6885554790496826,
          30.805622100830078,
          14.498559951782227,
          14.481881141662598,
          7.644915580749512,
          7.31282377243042,
          9.034801483154297,
          11.828612327575684,
          13.927311897277832,
          10.295412063598633,
          3.0865063667297363,
          9.028549194335938,
          14.226036071777344,
          -1.154172658920288,
          0.792746901512146,
          10.192314147949219,
          4.3197736740112305,
          -2.2705702781677246,
          9.25869369506836,
          5.525547981262207,
          5.1880083084106445,
          4.632363319396973,
          11.36804485321045,
          5.153968334197998,
          9.935151100158691,
          7.604747772216797,
          -1.1049116849899292,
          10.041033744812012,
          -0.5525417327880859,
          -0.8905562162399292,
          7.467044830322266,
          -1.071213722229004,
          9.097430229187012,
          7.303019046783447,
          6.723641395568848,
          -2.8917088508605957,
          9.648412704467773,
          14.560683250427246,
          9.27017879486084,
          12.885028839111328,
          18.388090133666992,
          9.634479522705078,
          9.689821243286133,
          9.268268585205078,
          2.2506587505340576,
          10.317316055297852,
          -0.8672534227371216,
          9.513734817504883,
          7.969902038574219,
          3.560222625732422,
          11.05402660369873,
          16.27411651611328,
          10.808733940124512,
          12.211922645568848,
          3.221069812774658,
          0.5468541979789734,
          32.397159576416016,
          10.213537216186523,
          -3.9562861919403076,
          6.81910514831543,
          2.396547794342041,
          7.784933090209961,
          3.449827194213867,
          6.099804878234863,
          14.743900299072266,
          3.5996434688568115,
          14.467046737670898,
          10.172770500183105,
          2.298006534576416,
          2.6627280712127686,
          15.335838317871094,
          -1.605057954788208,
          4.06513786315918,
          9.406213760375977,
          5.884276390075684,
          -1.2416530847549438,
          -1.9559125900268555,
          11.478055000305176,
          4.90126371383667,
          5.429581642150879,
          29.807031631469727,
          11.197933197021484,
          5.235963821411133,
          5.322810173034668,
          4.766659736633301,
          16.415067672729492,
          8.315987586975098,
          6.920410633087158,
          4.4479594230651855,
          14.34152603149414,
          8.31134033203125,
          -2.4355459213256836,
          5.26177453994751,
          6.698274612426758,
          2.908310651779175,
          29.49444007873535,
          1.3380390405654907,
          3.908147096633911,
          -2.092897653579712,
          8.347478866577148,
          -3.933706521987915,
          -2.9581058025360107,
          10.848369598388672,
          5.376035690307617,
          -1.0845130681991577,
          -5.211432456970215,
          4.5282135009765625,
          13.105682373046875,
          19.585901260375977,
          6.074934005737305,
          15.227529525756836,
          5.523501873016357,
          -2.3920814990997314,
          17.60698127746582,
          14.451712608337402,
          9.954455375671387,
          10.368378639221191,
          7.609935760498047,
          13.292734146118164,
          14.429289817810059,
          -2.7235705852508545,
          10.67019271850586,
          6.758508205413818,
          8.136937141418457,
          9.629240036010742,
          5.476169586181641,
          15.402953147888184,
          9.570148468017578,
          15.190296173095703,
          5.943331718444824,
          10.048949241638184,
          6.901285648345947,
          -1.2332228422164917,
          5.486608028411865,
          0.7652790546417236,
          5.75131893157959,
          3.3791205883026123,
          13.925095558166504,
          13.159073829650879,
          10.652158737182617,
          -4.441427230834961,
          6.37576961517334,
          16.380958557128906,
          3.809642791748047,
          4.900717258453369,
          5.079669952392578,
          7.768815994262695,
          14.949223518371582,
          -4.065680980682373,
          1.3718420267105103,
          3.541954278945923,
          6.308430194854736,
          10.594146728515625,
          6.765730857849121,
          31.744972229003906,
          12.651545524597168,
          13.534721374511719,
          -3.59121036529541,
          10.43238353729248,
          15.819942474365234,
          4.126368045806885,
          5.791725158691406,
          -0.8072144389152527,
          8.410696983337402,
          5.986075401306152,
          7.949770450592041,
          14.805599212646484,
          13.092693328857422,
          10.415285110473633,
          5.568807601928711,
          2.0802388191223145,
          4.521221160888672,
          9.240998268127441,
          -2.410856246948242,
          9.023641586303711,
          8.092761993408203,
          -1.5917011499404907,
          14.685620307922363,
          -0.15672647953033447,
          -0.5641650557518005,
          5.596745491027832,
          9.268001556396484,
          8.65186882019043,
          -2.9678890705108643,
          8.944461822509766,
          3.4665017127990723,
          -2.1847355365753174,
          10.547417640686035,
          -0.967650294303894,
          3.0196797847747803,
          -0.597136914730072,
          3.1936428546905518,
          14.731156349182129,
          13.812685012817383,
          14.710137367248535,
          8.67024040222168,
          2.9805963039398193,
          3.182161331176758,
          4.4727396965026855,
          1.9118187427520752,
          -4.394049644470215,
          14.13023853302002,
          14.560504913330078,
          13.85288143157959,
          8.872786521911621,
          11.039450645446777,
          4.622185230255127,
          4.139596462249756,
          14.569823265075684,
          8.033258438110352,
          5.93859338760376,
          6.838191509246826,
          4.9676337242126465,
          8.709356307983398,
          5.864054203033447,
          15.584320068359375,
          -1.2200604677200317,
          14.831686973571777,
          -2.30411958694458,
          4.8362812995910645,
          -0.8109480738639832,
          8.67383098602295,
          9.250734329223633,
          6.966151714324951,
          9.86944580078125,
          4.0154523849487305,
          6.588966369628906,
          1.8642239570617676,
          -2.2915408611297607,
          12.706851959228516,
          7.306250095367432,
          4.9667887687683105,
          5.720702648162842,
          6.23994255065918,
          5.0557355880737305,
          -0.9056242108345032,
          9.620752334594727,
          5.920017242431641,
          5.671928405761719,
          13.71044635772705,
          2.3556416034698486,
          6.205946445465088,
          10.26193904876709,
          9.444754600524902,
          12.259980201721191,
          5.938435077667236,
          15.699048042297363,
          5.22973108291626,
          14.61705207824707,
          8.577400207519531,
          -0.7881229519844055,
          10.50668716430664,
          13.75696086883545,
          10.966880798339844,
          4.349396228790283,
          -3.4251108169555664,
          17.08450698852539,
          12.07817554473877,
          2.117433786392212,
          14.398626327514648,
          3.1630592346191406,
          2.8905491828918457,
          4.137815475463867,
          4.738452434539795,
          25.0676212310791,
          5.110198974609375,
          7.540959358215332,
          7.547100067138672,
          16.680633544921875,
          10.121859550476074,
          15.401055335998535,
          9.348928451538086,
          4.5522050857543945,
          10.145562171936035,
          5.046173572540283,
          -2.9751992225646973,
          21.76338005065918,
          5.305840969085693,
          7.190892696380615,
          9.5684814453125,
          12.326053619384766,
          3.6128299236297607,
          10.180948257446289,
          10.355557441711426,
          10.990398406982422,
          -4.501132965087891,
          8.66817569732666,
          9.79643726348877,
          -5.050253868103027,
          8.90827751159668,
          4.259758472442627,
          -1.1585655212402344,
          11.927861213684082,
          9.622919082641602,
          10.338233947753906,
          7.860171318054199,
          -4.258205890655518,
          2.2645554542541504,
          7.983892917633057,
          6.768245220184326,
          -2.3601999282836914,
          10.192644119262695,
          -3.6072945594787598,
          -1.7011778354644775,
          19.76845932006836,
          4.655216693878174,
          8.314453125,
          4.492719650268555,
          -2.406989336013794,
          11.528200149536133,
          -0.6209034323692322,
          10.659257888793945,
          15.070496559143066,
          1.3823000192642212,
          10.337091445922852,
          2.15250825881958,
          -1.0721726417541504,
          -1.2649168968200684,
          3.2714099884033203,
          15.666881561279297,
          -0.6206010580062866,
          15.773831367492676,
          21.735515594482422,
          7.447699069976807,
          10.624044418334961,
          7.603423118591309,
          7.547260284423828,
          16.079967498779297,
          5.853717803955078,
          15.089975357055664,
          10.904584884643555,
          21.46438980102539,
          13.519766807556152,
          5.339502811431885,
          11.581560134887695,
          12.591537475585938,
          -3.4645729064941406,
          5.656142234802246,
          20.243131637573242,
          9.282615661621094,
          14.734393119812012,
          8.999756813049316,
          -0.03843212127685547,
          5.5026116371154785,
          6.284721374511719,
          15.107256889343262,
          29.972347259521484,
          7.668495178222656,
          -0.8224818110466003,
          5.8061113357543945,
          9.684518814086914,
          7.071673393249512,
          6.587924003601074,
          3.5601775646209717,
          5.626086235046387,
          12.489618301391602,
          5.656094551086426,
          8.938088417053223,
          16.49776268005371,
          4.895593166351318,
          6.960526943206787,
          3.983783006668091,
          8.732294082641602,
          11.09826946258545,
          1.241755485534668,
          20.1558895111084,
          15.424924850463867,
          -1.6584290266036987,
          8.156327247619629,
          -4.640685558319092,
          -2.835540533065796,
          4.196916103363037,
          4.893558979034424,
          14.591005325317383,
          15.296913146972656,
          9.305604934692383,
          -0.848127543926239,
          -2.0782060623168945,
          11.662642478942871,
          17.604402542114258,
          -2.804003953933716,
          8.896106719970703,
          6.146132469177246,
          10.694671630859375,
          12.607860565185547,
          5.221158981323242,
          -2.4248132705688477,
          14.09682846069336,
          5.680761337280273,
          7.959798336029053,
          14.276359558105469,
          9.321935653686523,
          -1.024481177330017,
          7.896381855010986,
          7.578955173492432,
          7.526549339294434,
          4.42609977722168,
          2.7995970249176025,
          5.843776702880859,
          -3.2113943099975586,
          5.173770904541016,
          -1.051935076713562,
          2.5879151821136475,
          -1.463683009147644,
          14.413188934326172,
          8.884355545043945,
          6.485893249511719,
          23.051828384399414,
          12.073378562927246,
          10.937122344970703,
          6.9808220863342285,
          -4.368269443511963,
          5.890398979187012,
          18.985332489013672,
          10.951818466186523,
          5.392754077911377,
          -2.2666306495666504,
          2.5958311557769775,
          20.30604362487793,
          10.267679214477539,
          7.226306915283203,
          7.640926361083984,
          16.324085235595703,
          16.35581398010254,
          2.920706033706665,
          5.232666015625,
          9.727152824401855,
          14.724800109863281,
          8.781129837036133,
          6.0526580810546875,
          8.03912353515625,
          17.616880416870117,
          0.7732401490211487,
          17.834232330322266,
          30.553897857666016,
          5.0407938957214355,
          14.445392608642578,
          -1.4109818935394287,
          8.092331886291504,
          -2.009092330932617,
          -4.3161516189575195,
          10.681891441345215,
          0.5832059979438782,
          10.302593231201172,
          5.1886210441589355,
          6.601977348327637,
          9.910593032836914,
          1.2395999431610107,
          10.149104118347168,
          7.9584197998046875,
          15.109179496765137,
          9.124342918395996,
          5.911545276641846,
          10.903096199035645,
          11.018685340881348,
          -1.0447756052017212,
          4.685796737670898,
          10.560530662536621,
          9.081537246704102,
          9.619546890258789,
          9.916891098022461,
          10.082464218139648,
          14.08337688446045,
          4.5706634521484375,
          -0.24506716430187225,
          3.2285542488098145,
          11.76418399810791,
          8.673263549804688,
          6.719225883483887,
          6.5015482902526855,
          10.685394287109375,
          3.1910173892974854,
          -3.7521002292633057,
          9.16246223449707,
          6.787114143371582,
          19.009992599487305,
          9.252052307128906,
          12.176936149597168,
          6.4771342277526855,
          -2.6698007583618164,
          2.347642660140991,
          11.12503719329834,
          9.770678520202637,
          14.959273338317871,
          14.390130996704102,
          13.80323600769043,
          3.577765941619873,
          30.929492950439453,
          4.864286422729492,
          9.546268463134766,
          11.893417358398438,
          14.987427711486816,
          0.006026868242770433,
          6.9991302490234375,
          8.525433540344238,
          12.627822875976562,
          12.757963180541992,
          17.44341468811035,
          17.116912841796875,
          14.904511451721191,
          12.307875633239746,
          14.623892784118652,
          15.760761260986328,
          8.304266929626465,
          4.617492198944092,
          21.08785057067871,
          15.517855644226074,
          4.603346824645996,
          10.423773765563965,
          2.2465670108795166,
          14.203197479248047,
          8.115352630615234,
          31.061538696289062,
          12.59794807434082,
          -2.477811098098755,
          11.737035751342773,
          5.8471760749816895,
          2.5156614780426025,
          -1.3678570985794067,
          21.23793601989746,
          9.012354850769043,
          9.828332901000977,
          5.99059534072876,
          7.3541951179504395,
          -1.285003900527954,
          -1.6477755308151245,
          6.291728496551514,
          7.69423770904541,
          16.822738647460938,
          10.652033805847168,
          14.533493041992188,
          15.920480728149414,
          7.131368160247803,
          -3.654053211212158,
          0.6491982340812683,
          -0.9873794913291931,
          20.252025604248047,
          13.876971244812012,
          5.6150126457214355,
          10.737287521362305,
          8.99284839630127,
          9.363351821899414,
          10.324081420898438,
          13.52244758605957,
          5.962462902069092,
          6.997894287109375,
          -1.7707979679107666,
          4.708375453948975,
          12.979991912841797,
          14.596084594726562,
          15.87734603881836,
          6.338601589202881,
          8.554594039916992,
          13.763004302978516,
          10.371813774108887,
          18.626720428466797,
          6.767083644866943,
          5.198225975036621,
          1.077736258506775,
          13.881054878234863,
          -1.7774899005889893,
          14.125794410705566,
          14.06580638885498,
          14.72403335571289,
          -1.6196844577789307,
          6.458926200866699,
          -3.888155460357666,
          10.192142486572266,
          4.195529937744141,
          -1.7802777290344238,
          1.9925857782363892,
          6.948264122009277,
          5.159496784210205,
          15.215460777282715,
          30.899776458740234,
          -0.2820408344268799,
          20.825912475585938,
          -1.1570886373519897,
          10.269686698913574,
          10.755538940429688,
          9.36292839050293,
          6.435414791107178,
          5.533087730407715,
          15.61901569366455,
          31.894241333007812,
          15.24355697631836,
          5.410305976867676,
          16.988162994384766,
          -4.215479850769043,
          7.4686174392700195,
          16.9410400390625,
          4.336075782775879,
          9.261567115783691,
          14.3720121383667,
          3.535055160522461,
          12.857535362243652,
          6.320676326751709,
          4.168396949768066,
          10.383825302124023,
          9.798270225524902,
          8.705703735351562,
          6.399684429168701,
          11.351672172546387,
          22.016586303710938,
          6.755484104156494,
          16.041975021362305,
          4.125995635986328,
          5.635857582092285,
          16.893938064575195,
          3.9791715145111084,
          5.447801113128662,
          3.207535982131958,
          12.162620544433594,
          9.580031394958496,
          -0.60201495885849,
          16.837881088256836,
          13.182551383972168,
          14.94217300415039,
          14.582308769226074,
          7.665270805358887,
          8.885445594787598,
          6.403367519378662,
          12.499666213989258,
          -4.618819713592529,
          -3.8505656719207764,
          5.545065879821777,
          9.7017240524292,
          7.605257034301758,
          11.002854347229004,
          7.261524200439453,
          9.931195259094238,
          5.472750663757324,
          6.211961269378662,
          6.072692394256592,
          -0.16375714540481567,
          14.440635681152344,
          6.347507953643799,
          15.773446083068848,
          10.936671257019043,
          7.789439678192139,
          7.926898002624512,
          8.087715148925781,
          13.506706237792969,
          9.704442977905273,
          -0.1717713177204132,
          10.227910041809082,
          14.648255348205566,
          10.197524070739746,
          4.819270133972168,
          8.809704780578613,
          2.6052770614624023,
          9.365409851074219,
          10.579475402832031,
          8.4234619140625,
          15.289717674255371,
          5.731274604797363,
          -0.7204463481903076,
          20.47390365600586,
          4.733830451965332,
          13.159711837768555,
          9.892273902893066,
          7.529664993286133,
          5.529506206512451,
          12.26149845123291,
          3.68951416015625,
          6.8552470207214355,
          3.3384335041046143,
          6.358644485473633,
          9.546279907226562,
          -5.105184555053711,
          16.417539596557617,
          8.44031047821045,
          1.6657836437225342,
          10.92322826385498,
          12.07036304473877,
          9.283343315124512,
          2.051612138748169,
          15.585450172424316,
          17.962976455688477,
          8.836559295654297,
          14.188340187072754,
          6.8095831871032715,
          9.503280639648438,
          -0.4580366909503937,
          14.801695823669434,
          11.434328079223633,
          8.916437149047852,
          16.029218673706055,
          8.490473747253418,
          3.879617691040039,
          9.445176124572754,
          9.532760620117188,
          14.713282585144043,
          5.55802583694458,
          5.526209831237793,
          9.877886772155762,
          -3.437276601791382,
          22.029170989990234,
          1.840517520904541,
          23.07759666442871,
          23.18943214416504,
          4.964663505554199,
          2.1097891330718994,
          17.027328491210938,
          13.300081253051758,
          14.321022033691406,
          -3.040654420852661,
          9.97231388092041,
          6.098870754241943,
          9.03424072265625,
          6.25937032699585,
          -0.234506294131279,
          9.35116958618164,
          8.127340316772461,
          15.791125297546387,
          7.979698181152344,
          9.486032485961914,
          5.4086198806762695,
          5.928439617156982,
          4.232578754425049,
          10.418498992919922,
          3.1419899463653564,
          14.835155487060547,
          8.743066787719727,
          13.220878601074219,
          4.559865474700928,
          -4.757358074188232,
          15.094630241394043,
          4.981107234954834,
          4.171247959136963,
          15.078771591186523,
          -1.5581947565078735,
          5.544297695159912,
          14.668346405029297,
          9.434527397155762,
          15.339726448059082,
          3.641413450241089,
          4.5550971031188965,
          6.318709850311279,
          1.864046573638916,
          17.919029235839844,
          -0.6538214087486267,
          -3.849669933319092,
          2.2887306213378906,
          23.900060653686523,
          -1.4126546382904053,
          6.448967933654785,
          4.438506126403809,
          3.5778353214263916,
          17.280155181884766,
          5.64785623550415,
          9.729521751403809,
          -1.976585030555725,
          16.446250915527344,
          11.40971565246582,
          3.5206592082977295,
          5.887420177459717,
          3.114220142364502,
          3.853034496307373,
          5.470633029937744,
          7.925840377807617,
          8.786530494689941,
          10.291033744812012,
          13.434626579284668,
          12.489303588867188,
          11.693337440490723,
          15.496106147766113,
          13.817560195922852,
          -1.5720717906951904,
          6.987701892852783,
          7.324088096618652,
          15.478094100952148,
          5.87994384765625,
          5.53413200378418,
          7.039211273193359,
          6.203047752380371,
          12.509081840515137,
          6.750546455383301,
          5.349732398986816,
          7.752354621887207,
          5.962273597717285,
          3.5488717555999756,
          5.3602213859558105,
          7.842550754547119,
          15.00337028503418,
          -1.2819819450378418,
          8.781577110290527,
          8.971076965332031,
          31.713027954101562,
          11.086381912231445,
          -2.3819901943206787,
          4.965717792510986,
          10.147522926330566,
          6.129459381103516,
          6.079638481140137,
          21.696420669555664,
          14.370893478393555,
          -4.003570556640625,
          14.412415504455566,
          -1.3306368589401245,
          12.34274673461914,
          -0.09550309181213379,
          3.8775928020477295,
          10.163686752319336,
          2.3906993865966797,
          4.022775173187256,
          0.7449581623077393,
          16.08558464050293,
          3.757869005203247,
          5.549006462097168,
          5.546380519866943,
          6.585447311401367,
          10.246976852416992,
          9.116198539733887,
          5.416449546813965,
          12.579954147338867,
          14.479263305664062,
          9.922662734985352,
          9.396340370178223,
          -3.2080881595611572,
          -0.7130460739135742,
          -2.8107621669769287,
          14.173553466796875,
          10.527324676513672,
          5.493494033813477,
          8.04000186920166,
          4.869380950927734,
          -0.8617914319038391,
          7.749521255493164,
          3.582930326461792,
          6.829599857330322,
          14.240403175354004,
          17.369304656982422,
          3.430290937423706,
          2.3334622383117676,
          9.784682273864746,
          14.21321964263916,
          10.311381340026855,
          -1.7122671604156494,
          7.959321975708008,
          14.63415813446045,
          9.162871360778809,
          3.602250337600708,
          10.578367233276367,
          14.667500495910645,
          10.49746322631836,
          10.326177597045898,
          13.697683334350586,
          9.799285888671875,
          5.147750377655029,
          6.246872425079346,
          13.935531616210938,
          21.290573120117188,
          5.338279724121094,
          14.381107330322266,
          10.430676460266113,
          9.761706352233887,
          4.7811079025268555,
          13.26772403717041,
          2.651819944381714,
          13.402467727661133,
          5.650549411773682,
          13.326362609863281,
          10.313496589660645,
          7.709081172943115,
          7.545042991638184,
          10.482925415039062,
          4.016689777374268,
          -0.4442884027957916,
          -2.175959587097168,
          4.131730556488037,
          0.46268871426582336,
          7.469341278076172,
          1.7959446907043457,
          10.348004341125488,
          15.461108207702637,
          6.332949638366699,
          5.108413219451904,
          6.68015193939209,
          15.838468551635742,
          14.054728507995605,
          5.8893561363220215,
          13.2091646194458,
          15.432083129882812,
          12.802594184875488,
          4.459641933441162,
          15.743865013122559,
          15.447968482971191,
          7.409459114074707,
          8.204062461853027,
          13.959990501403809,
          8.441787719726562,
          9.979769706726074,
          5.365921974182129,
          4.647134304046631,
          3.9380998611450195,
          -3.4077346324920654,
          8.463294982910156,
          12.922643661499023,
          15.670777320861816,
          13.291556358337402,
          7.178610801696777,
          3.9313528537750244,
          4.981767177581787,
          -0.9059227108955383,
          15.412403106689453,
          8.140982627868652,
          -3.016585111618042,
          6.921610355377197,
          6.136865139007568,
          17.0095157623291,
          10.275381088256836,
          30.64618492126465,
          2.813194751739502,
          3.89524507522583,
          13.883196830749512,
          13.60165786743164,
          5.332529067993164,
          -0.16760818660259247,
          14.032853126525879,
          -1.9565714597702026,
          -0.25166770815849304,
          12.954325675964355,
          0.11544271558523178,
          -3.0674936771392822,
          14.908663749694824,
          -0.36376696825027466,
          13.568477630615234,
          6.303272247314453,
          10.292948722839355,
          24.211017608642578,
          1.8986001014709473,
          10.342631340026855,
          16.753257751464844,
          10.752969741821289,
          -0.3022121787071228,
          1.7302626371383667,
          7.382047176361084,
          3.9226582050323486,
          3.463711738586426,
          10.671186447143555,
          8.380752563476562,
          7.780655384063721,
          1.6529847383499146,
          11.333081245422363,
          12.254912376403809,
          3.426969289779663,
          10.865200996398926,
          16.118886947631836,
          6.270297527313232,
          6.560305118560791,
          8.6137113571167,
          5.793666839599609,
          0.1314469575881958,
          7.67092752456665,
          4.345062255859375,
          30.582534790039062,
          6.67238712310791,
          16.824907302856445,
          2.84208345413208,
          3.300724506378174,
          -2.3179469108581543,
          8.340338706970215,
          11.10873794555664,
          10.884941101074219,
          17.425859451293945,
          12.350334167480469,
          9.27204704284668,
          14.986737251281738,
          0.052706748247146606,
          -1.6485406160354614,
          -1.014514446258545,
          -1.6930017471313477,
          2.397294044494629,
          7.790370941162109,
          9.604650497436523,
          12.045098304748535,
          12.42147445678711,
          13.8349609375,
          4.372005939483643,
          6.758205890655518,
          9.455711364746094,
          10.701752662658691,
          6.715385913848877,
          5.399704933166504,
          15.365344047546387,
          -2.606962203979492,
          5.52889347076416,
          7.908519744873047,
          3.7047536373138428,
          -4.346850395202637,
          16.86881446838379,
          3.0852062702178955,
          -3.1989259719848633,
          7.104519367218018,
          10.166422843933105,
          15.446073532104492,
          6.591392993927002,
          5.874336242675781,
          7.045558929443359,
          16.519189834594727,
          8.109319686889648,
          16.172945022583008,
          11.894584655761719,
          16.506385803222656,
          0.9069950580596924,
          12.896398544311523,
          3.166594982147217,
          -3.4777345657348633,
          7.523480415344238,
          -1.9743746519088745,
          3.9568700790405273,
          -2.6923906803131104,
          10.644556999206543,
          5.529138565063477,
          16.861841201782227,
          11.131139755249023,
          -3.358262062072754,
          6.639126300811768,
          5.705672740936279,
          12.213873863220215,
          7.30340051651001,
          19.603490829467773,
          3.454184055328369,
          -2.1823086738586426,
          -3.902940511703491,
          -1.3431447744369507,
          0.7483174204826355,
          9.685685157775879,
          10.722732543945312,
          3.533623218536377,
          5.983223915100098,
          -1.8606449365615845,
          6.013963222503662,
          21.960063934326172,
          15.122026443481445,
          7.727001190185547,
          3.0547518730163574,
          8.657888412475586,
          12.590483665466309,
          11.335689544677734,
          16.114194869995117,
          8.03889274597168,
          12.402273178100586,
          2.6866753101348877,
          5.950875759124756,
          24.174219131469727,
          16.1634578704834,
          18.2835636138916,
          8.252267837524414,
          14.653424263000488,
          -0.4412091374397278,
          7.760929584503174,
          16.190196990966797,
          5.28441047668457,
          0.5516844987869263,
          10.026634216308594,
          6.192536354064941,
          9.779848098754883,
          5.454680442810059,
          6.808882236480713,
          3.1236257553100586,
          16.304588317871094,
          2.2721269130706787,
          8.967188835144043,
          14.152597427368164,
          7.478974342346191,
          7.904541492462158,
          2.5488250255584717,
          10.255437850952148,
          7.531139850616455,
          10.381197929382324,
          3.3894922733306885,
          8.240824699401855,
          20.289663314819336,
          7.998329162597656,
          8.347283363342285,
          6.9272942543029785,
          10.552258491516113,
          14.696338653564453,
          1.3585827350616455,
          8.0570068359375,
          24.4447078704834,
          16.32709312438965,
          17.777999877929688,
          24.70442771911621,
          8.83362102508545,
          14.241737365722656,
          21.79086685180664,
          10.661069869995117,
          -2.807647466659546,
          5.475766658782959,
          15.266446113586426,
          5.690805435180664,
          -1.9792873859405518,
          11.246755599975586,
          16.113773345947266,
          4.026843547821045,
          7.632134914398193,
          8.899950981140137,
          14.159261703491211,
          4.481553554534912,
          10.407933235168457,
          21.890050888061523,
          8.605984687805176,
          16.0225887298584,
          10.014901161193848,
          -0.22747240960597992,
          5.5916428565979,
          12.587028503417969,
          6.035184860229492,
          1.6891001462936401,
          15.849940299987793,
          13.401576042175293,
          16.974912643432617,
          5.994102954864502,
          -0.5932109355926514,
          -4.977242469787598,
          4.070840835571289,
          5.482875347137451,
          7.70626163482666,
          14.369924545288086,
          14.72485637664795,
          7.362228870391846,
          -2.002562999725342,
          -2.039680004119873,
          13.346518516540527,
          -0.501261293888092,
          15.121082305908203,
          16.11166763305664,
          30.899080276489258,
          8.893270492553711,
          -4.879443645477295,
          9.45118236541748,
          5.8429975509643555,
          3.027535915374756,
          2.356954574584961,
          3.8707833290100098,
          12.892012596130371,
          3.37795090675354,
          5.240411758422852,
          11.049667358398438,
          5.441891670227051,
          16.65006446838379,
          0.43798476457595825,
          6.935516357421875,
          10.575018882751465,
          9.769835472106934,
          23.660377502441406,
          6.54203462600708,
          3.2698404788970947,
          9.673035621643066,
          0.25380799174308777,
          -0.7340164184570312,
          7.939759254455566,
          22.113107681274414,
          14.021254539489746,
          -1.2314625978469849,
          7.104291915893555,
          2.341893434524536,
          10.153457641601562,
          3.9575858116149902,
          6.012841701507568,
          7.550690650939941,
          30.303483963012695,
          11.073915481567383,
          11.768516540527344,
          -1.5496145486831665,
          5.212242126464844,
          -3.871553897857666,
          17.349340438842773,
          1.9742547273635864,
          -1.5157254934310913,
          -1.2523857355117798,
          6.067640781402588,
          10.23453426361084,
          5.100801944732666,
          8.616053581237793,
          9.797383308410645,
          -0.7172805666923523,
          6.33867883682251,
          15.70022964477539,
          3.511463165283203,
          8.472922325134277,
          5.925278186798096,
          10.846040725708008,
          15.806209564208984,
          7.545350074768066,
          8.579625129699707,
          0.3192062973976135,
          4.5267252922058105,
          -2.2440059185028076,
          -3.720367908477783,
          -1.1983671188354492,
          15.392394065856934,
          16.106529235839844,
          -3.9511337280273438,
          5.727230072021484,
          5.8660688400268555,
          9.255412101745605,
          4.457098960876465,
          10.820500373840332,
          7.294715404510498,
          14.928369522094727,
          15.794050216674805,
          6.142768383026123,
          15.290669441223145,
          8.859638214111328,
          10.155485153198242,
          2.839380979537964,
          -0.9430215358734131,
          13.540872573852539,
          -0.5911639928817749,
          3.1683602333068848,
          5.934106826782227,
          15.419612884521484,
          4.019034385681152,
          9.133095741271973,
          5.228785991668701,
          11.860125541687012,
          17.833139419555664,
          11.617342948913574,
          5.554988384246826,
          2.673461675643921,
          8.531076431274414,
          9.2611722946167,
          -2.215007781982422,
          2.9557013511657715,
          -3.966728925704956,
          -2.1874773502349854,
          2.5487306118011475,
          2.413986921310425,
          -0.572942852973938,
          15.548638343811035,
          0.38071995973587036,
          7.385915756225586,
          12.758484840393066,
          -3.5381851196289062,
          14.908120155334473,
          15.273265838623047,
          9.471695899963379,
          14.770461082458496,
          3.8265411853790283,
          12.414143562316895,
          8.382006645202637,
          -0.5133323073387146,
          4.855861663818359,
          15.714910507202148,
          9.375005722045898,
          13.374496459960938,
          3.0018868446350098,
          15.181783676147461,
          -2.649312734603882,
          3.196197986602783,
          5.983449935913086,
          6.984504699707031,
          4.634011268615723,
          -1.4716843366622925,
          7.2722859382629395,
          19.767736434936523,
          7.646369457244873,
          9.053175926208496,
          6.282536029815674,
          3.155914545059204,
          6.269354820251465,
          4.7437567710876465,
          0.6278661489486694,
          9.560381889343262,
          8.267964363098145,
          0.4305787682533264,
          6.528480529785156,
          15.75300121307373,
          14.551098823547363,
          15.11542797088623,
          -2.577155828475952,
          15.738694190979004,
          7.0450119972229,
          13.042274475097656,
          -2.298326015472412,
          8.363324165344238,
          8.091693878173828,
          3.9219346046447754,
          3.36161732673645,
          6.482936382293701,
          2.446432113647461,
          4.690476894378662,
          4.14154052734375,
          14.211922645568848,
          4.054015636444092,
          0.319985032081604,
          1.6993167400360107,
          7.69283390045166,
          6.126918792724609,
          16.081003189086914,
          9.791924476623535,
          5.193322658538818,
          5.097914218902588,
          21.14838218688965,
          15.757709503173828,
          -4.886580944061279,
          4.06955099105835,
          10.580031394958496,
          6.669850826263428,
          10.383262634277344,
          4.386204719543457,
          -3.0610485076904297,
          9.13766860961914,
          5.588662147521973,
          12.280923843383789,
          -2.604816436767578,
          -3.214301824569702,
          16.39051055908203,
          15.246955871582031,
          16.010801315307617,
          20.956579208374023,
          15.60517692565918,
          14.487054824829102,
          1.1558120250701904,
          8.13002872467041,
          14.612444877624512,
          10.305763244628906,
          31.336301803588867,
          8.441627502441406,
          20.43042755126953,
          29.656620025634766,
          10.803494453430176,
          3.4091732501983643,
          15.6826171875,
          24.225208282470703,
          4.346067905426025,
          12.361686706542969,
          6.369575023651123,
          8.854819297790527,
          10.171706199645996,
          -0.752036452293396,
          9.718143463134766,
          2.559040069580078,
          5.486771106719971,
          15.924789428710938,
          15.283756256103516,
          6.111952781677246,
          -2.1098744869232178,
          17.6163387298584,
          5.614045143127441,
          20.352224349975586,
          14.347885131835938,
          30.038259506225586,
          -3.8120980262756348,
          5.611405849456787,
          6.495670795440674,
          6.2281036376953125,
          13.905505180358887,
          6.313732147216797,
          12.47167682647705,
          7.287408351898193,
          9.526873588562012,
          7.390023708343506,
          20.056270599365234,
          14.920816421508789,
          15.269156455993652,
          7.520022392272949,
          16.02608299255371,
          15.694993019104004,
          19.82602310180664,
          16.262866973876953,
          16.99051284790039,
          3.2418811321258545,
          1.4162248373031616,
          6.345893383026123,
          9.536735534667969,
          9.057372093200684,
          3.6130001544952393,
          15.668100357055664,
          8.968835830688477,
          10.27426528930664,
          10.090482711791992,
          16.17234992980957,
          13.484118461608887,
          16.64585304260254,
          -0.011764816008508205,
          14.159818649291992,
          17.740489959716797,
          6.433501243591309,
          10.34268569946289,
          9.542686462402344,
          15.206354141235352,
          -1.17438805103302,
          7.693182945251465,
          20.187259674072266,
          9.609156608581543,
          14.561211585998535,
          24.60260772705078,
          13.697319984436035,
          2.8357763290405273,
          11.575263977050781,
          -3.4257266521453857,
          3.7907376289367676,
          5.839991569519043,
          -1.8404901027679443,
          5.7935919761657715,
          11.236087799072266,
          6.158980846405029,
          6.29434061050415,
          4.453516483306885,
          2.4721522331237793,
          3.618821144104004,
          5.5202813148498535,
          7.597151756286621,
          5.51705265045166,
          2.8130266666412354,
          9.437911033630371,
          6.825131416320801,
          6.473729133605957,
          9.233942985534668,
          5.140151023864746,
          7.531794548034668,
          5.39591646194458,
          9.116897583007812,
          6.728850364685059,
          -1.3702592849731445,
          -1.2771129608154297,
          -4.231285095214844,
          9.178174018859863,
          -1.4646031856536865,
          7.751217842102051,
          5.915364742279053,
          10.686702728271484,
          5.636287212371826,
          5.425405979156494,
          12.623501777648926,
          13.036789894104004,
          1.2113416194915771,
          12.420804023742676,
          2.9583117961883545,
          6.772970199584961,
          14.07458209991455,
          13.478907585144043,
          2.4740467071533203,
          14.943879127502441,
          4.659524440765381,
          7.886772155761719,
          10.094718933105469,
          4.5263752937316895,
          5.2624945640563965,
          15.900235176086426,
          12.295639991760254,
          -0.4759295582771301,
          4.497258186340332,
          7.110163688659668,
          4.760278701782227,
          3.9159364700317383,
          -3.266265392303467,
          4.424311637878418,
          17.341964721679688,
          21.909379959106445,
          -1.8378535509109497,
          7.234633922576904,
          6.913219928741455,
          15.643986701965332,
          30.34386444091797,
          -1.768619418144226,
          11.03274154663086,
          14.175614356994629,
          0.11657354980707169,
          3.2469961643218994,
          3.380857229232788,
          6.857799053192139,
          -3.0958750247955322,
          9.03359603881836,
          10.578405380249023,
          4.576152324676514,
          4.126607894897461,
          9.049644470214844,
          9.716951370239258,
          6.617191791534424,
          9.497679710388184,
          -1.9686551094055176,
          6.492424011230469,
          8.100107192993164,
          -5.22703218460083,
          7.944356441497803,
          10.835993766784668,
          -1.2868926525115967,
          8.793468475341797,
          7.204627513885498,
          8.329768180847168,
          6.507226943969727,
          9.97510814666748,
          23.156749725341797,
          9.67779541015625,
          8.366312980651855,
          9.981331825256348,
          7.193383693695068,
          4.570688724517822,
          15.585223197937012,
          -4.088999271392822,
          17.892621994018555,
          17.256563186645508,
          5.907687664031982,
          5.22281551361084,
          15.582192420959473,
          20.457828521728516,
          5.339810371398926,
          31.345361709594727,
          14.372757911682129,
          3.7540676593780518,
          1.146966576576233,
          3.6706326007843018,
          10.441555976867676,
          15.34731674194336,
          5.999413967132568,
          1.180485725402832,
          6.589346885681152,
          -1.0373477935791016,
          9.194969177246094,
          13.378886222839355,
          15.358025550842285,
          -1.0950127840042114,
          4.306581974029541,
          9.811691284179688,
          7.448078632354736,
          6.3295578956604,
          15.247817039489746,
          30.4438533782959,
          -1.0594052076339722,
          15.361124992370605,
          -4.840096950531006,
          -0.38175657391548157,
          15.326581954956055,
          13.675783157348633,
          1.1938605308532715,
          6.281639575958252,
          15.768064498901367,
          4.5412468910217285,
          14.96168041229248,
          -3.286963939666748,
          -1.2193270921707153,
          6.368879795074463,
          29.91949462890625,
          8.230978012084961,
          10.565181732177734,
          -3.8587727546691895,
          11.414752006530762,
          5.714488506317139,
          5.485848903656006,
          5.54162073135376,
          -3.899120569229126,
          4.919203758239746,
          5.114600658416748,
          8.913227081298828,
          11.987645149230957,
          5.241713047027588,
          -2.543856620788574,
          14.12376594543457,
          -2.883723258972168,
          0.02594529651105404,
          22.125364303588867,
          -0.02622641995549202,
          17.067018508911133,
          10.822874069213867,
          8.029947280883789,
          -3.177910566329956,
          10.006142616271973,
          14.356527328491211,
          8.174142837524414,
          14.144407272338867,
          10.320658683776855,
          6.072737693786621,
          13.04606819152832,
          2.5345726013183594,
          6.042454719543457,
          4.413275241851807,
          4.81200647354126,
          14.474955558776855,
          8.537063598632812,
          13.493117332458496,
          15.949278831481934,
          10.375236511230469,
          5.941681385040283,
          6.850491523742676,
          -3.422349691390991,
          9.563002586364746,
          14.177668571472168,
          7.735841751098633,
          14.62557315826416,
          4.21950626373291,
          10.257173538208008,
          3.0781280994415283,
          8.992972373962402,
          8.42605209350586,
          14.816720008850098,
          9.954842567443848,
          0.6681254506111145,
          9.242650032043457,
          7.204506874084473,
          12.103422164916992,
          5.480014801025391,
          9.098596572875977,
          5.810632228851318,
          14.412862777709961,
          9.465439796447754,
          5.90704345703125,
          14.223433494567871,
          9.718896865844727,
          6.169312477111816,
          24.520917892456055,
          16.47699737548828,
          4.088268280029297,
          8.08103084564209,
          30.258056640625,
          2.2545058727264404,
          7.32468318939209,
          5.737854480743408,
          11.77713680267334,
          23.82662010192871,
          5.851008892059326,
          9.067465782165527,
          9.574532508850098,
          12.562307357788086,
          10.029425621032715,
          5.667824745178223,
          6.5226359367370605,
          31.272911071777344,
          6.112063407897949,
          9.444097518920898,
          7.3017191886901855,
          5.466996669769287,
          5.959094047546387,
          11.98128604888916,
          9.78885555267334,
          -0.9147563576698303,
          4.026026248931885,
          -1.1075974702835083,
          6.473783016204834,
          7.977245330810547,
          9.419548034667969,
          8.614778518676758,
          2.2123494148254395,
          14.221000671386719,
          -0.7524023056030273,
          5.040459156036377,
          10.643580436706543,
          2.1480937004089355,
          9.831144332885742,
          -2.006282091140747,
          7.105239391326904,
          8.147462844848633,
          2.5803890228271484,
          4.883159637451172,
          6.850945472717285,
          11.911999702453613,
          6.304821968078613,
          9.980466842651367,
          14.651443481445312,
          9.921442985534668,
          14.553533554077148,
          3.5372772216796875,
          5.761327266693115,
          14.998791694641113,
          6.276838302612305,
          5.848100185394287,
          9.788399696350098,
          6.5588788986206055,
          -0.9597964882850647,
          11.125731468200684,
          5.538743019104004,
          16.64979362487793,
          8.708280563354492,
          5.960022926330566,
          12.239706993103027,
          21.698396682739258,
          7.1946892738342285,
          3.405143976211548,
          11.967159271240234,
          -1.3944419622421265,
          4.471757411956787,
          11.092052459716797,
          9.540116310119629,
          -0.8876268863677979,
          15.850181579589844,
          17.771268844604492,
          10.402525901794434,
          29.841798782348633,
          5.527982711791992,
          4.543675422668457,
          15.941944122314453,
          7.278738498687744,
          17.15713119506836,
          10.07798957824707,
          9.684803009033203,
          10.151352882385254,
          10.522992134094238,
          9.480671882629395,
          7.180079460144043,
          10.848175048828125,
          10.630507469177246,
          8.067903518676758
         ],
         "y": [
          6.14813756942749,
          5.301786422729492,
          4.429060459136963,
          4.913839340209961,
          4.387616157531738,
          3.79673171043396,
          6.307894706726074,
          -1.4702025651931763,
          -0.4047945737838745,
          6.1635918617248535,
          13.76734733581543,
          0.9303878545761108,
          6.212696552276611,
          8.709794044494629,
          4.635494709014893,
          0.21791234612464905,
          3.186023712158203,
          -0.6378796696662903,
          -6.1833882331848145,
          -0.12301572412252426,
          15.7596435546875,
          15.9695463180542,
          -4.1901936531066895,
          17.1979923248291,
          8.272355079650879,
          7.135176658630371,
          3.8977210521698,
          -3.075420618057251,
          6.961543560028076,
          20.91317367553711,
          7.953710556030273,
          -2.413121461868286,
          -0.44851478934288025,
          13.79478931427002,
          -0.43487703800201416,
          4.684791564941406,
          -6.0060553550720215,
          -8.708354949951172,
          13.47252082824707,
          2.548717737197876,
          -0.33265066146850586,
          -1.6400035619735718,
          1.6807210445404053,
          -0.1499963402748108,
          0.25511226058006287,
          1.9031693935394287,
          4.480918884277344,
          5.892838478088379,
          4.488662242889404,
          4.475327014923096,
          -2.7549731731414795,
          -1.287980318069458,
          16.880985260009766,
          13.563403129577637,
          7.802254676818848,
          2.2833192348480225,
          -0.6648275256156921,
          3.702251434326172,
          -1.3587932586669922,
          -2.29352068901062,
          -4.815088748931885,
          8.031800270080566,
          -5.2767252922058105,
          -7.989709377288818,
          7.228559494018555,
          8.290979385375977,
          7.460687637329102,
          0.52885502576828,
          5.92613410949707,
          1.9557595252990723,
          -3.252034902572632,
          4.900868892669678,
          2.00260329246521,
          15.288713455200195,
          0.49553200602531433,
          -4.946910858154297,
          4.527639389038086,
          -0.14849282801151276,
          14.637541770935059,
          -8.471235275268555,
          2.073904037475586,
          -3.5712618827819824,
          7.214406967163086,
          -0.3560853898525238,
          8.288413047790527,
          6.240735054016113,
          4.095879554748535,
          4.485720157623291,
          -1.003391146659851,
          8.039962768554688,
          4.025506496429443,
          9.332666397094727,
          12.182759284973145,
          -1.5838351249694824,
          4.2344794273376465,
          6.145914077758789,
          2.4802145957946777,
          5.540050983428955,
          6.872585296630859,
          7.977926254272461,
          -6.279621124267578,
          -2.9192090034484863,
          14.087689399719238,
          1.353789210319519,
          13.083390235900879,
          7.808326721191406,
          7.908924579620361,
          8.248115539550781,
          5.317257881164551,
          1.728248953819275,
          6.175978183746338,
          -2.491112470626831,
          -4.249331474304199,
          8.135912895202637,
          7.590554714202881,
          6.131641864776611,
          5.979249000549316,
          1.7012912034988403,
          12.553275108337402,
          16.135522842407227,
          6.307007789611816,
          5.136382102966309,
          7.716822147369385,
          -6.168945789337158,
          6.358876705169678,
          7.210792064666748,
          5.097386360168457,
          4.158943176269531,
          -7.301263332366943,
          6.991236686706543,
          3.179844856262207,
          -3.0447230339050293,
          1.430448055267334,
          3.3098275661468506,
          17.691547393798828,
          7.484562873840332,
          7.152260780334473,
          5.403470993041992,
          7.146379470825195,
          1.566029667854309,
          13.389820098876953,
          7.892482757568359,
          -4.337165355682373,
          6.377155780792236,
          12.58012580871582,
          4.992061614990234,
          9.906478881835938,
          -1.9651131629943848,
          3.340956449508667,
          0.38314178586006165,
          -0.9685337543487549,
          -4.282447338104248,
          2.741410970687866,
          7.203975677490234,
          -6.280332088470459,
          8.850530624389648,
          2.772725820541382,
          5.387612819671631,
          7.396237373352051,
          16.79738426208496,
          1.941625952720642,
          -0.2906336486339569,
          -1.5070934295654297,
          7.316122531890869,
          0.553813636302948,
          15.263872146606445,
          14.175640106201172,
          4.588761806488037,
          6.15784215927124,
          7.799075603485107,
          8.944562911987305,
          3.834015130996704,
          7.833429336547852,
          -0.1374417245388031,
          5.16622257232666,
          -1.1273748874664307,
          4.354115009307861,
          2.1417369842529297,
          7.545951843261719,
          -0.3698306679725647,
          4.232178211212158,
          -0.9475512504577637,
          5.328678607940674,
          7.639290809631348,
          7.175933361053467,
          5.521310806274414,
          4.93494987487793,
          -3.642693281173706,
          -3.4195053577423096,
          7.182497501373291,
          -8.601383209228516,
          2.1452322006225586,
          8.96844482421875,
          4.19888162612915,
          10.486927032470703,
          3.7334861755371094,
          -4.2737836837768555,
          15.086702346801758,
          13.007039070129395,
          8.817564964294434,
          5.046633243560791,
          6.175942420959473,
          13.283636093139648,
          2.7476859092712402,
          3.8866963386535645,
          -6.356616973876953,
          3.8348920345306396,
          -3.5222861766815186,
          2.004812240600586,
          2.5472054481506348,
          14.279093742370605,
          0.8110478520393372,
          4.141079902648926,
          7.559075832366943,
          10.585342407226562,
          -1.3990044593811035,
          -7.037127494812012,
          -2.01397967338562,
          -6.543705940246582,
          15.48311996459961,
          5.796085834503174,
          3.98868465423584,
          5.510857105255127,
          -0.7750116586685181,
          7.77974796295166,
          4.7271013259887695,
          5.014682292938232,
          1.3582795858383179,
          -1.185566782951355,
          8.190360069274902,
          4.443196773529053,
          -7.347524642944336,
          5.054320335388184,
          6.315281867980957,
          0.08117829263210297,
          2.7099947929382324,
          0.7976296544075012,
          17.13644790649414,
          1.968013882637024,
          8.63592529296875,
          4.754593372344971,
          6.443296432495117,
          8.636536598205566,
          5.235480785369873,
          5.090291500091553,
          -4.235614776611328,
          6.731983184814453,
          7.273775577545166,
          -6.874248027801514,
          -1.8428730964660645,
          -6.837371349334717,
          -5.371512413024902,
          2.2788145542144775,
          -8.270649909973145,
          1.2824171781539917,
          17.219989776611328,
          5.106165409088135,
          5.087857723236084,
          4.306381702423096,
          2.3169827461242676,
          3.7676570415496826,
          1.241774082183838,
          3.3799943923950195,
          6.063041687011719,
          -0.788731575012207,
          13.57848834991455,
          -0.5503364205360413,
          2.0693204402923584,
          6.190174579620361,
          6.968960285186768,
          12.247790336608887,
          8.12452507019043,
          3.840169668197632,
          1.4964966773986816,
          4.293564319610596,
          1.7328541278839111,
          2.9582149982452393,
          7.50715970993042,
          7.241602420806885,
          -1.331942081451416,
          3.378345251083374,
          -5.103175640106201,
          -4.48955774307251,
          -4.373410224914551,
          6.972916126251221,
          5.72285795211792,
          7.418399810791016,
          16.063371658325195,
          13.343313217163086,
          6.3229522705078125,
          1.3600513935089111,
          8.442598342895508,
          8.477952003479004,
          6.293469429016113,
          11.899236679077148,
          -0.9265012741088867,
          7.330230712890625,
          3.239961862564087,
          2.7342560291290283,
          4.9540581703186035,
          2.1631698608398438,
          -3.3609085083007812,
          9.614596366882324,
          0.8509044647216797,
          14.184045791625977,
          -4.118028163909912,
          9.438017845153809,
          2.2517521381378174,
          -1.0133230686187744,
          2.6698098182678223,
          2.7502849102020264,
          -4.5391411781311035,
          9.207440376281738,
          1.7021138668060303,
          6.18326997756958,
          5.172021389007568,
          4.708725452423096,
          0.6567452549934387,
          9.945449829101562,
          8.852706909179688,
          6.599761009216309,
          3.361436605453491,
          -0.006486724130809307,
          2.385568618774414,
          1.607513189315796,
          -7.142547130584717,
          5.165141582489014,
          10.56084156036377,
          -1.7093932628631592,
          1.0069063901901245,
          -5.767018795013428,
          -4.286301136016846,
          11.445588111877441,
          -5.759949207305908,
          0.08338518440723419,
          -2.530358076095581,
          -6.102378845214844,
          -2.670907974243164,
          8.378708839416504,
          0.37119781970977783,
          6.386932373046875,
          3.450211763381958,
          4.915008544921875,
          1.886297583580017,
          8.645564079284668,
          7.141289234161377,
          -0.27000901103019714,
          -6.74969482421875,
          4.323184967041016,
          5.523563861846924,
          -0.2734466791152954,
          12.250109672546387,
          -4.342952251434326,
          -3.1275081634521484,
          13.767175674438477,
          0.24662238359451294,
          2.184135913848877,
          6.033489227294922,
          -1.5439375638961792,
          6.677126884460449,
          5.042908668518066,
          -0.04506580904126167,
          -4.718167304992676,
          14.572614669799805,
          5.659700870513916,
          6.143002033233643,
          1.4503194093704224,
          1.5333608388900757,
          -0.8568273782730103,
          5.550302982330322,
          4.197974681854248,
          -0.8684937953948975,
          0.24717292189598083,
          13.307452201843262,
          -0.5080615282058716,
          9.465095520019531,
          3.775805950164795,
          -4.05756950378418,
          14.229802131652832,
          4.025755882263184,
          7.3820905685424805,
          5.91360330581665,
          1.6357651948928833,
          -1.269097924232483,
          8.565352439880371,
          3.3286046981811523,
          8.23628044128418,
          21.18547821044922,
          -0.48981615900993347,
          7.944756507873535,
          5.869874954223633,
          4.37006950378418,
          4.807724952697754,
          1.5320615768432617,
          -4.602991104125977,
          2.4403231143951416,
          -5.620234966278076,
          1.9404479265213013,
          4.449430465698242,
          0.09326101094484329,
          4.0850605964660645,
          -1.0043400526046753,
          2.0282535552978516,
          -1.0753417015075684,
          -2.5013537406921387,
          5.98351526260376,
          6.204457759857178,
          7.084070682525635,
          7.397822856903076,
          5.703957557678223,
          -0.525621771812439,
          -1.1736358404159546,
          7.421573638916016,
          -0.3529133200645447,
          0.622329592704773,
          8.252337455749512,
          6.474368572235107,
          0.244155615568161,
          0.22291213274002075,
          -5.003501892089844,
          9.06528377532959,
          6.642613410949707,
          -0.2369069755077362,
          -4.330696105957031,
          2.644721508026123,
          4.085965156555176,
          8.255253791809082,
          3.2409582138061523,
          -4.373939514160156,
          1.3496285676956177,
          4.002774238586426,
          6.186990261077881,
          -3.1175601482391357,
          -0.5892938375473022,
          7.694094657897949,
          -2.5553267002105713,
          6.973503112792969,
          5.817773818969727,
          6.812533855438232,
          1.9975708723068237,
          5.3533616065979,
          13.298482894897461,
          9.152032852172852,
          8.43880844116211,
          -0.8361976742744446,
          6.539015769958496,
          3.586967706680298,
          -0.9736893177032471,
          6.869541645050049,
          6.356445789337158,
          -4.591217994689941,
          7.796549320220947,
          1.8163502216339111,
          1.9102486371994019,
          7.074812889099121,
          -3.28610897064209,
          13.25314712524414,
          -1.5867292881011963,
          4.136479377746582,
          2.5095417499542236,
          -7.595149517059326,
          4.165499687194824,
          -2.6901488304138184,
          8.029221534729004,
          5.771789073944092,
          0.18850527703762054,
          1.1814664602279663,
          3.5483505725860596,
          1.2208987474441528,
          7.25015115737915,
          7.901776313781738,
          -3.182070016860962,
          5.734827518463135,
          -0.9890391230583191,
          16.342966079711914,
          -1.8032478094100952,
          8.356860160827637,
          3.4825446605682373,
          4.0030388832092285,
          5.016913414001465,
          6.082235336303711,
          -5.477542877197266,
          -1.0599900484085083,
          4.225025653839111,
          4.882440090179443,
          8.87995719909668,
          8.426961898803711,
          9.627237319946289,
          13.805810928344727,
          4.268904685974121,
          -5.896398067474365,
          -7.504194736480713,
          -7.264542579650879,
          -8.18563461303711,
          2.496938467025757,
          7.5932769775390625,
          11.876447677612305,
          2.1611328125,
          6.789865016937256,
          5.440669059753418,
          -0.8609665632247925,
          -7.717176914215088,
          4.590029239654541,
          -1.268664836883545,
          8.333868980407715,
          1.1583364009857178,
          17.357812881469727,
          5.717792510986328,
          -3.188427686691284,
          3.6741180419921875,
          4.732497215270996,
          0.26571375131607056,
          1.0402213335037231,
          5.896650791168213,
          8.656036376953125,
          -1.2993894815444946,
          5.240669250488281,
          0.9924896359443665,
          4.911485195159912,
          1.6273436546325684,
          -7.461677074432373,
          8.624052047729492,
          17.13825798034668,
          7.423648834228516,
          6.77288818359375,
          3.408358573913574,
          -0.1918104588985443,
          3.294434070587158,
          9.174129486083984,
          0.2969547212123871,
          -1.4950761795043945,
          3.9852800369262695,
          -0.7870341539382935,
          6.142874240875244,
          6.238293647766113,
          -0.05629339441657066,
          -0.465667724609375,
          -0.7838158011436462,
          4.343606472015381,
          5.383120059967041,
          2.2222204208374023,
          10.654411315917969,
          4.323541164398193,
          -1.3840397596359253,
          7.47066068649292,
          12.261438369750977,
          -5.363658905029297,
          0.4422573149204254,
          -0.047018349170684814,
          5.87189245223999,
          7.195530414581299,
          21.322372436523438,
          9.034259796142578,
          16.122875213623047,
          8.639240264892578,
          6.579311370849609,
          0.22394225001335144,
          0.4925360381603241,
          7.823652267456055,
          1.1086338758468628,
          -3.4560277462005615,
          12.00536060333252,
          8.601019859313965,
          -2.9141478538513184,
          -7.288467884063721,
          8.565523147583008,
          5.817687511444092,
          12.381742477416992,
          8.435813903808594,
          9.701516151428223,
          4.782788276672363,
          5.4060821533203125,
          7.721059322357178,
          -0.5522447824478149,
          0.6694400906562805,
          -3.014606237411499,
          2.6529195308685303,
          5.202810764312744,
          6.192615509033203,
          3.1578636169433594,
          6.140284538269043,
          4.326066017150879,
          -2.7494466304779053,
          8.988272666931152,
          9.72900104522705,
          -1.2588499784469604,
          3.7374513149261475,
          0.9852461218833923,
          5.961220741271973,
          1.1516380310058594,
          5.346913814544678,
          8.214673042297363,
          1.3849797248840332,
          4.879843711853027,
          8.131945610046387,
          2.6207027435302734,
          8.511720657348633,
          8.023310661315918,
          9.647759437561035,
          -1.9881727695465088,
          4.8232221603393555,
          2.994925022125244,
          -0.5906059741973877,
          5.308838367462158,
          1.2036751508712769,
          6.137289047241211,
          6.805331230163574,
          -4.050753116607666,
          13.429817199707031,
          7.88575553894043,
          -2.4171786308288574,
          6.350497722625732,
          2.3226191997528076,
          6.082579612731934,
          0.06534194946289062,
          7.58740758895874,
          0.7126486301422119,
          0.5001037120819092,
          -3.389552593231201,
          -2.8549082279205322,
          1.9558895826339722,
          9.224308013916016,
          4.696098804473877,
          -4.7670745849609375,
          4.785073280334473,
          3.1665027141571045,
          7.496363639831543,
          0.6183395981788635,
          1.9626893997192383,
          9.670698165893555,
          5.725260257720947,
          0.4455137848854065,
          7.964174747467041,
          6.501895427703857,
          -3.989586353302002,
          3.3452720642089844,
          -0.4821621775627136,
          7.502224922180176,
          8.135144233703613,
          4.814479351043701,
          -0.7610157132148743,
          -1.0511932373046875,
          6.149980545043945,
          13.160240173339844,
          7.841280937194824,
          5.985702991485596,
          7.044920921325684,
          4.709207057952881,
          0.3630329370498657,
          1.1848911046981812,
          7.706938743591309,
          -1.2260746955871582,
          4.501572132110596,
          2.7430527210235596,
          16.609954833984375,
          2.186588764190674,
          -0.40217864513397217,
          6.062616348266602,
          7.823564052581787,
          7.935490608215332,
          5.747042655944824,
          5.127414703369141,
          1.9061640501022339,
          -3.466928482055664,
          2.590841293334961,
          4.092024326324463,
          5.776954174041748,
          4.941619873046875,
          4.828559398651123,
          3.4478254318237305,
          7.065855503082275,
          1.3437459468841553,
          -2.767791986465454,
          0.07786908000707626,
          -4.9010748863220215,
          1.808180809020996,
          5.933903694152832,
          4.486721992492676,
          14.798665046691895,
          0.03828415647149086,
          4.78668212890625,
          2.0419204235076904,
          8.903602600097656,
          15.456653594970703,
          4.989305019378662,
          4.844366073608398,
          2.750730514526367,
          7.753750801086426,
          3.149705648422241,
          7.3334174156188965,
          -7.0918989181518555,
          6.701683521270752,
          -2.7207741737365723,
          8.162263870239258,
          -5.195397853851318,
          6.3847737312316895,
          13.107878684997559,
          14.838809967041016,
          7.355336666107178,
          3.423159599304199,
          7.92446231842041,
          -0.7414466738700867,
          7.975314140319824,
          5.319677352905273,
          -6.983895778656006,
          5.637279033660889,
          -1.9533138275146484,
          5.667064666748047,
          8.312414169311523,
          -1.1130893230438232,
          1.8583403825759888,
          -1.3290934562683105,
          5.467082977294922,
          6.8682379722595215,
          3.8129889965057373,
          7.675141334533691,
          -5.364606857299805,
          1.2798210382461548,
          7.1794281005859375,
          6.9393630027771,
          8.609278678894043,
          13.807509422302246,
          5.241330146789551,
          0.8334168791770935,
          5.435662269592285,
          -5.833457946777344,
          7.345452308654785,
          4.252602577209473,
          1.5416351556777954,
          4.751150608062744,
          1.480563998222351,
          15.320112228393555,
          -2.8298087120056152,
          3.935370445251465,
          6.85230827331543,
          7.415358066558838,
          9.807382583618164,
          9.202622413635254,
          -7.840290069580078,
          0.8288144469261169,
          -2.513627529144287,
          -0.8017733693122864,
          2.299713134765625,
          1.8942691087722778,
          -1.2093586921691895,
          4.635915756225586,
          0.21336787939071655,
          14.059468269348145,
          -4.44271183013916,
          -0.52260822057724,
          -4.252345561981201,
          7.0973615646362305,
          10.852824211120605,
          -4.4359450340271,
          12.120134353637695,
          0.8492931127548218,
          13.133835792541504,
          -5.698422908782959,
          4.094280242919922,
          -2.7796471118927,
          10.001791954040527,
          6.28456974029541,
          4.259872913360596,
          -1.127816081047058,
          -1.3254690170288086,
          9.080283164978027,
          -5.418969631195068,
          1.39952552318573,
          -1.5342357158660889,
          5.850841045379639,
          7.435775279998779,
          5.192263126373291,
          7.299675941467285,
          2.6237986087799072,
          12.579855918884277,
          -0.03593672066926956,
          6.903570175170898,
          5.854018211364746,
          1.0092908143997192,
          7.998778343200684,
          4.841187477111816,
          7.521239280700684,
          -2.82122540473938,
          13.952640533447266,
          21.228309631347656,
          3.943201780319214,
          -1.4240375757217407,
          4.264081954956055,
          5.335577011108398,
          -4.937567710876465,
          12.810669898986816,
          13.672174453735352,
          2.6297929286956787,
          13.512348175048828,
          -2.051847457885742,
          6.521050930023193,
          -0.45787113904953003,
          7.626415252685547,
          -1.291109323501587,
          3.0956830978393555,
          4.08653450012207,
          7.042462348937988,
          -0.667580246925354,
          5.324773788452148,
          -7.84239387512207,
          3.4275593757629395,
          15.515925407409668,
          -4.979040145874023,
          0.47362467646598816,
          2.989267110824585,
          7.562984943389893,
          -8.145354270935059,
          -0.1874951720237732,
          14.102607727050781,
          0.33344608545303345,
          6.0656538009643555,
          13.824310302734375,
          -0.0764235109090805,
          6.773926258087158,
          12.895910263061523,
          7.841366291046143,
          -7.3245320320129395,
          6.788157939910889,
          1.1800870895385742,
          8.340536117553711,
          10.37406063079834,
          3.2828588485717773,
          -2.5763232707977295,
          -2.7175183296203613,
          2.2769763469696045,
          5.364096641540527,
          3.373434066772461,
          5.405828475952148,
          6.47194242477417,
          3.6875600814819336,
          4.80314826965332,
          -3.0131676197052,
          5.894551753997803,
          17.07654571533203,
          6.092311382293701,
          8.303812980651855,
          -2.213526487350464,
          -5.986484527587891,
          21.080322265625,
          7.934963703155518,
          12.594478607177734,
          3.3105430603027344,
          -1.388430118560791,
          -1.0349233150482178,
          8.384403228759766,
          8.125346183776855,
          5.302053928375244,
          3.176647186279297,
          -1.6404247283935547,
          5.770980358123779,
          -2.812405586242676,
          5.908755302429199,
          7.823486328125,
          0.13250556588172913,
          6.213918209075928,
          3.7343456745147705,
          -4.522641658782959,
          -0.03658777475357056,
          9.395675659179688,
          8.651907920837402,
          3.013690948486328,
          0.2555323541164398,
          7.69327974319458,
          -6.417929172515869,
          1.3557316064834595,
          -1.5919216871261597,
          7.5243754386901855,
          -6.5650954246521,
          7.345175743103027,
          15.187037467956543,
          4.1936798095703125,
          15.346759796142578,
          1.0699694156646729,
          2.041316032409668,
          -2.3665263652801514,
          -1.7106891870498657,
          7.1817827224731445,
          -4.099669456481934,
          7.957590579986572,
          6.555997371673584,
          6.536386966705322,
          -2.752241849899292,
          -0.7170464992523193,
          9.34834098815918,
          -2.273292303085327,
          9.606025695800781,
          4.654547214508057,
          2.8709664344787598,
          7.609549045562744,
          -9.076809883117676,
          -6.838057994842529,
          0.037382274866104126,
          5.845372676849365,
          6.194222927093506,
          6.917178153991699,
          1.757400393486023,
          7.635171890258789,
          14.441267967224121,
          13.656549453735352,
          -6.672970771789551,
          2.792053461074829,
          8.917464256286621,
          19.302541732788086,
          -0.3894571363925934,
          -0.2906765639781952,
          -5.3354811668396,
          5.573914527893066,
          -2.6817076206207275,
          -4.089280128479004,
          -1.692867398262024,
          7.372494697570801,
          3.955246686935425,
          7.641299724578857,
          0.809043288230896,
          14.924775123596191,
          1.6720788478851318,
          -6.885867595672607,
          6.22673225402832,
          4.921287536621094,
          3.9149060249328613,
          7.338473796844482,
          7.618261814117432,
          7.884803771972656,
          -5.028133392333984,
          -7.762199878692627,
          6.795197010040283,
          6.427450180053711,
          -6.666807651519775,
          -1.6599767208099365,
          4.017651557922363,
          6.3542256355285645,
          6.941046714782715,
          7.006636142730713,
          4.417562007904053,
          3.963667392730713,
          5.220468521118164,
          -4.348892688751221,
          -1.6918827295303345,
          -6.602309703826904,
          -2.5259249210357666,
          5.444545269012451,
          3.827824831008911,
          12.931925773620605,
          -6.619862079620361,
          2.478499174118042,
          17.06631851196289,
          2.0863897800445557,
          6.750965595245361,
          -1.301362156867981,
          2.154757022857666,
          7.9351348876953125,
          8.37999153137207,
          5.9796881675720215,
          3.645132303237915,
          11.831292152404785,
          -6.6840691566467285,
          7.34274959564209,
          -3.2277369499206543,
          0.44131410121917725,
          -4.834383487701416,
          14.024134635925293,
          5.718076705932617,
          3.8150525093078613,
          7.338714599609375,
          -1.2354648113250732,
          1.7162278890609741,
          6.200538158416748,
          10.447680473327637,
          -8.322957038879395,
          4.637686729431152,
          8.254520416259766,
          -0.6969444751739502,
          2.4391064643859863,
          15.545056343078613,
          2.1975460052490234,
          8.821267127990723,
          9.465985298156738,
          -5.933529376983643,
          -1.9126074314117432,
          -5.610025882720947,
          5.946549415588379,
          9.273844718933105,
          8.414079666137695,
          7.792980670928955,
          6.016275882720947,
          3.9387032985687256,
          -5.151149272918701,
          8.586679458618164,
          8.341254234313965,
          -0.7364428639411926,
          4.806539535522461,
          1.7060810327529907,
          14.511868476867676,
          -8.050435066223145,
          2.410639762878418,
          -5.293482303619385,
          -6.883916854858398,
          8.141840934753418,
          3.5626821517944336,
          -0.4948424696922302,
          7.929542541503906,
          1.7886728048324585,
          -3.0475590229034424,
          4.045907974243164,
          1.9915618896484375,
          -2.213305950164795,
          7.590574741363525,
          -5.624172210693359,
          9.096233367919922,
          5.718649864196777,
          -0.8751020431518555,
          -3.5508172512054443,
          2.571730613708496,
          -5.77555513381958,
          4.947772026062012,
          8.31171703338623,
          6.171008110046387,
          5.632609844207764,
          4.876763343811035,
          6.063420295715332,
          -0.7898322939872742,
          4.520042896270752,
          1.403504490852356,
          4.921833038330078,
          0.8666656017303467,
          5.29290771484375,
          0.7624328136444092,
          0.6773535013198853,
          5.889474391937256,
          9.757707595825195,
          7.7435197830200195,
          2.2352702617645264,
          7.909981727600098,
          10.34535026550293,
          8.619380950927734,
          -0.5384601950645447,
          -0.5822415947914124,
          5.888981342315674,
          6.347062110900879,
          5.979724884033203,
          9.080631256103516,
          -1.2934712171554565,
          9.504926681518555,
          -0.7646979093551636,
          7.95078182220459,
          0.8129172921180725,
          15.631753921508789,
          -3.028637647628784,
          -1.8529248237609863,
          -6.114772796630859,
          7.426185131072998,
          5.762447357177734,
          -0.2223580777645111,
          14.65798282623291,
          -2.6817257404327393,
          -1.0681473016738892,
          4.8151373863220215,
          6.384853363037109,
          8.761985778808594,
          -4.155613899230957,
          4.070479393005371,
          8.141006469726562,
          10.348608016967773,
          -5.083677768707275,
          2.3781397342681885,
          -1.1010456085205078,
          6.710214614868164,
          4.7180962562561035,
          8.043578147888184,
          9.61964225769043,
          10.954724311828613,
          6.276647567749023,
          2.4006550312042236,
          7.818099021911621,
          -5.29067850112915,
          -0.5368057489395142,
          8.708473205566406,
          -7.110403537750244,
          4.660732746124268,
          -1.5823242664337158,
          7.440869331359863,
          -5.0177507400512695,
          2.1474947929382324,
          -2.7380945682525635,
          6.6810126304626465,
          6.228140830993652,
          10.638209342956543,
          -2.1923789978027344,
          3.5013206005096436,
          3.904137134552002,
          -3.357738494873047,
          -0.6283376216888428,
          9.607979774475098,
          -1.8977607488632202,
          1.1463720798492432,
          8.717485427856445,
          3.662477731704712,
          14.429889678955078,
          8.991853713989258,
          -4.963184833526611,
          13.568124771118164,
          -0.01012887991964817,
          1.9782880544662476,
          9.292716979980469,
          3.755692720413208,
          8.549501419067383,
          6.2067742347717285,
          13.105475425720215,
          17.21824836730957,
          2.3316807746887207,
          7.714242935180664,
          2.676422119140625,
          6.015481472015381,
          10.203202247619629,
          -2.3470983505249023,
          0.23230750858783722,
          13.711309432983398,
          6.388406753540039,
          -3.2175588607788086,
          7.78240442276001,
          -4.875787734985352,
          13.903972625732422,
          -0.42050620913505554,
          -2.4516119956970215,
          5.341421604156494,
          -1.1547770500183105,
          -6.302931785583496,
          19.1806583404541,
          6.563819408416748,
          -1.1125317811965942,
          -0.48421430587768555,
          10.792396545410156,
          -1.6357532739639282,
          5.668634414672852,
          -1.6682674884796143,
          7.204807758331299,
          -2.7549970149993896,
          3.638493776321411,
          -3.631774425506592,
          -0.5268096327781677,
          5.487668514251709,
          -0.6798858046531677,
          4.227562427520752,
          15.449322700500488,
          -5.977921009063721,
          8.317136764526367,
          6.580069541931152,
          6.80963134765625,
          -7.1747941970825195,
          2.766746997833252,
          2.6815202236175537,
          -5.931990623474121,
          -2.5142822265625,
          14.928483009338379,
          8.428841590881348,
          3.25754976272583,
          -3.140505075454712,
          3.5181243419647217,
          6.358018398284912,
          -4.787138938903809,
          13.48510456085205,
          7.921144485473633,
          -2.65545916557312,
          7.843759059906006,
          7.817446708679199,
          2.562912702560425,
          8.525390625,
          -3.405179500579834,
          -6.689599990844727,
          -0.08995097875595093,
          -1.5356448888778687,
          5.743964195251465,
          3.5120911598205566,
          -1.0482970476150513,
          3.2596797943115234,
          -1.259486436843872,
          3.545008659362793,
          8.715513229370117,
          -1.5521832704544067,
          5.880509376525879,
          3.754833459854126,
          -7.343629837036133,
          8.206060409545898,
          5.867606163024902,
          8.028032302856445,
          4.502484321594238,
          4.295331954956055,
          5.744412899017334,
          6.9845991134643555,
          8.655632019042969,
          2.9785473346710205,
          5.534965515136719,
          8.344680786132812,
          3.0346016883850098,
          1.2671120166778564,
          -0.12264417111873627,
          -5.343474864959717,
          4.5899553298950195,
          8.08536434173584,
          6.09748649597168,
          -1.4654483795166016,
          4.795067310333252,
          7.098464488983154,
          12.11080551147461,
          10.478750228881836,
          7.614508152008057,
          8.992681503295898,
          4.3632683753967285,
          12.070489883422852,
          -1.7875970602035522,
          -0.5999460816383362,
          3.907895088195801,
          3.291947364807129,
          12.272783279418945,
          5.919950485229492,
          -3.031874179840088,
          1.7439486980438232,
          -6.069146633148193,
          -3.268568754196167,
          -0.09015972167253494,
          -4.181539535522461,
          13.193359375,
          8.74125862121582,
          8.027114868164062,
          0.14044862985610962,
          6.600171089172363,
          4.62579345703125,
          15.524084091186523,
          6.66196346282959,
          1.8840947151184082,
          6.8818159103393555,
          -0.743426501750946,
          5.693347454071045,
          -5.501601696014404,
          3.7506103515625,
          7.874583721160889,
          7.301980018615723,
          8.321775436401367,
          0.21681827306747437,
          -1.2693488597869873,
          4.646254539489746,
          -5.894504547119141,
          -4.205295562744141,
          -1.8954823017120361,
          -4.549682140350342,
          -1.9565929174423218,
          -1.5719759464263916,
          3.9057536125183105,
          6.029104709625244,
          7.602793216705322,
          0.42347320914268494,
          7.5650200843811035,
          -1.2366122007369995,
          8.259317398071289,
          6.742683410644531,
          -1.0656267404556274,
          7.269210338592529,
          -0.5432603359222412,
          15.872371673583984,
          -1.2591336965560913,
          -1.1000025272369385,
          3.9724910259246826,
          7.446681022644043,
          3.7672085762023926,
          2.0684821605682373,
          15.466391563415527,
          -0.9478966593742371,
          6.422202110290527,
          1.690428376197815,
          -3.1282267570495605,
          -1.7095555067062378,
          1.1241326332092285,
          6.307084560394287,
          1.6103925704956055,
          10.125626564025879,
          2.3824706077575684,
          4.225283145904541,
          9.694292068481445,
          0.8806020021438599,
          -1.3615368604660034,
          -0.2280857115983963,
          14.10787296295166,
          -6.7527313232421875,
          7.107045650482178,
          5.236765384674072,
          -1.256255030632019,
          -0.9239029288291931,
          11.929686546325684,
          -0.2843858599662781,
          -0.4121786653995514,
          0.5724397897720337,
          2.642688512802124,
          8.676115036010742,
          -1.181416630744934,
          1.6580932140350342,
          7.153268337249756,
          -3.8392462730407715,
          -4.699051856994629,
          3.7109522819519043,
          0.8510314226150513,
          -3.6589767932891846,
          4.252500057220459,
          0.6239430904388428,
          6.313145160675049,
          5.676443576812744,
          4.068865776062012,
          5.10701847076416,
          9.010284423828125,
          5.343493461608887,
          -1.5320388078689575,
          6.863203525543213,
          20.95991325378418,
          7.741659641265869,
          8.20522403717041,
          13.385149955749512,
          7.939553260803223,
          0.10833782702684402,
          10.682262420654297,
          -2.4089441299438477,
          -0.6526488661766052,
          5.629944801330566,
          1.7657921314239502,
          4.050586223602295,
          -0.8433118462562561,
          8.216034889221191,
          -2.1611108779907227,
          8.916962623596191,
          9.370230674743652,
          3.0692172050476074,
          3.3139777183532715,
          -4.90614128112793,
          -0.5456123352050781,
          -2.09074330329895,
          -1.6096240282058716,
          12.226015090942383,
          4.835811614990234,
          6.038527965545654,
          2.8170228004455566,
          4.122303009033203,
          6.150538444519043,
          8.137670516967773,
          -4.128210544586182,
          -2.828350067138672,
          5.348251819610596,
          3.6667938232421875,
          -3.60072922706604,
          6.123968601226807,
          -2.677119731903076,
          -0.6752465963363647,
          -5.252591609954834,
          -4.5179548263549805,
          -3.5206868648529053,
          -0.8927625417709351,
          13.891889572143555,
          8.273280143737793,
          -7.2956223487854,
          4.306636810302734,
          12.718833923339844,
          8.158550262451172,
          -0.8192557096481323,
          5.321959495544434,
          -1.669338583946228,
          8.488802909851074,
          8.954401016235352,
          -4.805516242980957,
          7.7034502029418945,
          -0.27385973930358887,
          -3.151667356491089,
          11.657373428344727,
          -7.013330936431885,
          -9.037715911865234,
          -0.312800794839859,
          8.221111297607422,
          3.293916702270508,
          -1.318793535232544,
          19.163503646850586,
          3.3387393951416016,
          -0.6586159467697144,
          5.935396194458008,
          -6.615023136138916,
          -5.863489627838135,
          3.9808080196380615,
          5.478737831115723,
          -0.1872662901878357,
          4.1667327880859375,
          7.037403106689453,
          4.06331729888916,
          5.306766986846924,
          15.196065902709961,
          4.781537055969238,
          -1.645393967628479,
          9.495504379272461,
          5.657731533050537,
          -0.5620749592781067,
          7.631577014923096,
          2.335263967514038,
          0.14461255073547363,
          5.112026214599609,
          -3.0933518409729004,
          -0.3863827884197235,
          2.779111385345459,
          5.471044063568115,
          3.536665916442871,
          2.1993868350982666,
          7.912992477416992,
          -5.686568260192871,
          2.049715518951416,
          4.064554691314697,
          -2.094874858856201,
          10.040504455566406,
          -3.2448177337646484,
          6.453413963317871,
          -1.9393218755722046,
          7.165355682373047,
          17.079912185668945,
          6.66216516494751,
          1.8681870698928833,
          3.6888513565063477,
          5.15726375579834,
          8.215872764587402,
          8.730710983276367,
          -5.949117660522461,
          14.099544525146484,
          -8.737070083618164,
          5.908720970153809,
          5.4018473625183105,
          11.673608779907227,
          6.4184370040893555,
          -1.3240822553634644,
          0.8031648993492126,
          1.3838884830474854,
          5.991236686706543,
          2.9189095497131348,
          1.1820969581604004,
          4.092319488525391,
          -4.821361064910889,
          17.32132339477539,
          8.93416976928711,
          17.21999168395996,
          15.619483947753906,
          7.975834846496582,
          2.1892364025115967,
          7.22577428817749,
          -2.2633063793182373,
          5.0866475105285645,
          -0.03226431459188461,
          5.531774997711182,
          -7.389495849609375,
          0.08338677883148193,
          3.4240634441375732,
          6.886994361877441,
          -1.4054733514785767,
          7.612893104553223,
          -4.862989902496338,
          6.790652275085449,
          -0.9218475222587585,
          13.807999610900879,
          15.5647611618042,
          6.869744300842285,
          5.313022613525391,
          7.966507911682129,
          3.490211248397827,
          8.615986824035645,
          0.7454902529716492,
          -0.836182177066803,
          5.520320892333984,
          4.483226299285889,
          7.003870964050293,
          -5.772470474243164,
          6.666944980621338,
          1.6701295375823975,
          6.889826774597168,
          1.7289104461669922,
          -0.40851351618766785,
          6.98978328704834,
          -0.6946508288383484,
          -1.8577710390090942,
          9.098907470703125,
          4.879942417144775,
          -0.7522664070129395,
          7.507788181304932,
          -1.9578464031219482,
          2.841698169708252,
          4.906622409820557,
          8.344829559326172,
          7.420753002166748,
          5.065918922424316,
          6.694891452789307,
          7.4373250007629395,
          4.975475788116455,
          4.726511478424072,
          0.04933379590511322,
          5.83145809173584,
          0.048610154539346695,
          17.543359756469727,
          7.620355129241943,
          15.21459674835205,
          -2.35455584526062,
          -6.722423076629639,
          5.565553665161133,
          2.6922218799591064,
          5.500334739685059,
          -2.4280710220336914,
          1.9912186861038208,
          4.484673023223877,
          0.07860572636127472,
          10.66670036315918,
          1.2598812580108643,
          7.413192272186279,
          4.027937889099121,
          -1.2872447967529297,
          -0.8214079141616821,
          -2.3488667011260986,
          1.331496000289917,
          4.9729180335998535,
          3.879976749420166,
          -3.283677339553833,
          8.249570846557617,
          -0.7854981422424316,
          -2.3218255043029785,
          5.3614277839660645,
          17.755496978759766,
          -0.9544094204902649,
          9.20583724975586,
          -7.530470848083496,
          13.592109680175781,
          1.9938629865646362,
          4.7499542236328125,
          6.075185298919678,
          -6.426509857177734,
          5.732655048370361,
          -1.1906458139419556,
          0.12364369630813599,
          15.59780216217041,
          7.437491416931152,
          -4.0262885093688965,
          4.88637113571167,
          5.726199150085449,
          12.344938278198242,
          7.540990829467773,
          -8.7295503616333,
          3.4929516315460205,
          3.1674962043762207,
          0.2573806345462799,
          13.500236511230469,
          7.202648639678955,
          6.2108988761901855,
          8.619989395141602,
          7.156680107116699,
          1.201332688331604,
          6.308892250061035,
          7.597132682800293,
          11.926236152648926,
          7.572015762329102,
          7.935586452484131,
          -2.6531624794006348,
          6.183640956878662,
          -7.17381477355957,
          7.9622883796691895,
          2.1781272888183594,
          -1.6967248916625977,
          0.5325538516044617,
          -1.2857192754745483,
          0.321554034948349,
          10.251321792602539,
          -2.7190890312194824,
          -2.1862826347351074,
          4.722929954528809,
          2.0154776573181152,
          3.517934560775757,
          8.91990852355957,
          6.565131187438965,
          7.4120001792907715,
          -7.1140336990356445,
          -6.676795482635498,
          5.428868293762207,
          -2.8965160846710205,
          7.154577732086182,
          -8.13940715789795,
          -4.853173732757568,
          -0.18551282584667206,
          -1.2449666261672974,
          -0.25113412737846375,
          21.021024703979492,
          6.616497993469238,
          -0.18126662075519562,
          9.89162540435791,
          5.948740482330322,
          2.976083993911743,
          9.257326126098633,
          1.562726378440857,
          9.093915939331055,
          6.880996227264404,
          1.9872771501541138,
          3.9437382221221924,
          0.13236720860004425,
          -1.145830750465393,
          -4.313233852386475,
          -8.061307907104492,
          5.40173864364624,
          8.02117919921875,
          4.268483638763428,
          4.261140823364258,
          4.197585105895996,
          -0.9739556908607483,
          12.840534210205078,
          5.416809558868408,
          3.050542116165161,
          7.019277572631836,
          4.660764217376709,
          17.03510284423828,
          1.0540978908538818,
          7.575154781341553,
          -4.975919246673584,
          0.6266050934791565,
          2.4617919921875,
          16.666889190673828,
          1.1702138185501099,
          4.002297878265381,
          3.8106391429901123,
          -4.5221428871154785,
          6.239176273345947,
          3.8365347385406494,
          -0.4880794584751129,
          1.910496473312378,
          6.207507610321045,
          6.24400520324707,
          7.079058647155762,
          11.946975708007812,
          5.598742961883545,
          4.979252815246582,
          14.392733573913574,
          8.83113956451416,
          4.8127055168151855,
          -9.46652603149414,
          17.894433975219727,
          0.6739150285720825,
          6.749607563018799,
          -0.5470833778381348,
          6.343753814697266,
          -1.2661412954330444,
          5.213246822357178,
          8.531231880187988,
          7.778267860412598,
          9.444963455200195,
          -6.783641338348389,
          4.340261459350586,
          6.726590633392334,
          -0.21073628962039948,
          7.200646877288818,
          -0.13430140912532806,
          17.098674774169922,
          4.388373374938965,
          8.291598320007324,
          4.306120872497559,
          2.8702197074890137,
          3.1863529682159424,
          6.1638054847717285,
          9.02502727508545,
          6.381250858306885,
          1.4024168252944946,
          5.8662543296813965,
          -3.677572250366211,
          12.977804183959961,
          2.3084332942962646,
          -5.5122175216674805,
          -1.6858258247375488,
          -0.40907174348831177,
          17.391277313232422,
          5.671016693115234,
          7.859236717224121,
          7.076779365539551,
          5.353268146514893,
          -0.23968030512332916,
          8.368106842041016,
          6.425179958343506,
          2.489084482192993,
          2.0520997047424316,
          7.721064567565918,
          7.435285568237305,
          4.608210563659668,
          16.676836013793945,
          8.87491226196289,
          6.459542751312256,
          8.728646278381348,
          -5.319896221160889,
          3.3676795959472656,
          9.083566665649414,
          5.531509876251221,
          0.31149134039878845,
          13.093414306640625,
          7.152663230895996,
          0.44572338461875916,
          1.7151763439178467,
          9.895126342773438,
          5.543560981750488,
          2.9327280521392822,
          7.590897560119629,
          -0.6201938986778259,
          5.564467430114746,
          -1.0112485885620117,
          6.2417402267456055,
          7.333034038543701,
          8.333647727966309,
          8.50548267364502,
          4.621174335479736,
          -4.157507419586182,
          13.45875358581543,
          7.159472465515137,
          4.6779303550720215,
          17.60856819152832,
          15.46403980255127,
          -6.233670711517334,
          3.1953001022338867,
          4.0108819007873535,
          18.136999130249023,
          2.3282952308654785,
          3.949014663696289,
          -6.524838447570801,
          -0.9536645412445068,
          -1.0225400924682617,
          2.0565483570098877,
          8.229110717773438,
          -5.1574578285217285,
          -1.5452505350112915,
          4.2314558029174805,
          -0.3413999378681183,
          13.651031494140625,
          1.8494114875793457,
          1.466864824295044,
          6.0558295249938965,
          -2.186966896057129,
          6.274160385131836,
          -4.317680835723877,
          16.87649154663086,
          8.271273612976074,
          6.211147308349609,
          -4.210329055786133,
          -1.1847926378250122,
          5.0919575691223145,
          -1.9779967069625854,
          -1.654124140739441,
          6.378201484680176,
          8.835833549499512,
          -3.7767436504364014,
          2.339571475982666,
          0.7547896504402161,
          6.22357702255249,
          12.377090454101562,
          4.144392013549805,
          1.6114883422851562,
          -6.0328049659729,
          -5.340038299560547,
          -4.916296482086182,
          -0.13427427411079407,
          7.392472743988037,
          5.065182209014893,
          -1.9896314144134521,
          0.7780845165252686,
          4.274326324462891,
          1.253147840499878,
          4.044741630554199,
          -0.13395461440086365,
          -6.453737735748291,
          0.5496835708618164,
          3.891903877258301,
          -4.060815811157227,
          1.7115522623062134,
          -1.9982235431671143,
          8.39750862121582,
          7.982838153839111,
          6.053633213043213,
          -6.533652305603027,
          6.373242378234863,
          16.414770126342773,
          3.5571768283843994,
          7.263389587402344,
          5.752532958984375,
          -1.8717883825302124,
          4.155710220336914,
          -1.724626898765564,
          -4.903653144836426,
          7.6710100173950195,
          1.278066635131836,
          2.1890182495117188,
          3.5901689529418945,
          1.3503607511520386,
          6.760015487670898,
          0.9432812929153442,
          -2.3278088569641113,
          -6.391060829162598,
          -5.765633583068848,
          4.0626912117004395,
          5.301709175109863,
          0.7515482306480408,
          -6.581427097320557,
          -0.5287781357765198,
          -5.799510955810547,
          -0.40365681052207947,
          -6.523801803588867,
          8.063846588134766,
          -2.076873302459717,
          7.393180847167969,
          -2.4465465545654297,
          -0.07759055495262146,
          16.10002899169922,
          8.79801082611084,
          -4.772090435028076,
          4.796971797943115,
          -1.1141622066497803,
          12.109060287475586,
          8.951658248901367,
          9.23136043548584,
          14.073895454406738,
          17.481889724731445,
          7.820132732391357,
          12.770222663879395,
          6.798081398010254,
          -0.7708086967468262,
          16.87641716003418,
          -0.310699462890625,
          -6.624352931976318,
          5.657923221588135,
          6.012697696685791,
          8.180057525634766,
          5.923549652099609,
          13.763765335083008,
          9.903105735778809,
          1.1119294166564941,
          -3.986884832382202,
          5.594139099121094,
          8.381040573120117,
          1.7715054750442505,
          5.753666400909424,
          -1.8041326999664307,
          8.294668197631836,
          2.1690280437469482,
          8.838033676147461,
          -0.8316603302955627,
          7.377776145935059,
          1.9014133214950562,
          6.0893096923828125,
          4.204968452453613,
          17.20146942138672,
          4.9927802085876465,
          7.5543694496154785,
          -6.568678379058838,
          -6.605335235595703,
          3.9100184440612793,
          -1.2920159101486206,
          8.590110778808594,
          16.644681930541992,
          8.580451011657715,
          17.617502212524414,
          5.1849493980407715,
          4.295281887054443,
          -5.029444694519043,
          -1.0837018489837646,
          -4.2791619300842285,
          3.6599831581115723,
          5.655599594116211,
          4.950676441192627,
          1.2787799835205078,
          7.106914043426514,
          14.17149543762207,
          5.7894287109375,
          14.796708106994629,
          1.3551428318023682,
          -8.212725639343262,
          5.297400951385498,
          3.2539756298065186,
          5.706522464752197,
          3.330596446990967,
          5.488572597503662,
          -0.32348141074180603,
          8.804240226745605,
          15.492231369018555,
          5.910214424133301,
          6.771081447601318,
          7.343740463256836,
          8.653181076049805,
          2.589035749435425,
          -1.978585958480835,
          -0.7611099481582642,
          6.33053731918335,
          7.166834354400635,
          6.811434268951416,
          12.24151611328125,
          8.150264739990234,
          -1.8229273557662964,
          -4.211958408355713,
          -2.101245880126953,
          7.060232639312744,
          -4.944328308105469,
          -5.715094089508057,
          4.985766887664795,
          -6.947048187255859,
          -1.2325533628463745,
          2.1678314208984375,
          -5.758446216583252,
          3.7565853595733643
         ]
        },
        {
         "hoverinfo": "text",
         "hovertext": [
          "Combining both the script data with character metadata and episode metadata.",
          " Calculating number of conversations for the first 10 episodes",
          "Merge the script lines with episodes' details, characters, and locations.",
          " Using more characters and episodes than previously, we will try to predict which character is saying which line, using two approaches.",
          "Retrieve the conversation for episodes that contain 2 or more characters.",
          " Show the first episode",
          "Counting the number of lines in episodes",
          "Merge all the scripts, characters, locations, and episodes into a single dataframe.",
          "Later we will need to group the script lines by episode, so we precompute this for later usage.",
          " Segment neighborhoods as different episodes.",
          "Merge the data for characters, locations, and script lines using the episode ID as the common key.",
          "Build the dataframe to be used in this notebook with the characters' lines along with the episode id and name for further analysis.",
          "Check if scripts lines has the episode ID",
          "Filter out stories that are too short.",
          "For now, drop the seven episodes that do not have any line associated with them",
          "Select conversation and extract lines by episode and character",
          "Combine the data of the episodes with their corresponding scripts.",
          " Merge script, episodes, characters and location data into one dataframe",
          "Set the length of all TV script lines to 300 characters or less.",
          "Merge the scripts with their respective episodes, characters, and locations.",
          "Concatenate the location, character and speaking turn from the script to the episodes.",
          "Filter out the episode ids that are in the lines dataset from the episodes dataset.",
          "Join to get the locations and entities present in every episode",
          "Combine the script lines with the episode titles",
          "Merge the script with the characters and the episodes dataframes to have all the relevant info in one place.",
          " Merge script with characters, locations and episodes names",
          "The lines in the original script are randomly ordered. Let's first sort them by episode id and index.",
          "merge location and episodes dataframes",
          "Select the script for episode 1 (June 15, 2017)",
          "Extraire le texte de tous les épisodes",
          "The first thing we'll do with the script data is to connect the script lines to episode, character and location ids.",
          "Function to filter the script by episode id.",
          "Print the script from the first episode",
          "Get the episodes for each character",
          "Merge the dataset on episode, character, location, and script together.",
          "Extract script for a single episode",
          "Define a class for preprocessing the script data, extracting the script for each episode, and tokenizing the text for natural language processing.",
          "Concatenate location and episode in the script dataframe",
          "Selecting only lines from one specific episode",
          "Expanding the script lines to show Episode title and character name instead of their ids.",
          "Let's display the first 10 episodes and their corresponding IMDb rating.",
          "Filtering the script data for the episode number and the episode name",
          "Count the number of transcript lines per episode",
          "Create a new data frame containing only episode name, character name, and dialogue.",
          "join lines to attach the episode's title to the episode number",
          "Combine script lines and episodes dataframes so we can use episode information to analyze the script lines data.",
          "ronly listed episodes; verify that proper episodes included in download",
          "Function to get a character's lines in a specific episode",
          "Merge characters, locations, and episodes into a single dataframe using left join with scripts dataframe.",
          "Extract names of episodes",
          "Merge the episodes, locations, and script data into the characters dataframe and save it.",
          "Filter out episode length less than 20 lines",
          "Create a list of episodes.",
          " Extracting the text of each line along with its corresponding character, location, and episode title.",
          "Visualizing the length of the scripts per episode",
          "Link the script to the episode.",
          "Select episode 1, filter out non main characters and get the actual script",
          "Filter the script for only the episodes 1 to 3 of season 1.",
          "Create the list of scripts for each episode ID.",
          " Let's work with a smaller dataset containing only one episode script to demonstrate the analytical process.",
          "Remove stopwords from script lines and combine them by episode Id",
          "Filter out episodes older than 1990.",
          " Check if script line and episode have same id",
          " Merge the script lines with the characters, locations and episodes dataframe",
          "Count Number of lines for each Episode",
          "Filtering for just the title and ID of each episode.",
          "Check if the lines have the `character_id`, `location_id` and `episode_id` (where available) that match the `id` in the characters, locations, and episodes tables.",
          "Function to retrieve script for a specific episode",
          "[Optional] Remove characters who appear in less than 10 episodes.",
          "Join locations, script, and characters dataframes on the episode id",
          "Check that each episode in script_lines.csv refers to an actual episode.",
          "Extract the first 100,000 script lines and limit them to the first 50 episodes only",
          "Merge episodes with script in order to obtain episode data at every line's level.",
          "Filtering for the episode with the most lines and including only spoken lines",
          "Create episode transcripts by joining script lines on episode id and then\n# and then grouping by episode id aggregating text.",
          "Let's put the scipts together by episodes",
          "Ensure the episode is the full episode and not a short.",
          "Finding episode titles for each id in the dialogs dataset.",
          "provide the list of dates an episode first aired",
          "Insights\n# Let's take a closer look at the episodes first.",
          "Join scripts, characters, locations, and episodes in one dataframe",
          "Displaying scripts for the first episode",
          "Merge the episodes file with the script file so that each script line is associated with its corresponding episode.",
          " We transform the season and episode number of each script line to a unified format XYY\n# where X is the season number and YY is the episode number.",
          " Merge the characters, locations, episodes and script dataframes.",
          "Create a new column for script data that contains the episode data",
          "Combine script lines, characters, locations, and episodes into one dataframe.",
          "Combine characters, locations and episodes under a single dataframe",
          "Merge the script, episodes, characters and locations in one DataFrame",
          "Join characters, locations, script lines and episodes",
          "Filter out episode of length 0",
          " Select only the episodes corresponding to the first 8 seasons.",
          "We'll merge the two datasets to get the episode for each script line.",
          "Get the TV script of the episode with the most number of lines.",
          "Create a table with the title and the number of lines for each episode.",
          "Assign named spans to refer to specific episodes etc.",
          " Set the context for the analysis - the n-th episode and the minimum number of words for the lines",
          " Merge the dataset based on the character_id, episode_id from the scripts data.",
          "function to extract episode number from raw data",
          "Count of quotes per episode",
          " Check the number of existing episodes.",
          " For simplicity, let's concatenate all the lines in the script together, segmenting them by episode.",
          "Merge the characters, locations, episodes and scripts dataframes",
          "Create a list of all episode names",
          "To allow for better readability of the script lines, we will introduce a column representing the season and the episode number in the script lines dataframe.",
          "Join the data on episodes, script and characters",
          "Create separate dataframes for the different characters of the show",
          "According to the script data, each line is labeled with a character, and an episode.",
          "Create a column with all the script lines of an episode",
          "Merge the lines with the episodes",
          "Merge characters, locations and episodes in the scripts dataset for better analyzis",
          "Join the script lines with the characters, locations, and episodes dataframes.",
          " Let's count the number of script lines in each episode and store the result in a new dataframe.",
          "Merge characters, locations and episodes on script dataframe",
          "Extract script for each episode and each character",
          "Filter out the episodes which script lines are not present in the dataset",
          "Separate the script data by episodes.",
          "merge script lines with episodes and select character-based script lines",
          "Merge the dataframes that contain the scripts with the dataframes containing the characters and locations as well as the episodes.",
          "Extract all sentences said by a certain character in a specific episode.",
          "We will start cleaning and transforming the data starting by the episodes data frame.",
          "Remove duplicate script lines, and merge character, location, and episode data into the script data.",
          "Creating a series of episodes with their lines",
          "filter data for episode 1 of season 1 and for script type 'spoken'",
          " Selecting only the script for the first episode",
          "Find the season/episode with the most lines",
          "Filter for a specific episode, e.g., episode \"1\", and display the first 5 lines",
          " Create a list of episode titles",
          "Create dictionary for episode titles",
          "Extract the script for a single episode.",
          "Select one or more episodes to analyze\nepisodes = [\n    'noir'\n]",
          "Ensure the script and episodes have the same number of seasons, with the season/episode format consistent across both datasets.",
          " Joining the scripts with the episodes on the episode id",
          "We need to fix the episode title - some of the titles from the script data frame have additional information about the season and episode numbers. We need to remove this information.",
          "Define the most likely episode length in minutes from 15 to 30 minutes",
          "Create a version of the script dataframe which joins the character, location, and episode details with each line.",
          "Extract character lines from the script dataframe and join the location and episode names",
          " function to get the script lines for a certain episode"
         ],
         "marker": {
          "opacity": 0.5,
          "size": 5
         },
         "mode": "markers+text",
         "name": "0_Extracting and Combining Script and Episode Information",
         "text": [
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          ""
         ],
         "textfont": {
          "size": 12
         },
         "type": "scattergl",
         "x": [
          8.001355171203613,
          8.271493911743164,
          8.153094291687012,
          8.894357681274414,
          8.132558822631836,
          7.195357322692871,
          8.153779029846191,
          6.969639778137207,
          8.04898738861084,
          7.909270763397217,
          7.489981651306152,
          6.660952091217041,
          7.442967891693115,
          8.656026840209961,
          7.7703633308410645,
          8.699627876281738,
          6.776883125305176,
          6.78847599029541,
          8.701605796813965,
          8.087881088256836,
          8.128769874572754,
          7.222953796386719,
          7.501611232757568,
          8.160228729248047,
          7.322238922119141,
          8.213996887207031,
          7.31245756149292,
          6.255224227905273,
          8.07193660736084,
          7.61431884765625,
          7.689499378204346,
          6.855495929718018,
          7.983409404754639,
          7.723083019256592,
          6.932191371917725,
          7.590373516082764,
          8.297103881835938,
          6.799391746520996,
          8.098188400268555,
          7.620375156402588,
          7.358356475830078,
          7.457259654998779,
          7.653744697570801,
          7.334331035614014,
          8.004785537719727,
          6.802923202514648,
          6.4608845710754395,
          8.835532188415527,
          6.816882133483887,
          6.968323707580566,
          7.774927139282227,
          8.458626747131348,
          7.012388229370117,
          8.006423950195312,
          8.59682559967041,
          7.582086563110352,
          8.13839054107666,
          7.844398021697998,
          7.1651291847229,
          6.926026344299316,
          8.06181526184082,
          7.289587497711182,
          7.129960536956787,
          7.254480838775635,
          8.06644058227539,
          7.200395584106445,
          7.710543632507324,
          7.573829650878906,
          7.952116012573242,
          6.680609703063965,
          8.33184814453125,
          7.468496322631836,
          7.227197170257568,
          8.40577507019043,
          7.5561347007751465,
          7.598299503326416,
          7.048924922943115,
          6.7099103927612305,
          7.101012706756592,
          6.921056747436523,
          7.062860488891602,
          8.232897758483887,
          7.684875011444092,
          7.79793119430542,
          7.421689033508301,
          6.823570251464844,
          6.949769020080566,
          6.566962718963623,
          6.454708099365234,
          7.899911880493164,
          7.734919548034668,
          7.606761932373047,
          7.0878520011901855,
          8.35309886932373,
          7.670788764953613,
          6.428861141204834,
          7.903417110443115,
          6.794256687164307,
          6.3150858879089355,
          7.6001386642456055,
          6.804973602294922,
          8.091889381408691,
          7.260283470153809,
          6.867854118347168,
          7.500836372375488,
          7.19700813293457,
          6.182044506072998,
          8.29129695892334,
          7.568701267242432,
          7.428403377532959,
          8.029218673706055,
          8.031688690185547,
          7.022019863128662,
          7.140070915222168,
          7.909090042114258,
          7.481369972229004,
          7.557229042053223,
          7.874636173248291,
          7.238137245178223,
          8.444520950317383,
          6.292199611663818,
          7.740353584289551,
          7.715421199798584,
          7.813126564025879,
          7.761776447296143,
          8.443942070007324,
          7.610264778137207,
          6.583188056945801,
          5.825473785400391,
          7.890478134155273,
          7.472600936889648,
          7.447759628295898,
          7.3055925369262695,
          8.296835899353027,
          7.669892311096191,
          7.0625529289245605,
          7.499730110168457,
          8.322916030883789
         ],
         "y": [
          4.0147705078125,
          6.261305809020996,
          4.318277835845947,
          5.521343231201172,
          5.52665901184082,
          3.8455300331115723,
          5.329218864440918,
          3.620751142501831,
          4.371535301208496,
          4.731654167175293,
          3.89094877243042,
          4.589592456817627,
          4.250629425048828,
          5.231553077697754,
          4.772973537445068,
          4.917097091674805,
          3.6221139430999756,
          3.539445400238037,
          4.102296829223633,
          3.6882219314575195,
          4.763429641723633,
          4.468020915985107,
          4.629143714904785,
          4.127105712890625,
          4.181468963623047,
          3.879889726638794,
          4.037776947021484,
          3.424384117126465,
          3.2549221515655518,
          4.563323020935059,
          4.341230869293213,
          4.182024955749512,
          3.688135862350464,
          5.02170991897583,
          3.4495346546173096,
          3.821357011795044,
          4.534430980682373,
          3.336867570877075,
          5.192807197570801,
          4.215517044067383,
          4.4365458488464355,
          4.223029136657715,
          5.509550094604492,
          4.89163875579834,
          4.793528079986572,
          3.901928186416626,
          4.054940700531006,
          5.033050060272217,
          3.438457489013672,
          4.550998210906982,
          4.321037292480469,
          4.964536666870117,
          4.800530910491943,
          4.597064018249512,
          5.19134521484375,
          3.205970525741577,
          4.277426242828369,
          3.6787168979644775,
          3.667250394821167,
          3.5668957233428955,
          3.9085922241210938,
          4.338669300079346,
          4.114305019378662,
          3.775148868560791,
          5.543735504150391,
          4.152053356170654,
          4.461298942565918,
          3.8608028888702393,
          4.693259239196777,
          4.143017768859863,
          4.012217998504639,
          4.205394268035889,
          4.2797417640686035,
          5.595421314239502,
          4.868990421295166,
          4.2602715492248535,
          4.148853302001953,
          4.42343282699585,
          4.218862056732178,
          3.9082462787628174,
          3.7222139835357666,
          3.7254860401153564,
          3.554490327835083,
          4.421138286590576,
          3.6324079036712646,
          4.5067291259765625,
          3.966451644897461,
          3.402811288833618,
          3.4289987087249756,
          4.273307800292969,
          4.7781805992126465,
          3.792370319366455,
          3.4730660915374756,
          5.1889448165893555,
          5.437040328979492,
          4.729063987731934,
          5.31393575668335,
          3.7277026176452637,
          4.631911277770996,
          5.354448318481445,
          4.2968621253967285,
          4.472227096557617,
          3.539909601211548,
          4.842868804931641,
          4.178203105926514,
          4.301109790802002,
          3.9460160732269287,
          4.7186055183410645,
          4.713593482971191,
          4.405627250671387,
          3.461956262588501,
          4.882087230682373,
          4.397831916809082,
          3.5903332233428955,
          4.369413375854492,
          4.60880184173584,
          3.9603171348571777,
          4.344574451446533,
          4.039867401123047,
          4.926844596862793,
          3.22230863571167,
          3.840758800506592,
          4.702651500701904,
          5.088316917419434,
          3.744635820388794,
          5.14218282699585,
          4.979207992553711,
          4.709868431091309,
          4.908449172973633,
          3.523580551147461,
          4.705760955810547,
          3.773395538330078,
          3.9516279697418213,
          4.394542217254639,
          5.501856803894043,
          4.63823127746582,
          4.4463653564453125,
          4.250304698944092
         ]
        },
        {
         "hoverinfo": "text",
         "hovertext": [
          "Display the first few rows of the characters dataframe\ndf_characters.head()",
          "Display the first few rows of the characters dataframe\ndf_characters.head()",
          " Display the first few rows of the characters dataframe\ndf_characters.head()",
          "Display the first few rows of the characters DataFrame\ndf_characters.head()",
          "Display the first few rows of the characters dataframe\ndf_characters.head()",
          "Display the first few rows of the characters dataframe\ndf_characters.head()",
          "Display the first few rows of the characters dataframe\ndf_characters.head()",
          "Display the first few rows of the characters dataframe\ndf_characters.head()",
          " Display the first few rows of the characters dataframe\ndf_characters.head()",
          "Display the first few rows of the characters dataframe\ndf_characters.head()",
          " Display the first few rows of the characters dataframe\ndf_characters.head()",
          "Display the first few rows of the characters DataFrame\ndf_characters.head()",
          " Display the first few rows of the characters dataframe\ndf_characters.head()",
          " Display the first few rows of the characters dataframe.\ndf_characters.head()",
          "Display the first few rows of the characters dataframe\ndf_characters.head()",
          "Displays the first few rows of the df_characters DataFrame\ndf_characters.head()",
          "Display the first few rows of the characters dataframe\ndf_characters.head()",
          "Display the first few rows of the character dataframe\ndf_characters.head()",
          " Display the first few rows of the characters dataframe\ndf_characters.head()",
          "Display the first few rows of the characters DataFrame\ndf_characters.head()",
          "Display the first few rows of the characters dataframe\ndf_characters.head()",
          " Display the first few rows of the characters dataframe\ndf_characters.head()",
          " Display the first few rows of the characters DataFrame\ndf_characters.head()",
          "Print first few rows of `df_characters`\ndf_characters.head()",
          "Display the first few rows of the characters dataframe\ndf_characters.head()",
          " Display the first few rows of the characters dataframe\ndf_characters.head()",
          " Display the first few rows of the characters dataframe\ndf_characters.head()",
          " Display the first few rows of the characters dataframe\ndf_characters.head()",
          "Display the first few rows of the characters dataframe\ndf_characters.head()",
          "Display the first few rows of the characters dataframe\ndf_characters.head()",
          "Display the first few rows of the characters DataFrame\ndf_characters.head()",
          "Print the first few rows of the characters dataframe\ndf_characters.head()",
          "Display the first few rows of the characters dataframe\ndf_characters.head()",
          "Display the first few rows of the characters dataframe\ndf_characters.head()",
          "Display the first few rows of the characters dataframe\ndf_characters.head()",
          " Display the first few rows of the characters dataframe\ndf_characters.head()",
          " Display the first few rows of the characters dataframe\ndf_characters.head()",
          "Display the first few rows of the characters dataframe\ndf_characters.head()",
          "Display the first few rows of the characters dataframe\ndf_characters.head()",
          "Display the first few rows of the characters dataframe\ndf_characters.head()",
          "Display the first few rows of the characters dataframe\ndf_characters.head()",
          "display the first few rows of the characters dataframe\ndf_characters.head()",
          "Display a few rows of the characters DataFrame\ndf_characters.head()",
          " Display the first few rows of the dataframe for characters\ndf_characters.head()",
          " Display the first few rows of the characters dataframe\ndf_characters.head()",
          "Display the first few rows of the characters dataframe\ndf_characters.head()",
          "Display the first few rows of the characters dataframe\ndf_characters.head()",
          "Display the first few rows of the characters dataframe\ndf_characters.head()",
          " Display the first few rows of the characters dataframe\ndf_characters.head()",
          " Display the first few rows of the characters data frame\ndf_characters.head()",
          "Display the first few rows of the characters DataFrame\ndf_characters.head()",
          "Display the first few rows of the characters dataframe\ndf_characters.head()",
          " Display the first few rows of the characters dataframe\ndf_characters.head()",
          "Display the first few rows of the characters dataframe\ndf_characters.head()",
          "# Print the first few rows of the dataframe\ndf_characters.head()",
          "Display the first few rows of the characters dataframe\ndf_characters.head()",
          " Display the first few rows of the characters dataframe\ndf_characters.head()",
          " Display the first few rows of the characters dataframe\ndf_characters.head()",
          "Display the first few rows of the characters dataframe\ndf_characters.head()",
          " Display the first few rows of the characters dataframe\ndf_characters.head()",
          " Display the first few rows of the characters dataframe\ndf_characters.head()",
          "Display the first few rows of the characters dataframe\ndf_characters.head()",
          "Display the first few rows of the characters dataframe\ndf_characters.head()",
          "Display the first few rows of the characters dataframe\ndf_characters.head()",
          "Display the first few rows of the characters dataframe\ndf_characters.head()",
          "Display the first few rows of the characters dataframe\ndf_characters.head()",
          "Display the first few rows of the characters dataframe\ndf_characters.head()",
          " Display the first few rows of the characters dataframe\ndf_characters.head()",
          " Display the first few rows of the characters dataframe\ndf_characters.head()",
          "Display the first few rows of the characters dataframe\ndf_characters.head()",
          " Display the first few rows of the character dataframe\ndf_characters.head()",
          "Display the first few rows of the characters dataframe\ndf_characters.head()",
          "Display the first few rows of the characters dataframe\ndf_characters.head()",
          "Display the first few rows of the characters dataframe\ndf_characters.head()",
          " Display the first few rows of the dataframe for characters\ndf_characters.head()",
          "Display the first few rows of the characters DataFrame\ndf_characters.head()",
          "Display the first few rows of the characters dataframe\ndf_characters.head()",
          "Display the first few rows of the characters dataframe\ndf_characters.head()",
          "Display the first few rows of the characters dataframe\ndf_characters.head()",
          " Display the first few rows of the characters dataframe\ndf_characters.head()",
          " Display the first few rows of the characters dataframe\ndf_characters.head()",
          " Display the first few rows of the characters DataFrame\ndf_characters.head()",
          "Display the first few rows of the characters dataframe\ndf_characters.head()",
          " Display the first few rows of the characters dataframe\ndf_characters.head()",
          "Display the first few rows of the characters dataframe\ndf_characters.head()",
          "Print the first few rows of the characters dataframe\ndf_characters.head()",
          " Display the first few rows of the characters dataframe\ndf_characters.head()",
          "Display the first few rows of the characters dataframe\ndf_characters.head()",
          "Display the first few rows of the characters DataFrame\ndf_characters.head()",
          " Display the first few rows of the characters DataFrame\ndf_characters.head()",
          " Display the first few rows of the characters dataframe\ndf_characters.head()",
          " Display the first few rows of the characters DataFrame\ndf_characters.head()",
          "Display the first few rows of the characters dataframe\ndf_characters.head()",
          "display the first few rows of the characters dataframe\ndf_characters.head()",
          "Display the first few rows of the characters dataframe\ndf_characters.head()",
          "Display the first few rows of the characters dataframe\ndf_characters.head()",
          "Display the first few rows of the characters data frame\ndf_characters.head()",
          "Display the first few rows of the character dataframe\ndf_characters.head()",
          "Display the first few rows of the characters dataframe\ndf_characters.head()",
          "Display the first few rows of the characters dataframe\ndf_characters.head()",
          " Display the first few rows of the characters dataframe\ndf_characters.head()",
          " Display the first few rows of the characters DataFrame\ndf_characters.head()",
          "Display the first few rows of the characters dataframe\ndf_characters.head()",
          " Display the first few rows of the characters dataframe\ndf_characters.head()",
          " Display the first few rows of the characters dataframe\ndf_characters.head()",
          "Display the first few rows of the characters dataframe\ndf_characters.head()",
          " Display the first few rows of the character dataframe\ndf_characters.head()",
          "Display the first few rows of the characters dataframe\ndf_characters.head()",
          " Display the first few rows of the characters dataframe\ndf_characters.head()",
          " Display the first few rows of the characters DataFrame\ndf_characters.head()",
          "Display the first few rows of the characters dataframe\ndf_characters.head()",
          "Display the first few rows of the characters dataframe\ndf_characters.head()",
          "Display the first few rows of the characters dataframe\ndf_characters.head()",
          "Display the first few rows of the characters dataframe\ndf_characters.head()",
          " display the first few rows of the characters dataframe\ndf_characters.head()",
          " Display the first few rows of the characters dataframe\ndf_characters.head()",
          " Display the first few rows of the characters DataFrame\ndf_characters.head()",
          " Display the first few rows of the characters dataframe\ndf_characters.head()",
          "Display the first few rows of the characters dataframe\ndf_characters.head()",
          " Display the first few rows of the characters dataframe\ndf_characters.head()",
          "Display the first few rows of the characters dataframe\ndf_characters.head()",
          " Display the first few rows of the characters DataFrame\ndf_characters.head()",
          "Display the first few rows of the characters DataFrame\ndf_characters.head()",
          "Display the first few rows of the characters dataframe\ndf_characters.head()",
          "Display the first few rows of the characters dataframe\ndf_characters.head()",
          " Display the first few rows of the characters dataframe\ndf_characters.head()",
          "Display the first few rows of the characters dataframe\ndf_characters.head()",
          "Display the first few rows of the characters DataFrame\ndf_characters.head()",
          " Display the first few rows of the characters dataframe\ndf_characters.head()",
          " Display the first few rows of the characters dataframe\ndf_characters.head()",
          "Display the first few rows of the characters dataframe\ndf_characters.head()",
          "To view the first few rows of the characters data frame\ndf_characters.head()",
          "Display the first few rows of the characters dataframe\ndf_characters.head()",
          "Display the first few rows of the characters dataframe\ndf_characters.head()",
          "Print the first few rows of the characters dataframe\ndf_characters.head()",
          " Display the first few rows of the characters dataframe\ndf_characters.head()"
         ],
         "marker": {
          "opacity": 0.5,
          "size": 5
         },
         "mode": "markers+text",
         "name": "1_Display first few rows of characters dataframe",
         "text": [
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          ""
         ],
         "textfont": {
          "size": 12
         },
         "type": "scattergl",
         "x": [
          -4.727355003356934,
          -4.085472106933594,
          -4.165167808532715,
          -3.3765454292297363,
          -3.8692214488983154,
          -3.7374420166015625,
          -3.8408265113830566,
          -4.101683616638184,
          -3.2811055183410645,
          -4.048303127288818,
          -3.5134449005126953,
          -3.586803913116455,
          -3.503445863723755,
          -3.9851596355438232,
          -4.481265544891357,
          -3.473086357116699,
          -3.5238454341888428,
          -4.949301719665527,
          -3.4127109050750732,
          -4.156800746917725,
          -4.156387805938721,
          -3.0085318088531494,
          -4.254471778869629,
          -3.534965753555298,
          -3.55765438079834,
          -3.9757237434387207,
          -3.9688961505889893,
          -4.454394340515137,
          -2.8373777866363525,
          -3.3883168697357178,
          -3.26470947265625,
          -3.685236930847168,
          -4.3341240882873535,
          -4.629515647888184,
          -3.358623743057251,
          -3.761136293411255,
          -4.122324466705322,
          -4.624546051025391,
          -4.193612098693848,
          -3.3296992778778076,
          -4.366314888000488,
          -4.525259971618652,
          3.3673360347747803,
          -3.5146424770355225,
          -2.9873859882354736,
          -3.9594807624816895,
          -4.104717254638672,
          -4.2487945556640625,
          -3.9489619731903076,
          -2.65193772315979,
          -3.6668574810028076,
          -3.3789994716644287,
          -3.906998872756958,
          -4.158134937286377,
          -3.218007802963257,
          -3.8264880180358887,
          -4.165659427642822,
          -3.953364133834839,
          -3.3708393573760986,
          -3.733456611633301,
          -4.238859176635742,
          -4.37152624130249,
          -3.533054828643799,
          -3.5886824131011963,
          -4.610813617706299,
          -3.3313870429992676,
          -3.5601930618286133,
          -3.231461524963379,
          -4.59515380859375,
          -4.46054220199585,
          -4.489321708679199,
          -2.871882915496826,
          -4.1148858070373535,
          -3.817028522491455,
          -3.349295139312744,
          -3.5202982425689697,
          -3.7613861560821533,
          -3.7751917839050293,
          -3.6912448406219482,
          -3.0465760231018066,
          -4.8951029777526855,
          -4.451329231262207,
          -4.126612663269043,
          -3.6719303131103516,
          -3.113346576690674,
          -3.6231489181518555,
          -3.6027231216430664,
          -4.254561424255371,
          -3.6825692653656006,
          -4.156991004943848,
          -4.3577752113342285,
          -3.3021185398101807,
          -4.238563060760498,
          -3.911083459854126,
          -4.5613112449646,
          -3.419916868209839,
          -2.7083752155303955,
          -4.483255386352539,
          -4.55729866027832,
          -3.4623947143554688,
          -3.1822986602783203,
          -4.0492634773254395,
          -4.024726867675781,
          -4.452389240264893,
          -3.807063341140747,
          -3.95265531539917,
          -4.36599063873291,
          -3.6298587322235107,
          -3.092782497406006,
          -3.7819743156433105,
          -4.227714538574219,
          -4.391412258148193,
          -3.796924114227295,
          -4.343094348907471,
          -3.3483989238739014,
          -3.2250418663024902,
          -3.580901622772217,
          -3.095029354095459,
          -3.4677302837371826,
          -3.8820905685424805,
          -3.9595770835876465,
          -3.8980801105499268,
          -3.2815542221069336,
          -3.6556341648101807,
          -3.5024499893188477,
          -4.024379730224609,
          -4.640254497528076,
          -3.5026214122772217,
          -4.335265159606934,
          -3.3515002727508545,
          -3.2805025577545166,
          -1.724038004875183,
          -3.1018054485321045,
          -4.093378067016602,
          -3.6214585304260254,
          -3.173121929168701
         ],
         "y": [
          22.56713104248047,
          22.278257369995117,
          22.279651641845703,
          22.606666564941406,
          23.404993057250977,
          23.705944061279297,
          22.144432067871094,
          23.155019760131836,
          23.192028045654297,
          23.37641143798828,
          22.18726348876953,
          22.75426483154297,
          21.925230026245117,
          22.742830276489258,
          23.539857864379883,
          23.68805694580078,
          23.485397338867188,
          22.778474807739258,
          22.38134765625,
          22.957788467407227,
          23.899490356445312,
          22.737510681152344,
          22.431289672851562,
          20.6270694732666,
          22.680370330810547,
          22.638532638549805,
          23.144237518310547,
          22.3631591796875,
          22.691864013671875,
          22.610515594482422,
          23.53096580505371,
          20.890256881713867,
          23.730602264404297,
          22.58477020263672,
          22.34882354736328,
          23.05929183959961,
          23.014022827148438,
          23.03848648071289,
          23.360183715820312,
          23.502397537231445,
          22.782333374023438,
          22.873210906982422,
          18.521263122558594,
          22.779308319091797,
          23.327411651611328,
          22.72795867919922,
          23.586990356445312,
          22.78534698486328,
          22.320096969604492,
          22.374134063720703,
          23.458181381225586,
          22.419160842895508,
          23.34591293334961,
          22.41565704345703,
          20.53725814819336,
          22.504858016967773,
          22.718671798706055,
          22.845195770263672,
          22.134689331054688,
          22.88243293762207,
          22.817272186279297,
          23.598365783691406,
          23.164939880371094,
          23.164508819580078,
          22.791715621948242,
          23.314428329467773,
          23.076539993286133,
          22.971717834472656,
          22.553741455078125,
          22.686838150024414,
          23.043405532836914,
          23.15809440612793,
          23.116525650024414,
          23.69277000427246,
          22.68631362915039,
          22.81048011779785,
          22.692100524902344,
          22.828914642333984,
          23.070890426635742,
          23.29450798034668,
          22.74783706665039,
          22.94149398803711,
          23.838775634765625,
          22.113927841186523,
          22.598073959350586,
          21.002532958984375,
          22.017803192138672,
          23.128185272216797,
          23.277429580688477,
          23.672555923461914,
          22.02068328857422,
          22.650083541870117,
          22.087112426757812,
          22.702280044555664,
          22.650272369384766,
          22.56951141357422,
          21.83609962463379,
          23.07091522216797,
          23.235933303833008,
          23.591033935546875,
          22.827783584594727,
          22.91971206665039,
          23.209367752075195,
          22.417877197265625,
          22.35200309753418,
          23.077354431152344,
          22.94257164001465,
          22.319469451904297,
          22.27820587158203,
          23.36231231689453,
          23.74229621887207,
          22.132110595703125,
          22.54785919189453,
          23.4271183013916,
          23.66170310974121,
          23.328527450561523,
          22.861679077148438,
          23.087263107299805,
          23.11417007446289,
          23.407752990722656,
          23.18048667907715,
          22.310195922851562,
          23.272424697875977,
          23.657787322998047,
          22.898799896240234,
          22.575956344604492,
          22.95118522644043,
          23.4205379486084,
          22.633750915527344,
          21.972320556640625,
          22.899499893188477,
          20.99467658996582,
          22.016136169433594,
          23.278905868530273,
          21.05875015258789,
          22.52427864074707
         ]
        },
        {
         "hoverinfo": "text",
         "hovertext": [
          "Merge all data into one dataframe\ndf_merged = df_script.merge(df_characters, on='character_id', suffixes=('', '_character'))\ndf_merged = df_merged.merge(df_locations, on='location_id', suffixes=('', '_location'))\ndf_merged = df_merged.merge(df_episodes, on='episode_id', suffixes=('', '_episode'))",
          "Minimum data\ndf_script = df_script.dropna(subset=['character_id', 'location_id'])\n\n# Merge the data\ndf_script = df_script.merge(\n    df_episodes[['id', 'title', 'original_air_date']],\n    how='left', left_on='episode_id', right_on='id'\n).merge(\n    df_characters[['id', 'character_name']],\n    how='left', left_on='character_id', right_on='id'\n).merge(\n    df_locations[['id', 'location_name']],\n    how='left', left_on='location_id', right_on='id'\n)",
          "Merge the datasets to add more dimensions to the data analysis\ndf_script_ext = pd.merge(\n    pd.merge(\n        pd.merge(df_script, df_characters, on='character_id', how='left'),\n        df_episodes,\n        on='episode_id',\n        how='left'\n    ),\n    df_locations,\n    on='location_id',\n    how='left'\n)",
          "Merge with datasets with script\ndf_merged = df_script.merge(df_episodes, on='episode_id', suffixes=('_script', '_episode'))\ndf_merged = df_merged.merge(df_characters, on='character_id', suffixes=('_merged', '_character'))\ndf_merged = df_merged.merge(df_locations, on='location_id', suffixes=('_merged', '_location'))",
          " Merge script lines with characters, locations and episodes\ndf_script = df_script.merge(df_characters, left_on='character_id', right_on='id', suffixes=['_script', '_character'], how='left')\ndf_script = df_script.merge(df_locations, left_on='location_id', right_on='id', suffixes=['_script', '_location'], how='left')\ndf_script = df_script.merge(df_episodes, left_on='episode_id', right_on='id', suffixes=['_script', '_episode'], how='left')",
          "Merge all into one\ndf_simpsons = (df_script\n                .merge(df_episodes, on='episode_id', how='inner')\n                .merge(df_characters, on='character_id', how='inner')\n                .merge(df_locations, on='location_id', how='inner'))",
          "# Merge scripts, characters and locations\ndf_temp = pd.merge(df_script, df_episodes, on='episode_id')\ndf_temp = pd.merge(df_temp, df_characters, left_on='character_id', right_on='id', suffixes=('', '_character')).drop(columns='id')\ndf_temp = pd.merge(df_temp, df_locations, left_on='location_id', right_on='id', suffixes=('', '_location')).drop(columns='id')",
          "Join the data together\ndf = (df_script\n      .merge(df_episodes, on='episode_id', suffixes=('_script', 'ep'))\n      .merge(df_characters, on='character_id', suffixes=('_ep', 'char'))\n      .merge(df_locations, on='location_id', suffixes=('_char', 'loc'))\n     )",
          "Merge the datasets\ndf_characters = pd.merge(df_characters, df_script, left_on='id', right_on='character_id')\ndf_characters = pd.merge(df_characters, df_episodes, left_on='episode_id', right_on='id')\ndf_characters = pd.merge(df_characters, df_locations, left_on='location_id', right_on='id')",
          "Combine character and location information with script data\ndf_merged = df_script.merge(df_episodes, left_on='episode_id', right_on='id', suffixes=('', '_episode'))\ndf_merged = df_merged.merge(df_characters, left_on='character_id', right_on='id', suffixes=('', '_character'))\ndf_merged = df_merged.merge(df_locations, left_on='location_id', right_on='id', suffixes=('', '_location'))",
          "Merge scripts with characters and locations\ndf_script = df_script.merge(df_characters, left_on='character_id', right_on='id', suffixes=('','_char'), validate=\"many_to_one\")\ndf_script = df_script.merge(df_locations, left_on='location_id', right_on='id', suffixes=('','_loc'), validate=\"many_to_one\")\n\n# Shorten the character and location dataframes for merging\ndf_characters = df_characters[['id', 'name']]\ndf_locations = df_locations[['id', 'name']]\n\n# Merge into one dataframe\n# df_episodes[df_episodes.id==30] # Example of how to extract a specific id\ndf = df_script.merge(df_episodes, left_on='episode_id', right_on='id', suffixes=('','_ep'), validate=\"many_to_one\")",
          "Merge character, location and episode data into script data\ndf_script = df_script.merge(df_characters, how='left', left_on='character_id', right_on='id', suffixes=('', '_character'))\ndf_script = df_script.merge(df_locations, how='left', left_on='location_id', right_on='id', suffixes=('', '_location'))\ndf_script = df_script.merge(df_episodes, how='left', left_on='episode_id', right_on='id', suffixes=('', '_episode'))",
          "merge the dataframes on episode_id\ndf = pd.merge(df_script, df_episodes, how='left', on='episode_id')\ndf = pd.merge(df, df_characters, how='left', left_on='raw_character_text', right_on='normalized_name')\ndf = pd.merge(df, df_locations, how='left', left_on='raw_location_text', right_on='normalized_name')",
          "Prepare data\n# Merge the datasets\ndf_all = pd.merge(df_script, df_episodes, how='left', on='episode_id')\ndf_all = pd.merge(df_all, df_characters, how='left', on='character_id')\ndf_all = pd.merge(df_all, df_locations, how='left', on='location_id')",
          "Merge the script with the characters and locations\ndf_script = df_script.merge(df_episodes, on='episode_id', how='left').merge(df_characters, on='character_id', how='left').merge(df_locations, on='location_id', how='left')",
          "\n# Merge dataframes to create a unified dataframe for analysis\ndf_merged = pd.merge(df_script, df_episodes, on='episode_id', how='inner')\ndf_merged = pd.merge(df_merged, df_characters, on='character_id', how='inner')\ndf_merged = pd.merge(df_merged, df_locations, on='location_id', how='inner')\n\n# Output the first few rows of the merged dataframe\ndf_merged.head()",
          "Merge the dataframes into a single dataframe for analysis\ndf_merged = df_script.merge(df_episodes, on='episode_id')\r\ndf_merged = df_merged.merge(df_characters, on='character_id')\r\ndf_merged = df_merged.merge(df_locations, on='location_id')",
          " Merge character, location and episode data into main dataframe for analysis\n# Merge on 'id' in 'df_script' and character_id in 'df_characters'\ndf_merged = df_script.merge(df_characters, left_on='character_id', right_on='id', suffixes=['_script', '_character'])\n\n# Merge on 'id' in previous merge result and 'episode_id' in 'df_episodes'\ndf_merged = df_merged.merge(df_episodes, left_on='episode_id', right_on='id', suffixes=['_merged', '_episode'])\n\n# Merge on 'location_id' in previous merge result and 'id' in 'df_locations'\ndf_merged = df_merged.merge(df_locations, left_on='location_id', right_on='id', suffixes=['_previous', '_location'])",
          "left join location, episode to script \ndf_merged = df_script.join(df_episodes.set_index('id'), on='episode_id') \ndf_merged = df_merged.join(df_locations.set_index('id'), on='location_id')",
          "Merge episodes data with characters data\ndf = df_script.merge(df_episodes, on='episode_id').merge(df_characters, on='character_id').merge(df_locations, on='location_id')",
          "Merge data for a more comprehensive analysis\ndf_merged = pd.merge(df_script, df_episodes, on='episode_id')\ndf_merged = pd.merge(df_merged, df_characters, on='character_id')\ndf_merged = pd.merge(df_merged, df_locations, on='location_id')",
          "Keep short only the ones that are useful to avoid cluttering when making predictions from the script\nshort_cols = ['id', 'character_id', 'location_id', 'episode_id', 'raw_text']\n\n# Keep only the useful columns\ndf_script = df_script[short_cols]\n\n# Add episode related data\ndf_script = df_script.merge(df_episodes,\n                            how='left',\n                            on='episode_id')",
          " Merge the script lines with the characters, locations, and episodes datasets\ndf_script = df_script.merge(df_characters, on='character_id', how='left')\ndf_script = df_script.merge(df_locations, on='location_id', how='left')\ndf_script = df_script.merge(df_episodes, on='episode_id', how='left')",
          "Join the script dataframe with the rest of the dataframes\n# This way we can get the right character, location and episode ids for each line of the scripts\ndf_script = df_script\\\n    .join(df_characters, on='character_id', rsuffix='_character')\\\n    .join(df_locations, on='location_id', rsuffix='_location')\\\n    .join(df_episodes, on='episode_id', rsuffix='_episode')",
          "Merge the data into a single dataframe\ndf = (\n    df_script\n    .merge(df_characters, how='left', left_on='character_id', right_on='id', suffixes=('', '_character'))\n    .merge(df_locations, how='left', left_on='location_id', right_on='id', suffixes=('', '_location'))\n    .merge(df_episodes, how='left', left_on='episode_id', right_on='id', suffixes=('', '_episode'))\n)",
          "remove all redundant data in the script data\nscript_reduced_columns = df_script[['episode_id', 'number', 'raw_text', 'character_id', 'location_id']]\nscript_reduced_columns = script_reduced_columns.dropna()\n\nscript_merged = pd.merge(script_reduced_columns, df_characters, left_on='character_id', right_on='id')\nscript_merged = pd.merge(script_merged, df_locations, left_on='location_id', right_on='id')\n\nscript_merged = script_merged[['episode_id', 'number', 'raw_text', 'character_id', 'location_id', 'normalized_name_x', 'name_x', 'normalized_name_y', 'name_y']]\nscript_merged.columns = ['episode_id', 'number', 'raw_text', 'character_id', 'location_id', 'character_name_normalized', 'character_name', 'location_name_normalized', 'location_name']\n\nscript_merged[:5]",
          " Merge Simpsons script with episodes and characters\ndf = df_script.merge(df_episodes, on='episode_id', how='left').merge(df_characters, left_on='character_id', right_on='id', how='left').merge(df_locations, left_on='raw_location_id', right_on='id', how='left')",
          "\n# Merge the dataframes\ndf_script = df_script.merge(df_episodes, on='episode_id', how='left', suffixes=('_script', '_episode'))\ndf_script = df_script.merge(df_locations, on='location_id', how='left', suffixes=('_script', '_location'))\ndf_script = df_script.merge(df_characters, on='character_id', how='left', suffixes=('_script', '_character'))",
          "Merge script lines with relevant information about episodes, characters, and locations\ndf_merged = df_script.merge(df_episodes, on='episode_id', how='left')\ndf_merged = df_merged.merge(df_characters, on='character_id', how='left')\ndf_merged = df_merged.merge(df_locations, on='location_id', how='left')",
          " merge to get speaker/line/episode information\ndf_merged = df_script.merge(df_episodes, on='episode_id')\ndf_merged = df_merged.merge(df_characters, on='character_id')\ndf_merged = df_merged.merge(df_locations, on='location_id')",
          " Merge main dataframe with characters and locations\ndf_merged = pd.merge(df_script, df_episodes, on='episode_id', how='left')\ndf_merged = pd.merge(df_merged, df_characters, left_on='character_id', right_on='id', how='left')\ndf_merged = pd.merge(df_merged, df_locations, left_on='location_id', right_on='id', how='left')",
          "Merge data\ndf_characters_script = df_script.merge(df_characters, how='left')\ndf_script_merged = df_characters_script.merge(df_episodes, how='left')",
          " Join all tables to determine what characters are in what episodes\ndf_char_episode = df_script.merge(df_episodes[['id', 'title']], left_on='episode_id', right_on='id', suffixes=('_script', '_episode'))\ndf_char_episode = df_char_episode.merge(df_characters, left_on='character_id', right_on='id', suffixes=('_ce', '_character'))\ndf_char_episode = df_char_episode.merge(df_locations, left_on='location_id', right_on='id', suffixes=('_ce', '_location'))",
          "Filter columns\ndf_script = df_script[['episode_id', 'number', 'raw_text', 'character_id', 'location_id']].copy()\n\n# Merge the tables\ndf = df_script.copy()\ndf = df.merge(df_episodes, left_on='episode_id', right_on='id')\ndf = df.merge(df_characters, left_on='character_id', right_on='id')\ndf = df.merge(df_locations, left_on='location_id', right_on='id')\n\n# Save for later use\ndf.to_csv('data/merged_simpsons_dataset.csv', index=False)",
          " Merge scripts with corresponding episode data\ndf = df_script.join(df_episodes, on='episode_id', rsuffix='_ep')\ndf = df.join(df_characters, on='character_id', rsuffix='_ch')\ndf = df.join(df_locations, on='location_id', rsuffix='_loc')\n\n# Preview the dataset\ndf.head()",
          "Data organization\ndf_script = df_script.merge(df_episodes, on='episode_id', how='left')\ndf_script = df_script.merge(df_characters, on='character_id', how='left')\ndf_script = df_script.merge(df_locations, on='location_id', how='left')",
          "Merge relevant columns from the other DataFrames into the main df_script DataFrame\ncols_characters = [\"id\",\"name\",\"normalized_name\",\"gender\"]\ncols_locations = [\"id\",\"name\",\"normalized_name\"]\ncols_episodes = [\"id\",\"title\",\"original_air_date\"]\n\ndf_script = pd.merge(df_script, df_characters[cols_characters], left_on=\"character_id\", right_on=\"id\", suffixes=(\"\", \"_character\")).drop(columns=[\"id\"])\ndf_script = pd.merge(df_script, df_locations[cols_locations], left_on=\"location_id\", right_on=\"id\", suffixes=(\"\", \"_location\")).drop(columns=[\"id\"])\ndf_script = pd.merge(df_script, df_episodes[cols_episodes], left_on=\"episode_id\", right_on=\"id\", suffixes=(\"\", \"_episode\")).drop(columns=[\"id\"])",
          "Merge the datasets on episode_id\ndf = pd.merge(df_script, df_episodes, on='episode_id').merge(df_characters, on='character_id').merge(df_locations, on='location_id')",
          " Join locations and episodes information to script data\ndf_script = pd.merge(df_script, df_episodes, on='episode_id', how='left')\ndf_script = pd.merge(df_script, df_locations, on='location_id', how='left')",
          "merge episodes with characters and locations\ndf_episodes_chars_locs = pd.merge(df_episodes, df_characters, on='episode_id')\ndf_episodes_chars_locs = pd.merge(df_episodes_chars_locs, df_locations, on='episode_id')",
          "Merge episodes and script with character and location details\ndf = df_script.merge(df_episodes, on='episode_id')  # Merge episodes with script\ndf = df.merge(df_characters, on='character_id')  # Merge characters with episode-script\ndf = df.merge(df_locations, on='location_id')  # Merge locations with episode-script",
          "Compute important additional data\ndf_script = df_script.merge(df_episodes, on='episode_id', how='left')\ndf_script = df_script.merge(df_characters, on='character_id', how='left')\ndf_script = df_script.merge(df_locations, on='location_id', how='left')",
          "# Extract relevant columns\ndf_script = df_script[['episode_id', 'number', 'raw_text', 'character_id', 'location_id']]\n\n# Merge dataframes\ndf_script = df_script.merge(df_characters, left_on='character_id', right_on='id')\ndf_script = df_script.merge(df_locations, left_on='location_id', right_on='id')\n\n# Drop unnecessary columns\ndf_script.drop(columns=['id_x', 'id_y', 'normalized_name', 'normalized_location'], inplace=True)\n\n# Show df_script\ndf_script.head()",
          "Merge characters, locations, episodes, and script lines\ndf = df_script.merge(df_episodes, on='episode_id', how='inner') \\\n              .merge(df_characters, on='character_id', how='inner') \\\n              .merge(df_locations, on='location_id', how='inner')",
          " Merge data\ndf = df_script.merge(df_episodes, on='episode_id')\ndf = df.merge(df_characters, on='character_id')\ndf = df.merge(df_locations, on='location_id')",
          "Merge datasets for a complete view of the data\ndf_complete = df_script.merge(df_episodes, how='left', on='episode_id')\ndf_complete = df_complete.merge(df_characters, how='left', left_on='character_id', right_on='id', suffixes=('_script', '_character')).drop(['id_script', 'id_character'], axis=1)\ndf_complete = df_complete.merge(df_locations, how='left', left_on='location_id', right_on='id', suffixes=('_character', '_location')).drop(['id_character', 'id'], axis=1)",
          "Merging all the datasets based on \"episode_id\"\ndf = pd.merge(df_script, df_episodes, on='episode_id')\ndf = pd.merge(df, df_characters, on='character_id')\ndf = pd.merge(df, df_locations, on='location_id')",
          "Merge script lines with characters and locations data\ndf_script_characters = df_script.merge(df_characters, on='character_id', suffixes=('', '_char')).merge(df_locations, on='location_id', suffixes=('', '_char')).merge(df_episodes, on='episode_id', suffixes=('', '_char'))",
          "Merge dataframes to have all the data in one place\ndf_merged = pd.merge(df_script, df_episodes, on='episode_id')\ndf_merged = pd.merge(df_merged, df_characters, on='character_id', how='inner')\ndf_merged = pd.merge(df_merged, df_locations, on='location_id', how='inner')",
          "Merge datasets to have episode, character and location information in one DataFrame\ndf_merged = pd.merge(df_script, df_episodes, how='left', on='episode_id')\ndf_merged = pd.merge(df_merged, df_characters, how='left', left_on='character_id', right_on='id')\ndf_merged = pd.merge(df_merged, df_locations, how='left', left_on='location_id', right_on='id')\n\n# Show the first few rows of the DataFrame\ndf_merged.head()",
          " Join the dataframes on the appropriate columns\ndf_joined = (df_script\n            .merge(df_episodes, how='left', left_on='episode_id', right_on='id', suffixes=('_script', '_episod'))\n            .merge(df_characters, how='left', left_on='character_id', right_on='id', suffixes=('_script', '_character'))\n            .merge(df_locations, how='left', left_on='location_id', right_on='id', suffixes=('_script', '_location')))",
          "Merging datasets\ndf_merge = df_script.merge(df_episodes, on='episode_id', how='inner')\ndf_merge = df_merge.merge(df_characters, on='character_id', how='inner')\ndf_merge = df_merge.merge(df_locations, on='location_id', how='inner')\n\n# Moving the merge key to the front\ncols = list(df_merge)\ncols.insert(0, cols.pop(cols.index('id')))\ndf_merge = df_merge.loc[:, cols]",
          "df_script_episode = pd.merge(df_script, df_episodes, left_on='episode_id', right_on='id')\ndf_script_character = pd.merge(df_script, df_characters, left_on='character_id', right_on='id')\ndf_script_location = pd.merge(df_script, df_locations, left_on='location_id', right_on='id')",
          "fourth merge to create our final dataset: df\ndf = (\n    df_script\n    .merge(df_characters, how='inner', on='character_id')\n    .merge(df_episodes, how='inner', on='episode_id')\n    .merge(df_locations, how='inner', on='location_id')\n)",
          "Merge the dataframes to simplify analysis.\ndf = df_script.merge(df_episodes, on='episode_id')\ndf = df.merge(df_characters, on='character_id', suffixes=['_script', '_character'])\ndf = df.merge(df_locations, on='location_id')",
          "Merge lines with character and locations files\ndf_script = pd.merge(df_script, df_characters, on='character_id', how='left')\ndf_script = pd.merge(df_script, df_locations, on='location_id', how='left')\n\n# Merge script with episodes\ndf_script = pd.merge(df_script, df_episodes, on='episode_id', how='left')",
          "Merge the dataframes\ndf_joined = df_script.merge(df_episodes, how='left', on='episode_id')\ndf_joined = df_joined.merge(df_characters, how='left', left_on='character_id', right_on='id')\ndf_joined = df_joined.merge(df_locations, how='left', left_on='raw_location_text', right_on='raw_location_text')",
          "Merge all datasets into one by episode_id\ndf = pd.merge(df_script, df_episodes, on='episode_id')\ndf = pd.merge(df, df_characters, on='character_id')\ndf = pd.merge(df, df_locations, on='location_id')",
          "Merge characters, locations, episodes, and script lines.\ndf_merged = df_script.merge(df_episodes, on='episode_id') \\\n    .merge(df_characters, on='character_id') \\\n    .merge(df_locations, on='location_id')\n\nprint('Number of merged rows:', df_merged.shape[0])\n\n# Display the merged dataframe\ndf_merged.head()",
          "Merge script with locations and characters\ndf_script = df_script.merge(df_episodes[['id', 'season', 'number_in_season', 'number_in_series']], on='id')\n\ndf_script = df_script.merge(df_characters, on='character_id')\n\ndf_script = df_script.merge(df_locations, on='location_id')",
          "Merge script lines with characters\ndf_script = df_script.merge(df_characters, on='character_id', how='inner')\n\n# Merge script lines with locations\ndf_script = df_script.merge(df_locations, on='location_id', how='inner')\n\n# Merge script lines with episodes\ndf_script = df_script.merge(df_episodes, on='episode_id', how='inner')",
          "Join the datasets together\ndf_all = pd.merge(\n    pd.merge(pd.merge(df_script, df_episodes, on='episode_id'), df_characters, on='character_id'),\n    df_locations,\n    on='location_id'\n)",
          " Merge lines with characters and locations\ndf_lines = df_script.merge(df_episodes, on=\"episode_id\")\ndf_lines = df_lines.merge(df_characters, on=\"character_id\", suffixes=('_line', '_character'))\ndf_lines = df_lines.merge(df_locations, on=\"location_id\", suffixes=('_line', '_location'))",
          "Merge `df_script` with `df_characters` on `character_id`\ndf_script_char = df_script.merge(df_characters, on='character_id', how='left')\n# Merge `df_script` with `df_locations` on `location_id`\ndf_script_char_loc = df_script_char.merge(df_locations, on='location_id', how='left')\n# Merge `df_script` with `df_episodes` on `episode_id`\ndf = df_script_char_loc.merge(df_episodes, on='episode_id', how='left')",
          "Data transformation\n# Select important columns from the df_script dataframe\ndf_script = df_script[['episode_id', 'number', 'timestamp_in_ms', 'character_id', 'location_id', 'raw_text']]\n\n# Merge the df_script dataframe with the df_episodes dataframe\ndf_episodes['episode_id'] = df_episodes.index + 1  # The episode_id starts at 1 instead of 0\ndf_script = pd.merge(df_script, df_episodes, on='episode_id')\n\n# Merge the df_script dataframe with the df_characters dataframe\ndf_script = pd.merge(df_script, df_characters, left_on='character_id', right_on='id', suffixes=('', '_character'))\n\n# Merge the df_script dataframe with the df_locations dataframe\ndf_script = pd.merge(df_script, df_locations, left_on='location_id', right_on='id', suffixes=('', '_location'))",
          "Merge script with character, location and episode\ndf = (df_script\n      .merge(df_characters, how='left', on='character_id', suffixes=('', '_character'))\n      .merge(df_locations, how='left', on='location_id', suffixes=('', '_location'))\n      .merge(df_episodes, how='left', on='episode_id', suffixes=('', '_episode')))",
          "Join all available data to create a master dataframe.\n# Join characters\ndf = df_script.join(df_characters, on='character_id', lsuffix='_script', rsuffix='_character', how='left')\n\n# Join locations\ndf = df.join(df_locations, on='location_id', lsuffix='_script', rsuffix='_location', how='left')\n\n# Join episodes\ndf = df.join(df_episodes, on='episode_id', lsuffix='_script', rsuffix='_location', how='left')",
          " Merge locations, script lines and episodes into one dataframe\ndf_merged = (df_script\n             .merge(df_locations, how='left', on='raw_location_text')\n             .merge(df_episodes, how='left', left_on='episode_id', right_on='id'))\n\n# Merge with characters to include Speaker/Listener names\ndf_merged = df_merged.merge(df_characters, how='left', left_on='raw_character_text', right_on='name')",
          "Merge relevant data\ndf_merged = pd.merge(df_script, df_episodes,\n                     on='episode_id',\n                     how='left')\n\ndf_merged = pd.merge(df_merged, df_characters,\n                     on='character_id',\n                     how='left')\n\ndf_merged = pd.merge(df_merged, df_locations,\n                     on='location_id',\n                     how='left')",
          "\n# Merge main data into a single dataframe\ndf_merged = (\n    df_script\n    .merge(df_episodes, on='episode_id', suffixes=('_script', ''))\n    .merge(df_characters, on='character_id', suffixes=('_script', '_character'))\n    .merge(df_locations, on='location_id', suffixes=('_script', '_location'))\n)",
          "Join datasets\n# Merge the datasets to have all the information in the same DataFrame\ndf = df_script.merge(df_episodes, on='episode_id')\ndf = df.merge(df_characters, on='character_id', suffixes=('', '_from'))\ndf = df.merge(df_locations, on='location_id', suffixes=('', '_from'))",
          "Joining characters, locations and episodes to script data\ndf_script = df_script.merge(df_characters, on='character_id', how='left')\ndf_script = df_script.merge(df_locations, on='location_id', how='left')\ndf_script = df_script.merge(df_episodes, on='episode_id', how='left')",
          "Merging tables to get all informations in the same place\ndf = df_script.merge(df_episodes, on='episode_id', suffixes=('_script', '_ep'))\ndf = df.merge(df_characters, on='character_id', suffixes=(False, '_ch'))\ndf = df.merge(df_locations, on='location_id', suffixes=(False, '_loc'))",
          "Merge the characters and locations dataframes with the script dataframe\ndf_script = df_script.merge(df_characters, left_on='character_id', right_on='id')\ndf_script = df_script.merge(df_locations, left_on='location_id', right_on='id')\n\n# Reorder columns\ndf_script = df_script[['id_x', 'episode_id', 'number', 'raw_text', 'timestamp_in_ms', 'speaking_line', \n                       'character_id', 'name_x', 'normalized_text_y', 'location_id', 'name_y', 'image_url', \n                       'normalized_text_x', 'wikipedia_url', 'number_y', 'normalized_text']]",
          "Merge characters and locations on episode_id\ndf_characters_locations = df_characters.merge(df_locations, on='episode_id')",
          "Join episodes and locations\ndf_joined = df_episodes.merge(\n    df_locations,\n    how='left',\n    left_on='id',\n    right_on='episode_id'\n)",
          "Join locations, characters and script data\ndf_locations = df_locations.merge(df_script, left_on='id', right_on='location_id', suffixes=('_location', ''))\ndf_locations = df_locations.merge(df_episodes, on='episode_id', suffixes=('_location', '_episode'))\ndf_characters = df_characters.merge(df_script, left_on='id', right_on='character_id', suffixes=('_character', ''))",
          "Merge the data into a single dataframe\ndf = (\n    df_script\n    .merge(df_episodes, on='episode_id', how='left')\n    .merge(df_characters, on='character_id', how='left')\n    .merge(df_locations, on='location_id', how='left')\n)",
          "Merging dataframes for comprehensive dataframe of Simpsons data\ndf = df_script.merge(df_episodes, how=\"left\", on=\"episode_id\")\ndf = df.merge(df_characters, how=\"left\", left_on=\"character_id\", right_on=\"id\").rename(columns={\"name\": \"character_name\"})\ndf = df.merge(df_locations, how=\"left\", left_on=\"location_id\", right_on=\"id\").rename(columns={\"name\": \"location_name\"})\n\n# Save the merged dataframe for future use\ndf.to_pickle(\"data/simpsons_dataframe.pkl\")",
          "Merge with character information\ndf_script = df_script.merge(df_characters, left_on='character_id', right_on='id', suffixes=('','_character')).drop(labels='id_character', axis=1)\n\n# Merge with location information\ndf_script = df_script.merge(df_locations, left_on='location_id', right_on='id', suffixes=('','_location')).drop(labels='id_location', axis=1)\n\n# Merge with episode information\ndf_script = df_script.merge(df_episodes, left_on='episode_id', right_on='id', suffixes=('','_episode')).drop(labels='id_episode', axis=1)\n\n# Display the resulting dataframe\ndf_script.head()",
          "Merge character, location and episodes information into the main script dataframe\ndf_script = df_script.merge(df_characters, how='left', left_on='character_id', right_on='id', suffixes=(False, False)).drop('id', axis=1)\ndf_script = df_script.merge(df_locations, how='left', left_on='location_id', right_on='id', suffixes=(False, False)).drop('id', axis=1)\ndf_script = df_script.merge(df_episodes, how='left', left_on='episode_id', right_on='id', suffixes=(False, False)).drop('id', axis=1)",
          " Merge some dataframes to be used later on\ndf = df_script.merge(df_characters, how='inner', on='character_id')\ndf = df.merge(df_locations, how='inner', on='location_id')\ndf = df.merge(df_episodes, how='left', on='episode_id')\n\n# Show first rows\ndf.head()",
          "Merge episode, character and location data into script data\ndf_script = df_script.merge(df_episodes, on='episode_id')\ndf_script = df_script.merge(df_characters, on='character_id', suffixes=('', '_character'))\ndf_script = df_script.merge(df_locations, on='location_id', suffixes=('', '_location'))",
          "Adds characters information to script dataframe\ndf_script = pd.merge(df_script,\n                     df_characters,\n                     left_on='character_id',\n                     right_on='id').drop(columns=['id'])\n\n# Adds locations information to script dataframe\ndf_script = pd.merge(df_script,\n                     df_locations,\n                     left_on='location_id',\n                     right_on='id').drop(columns=['id'])\n\n# Adds episodes information to script dataframe\ndf_script = pd.merge(df_script,\n                     df_episodes,\n                     left_on='episode_id',\n                     right_on='id').drop(columns=['id'])\n\ndf_script.head()",
          "# Smarter overviews by joining the data\ndf_merged = df_script.copy()\ndf_merged = df_merged.join(df_episodes.set_index('id'), on='episode_id')\ndf_merged = df_merged.join(df_characters.set_index('id'), on='character_id', rsuffix='_character')\ndf_merged = df_merged.join(df_locations.set_index('id'), on='location_id', rsuffix='_location')",
          "merge main tables using foreignkeys and other columns\ndf_merged = df_script.merge(df_episodes, on='episode_id', suffixes=('', '_ep'))\ndf_merged = df_merged.merge(df_characters, on='character_id', suffixes=('', '_ch'))\ndf_merged = df_merged.merge(df_locations, on='location_id', suffixes=('', '_l'))",
          " Merge dataframes to get a full view of the data\ndf_episodes_full = df_episodes.merge(df_script, on='episode_id', how='outer')\ndf_episodes_full = df_episodes_full.merge(df_locations, on='location_id', how='outer')\ndf_episodes_full = df_episodes_full.merge(df_characters, left_on='raw_character_text', right_on='name', how='left')",
          "Merge character information into the script dataframe\ndf_full = pd.merge(\n    df_script,\n    df_episodes,\n    how='left',\n    on='episode_id',\n    suffixes=('_script', '_episode')\n)\n\ndf_full = pd.merge(\n    df_full,\n    df_characters,\n    how='left',\n    on='character_id',\n    suffixes=('', '_character')\n)",
          "Merge character, location and episode data into the script data\ndf_script = pd.merge(df_script, df_characters, on='character_id', how='left')\ndf_script = pd.merge(df_script, df_locations, on='location_id', how='left')\ndf_script = pd.merge(df_script, df_episodes, on='episode_id', how='left')",
          "# Merge script, characters, locations and episodes files\ndf_script['character_id'] = df_script['character_id'].astype('Int64')\ndf_script['location_id'] = df_script['location_id'].astype('Int64')\ndf_script = df_script \\\n        .merge(df_characters, how='left', left_on='character_id', right_on='id', suffixes=('_script', '_character')) \\\n        .merge(df_locations, how='left', left_on='location_id', right_on='id', suffixes=('_script', '_location')) \\\n        .merge(df_episodes, how='left', left_on='episode_id', right_on='id', suffixes=('_script', '_episode'))\n\n# Sort the df_script to always have the episodes in order\ndf_script = df_script.sort_values(by=['imdb_rating', 'original_air_date', 'season', 'number_in_season', 'number_in_series'])\n\n# We don't need the same information twice or ids\ndf_script.drop(['id_script', 'id_character', 'id_location', 'id_episode'], axis=1, inplace=True)",
          "Merge datasets: Location to Episode\ndf_locations_ep = df_locations.merge(df_episodes,\n                                     on='id',\n                                     how='right')\n# Change the order of columns\n# Get the list of columns\ncols = df_locations_ep.columns.tolist()\n# Print the list\nprint(cols)",
          "Merge the scripts with the characters and locations\ndf_merged = df_script.merge(df_episodes, on='episode_id')  # merge scripts with episodes\ndf_merged = df_merged.merge(df_characters, on='character_id')  # merge characters\ndf_merged = df_merged.merge(df_locations, on='location_id')  # merge locations",
          "Merge the dataframes to simplify the analysis\ndf_merge = pd.merge(df_script, df_episodes, how='left', on='episode_id')\ndf_merge = pd.merge(df_merge, df_characters, how='left', on='character_id')\ndf_merge = pd.merge(df_merge, df_locations, how='left', on='location_id')\n\nprint('Number of entries: {}'.format(len(df_merge)))",
          "ppend all the data into one single data frame\ndf_final = pd.merge(df_script, df_characters, how='left', on=['character_id'])\ndf_final = pd.merge(df_final, df_locations, how='left', on=['location_id'])\ndf_final = pd.merge(df_final, df_episodes, how='left', on=['episode_id'])",
          "Create a pandas dataframe containing the character, location and episode information\n\nloc_c = pd.DataFrame(pd.merge(df_script, df_characters, on='character_id', how='left'))\nloc_c_e = pd.DataFrame(pd.merge(loc_c, df_episodes, on='episode_id', how='left'))\nloc_c_e.url=loc_c_e.url.astype(str)\n\nloc_c_e.info()",
          "Merge characters, locations and episodes into the main dataframe\ndf_script_full = (df_script\n                  .merge(\n                      df_characters,\n                      how='left',\n                      left_on='character_id',\n                      right_on='id',\n                      suffixes=('_script', '_character')\n                  )\n                  .merge(\n                      df_locations,\n                      how='left',\n                      left_on='location_id',\n                      right_on='id',\n                      suffixes=('','_location')\n                  )\n                  .merge(\n                      df_episodes,\n                      how='left',\n                      left_on='episode_id',\n                      right_on='id',\n                      suffixes=('','_episode')\n                  )\n                 )",
          "Merge all datasets on 'episode_id'\ndf = df_script.merge(df_episodes, on='episode_id')\ndf = df.merge(df_locations, on='location_id')\ndf = df.merge(df_characters, on='character_id')",
          " Merge datasets\ndf_script_episodes = df_script.merge(df_episodes, on='episode_id', how='left')\ndf_script_episodes_characters = df_script_episodes.merge(df_characters, left_on='character_id', right_on='id', how='left', suffixes=['_script', '_character'])\ndf_script_episodes_characters_locations = df_script_episodes_characters.merge(df_locations, left_on='location_id', right_on='id', how='left', suffixes=['_character', '_location'])\n\n# Now we have a single dataframe containing all the information.",
          "Merge lines with episodes and characters\ndf_merged = df_script.merge(df_episodes, how='left', on='episode_id')\ndf_merged = df_merged.merge(df_characters, how='left', left_on='character_id', right_on='index')\n\n# Add locations\ndf_merged = df_merged.merge(df_locations, how='left', left_on='location_id', right_on='index')",
          "Merge episode, character and location names into the main script dataframe\ndf_script = df_script.merge(df_episodes[['id', 'title', 'original_air_date', 'production_code']], \n                            left_on='episode_id', right_on='id', how='left')\ndf_script = df_script.merge(df_characters[['id', 'normalized_name']], \n                            left_on='character_id', right_on='id', how='left')\ndf_script = df_script.merge(df_locations[['id', 'normalized_name']], \n                            left_on='location_id', right_on='id', how='left')",
          "Merge episodes with locations and characters\ndf_episodes['id'] = df_episodes['id'].astype(int)\ndf_locations['id'] = df_locations['id'].astype(int)\ndf_characters['id'] = df_characters['id'].astype(int)",
          "Selecting the seasons that we want to keep\ndf_episodes = df_episodes[df_episodes.season <= 12]\n\n# Merging the characters, locations and episodes with the script\ndf_simpsons = pd.merge(df_script, df_episodes, how='left', on='episode_id')\ndf_simpsons = pd.merge(df_simpsons, df_characters, how='left', left_on='character_id', right_on='id', suffixes=('_script', '_character'))\ndf_simpsons = pd.merge(df_simpsons, df_locations, how='left', left_on='location_id', right_on='id', suffixes=('_script', '_location'))",
          " Merge all datasets into a single dataframe\ndf = (df_script\n      .merge(df_episodes, on='episode_id')\n      .merge(df_characters, on='character_id', how='left')\n      .merge(df_locations, on='location_id', how='left'))",
          "Merge script with episodes and characters\ndf_script = df_script.merge(df_episodes, on='episode_id', how='left')\ndf_script = df_script.merge(df_characters, left_on='character_id', right_on='id', how='left', suffixes=('', '_character'))\ndf_script = df_script.merge(df_locations, left_on='location_id', right_on='id', how='left', suffixes=('', '_location'))",
          "Merge the characters, locations, and episodes dataframes with the script dataframe\ndf_script = df_script.merge(df_episodes, how='left', left_on='episode_id', right_on='id',\n                            suffixes=('_script', '_episodes'))\ndf_script = df_script.merge(df_characters, how='left', left_on='character_id', right_on='id',\n                            suffixes=('', '_characters'))\ndf_script = df_script.merge(df_locations, how='left', left_on='location_id', right_on='id',\n                            suffixes=('_script', '_locations'))",
          " Merge the tables to have everything in a single place\ndf = df_script.merge(df_episodes, on='episode_id', suffixes=('', '_episode'))\ndf = df.merge(df_locations, on='location_id', suffixes=('', '_location'))\ndf = df.merge(df_characters, on='character_id', suffixes=('', '_character'))",
          "Merge the dataframes together\ndf_merged = df_script.merge(df_characters, on='character_id')\ndf_merged = df_merged.merge(df_locations, on='location_id')\ndf_merged = df_merged.merge(df_episodes, on='episode_id')",
          "Merge characters, locations, script lines, and episodes data\ndf_episodes['id'] = df_episodes['id'].astype(str)  # Change type to string to merge\ndf_script['episode_id'] = df_script['episode_id'].astype(str)  # Change type to string to merge\ndf = df_script.merge(df_episodes, left_on='episode_id', right_on='id')  # Merge script lines and episodes\ndf['character_id'] = df['character_id'].astype(str)  # Change type to string to merge\ndf = df.merge(df_characters, left_on='character_id', right_on='id')  # Merge script lines and characters\ndf['location_id'] = df['location_id'].astype(str)  # Change type to string to merge\ndf = df.merge(df_locations, left_on='location_id', right_on='id')  # Merge script lines and locations",
          "Merge the script lines with the episodes and characters dataframes to add the episode and character information\ndf_characters = df_characters.rename(columns={\"id\": \"character_id\"})\ndf_locations = df_locations.rename(columns={\"id\": \"location_id\"})\ndf_script = pd.merge(df_script, df_characters, on='character_id', how='left')\ndf_script = pd.merge(df_script, df_locations, on='location_id', how='left')\ndf_script = pd.merge(df_script, df_episodes, on='episode_id', how='left')\n\n# Sanity check\ndf_script.head()",
          "\n# Merge script, characters and locations dataframes on episode id\ndf_merged = df_script.merge(df_episodes, on='episode_id')\ndf_merged = df_merged.merge(df_characters, left_on='character_id', right_on='id', suffixes=('_script', '_character'))\ndf_merged = df_merged.merge(df_locations, left_on='location_id', right_on='id', suffixes=('_character', '_location'))",
          "Join the datasets\ndf_script = (\n    df_script\n    .merge(df_episodes, left_on='episode_id', right_on='id', suffixes=('', '_episode'))\n    .merge(df_characters, left_on='character_id', right_on='id', suffixes=('', '_character'))\n    .merge(df_locations, left_on='location_id', right_on='id', suffixes=('', '_location'))\n)",
          "Data merge\ndf_script = df_script \n    .merge(df_episodes, on='episode_id', how='left')\n    .merge(df_characters, on='character_id', how='left')\n    .merge(df_locations, on='location_id', how='left')",
          "Merge script data with character and episode information\ndf_script = (\n    df_script\n    .merge(df_characters, how='left', left_on='character_id', right_on='id', suffixes=('', '_character'))\n    .merge(df_locations, how='left', left_on='location_id', right_on='id', suffixes=('', '_location'))\n    .merge(df_episodes, how='left', left_on='episode_id', right_on='id', suffixes=('', '_episode'))\n)",
          "Merge all datasets\ndf_merged = df_script.merge(df_episodes, left_on='episode_id', right_on='id', suffixes=('', '_ep'))\ndf_merged = df_merged.merge(df_characters, left_on='character_id', right_on='id', suffixes=('', '_ch'))\ndf_merged = df_merged.merge(df_locations, left_on='location_id', right_on='id', suffixes=('', '_loc'))",
          " Merge datasets\n# Merge characters and script\ndf_chars_script = pd.merge(df_characters, df_script, on='character_id')\n\n# Merge episodes and locations\ndf_ep_locs = pd.merge(df_episodes, df_locations, on='location_id')\n\n# Merge the previous result with characters and script\ndf_ep_locs_chars_script = pd.merge(df_ep_locs, df_chars_script, on='episode_id')",
          "Merge episodes with locations\ndf_episodes_locations = df_episodes.merge(\n    df_locations, left_on='id', right_on='episode_id')\n\n# Count how many times each location was used\nlocation_counts = df_episodes_locations.location_id.value_counts()\n\n# Merge episodes with characters\ndf_episodes_characters = df_episodes.merge(\n    df_characters, left_on='id', right_on='episode_id')\n\n# Count how many times each character was used\ncharacter_counts = df_episodes_characters.character_id.value_counts()\n\n# Create a location count plot\nlocation_counts.plot(kind='bar', figsize=(15, 5))\nplt.title('Number of times each location was used')\nplt.ylabel('Count')\nplt.xlabel('Location')\nplt.show()\n\n# Create a character count plot\ncharacter_counts.plot(kind='bar', figsize=(15, 5))\nplt.title('Number of times each character was used')\nplt.ylabel('Count')\nplt.xlabel('Character')\nplt.show()",
          " Join the tables on their respective identifiers\ndf = df_script.merge(df_characters, left_on='character_id', right_on='id')\ndf = df.merge(df_locations, left_on='location_id', right_on='id')\ndf = df.merge(df_episodes, left_on='episode_id', right_on='id')"
         ],
         "marker": {
          "opacity": 0.5,
          "size": 5
         },
         "mode": "markers+text",
         "name": "2_Data merging and joining with pandas",
         "text": [
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          ""
         ],
         "textfont": {
          "size": 12
         },
         "type": "scattergl",
         "x": [
          0.8372123837471008,
          2.5942068099975586,
          0.7801926732063293,
          0.9479038715362549,
          2.077594518661499,
          1.715301513671875,
          1.9557801485061646,
          1.170737385749817,
          0.6387087106704712,
          1.7637375593185425,
          1.4858949184417725,
          1.8770473003387451,
          1.3579071760177612,
          0.4744926691055298,
          1.3472073078155518,
          0.44940510392189026,
          0.5502644181251526,
          1.6062438488006592,
          1.466436505317688,
          1.5458968877792358,
          0.7727036476135254,
          1.6704212427139282,
          1.6932806968688965,
          1.40587317943573,
          1.434654712677002,
          1.8373699188232422,
          1.7712502479553223,
          1.50355863571167,
          2.0523219108581543,
          2.6915550231933594,
          1.0918254852294922,
          0.9145764708518982,
          1.9338791370391846,
          1.6273479461669922,
          0.9516232013702393,
          1.1237555742263794,
          2.2406487464904785,
          0.5280584692955017,
          1.0791996717453003,
          1.4941942691802979,
          1.5692245960235596,
          1.7243794202804565,
          2.550365924835205,
          1.381681203842163,
          1.387304663658142,
          1.7720915079116821,
          0.5105898380279541,
          1.504488468170166,
          0.536702573299408,
          0.6294195652008057,
          1.1721973419189453,
          0.5986788868904114,
          1.5392986536026,
          0.6853958368301392,
          1.1283485889434814,
          1.803707242012024,
          1.373286247253418,
          0.4237704277038574,
          0.9976878762245178,
          1.934052586555481,
          1.6807124614715576,
          0.879925012588501,
          2.152074098587036,
          1.4912606477737427,
          1.9975707530975342,
          1.410245656967163,
          1.0178606510162354,
          2.0884649753570557,
          0.8643401265144348,
          1.214489459991455,
          1.4529238939285278,
          1.2273657321929932,
          0.9058386087417603,
          2.2424280643463135,
          1.2046098709106445,
          1.2008452415466309,
          1.6405068635940552,
          0.7949310541152954,
          2.0942487716674805,
          2.480545997619629,
          2.350874185562134,
          0.8922217488288879,
          1.5329793691635132,
          2.2573468685150146,
          1.1578525304794312,
          1.0019325017929077,
          1.1127877235412598,
          1.4378234148025513,
          1.2100780010223389,
          1.8613736629486084,
          0.09952449053525925,
          1.249523401260376,
          0.5555106401443481,
          0.6702791452407837,
          0.997671365737915,
          1.4479734897613525,
          0.8067142963409424,
          1.2233045101165771,
          1.9539517164230347,
          2.051328659057617,
          2.0116403102874756,
          2.00252628326416,
          0.7134736180305481,
          1.6932371854782104,
          1.5294055938720703,
          1.1298365592956543,
          1.1123121976852417,
          2.2384085655212402,
          2.281426191329956,
          1.3317795991897583,
          1.4529916048049927,
          1.1362569332122803,
          1.7121896743774414,
          1.0517120361328125,
          0.5179507732391357,
          1.3281476497650146,
          1.311240553855896
         ],
         "y": [
          7.980993270874023,
          7.814395427703857,
          8.053804397583008,
          7.60822868347168,
          8.63949203491211,
          8.067424774169922,
          7.724775314331055,
          7.9388957023620605,
          7.846190929412842,
          8.688858985900879,
          8.952364921569824,
          8.771492958068848,
          8.202458381652832,
          8.169535636901855,
          8.772540092468262,
          8.446746826171875,
          7.882386207580566,
          9.026994705200195,
          7.458232879638672,
          7.44222354888916,
          7.832034587860107,
          7.44540548324585,
          8.268128395080566,
          7.268777370452881,
          9.138448715209961,
          8.06135368347168,
          8.912626266479492,
          8.641253471374512,
          8.586359024047852,
          7.82621431350708,
          8.62351131439209,
          8.09334945678711,
          7.772625923156738,
          7.579910755157471,
          6.746441841125488,
          8.511693954467773,
          8.389994621276855,
          7.380428791046143,
          8.142770767211914,
          6.988774299621582,
          7.59818172454834,
          8.41942024230957,
          7.742094993591309,
          7.887796878814697,
          7.6075639724731445,
          8.138282775878906,
          7.252388954162598,
          8.436277389526367,
          7.986318588256836,
          8.657231330871582,
          8.03690242767334,
          7.376106262207031,
          8.46358585357666,
          7.797653675079346,
          7.905806541442871,
          8.764427185058594,
          8.346612930297852,
          7.181016445159912,
          8.091795921325684,
          7.440870761871338,
          7.815307140350342,
          7.209728717803955,
          7.815106391906738,
          8.990072250366211,
          8.097030639648438,
          9.005229949951172,
          7.952292442321777,
          8.068442344665527,
          8.52386474609375,
          7.545063018798828,
          6.947904586791992,
          8.660758018493652,
          7.730419158935547,
          8.450119018554688,
          7.156317234039307,
          8.016602516174316,
          8.031643867492676,
          8.815071105957031,
          8.768943786621094,
          8.296185493469238,
          8.488199234008789,
          8.733027458190918,
          7.83955717086792,
          8.217422485351562,
          7.261812210083008,
          7.9367547035217285,
          8.967409133911133,
          8.17343521118164,
          8.88229751586914,
          8.622037887573242,
          7.614406108856201,
          7.157922267913818,
          8.594654083251953,
          8.647180557250977,
          9.139660835266113,
          9.047247886657715,
          7.555705547332764,
          9.132390022277832,
          8.468976974487305,
          8.27946662902832,
          6.602035999298096,
          8.239818572998047,
          8.563863754272461,
          9.030357360839844,
          8.67562484741211,
          7.508957386016846,
          7.958723545074463,
          8.34891414642334,
          8.527894973754883,
          8.235547065734863,
          7.437575817108154,
          8.917375564575195,
          8.74227523803711,
          7.585366249084473,
          7.308308124542236,
          8.390066146850586,
          7.556387901306152
         ]
        },
        {
         "hoverinfo": "text",
         "hovertext": [
          "Convert string representations of lists to actual lists\nimport ast\n\ndf_script['raw_character_text'] = df_script['raw_character_text'].apply(ast.literal_eval)\ndf_script['spoken_words'] = df_script['spoken_words'].apply(ast.literal_eval)",
          "Filter dialogues with at least one word comprised of alphabet characters\ndf_script_filtered = df_script[df_script['raw_character_text'].str.isalpha()].reset_index(inplace=False, drop=True)",
          " Filter out non-speaking lines from df_script\ndf_script = df_script[df_script.speaking_line].reset_index(drop=True)",
          "Preprocess script data\ndf_script = df_script[df_script['speaking_line'] == True].reset_index(inplace=False, drop=True)",
          "Remove quotations around the speaker name in the script data\ndf_script['character_id'] = df_script['character_id'].str.replace('\"', '')\ndf_script['raw_character_text'] = df_script['raw_character_text'].str.replace('\"', '')\ndf_script['spoken_words'] = df_script['spoken_words'].str.replace('\"', '')",
          "Create a dataframe with the necessary information to work (only the characters with speaking lines)\ndf_script.loc[df_script['speaking_line'] == 'true'].reset_index(inplace=True, drop=True)",
          "Extract quotes from script\nquotes = df_script[df_script['speaking_line'] == True][['character_id','raw_text']]\n\n# Extract quotes from script\ncharacters = df_characters['name']\n\n# Extract locations from dataset",
          "Removing lines corresponding to non-dialogue actions from the script dataframe",
          "Remove rows with missing 'spoken_words' and 'raw_text' values\ndf_script = df_script.dropna(subset=['spoken_words', 'raw_text'])",
          "Filter out lines which are not spoken by characters\ndf_script = df_script.loc[df_script['speaking_line'] == True]",
          "Data preprocessing\n# lowercase everything\ndf_script['spoken_words'] = df_script['spoken_words'].str.lower()",
          "Remove lines where the speaking character id is not in the characters dataframe",
          "Concatenate the character name and speaking line into one string in a new column\ndf_script['raw_text'] = df_script['raw_character_text'] + ': ' + df_script['spoken_words']",
          " Define the speaker for each line in the script\ndf_script = df_script.merge(df_characters.rename(columns={'character_name': 'speaker'}), on='speaker_id')",
          "Filter out non-dialogue script lines, remove irrelevant columns, and save to CSV\ndf_script = df_script[df_script['speaking_line'] == True].reset_index(inplace=False, drop=True)",
          "Filtering only the spoken lines and relevant columns\ndf_script = df_script[(df_script['speaking_line'] == True) & (df_script['raw_character_text'].notna())]\ndf_script = df_script[['raw_character_text', 'spoken_words', 'episode_id']]\n\n#Renaming columns for clarity\ndf_script.columns = ['character', 'dialogue', 'episode_id']",
          " Keep only \"spoken_words\" and \"raw_text\" columns\ndf_script = df_script[[\"spoken_words\", \"raw_text\"]]",
          "# Filter non-spoken lines and reset index\ndf_script = df_script[df_script['speaking_line'] == True].reset_index(drop=True)",
          "Remove incomplete script lines from the dataframe\ndf_script = df_script[(df_script['speaking_line'] == True) & (df_script['raw_location_text'].notnull())]\ndf_script.reset_index(drop=True, inplace=True)",
          "Filter out the non-spoken lines from the dataset and save the result in a new dataframe of its own.",
          " Filter out rows from df_script that don't contain any spoken lines (i.e. rows where the speaking_line column is False)\ndf_script = df_script[df_script[\"speaking_line\"] == True].reset_index(drop=True)",
          "Separate the columns containing the text data that we care about:\ntext_columns = ['raw_character_text', 'spoken_words', 'raw_location_text', 'normalized_text']",
          "Add missing columns to fullfil the schema and fill the NaN records with empty strings\ndf_script=df_script[df_script['normalized_text'].notna()]\ndf_script=df_script[df_script['spoken_words'].notna()]",
          "Filter out the non-dialogue lines from the script dataframe\ndf_script_dialogue = df_script[df_script['speaking_line'] == True]",
          "Clean data\ndf_script = df_script[df_script[\"spoken_words\"].notna()]",
          "remove script lines without any text\ndf_script = df_script.dropna(subset=['spoken_words'])",
          " Retain only the rows with non-null values in the speaking line column\ndf_script_cleaned = df_script[df_script['speaking_line'].notnull()]",
          "Remove values where the speech is not defined, and episode is not defined\ndf_script = df_script.replace({pd.np.nan: None})\ndf_script = df_script[df_script.speech.str.len() > 0]\ndf_script = df_script[df_script.episode_id.notnull()]",
          "Remove some unused columns\ndf_script.drop(['spoken_words', 'raw_text', 'timestamp_in_ms', 'speaking_line'], axis=1, inplace=True)",
          "Convert non-numeric values to NaN\ndf_script['spoken_words'] = df_script['spoken_words'].apply(lambda x: np.nan if isinstance(x, str) and not x.isdigit() else x)",
          "df_script = df_script[df_script['speaking_line'] == True].reset_index(drop=True)",
          "Remove rows with empty \"spoken_words\" in the script\ndf_script = df_script.dropna(subset=['spoken_words'])",
          "Get it to the right encoding\ndf_script = df_script.astype({\"index\": int, \"id\": int, \"number\": pd.Int64Dtype(),\n                              \"raw_text\": str, \"timestamp_in_ms\": pd.Int64Dtype(), \"speaking_line\": bool, \"character_id\": pd.Int64Dtype(),\n                              \"location_id\": pd.Int64Dtype(), \"raw_character_text\": str, \"raw_location_text\": str,\n                              \"spoken_words\": str, \"normalized_text\": str, \"word_count\": pd.Int64Dtype()})",
          "Rename columns for consistency and readability\ndf_script = df_script.rename(columns={'normalized_text': 'spoken_words',\n                                      'raw_text': 'raw_spoken_words',\n                                      'timestamp_in_ms': 'timestamp',\n                                      'speaking_line': 'is_speaking_line',\n                                      'character_id': 'raw_character_id',\n                                      'location_id': 'raw_location_id'})",
          "Filter script to only keep spoken lines from characters\nspoken_lines = df_script[(df_script['character_id'] != 2) & (df_script['character_id'].notnull())]",
          "Split rows in 'simpsons_script_lines' by newlines in 'normalized_text'\ndf_script = df_script.assign(normalized_text=df_script['normalized_text'].str.split('\\n')).explode('normalized_text')\n\n# Remove ':' from speaker names\ndf_script = df_script.assign(speaker=df_script['speaker'].str.replace(':', ''))\n\n# Keep only 'spoken_words' and speaker name\ndf_script = df_script.assign(normalized_text=df_script['normalized_text'].str.split(':')).explode('normalized_text')\n\n# Remove leading/trailing whitespaces from 'normalized_text'\ndf_script = df_script.assign(normalized_text=df_script['normalized_text'].str.strip())\n\n# Remove rows with 'normalized_text' == ''\ndf_script = df_script[df_script['normalized_text'] != '']",
          "Remove rows where the `spoken_words` column contains bad data\ndf_script = df_script[df_script['spoken_words'].apply(lambda x: isinstance(x, str))]",
          " Drop rows in the data that are NaN in the speaking_line column\ndf_script = df_script.dropna(subset=['speaking_line'])",
          "Format script data\ndf_script = df_script[df_script['episode_id'] != 'special']\ndf_script['raw_character_text'] = df_script['raw_character_text'].astype(str)\ndf_script['spoken_words'] = df_script['spoken_words'].astype(str)\ndf_script = df_script.dropna(subset=['raw_character_text'])\ndf_script = df_script.dropna(subset=['spoken_words'])",
          "Filter out bad orders (for example when a main character doesn't talk)\nprint('Rows before cleaning:', df_script.shape[0])\ndf_script = df_script.loc[df_script['raw_character_text'].isin(df_characters['character_text'])]\ndf_script = df_script[df_script['spoken_words'].str.len() > 0]\nprint('Rows after cleaning:', df_script.shape[0])",
          "Select the character's dialogues for sentiment analysis\nmoe_lines = df_script.loc[df_script[\"raw_character_text\"] == \"Moe Szyslak\"][\"spoken_words\"]",
          "Remove rows with NaN valued spoken_words (empty spoken_words)\ndf_script = df_script.dropna(subset=['spoken_words'])",
          "Create a new column containing the normalized lemmatized version of the spoken lines\ndf_script['spoken_lemmatized'] = df_script['normalized_text'].progress_apply(spacy_lemmatize)",
          "Remove empty quips (some lines have only a quip, or the quip is part of the dialog [1/3, 1/3])\ndf_script = df_script.dropna(subset=['spoken_words'])",
          " Leave only lines\ndf_lines = df_script[df_script['speaking_line']]\ndf_lines = df_lines.merge(df_characters[['name', 'character_id']], on='character_id')",
          " Remove rows we don't need to minimize memory usage\ndf_script.drop(['spoken_words', 'raw_text'], axis=1, inplace=True)",
          "Keep only the spoken lines\ndf_script = df_script[df_script.speaking_line].reset_index(inplace=False, drop=True)",
          "Split the `text` column into multiple columns: \ndf_script[['speaking_line', 'character_id', 'location_id', 'raw_text', 'timestamp_in_ms2', 'timestamp_in_ms', 'raw_character_text', 'raw_location_text', 'spoken_words', 'normalized_text']] = pd.DataFrame(df_script['text'].str.split(',',10).tolist())",
          " Clean script dataframe\ndf_script = df_script[pd.notnull(df_script['normalized_text'])]\ndf_script = df_script[pd.notnull(df_script['character_id'])]\ndf_script = df_script[df_script['speaking_line'] == True]\ndf_script = df_script[df_script['normalized_text'] != '(END OF PREVIEW)']",
          " The lines correspond to XML codes, so we remove them using only the columns related to single lines of speech, and we fill NaN with an empty string\nlines = df_script[['character_id', 'location_id', 'spoken_words']].fillna('')\nlines.head()",
          "Removing unnecessary columns in df_script\ndf_script = df_script.drop(['date', 'timestamp_in_ms', 'speaking_line', 'raw_text', 'normalized_text', 'word_count'], axis=1)",
          "Creating a new column containing the tokenized version of the 'spoken_words' column.",
          " Create a new dataframe with only the parts of the script that are spoken by a character (not scene headings, etc.)\ndf_script_lines = df_script[df_script.raw_text.str.contains(\"[A-Za-z0-9]+:\")]\ndf_script_lines.reset_index(drop=True, inplace=True)",
          "Removing all non speaking_lines\nspeaking_lines = df_script[df_script.speaking_line]\nspeaking_lines_idxs = speaking_lines.line_id\n\n#cleaning the strings for speakers and raw_texts\nspeaking_lines.raw_text = speaking_lines.raw_text.str.replace('\\r', ' ')\nspeaking_lines.raw_text = speaking_lines.raw_text.str.replace('\\n', ' ')\nspeaking_lines.character_id = speaking_lines.character_id.str.replace('^\\s+', '', regex=True)",
          "Filtering the script dataframe to only include spoken lines (i.e., not stage directions or observations)",
          "Remove rows with NaN in \"raw_character_text\" or \"spoken_words\" columns\ndf_script = df_script.dropna(subset=['raw_character_text', 'spoken_words']).reset_index(drop=True)",
          "Remove punctuation and numbers from lines for each character\n#df_script = df_script.sample(frac=0.1, replace=True, random_state=1) # Uncomment this line to test your code with only a fraction of the data\ndf_script['spoken_words'] = df_script['spoken_words'].str.replace('[^A-Za-z\\s\\']','')\ndf_script['spoken_words'] = df_script['spoken_words'].str.replace('\\d+','')",
          " Clean text and add a column with the lengths of the sequences\ndf_script['spoken_words'] = df_script['spoken_words'].str.replace('\\r', ' ')\ndf_script['spoken_words'] = df_script['spoken_words'].str.replace('\\n', ' ')\ndf_script['spoken_words'] = df_script['spoken_words'].str.replace('<b>', ' ')\ndf_script['spoken_words'] = df_script['spoken_words'].str.replace('</b>', ' ')\ndf_script['spoken_words'] = df_script['spoken_words'].str.replace('<i>', ' ')\ndf_script['spoken_words'] = df_script['spoken_words'].str.replace('</i>', ' ')\ndf_script['spoken_words'] = df_script['spoken_words'].str.replace('<u>', ' ')\ndf_script['spoken_words'] = df_script['spoken_words'].str.replace('</u>', ' ')\ndf_script['spoken_words'] = df_script['spoken_words'].str.replace('<br />', ' ')",
          "Remove all non speaking_lines from script\ndf_script = df_script[df_script['speaking_line'] == True]",
          "Clean empty utterances\ndf_script = df_script.dropna(subset=['raw_character_text', 'spoken_words'])",
          "Change types for memory optimization\ndf_script['normalized_text'] = df_script['normalized_text'].astype('str')\ndf_script['spoken_words'] = df_script['spoken_words'].astype('str')\ndf_script['raw_text'] = df_script['raw_text'].astype('str')\ndf_script['timestamp_in_ms'] = df_script['timestamp_in_ms'].astype('float32')",
          "Set NaN values to empty strings in character_name, raw_location_text, and spoken_words.\ndf_script['character_name'] = df_script['character_name'].fillna('')\ndf_script['raw_location_text'] = df_script['raw_location_text'].fillna('')\ndf_script['spoken_words'] = df_script['spoken_words'].fillna('')",
          " Split the 'raw_text' speech into a list of quotes of parts of 7 types.",
          "Limit the script to only include spoken words by characters\ndf_script = df_script[df_script['speaking_line'] == True]",
          " Replace NaN\ndf_script.loc[:, 'speaking_line'] = df_script['speaking_line'].fillna(False).astype(bool)\ndf_script.loc[:, 'character_id'] = pd.to_numeric(df_script['character_id'], downcast='integer', errors='coerce')\ndf_script.loc[:, 'location_id'] = pd.to_numeric(df_script['location_id'], downcast='integer', errors='coerce')",
          "\n# Drop incomplete data\ndf_script = df_script.dropna(subset=['normalized_text'])\n\n# Perform a left join to add the character names to the script data\n# Drop the character_id column\n# Fill NaN values from the speaking_line column with False\ndf_joined = df_script.merge(df_characters, on='id', how='left').drop(columns=['character_id']).fillna(value={'speaking_line': False})\n\n# Remove non-speaking script lines\ndf_speaking = df_joined[df_joined['speaking_line']].copy()",
          "Remove non-UTF-8 characters from the \"raw_character_text\" and \"spoken_words\" columns\ndf_script['raw_character_text'] = df_script['raw_character_text'].apply(lambda x: x.encode('utf-8', 'ignore').decode('utf-8'))\ndf_script['spoken_words'] = df_script['spoken_words'].apply(lambda x: x.encode('utf-8', 'ignore').decode('utf-8'))",
          " Remove all non-spoken lines\ndf_script = df_script[df_script.speaking_line == True]",
          "Create a new column with the lowercased lines\ndf_script['spoken_words_lower'] = df_script['spoken_words'].str.lower()",
          "Filter out non-dialogue lines from the script data\ndf_script_dialogue = df_script[(df_script[\"speaking_line\"] == True) & (df_script[\"character_id\"].notnull())].reset_index(inplace=False, drop=True)",
          "drop the location quote, raw_location_text, raw_character_text\n# drop normalized text\n# drop has spoken\n# drop timestamp_in_ms\n# drop starts_with_quote\ndf_script.drop(columns=['location_quote', 'raw_location_text', 'raw_character_text', \n                        'normalized_text', 'spoken_words', \n                        'timestamp_in_ms', 'start_with_quote'], inplace=True)",
          " preprocessing the script\ndf_script = df_script[(df_script['speaking_line'] == True)]",
          "Combine name and normalized_text columns\ndf_script['speaking'] = df_script['raw_text']\ndf_script['speaking'] = df_script['speaking'].fillna(df_script['normalized_text'])\n\n# Get first words of each script and lowercase them\ndf_script['first_word'] = df_script['speaking'].apply(lambda x: x.strip().lower().split(' ')[0])",
          "Keep only the communication lines from the script dataframe\ndf_script_lines = df_script[df_script['speaking_line'] == True]\ndf_script_lines.reset_index(inplace=True, drop=True)",
          "Only keep dialog\ndf_script = df_script[df_script['speaking_line'] == True]\n\ndf_script.head()",
          "Remove all the non speaking lines from the script data frame\ndf_script = df_script[df_script.speaking_line == True].copy()",
          " Replace nans in spoken_words with \"\"\ndf_script['raw_character_text'] = df_script['raw_character_text'].fillna(\"\")\ndf_script['spoken_words'] = df_script['spoken_words'].fillna(\"\")",
          "Creating a new DataFrame containing only the raw text of the script lines, and the character that spoke them.\ndf_conversations = df_script[['raw_text', 'character_id']]\ndf_conversations = df_conversations.dropna()\ndf_conversations.reset_index(inplace=True, drop=True)\n\n# The character_id is of float type; converting it to int for compatibility with spacy's EntityRuler\ndf_conversations['character_id'] = df_conversations['character_id'].astype('int')",
          "Preprocess data\ndf_script = df_script[df_script['timestamp_in_ms'] < 6.0e+10]  # Filter out bad data\ndf_script = df_script[(df_script['character_id'] != 2) &  # Remove speaker 'None'\n                      (df_script['character_id'] != 1)]",
          "Filter by spoken words\ndf_script_lines = df_script[df_script['speaking_line'] == True]",
          "Drop conversations with just a single speaker\ndf_script = df_script[df_script['number'] != 'unassigned']",
          "Fix some properties with the types they should have\ndf_script['timestamp_in_ms'] = df_script['timestamp_in_ms'].replace(np.nan, 0).astype('int64')\ndf_script['raw_text'] = df_script['raw_text'].replace(np.nan, '')\ndf_script['speaking_line'] = df_script['speaking_line'].astype(bool)\ndf_script['character_id'] = df_script['character_id'].replace(np.nan, -1).astype('int32')\ndf_script['location_id'] = df_script['location_id'].replace(np.nan, -1).astype('int32')",
          "Remove speech lines that do not contain any actual text in them.\ndf_script = df_script[df_script.raw_text.str.replace(' ', '') != '']\ndf_script = df_script[df_script.raw_text.str.replace(' ', '') != '...']",
          "Remove any rows that have NaN values for the character speaking or the dialogue.",
          " Puts everything to lower case\ndf_script_normalized = df_script\ndf_script_normalized['raw_character_text'] = df_script_normalized['raw_character_text'].str.lower()\ndf_script_normalized['raw_location_text'] = df_script_normalized['raw_location_text'].str.lower()\ndf_script_normalized['spoken_words'] = df_script_normalized['spoken_words'].str.lower()",
          "Remove other voice and change NaN values to Unknown and a unknown values\ndf_script = df_script[(df_script[\"raw_text\"].str.startswith('(') == False)]\ndf_script = df_script.fillna('Unknown')\ndf_script = df_script[df_script['spoken_words'] != 'Unknown']",
          "Add a new column to script dataframe that stores if the line is spoken by a character or not",
          "Filter out bad data\ndf_script = df_script[\n    (df_script.speaking_line == True) & \n    (df_script.character_id != 2) & \n    (df_script.character_id != 1)\n]",
          " Clean 'speaking line' column in df_script\ndf_script = df_script.dropna(subset=['speaking_line'])",
          " Create a column for character names in the script dataframe\ndf_script = df_script[df_script['speaking_line'] == True]  # Keep only rows with a speaking line\ndf_script = df_script.merge(df_characters, left_on='character_id', right_on='id', suffixes=('','_original'))  # Join the character names",
          " Filter out characters who have spoken too few lines\nMIN_LINES = 500\ncharacter_lines = df_script.groupby('character_id').size()\nvalid_characters = character_lines[character_lines > MIN_LINES].index.tolist()\ndf_script = df_script[df_script['character_id'].isin(valid_characters)]",
          "Limit to main character speeches.\ndf_script = df_script[df_script['speaking_line']]",
          "# Preprocessing of the script\n\n# Remove the missing values\ndf_script = df_script.loc[~df_script['raw_text'].isna()]\n\n# Create a dictionary having as key the raw character text and as value the characters' unique identifier\ncharacters_dict = {name:(uid,lines) for uid,name,lines in zip(df_characters['character_id'],df_characters['raw_character_text'], df_characters['spoken_words'])}",
          "Conversion of the columns that contain json format to actual python objects\nimport json\n\ndf_characters['character_image_url'] = df_characters['character_image_url'].apply(lambda x: json.loads(x))\ndf_script['spoken_words'] = df_script['spoken_words'].apply(lambda x: json.loads(x))",
          "Create a new column `text_len` that contains the length of `spoken_words` if not `NaN`, and 0 if `NaN`",
          " Add column of lowercase words to the dataframe",
          "reate a new column containing the processed text from the spoken words in the script\ndf_script['processed_text'] = df_script['spoken_words'].apply(lambda x: nlp(x).text)",
          " Filter only \"spoken_lines\"\ndf_script = df_script[df_script[\"speaking_line\"] == \"true\"].reset_index(inplace=False, drop=True)",
          "Strip quotes around 'raw_location_text' and 'spoken_words' columns\ndf_script['raw_location_text'] = df_script['raw_location_text'].str.strip('\\'')\ndf_script['spoken_words'] = df_script['spoken_words'].str.strip('\\'')",
          "Filter the script data to only include spoken lines from the characters dataframe.",
          "Filter out rows with empty or NaN values for the spoken_words attribute of the script.\ndf_script = df_script.dropna(subset=['spoken_words']).reset_index(drop=True)",
          "Drop useless data\ndf_script = df_script.drop(['index', 'raw_text', 'timestamp_in_ms',\n                            'speaking_line', 'character_id', 'location_id',\n                            'raw_character_text', 'raw_location_text',\n                            'spoken_words'], axis=1)",
          "\n# We only need raw lines from the script\ndf_script = df_script[df_script.speaking_line]",
          "Clean the character list by removing non-speaker tokens\ndf_characters = df_characters[~df_characters['normalized_text'].isin(['string', 'music', 'singing', 'gasps'])]",
          "# Time to process the data and to create a word cloud\n# Filling up the NaN values with empty string\ndf_script = df_script.fillna('')\n# Concatenating the string fields of the data frame\ndf_script['spoken_words_concat'] = df_script['raw_text'] + ' ' + df_script['normalized_text'] + ' ' + df_script['spoken_words']",
          "Create a subset of df_script that contains only spoken lines",
          "Create a subset of the script lines dataframe containing only the spoken lines",
          "Visualize the word cloud for the character speaking lines\nspeaking_lines = df_script.query('speaking_line').reset_index(inplace=False, drop=True)",
          " Step 1: get rid of row copies and script lines with no speaker\ndf_script_cleaned = df_script.drop_duplicates('id').dropna(subset=['raw_character_text']).copy()",
          "Filtering bad lines from dataset\ndf_script = df_script[df_script['raw_character_text'].notna()]\ndf_script = df_script[df_script['spoken_words'].notna()]",
          " Filter the dataframe to only keep the dialogue lines",
          "# Filter the dataframe to only include spoken lines\ndf_script = df_script.loc[df_script['speaking_line'] == True].reset_index(inplace=False, drop=True)"
         ],
         "marker": {
          "opacity": 0.5,
          "size": 5
         },
         "mode": "markers+text",
         "name": "3_Filtering spoken lines in a script",
         "text": [
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          ""
         ],
         "textfont": {
          "size": 12
         },
         "type": "scattergl",
         "x": [
          6.951513767242432,
          7.540623188018799,
          7.862682819366455,
          7.770017623901367,
          6.707935810089111,
          7.706734657287598,
          7.191412925720215,
          8.850935935974121,
          6.874111175537109,
          7.641334056854248,
          7.074404239654541,
          7.728283882141113,
          6.960896968841553,
          5.223922252655029,
          7.837873935699463,
          7.018056392669678,
          7.179396629333496,
          8.435833930969238,
          7.296988487243652,
          8.75683879852295,
          7.777910232543945,
          6.865845680236816,
          7.4142022132873535,
          8.204584121704102,
          7.448496341705322,
          7.563302516937256,
          7.988470077514648,
          7.775925159454346,
          6.40854549407959,
          7.843818664550781,
          7.814726829528809,
          7.260875225067139,
          6.347246170043945,
          5.3516154289245605,
          7.18380880355835,
          6.457245349884033,
          7.415591239929199,
          6.969455242156982,
          6.384449481964111,
          7.322526454925537,
          8.433941841125488,
          7.58595085144043,
          8.384770393371582,
          7.472893238067627,
          5.6782965660095215,
          6.850972652435303,
          7.898927688598633,
          6.417154788970947,
          6.744505405426025,
          7.309834957122803,
          6.1234917640686035,
          8.073954582214355,
          7.574974536895752,
          7.582127094268799,
          8.583955764770508,
          7.443422317504883,
          7.184147357940674,
          7.733220100402832,
          7.963451862335205,
          7.400906085968018,
          6.669787883758545,
          7.104680061340332,
          7.287355899810791,
          7.780863285064697,
          6.2503509521484375,
          6.287435054779053,
          7.166626453399658,
          7.977430820465088,
          6.614352226257324,
          7.595945835113525,
          6.477985858917236,
          8.291964530944824,
          6.881875038146973,
          8.012624740600586,
          8.293919563293457,
          8.04539966583252,
          7.5634660720825195,
          7.0345282554626465,
          6.348080635070801,
          7.915236473083496,
          7.355595588684082,
          5.612100124359131,
          7.433740139007568,
          7.75157356262207,
          6.361169815063477,
          7.495101451873779,
          7.737921714782715,
          6.7994914054870605,
          7.534012317657471,
          6.133223056793213,
          6.976091384887695,
          8.092047691345215,
          7.009830474853516,
          7.256092548370361,
          8.089017868041992,
          6.673022747039795,
          7.753057956695557,
          7.841264247894287,
          6.801806449890137,
          8.391619682312012,
          7.358166694641113,
          5.961685657501221,
          8.386686325073242,
          6.849026679992676,
          7.73240327835083,
          8.107335090637207,
          8.382732391357422,
          8.207883834838867,
          6.567450046539307,
          7.664074420928955,
          8.13157844543457,
          8.12453556060791
         ],
         "y": [
          7.309611797332764,
          7.40595006942749,
          7.598295211791992,
          7.599244117736816,
          7.260274887084961,
          7.701949119567871,
          7.389972686767578,
          6.119206428527832,
          6.580785274505615,
          7.135993003845215,
          7.038605213165283,
          6.856007099151611,
          7.5006937980651855,
          7.8598504066467285,
          6.296539306640625,
          7.1513872146606445,
          7.51985502243042,
          7.1654181480407715,
          7.244394779205322,
          6.356816291809082,
          6.915022850036621,
          7.252382278442383,
          6.526957988739014,
          6.533389091491699,
          6.511114120483398,
          6.519649505615234,
          6.917366981506348,
          6.808520317077637,
          6.165040016174316,
          6.7578816413879395,
          7.553906440734863,
          6.394031524658203,
          6.643405437469482,
          7.55551815032959,
          7.243993282318115,
          7.658410549163818,
          6.791310787200928,
          6.118448734283447,
          7.195930480957031,
          7.185969829559326,
          6.927903652191162,
          6.164511203765869,
          7.192800998687744,
          6.52990198135376,
          8.256677627563477,
          5.728158950805664,
          7.4052581787109375,
          6.973659992218018,
          7.530275344848633,
          6.651299953460693,
          5.3702616691589355,
          7.2639923095703125,
          6.994816303253174,
          7.460965156555176,
          6.320319652557373,
          6.2031145095825195,
          7.619523525238037,
          8.061982154846191,
          7.049526691436768,
          6.8156867027282715,
          5.899035930633545,
          6.394207000732422,
          7.740840435028076,
          6.943713665008545,
          6.487060546875,
          6.966322898864746,
          7.0253448486328125,
          7.109091281890869,
          7.432048320770264,
          6.615283966064453,
          6.430569171905518,
          7.203681468963623,
          7.6280694007873535,
          7.268378257751465,
          6.667003631591797,
          6.799617290496826,
          6.431576251983643,
          6.483473300933838,
          6.623016834259033,
          6.6835761070251465,
          6.673593521118164,
          6.5498552322387695,
          7.3554534912109375,
          5.807519912719727,
          7.383232593536377,
          6.402139663696289,
          6.602957725524902,
          7.18218469619751,
          6.78364896774292,
          8.219013214111328,
          7.791864395141602,
          6.821949005126953,
          7.131806373596191,
          7.348407745361328,
          7.078943729400635,
          7.963542461395264,
          7.480313301086426,
          6.905272006988525,
          7.464641094207764,
          6.1729607582092285,
          6.356294631958008,
          5.958688735961914,
          7.256732940673828,
          7.528290748596191,
          6.9019575119018555,
          6.623274326324463,
          6.384822368621826,
          7.561202049255371,
          6.7310380935668945,
          6.858775615692139,
          5.656582355499268,
          7.06508731842041
         ]
        },
        {
         "hoverinfo": "text",
         "hovertext": [
          "Check the content of Simpsons characters dataset",
          "Since the snippet is incomplete, It cannot be executed. Therefore, I will provide an explanation regarding the code.\nThe code snippet provided contains the import statements for the required libraries along with the custom imports.\nIt also reads csv files for Simpsons characters, locations, script lines, and episodes into pandas dataframes.",
          "Exploring the Simpsons dataset",
          "Now that we have imported the required libraries and loaded the datasets, we can start exploring and analyzing the data to gain insights into \"The Simpsons\" TV show.",
          "First we are importing typical Python libraries such as os, pandas, numpy, spacy, matplotlib, etc. Then we are importing some specific functions and libraries we will use in the script. After the imports, we are reading CSV files using pandas and creating DataFrames for characters, locations, script lines, and episodes from The Simpsons dataset.",
          "Check the content of the file 'simpsons_characters.csv'",
          "df_characters, df_locations, df_script, and df_episodes are DataFrames containing characters, locations, script lines, and episodes data from the Simpsons show.",
          "Check the content of the \"Simpsons Characters\" dataset",
          "Show what the Simpsons characters data looks like",
          "We open the datasets containing the Simpsons script lines, characters, locations, and episodes using pandas, and reset the index.",
          "Extract the name of the characters, location of the scenes and name of the episodes of the Simpsons dataframe",
          " Information of the dataframe related to the Simpsons series",
          "Display types and size of dataframes for the Simpsons data.",
          "This code snippet imports necessary libraries and reads in data from CSV files using pandas. The data includes information about characters, locations, script lines, and episodes from The Simpsons TV show.",
          "Visualisation of the Simpsons dataset",
          " Now the Simpsons dataset is loaded and ready for analysis.",
          "A subset of the Simpson dataset of interest for our text analysis is extracted. The chosen dataset includes the following tables: script lines, episodes, characters, and locations.",
          "Since the filenames for the datasets are 'simpsons_characters.csv', 'simpsons_locations.csv', 'simpsons_script_lines.csv', and 'simpsons_episodes.csv' it can be inferred that the datasets contain information about characters, locations, script lines, and episodes from the show \"The Simpsons.\"",
          "Data from `simpsons_script_lines.csv` will be used since that's where the text data is located.",
          "First, the necessary Python packages are imported. These include standard packages such as `os`, `pandas`, `numpy`, `spacy`, and `matplotlib`, as well as custom packages such as `tqdm` and `Counter`. The `%matplotlib inline` command is also used to ensure that `matplotlib` works correctly with Jupyter.\nThen, four datasets (`df_characters`, `df_locations`, `df_script`, and `df_episodes`) are read from CSV files using `pd.read_csv` and stored in Pandas DataFrames. These datasets contain information about characters, locations, script lines, and episodes from The Simpsons TV show, and will be used for analysis and visualization.",
          " Filter 1 of 1: Imaginationland\n# Due to the lack of imagination in this dataset, the following TV Series will be used\n# The Simpsons\ntv_series = 'the simpsons'",
          " Creating a single dataframe from the simpsons lines and episodes dataframes",
          "Join the \"simpsons_script_lines\" with \"simpsons_episodes\" to extend our dataset.",
          "some of the first attributes come from this explanation https://www.kaggle.com/pierremegret/dialogue-lines-of-the-simpsons#simpsons_script_lines.csv",
          "Merging of Simpsons data into one single dataframe",
          " Let's take a quick look at the Simpsons script data.",
          "source: https://www.kaggle.com/pierremegret/dialogue-lines-of-the-simpsons?select=simpsons_script.csv",
          "Inspect the contents of the 'simpsons_characters.csv' file",
          "To avoid encoding issues, we'll specify the encoding as ISO-8859-1 when reading the Simpsons script lines.",
          "The purpose of this code is to import the required datasets using pandas for analysis of the Simpsons scripts. The data is loaded from CSV files using the `pd.read_csv` function and is stored in pandas dataframes `df_characters`, `df_locations`, `df_script`, and `df_episodes`. These dataframes will be used for further analysis and visualization of the Simpsons script data.",
          "We will use the 'simpsons_script_lines.csv' file to analyze the script lines.",
          "Unable to access the Simpsons dataset for character, location, script, and episodes.",
          "This is an example of loading CSV data into pandas dataframes in Python. The dataframes are named df_characters, df_locations, df_script, and df_episodes. The dataframes will hold the data from the CSV files 'simpsons_characters.csv', 'simpsons_locations.csv', 'simpsons_script_lines.csv', and 'simpsons_episodes.csv', respectively.",
          "Create a new column 'raw_character_text' in the df_script dataframe to store the raw text from the Simpsons script.",
          "All the CSV files need to be found or imported in order to load the Simpsons dataset.",
          " By importing data, we can access the datasets and start working with the Simpson's script.",
          " The script initially loads necessary libraries and datasets to begin the analysis. This includes pandas, numpy, spacy, matplotlib, and the WordCloud library for visualization. It also loads the custom imports tqdm and Counter. The script then loads several datasets such as simpsons_characters, simpsons_locations, simpsons_script_lines, and simpsons_episodes using pandas and assigns them to dataframes df_characters, df_locations, df_script, and df_episodes, respectively.",
          "First, we begin by loading all the necessary data from CSV files using pandas. The data consists of information about Simpsons characters, locations, script lines, and episodes.",
          " Visualisation of character's prevalence in the Simpson corpus",
          "First, we import the required libraries and then load the Simpsons dataset using pandas. The dataset contains information about characters, locations, script lines, and episodes from the Simpsons TV show.",
          "Load and prepare the Simpsons dataset",
          "This code snippet shows the necessary imports and data loading for a data analysis project on Simpsons TV show. The code uses pandas to load CSV files into dataframes and then performs some initial data processing.",
          "Further code will interact with the datasets loaded in the previous step to extract insights or perform analysis on The Simpsons script data.",
          "Extract data for The Simpsons TV show",
          "Assume we want to analyze the script data of the Simpsons. We can start by inspecting the first few rows of the dataset.",
          "Our dataset consists of four DataFrames:\n\n#   df_characters: information about the characters in The Simpsons\n#   df_locations: information about the locations in The Simpsons\n#   df_script: the script of each line in The Simpsons\n#   df_episodes: information about the episodes in The Simpsons",
          "Load the 'simpsons_script_lines.csv', 'simpsons_episodes.csv', 'simpsons_characters.csv', and 'simpsons_locations.csv' files into pandas dataframes.",
          "A sample of the 'simpsons_script_lines' dataset\ndf_script.sample(5)",
          "Place code to further analyze the Simpsons dataset here.",
          "Checking simpsons_characters data",
          "Basic exploration of 'Simpsons' dataset",
          "Check the content of Simpsons characters.",
          "The simpsons_characters.csv, simpsons_locations.csv, and simpsons_episodes.csv files contain the metadata for characters, locations, and episodes, respectively.",
          "Visualizing the Simpsons script data",
          "Visualizations of characters, locations and places in the Simpsons series",
          "We will focus only on the \"Simpsons script lines\" file for this analysis.",
          " We are importing necessary libraries and datasets to preprocess the Simpson script lines.",
          "This code snippet imports the necessary libraries and datasets for the subsequent analysis of Simpson's script data.",
          "Let's start by taking a look at the data from the 'simpsons_characters.csv' file.",
          "Combining the data from simpsons_script_lines with the text data to make the analysis easier.",
          "Display the dataframe about characters in the Simpsons",
          " What is the structured data in the `simpsons_characters.csv`, `simpsons_locations.csv`, `simpsons_script_lines.csv`, and `simpsons_episodes.csv` files?",
          "We will start with the data exploration of the 'simpsons_script_lines.csv' file.",
          "Inspect the Simpsons script data to get an idea of its structure and the information available.",
          "Insight Data Science: Simplifying Script Flows for The Simpsons.",
          "This line of code reads various CSV files containing Simpsons data and stores them in separate dataframes for characters, locations, script lines, and episodes.",
          "Look at the structure of the Simpsons dataset",
          "taken from https://www.kaggle.com/pierremegret/dialogue-lines-of-the-simpsons\n# Some descriptions of the individual dataframes can be found there.",
          "Viewing first 10 records of Simpsons Characters data",
          "Importing the necessary libraries for the analysis of data from \"The Simpsons\" TV show, including spacy, pandas, numpy, and wordcloud. Also, custom imports like tqdm and Counter for additional functionalities.",
          "The Simpsons Script Analysis for Business Insights and Data Analysis",
          "Some initial instructions and library imports for data analysis with The Simpsons dataset.",
          "Data description:\n# - df_characters: information about the characters in the Simpsons series\n# - df_locations: information about the locations where the series takes place\n# - df_script: the script lines for each episode\n# - df_episodes: information about each episode",
          "Assuming you have the following workspace\ndata\n├── simpsons_characters.csv\n├── simpsons_episodes.csv\n├── simpson_locations.csv\n├── simpsons_script_lines.csv",
          "Merge the dataframes to get a comprehensive view of the Simpsons dataset",
          "Insightful Data Analysis to Understand the Simpsons Dataset and Character Interactions",
          "Script lines are too big for the upload to GitHub, but you can find it here:\n# https://www.kaggle.com/ambarish/simpsons-script-lines#simpsons_script_lines.csv",
          "Get an overview of the Simpsons characters dataframe\nprint(\"Number of lines in the dataframe: \" + str(len(df_characters)), \"\\n\")\nprint(df_characters.head(), \"\\n\")\nprint(df_characters.info())",
          "\n# %%bash\n# head -n 3 simpsons_characters.csv",
          "Out-of-the-box excerpted from the summary\n# These scripts are licenced by simpsons_dataset, grouped by season. It contains up to 27 seasons,\n# dated to november 2015, which stands for the 596th episode of this dataset. The author tries to \n# keep contrack for the future.",
          " Defining the problem\n\n# We're given a dataset of Simpson's scripts and we want to use natural language processing (NLP) techniques to better understand the show.",
          "Selecting \"The Simpsons\" TV show from the dataset",
          "The Simpsons dataset files have been read into pandas DataFrames.",
          " Integration of data related to 'the simpsons' such as character, location, script lines and episodes into the notebook.",
          "Normalize `character_name` of `simpsons_script_lines.csv` and `normalized_name` of `simpsons_characters.csv` using spacy's `nlp` model.",
          "We have loaded the necessary libraries and datasets for our Simpsons script analysis. Now we can proceed with data exploration, cleaning, and analysis.",
          "Remove \"cc by-sa 2.0\" from the end of all the lines in simpsons_episodes.csv\n# (this is bad practice, be careful in your own projects, kids!).",
          " Credits to https://www.kaggle.com/pierremegret/dialogue-lines-of-the-simpsons\n# to provide the data on kaggle.",
          "Add the Simpsons script in case the CSV is not available.",
          "Some data is imported to perform exploratory data analysis and natural language processing on a dataset related to \"The Simpsons\" TV show.",
          "For the purpose of this analysis, we are only going to use the gender column from the simpsons_characters.csv file.",
          "Display the data for simpsons characters dataframe",
          "Reading the datasets containing the characters, locations, script lines, and episodes of The Simpsons.",
          "Extract the characters who appear in each simpsons episode and create a new DataFrame",
          "The main principle of dividing data into different datasets is to make them more manageable and easier to work with. By loading the data of Simpsons characters, locations, script lines, and episodes into separate DataFrames, we can perform targeted analysis and explore specific relationships within the data. Additionally, it allows for modularity and reusability of these datasets, providing a more organized structure for data analysis and manipulation.",
          "Import our custom module\nimport simpsons_helper as sh"
         ],
         "marker": {
          "opacity": 0.5,
          "size": 5
         },
         "mode": "markers+text",
         "name": "4_Simpsons dataset analysis using pandas libraries",
         "text": [
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          ""
         ],
         "textfont": {
          "size": 12
         },
         "type": "scattergl",
         "x": [
          11.301013946533203,
          12.328937530517578,
          11.017598152160645,
          11.69809627532959,
          12.2875337600708,
          11.599577903747559,
          0.581549882888794,
          11.141497611999512,
          11.035025596618652,
          10.620291709899902,
          10.543346405029297,
          10.427213668823242,
          10.907694816589355,
          11.814079284667969,
          11.170392036437988,
          12.015284538269043,
          11.73715877532959,
          11.871760368347168,
          12.04162311553955,
          11.982104301452637,
          9.813241004943848,
          9.002881050109863,
          10.950021743774414,
          10.879843711853027,
          5.6618781089782715,
          11.607093811035156,
          10.460119247436523,
          11.695028305053711,
          11.85226058959961,
          11.632658958435059,
          11.222116470336914,
          11.45344066619873,
          11.413673400878906,
          3.790959119796753,
          11.844389915466309,
          11.911407470703125,
          11.815396308898926,
          11.485107421875,
          11.411972999572754,
          11.61807918548584,
          11.269344329833984,
          11.66658878326416,
          11.753032684326172,
          10.79892635345459,
          12.01694107055664,
          1.0299361944198608,
          11.504616737365723,
          11.28415298461914,
          11.438226699829102,
          11.240635871887207,
          11.211967468261719,
          10.836522102355957,
          11.701249122619629,
          11.498544692993164,
          10.783944129943848,
          11.550298690795898,
          12.282332420349121,
          12.274751663208008,
          11.435113906860352,
          11.350208282470703,
          3.5528271198272705,
          11.832842826843262,
          11.886897087097168,
          11.37098503112793,
          12.096914291381836,
          11.737312316894531,
          11.398359298706055,
          10.566025733947754,
          10.84487533569336,
          12.03907585144043,
          12.003032684326172,
          11.764883995056152,
          1.4686936140060425,
          12.315834999084473,
          10.217318534851074,
          11.548359870910645,
          11.881778717041016,
          3.4791452884674072,
          11.568249702453613,
          10.95324993133545,
          12.242992401123047,
          10.305015563964844,
          11.100748062133789,
          11.805961608886719,
          11.694646835327148,
          12.19407844543457,
          12.179150581359863,
          11.193399429321289,
          11.926079750061035,
          12.230618476867676,
          10.836055755615234,
          3.2175092697143555,
          11.477194786071777,
          9.838827133178711,
          11.299336433410645,
          13.00791072845459
         ],
         "y": [
          5.7965407371521,
          3.247194766998291,
          5.469411373138428,
          5.312641620635986,
          2.462355375289917,
          5.399518013000488,
          2.2668511867523193,
          5.631380558013916,
          6.08547306060791,
          3.5023953914642334,
          5.138286590576172,
          5.137758255004883,
          5.621704578399658,
          3.8948616981506348,
          6.09043025970459,
          5.495096206665039,
          5.076972961425781,
          4.505444049835205,
          4.34506893157959,
          3.354844570159912,
          5.510568618774414,
          4.620122909545898,
          4.716827392578125,
          4.761087417602539,
          -0.021217498928308487,
          5.527506351470947,
          4.72562837600708,
          5.010764122009277,
          5.457764148712158,
          3.7153007984161377,
          4.582827568054199,
          5.213770866394043,
          3.6160624027252197,
          12.206066131591797,
          4.965264797210693,
          4.635662078857422,
          2.965989589691162,
          4.438141822814941,
          6.1001105308532715,
          4.589591979980469,
          5.611458778381348,
          2.0128355026245117,
          4.86222505569458,
          5.4378275871276855,
          5.273794174194336,
          2.2655749320983887,
          3.9591245651245117,
          4.303502559661865,
          5.1861090660095215,
          5.9653706550598145,
          5.627059459686279,
          6.079490661621094,
          4.314457416534424,
          5.9522385597229,
          6.339332103729248,
          5.088093280792236,
          4.557661056518555,
          4.671807765960693,
          5.675485134124756,
          5.366286277770996,
          12.653094291687012,
          4.060325622558594,
          4.836733341217041,
          5.486179828643799,
          5.314712047576904,
          3.3188347816467285,
          5.847442626953125,
          5.099236965179443,
          5.462072849273682,
          3.578507423400879,
          5.409985542297363,
          4.817920207977295,
          2.409916639328003,
          4.280243396759033,
          4.8396687507629395,
          5.558800220489502,
          4.789802074432373,
          13.44072437286377,
          4.911479949951172,
          5.5705108642578125,
          4.6170654296875,
          5.367283821105957,
          4.423833847045898,
          5.148210525512695,
          5.235274791717529,
          5.049624443054199,
          5.138562202453613,
          5.186422824859619,
          5.087364196777344,
          4.736090183258057,
          6.4740891456604,
          12.837841033935547,
          5.3492350578308105,
          5.092177391052246,
          4.936570167541504,
          3.899529457092285
         ]
        },
        {
         "hoverinfo": "text",
         "hovertext": [
          "Split location / raw_text.attrib_cleaned characters from script_lines\ndf_loc_identifier_script = df_script\\\n.merge(df_locations, left_on='location_id', right_on='id', suffixes=('_script', '_loc')).drop(columns=['id','normalized_name','image_url'])\\\n.merge(df_characters, left_on='character_id', right_on='id', suffixes=('_loc', '_char')).drop(columns=['id','normalized_name','image_url'])",
          " Merge locations with script\ndf_loc_script = pd.merge(\n    df_script,\n    df_locations,\n    how=\"left\",\n    left_on=\"location_id\",\n    right_on=\"id\",\n    suffixes=(\"-script\", \"-location\"),\n)\n\nprint(f\"We lost {df_loc_script['id-location'].isnull().sum()} records that weren't in the locations dataframe\")",
          "Join Script Lines and Character Info\nmerged_df = pd.merge(df_script, df_characters, left_on='character_id', right_on='id', suffixes=('_script', '_char'), how='left').fillna(value=np.nan)\n\n# Join Script Lines and Location Info\nmerged_df = pd.merge(merged_df, df_locations, left_on='location_id', right_on='id', suffixes=('_script', '_loc'), how='left').fillna(value=np.nan)",
          "Merge the script with the relevant locations and characters\ndf_script_loc_char = df_script.merge(df_locations[['location_id', 'name', 'normalized_name']], on='location_id', how='left')\\\n.merge(df_characters[['character_id', 'name', 'normalized_name']], on='character_id', how='left')",
          "Merge the dataframes to add character information to the script lines\ndf_script = df_script.merge(df_characters, on='character_id', suffixes=('', '_orig'))\n# Merge the dataframes to add location information to the script lines\ndf_script = df_script.merge(df_locations, on='location_id', suffixes=('', '_orig'))",
          "Merge script lines with character and locations data\ndf_script_char = df_script.merge(df_characters, how='left', left_on='character_id', right_on='id')",
          " Merge names with main characters and locations\ndf_script = pd.merge(df_script, df_characters,\n                    how='left', left_on='character_id', right_on='id')",
          " Add column with the full name of the character and the location to the script lines dataframe\ndf_script = (\n    df_script\n    .merge(df_characters[['id', 'name']], left_on='character_id', right_on='id', suffixes=(None, '_character'))\n    .merge(df_locations[['id', 'name']], left_on='location_id', right_on='id', suffixes=(None, '_location'))\n)",
          "Merge character & location into scripts dataframe\ndf_script = df_script.merge(df_characters[['id', 'name']], left_on='character_id', right_on='id', suffixes=('', '_character'))\ndf_script = df_script.merge(df_locations[['id', 'name']], left_on='location_id', right_on='id', suffixes=('', '_location'))",
          " Merge script lines with linking character and location information\ndf_script_location = df_script.copy()\ndf_script_location['character_id'] = df_script_location['character_id'].astype(str)",
          "Merge script lines, characters and locations\ndf_merged = df_script.merge(df_characters, how='left', on='character_id')",
          "Merge script lines with the characters and locations\ndf_merged = pd.merge(df_script, df_characters, left_on='character_id', right_on='character_id', suffixes=('_script', '_character'))\ndf_merged = pd.merge(df_merged, df_locations, left_on='location_id', right_on='location_id', suffixes=('_df_merged', '_location'))",
          " Merge locations into script df\ndf_script_locations = pd.merge(df_script, df_locations, how='left', left_on='location_id', right_on='id').drop(columns=['id', 'location_id']).rename(columns={\"name\": \"location\"})",
          "Merge character information into the main script DataFrame\ndf_script = pd.merge(\n    df_script, \n    df_characters,\n    how=\"left\",\n    left_on=\"character_id\",\n    right_on=\"id\"\n)\n\n# Merge location info into the main script DataFrame\ndf_script = pd.merge(\n    df_script, \n    df_locations,\n    how=\"left\",\n    left_on=\"location_id\",\n    right_on=\"id\"\n)",
          "Merge the characters and script dataframes\ndf = pd.merge(df_characters, df_script, left_on='id', right_on='character_id', suffixes=('_characters', '_script'))\ndf = pd.merge(df, df_locations, left_on='location_id', right_on='id', suffixes=('', '_locations'))",
          " Merge the script data with the character data\ndf = df_script.merge(df_characters, on='character_id', how='left')\ndf = df.merge(df_locations, on='location_id', how='left')",
          " Merge locations into script dataframe\ndf_script = (\n    df_script\n    .merge(\n        df_locations,\n        how='left',\n        left_on='raw_location_text',\n        right_on='raw_location_text',\n    )\n    .rename(columns={'normalized_location':'location'})\n    .drop(columns='timestamp_in_ms')\n)",
          "Merge the scripts with the corresponding characters and locations\ndf_character_script = df_characters.merge(df_script, on='character_id')\ndf_merged = df_character_script.merge(df_locations, on='location_id')",
          "Join locations to scripts\ndf_locations = df_locations.rename(columns={'id': 'location_id'})",
          "Merge location into script data frame\ndf_script = df_script.merge(df_locations, left_on='raw_location_text', right_on='name', how='left').rename(columns={'normalized_name': 'location'})",
          " Merge characters and their location\ndf_characters_location = pd.merge(df_characters, df_locations, how='left', left_on='location_id', right_on='id', suffixes=('character', 'location')).drop('idlocation', axis=1)",
          "Combine locations and scripts\ndf_script_locations = df_script.merge(df_locations, left_on='location_id', right_on='id', suffixes=('_script', '_location'))",
          "Merge scripts with locations\ndf_merged = pd.merge(df_script, df_locations, left_on='location_id', right_on='id', suffixes=('_script', '_location'))\n\n# See the data\ndf_merged.head()",
          "Join the characters and locations to the script data\ndf_script_characters = df_script.join(df_characters.set_index('character_id'), on='character_id', rsuffix='_character')\ndf_script_locations = df_script_characters.join(df_locations.set_index('location_id'), on='location_id', rsuffix='_location')",
          "\n# Merge the dialogue with the corresponding characters and location\ndf_merged = df_script.merge(df_characters[['id', 'name']], left_on='character_id', right_on='id')\ndf_merged = df_merged.rename(columns={'name': 'character_name'}).drop(columns='id')\ndf_merged = df_merged.merge(df_locations[['id', 'name']], left_on='location_id', right_on='id')\ndf_merged = df_merged.rename(columns={'name': 'location_name'}).drop(columns='id')",
          "Selecting only the lines in which the characters and locations exist\ndf_script = df_script[df_script[\"normalized_text\"].notna()]\ndf_script = df_script[df_script[\"location_id\"].notna()]\n\n# Left joining the script dataset with the character names and location names\ndf_script = pd.merge(df_script, df_characters['name'], how='left', left_on=df_script['character_id'], right_index=True)\ndf_script = df_script.rename(columns={'name': 'character_name'})\n\ndf_script = pd.merge(df_script, df_locations['name'], how='left', left_on=df_script['location_id'], right_index=True)\ndf_script = df_script.rename(columns={'name': 'location_name'})\n\n# Dropping the location_id and character_id columns\ndf_script = df_script.drop(columns=['location_id', 'character_id'])",
          " Merge characters and locations into the script dataframe\ndf_script = pd.merge(df_script, df_characters, left_on='character_id', right_on='id', suffixes=('','_character')).drop(columns=['id','normalized_name']).reset_index(drop=True)\ndf_script = pd.merge(df_script, df_locations, left_on='location_id', right_on='id', suffixes=('','_location')).drop(columns=['id']).reset_index(drop=True)",
          "Combine the script data with the character and location data per script line.\ndf_script = (\n    df_script\n    .merge(df_characters, how='left', left_on='character_id', right_on='id', suffixes=(False, False))\n    .merge(df_locations, how='left', left_on='location_id', right_on='id', suffixes=(False, False))\n)",
          "Join scripts with characters and locations\ndf_script = pd.merge(df_script, df_characters, how='left', left_on='character_id', right_on='id', suffixes=('', '_character'))\ndf_script = pd.merge(df_script, df_locations, how='left', left_on='location_id', right_on='id', suffixes=('', '_location'))",
          "Merge script with characters and locations\ndf_script = pd.merge(df_script,\n                     df_characters,\n                     left_on='character_id',\n                     right_on='id',\n                     suffixes=('_script', '_character'),\n                     validate='many_to_one')\n\ndf_script = pd.merge(df_script,\n                     df_locations,\n                     left_on='location_id',\n                     right_on='id',\n                     suffixes=('_script', '_location'),\n                     validate='many_to_one')",
          " Merge characters and locations into the script dataframe\ndf_script = df_script.merge(df_characters, how='left', left_on='character_id', right_on='id', suffixes=(None, '_character'))\ndf_script = df_script.merge(df_locations, how='left', left_on='location_id', right_on='id', suffixes=(None, '_location'))",
          " Merging the scripts with characters and locations datasets\ndf_script = pd.merge(df_script, df_characters, left_on='character_id', right_on='id')\ndf_script = df_script.rename(columns={'name': 'character_name'})\ndf_script = pd.merge(df_script, df_locations, left_on='location_id', right_on='id')\ndf_script = df_script.rename(columns={'name': 'location_name'})",
          "Merge character and location info into script data\ndf_script = df_script.merge(df_characters, on='Character_ID', suffixes=('', '_y'))\ndf_script = df_script.merge(df_locations, on='Location_ID', suffixes=('', '_y'))",
          " Merge with the location data to get the locations mentioned per line\ndf_lines_with_locations = pd.merge(df_script, df_locations, how='left', left_on='location_id', right_on='id')",
          "Merge character and location quote lines\ndf_char_loc = df_script[(df_script['character_id'] <= df_characters.shape[0]) & (df_script['location_id'] <= df_locations.shape[0])].reset_index(inplace=False, drop=True)\ndf_char_loc[\"character\"] = df_char_loc['character_id'].map(df_characters['name'])\ndf_char_loc[\"location\"] = df_char_loc['location_id'].map(df_locations['name'])\n\n# Verify the new DataFrame\ndf_char_loc.head()",
          "Merge characters, locations and script\ndf = df_script.merge(df_characters, left_on='character_id',\n                     right_on='character_id', suffixes=('_script', '_character'))\ndf = df.merge(df_locations, left_on='location_id', right_on='location_id', suffixes=('_script', '_location'))",
          "Creating master dataframe with character, location and line information\ndf = pd.merge(df_script, df_characters, on='character_id', how='left')\ndf = pd.merge(df, df_locations, on='location_id', how='left')",
          "Join characters and locations with scripts dataframes\ndf_script_characters = pd.merge(df_script, df_characters, how='inner', left_on='character_id', right_on='id', suffixes=('_script', '_character'))\ndf_script_locations = pd.merge(df_script, df_locations, how='inner', left_on='location_id', right_on='id')",
          "# Ensure all have the same name for character id column\ndf_characters = df_characters.rename(columns={'id': 'character_id'})\ndf_locations = df_locations.rename(columns={'id': 'location_id'})",
          "Merge locations and script_data\nlocations_script = df_locations.rename(columns={\"id\": \"location_id\"}).merge(\n    df_script.rename(columns={\"location_id\": \"script_location_id\"}),\n    how='left',\n    on='location_id'\n)",
          "merged_df = df_script.merge(df_characters, on='raw_character_text', how = 'left')\nmerged_df = merged_df.merge(df_locations, on='raw_location_text', how = 'left')",
          "Merge script with characters and locations\ndf_all = pd.merge(df_script, df_characters, how='left', left_on='character_id', right_on='id')\ndf_all = pd.merge(df_all, df_locations, how='left', left_on='location_id', right_on='id')",
          "Join script with characters and locations\ndf_script_characters = pd.merge(\n    df_script,\n    df_characters,\n    how='left',\n    left_on=['raw_character_text'],\n    right_on=['name']\n)\n\ndf_script_locations = pd.merge(\n    df_script,\n    df_locations,\n    how='left',\n    left_on=['raw_location_text'],\n    right_on=['name']\n)",
          "Merge the dialog lines with the character and location tables\ndf_ep_char_loc_lines = df_script.merge(\n    df_characters,\n    left_on='character_id',\n    right_on='id',\n    suffixes=('','_character')\n).merge(\n    df_locations,\n    left_on='location_id',\n    right_on='id',\n    suffixes=('','_location')\n)\n\ndf_ep_char_loc_lines.head()",
          " Merge characters and script\ndf_characters_script = df_script.merge(df_characters, left_on='character_id', right_on='id')\n\n# Merge locations and script\ndf_locations_script = df_script.merge(df_locations, left_on='location_id', right_on='id')",
          "Join script, characters and locations\ndf_script_full = df_script\\\n    .merge(\n        df_characters,\n        how='left',\n        left_on='character_id',\n        right_on='id'\n    )\\\n    .merge(\n        df_locations,\n        how='left',\n        left_on='location_id',\n        right_on='id'\n    )",
          "# Combine location data into script data\ndf_script_locations = df_script[\n    df_script['raw_location_text'].notna() & df_script['location_id'].isna()\n].merge(df_locations.add_prefix('loc_'), left_on='raw_location_text', right_on='loc_name', how='left').rename(columns={'loc_location_id': 'location_id'})\n\n# Update script data with location ids\ndf_script = df_script.merge(df_script_locations[['id', 'location_id']], on='id', how='left').fillna({'location_id': -1})",
          "Merge characters in script\ndf_script_characters = df_script.merge(df_characters, how='left', on='id', suffixes=('_script', '_character'))\n\n# Merge locations in script\ndf_script_locations = df_script_characters.merge(df_locations, how='left', left_on='raw_location_text', right_on='raw_location_text', suffixes=('', '_location'))",
          "Merge the data into a single dataframe for analysis\ndf_characters_SCRIPT = df_characters.rename(columns={'id':'character_id'}).merge(df_script.rename(columns={'character_id_id':'character_id'}), on='character_id')\ndf_locations_SCRIPT = df_locations.rename(columns={'id':'location_id'}).merge(df_script.rename(columns={'location_id_id':'location_id'}), on='location_id')",
          "Merge character metadata\ndf_characters_and_locations = pd.merge(\n    df_characters,\n    df_locations,\n    how='outer',\n    left_on='id',\n    right_on='normalized_name'\n)",
          " Merge script, characters, and locations\ndf_all = pd.merge(df_script, df_characters, on='raw_character_text', how='left')\ndf_all = pd.merge(df_all, df_locations, on='raw_location_text', how='left')",
          "Merge the script and the character datasets\ndf_characters = df_characters.rename(columns=lambda x: \"character_\" + x)\ndf_script = pd.merge(df_script, df_characters, left_on=\"character_id\", right_on=\"character_id\", how='left')\n\n# Merge the script and the location datasets\ndf_locations = df_locations.rename(columns=lambda x: \"location_\" + x)\ndf_script = pd.merge(df_script, df_locations, left_on=\"location_id\", right_on=\"location_id\", how='left')",
          "Merge the scripts dataframe with the character and location dataframes\ndf_script_char = df_script.merge(df_characters, left_on='character_id', right_on='id', suffixes=('_script', '_char'))\ndf_script_char_loc = df_script_char.merge(df_locations, left_on='location_id', right_on='id', suffixes=('_merge', '_loc'))",
          "Merge characters and locations to get character_speech\ndf_char_loc = pd.merge(df_script, df_characters, how='left', left_on='raw_character_text', right_on='character_text')\ndf_char_loc.rename(columns={'character_id': 'raw_character_id', 'name': 'raw_character_name'}, inplace=True)\ndf_char_loc = pd.merge(df_char_loc, df_locations, how='left', left_on='raw_location_text', right_on='location_text')\ndf_char_loc.rename(columns={'location_id': 'raw_location_id', 'name': 'raw_location_name'}, inplace=True)",
          "Merge character lines with character and location data\ndf_merged = df_script.merge(df_characters, on='character_id', suffixes=('', '_char'))\ndf_merged = df_merged.merge(df_locations, on='location_id', suffixes=('', '_loc'))\n\n# Print first few rows\ndf_merged.head()",
          " Merge script with character info and its location\ndf_script = df_script.merge(df_characters, how='inner', on='character_id')\ndf_script = df_script.merge(df_locations, how='inner', on='location_id')",
          "combine the script with the character and location for each line\ndf_script_full = (\n    df_script\n    .merge(df_characters, how='left', left_on='character_id', right_on='id', suffixes=('_script', '_character'))\n    .merge(df_locations, how='left', left_on='location_id', right_on='id', suffixes=('_script', '_location'))\n)",
          "Merge characters, locations and script together\ndf_script = df_script.merge(df_characters, how='left', on='character_id')\ndf_script = df_script.merge(df_locations, how='left', on='location_id')",
          "# Merge script and location with character information\n# WARNING: this step can take a few minutes as it requires to process all the textual data\ndf_merged = pd.merge(df_script,\n                     df_characters,\n                     how='left',\n                     left_on='character_id',\n                     right_on='id')\n\ndf_merged = pd.merge(df_merged,\n                     df_locations,\n                     how='left',\n                     left_on='location_id',\n                     right_on='id')",
          "Merge datasets to match lines with characters and locations\ndf_joined_script = df_script.merge(df_characters, on='character_id', how='left')\ndf_joined_script = df_joined_script.merge(df_locations, on='location_id', how='left')",
          "Harmonize character locations\ndf_harmonized = df_script.merge(df_characters, left_on=\"character_id\", right_on=\"id\", suffixes=('_script', '_character'))\ndf_harmonized = df_harmonized.merge(df_locations, left_on=\"location_id\", right_on=\"id\", suffixes=('_character', '_location'))",
          " Merging script with characters and locations\ndf_script_chars = df_script.merge(df_characters, left_on='character_id', right_on='id', suffixes=('_script', '')).drop(columns='id')\ndf_script_loca = df_script_chars.merge(df_locations, left_on='location_id', right_on='id', suffixes=('_script', '')).drop(columns='id')",
          "Merge script with characters and locations data\ndf_script = df_script.merge(df_characters, left_on='character_id', right_on='id', suffixes=('', '_character'))\ndf_script = df_script.merge(df_locations, left_on='location_id', right_on='id', suffixes=('', '_location'))",
          "Combine the script with the character names and locations\ndf_script_ext = (\n    df_script\n    .merge(df_characters.rename(columns={\"id\": \"character_id\"}), on=\"character_id\")\n    .merge(df_locations.rename(columns={\"id\": \"location_id\"}), on=\"location_id\")\n)",
          "Create a new dataframe that merges lines and characters dataframes on character id, then merges result with locations dataframe on location id.",
          "Merge the script with the characters and locations\ndf_script_characters = pd.merge(df_script, df_characters, left_on='character_id', right_on='id', suffixes=('_script', '_character')).drop(columns='id_character')\ndf_script_characters_locations = pd.merge(df_script_characters, df_locations, left_on='location_id', right_on='id', suffixes=('_script', '_location')).drop(columns='id_location')",
          "Merge characters, locations and script\ndf_merged = pd.merge(df_script, df_characters, left_on='character_id', right_on='id').merge(df_locations, left_on='location_id', right_on='id')",
          " merging characters and locations with the script lines\ndf_script_lines_characters = df_script_lines.merge(df_characters, on='character_id')\ndf_script_lines_characters_locations = df_script_lines_characters.merge(df_locations, on='location_id')",
          " Rename ID columns\ndf_characters = df_characters.rename(columns={'id': 'character_id'})\ndf_locations = df_locations.rename(columns={'id': 'location_id'})",
          "join locations and characters\ndf_joined = df_locations.merge(\n    df_characters,\n    left_on='location_id',\n    right_on='location_id',\n    how='inner'\n)",
          "Merge characters, locations and lines\ndf = pd.merge(df_script, df_characters, left_on='character_id', right_on='character_id',  how='inner')\ndf = pd.merge(df, df_locations, left_on='location_id', right_on='location_id', how='inner')",
          "Merge script and character dataframes\ndf_script['character'] = df_script['character_id'].apply(lambda x: df_characters['name'][x])\ndf_script['location'] = df_script['location_id'].apply(lambda x: df_locations['name'][x])\ndf_script['raw_location_id'] = df_script['location_id']\ndf_script['location_id'] = df_script['location']",
          "Merge script with character & location infos\ndf_script_char = pd.merge(df_script, df_characters, how='inner', left_on=['character_id'], right_on=['id']).rename(columns={'name': 'character_name'}).drop(columns=['id'])\ndf_script_char_loc = pd.merge(df_script_char, df_locations, how='left', left_on=['location_id'], right_on=['id']).rename(columns={'name': 'location_name'}).drop(columns=['id'])",
          "Merge the script with characters and locations\ndf_script_chars_locations = pd.merge(df_script, df_characters, left_on='raw_character_text', right_on='character_name', how='left')\n\ndf_script_chars_locations = pd.merge(df_script_chars_locations, df_locations, left_on='raw_location_text', right_on='raw_location_text', how='left')\n\n# Verify the result\ndf_script_chars_locations.head()",
          "Merge script data with character and location data\ndf_script_full = (df_script.merge(df_characters[['id', 'normalized_name']], \n                                  left_on='character_id', \n                                  right_on='id', \n                                  how='left')\n                            .rename(columns={'normalized_name': 'character_name'})\n                            .drop(columns='id')\n                            .merge(df_locations[['id', 'normalized_name']], \n                                   left_on='location_id', \n                                   right_on='id', \n                                   how='left')\n                            .rename(columns={'normalized_name': 'location'})\n                            .drop(columns='id')\n                  )\n\ndf_script_full.head()",
          "Merge character and location to script\ndf_script = df_script.merge(df_characters[['character_id', 'character_name']], \n                            how='left', on='character_id')\ndf_script = df_script.merge(df_locations[['location_id', 'location_name']], \n                            how='left', on='location_id')",
          "merge script and location on\n#location_id\ndf_merged = pd.merge(df_script, df_locations, how='inner', on='location_id')",
          " Merge script data with corresponding character and location data\ndf_script_character = df_script.merge(df_characters, on='character_id', how='left')\ndf_script_location = df_script.merge(df_locations, on='location_id', how='left')",
          "Merge characters and locations with the main df_script DataFrame\ndf_script['character'] = df_script['character_id'].map(df_characters.set_index('id')['name'])\ndf_script['location'] = df_script['location_id'].map(df_locations.set_index('id')['name'])",
          "Merge the characters and locations dataframes to the script dataframe using the 'character_id' and 'location_id' columns respectively.\ndf_script = df_script.merge(df_characters, on='character_id', how='left')",
          " Merge script with characters and locations names\ndf = df_script.merge(df_characters[['id', 'name']], how='left', left_on='character_id', right_on='id')\ndf = df.rename(columns={'name': 'character_name'}).drop('id', axis=1)\ndf = df.merge(df_locations[['id', 'name']], how='left', left_on='location_id', right_on='id')\ndf = df.rename(columns={'name': 'location_name'}).drop('id', axis=1)",
          "Merge locations and script\ndf_locations_script = pd.merge(\n    df_locations,\n    df_script,\n    left_on='id', \n    right_on='location_id',\n    suffixes=('_location', '_script')\n).drop(['id', 'location_id'], axis=1)",
          "Merge with characters and locations names\ndf_script = df_script.merge(df_characters[['id', 'name']], how='left', left_on='character_id', right_on='id', suffixes=('', '_c')).drop('id', axis=1)\ndf_script = df_script.merge(df_locations[['id', 'name']], how='left', left_on='location_id', right_on='id', suffixes=('', '_l')).drop('id', axis=1)",
          "merge script, characters and locations tables\ndf_script_char = pd.merge(df_script, df_characters, left_on='character_id', right_on='id', suffixes=('_script', '_char')).drop(columns='id')\ndf_script_char_loc = pd.merge(df_script_char, df_locations, left_on='location_id', right_on='id', suffixes=('', '_loc')).drop(columns='id')",
          "Merge df_script with df_characters and df_locations\ndf_script_characters_locations = pd.merge(\n    pd.merge(df_script, df_characters, on='character_id', how='left'),\n    df_locations,\n    on='location_id',\n    how='left'\n)",
          "Merge the characters and locations into the main script dataframe\ndf_script = pd.merge(df_script, df_characters, how='left',\n                     left_on='character_id', right_on='id')\ndf_script = pd.merge(df_script, df_locations, how='left',\n                     left_on='location_id', right_on='id')",
          " merge the locations with the script lines\ndf_locations = df_locations.rename(columns={\"id\": \"raw_location_id\"})\ndf_script = df_script.rename(columns={\"raw_location_id\": \"location_id\"})",
          "Merge the script lines with the characters and locations information\ndf_script_full = df_script.merge(df_characters, how='left', on='character_id')\ndf_script_full = df_script_full.merge(df_locations, how='left', on='location_id')",
          " Combine script lines with characters and locations\ndf_script_full = pd.merge(df_script, df_characters, on='character_id', how='left')\ndf_script_full = pd.merge(df_script_full, df_locations, on='location_id', how='left')",
          "Merge characters and locations into the script DataFrame\ndf_script = df_script.merge(df_characters, how='left', left_on='character_id', right_on='id')\ndf_script = df_script.merge(df_locations, how='left', left_on='location_id', right_on='id')"
         ],
         "marker": {
          "opacity": 0.5,
          "size": 5
         },
         "mode": "markers+text",
         "name": "5_Merging Character and Location Data in a Script",
         "text": [
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          ""
         ],
         "textfont": {
          "size": 12
         },
         "type": "scattergl",
         "x": [
          3.0240001678466797,
          2.1449766159057617,
          2.831418752670288,
          3.861884593963623,
          2.9870426654815674,
          3.5069005489349365,
          3.9278852939605713,
          3.7591419219970703,
          3.2234854698181152,
          3.41838002204895,
          3.8228683471679688,
          2.8574275970458984,
          3.2309482097625732,
          3.1206042766571045,
          2.8400375843048096,
          3.727268695831299,
          3.5465407371520996,
          3.5775928497314453,
          3.64284348487854,
          3.435460090637207,
          3.0030415058135986,
          2.560195207595825,
          2.3767988681793213,
          3.870297431945801,
          3.0585124492645264,
          3.360752582550049,
          3.4934394359588623,
          3.4995100498199463,
          2.8301122188568115,
          2.665741443634033,
          2.8436102867126465,
          3.05851411819458,
          2.940404176712036,
          3.4426562786102295,
          3.6699492931365967,
          3.122675895690918,
          3.1883175373077393,
          2.6032090187072754,
          3.8947393894195557,
          3.2238523960113525,
          3.8072869777679443,
          3.1179087162017822,
          3.222430467605591,
          3.4225900173187256,
          3.2287192344665527,
          3.1424992084503174,
          2.8905386924743652,
          3.196976661682129,
          3.644327163696289,
          3.3272922039031982,
          3.7012622356414795,
          3.0861473083496094,
          3.2765283584594727,
          3.4559261798858643,
          3.343451976776123,
          3.1524085998535156,
          3.6718361377716064,
          3.323023796081543,
          3.071448564529419,
          3.215704917907715,
          2.956949234008789,
          3.132362127304077,
          3.225484848022461,
          3.7233850955963135,
          3.672811508178711,
          3.356727361679077,
          2.8138351440429688,
          2.994856595993042,
          3.541177988052368,
          2.9391257762908936,
          2.903120279312134,
          3.4994609355926514,
          3.3066599369049072,
          3.2625105381011963,
          3.3705132007598877,
          3.1669492721557617,
          2.347785711288452,
          3.4186205863952637,
          4.069098472595215,
          3.2490346431732178,
          3.4816408157348633,
          2.6854045391082764,
          3.025125026702881,
          3.034742832183838,
          3.235849380493164,
          3.1060123443603516,
          3.610368490219116,
          3.3312597274780273,
          3.397090196609497,
          3.3017871379852295
         ],
         "y": [
          9.4515380859375,
          9.997276306152344,
          10.59952449798584,
          9.675522804260254,
          10.008994102478027,
          10.336357116699219,
          10.69481086730957,
          9.906231880187988,
          9.827198028564453,
          10.51486587524414,
          10.210018157958984,
          10.466045379638672,
          9.452093124389648,
          11.075776100158691,
          10.17408561706543,
          10.321235656738281,
          9.504105567932129,
          10.03736686706543,
          9.016603469848633,
          9.314070701599121,
          10.42807674407959,
          10.123212814331055,
          10.129014015197754,
          9.428860664367676,
          9.058004379272461,
          9.183667182922363,
          9.389683723449707,
          10.25288200378418,
          10.624336242675781,
          10.357820510864258,
          10.36078929901123,
          9.442766189575195,
          9.97724723815918,
          10.277663230895996,
          9.467704772949219,
          10.098679542541504,
          10.534472465515137,
          10.525049209594727,
          8.601009368896484,
          9.532145500183105,
          11.067614555358887,
          10.831425666809082,
          11.12215805053711,
          9.412958145141602,
          10.49543285369873,
          10.56183910369873,
          9.602947235107422,
          10.619677543640137,
          9.35886287689209,
          11.15004825592041,
          11.061001777648926,
          10.131245613098145,
          10.265273094177246,
          9.326483726501465,
          10.352340698242188,
          10.589241981506348,
          10.32263469696045,
          10.657312393188477,
          11.160202980041504,
          10.390277862548828,
          10.332236289978027,
          9.662885665893555,
          10.131552696228027,
          9.146895408630371,
          9.824400901794434,
          9.153185844421387,
          10.725050926208496,
          9.985167503356934,
          8.455696105957031,
          10.368204116821289,
          10.847711563110352,
          9.839756965637207,
          9.185763359069824,
          10.991671562194824,
          9.245160102844238,
          10.404729843139648,
          10.324543952941895,
          10.639472007751465,
          9.502598762512207,
          10.339587211608887,
          8.96934986114502,
          9.769469261169434,
          9.506542205810547,
          9.896383285522461,
          11.01733112335205,
          10.594629287719727,
          8.8995943069458,
          10.700356483459473,
          10.737460136413574,
          10.757408142089844
         ]
        },
        {
         "hoverinfo": "text",
         "hovertext": [
          "Viewing the structure of the characters dataset",
          "Let's take a preview of the character data",
          " Look at who the characters are",
          "Defines the character names by its reception of the user defined name in a lowercase manner for searching consistency",
          "EDA on the characters dataset",
          "Check the character dataset",
          "Inspect the characters dataset",
          "Quick look at the character data",
          " Let's take a look at the characters dataset first.",
          "the `str` accossor will be used for performing string operations on the Series.",
          "Check what is inside the table of characters",
          "Let's take a look at the character data:",
          "Define the parser for the names",
          "Let's take a look at the characters dataset.",
          "Combining all character lines to obtain a single document for each character.",
          "Looking at the distribution of the character lines in the dataset before and after removing the 'NaN's.",
          "Let's inspect the first 5 records of the dataset containing the characters.",
          " Check the first few rows of the characters data.",
          "check character count and header",
          "Inspecting the first few characters of each table",
          " Set up statistics for the characters.",
          "Check the content of the first dataset (characters)",
          "Select your character of interest from the list of characters. Fill in the character name in the variable below.",
          " Show info of dataset of characters.",
          "Check the content of the characters file",
          "Inspect the character dataset",
          " Get the outfit color of the characters",
          " Display read data for characters.",
          " Making it easier to recognize the characters used in the dataset.",
          " Looking at the first couple of entries of our characters dataset",
          "Building the graph of the characters relationships.",
          "Checking out the content of the characters data",
          "Merge the character line with the character.",
          "Join the dataset on the character ID",
          "Let's see what the character data looks like.",
          "Explore the characters dataset",
          "Extract information about the characters",
          "Check the character dataset",
          "Checking the format of the data for characters",
          "Character names often appear with spaces and uppercase letters and a dot at the end.",
          "Look at the character data.",
          "Ensure all strings are actually strings.",
          "Let's have a look at Character lines and Locations.",
          "Let's look at the character dataset first.",
          "Exploring the characters dataset",
          "Check if characters have an alternative name",
          "Inspecting the first dataset - characters",
          " Let's sample the characters dataset and understand its structure.",
          "Exploring the characters dataset",
          "Get data from users_dicussion of all characters.",
          "We will start by analyzing the characters' lines.",
          "Simple visualisation to have an idea of the different characters.",
          "Examine the contents of the characters dataset",
          "Build a single dataset containing all the character lines and metadata",
          "Preview characters dataset.",
          "Inspect the table of characters.",
          " Let's take a look at the characters data.",
          "Character level counts",
          "function to get the character quotes",
          "Check the character id 2.",
          "Build a lookup table for characters and their gender.",
          "First, let's take a look at the character dataset.",
          " Displaying the records of the characters data.",
          " Check the content of the 'characters' file",
          "Checking Character details",
          "Inspect dataset 1: Characters",
          "Inspect the characters table",
          " Display general information of dataset characters",
          "Show the result of the first execution of the characters data base",
          "Let's take a look at the characters data.",
          " Combine first and last name for character identification",
          "Let's check how the character dataset looks like",
          "Creating a character-level dataset for each character in the list",
          "Extracting the names of the main characters from the table's names_eps variable.",
          "Visualising some basic character and location information",
          "wip - build character counts",
          "Define the string keyword for the characters we want to consider.",
          "Let's take a look at the characters data.",
          "Check whether characters names are duplicated or not.",
          "Let's first analyze the characters.",
          "Characters and locations involve different entries for different versions or spellings."
         ],
         "marker": {
          "opacity": 0.5,
          "size": 5
         },
         "mode": "markers+text",
         "name": "6_Character Dataset Inspection",
         "text": [
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          ""
         ],
         "textfont": {
          "size": 12
         },
         "type": "scattergl",
         "x": [
          10.215843200683594,
          10.858153343200684,
          9.656620025634766,
          10.432351112365723,
          10.460431098937988,
          10.338699340820312,
          10.239027976989746,
          10.811729431152344,
          10.884845733642578,
          11.319988250732422,
          10.473145484924316,
          10.966166496276855,
          10.788715362548828,
          10.948225021362305,
          10.936895370483398,
          10.436243057250977,
          10.39456844329834,
          10.657136917114258,
          10.349863052368164,
          10.936881065368652,
          10.692045211791992,
          10.568422317504883,
          10.064103126525879,
          9.977766036987305,
          10.968865394592285,
          10.236170768737793,
          10.141742706298828,
          10.693254470825195,
          10.674548149108887,
          10.650485038757324,
          10.526762008666992,
          10.310151100158691,
          10.538474082946777,
          6.7312188148498535,
          11.103203773498535,
          10.270651817321777,
          10.144620895385742,
          10.484039306640625,
          10.7367582321167,
          10.465117454528809,
          10.972925186157227,
          11.160859107971191,
          9.809046745300293,
          10.776323318481445,
          10.036515235900879,
          10.125284194946289,
          10.406017303466797,
          10.684723854064941,
          10.078753471374512,
          9.797245025634766,
          11.015202522277832,
          9.938567161560059,
          10.235729217529297,
          9.909268379211426,
          10.491531372070312,
          10.765384674072266,
          10.5514497756958,
          11.069350242614746,
          9.851280212402344,
          11.074300765991211,
          9.265216827392578,
          10.922452926635742,
          10.269484519958496,
          10.71995735168457,
          10.257062911987305,
          10.359986305236816,
          10.554566383361816,
          9.75605583190918,
          10.534605026245117,
          10.645410537719727,
          9.499095916748047,
          10.885417938232422,
          10.388582229614258,
          10.143263816833496,
          9.571832656860352,
          10.759900093078613,
          10.764946937561035,
          10.86873722076416,
          10.539956092834473,
          10.537932395935059,
          10.317497253417969
         ],
         "y": [
          8.827401161193848,
          9.05489444732666,
          7.174106121063232,
          6.636632442474365,
          8.901677131652832,
          8.763924598693848,
          9.012579917907715,
          8.504725456237793,
          9.47518539428711,
          7.253915309906006,
          8.432680130004883,
          8.650288581848145,
          5.910764694213867,
          9.041418075561523,
          7.46299934387207,
          10.006053924560547,
          9.491437911987305,
          8.539020538330078,
          8.296582221984863,
          9.009810447692871,
          8.598016738891602,
          9.683773040771484,
          7.640487194061279,
          8.614717483520508,
          8.288658142089844,
          9.018572807312012,
          6.946568965911865,
          8.416248321533203,
          9.508761405944824,
          9.234971046447754,
          8.025614738464355,
          8.258581161499023,
          6.917914390563965,
          2.0515353679656982,
          8.943753242492676,
          8.39623737335205,
          7.747949123382568,
          8.861990928649902,
          8.439260482788086,
          7.487488269805908,
          8.484786033630371,
          6.502758979797363,
          8.201543807983398,
          9.355621337890625,
          8.522496223449707,
          6.898209571838379,
          9.644726753234863,
          9.025146484375,
          8.498994827270508,
          8.465034484863281,
          7.683892250061035,
          7.786325454711914,
          8.6923828125,
          7.648995399475098,
          9.246794700622559,
          8.445320129394531,
          8.752386093139648,
          9.197240829467773,
          7.197518825531006,
          7.950561046600342,
          7.0912089347839355,
          9.129425048828125,
          8.510053634643555,
          8.712963104248047,
          8.073468208312988,
          9.53563117980957,
          8.543952941894531,
          9.52099323272705,
          9.324539184570312,
          8.670642852783203,
          7.423387050628662,
          9.620267868041992,
          8.623944282531738,
          7.583442211151123,
          7.675167560577393,
          8.853904724121094,
          7.169823169708252,
          8.476632118225098,
          7.434863090515137,
          8.208223342895508,
          7.954994201660156
         ]
        },
        {
         "hoverinfo": "text",
         "hovertext": [
          "Merge data\ndf_script = pd.merge(df_script, df_episodes, how='inner', left_on='episode_id', right_on='id')",
          "Merge the episodes with the script\ndf_episodes['id'] = df_episodes['id'].astype(int)\ndf_script = pd.merge(df_script, df_episodes, how='inner', left_on=df_script['episode_id'], right_on=df_episodes['id'])",
          "Join episodes with script\ndf = df_script.merge(df_episodes, on='episode_id')",
          "Merge the script lines with the episodes dataframe\ndf_script_full = pd.merge(df_script, df_episodes, on='episode_id')",
          "Merge df_script and df_episodes on episode_id",
          "Merge the episode dataset with the script dataset\ndf_merged = df_script.merge(df_episodes, on='episode_id')",
          "Merge datasets to get a unified dataset for analysis\ndf_merged = df_script.merge(df_episodes, on='episode_id')",
          "Merge the script lines with their respective episodes\ndf_script = df_script.merge(df_episodes, on='episode_id', suffixes=('', '_episode'))",
          "Merge all datasets on `episode_id`\ndf_merged = df_script.merge(df_episodes, on='episode_id', suffixes=('_script', '_ep'))\n# remove duplicate columns\ndf_merged = df_merged.loc[:, ~df_merged.columns.duplicated()]",
          "Merge episodes\ndf_episodes_script = df_episodes.merge(df_script, on='episode_id')",
          "Clean non-existant or old-fashioned episodes from df_script\ndf_script_cleaned = df_script.merge(df_episodes,on='episode_id')\ndf_script_cleaned = df_script_cleaned[(df_script_cleaned['original_air_year']>=1989) & (df_script_cleaned['original_air_year']<=2018)]\ndf_script = df_script_cleaned",
          " Merge the datasets together\ndf = df_script.merge(df_episodes, on='episode_id')",
          "Merging the script and episode dataframes by the 'episode_id' column\ndf_merged = df_script.merge(df_episodes, on='episode_id')",
          " Concatenate script and episode data_frames\ndf = pd.concat([df_script, df_episodes], axis=1, keys='episode_id', join='inner')",
          "Merge episodes and script\ndf_script_episodes = df_script.merge(df_episodes,\n                how='inner',\n                left_on='episode_id',\n                right_on='id',\n                suffixes=('_script', '_episode'))\n\n# Random look at the dataset\ndf_script_episodes.sample(10)",
          "Merge the script lines with episode data\ndf_script['episode_id'] = df_script['episode_id'].astype('int64')\ndf_merged = pd.merge(df_script, df_episodes, left_on='episode_id', right_on='id', suffixes=('_script', ''))",
          " Merge transcript with the rest\ndf_script['id'] = df_script['episode_id']\ndf = pd.merge(df_script, df_episodes, on='id')",
          "Define the label to merge by\nlabel = ['season', 'number_in_season']\n\n# Join the datasets on the common label\ndf_merged = df_script.merge(df_episodes, on=label)",
          " Merge the script and episode DataFrames\ndf = df_script.merge(df_episodes, on='episode_id')",
          "Create merge of episodes and script\ndf_episodes['id'] = df_episodes.id.astype(str)\ndf_script['episode_id'] = df_script.episode_id.astype(str)\ndf_mergerd = pd.merge(df_script, df_episodes, left_on='episode_id', right_on='id').drop(['id'], axis=1)",
          "Merge lines and episodes\ndf = pd.merge(df_script, df_episodes, on='episode_id')",
          "Set current episode info\ndf_curr_episode = df_episodes[df_episodes['id'] == 4855]\n\n# Set the joint data\ndf_joint = df_script[\n    (df_script['episode_id'] == df_curr_episode['id'].values[0])\n]",
          "Fining the episode_title and corresponding  animation_frame for each line in df_script.\ndf_script = df_script.merge(\n    df_episodes[['id', 'title', 'original_air_date']],\n    left_on='episode_id',\n    right_on='id',\n    suffixes=('', '_episode')\n)",
          "Merge script and episodes\ndf_merged = df_script.merge(df_episodes, on='episode_id')",
          "Character lines dataset\nline_data = pd.merge(df_script, df_episodes, on='episode_id', how='inner')",
          " Merge df_script with df_episodes to attach episode info to each line\ndf_script_all_info = pd.merge(df_script, df_episodes,\n                              on=['episode_id', 'season', 'number_in_season', 'number_in_series'])",
          "Merge\ndf_merge = df_script.merge(\n    df_episodes,\n    left_on='episode_id',\n    right_on='id',\n    suffixes=('_script', '_ep')\n)",
          "Merge script with episodes\ndf_merged = pd.merge(df_script, df_episodes, on='episode_id')",
          "Merge df_script and df_episodes on 'episode_id' to get the actual episode title in the df_script DataFrame\ndf_script = df_script.merge(right=df_episodes, how='inner', on='episode_id')",
          "merge the episodes with the script data. This will give us script data with episode data included\ndf = df_script.merge(df_episodes, on='episode_id')",
          "Get all the quotes from the episodes and movies and join them in a single string\nscript = \" \".join(script for script in df_script['dialog'])",
          "Merge episodes and script\ndf_script_episodes = df_script.merge(\n    df_episodes,\n    on='episode_id'\n)",
          " Create a new DataFrame merging 'df_episodes' with 'df_script'\ndf_merged = df_episodes.merge(df_script, on='id', suffixes=('_ep', '_script'))\n\n# Limitation\nLIMIT = None",
          " Merge all available data into one large DataFrame\ndf = df_script.merge(df_episodes, on='episode_id')",
          "Merge episodes with scripts\ndf = df_script.merge(df_episodes, on='episode_id')",
          "Test the merge capabilities on index for 'episodes' and 'script'\ndf_ep_sc = df_script.merge(df_episodes, on='episode_id')\nprint(f'{len(df_script)} merged with {len(df_episodes)} on episode_id to {len(df_ep_sc)}')",
          " Merge script data with respective episode data\ndf_script_episode = pd.merge(df_script,\n                             df_episodes,\n                             left_on='episode_id',\n                             right_on='id',\n                             suffixes=['_script', '_episode'])",
          " Join the df_episodes and df_script DataFrame on the 'episode_id' column\ndf = df_script.merge(df_episodes, on='episode_id')",
          "Merge datasets to have a comprehensive view of the data\ndf_merged = df_script.join(df_episodes, on='episode_id', rsuffix='_episode')",
          " Merge the script lines and the episodes dataframes on the episode_id column\ndf_merged = pd.merge(df_script, df_episodes, on='episode_id', how='outer')",
          "Join episodes with script\ndf_episodes_script = df_episodes.merge(\n    df_script, \n    how='inner', \n    left_on='id',\n    right_on='episode_id'\n).reset_index(inplace=False, drop=True)",
          "Merge the dataframes\ndf_merged = df_script.merge(df_episodes, on='episode_id', suffixes=('', '_episode'))",
          "Merge script with episodes\ndf_script_full = df_script.merge(df_episodes, on='episode_id').merge(df_characters, on='character_id')\n\n# Display the first 5 rows and all columns of the resulting dataframe\npd.set_option('display.max_columns', None)\ndf_script_full.head()",
          "Merge `df_script` with `df_episodes`\ndf_script = pd.merge(df_script, df_episodes, on='episode_id')",
          "Get script and merge\ndf_script = pd.merge(df_script, df_episodes, on='episode_id')\ndf_script = pd.merge(df_script, df_characters, on='character_id')",
          "Merge script and episode datasets\ndf = pd.merge(df_script, df_episodes, on='episode_id', how='inner')",
          " Merge the episodes' data into the script's data\ndf_script = df_script.merge(df_episodes, on=['episode_id'], how='inner')",
          "Merge dataframes\ndf_script = df_script.merge(df_episodes, left_on='episode_id', right_on='id', suffixes=('', '_ep')).drop(columns=['id', 'id_ep'])",
          "Merge datasets together\ndf_episodes = df_episodes.rename(columns={\"id\" : \"episode_id\"})\ndf_script = pd.merge(df_script, df_episodes[['episode_id', 'title']], on='episode_id')\ndf_script = df_script.dropna(subset=['raw_text', 'character_id'])\ndf_episodes = df_script.loc[:, ['episode_id', 'title']].drop_duplicates()\n# tqdm.pandas()\n# df_script['nlp_processed_text'] = df_script['raw_text'].progress_apply(lambda x: nlp(x))",
          "Merge the episodes and the script dataframes using the common 'episode_id' column.\ndf_merged = df_script.merge(df_episodes, on='episode_id')",
          " Dataframe that combines script lines and episode information\ndf_script_episodes = df_script.merge(df_episodes, on='episode_id', suffixes=('_script', '_episode'))\ndf_script_episodes",
          "'Inconsequential', 'other', 'TRASH', and 'noise' lines will be dropped.\nsentence_level_scripts = df_script.loc[df_script.raw_text.str.contains('Anonymous|PABF|JABF|TABF') == False].copy()\n\n# The merged dataframe will only consider scripts from the main 22 seasons\nmerged_df = df_episodes[df_episodes.season > 0]",
          "Merge the episode and script dataframes on the episode_id column\ndf = pd.merge(df_script, df_episodes, left_on='episode_id', right_on='id', suffixes=('_script', '_episode')).drop('id', axis=1)",
          "Merge script and episodes on episode_id\ndf_script_episodes = df_script.merge(df_episodes, on='episode_id')",
          "Merge script with episodes\ndf_episodes['id'] = df_episodes['id'].astype(int)\ndf_script = df_script.merge(df_episodes, left_on='episode_id', right_on='id', suffixes=('_script', '_episode'))",
          "Merge episode data into the script data\ndf = pd.merge(df_script, df_episodes, on='episode_id')",
          "Merge episodes with scripts\ndf_episodes['id'] = df_episodes['id'].astype(str)\ndf_script['episode_id'] = df_script['episode_id'].astype(str)\ndf = pd.merge(df_script, df_episodes, left_on = 'episode_id', right_on = 'id')",
          "Merge 'script' with 'episodes' using 'episode_id' as they share this column\ndf_script = pd.merge(df_script, df_episodes, on='episode_id')",
          "Merge the scripts and episodes datasets\ndf = df_script.merge(df_episodes, on='episode_id')",
          "Join \"lines\" and \"episodes\" DataFrame on \"episode_id\"\ndf = df_script.join(df_episodes, on='episode_id')",
          " Join script lines and get an example episode\ndf_script = df_script.merge(df_episodes, on='episode_id')",
          "Merge episodes with the script lines\ndf_episodes_and_script = df_script.merge(df_episodes, on='episode_id')",
          "Merge script lines and episodes dataframes\ndf = pd.merge(df_script, df_episodes, on='id', suffixes=('_script', '_episodes'))",
          "Merge episodes and scripts\ndf = pd.merge(df_script, df_episodes, on='episode_id')",
          "Define the list of episodes for which we have both the script and the subtitles\ncommon_episodes = list(set(df_script[df_script['episode_id'] != -1].episode_id).intersection(set(df_episodes[df_episodes['id'] != -1].id)))",
          "Join the script with episodes and select a few basic columns\ndf = df_script.merge(df_episodes, on='episode_id')",
          "Merged dataframe on episode_id\ndf_merged = pd.merge(df_script, df_episodes, on='episode_id', how='inner').head(50)",
          "Merge script lines with episode data\ndf_merged = pd.merge(\n    df_script, \n    df_episodes, \n    how='left',\n    on='episode_id',\n    suffixes=('', '_ep')\n)",
          "Merge scripts with episodes\ndf_scripts_episodes = df_script.merge(df_episodes, on='episode_id', how='outer')",
          "Merging `simpsons_script_lines` with `simpsons_episodes` across the `episode_id` column",
          "Merge episodes data to script data\ndf_script = pd.merge(df_script, df_episodes[['id', 'imdb_rating', 'number_in_series', 'original_air_date', 'original_air_year']], how='left', left_on='episode_id', right_on='id', suffixes=('_script', '_episodes')).drop(columns=['id_epsiodes'])",
          "Merge the episodes and the script dataframes on the id column\ndf_data = pd.merge(df_script, df_episodes, left_on='episode_id', right_on='id', suffixes=('', '_episode'))",
          "Merge the episodes and scripts dataframe on the column 'episode_id'\ndf_episodes_scripts = df_episodes.merge(\n    df_script, \n    how='inner', \n    left_on='id', \n    right_on='episode_id',\n    suffixes=('_episodes', '_scripts')\n)",
          "Merge script and episodes dataframes\ndf = df_script.merge(df_episodes, on='episode_id', suffixes=('_script', '_ep'))\n\n# Select only the episodes of the year 2000 and on\ndf = df[df['original_air_year'] >= 2000]",
          "Merge script and episode data\ndf_script = df_script.merge(df_episodes, on='episode_id')\n\n# Display the merged dataset\ndf_script.head()",
          "\n# Merge data for convenience\ndf_merged = pd.merge(\n    df_script,\n    df_episodes,\n    how=\"left\",\n    on=\"episode_id\",\n    suffixes=(\"_script\", \"_ep\")\n)",
          "Merge the script lines with the episode info\ndf = pd.merge(df_script, df_episodes, on='episode_id')",
          "Merge episodes with script data\ndf = df_script.merge(df_episodes, on='episode_id', how='inner')",
          "Set the series_id values to have the sames type as df_episodes['id'] to facilitate the upcoming merge",
          " Merge script lines with characters and episodes\ndf_lines_episodes = df_script.merge(df_characters, on='character_id').merge(df_episodes, on='episode_id').dropna()\n\ndf_lines_episodes.head()",
          "Merge episodes and script df\ndf_eps_script = pd.merge(df_episodes, df_script, on='episode_id')"
         ],
         "marker": {
          "opacity": 0.5,
          "size": 5
         },
         "mode": "markers+text",
         "name": "7_Merging Scripts and Episodes DataFrames",
         "text": [
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          ""
         ],
         "textfont": {
          "size": 12
         },
         "type": "scattergl",
         "x": [
          1.2356312274932861,
          1.2426451444625854,
          2.210193634033203,
          2.280802011489868,
          2.6840627193450928,
          2.1510303020477295,
          2.1543803215026855,
          2.3254165649414062,
          2.081711769104004,
          1.664266586303711,
          2.535292863845825,
          2.3577053546905518,
          2.033176898956299,
          2.2823426723480225,
          1.6094396114349365,
          1.3863749504089355,
          1.7167750597000122,
          1.7327369451522827,
          2.4490373134613037,
          1.653498888015747,
          2.154066324234009,
          2.580812931060791,
          2.207211494445801,
          1.5096677541732788,
          1.762732982635498,
          2.5343286991119385,
          1.4015027284622192,
          1.4702547788619995,
          1.571858286857605,
          2.77998685836792,
          2.2654623985290527,
          1.9824628829956055,
          2.0230486392974854,
          2.091780424118042,
          2.1045448780059814,
          1.6114581823349,
          2.0087523460388184,
          2.2339344024658203,
          2.0021567344665527,
          1.7666016817092896,
          2.3282883167266846,
          1.8456311225891113,
          18.98274803161621,
          1.7515860795974731,
          2.0765600204467773,
          1.5765641927719116,
          2.140315294265747,
          1.2679558992385864,
          2.7998924255371094,
          2.3582346439361572,
          2.11833119392395,
          2.0766854286193848,
          2.079413652420044,
          1.798717737197876,
          1.714349389076233,
          2.0236928462982178,
          1.779098391532898,
          1.835017442703247,
          2.5469603538513184,
          2.8812499046325684,
          2.7543399333953857,
          2.352247476577759,
          1.9576908349990845,
          1.9937859773635864,
          3.02478289604187,
          2.5232818126678467,
          1.2645657062530518,
          1.1340398788452148,
          1.6354233026504517,
          2.66631817817688,
          1.9200156927108765,
          1.8267865180969238,
          1.9993942975997925,
          2.959977388381958,
          1.9177285432815552,
          1.413509726524353,
          2.346168041229248,
          1.5830390453338623,
          1.7026288509368896,
          2.1029646396636963,
          1.4678401947021484
         ],
         "y": [
          6.042235851287842,
          6.005812644958496,
          4.80224609375,
          5.400530815124512,
          5.089810848236084,
          4.729589462280273,
          4.432135581970215,
          5.905183792114258,
          5.420474529266357,
          5.218991756439209,
          5.264828681945801,
          4.636131763458252,
          5.186019420623779,
          6.464102745056152,
          5.494317531585693,
          5.910950660705566,
          5.4646759033203125,
          4.895559310913086,
          5.05465841293335,
          6.582443714141846,
          5.907164096832275,
          5.462512493133545,
          5.651767253875732,
          5.314745903015137,
          6.578753471374512,
          6.121857643127441,
          5.838364601135254,
          5.593886375427246,
          6.181690692901611,
          5.341365814208984,
          6.560475826263428,
          5.234253406524658,
          5.497827529907227,
          4.970015048980713,
          5.044666767120361,
          4.240671157836914,
          5.962961196899414,
          4.886348724365234,
          4.744205951690674,
          5.575248718261719,
          5.325483798980713,
          5.698297023773193,
          1.0065624713897705,
          5.830538272857666,
          6.304025173187256,
          5.633607387542725,
          6.055210113525391,
          6.266476631164551,
          5.98173713684082,
          5.131231307983398,
          6.068552017211914,
          6.680905342102051,
          6.183657646179199,
          5.243892192840576,
          5.812260150909424,
          5.742541313171387,
          5.993545055389404,
          5.8628010749816895,
          4.816446781158447,
          4.746273040771484,
          5.586130619049072,
          5.435734748840332,
          6.219501495361328,
          5.9839887619018555,
          5.3380656242370605,
          5.090681076049805,
          5.486026763916016,
          6.073645114898682,
          5.419866561889648,
          6.035613059997559,
          6.001349449157715,
          5.90010929107666,
          5.574352264404297,
          4.745143413543701,
          5.401448726654053,
          5.966879844665527,
          5.76568603515625,
          6.1282267570495605,
          5.2707343101501465,
          6.536277770996094,
          5.730425834655762
         ]
        },
        {
         "hoverinfo": "text",
         "hovertext": [
          "Extract principal data from column to ease .csv navigation",
          "We are reading multiple CSV files into pandas dataframes for further analysis and processing.",
          " This line of code^- reads the csv files into pandas dataframes for further processing and analysis.",
          "Start by loading the datasets into pandas DataFrames.",
          "First, we import the necessary libraries and modules to set up our environment and load the data. Then, we read the CSV files into DataFrames using pandas.",
          "Import necessary modules and read in the CSV files into pandas dataframes.",
          " Load in the data from the CSV files into pandas DataFrames.",
          "Now that we have our datasets loaded into pandas DataFrames, we can start exploring the data and performing some analysis.",
          "Importing all necessary packages and setting up the dataframes for further analysis.",
          "Importing the required datasets from csv files into pandas dataframes.",
          "The last line of code imports the data from CSV files into pandas dataframes.",
          "First, we read the data from CSV files into pandas DataFrames for further processing and analysis.",
          "We have successfully loaded the datasets into Pandas dataframes.",
          "Data parallelisation, speeds up operations in pandas by splitting the data into chunks, each chunk can be processed on a different CPU core.",
          "begin by reading the data from csv files into pandas dataframes.",
          "It seems that the code was written to read several CSV files into pandas dataframes. This is likely to be part of a data analysis or data visualization project related to the TV show \"The Simpsons.\"",
          "We need to have some csv files saved in the 'data' directory. Additionally, we can make our Notebook find the utils.py file by adding it to the Python path.",
          "function to load large data files using dask (for parallelism)\ndef load_large_csv(file):\n    return dd.read_csv(file, blocksize=int(1e6))",
          "We have completed the general imports and have loaded the datasets into pandas dataframes.",
          "Hints: The code is reading multiple CSV files into pandas dataframes.",
          "Now we have imported the required data into dataframes for further analysis.",
          " Looks like the code is importing the necessary data using pandas.",
          "Import the data from the CSV files into pandas dataframes.",
          "The first few lines of code above are importing necessary libraries and packages. After this, the code loads data from CSV files into pandas dataframes for further processing and analysis.",
          "A LOT of warnings will occur from this chunk of code and that happens because pandas uses a lot of chained assignment in the code, which has been optimized but is not supported by Pylint and other tools. Pylint will let us know about this and suggest that we use the `at` method instead of the chained operators to access the data of our dataframe.",
          "The last few commands in the script load several datasets into pandas DataFrames. These DataFrames will be used for data analysis and visualization.",
          "First we import the necessary modules we'll use throughout the code. Then, we read in the data from the CSV files into pandas DataFrames using `pd.read_csv()`.",
          "Looks like the code reads data from CSV files into pandas dataframes.",
          "As we can see, we've added multiple CSV files to Pandas DataFrames for further processing and analysis.",
          "This will load the datasets into pandas dataframes for further analysis.",
          "We'll start by loading the data into pandas dataframes.",
          "We are importing multiple dataframes from CSV files using pandas and storing them in variables.",
          "We are importing data from CSV files and loading them into pandas dataframes for further analysis.",
          "First, read the provided CSV files into pandas DataFrames.",
          "Sometimes, the data from the csv might have excessive blank spaces, it is good practice to remove leading and trailing whitespace from your pandas dataframe.",
          "We can see that we are reading in multiple CSV files using pandas and storing them into dataframes.",
          "Fix someone's typo in sample code\nDataFrame name on each final line should be in the left hand side in place of pandas module name.",
          "We are now reading in the CSV files using pandas and storing them in dataframes.",
          " This is a Python code that reads CSV files into pandas dataframes. The code uses the pandas library to read the CSV files and store the data in dataframes. These dataframes can then be used for further data analysis and manipulation.",
          "Let's first load all the data from the CSV files into Pandas dataframes.",
          "The line above reads several CSV files into pandas DataFrames.",
          "\n# Python code to create a CSV file\n# from a list\nimport csv\n\n# field names\nfields = ['Name', 'Branch', 'Year', 'CGPA']\n\n# data rows of csv file\nrows = [ ['Nikhil', 'COE', '2017', '9.0'],\n         ['Sanchit', 'COE', '2017', '9.1'],\n         ['Aditya', 'IT', '2017', '9.3'],\n         ['Sagar', 'SE', '2017', '9.5'],\n         ['Prateek', 'MCE', '2017', '9.1'],\n         ['Sahil', 'EP', '2017', '9.2']]\n\n# name of csv file\nfilename = \"university_records.csv\"\n\n# writing to csv file\nwith open(filename, 'w') as csvfile:\n    # creating a csv dict writer object\n    csvwriter = csv.writer(csvfile)\n    \n    # writing the fields\n    csvwriter.writerow(fields)\n    \n    # writing the data rows\n    csvwriter.writerows(rows)",
          "Most of the time, the data in pandas dataframes is read-only. This means that the methods and attributes are in place, to ensure that the data doesn't get manipulated accidentally.",
          "First, we import the necessary libraries and then read the CSV files into pandas dataframes.",
          "First, we import the necessary libraries and then read in the data from CSV files into Pandas dataframes.",
          "This code snippet demonstrates the use of several Python libraries for data analysis and visualization. It reads data from CSV files using pandas, performs some preprocessing, and sets up the environment for further analysis. The code also includes custom imports for additional functionality.",
          "We have read the CSV files into Pandas dataframes.",
          "We have successfully imported the necessary libraries and read the data into pandas dataframes. Now we can move on to the next steps of data exploration and analysis.",
          "First we read the datasets into pandas DataFrame.",
          " Imports required for data visualization and analysis, and loading datasets into pandas DataFrames.",
          "In this step, we have read the CSV files into pandas dataframes for further processing and analysis.",
          "It is common to import multiple libraries and modules before beginning any data analysis or machine learning tasks in Python. In this example, we are importing pandas, numpy, spacy, matplotlib, wordcloud, tqdm, and collections. We also set up matplotlib to work correctly in a Jupyter notebook with the `%matplotlib inline` command. Additionally, we are reading in several CSV files using pandas to create dataframes for analysis.",
          "Setting the \"include\" parameter of the read_csv function call to \"all\" will force pandas to read all columns, \n # even if they have mixed dtypes. Use at your own risk - it's 5-10x slower.",
          " I'm not sure where this code is going or what its purpose is, but it appears to be loading data from CSV files into Pandas DataFrames.",
          "Load the data from the CSV files into pandas DataFrames.",
          "First, we read in the data from CSV files into pandas dataframes.",
          "Read the datasets from the data folder into pandas dataframes.",
          "Now, we will use the read_csv() function from pandas to load the CSV files into DataFrames.",
          "We are importing pandas, numpy, spacy, matplotlib, WordCloud, and other required libraries for our data analysis and visualization. We are also importing custom libraries such as tqdm, Counter, etc. Then we are reading the data from CSV files into pandas dataframes.",
          "Import the required libraries and read the CSV files into pandas dataframes.",
          "We start with the import statements, importing necessary libraries like pandas, numpy, spacy, matplotlib, and others. We also import the custom libraries like tqdm, Counter, and the WordCloud module from the wordcloud library. Then we read the CSV files using pandas, creating dataframes for characters, locations, script lines, and episodes.",
          "Acuna N (2015) write a small utility to enhance the pandas dataframe.",
          "In this snippet, we are reading the data from CSV files into Pandas DataFrames. These DataFrames will then be used for data analysis and visualization.",
          "We will start by loading the data from the CSV files into pandas DataFrames.",
          "So, we have successfully read all the CSV files into pandas dataframes.",
          " Purpose of this code is to read the CSV files and store them in pandas dataframes for further processing and analysis.",
          "The .csv files will now be loaded into dataframes so that they can be further inspected and processed.",
          "Read the datasets from CSV files into pandas DataFrames.",
          "I have imported the data from the CSV files using pandas and stored them in dataframes for further processing.",
          "Load the provided csv files into pandas dataframes.",
          "Read JSon conversion table from local storage\njcn = pd.read_csv('data/JsonConversion.csv')",
          "We're reading the CSV files into pandas DataFrames for further processing and analysis.",
          "Load the data from the CSV files into pandas DataFrames.",
          "The csv files are being read and loaded into pandas dataframes for further analysis and processing.",
          "In the above code, we are importing various libraries such as pandas, numpy, spacy, matplotlib, wordcloud, etc. We are also importing custom libraries like tqdm and Counter. Then we are reading CSV files into pandas dataframes using pd.read_csv().",
          "The first line of code imports the data from CSV files into pandas dataframes.",
          " Load and display dataframes from CSV files",
          "Here we are reading CSV files using pandas and storing them in dataframes for further processing."
         ],
         "marker": {
          "opacity": 0.5,
          "size": 5
         },
         "mode": "markers+text",
         "name": "8_Reading CSV files into pandas DataFrames",
         "text": [
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          ""
         ],
         "textfont": {
          "size": 12
         },
         "type": "scattergl",
         "x": [
          12.508589744567871,
          11.736502647399902,
          11.145991325378418,
          12.272624015808105,
          12.705883026123047,
          12.755989074707031,
          12.05359935760498,
          12.029500007629395,
          13.081818580627441,
          12.494169235229492,
          11.208558082580566,
          12.40101146697998,
          12.430424690246582,
          11.398344039916992,
          12.239920616149902,
          11.574914932250977,
          13.823448181152344,
          11.78303050994873,
          12.919083595275879,
          11.133959770202637,
          13.034443855285645,
          10.82935619354248,
          12.002309799194336,
          11.595409393310547,
          10.831509590148926,
          11.90351390838623,
          12.412498474121094,
          11.353592872619629,
          11.815473556518555,
          12.152070045471191,
          12.387271881103516,
          11.144596099853516,
          11.953499794006348,
          12.302037239074707,
          10.379045486450195,
          11.367888450622559,
          10.63786792755127,
          11.891611099243164,
          11.83559513092041,
          11.982165336608887,
          11.34284496307373,
          12.103379249572754,
          10.20671272277832,
          12.668516159057617,
          12.550409317016602,
          12.217681884765625,
          12.232499122619629,
          12.45977783203125,
          11.968400001525879,
          12.659811973571777,
          12.359330177307129,
          12.654902458190918,
          11.171257972717285,
          11.265931129455566,
          11.807718276977539,
          12.452588081359863,
          12.30836296081543,
          12.109824180603027,
          12.633757591247559,
          12.494502067565918,
          12.487561225891113,
          11.976799964904785,
          11.904038429260254,
          12.323729515075684,
          11.816814422607422,
          11.541048049926758,
          12.114455223083496,
          12.310996055603027,
          11.794139862060547,
          11.898126602172852,
          12.052027702331543,
          11.928391456604004,
          12.214831352233887,
          11.468502044677734,
          12.339468002319336,
          11.413138389587402,
          11.76880931854248,
          11.962183952331543
         ],
         "y": [
          -0.40536168217658997,
          -1.0668531656265259,
          -0.14099296927452087,
          -1.8735129833221436,
          -0.02418815903365612,
          -0.07920835167169571,
          -0.7323636412620544,
          -2.2567012310028076,
          -0.8117771744728088,
          -0.7710204124450684,
          -0.7308570742607117,
          -1.527051568031311,
          -1.4378212690353394,
          -0.9036373496055603,
          -1.2193931341171265,
          0.8096619248390198,
          0.6050440669059753,
          -0.13831494748592377,
          -0.9244847297668457,
          -0.8284628987312317,
          -1.1343530416488647,
          -0.45020821690559387,
          -0.6834136843681335,
          0.11122490465641022,
          -0.6749945878982544,
          -0.9366962909698486,
          -0.18946246802806854,
          -0.2261565774679184,
          -0.8047584295272827,
          -1.8655997514724731,
          -1.542640209197998,
          -1.2246683835983276,
          -1.2470594644546509,
          -1.0527641773223877,
          -0.4440147578716278,
          -0.8460443615913391,
          -1.1104055643081665,
          -1.3015847206115723,
          -0.05243970826268196,
          -0.491476446390152,
          -0.9032832384109497,
          -0.34240102767944336,
          -1.4724740982055664,
          -0.15182152390480042,
          -0.21127192676067352,
          0.2183281034231186,
          -0.7334997057914734,
          -1.3390132188796997,
          -2.026432514190674,
          -0.7734784483909607,
          -0.8289423584938049,
          0.6989096403121948,
          -0.2230144441127777,
          -0.29312312602996826,
          -0.8415608406066895,
          -1.459968090057373,
          -1.7003425359725952,
          -0.15250588953495026,
          0.21492451429367065,
          -0.29671940207481384,
          1.027533769607544,
          -1.978489637374878,
          -0.46368733048439026,
          -0.96120285987854,
          -0.20471550524234772,
          -0.25280052423477173,
          -0.7211744785308838,
          -1.478049874305725,
          -1.1858417987823486,
          -0.5760028958320618,
          0.12052910029888153,
          -1.0191256999969482,
          -0.7680697441101074,
          -0.786038875579834,
          0.35063040256500244,
          -0.5358656048774719,
          -0.5824896097183228,
          -1.1515864133834839
         ]
        },
        {
         "hoverinfo": "text",
         "hovertext": [
          "\ndf_script.head()",
          "df_script.head()",
          "df_script.head()",
          "df_script.head()",
          "df_script.head()",
          "\ndf_script.head()",
          "df_script.head()",
          "\ndf_script.head()",
          "\ndf_script.head()",
          "\ndf_script.head()",
          "df_script.head()",
          "df_script.head()",
          "df_script.head()",
          "df_script.head()",
          "\ndf_script.head()",
          "# What does the df contain?\ndf_script.head()",
          "df_script.head()",
          "\ndf_script.head()",
          "jupyter notebook... so much power!\ndf_script.head(20)",
          "f Script (first lines)\ndf_script.head()",
          "# Carry the same process out for script data\ndf_script.head()",
          "df_script.head()",
          "df_script.head(10)",
          "\ndf_script.head()",
          "df_script.head()",
          "df_script.head()",
          "Main dataframe head\ndf_script.head()",
          "df_script.head()",
          "\ndf_script.head()",
          "df_script.head()",
          "df_script.head()",
          "df_script.head()",
          "\ndf_script.head()",
          "\ndf_script.head()",
          "df_script.head()",
          "\ndf_script.head()",
          "df_script.head()",
          "df_script.head()",
          "\ndf_script.head()",
          "df_script.head()",
          "df_script.head()",
          "\ndf_script.head()",
          "\n# df_script.head()",
          "\ndf_script.head()",
          "df_script.head()",
          "Data frame sample\ndf_script.head()",
          "df_script.head()",
          "\ndf_script.head()",
          "df_script.head()",
          "# We'll work with the script text\ndf_script.head()",
          "print(df_script.head())",
          "# Spokane_County_Animation_Corpus_General\ndf_script.head()",
          "df_script.head()",
          "df_script.head()",
          "\ndf_script.head()",
          "\ndf_script.head()",
          "df_script.head()",
          "\ndf_script.head()",
          "Sanity check\ndf_script.head()",
          " Get the script from Treehouse\ndf_script_medium = df_script.head(1000)",
          "\ndf_script.head()",
          "\ndf_script.head()",
          "# Prints\ndf_script.head()",
          "df_script.head()",
          "Df at glance\ndf_script.head()",
          "# Sample\ndf_script.head()",
          "# Look at the first three lines\ndf_script.head(3)",
          "\ndf_script.head()",
          "df_script.head()",
          "df_script.head()",
          "df_script.head()"
         ],
         "marker": {
          "opacity": 0.5,
          "size": 5
         },
         "mode": "markers+text",
         "name": "9_df_script head extract and analysis",
         "text": [
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          ""
         ],
         "textfont": {
          "size": 12
         },
         "type": "scattergl",
         "x": [
          6.174624443054199,
          5.4296417236328125,
          5.711764335632324,
          6.310346603393555,
          5.734247207641602,
          5.780759811401367,
          5.56383752822876,
          5.8121747970581055,
          6.09089994430542,
          5.926300048828125,
          5.581207752227783,
          5.611894607543945,
          5.917202472686768,
          5.877167224884033,
          5.56494665145874,
          5.828852653503418,
          6.269620895385742,
          5.855560302734375,
          5.851058006286621,
          5.67238187789917,
          5.363584995269775,
          5.817318439483643,
          5.5275797843933105,
          6.307255744934082,
          6.140658855438232,
          5.55553674697876,
          6.037500381469727,
          5.876519203186035,
          5.787950038909912,
          5.023596286773682,
          5.99603271484375,
          6.159655570983887,
          5.78231954574585,
          5.669615745544434,
          6.175711631774902,
          5.145888328552246,
          5.50502872467041,
          6.249443531036377,
          5.48400354385376,
          5.236736297607422,
          5.610260009765625,
          5.692131519317627,
          5.707192897796631,
          5.4982829093933105,
          5.982235908508301,
          5.509420394897461,
          5.365803241729736,
          6.061857223510742,
          5.4332098960876465,
          5.827781677246094,
          6.068686008453369,
          5.881326198577881,
          5.866336822509766,
          5.274107933044434,
          6.285593032836914,
          5.86561393737793,
          5.667119026184082,
          5.902093887329102,
          5.645297050476074,
          5.504655838012695,
          6.122251987457275,
          5.639857292175293,
          5.809073448181152,
          5.489503860473633,
          6.009123802185059,
          5.509525775909424,
          6.160721302032471,
          6.307880878448486,
          5.632967948913574,
          5.848318099975586,
          5.6380510330200195
         ],
         "y": [
          -8.126235008239746,
          -8.14393138885498,
          -8.184650421142578,
          -7.878929138183594,
          -7.983638763427734,
          -7.967670917510986,
          -8.357402801513672,
          -8.582061767578125,
          -7.689446449279785,
          -8.632418632507324,
          -7.887458324432373,
          -7.892016887664795,
          -8.31837272644043,
          -7.768138885498047,
          -8.543845176696777,
          -7.230276107788086,
          -8.598706245422363,
          -7.959958553314209,
          -6.780685901641846,
          -8.646071434020996,
          -6.559261798858643,
          -8.381099700927734,
          -7.612669467926025,
          -7.8093061447143555,
          -8.157772064208984,
          -8.168797492980957,
          -7.065278053283691,
          -7.675294876098633,
          -8.685184478759766,
          -7.813144683837891,
          -8.291576385498047,
          -8.244587898254395,
          -7.831340789794922,
          -8.312356948852539,
          -8.602368354797363,
          -8.112483978271484,
          -8.059213638305664,
          -8.00117015838623,
          -8.184784889221191,
          -8.379504203796387,
          -8.44520092010498,
          -7.7736310958862305,
          -6.869272232055664,
          -7.6377482414245605,
          -8.03582763671875,
          -6.915088176727295,
          -8.46652889251709,
          -8.139533996582031,
          -8.420502662658691,
          -6.65765380859375,
          -6.9737162590026855,
          -6.960220813751221,
          -7.879487037658691,
          -7.98836612701416,
          -7.554032802581787,
          -8.622781753540039,
          -8.109848022460938,
          -7.642533302307129,
          -5.837235450744629,
          -4.99879789352417,
          -8.284578323364258,
          -8.245917320251465,
          -7.167292594909668,
          -7.9305830001831055,
          -8.556723594665527,
          -6.786048412322998,
          -7.1567583084106445,
          -8.108086585998535,
          -8.18338680267334,
          -8.206398010253906,
          -8.501383781433105
         ]
        },
        {
         "hoverinfo": "text",
         "hovertext": [
          "Display the first few rows of each dataframe to understand the data",
          "Optional: Display the first few rows of each DataFrame to check the data",
          "Display the first few rows of each dataframe to understand the data",
          "Print the first few rows of each dataframe to understand the data",
          "Display the first few rows of each DataFrame to understand the data",
          " Display the first few rows of each dataframe to understand the data",
          " Display the first few rows of each dataframe to understand the data",
          " Display the first few rows of each dataframe to understand the data",
          "Optional: Display the first few rows of the dataframe to get an overview of the data.",
          "Display the first few rows of each dataframe to get a sense of what the data looks like.",
          "Display the first few rows of each dataframe to understand the data",
          "Display the first few entries of each dataframe to get an understanding of the data.",
          "Displays the first 3 rows of the dataframe",
          "define a helper function to print the first few rows of a dataframe",
          "Show all columns and the first few rows of each DataFrame to understand what data is available",
          " Displaying the first few rows of each dataframe to understand the data",
          "Display the first few rows of each dataframe to understand what the data looks like.",
          "Display the first 10 rows of each dataframe to get a sense of the data",
          " Display the first few rows of each dataframe to know what information we have",
          "Optional: Display first few rows of the dataframe to understand the data",
          "let's show first the available columns for each dataframe",
          " Display the first few rows of each dataframe to understand the data",
          "Display the first few rows of the dataframe.",
          " Display the first few rows of each dataframe to understand the data",
          " Display the first few rows of each dataframe to understand the data",
          "Display the first few records of each dataframe to understand the data",
          "Display the first few rows of each dataframe to get an understanding of the data",
          " Visualize the first few rows of each dataframe to understand the data",
          "Display the first few rows of the dataframes to get an understanding of the data",
          "Display the first row of the dataframe.",
          "Display the first few rows of each dataframe to understand the data",
          "Display the first few rows of each dataframe to inspect the data.",
          "Shows the first few rows of each dataframe.",
          "Display the first few rows of each dataframe to understand the data",
          " Display the first few rows of each dataframe to get an overview of the data",
          "Visualize the first few rows of each dataframe to understand the data",
          "display first few rows of each dataframe to understand the data",
          "Display the first few rows of each DataFrame to understand the data.",
          " Display the first few rows of each dataframe to understand the data",
          "Display the first few rows of each dataframe to understand the data",
          "Display the first few rows of each dataframe to understand the data",
          " Load the data and display the first few rows of each dataframe",
          "Display the first few rows of each dataframe to understand the data",
          "Display the first few rows of each dataframe to understand the data",
          "Display the first few rows of each dataframe to understand the data",
          "Display the first few rows of each dataframe",
          "Display the first few rows of each dataframe to understand the data",
          "Display first few rows of each dataframe to understand the data",
          "Display the first few rows of each dataframe to understand the data",
          "Display the first few rows of each dataframe to understand the data",
          "Display the first, (2-30)mn, and last entries of the dataframe.",
          "display all the loaded dataframes with first rows",
          " Display the first few rows of each dataframe to understand the data",
          "Display the first few rows of each dataframe to get an understanding of the data",
          " Display the first few rows of the dataframe to understand the data",
          "Display the first few records in each dataframe to understand the data",
          " Show the initial records from the dataframe.",
          "Display the first few rows of each DataFrame to get an idea of the data",
          " Show at least the beginning of each dataframe to understand the data",
          "Show the first few rows of each dataframe to get an overview of the data",
          " Display the first few rows of each dataframe to understand the data",
          "Display the first few rows of each dataframe to understand the data",
          " Print the first few rows of each dataframe to understand the data",
          "Show the first few rows of each dataframe",
          "Display the first few rows of each dataframe to get an idea of the data",
          "Print the first few rows of each dataframe to understand the data",
          "Now let's print the first few rows of each dataframe to see what's inside"
         ],
         "marker": {
          "opacity": 0.5,
          "size": 5
         },
         "mode": "markers+text",
         "name": "10_Understanding Dataframes with First Few Rows Displayed",
         "text": [
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          ""
         ],
         "textfont": {
          "size": 12
         },
         "type": "scattergl",
         "x": [
          13.010359764099121,
          12.524880409240723,
          13.082053184509277,
          12.675665855407715,
          12.976920127868652,
          12.77717399597168,
          12.901308059692383,
          12.852404594421387,
          11.859050750732422,
          12.214766502380371,
          12.945199966430664,
          12.566920280456543,
          12.31920337677002,
          12.446290016174316,
          12.217259407043457,
          13.004875183105469,
          12.372610092163086,
          12.904027938842773,
          12.79751205444336,
          12.542999267578125,
          12.003744125366211,
          12.564705848693848,
          12.427963256835938,
          12.834185600280762,
          13.006380081176758,
          12.653243064880371,
          13.10798454284668,
          12.784828186035156,
          12.790877342224121,
          12.710186004638672,
          12.642143249511719,
          12.291383743286133,
          12.349766731262207,
          12.598901748657227,
          12.757155418395996,
          12.8806734085083,
          12.691438674926758,
          12.38926887512207,
          13.282010078430176,
          12.600411415100098,
          12.792278289794922,
          12.837348937988281,
          12.959332466125488,
          12.80289363861084,
          12.584098815917969,
          12.716550827026367,
          12.643904685974121,
          13.055316925048828,
          13.024945259094238,
          12.660585403442383,
          12.142077445983887,
          12.970359802246094,
          12.997664451599121,
          12.936200141906738,
          12.68989372253418,
          12.877443313598633,
          12.54828929901123,
          13.24392032623291,
          12.34019660949707,
          12.763195991516113,
          13.071388244628906,
          12.842597961425781,
          12.670543670654297,
          12.443154335021973,
          13.044761657714844,
          12.54032039642334,
          12.452105522155762
         ],
         "y": [
          -11.109241485595703,
          -8.307990074157715,
          -11.035774230957031,
          -11.202068328857422,
          -10.608720779418945,
          -10.66584300994873,
          -11.061117172241211,
          -10.506575584411621,
          -9.562581062316895,
          -9.616409301757812,
          -11.08629322052002,
          -9.791044235229492,
          -10.184419631958008,
          -11.413702964782715,
          -10.088379859924316,
          -10.462552070617676,
          -9.796263694763184,
          -9.402887344360352,
          -9.948667526245117,
          -9.75090217590332,
          -10.120366096496582,
          -10.628300666809082,
          -9.997564315795898,
          -10.997724533081055,
          -10.916991233825684,
          -9.767196655273438,
          -10.294232368469238,
          -9.655686378479004,
          -10.010845184326172,
          -10.059736251831055,
          -10.900270462036133,
          -9.134149551391602,
          -9.589689254760742,
          -10.813193321228027,
          -10.235795021057129,
          -9.780975341796875,
          -10.940707206726074,
          -10.251581192016602,
          -11.024933815002441,
          -10.947487831115723,
          -11.025437355041504,
          -9.588639259338379,
          -10.872228622436523,
          -10.829110145568848,
          -10.786100387573242,
          -10.143860816955566,
          -10.522546768188477,
          -10.548273086547852,
          -10.866783142089844,
          -10.701800346374512,
          -9.744096755981445,
          -9.066267967224121,
          -10.679451942443848,
          -10.341646194458008,
          -10.593771934509277,
          -9.813558578491211,
          -8.971330642700195,
          -9.870323181152344,
          -10.130420684814453,
          -10.40494155883789,
          -10.734749794006348,
          -10.511124610900879,
          -11.247507095336914,
          -10.303812980651855,
          -9.938645362854004,
          -11.192855834960938,
          -11.095470428466797
         ]
        },
        {
         "hoverinfo": "text",
         "hovertext": [
          " Create a directory for storing the plots\nif not os.path.exists('plots'):\n    os.makedirs('plots')",
          " Set TreeTagger directory\nos.environ['TREETAGGER_HOME'] = '/usr/local/Cellar/treetagger/3.2.2/'",
          "Helper function configparser\ndef get_project_path():\n    # Get the path to the main project folder\n    dir_path = os.path.dirname(os.path.realpath(__file__))\n    return os.path.abspath(os.path.join(dir_path, os.pardir))",
          "path to save outputs\noutput_path = 'output/'",
          "Create a directory to save the output figures\nif not os.path.exists('output'):\n    os.makedirs('output')",
          "Create an output folder to store images",
          "Set CWD to current folder\nos.chdir(os.path.dirname(os.path.abspath(__file__)))",
          "ensure data/simpsons folder exists\nif not os.path.exists('data/simpsons'):\n    print('Creating directory data/simpsons')\n    os.makedirs('data/simpsons')",
          "Create a directory to store the processed data if it does not exist\nif not os.path.exists('processed_data'):\n    os.mkdir('processed_data')",
          " Creating data folder if it doesn't exist\nif not os.path.exists('data'):\n    os.makedirs('data')",
          "Locating the path of the current file",
          "Create temporary files folder if it doesn't exist\ntemp_folder = './data/tmp'\nos.makedirs(temp_folder, exist_ok=True)",
          "Path to save results\nresults_path = \"results\"",
          "Change directory to parent\nos.chdir(os.pardir)",
          "Create new directory to save images if it doesn't exists\nimg_dir = 'images'\nif not os.path.exists(img_dir):\n    os.makedirs(img_dir)",
          "Create a directory to store images if it does not exist\nimg_dir = 'images'\nif not os.path.exists(img_dir):\n    os.makedirs(img_dir)",
          "Add custom functions' directory to the path\nmodule_dir = os.path.join(os.path.abspath(''), 'preprocessing')\nsys.path.insert(0, module_dir)",
          "Create a 'simpsons' folder if it doesn't exist\nif not os.path.exists('simpsons'):\n    os.makedirs('simpsons')",
          "# Create ./plots directory if it does not exist\nif not os.path.exists('./plots'):\n    os.makedirs('./plots')",
          "Create output directory if it does not exist\noutput_dir = 'output'\nif not os.path.exists(output_dir):\n    os.makedirs(output_dir)",
          "Path for exported data\noutput_data_path = 'output_data/'",
          "Set path to save files\nimg_path = 'data/img/'",
          "Configure workspace\nos.makedirs('images', exist_ok=True)",
          " Set working directory\nos.chdir('..')",
          "reate a directory to save text data\ndirectory = 'data/text_data'\nif not os.path.exists(directory):\n    os.makedirs(directory)",
          "Create a data folder if it doesn't exist\nif not os.path.exists('data'):\n    os.makedirs('data')",
          " Define the directory with NLP models and create a backup.\nnlp_dir = './nlp'\nif os.path.isdir(nlp_dir):\n    !mv $nlp_dir $nlp_dir'_backup'",
          "Create path to save figures\nimg_path = 'images'\n# Create the directory if it does not exist\nif not os.path.exists(img_path):\n    os.makedirs(img_path)",
          "We then specify where data will be saved\nsave_dir = 'image_outputs'\n\n# Make the directory if it doesn't exist\nos.makedirs(save_dir, exist_ok=True)",
          "Create a directory to save outputs\nif not os.path.exists('outputs'):\n    os.makedirs('outputs')",
          " Creating folder to save images",
          "Work directory\nprint(\"Current working directory\", os.getcwd())",
          "Specify an output location for any saved data.",
          "Make a directory to save the figures\nif not os.path.exists('figures'):\n    os.makedirs('figures')",
          " Create directory for figures if it doesn't exist\nif not os.path.exists('figures'):\n    os.makedirs('figures')",
          "create directory for storing output\noutput_dir = 'output'\n\n# Ensure the output directory exists\nif not os.path.exists(output_dir):\n    os.makedirs(output_dir)",
          "Working directory\nos.chdir('/mnt/data')",
          "Create a directory to save the visualization results\nif not os.path.exists('visualizations'):\n    os.makedirs('visualizations')",
          "if not os.path.exists('figures'):\n    os.makedirs('figures')",
          "Save path to get product of current working directory and folder the script is placed in.",
          "Create out directory if it doesn't exist\nif not os.path.exists('out'):\n    os.makedirs('out')",
          " Create directory for saving generated visualisations\nif not os.path.exists('visualizations'):\n    os.makedirs('visualizations')",
          "Create folder to save images",
          "Create directory for generated output\noutput_dir = 'output'\nos.makedirs(output_dir, exist_ok=True)",
          " Make the data directories if they do not exist\nos.makedirs('data', exist_ok=True)",
          "Set the directory for saving/loading the plot data.",
          "# Create path\nif not os.path.exists('images/'):\n    os.makedirs('images/')",
          "Create the necessary folders if they do not exist\nfolders = ['images', 'models', 'data/preprocessed']\nfor f in folders:\n    if not os.path.exists(f):\n        os.makedirs(f)",
          "#   Changing path to be in the script_files directory to use functions from the .py files\nos.chdir(\"script_files\")",
          "# Create \"simpsons\" folder\nif not os.path.exists('simpsons'):\n    os.mkdir('simpsons')",
          "Ensure working directory is correct\nos.getcwd()",
          "Set up directories for output\nimgdir = os.path.normpath('visualizations/')  # directory to save images\nos.makedirs(imgdir, exist_ok=True)",
          " Check that directories exists or create them\ntry:\n    for directory in ['images', 'vocabulary', 'dataframes']:\n        os.makedirs(directory)\nexcept FileExistsError:\n    print(\"Directories already exist\")",
          "Create a directory to store the images if it does not exist\nif not os.path.exists('images'):\n    os.makedirs('images')",
          "Isolate the environment to only a select few directories for only python code to be executed",
          "Create the 'simpsons' directory if it doesn't exist\nif not os.path.exists('simpsons'):\n    os.makedirs('simpsons')",
          "Check if the path exists\nif not os.path.exists('images'):\n    os.makedirs('images')",
          "Check if the folder does not exists, create it",
          "Create a directory to save the plots\nos.makedirs('plots', exist_ok=True)",
          " Custom\nos.makedirs(\"results\", exist_ok=True)",
          "Path to the output directory\nOUTPUT_DIR = 'output'",
          "Root path\nROOT = os.getcwd()",
          "Image folder\nIMG_FOLDER = 'images'",
          "Create a directory to save the output files\noutput_dir = 'output'\nif not os.path.exists(output_dir):\n    os.makedirs(output_dir)",
          "Create save directory if it doesn't exist\nif not os.path.exists('plots'):\n    os.mkdir('plots')",
          "Create directory to save figures if it doesn't exist\nif not os.path.exists('figures'):\n    os.mkdir('figures')"
         ],
         "marker": {
          "opacity": 0.5,
          "size": 5
         },
         "mode": "markers+text",
         "name": "11_Creating Directories",
         "text": [
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          ""
         ],
         "textfont": {
          "size": 12
         },
         "type": "scattergl",
         "x": [
          17.65693473815918,
          15.833362579345703,
          15.436236381530762,
          16.784679412841797,
          17.073486328125,
          16.418365478515625,
          15.605481147766113,
          15.154203414916992,
          16.1234188079834,
          15.607745170593262,
          15.897902488708496,
          15.563977241516113,
          16.460634231567383,
          15.567059516906738,
          16.639616012573242,
          16.743419647216797,
          15.36894702911377,
          15.598187446594238,
          17.358131408691406,
          15.952568054199219,
          16.290647506713867,
          16.622852325439453,
          16.814443588256836,
          15.576421737670898,
          15.721208572387695,
          15.633804321289062,
          15.790721893310547,
          16.600191116333008,
          16.637035369873047,
          16.640178680419922,
          16.709327697753906,
          15.951027870178223,
          16.4030704498291,
          17.414634704589844,
          17.28006362915039,
          16.152128219604492,
          15.751667976379395,
          17.449810028076172,
          17.0140438079834,
          15.811704635620117,
          15.911742210388184,
          17.276546478271484,
          16.782625198364258,
          16.294944763183594,
          15.874347686767578,
          17.529752731323242,
          16.378658294677734,
          16.01397132873535,
          15.032100677490234,
          15.401869773864746,
          15.84676742553711,
          17.075763702392578,
          16.269380569458008,
          16.69016456604004,
          15.512803077697754,
          15.396402359008789,
          16.527902603149414,
          15.680052757263184,
          17.77994728088379,
          16.09758949279785,
          16.366565704345703,
          16.123743057250977,
          16.790573120117188,
          16.217615127563477,
          17.6577091217041,
          17.300045013427734
         ],
         "y": [
          3.5211269855499268,
          4.0142502784729,
          3.6501965522766113,
          3.7052204608917236,
          3.8507742881774902,
          4.334228038787842,
          4.031004428863525,
          4.5899176597595215,
          4.722072601318359,
          4.6684794425964355,
          3.1459455490112305,
          4.384246826171875,
          3.7428205013275146,
          3.8045711517333984,
          4.592564105987549,
          4.338291168212891,
          3.8953511714935303,
          4.505226135253906,
          3.8174173831939697,
          4.440389156341553,
          3.1520845890045166,
          4.0729475021362305,
          4.245401382446289,
          3.565551280975342,
          5.01722526550293,
          4.5082316398620605,
          5.616588592529297,
          4.297693252563477,
          4.108931541442871,
          4.0562520027160645,
          4.612541675567627,
          3.503251075744629,
          3.4278976917266846,
          4.2090840339660645,
          4.286542892456055,
          4.042245388031006,
          3.187302350997925,
          3.6439850330352783,
          4.361613750457764,
          3.7424886226654053,
          4.520046710968018,
          3.6815218925476074,
          4.438872337341309,
          4.177871227264404,
          4.580245018005371,
          3.069507598876953,
          4.406288146972656,
          4.898395538330078,
          4.0365824699401855,
          4.251542568206787,
          3.3691115379333496,
          4.17553186416626,
          4.473618507385254,
          4.350691318511963,
          4.175148963928223,
          4.296224117279053,
          4.295825481414795,
          3.6075589656829834,
          3.4284508228302,
          4.106326103210449,
          3.8805348873138428,
          3.7026500701904297,
          4.00183629989624,
          4.125606536865234,
          3.647691249847412,
          4.139649868011475
         ]
        },
        {
         "hoverinfo": "text",
         "hovertext": [
          " Set pandas options to not truncate columns when printing\npd.set_option('display.max_colwidth', -1)",
          "SEt default display parameters for pandas\npd.set_option('display.max_columns', None)\npd.set_option('display.width', 1000)",
          "Set the pandas display options for long strings, so they are properly displayed\npd.set_option('display.max_colwidth', None)",
          "Set pandas display options to show full column width\npd.set_option('max_colwidth', None)",
          "Set correct display options for Pandas dataframes\npd.set_option('display.max_columns', None)\npd.set_option('display.max_rows', None)\npd.set_option('display.width', 200)",
          "Set pandas print options to make it more human friendly\npd.set_option('display.max_columns', 500)\npd.set_option('display.max_rows', 30)\npd.set_option('display.max_colwidth', None)",
          "Customisation\n# Set pandas display options\npd.set_option('display.max_rows', 5)\npd.set_option('display.max_columns', 500)\npd.set_option('display.width', 1000)",
          "Set pandas display options for easier exploration\npd.set_option('display.max_columns', None)\npd.set_option('display.max_colwidth', None)",
          " Set decimal precision for pandas dataframes\npd.set_option('display.float_format', lambda x: '%.3f' % x)",
          "Set the pandas display options for broader coverage\n# Also, disable the SettingWithCopyWarning (not good, but our code uses original dataframe)\npd.set_option('display.max_rows', 300)\npd.set_option('display.max_columns', 300)\npd.set_option('display.width', 1000)\npd.set_option('mode.chained_assignment', None)",
          "Set pandas to display long text\npd.set_option('display.max_colwidth', -1)",
          " Set max column width for dataframes to 1000\npd.set_option('display.max_colwidth', 1000)",
          "Set pandas table display configurations to get a better look at the data\npd.set_option('display.max_columns', None)\npd.set_option('display.max_rows', None)\npd.set_option('display.max_colwidth', None)",
          "Set up the print format so that we can see full dataframes rather than truncated versions\npd.set_option('display.max_colwidth', None)",
          "Display full dataframe info\npd.set_option('display.max_rows', None)\npd.set_option('display.max_columns', None)\npd.set_option('display.width', None)\npd.set_option('display.max_colwidth', -1)",
          "Set the dataframe lenght display at its maximum value",
          " Additional customization - Ensure pandas displays column info fully\npd.set_option('display.max_colwidth', None)",
          "Set the precision for Pandas\npd.set_option('precision', 2)",
          "Display full columns in dataframes\npd.set_option('display.max_colwidth', None)",
          "Set pandas to display wide columns\npd.set_option('display.max_colwidth', None)",
          " Display full DataFrame width\npd.set_option('display.max_colwidth', None)",
          "Set pandas to display long text\npd.set_option('display.max_colwidth', -1)",
          "Set maximum number of columns displayed in pandas\npd.set_option('display.max_columns', 500)\npd.set_option('display.width', 1000)",
          "Set pandas display options for easier viewing\npd.set_option('max_columns', 50)\npd.set_option('max_colwidth', 100)",
          "Set the pandas options to visualize the dataset\npd.set_option('display.max_columns', None)\npd.set_option('display.max_colwidth', None)",
          "Set some configuration options for pandas in order to display data more aesthetically.\npd.set_option('display.max_rows', 500)\npd.set_option('display.max_columns', 500)\npd.set_option('display.width', 1000)",
          "Set pandas to display wider columns, and lower the number of rows to display for brevity\npd.options.display.max_colwidth = 100\npd.options.display.max_rows = 10",
          "Set display options for pandas dataframes to ensure rows and columns are not truncated\npd.set_option('display.max_rows', None)\npd.set_option('display.max_columns', None)",
          "allow us to display large string in our dataframes\npd.options.display.max_colwidth = 200",
          "Set display options for Pandas to display nicely\npd.set_option('display.max_columns', None)\npd.set_option('display.expand_frame_repr', False)\npd.set_option('max_colwidth', -1)",
          "set max column with of pandas\npd.set_option('display.max_colwidth', 800)",
          " Turn off scientific notation for pandas\npd.set_option('display.float_format', lambda x: '%.3f' % x)",
          "Display pandas without truncation\npd.set_option('display.max_colwidth', None)",
          "Setting up pandas so we can see the data in a nice tabular fashion (with scrolling)\npd.set_option('display.max_columns', None)\npd.set_option('display.expand_frame_repr', False)\npd.set_option('max_colwidth', -1)",
          "Set the following configurations to avoid truncating DataFrame display (optional)\npd.set_option('display.max_columns', None)\npd.set_option('display.max_rows', None)",
          " Set the dataframe display option to show the full content of the cells\npd.set_option('display.max_colwidth', None)",
          " Set all pandas outputs to be displayed completely\npd.set_option('display.max_rows', None)\npd.set_option('display.max_columns', None)\npd.set_option('display.width', None)\npd.set_option('display.max_colwidth', None)",
          "Set the max width of columns to display for dataframes\npd.set_option('display.max_colwidth', 500)",
          "Limit number of float output to 3 decimal points\npd.set_option('display.float_format', lambda x: '%.3f' % x)",
          "Pandas option for column width\npd.set_option('display.max_colwidth', -1)",
          "Set pandas to display wide tables properly\npd.set_option('display.max_columns', 500)",
          "Set options for pandas\npd.set_option('display.max_columns', 500)\npd.set_option('display.max_colwidth', 500)",
          "Safety measure to prevent truncation of long string columns\npd.options.display.max_colwidth = 100",
          "Set display options for pandas dataframes\npd.options.display.max_columns = None\npd.set_option('display.float_format', lambda x: '%.3f' % x)",
          "Set the pandas display options for better visualisation of the DataFrames\npd.set_option('display.max_columns', None)\npd.set_option('max_colwidth', None)",
          " Setting display options for pandas to display the entire dataframe and prevent value truncating\npd.set_option('display.max_colwidth', None)\npd.set_option('display.max_rows', None)\npd.set_option('display.max_columns', None)",
          "Display settings for the pandas dataframes\npd.set_option('display.max_columns', 500)\npd.set_option('display.width', 1000)",
          " Ensure that pandas will display at least 500 characters in a column\npd.set_option('display.max_colwidth', 500)",
          "Set pandas display options for better data visualization\npd.options.display.max_columns = None\npd.options.display.max_rows = None\npd.options.display.max_colwidth = 1000",
          "# Display settings for pandas dataframes\npd.set_option('display.max_columns', None)\npd.set_option('display.width', 1000)",
          "set pandas to display wide data tables in full to make it easier to understand the data\npd.set_option('display.max_columns', None)",
          " To display the whole content of the dataframe without being cut off\npd.set_option('display.max_colwidth', -1)",
          "Set pandas display options for better visualisation\npd.set_option('display.max_columns', 500)\npd.set_option('display.width', 1000)",
          "Set pandas display options for easier visualization of our datasets\npd.set_option('display.max_columns', None)\npd.set_option('display.max_colwidth', None)",
          "Set options for pandas to display dataframes in a readable way\npd.set_option('display.max_rows', None)\npd.set_option('display.max_columns', None)\npd.set_option('display.width', None)\npd.set_option('display.max_colwidth', -1)",
          "Set output dataframe display to show entire content\npd.set_option(\"display.max_columns\", None)\npd.set_option(\"display.max_colwidth\", -1)",
          " Set float format for better readability\npd.options.display.float_format = '{:,.2f}'.format",
          "Prevent the truncated display of dataframes|# Remove the display truncation for dataframes\npd.set_option('display.max_colwidth', None)",
          "Set the pandas column display options to see the longer text.\npd.set_option('display.max_colwidth', 100)",
          "Set some options for Pandas to display data.frames\npd.set_option('display.max.columns', None)\npd.set_option('display.max_colwidth', None)",
          "Set some pandas display options for better visualizations\npd.set_option('display.max_columns', 50)\npd.set_option('display.max_colwidth', 100)\npd.set_option('display.max_rows', 50)",
          "Set pandas to display wide data\npd.set_option('display.max_colwidth', None)",
          " Allow pandas to display the full content of a column\npd.set_option('display.max_colwidth', None)",
          "utils and settings\ntqdm.pandas()\npd.set_option('display.max_colwidth', 150)",
          " Set maximum column width when displaying dataframes\npd.set_option('display.max_colwidth', 80)",
          " Set the max display width and max display rows for pandas dataframes\npd.set_option('display.max_colwidth', 300)\npd.set_option('display.max_rows', 300)"
         ],
         "marker": {
          "opacity": 0.5,
          "size": 5
         },
         "mode": "markers+text",
         "name": "12_Setting pandas display options for wide columns and long strings",
         "text": [
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          ""
         ],
         "textfont": {
          "size": 12
         },
         "type": "scattergl",
         "x": [
          23.0421142578125,
          22.66176986694336,
          23.487998962402344,
          23.040111541748047,
          22.562620162963867,
          22.754409790039062,
          23.435604095458984,
          22.55929946899414,
          22.367101669311523,
          22.44292640686035,
          23.256309509277344,
          23.54975700378418,
          22.369932174682617,
          22.074670791625977,
          22.0610408782959,
          23.0435791015625,
          23.056425094604492,
          22.126197814941406,
          22.553293228149414,
          22.95974349975586,
          22.567672729492188,
          23.438886642456055,
          23.03443717956543,
          22.995248794555664,
          22.174991607666016,
          23.129058837890625,
          22.653108596801758,
          21.817028045654297,
          23.58877944946289,
          23.24575424194336,
          23.435871124267578,
          22.316007614135742,
          22.507396697998047,
          22.885744094848633,
          21.78334617614746,
          22.62200927734375,
          22.362123489379883,
          23.339214324951172,
          22.65660285949707,
          22.866437911987305,
          22.63505744934082,
          23.225234985351562,
          23.712444305419922,
          22.02301788330078,
          22.051774978637695,
          22.11016845703125,
          23.28049087524414,
          23.144433975219727,
          22.334138870239258,
          23.10308074951172,
          21.881385803222656,
          22.572391510009766,
          23.252687454223633,
          22.05014991760254,
          21.885854721069336,
          22.5601749420166,
          22.970760345458984,
          22.068254470825195,
          23.465234756469727,
          22.395389556884766,
          22.6964111328125,
          22.714853286743164,
          22.855045318603516,
          23.1685733795166,
          23.187509536743164,
          23.116374969482422
         ],
         "y": [
          2.7650387287139893,
          1.825711965560913,
          3.058105707168579,
          3.0474448204040527,
          2.031419277191162,
          1.7080371379852295,
          1.894666314125061,
          2.3488571643829346,
          2.437234878540039,
          1.6254594326019287,
          3.239236354827881,
          2.2595345973968506,
          1.9342215061187744,
          2.726616382598877,
          1.6323142051696777,
          1.4441843032836914,
          2.8358144760131836,
          2.5766851902008057,
          2.5233426094055176,
          2.7672717571258545,
          2.4094769954681396,
          3.1412668228149414,
          1.7023248672485352,
          2.265523672103882,
          2.653333902359009,
          1.9232635498046875,
          1.728286862373352,
          1.9680790901184082,
          2.8026628494262695,
          1.7376693487167358,
          2.38372540473938,
          2.5643601417541504,
          2.820002317428589,
          2.0105905532836914,
          1.5782231092453003,
          2.9417057037353516,
          2.4888710975646973,
          2.595764398574829,
          2.4010045528411865,
          3.0168097019195557,
          1.5255722999572754,
          2.4131524562835693,
          2.930487632751465,
          1.921116590499878,
          2.4361863136291504,
          2.138465642929077,
          1.946132779121399,
          3.080073595046997,
          1.9258371591567993,
          2.1564764976501465,
          1.2501312494277954,
          2.4462063312530518,
          1.7538968324661255,
          2.507784128189087,
          2.0027849674224854,
          2.3319084644317627,
          2.185009002685547,
          2.482898473739624,
          3.2175002098083496,
          2.1557724475860596,
          1.9251636266708374,
          2.9307403564453125,
          2.6300089359283447,
          2.6062285900115967,
          2.404099702835083,
          1.807302474975586
         ]
        },
        {
         "hoverinfo": "text",
         "hovertext": [
          "Explore the data from df_characters dataframe",
          "Display the loaded dataframes\ndf_characters",
          "Display basic info of df_characters\ndf_characters.info()",
          "Display lines from the df_characters dataframe.",
          "View data shape and general info\ndf_characters.shape",
          "Display dataframe info\ndf_characters.info()",
          "List of characters as a set and list\nset_characters = set(df_characters['character'].values)\nlst_characters = list(set_characters)",
          "\ndf_characters['raw_character_text']",
          "Display the dataframes' content\ndf_characters",
          "\ndf_characters",
          "Display the characters dataframe\ndf_characters",
          "View all available columns in the characters dataframe\ndf_characters.columns",
          "DataFrame's info\ndf_characters.info()",
          "\nprint(df_characters)",
          "Columns from the df_characters Dataframe\nprint(df_characters.columns)",
          "Extracting df_characters subcolumns and reseting the index",
          " Show info about the characters dataframe\ndf_characters.info()",
          " Explore the content of the characters' dataframe\ndf_characters.info()",
          "View general information about our datasets\nprint('\\nInformation about the characters dataset:')\ndisplay(df_characters.info())",
          " Sample the characters dataframe\ndf_characters.sample(10)",
          "Inspect the contents of df_characters dataframe",
          "Inspect df_characters",
          "display(df_characters)",
          "Display some basic information about the characters dataframe\ndf_characters.info()",
          "Select your favourite character\ndf_characters['character'].values",
          "Check the info of df_characters\ndf_characters.info()",
          "# Number of characters\ndf_characters.shape[0]",
          "The first dataframe (df_characters) holds all the characters and their metadata.",
          "\n# let's remind ourselves what's in the data.\nprint(df_characters.keys())",
          " Display the dataframes to understand their structure and contents\ndf_characters",
          "Check the result\ndf_characters",
          "df_characters.info()",
          " Data overview\ndf_characters.info()",
          "Display most important columns\nprint(df_characters.info())",
          " Look at several random rows in the characters DataFrame\nprint(df_characters.sample(5))",
          "Explore the structure of the characters dataframe\nprint(df_characters.info())",
          "Print basic information on the characters dataset\ncharacters_info = df_characters.info()",
          "Display the basic information of characters dataset\ndf_characters.info()",
          "Inspect the characters dataframe to understand its structure and contents\ndf_characters.info()",
          "\nprint(\"Characters Dataset:\")\nprint(df_characters)",
          "Display a sample of each dataframe\ndf_characters.sample(5)",
          "Check basic info about characters DataFrame\ndf_characters.info()",
          " Display information for the characters dataset\ndf_characters.info()",
          "General information about the character dataset\nprint(df_characters.shape)\nprint(df_characters.columns)\nprint(df_characters.dtypes)",
          "Display the dataset samples\ndf_characters.sample(5)",
          "Set the character_name to be the index of df_characters",
          "Display the character dataframe\ndf_characters",
          "Display basic information about the loaded datasets\nprint('\\nCHARACTERS')\ndisplay(df_characters.info())\ndisplay(df_characters.head(5))",
          "Inspect \"df_characters\" DataFrame",
          "Sample the data to have a look at their structure\ndf_characters.sample(5)",
          "View DataFrame info\ndf_characters.info()",
          "Inspect data types and missing values\ndf_characters.info()",
          " Display information about the characters dataframe\nprint(df_characters.info())",
          " Display the information about the characters dataframe\ndf_characters.info()",
          "Inspect data columns and types\nprint(df_characters.dtypes)",
          "Inspecting the data\ndf_characters.info()",
          "Checking df_characters dataframe",
          " Display summary information for the characters dataset\nprint('Characters dataset:')\nprint(f'- Number of rows: {len(df_characters)}')\nprint('- Columns:', list(df_characters.columns))",
          "Inspecting the first three rows of the df_characters dataframe.",
          "Display the characters dataframe\ndf_characters",
          " Display basic information about the characters dataset\nprint(df_characters.info())",
          "type(df_characters)",
          "Check the contents of df_characters dataframe",
          "Print info of the characters dataframe\nprint(df_characters.info())",
          " Simply display the dataframes to understand their structure and contents\ndf_characters"
         ],
         "marker": {
          "opacity": 0.5,
          "size": 5
         },
         "mode": "markers+text",
         "name": "13_Displaying Information about the Characters DataFrame",
         "text": [
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          ""
         ],
         "textfont": {
          "size": 12
         },
         "type": "scattergl",
         "x": [
          7.567188262939453,
          7.092046737670898,
          7.4906134605407715,
          7.03456449508667,
          6.684723854064941,
          7.768560409545898,
          6.809349060058594,
          6.688868999481201,
          7.607017993927002,
          6.5586466789245605,
          7.208131790161133,
          7.362772464752197,
          7.785606861114502,
          6.581697463989258,
          7.188767433166504,
          6.468541622161865,
          7.730262756347656,
          7.42460823059082,
          7.075813293457031,
          7.2919769287109375,
          7.5263190269470215,
          6.926621913909912,
          6.944799900054932,
          7.69827938079834,
          6.779422283172607,
          6.728144645690918,
          6.8976287841796875,
          7.033864974975586,
          6.550182342529297,
          7.672935962677002,
          6.764157772064209,
          7.121516704559326,
          7.056427478790283,
          7.403101921081543,
          8.220620155334473,
          7.45208215713501,
          7.0969038009643555,
          7.354236125946045,
          7.39465856552124,
          6.836696624755859,
          7.448852062225342,
          7.508607387542725,
          7.316623210906982,
          6.472046852111816,
          6.399533271789551,
          6.166261672973633,
          7.112366676330566,
          6.9651947021484375,
          7.560055255889893,
          6.4983649253845215,
          7.683889865875244,
          6.9551005363464355,
          7.357418537139893,
          7.504552841186523,
          6.674833297729492,
          6.912323474884033,
          7.292754650115967,
          6.678565979003906,
          8.341873168945312,
          7.066532135009766,
          7.18506383895874,
          6.405509948730469,
          7.265987396240234,
          7.342921257019043,
          7.508925437927246
         ],
         "y": [
          12.211292266845703,
          12.07146167755127,
          12.910572052001953,
          13.102954864501953,
          13.531496047973633,
          12.821991920471191,
          11.432639122009277,
          10.549638748168945,
          12.508862495422363,
          11.897014617919922,
          12.32730484008789,
          11.710076332092285,
          13.025724411010742,
          12.297916412353516,
          11.621121406555176,
          10.727657318115234,
          13.21881103515625,
          12.711365699768066,
          13.595746994018555,
          13.143854141235352,
          12.202445983886719,
          12.76993465423584,
          12.03187084197998,
          13.245318412780762,
          10.763227462768555,
          12.98343276977539,
          11.409211158752441,
          13.847525596618652,
          13.469429969787598,
          12.352009773254395,
          12.414594650268555,
          12.363288879394531,
          12.922662734985352,
          13.600790977478027,
          11.317946434020996,
          13.485296249389648,
          13.040549278259277,
          13.097052574157715,
          13.081503868103027,
          12.791043281555176,
          11.162324905395508,
          13.126809120178223,
          12.925660133361816,
          13.602490425109863,
          13.044415473937988,
          10.602228164672852,
          12.044930458068848,
          13.901837348937988,
          12.258805274963379,
          12.794867515563965,
          13.304679870605469,
          12.367602348327637,
          13.60189437866211,
          12.89428424835205,
          12.470972061157227,
          12.789647102355957,
          12.444726943969727,
          13.762336730957031,
          12.702468872070312,
          12.266827583312988,
          13.379243850708008,
          12.111680030822754,
          11.895686149597168,
          13.20230484008789,
          12.220208168029785
         ]
        },
        {
         "hoverinfo": "text",
         "hovertext": [
          "Remove rows with missing values in the script and characters DataFrames\ndf_script.dropna(inplace=True)\ndf_characters.dropna(inplace=True)",
          "# Some pre-processing\ndf_script = df_script.dropna(subset=['normalized_text'])",
          "Remove script lines without character, location, or raw text\ndf_script = df_script.dropna(subset=['character_id', 'location_id', 'raw_text']).reset_index(inplace=False, drop=True)",
          "# We set the custom null value '???' as standard NaN. We also fix the characters_id datatype\ndf_script['character_id'] = pd.to_numeric(df_script['character_id'], errors='coerce')\ndf_script['character_id'] = df_script['character_id'].fillna(-1).astype(int)",
          " Drop the first data in the df_characters dataframe as it is just a row of NaN values.",
          "Removing rows with empty or NaN values in the 'normalized_text' column\ndf_script = df_script.dropna(subset=['normalized_text']).reset_index(inplace=False, drop=True)",
          "Drop all the na entries from the script, characters and location dataframes",
          " Due to the size of the dataset, we will drop rows with missing values in the following columns: `script`, `character_id`, `location_id`, and `raw_text`.",
          "Discard rows with NaN values in the normalized_text column\ndf_script = df_script.dropna(subset=['normalized_text'])",
          "Clean df_characters\ndf_characters = df_characters.dropna()",
          "Clean encountered NaN in raw data\ndf_script_clean = df_script.dropna(subset=['raw_text']).reset_index(drop=True)",
          "Remove rows where character id or locations are missing\ndf_script = df_script.dropna(subset=['character_id', 'location_id'])",
          "Drop lines where either character or location is missing, and keep only id, character and location columns\ndf_script = df_script.dropna(subset=['character_id', 'location_id']).reset_index(inplace=False, drop=True).loc[:, ['id', 'character_id', 'location_id']]",
          "# remove missing values\ndf_script = df_script.dropna()",
          "Preprocessing\n# Removing rows where the 'normalized_text' column is NaN\ndf_script = df_script.dropna(subset=['normalized_text'])",
          " Remove columns with too many missing values\ndf_script.drop(columns=['alignment', 'raw_text'], inplace=True)",
          "drop nan values\ndf_script = df_script.dropna(subset=['character_id', 'location_id', 'normalized_text'])",
          "Dropping rows with missing values on 'raw_character_text' column\ndf_script.dropna(subset=['raw_character_text'], inplace=True)",
          " Remove rows with empty script lines\ndf_script = df_script.dropna(subset=['raw_text']).reset_index(inplace=False, drop=True)",
          "Clean up NaN values\ndf_script = df_script.dropna(subset=['raw_text'])",
          " clean script df\ndf_script_clean = df_script.dropna(subset=['raw_text'])  # Remove rows with NaN in 'raw_text' column",
          "remove rows with empty \"normalized_text\" column\ndf_script = df_script.dropna(subset=['normalized_text'])",
          "# Remove empty lines\ndf_script = df_script.dropna(subset=['raw_text'])",
          "Drop rows with missing data from the df_script dataframe\ndf_script.dropna(inplace=True)",
          "Remove lines without any text in them.\ndf_script = df_script.dropna(subset=['normalized_text'])",
          "Clean the NaNs\ndf_script = df_script.dropna(subset=['raw_text'])",
          "Remove rows with missing script data\ndf_script = df_script.dropna(subset=['normalized_text'])",
          "Remove records with missing script data\ndf_script = df_script.dropna(subset=['raw_text'])\n\n# Show resulting statistics to ensure records were removed\ndf_script.info()",
          "Drop lines without any character or dialogue\ndf_script = df_script.dropna(subset=['character_id', 'raw_text'])",
          " Remove NaN values from 'text' column of df_script\ndf_script = df_script[df_script['text'].notna()].reset_index(inplace=False, drop=True)",
          " Remove rows with missing information in the script dataset\ndf_script.dropna(subset=['normalized_text', 'raw_text', 'word_count'], inplace=True)",
          "Drop rows with NaN\ndf_script = df_script.dropna(subset=['character_id', 'location_id'])",
          "Remove Simpsons’ lines with empty text\ndf = df_script.copy()\ndf.dropna(subset=['normalized_text'], inplace=True)",
          "Remove NA values in speaking line column\ndf_script = df_script.dropna(subset=['Normalized_text']).reset_index(inplace=False, drop=True)",
          " Preprocess script dataframe\ndf_script = df_script.dropna(subset=['normalized_text'])  # Keep only non-NA values in the dataframe\ndf_script = df_script[df_script.normalized_text != '']  # Keep only non-empty values in the dataframe",
          "preprocessing\ndf_script = df_script.dropna(subset=['character_id', 'location_id'])",
          " Remove the empty lines\ndf_script = df_script[df_script[\"raw_character_text\"].notna()].reset_index(inplace=False, drop=True)",
          "\n# We drop the lines without quoting character\ndf_script = df_script.drop(df_script[df_script.raw_character_text.isna()].index)",
          " Drop lines containing unwanted data from df_script\n# Check elements to be removed\ndf_script.replace('\\\\N','')",
          "Drop rows where one element is NaN\ndf_script = df_script.dropna()",
          "# Remove rows with empty character names\ndf_script = df_script.dropna(subset=['raw_character_text'])",
          "Remove unwanted rows and leave only those, which have the same length of 'normalized_text' and 'word_count'",
          "Cleaning the data\ndf_script = df_script.dropna(subset=['normalized_text', 'character_id']).reset_index(inplace=False, drop=True)",
          " df_script = df_script.dropna(subset=['normalized_text'])",
          "Remove script lines without any speaking character\ndf_script = df_script.dropna(subset=['character_id'])",
          "Remove rows with empty strings from the \"normalized_text\" column in df_script\ndf_script = df_script[df_script[\"normalized_text\"].apply(lambda x: x != '')]",
          "Delete rows from the script where the normalized_text is missing.",
          "Remove rows where the character, location, or dialogue is missing\ndf_script = df_script.dropna(subset=['character_id', 'location_id', 'normalized_text'])",
          "Remove NaN values from 'character_id' column, and convert it to int\ndf_script = df_script.dropna(subset=['character_id'])\ndf_script['character_id'] = df_script['character_id'].astype(int)",
          " Remove rows with missing values in the specified column\ndf_script = df_script.dropna(subset=['raw_text'])",
          " Remove all the \"bad\" lines (i.e. duplicate, not indiced, without a raw_text)\ndf_script = df_script[df_script[\"raw_text\"].notna()]",
          "Drop any NaN values from the 'raw_text' column, as they don't provide any valuable information for our analysis\ndf_script = df_script.dropna(subset=['raw_text'])",
          "Clean up\ndf_script = df_script.dropna()",
          "Remove the character_id and location_id\ndf_script.drop(columns=['character_id', 'location_id'], inplace=True)",
          "Remove rows with missing data\ndf_script = df_script.dropna(subset=['normalized_text'])",
          "Drop NaN values in 'raw_text' and 'character_id' columns\ndf_script = df_script.dropna(subset=['raw_text', 'character_id'])",
          " Add regex to drop rows with all na values\ndf_script = df_script.dropna(how='all', subset=['normalized_text'])",
          " Remove nas\ndf_script = df_script.dropna(subset=['normalized_text'])",
          "# We first need to remove any NaN values from the character_name field\ndf_script.dropna(subset=['character_id'], inplace=True)\n\n# Get the characters IDs\ncharacter_ids = df_characters[['id']]\n# Get the characters IDs\nlocation_ids = df_locations[['id']]",
          "Filter rows with NaN valued from the `character_id` column.",
          "Clean the scripts data\ndf_script_dropna = df_script.dropna(subset=['raw_text'])\ndf_script_dropna = df_script_dropna[df_script_dropna.raw_text != '']\ndf_script_dropna.reset_index(inplace=True, drop=True)",
          "Remove all the rows where at least one element is missing.\ndf_script = df_script.dropna()",
          "Clean data\ndf_script_clean = df_script.dropna(subset=['raw_text'])\n\n# Preview data\ndf_script_clean.head()"
         ],
         "marker": {
          "opacity": 0.5,
          "size": 5
         },
         "mode": "markers+text",
         "name": "14_Data Cleaning and Removal of Missing Values in df_script DataFrame",
         "text": [
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          ""
         ],
         "textfont": {
          "size": 12
         },
         "type": "scattergl",
         "x": [
          6.378630638122559,
          6.341158390045166,
          5.712435245513916,
          5.551868438720703,
          6.7362823486328125,
          6.5207695960998535,
          6.472625732421875,
          5.894720077514648,
          6.606391906738281,
          6.470204830169678,
          6.123087406158447,
          5.636847972869873,
          5.851902961730957,
          6.21096658706665,
          6.908647537231445,
          6.029437065124512,
          6.0454816818237305,
          6.104610919952393,
          6.146099090576172,
          6.37260627746582,
          6.690649032592773,
          6.870419025421143,
          6.107424259185791,
          6.153489112854004,
          6.555346965789795,
          6.35899543762207,
          6.73969030380249,
          6.144506454467773,
          6.382002830505371,
          6.614789009094238,
          6.9787983894348145,
          5.786419868469238,
          5.856250286102295,
          6.8837480545043945,
          6.815855503082275,
          5.198235511779785,
          6.094204425811768,
          5.882884502410889,
          6.499643325805664,
          6.262996196746826,
          6.10670280456543,
          8.010784149169922,
          5.852758407592773,
          6.146308898925781,
          5.967617988586426,
          6.643500804901123,
          7.360826015472412,
          5.6686248779296875,
          5.817196846008301,
          6.442264080047607,
          6.088402271270752,
          6.685499668121338,
          6.121896266937256,
          5.337396621704102,
          6.666228294372559,
          6.183657169342041,
          6.494454860687256,
          6.719871997833252,
          5.76590633392334,
          5.744748592376709,
          6.134382724761963,
          6.655686855316162,
          6.2790117263793945
         ],
         "y": [
          5.300658702850342,
          6.960381984710693,
          6.631192207336426,
          6.070120334625244,
          6.917148113250732,
          6.192397117614746,
          4.907462120056152,
          5.442481517791748,
          5.910698890686035,
          5.832500457763672,
          4.986809730529785,
          6.035882949829102,
          6.183866500854492,
          4.5021257400512695,
          6.420411586761475,
          5.027314186096191,
          5.633133888244629,
          5.92055606842041,
          6.227673053741455,
          5.440984725952148,
          5.566042423248291,
          6.711573600769043,
          6.013623237609863,
          4.704582214355469,
          6.914079666137695,
          5.584304332733154,
          6.0337605476379395,
          5.480187892913818,
          6.538466930389404,
          4.718812465667725,
          5.762818813323975,
          5.710690498352051,
          6.8359880447387695,
          5.996852874755859,
          6.263575077056885,
          5.848336696624756,
          6.722711086273193,
          6.341777801513672,
          6.24575138092041,
          4.776686191558838,
          6.32632303237915,
          6.157137393951416,
          7.0433220863342285,
          6.764954566955566,
          6.534003734588623,
          7.265579700469971,
          6.321993827819824,
          6.307344913482666,
          6.409334182739258,
          5.546277046203613,
          6.376553058624268,
          5.568621635437012,
          4.0862202644348145,
          6.331480979919434,
          6.369164943695068,
          6.196363925933838,
          6.067463397979736,
          6.574599266052246,
          5.770493507385254,
          5.837995529174805,
          5.845875263214111,
          4.579842567443848,
          6.171456813812256
         ]
        },
        {
         "hoverinfo": "text",
         "hovertext": [
          "Let's look at the some data to understand it better\ndf_episodes.head(2)",
          "Check the results\ndf_episodes.head()",
          "Check the result\ndf_episodes.head()",
          "\ndf_episodes.head()",
          "Set correct datatypes for each column\ndf_episodes.head()",
          "Explore the data\ndf_episodes.head()",
          "Check the content of the episodes dataset\ndf_episodes.head()",
          "Creating a basic dataframe of episodes data\ndf_episodes.head()",
          "Check the data structure of the episodes data\nprint(f'Episodes shape: {df_episodes.shape}')\ndf_episodes.head()",
          "Look at sample of episodes data\ndf_episodes.sample(5)",
          "Preview the episodes dataframe\ndf_episodes.head()",
          " Display main datasets\ndf_episodes.head()",
          "Check the data and its format\ndf_episodes.head()",
          "Look the five first data of the dataframe df_episodes\ndf_episodes.head()",
          " Display\ndf_episodes.head()",
          "View some first lines of the data\ndf_episodes.head()",
          "Check the first episodes record to see what data is available\ndf_episodes.iloc[0]",
          " Look at the info to see missing data\ndf_episodes.info()",
          " Subsets\ndf_episodes.head()",
          "Displaying head of df_episodes\ndf_episodes.head()",
          "Quick overview of the dataset\nprint(df_episodes.head())",
          "Plot some simple histograms for the episodes dataframe",
          "View the data\ndf_episodes.head()",
          "Quick look at the data\ndf_episodes.head()",
          "Data inspection and exploration\ndf_episodes.head()",
          " Display the dataframe\ndf_episodes",
          " Take a look at the first few rows of the dataframe\ndf_episodes.head()",
          "Display general information about the data\ndf_episodes.info()",
          "Print the head of the episodes dataframe\nprint(df_episodes.head())",
          "Choose an episode at random for this analysis\nep = df_episodes.sample(1)\nep",
          "df_episodes",
          "View the content of the episodes dataframe\ndf_episodes.head()",
          "Get top movie release years\ndf_movies = pd.read_csv('data/movie_metadata.csv')\ndf_movies['title_year'].value_counts().head(10)",
          "Check the content of the episodes dataframe",
          "Create a summary statistics of the episodes data\ndf_episodes.describe()",
          " Show the head of the episodes dataframe\ndf_episodes.head()",
          "Show dataframe head\ndf_episodes.head()",
          " exploration\ndf_episodes.head()",
          "# Show head of episodes\ndf_episodes.head()",
          " Showing the head of the episodes dataframe\ndf_episodes.head()",
          " The head of the episode dataframe\ndf_episodes.head()",
          "Inspect data\ndf_episodes.head()",
          "Check data samples for consistency\ndf_episodes.head()",
          "lec df_episodes.head()",
          "#Overview of the data\ndf_episodes.head()",
          "Explore the structure of episodes data\ndf_episodes.head(10)",
          "check out the data to give an overview of what we are working with\ndf_episodes.info()",
          "Preview the episodes data\ndf_episodes.head()",
          "Sanity-check dataframe objects\ndf_episodes",
          "Dataframe columns header correction\ndf_episodes.columns.tolist()",
          "Explore the datasets\ndf_episodes.head()",
          "Print the head of the episodes dataframe\nprint(df_episodes.head())",
          "Check our datasets\ndf_episodes.head()",
          "Show the data from the episode CSV file\ndf_episodes.head()",
          " Display the contents of the episodes dataframe\ndf_episodes.head()",
          "Preview the data\ndf_episodes.head()",
          "Just let's see the top lines of the episodes dataset\ndf_episodes.head()",
          "Check out the data\ndf_episodes.head()",
          " Verify content of dataset\ndf_episodes.head()",
          "Print the head of the dataframe to check its structure\ndf_episodes.head()",
          "Look at the first 3 rows of the episodes DataFrame.\ndf_episodes.head(3)",
          "Preview the episodes dataset\ndf_episodes.head()"
         ],
         "marker": {
          "opacity": 0.5,
          "size": 5
         },
         "mode": "markers+text",
         "name": "15_Previewing Episodes DataFrame",
         "text": [
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          ""
         ],
         "textfont": {
          "size": 12
         },
         "type": "scattergl",
         "x": [
          2.29732608795166,
          2.123201370239258,
          1.927895188331604,
          2.132038116455078,
          1.903576374053955,
          1.8299177885055542,
          2.5279784202575684,
          2.3915047645568848,
          2.122710704803467,
          2.750566005706787,
          1.3309603929519653,
          2.0801515579223633,
          2.4164884090423584,
          2.2260279655456543,
          2.364656925201416,
          1.3950200080871582,
          3.246070384979248,
          3.090841054916382,
          2.042954921722412,
          2.222506523132324,
          1.7803453207015991,
          2.4136013984680176,
          1.9610803127288818,
          1.8735774755477905,
          1.825582504272461,
          2.1888647079467773,
          2.1519906520843506,
          1.3374119997024536,
          2.4483437538146973,
          2.925795316696167,
          2.6388072967529297,
          2.5116589069366455,
          1.7241082191467285,
          2.9711225032806396,
          1.8982127904891968,
          2.534560441970825,
          2.232879161834717,
          2.010789394378662,
          2.4403505325317383,
          2.264606475830078,
          2.1549324989318848,
          1.6461399793624878,
          1.562780737876892,
          2.428023099899292,
          1.770302414894104,
          1.9282922744750977,
          2.1605451107025146,
          1.8518877029418945,
          1.6058084964752197,
          1.469313383102417,
          1.9782582521438599,
          2.1646924018859863,
          2.2702715396881104,
          2.439016342163086,
          2.247220039367676,
          1.6276631355285645,
          1.9927113056182861,
          2.2869486808776855,
          2.0141468048095703,
          1.8437061309814453,
          2.472763776779175,
          1.596065878868103
         ],
         "y": [
          2.7099339962005615,
          2.5926499366760254,
          2.686096429824829,
          2.4034323692321777,
          2.541867256164551,
          2.9008326530456543,
          2.5777270793914795,
          2.1567676067352295,
          2.176755905151367,
          2.876842498779297,
          3.0994269847869873,
          2.514371156692505,
          2.47723388671875,
          3.4676594734191895,
          2.2992401123046875,
          3.3420464992523193,
          3.0747814178466797,
          2.5779502391815186,
          2.5256404876708984,
          2.0399346351623535,
          3.2003910541534424,
          3.5291199684143066,
          2.833005905151367,
          2.830195426940918,
          2.6067774295806885,
          2.4915385246276855,
          2.650211811065674,
          2.4256343841552734,
          1.7847987413406372,
          3.298285484313965,
          2.7334225177764893,
          1.8347947597503662,
          3.503866195678711,
          2.229407787322998,
          2.5792510509490967,
          1.8874248266220093,
          1.629217505455017,
          2.4919397830963135,
          2.285606861114502,
          1.6223810911178589,
          1.8593807220458984,
          2.673767328262329,
          2.6221535205841064,
          2.2605936527252197,
          2.7611818313598633,
          3.0984601974487305,
          2.6279454231262207,
          3.131291151046753,
          1.693852186203003,
          1.893904447555542,
          2.886023759841919,
          2.0574121475219727,
          2.6606383323669434,
          2.3622446060180664,
          1.8291077613830566,
          3.0888795852661133,
          2.927701950073242,
          2.8957879543304443,
          2.2152886390686035,
          2.0085408687591553,
          3.0901288986206055,
          2.6978657245635986
         ]
        },
        {
         "hoverinfo": "text",
         "hovertext": [
          "Inspect the first few rows of the characters data\ndf_characters.head()",
          "Check the first few rows of the characters dataframe\ndf_characters.head()",
          "Check the first few rows of the characters dataframe\ndf_characters.head()",
          "Sanity check for first rows of df_characters\ndf_characters.head()",
          " Checking the first few rows of the characters dataframe\ndf_characters.head()",
          "Inspect the first few rows of the characters dataset\ndf_characters.head()",
          "Check the first few rows of the characters dataframe\ndf_characters.head()",
          "Check the first rows of each dataframe\ndf_characters.head()",
          " Check the first few rows of the characters DataFrame\ndf_characters.head()",
          "Check the first few rows of the characters dataframe\ndf_characters.head()",
          "Inspect the first few rows of the characters dataset\ndf_characters.head()",
          "Check the first rows of characters.csv\ndf_characters.head()",
          " Check the first few rows of the characters dataframe\ndf_characters.head()",
          "Check the 5 first lines of the characters dataframe to understand its structure\ndf_characters.head()",
          "Examine the first few rows of the characters dataset\ndf_characters.head()",
          "Inspecting the first few rows of the characters dataset\ndf_characters.head()",
          "Check the first few rows of the characters dataset\ndf_characters.head()",
          "Checking first rows for each dataset\ndf_characters.head()",
          "Checking the first few rows of each dataframe to understand its structure\nprint('Characters')\nprint(df_characters.head())",
          "Check first rows of `df_characters`\ndf_characters.head()",
          "Checking the first few rows of characters dataframe\ndf_characters.head()",
          "Check the first few rows of the dataframe\nprint(df_characters.head())",
          " Use pandas to see what's inside the first loaded dataset\ndf_characters.head()",
          "Check the first few rows of the characters dataframe\ndf_characters.head()",
          "Check the first few entries of the characters dataframe\ndf_characters.head()",
          "Explore the first rows of the characters dataset\ndf_characters.head()",
          "Check the first row of each dataframe\ndf_characters.head(1)",
          "Inspecting first rows of the dataset\ndf_characters.head()",
          "Check the first rows of the characters dataframe\ndf_characters.head()",
          "Check the first few rows of the characters data\ndf_characters.head()",
          "Checking the first rows for df_characters",
          "Check the first few rows of the characters dataframe\ndf_characters.head()",
          "Check first rows of the characters dataframe\ndf_characters.head()",
          "Checking the first few rows of the characters dataset to understand its structure\ndf_characters.head()",
          " Check the first few rows of each dataframe\nprint(\"Characters:\")\ndisplay(df_characters.head())",
          " Check the first few rows of the characters dataframe to understand its structure\ndf_characters.head()",
          "Check the first few rows of the characters dataframe\ndf_characters.head()",
          "Check the first few rows of the characters dataframe\ndf_characters.head()",
          "Check the first few rows of the characters dataframe\ndf_characters.head()",
          "Check the first few rows of the characters dataframe\ndf_characters.head()",
          "Check first few rows of df_characters\ndf_characters.head()",
          "Check first few rows of characters dataframe\ndf_characters.head()",
          " Check the first few rows of the characters dataframe\ndf_characters.head()",
          "Check the first few rows of the characters dataframe\ndf_characters.head()",
          "Check first few rows of characters dataframe\ndf_characters.head()",
          "checking the first few rows of the characters dataframe\ndf_characters.head()",
          " Check the first few entries of the characters dataframe\ndf_characters.head()",
          "Check the first few rows of df_characters\ndf_characters.head()",
          " Check the first few lines of the characters dataframe\ndf_characters.head()",
          "Check the first few rows of the characters dataframe\ndf_characters.head()",
          "Check the first few rows of each dataframe\ndf_characters.head()",
          " Check three first characters dataframe\ndf_characters.head(3)",
          "an inspection of the first few rows of df_characters\ndf_characters.head()",
          "Check the first few rows of the characters dataframe\ndf_characters.head()",
          "Check the first few rows of the characters dataframe\ndf_characters.head()",
          "Check the first rows of the characters DataFrame\ndf_characters.head()",
          "Examine the first few rows of the characters data\ndf_characters.head()",
          "Check the first few lines of the characters dataframe\ndf_characters.head()",
          "Check the first few lines of the characters dataframe\ndf_characters.head()",
          " Check the first few rows of the characters data\ndf_characters.head()",
          "Check head of the first dataframe\ndf_characters.head()",
          "Check the first lines of each dataframes\ndf_characters.head()"
         ],
         "marker": {
          "opacity": 0.5,
          "size": 5
         },
         "mode": "markers+text",
         "name": "16_Checking the Sanity of Characters Dataset rows",
         "text": [
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          ""
         ],
         "textfont": {
          "size": 12
         },
         "type": "scattergl",
         "x": [
          4.312262535095215,
          3.489804267883301,
          3.6310105323791504,
          3.378896713256836,
          2.988276481628418,
          4.442013263702393,
          3.1123859882354736,
          3.4862091541290283,
          3.3274548053741455,
          3.166168212890625,
          4.411008834838867,
          3.1339099407196045,
          3.5754013061523438,
          4.491796016693115,
          3.8173203468322754,
          3.9072093963623047,
          3.9131011962890625,
          3.52329683303833,
          4.519347667694092,
          3.6077442169189453,
          2.949018716812134,
          3.9166362285614014,
          4.209377288818359,
          3.451122999191284,
          3.6100287437438965,
          3.4122250080108643,
          3.3006911277770996,
          3.397477149963379,
          3.340223789215088,
          3.663036346435547,
          4.458286762237549,
          3.2849650382995605,
          3.4070708751678467,
          4.279821872711182,
          4.664469242095947,
          3.9434545040130615,
          3.3069493770599365,
          3.4746944904327393,
          3.735905885696411,
          3.3352391719818115,
          3.5804574489593506,
          3.238784074783325,
          3.267763614654541,
          3.4857394695281982,
          2.923043966293335,
          2.867218494415283,
          3.6903347969055176,
          3.660775899887085,
          3.772817373275757,
          3.2536778450012207,
          3.513167142868042,
          3.309849500656128,
          3.7914013862609863,
          3.3708298206329346,
          3.47275447845459,
          3.314669609069824,
          3.3732547760009766,
          4.138648509979248,
          4.066041946411133,
          3.7074897289276123,
          3.9446499347686768,
          3.732555866241455
         ],
         "y": [
          17.497724533081055,
          20.695959091186523,
          20.370899200439453,
          18.94060707092285,
          20.245939254760742,
          15.776863098144531,
          20.611265182495117,
          19.522367477416992,
          20.667612075805664,
          20.929166793823242,
          15.88267993927002,
          19.279245376586914,
          20.778650283813477,
          19.065303802490234,
          16.487380981445312,
          16.405109405517578,
          17.381603240966797,
          18.532514572143555,
          19.605506896972656,
          19.077346801757812,
          19.952228546142578,
          20.39504623413086,
          15.9932222366333,
          20.455114364624023,
          20.929744720458984,
          16.189176559448242,
          19.573453903198242,
          16.944276809692383,
          19.785919189453125,
          18.533714294433594,
          18.320350646972656,
          20.738523483276367,
          19.512861251831055,
          16.270933151245117,
          19.842321395874023,
          19.8415584564209,
          20.512556076049805,
          20.51456642150879,
          20.742290496826172,
          20.286497116088867,
          19.458820343017578,
          19.906312942504883,
          20.509925842285156,
          20.723901748657227,
          19.86681365966797,
          20.060869216918945,
          20.784423828125,
          19.335315704345703,
          20.25101661682129,
          20.843473434448242,
          20.01051902770996,
          16.032440185546875,
          18.068336486816406,
          20.829790115356445,
          20.4722900390625,
          19.677852630615234,
          17.388139724731445,
          20.21776580810547,
          20.39396095275879,
          18.51909828186035,
          20.574426651000977,
          20.2039852142334
         ]
        },
        {
         "hoverinfo": "text",
         "hovertext": [
          "Merge character data\ndf_characters = df_characters.rename(columns={'id':'character_id'})\ndf_script = df_script.merge(df_characters, on='character_id')",
          "Aggregating data on main locations and main characters\ndf_script_characters = df_script[df_script.raw_character_text.notnull()]\ndf_script_characters = df_script_characters.merge(\n    df_characters[['id', 'normalized_name', 'gender']],\n    left_on='raw_character_text', right_on='normalized_name',\n    how='left')",
          "Merge characters in script\ndf_script_characters = (\n    df_script\n    .loc[df_script['speaking_line']]\n    .merge(\n        df_characters,\n        how='left',\n        left_on='raw_character_text',\n        right_on='character'\n    )\n)",
          " merge characters and script dataframe\ndf_characters.rename(columns={'id': 'character_id'}, inplace=True)\ndf_merged = pd.merge(df_script, df_characters, on='character_id', how='left')",
          "Join characters and script\ndf_characters_script = pd.merge(df_script, df_characters, left_on='character_id', right_on='id')",
          "Merge script with characters\ndf_script_char = df_script.merge(\n    df_characters,\n    left_on='character_id',\n    right_on='id',\n    suffixes=('_script', '_char'))\ndf_script_char.head()",
          "Merging character names into the script DataFrame\ndf_script = pd.merge(df_script, df_characters, how='inner', left_on='character_id', right_on='id', suffixes=('_script', '_character'))",
          "Merge script with characters ids\ndf_script['character_id'] = df_script['raw_character_text'].map(lambda x: df_characters[df_characters['normalized_name'] == x.lower()]['id'].values[0] if len(df_characters[df_characters['normalized_name'] == x.lower()]['id'].values) > 0 else np.nan)",
          "Rename character name in df_script to prepare for join",
          " Add a column with the appropiate characters to df_script\ndf_script = df_script.merge(\n    df_characters[['id', 'name']],\n    how='left',\n    left_on='character_id',\n    right_on='id'\n)",
          "# Merging dataFrames in a unique one\ndf = df_script.copy()\ndf['character_id'] = df['character_id'].fillna(-1).astype(int)",
          "Separate script and character lines\ndf_script_lines = df_script[df_script['character_id'].notna()]\ndf_character_lines = pd.merge(df_script_lines, df_characters, left_on='character_id', right_on='id')",
          "Merge script with characters\ndf_merged = pd.merge(df_script, df_characters, how='left',\non=['character_id'], suffixes=('', '_char'))",
          "Merge the scripts with the character metadata\ndf_scripts_characters = pd.merge(df_script, df_characters, on='character_id', how='inner')",
          "Merge the dialogues with the character metadata\ndf_character_lines = pd.merge(df_script, df_characters, left_on='character_id', right_on='id')",
          "Merge script with characters\ndf_characters_script = df_script.merge(df_characters, left_on='character_id', right_on='character_id')",
          "Merging df_script with character data\ndf_script_chars = pd.merge(df_script, df_characters, left_on='character_id', right_on='id')",
          "Merge characters and script\ndf_script = df_script[df_script.raw_character_text != \"\"]\ndf_script = pd.merge(df_script, df_characters, how=\"left\", on=[\"raw_character_text\"])",
          "Create a dataframe by merging `df_script` with `df_characters` on the `character_id` field.",
          "Merge script and character data\ndf_lines_characters = pd.merge(df_script, df_characters, how='inner', left_on='character_id', right_on='id').drop(columns=['id'])",
          "Merge the script and character dataframe\ndf_script = df_script.merge(df_characters.add_prefix('character_'), left_on='character_id', right_on='character_id', how='left')",
          "Merge scripts with character names and locations\ndf_merged = df_script.merge(df_characters, how='left', left_on='character_id', right_on='id', suffixes=('_script', '_character'))",
          "Merge characters and script dataframes\ndf_characters_and_script = pd.merge(df_script,\n                                    df_characters,\n                                    left_on='character_id',\n                                    right_on='id',\n                                    suffixes=(False, False))",
          "Join script lines and characters\ndf_char_lines = pd.merge(df_script, df_characters, on='character_id', how='left')",
          " Join script lines with character id\ndf_script = df_script.merge(df_characters[['id', 'raw_character_text']], left_on='character_id', right_on='id', how='left')",
          " Merge script and character data\ndf_script_full = df_script.merge(df_characters, how='left', left_on='character_id', right_on='id')",
          " Add character names to script lines dataframe\ndf_script = df_script.merge(df_characters, left_on='character_id', right_index=True)",
          "Merge character data into script data\ndf_script_characters = df_script.merge(df_characters, how='left', left_on='character_id', right_on='id')",
          "# Merge datasets based on common keys\ndf_merged = df_script.merge(df_characters, on='character_id', how='left')",
          " Merge scripts with characters and cleaning\ndf_script = df_script.merge(df_characters[['id', 'name']], 'left', left_on='character_id', right_on='id')",
          "Add the character information to the script dataframe\ndf_script = df_script.merge(df_characters, how='left', on='character_id')",
          " Merge characters and script\ndf_charlines = df_script.merge(df_characters, on='character_id')",
          "# Merge scripts with characters\ndf_script_info = df_script.merge(df_characters, how='left', left_on='character_id', right_on='character_id', suffixes=('_script', '_character'))",
          "Merge the dataset\ndf_name_only = df_characters.loc[:, ['name', 'normalized_name']]\ndf_total = pd.merge(df_script, df_name_only, how='left', left_on='raw_character_text', right_on='name')\n\ndf_total.dropna(subset=['normalized_name'], inplace=True)",
          "Merge character data into script data\ndf = pd.merge(df_script, df_characters, how='left', left_on='character_id', right_on='id', suffixes=('_script', '_character'))",
          " Merge script with characters\ndf_script_characters = pd.merge(df_script, df_characters, how='left', left_on='character_id', right_on='id', suffixes=('_script', '_character')).reset_index(inplace=False, drop=True)",
          "Merge the three files together\ndf = df_script.merge(df_characters, left_on='character_id', right_on='id', suffixes=('_script', '_character'))",
          "Merge the character information into the script\ndf_script = df_script.merge(df_characters, how=\"inner\", on=\"character_id\")",
          "Merge the dataframes together\ndf = df_script.merge(df_characters, how='left', on='character_id')",
          " Merge characters and script\ndf_char_scripts = pd.merge(df_script, df_characters, on='character_id', suffixes=(\"\", \"_char\"), how=\"left\")",
          " Join characters with script\ndf_characters_script = df_script.merge(df_characters, left_on='character_id', right_on='id').drop(columns=['id', 'normalized_name'])\ndf_characters_script.head()",
          "Join Scripts and character names to get sentences with character names\ndf_script['raw_character_text'] = df_script['raw_character_text'].str.lower()\ndf_characters['name'] = df_characters['name'].str.lower()\ndf_main = pd.merge(df_script, df_characters,  how='left', left_on=['raw_character_text'], right_on = ['name']).drop(['name'], axis=1)",
          "Add additional character metadata\ndf_characters = df_characters.merge(df_script[['character_id', 'raw_character_text']], left_on='id', right_on='character_id', how='inner')\ndf_characters.rename(columns={'raw_character_text': 'name_original'}, inplace=True)",
          " Merge character names and script lines on character_id\ndf = df_script.merge(df_characters, on=\"character_id\", how=\"left\")",
          " Mergethe two dataframes to get the character id",
          " Join characters name to scripts\ndf_characters = df_characters.rename(columns={'id':'character_id', 'name':'character_name'})\ndf_script = df_script.merge(df_characters[['character_id', 'character_name']], how='inner', on='character_id')",
          "Merging character names and script\ndf_characters_script = df_script.merge(\n    df_characters,\n    how='left',\n    left_on='character_id',\n    right_on='id',\n    suffixes=('_script', '_character'),\n)",
          "# Merge characters and script\ndf_merged = df_script.merge(df_characters, on='id', suffixes=('_lines', '_characters'))",
          " Merge characters and script dataframes\ndf_characters_script = pd.merge(df_characters, df_script, left_on='id', right_on='character_id')\ndf_characters_script.head()",
          "Merge characters and script dataframe\ndf_characters = df_characters.rename(columns={'id': 'character_id'})\ndf_script = df_script.merge(df_characters, how='left', on='character_id')",
          "Merge characters with script\ndf_script = pd.merge(df_script, df_characters, on='character_id', how='left')",
          "Merge the characters and lines based on the character_id",
          "Merge df_characters and df_script\ndf_script = df_script.merge(df_characters[['id', 'name']], left_on='character_id', right_on='id', suffixes=(None, '_character'))",
          "# Merge script with character information\ndf_script = df_script.rename(columns={'raw_character_text': 'name'})\ndf_script_extended = df_script.merge(df_characters, on='name', how='left')\n\ndf_script_extended.head()",
          " Combine character information with script lines\ndf_combined = df_script.merge(df_characters.add_suffix('_characters'), how='left', left_on='character_id', right_on='id_characters')",
          "Merge character details and script lines\ndf_characters_script = pd.merge(df_characters, df_script, left_on='id', right_on='character_id')",
          "Merge the script and the characters DataFrame along the 'character_id'\ndf_script = pd.merge(df_script, df_characters, on='character_id')",
          "Merge table to keep only scripts with a known character ID\ndf = pd.merge(df_script, df_characters, how='inner', on='id', suffixes=('', '_y'))\ndf = df[pd.notnull(df['normalized_text'])]"
         ],
         "marker": {
          "opacity": 0.5,
          "size": 5
         },
         "mode": "markers+text",
         "name": "17_Document merging with script and character data",
         "text": [
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          ""
         ],
         "textfont": {
          "size": 12
         },
         "type": "scattergl",
         "x": [
          5.0160722732543945,
          4.571682453155518,
          4.740828990936279,
          4.380854606628418,
          4.618835926055908,
          4.677803993225098,
          5.085918426513672,
          5.738497734069824,
          4.927474498748779,
          4.871455669403076,
          4.869809627532959,
          4.974160671234131,
          4.635277271270752,
          4.99971342086792,
          4.930983543395996,
          5.02211332321167,
          4.643746852874756,
          4.363819599151611,
          5.349496841430664,
          4.644163131713867,
          4.524477005004883,
          4.1937479972839355,
          4.9332990646362305,
          4.297077178955078,
          4.705737113952637,
          4.605853080749512,
          4.646601676940918,
          4.632903575897217,
          4.503067970275879,
          5.153716087341309,
          4.470584869384766,
          4.754960536956787,
          4.8998284339904785,
          5.197144985198975,
          4.961973667144775,
          4.785079479217529,
          4.881925106048584,
          5.152194499969482,
          4.213441371917725,
          4.790242671966553,
          5.496043682098389,
          4.91865873336792,
          5.029304504394531,
          4.2131876945495605,
          4.754372596740723,
          5.297142028808594,
          4.836373329162598,
          4.565769672393799,
          4.551565647125244,
          4.449613571166992,
          4.445703506469727,
          4.235386371612549,
          5.212411403656006,
          5.051779270172119,
          4.7238898277282715,
          4.645493507385254,
          5.090025901794434,
          5.391821384429932
         ],
         "y": [
          9.700489044189453,
          9.868489265441895,
          9.910480499267578,
          10.163307189941406,
          10.221312522888184,
          10.003396987915039,
          10.631353378295898,
          9.257119178771973,
          9.597434997558594,
          9.96155834197998,
          9.554876327514648,
          9.630375862121582,
          10.6198091506958,
          10.036131858825684,
          8.90258502960205,
          10.27142333984375,
          10.28069019317627,
          10.619245529174805,
          9.290343284606934,
          9.541634559631348,
          10.459532737731934,
          10.547234535217285,
          10.416359901428223,
          9.80842113494873,
          10.132415771484375,
          10.468676567077637,
          9.978119850158691,
          10.284143447875977,
          10.518026351928711,
          10.193868637084961,
          10.341249465942383,
          9.670612335205078,
          10.489267349243164,
          9.07364559173584,
          10.486772537231445,
          10.902091979980469,
          10.563319206237793,
          9.922069549560547,
          10.020337104797363,
          10.927482604980469,
          9.639713287353516,
          10.078330039978027,
          9.496583938598633,
          9.82638168334961,
          9.70009994506836,
          9.944268226623535,
          10.520390510559082,
          10.068587303161621,
          10.33155632019043,
          9.925126075744629,
          10.5735445022583,
          9.241469383239746,
          10.066027641296387,
          10.013934135437012,
          10.266890525817871,
          9.850686073303223,
          10.028953552246094,
          9.248940467834473
         ]
        },
        {
         "hoverinfo": "text",
         "hovertext": [
          "#Select the required columns\ndf_script = df_script[['episode_id', 'number', 'raw_text', 'speaking_line', 'character_id']]\n\n# Informationen zu der Tabelle\nprint(df_script.info())",
          "\ndf_script = df_script[['id', 'episode_id', 'number', 'raw_text', 'timestamp_in_ms', 'speaking_line', 'character_id', 'location_id', 'raw_character_text', 'raw_location_text', 'spoken_words', 'normalized_text']].copy()",
          "convert ids to integers\ndf_script['episode_id'] = df_script['episode_id'].astype(int)\ndf_script['character_id'] = df_script['character_id'].astype(int)",
          "We will only use the following columns from df_script DataFrame:\ndf_script = df_script[['episode_id', 'raw_text', 'character_id', 'location_id']]\n",
          "# Create a new temporary dataframe with the necessary data and set correct data types\ndf_script_temp = df_script[['episode_id', 'number', 'raw_text', 'character_id']].copy()\ndf_script_temp['episode_id'] = df_script_temp['episode_id'].astype(int)\ndf_script_temp['character_id'] = df_script_temp['character_id'].astype(float)",
          "Select relevant columns and transforming id columns to ints\ndf_script = df_script[['episode_id','number','raw_text','character_id','location_id']]\ndf_script.character_id = df_script.character_id.astype('Int64')\ndf_script.location_id = df_script.location_id.astype('Int64')",
          "Set up data for analysis\n# Extract episode number and script from the main dataframe\nepisodes_script = df_script[['episode_id', 'raw_text']]",
          " Remove useless data\ndf_script = df_script[['episode_id', 'raw_text']]",
          " For the purposes of this analysis, the following columns are extracted:\n\nExtracting only necessary columns from the `script_lines` dataset:\n\n- `episode_id`\n- `number`\n- `raw_text`\n- `timestamp_in_ms`\n- `speaking_line`\n- `character_id`\n\nExtracting only necessary columns from the `characters` dataset:\n\n- `name`\n- `id`\n\nExtracting only necessary columns from the `locations` dataset:\n\n- `name`\n- `id`",
          "Extract episode_id and raw_text from df_script\ndf_script = df_script[['episode_id', 'raw_text']]",
          " Extract columns of interest\ndf_script = df_script[['episode_id', 'character_id', 'location_id', 'normalized_text']]",
          "Select only important columns\ndf_script = df_script[['episode_id', 'number', 'raw_text', 'character_id', 'location_id']].copy()",
          "also drop and reorder the columns in the script dataframe\ndf_script = df_script.drop(['id', 'episode_id', 'number', 'raw_text', 'timestamp_in_ms'], axis=1)\ndf_script = df_script[['episode_id', 'character_id', 'location_id', 'spoken_words']]",
          " Data quality\n# df_script contains the raw text\n\n# Ensure we have all the needed data\nrequired_cols = ['episode_id', 'character_id', 'location_id', 'raw_text', 'timestamp_in_ms']\nfor col in required_cols:\n    assert col in df_script.columns, f\"Column '{col}' not found in df_script\"\n\nprint(\"All required columns found in df_script\")",
          "Create a subset of df_script that includes only the fields needed\ndf_script_subset = df_script[['id', 'episode_id', 'character_id', 'location_id', 'raw_text']].copy()",
          "Remove unused columns\ndf_script = df_script[['episode_id', 'number', 'raw_text', 'speaker_line', 'timestamp_in_ms', 'location_id', 'raw_character_text', 'raw_location_text', 'spoken_words']]\ndf_episodes = df_episodes[['id', 'title', 'original_air_date']]\ndf_locations = df_locations[['id', 'name']]",
          " Remove unnecessary columns\ndf_characters = df_characters[['id', 'name', 'normalized_name']]\ndf_locations = df_locations[['id', 'name', 'normalized_name']]\ndf_episodes = df_episodes[['id', 'title']]\ndf_script = df_script[['episode_id', 'number', 'raw_text']]",
          "Simplify dataframe\ndf_script_simple = df_script[['episode_id', 'number', 'raw_text', 'timestamp_in_ms']]",
          "Notes for dataframes:\n# df_characters: \n# df_locations: \n# df_script: id|episode_id|number|raw_text|timestamp_in_ms|speaking_line|character_id|location_id\n# df_episodes: id|title|original_air_date|production_code|season|number_in_season|number_in_series|us_viewers_in_millions|views|imdb_rating|imdb_votes|image_url|video_url\n",
          "Subsetting the dataframe for columns of interest\ndf_script = df_script[['episode_id', 'number', 'raw_text', 'character_id']]\n\n# Initial Data Exploration\nprint('\\n','#'*120,'\\n','DATAFRAME HEAD','\\n','#'*120,'\\n',df_script.head(5),'\\n','#'*120)",
          "Extract relevant columns\ndf_script = df_script[['episode_id', 'number', 'raw_text', 'normalized_text', 'raw_character_text',\n                       'spoken_words', 'normalized_text', 'word_count']]\n\n# Removing leading/trailing spaces from al fanmes\ndf_characters['character'] = df_characters['character'].str.strip()\ndf_locations['raw_location_text'] = df_locations['raw_location_text'].str.strip()\ndf_script['raw_character_text'] = df_script['raw_character_text'].str.strip()",
          "# Coverting episode_number to int as it has some '.0' values\ndf_episodes.at[:, 'number'] = df_episodes['number'].fillna(0).astype(int)",
          "# Helper function to show lines based on a condition\ndef where(df, condition):\n    return df[condition]\n\n# Helper function to retrieve text from the script\ndef get_script_text(df, episode_number):\n    return df[df['episode_id'] == episode_number]['raw_text'].values",
          "Extract main columns\ndf_episodes = df_episodes[['id', 'title', 'original_air_date', 'production_code', 'season', 'number_in_season', 'number_in_series', 'us_viewers_in_millions', 'views', 'imdb_rating','imdb_votes']]\ndf_script = df_script[['id', 'episode_id', 'number', 'raw_text', 'timestamp_in_ms']]\ndf_characters = df_characters[['id', 'first_name', 'last_name']]\ndf_locations = df_locations[['id', 'name']]",
          "Select some columns and sample some data\n# This way, we can better understand the data we are working with\ndf_script.sample(10)[['normalized_text', 'spoken_words', 'raw_text', 'episode_id', 'character_id']]",
          "Declare which columns to be used for each dataframe.\nchar_fields = [\n    'id',\n    'name'\n]\n\nloc_fields = [\n    'id',\n    'name'\n]\n\nep_fields = [\n    'id',\n    'title'\n]\n\nscript_fields = [\n    'episode_id',\n    'number',\n    'raw_text',\n    'character_id',\n    'location_id'\n]",
          "Set all IDs to integers\ndf_script['episode_id'] = df_script['episode_id'].astype(int)\ndf_script['timestamp_in_ms'] = df_script['timestamp_in_ms'].astype(int)\ndf_script['character_id'] = df_script['character_id'].fillna(-1).astype(int)\ndf_script['location_id'] = df_script['location_id'].fillna(-1).astype(int)",
          "reduce memory usage\ndf_script['id'] = pd.to_numeric(df_script['id'], downcast='integer')\ndf_script['episode_id'] = pd.to_numeric(df_script['episode_id'], downcast='integer')\ndf_script['number'] = pd.to_numeric(df_script['number'], downcast='integer')\ndf_script['raw_text'] = df_script['raw_text'].astype('string')\ndf_script['timestamp_in_ms'] = pd.to_numeric(df_script['timestamp_in_ms'], downcast='integer')\ndf_script['speaking_line'] = df_script['speaking_line'].astype('boolean')\ndf_script['character_id'] = pd.to_numeric(df_script['character_id'], downcast='integer')\ndf_script['location_id'] = pd.to_numeric(df_script['location_id'], downcast='integer')\ndf_script['raw_text'] = df_script['raw_text'].astype('string')\n\ndf_episodes['id'] = pd.to_numeric(df_episodes['id'], downcast='integer')\ndf_episodes['viewers'] = pd.to_numeric(df_episodes['viewers'], downcast='integer')\n\ndf_characters['id'] = pd.to_numeric(df_characters['id'], downcast='integer')\ndf_characters['name'] = df_characters['name'].astype('string')\ndf_characters['normalized_name'] = df_characters['normalized_name'].astype('string')\ndf_characters['gender'] = df_characters['gender'].astype('string')\ndf_characters['description'] = df_characters['description'].astype('string')\ndf_characters['color'] = df_characters['color'].astype('string')\n\ndf_locations['id'] = pd.to_numeric(df_locations['id'], downcast='integer')\ndf_locations['name'] = df_locations['name'].astype('string')\ndf_locations['normalized_name'] = df_locations['normalized_name'].astype('string')\ndf_locations['image_url'] = df_locations['image_url'].astype('string')",
          " Remove the first 3 columns from df_script since they don't provide any value\ndf_script = df_script[['episode_id', 'id', 'character_id', 'location_id', 'raw_text']]",
          "Extract numeric id from episode url\ndf_episodes['id'] = df_episodes['id'].str.extract('\\/([0-9]+)')",
          " Select columns\ndf_script = df_script[['episode_id', 'number', 'raw_text', 'character_id', 'location_id']]",
          "REMOVING UNNECESSARY COLUMNS\ndf_script = df_script[['episode_id', 'id', 'character_id', 'location_id', 'raw_text']]",
          "Filter scripts to avoid using too much memory on temporary data\ndf_script_filtered = df_script[['episode_id', 'character_id', 'location_id', 'spoken_words']].copy()",
          "Remove non-text columns\ndf_script = df_script[['episode_id', 'number', 'raw_text']]",
          "Clean the script dataframe\ndf_script_cleaned = df_script[['episode_id', 'timestamp_in_ms', 'speaking_line', 'character_id', 'location_id', 'raw_text']].copy()\ndf_script_cleaned['episode_id'] = df_script_cleaned['episode_id'].astype(int)\ndf_script_cleaned['timestamp_in_ms'] = df_script_cleaned['timestamp_in_ms'].astype(int)\ndf_script_cleaned['character_id'] = df_script_cleaned['character_id'].astype(int)\ndf_script_cleaned['location_id'] = df_script_cleaned['location_id'].astype(int)\ndf_script_cleaned.head()",
          " Create a sub-dataframe using only the lines\ndf_lines = df_script[['episode_id', 'number', 'raw_text']]",
          "Create new columns\ndf_script['episode_id'] = pd.to_numeric(df_script['episode_id'], errors='coerce')\ndf_script['character_id'] = pd.to_numeric(df_script['character_id'], errors='coerce')\ndf_script['location_id'] = pd.to_numeric(df_script['raw_location_text'], errors='coerce')",
          "\n# Light cleaning of the lines dataframe to keep only relevant columns\ndf_script = df_script[['episode_id', 'number', 'raw_text', 'character_id', 'location_id']]",
          "Remove unused columns\ndf_script = df_script[['episode_id', 'id', 'character_id', 'location_id', 'raw_text']]",
          "Select relevant columns for each dataframe\ndf_characters = df_characters[['id', 'name', 'normalized_name', 'gender', 'normalized_gender']]\ndf_locations = df_locations[['id', 'name', 'normalized_name']]\ndf_script = df_script[['episode_id', 'number', 'raw_text', 'timestamp_in_ms', 'speaking_line', 'character_id', 'location_id']].copy()\ndf_episodes = df_episodes[['id', 'title', 'original_air_date', 'production_code', 'season', 'number_in_season', 'number_in_series']].copy()",
          " Our df_script dataframe contains different kind of information id, episode_id, number, raw_text, speaking_line, character_id, location_id, and timestamp.",
          "select features to keep\ndf_script = df_script[[\n    'episode_id',\n    'number',\n    'raw_text',\n    'raw_character_text',\n    'spoken_words',\n    'raw_location_text',\n    'normalized_text',\n    'word_count'\n]]",
          "subset_columns\u0012=['normalized_text', 'episode_id', 'character_id', 'location_id']",
          " Keep the useful columns\ndf_script = df_script[['id', 'episode_id', 'number', 'raw_text', 'timestamp_in_ms', 'speaking_line', 'character_id', 'location_id', 'raw_character_text', 'raw_location_text']]",
          "# Getting just the fields we are interested in\ndf_script = df_script[['episode_id', 'character_id', 'location_id', 'raw_text']]",
          "Combine script, character, and location data\ndf_episodes_sub = df_episodes[['id', 'imdb_rating', 'title', 'original_air_date', 'production_code', 'season', 'number_in_season']]\ndf_script_sub = df_script[['episode_id', 'character_id', 'location_id', 'norm_text']]",
          "Selecting main columns for characters and script DataFrames\ndf_characters = df_characters[['id', 'name']]\ndf_script = df_script[['id', 'episode_id', 'number', 'raw_text', 'normalized_text', 'character_id', 'location_id']]",
          "Remove irrelevant columns from script dataframe\ndf_script = df_script[['episode_id', 'number', 'raw_text', 'timestamp_in_ms']]",
          "select only necessary columns\ndf_script = df_script[['episode_id', 'id', 'character_id', 'location_id', 'raw_text']]",
          "Display scripts\nscript_cols = ['episode_id', 'number', 'raw_text']\ndf_script[script_cols].head()",
          "Create a row identifier by combining 'episode_id' and 'timestamp_in_ms'\ndf_script[\"row_id\"] = df_script[\"episode_id\"].astype(str) + \"_\" + df_script[\"timestamp_in_ms\"].astype(str)",
          "Filter unnecessary columns\ndf_script = df_script[['id', 'episode_id', 'number', 'raw_text', 'timestamp_in_ms', 'speaking_line', 'character_id', 'location_id']]",
          " Set correct types for character_id, location_id and episode_id\ndf_script = df_script.astype({'character_id': 'Int64', 'location_id': 'Int64', 'episode_id': 'Int64'})",
          "Extract useful columns\ndf_characters = df_characters[['id', 'name']]\ndf_locations = df_locations[['id', 'name']]\ndf_episodes = df_episodes[['id', 'title']]",
          "Set 'raw_text' to script's rightmost side\ndf_script = df_script[['episode_id', 'raw_text']]",
          "Remove unused columns for the script and characters dataframe\ndf_script = df_script[['episode_id', 'number', 'raw_text', 'spoken_words', 'character_id', 'location_id', 'timestamp_in_ms']]\ndf_characters = df_characters[['id', 'name', 'normalized_name']]\ndf_locations = df_locations[['id', 'name']]",
          " Select features of interest from the script dataset\ndf_script = df_script[['episode_id', 'number', 'raw_text', 'character_id', 'location_id']]\n\n# Convert episode number from float to int\ndf_script['number'] = df_script['number'].fillna(0).astype(int)",
          "Keep relevant columns only\ndf_script = df_script[['episode_id', 'number', 'raw_text', 'character_id', 'location_id']]"
         ],
         "marker": {
          "opacity": 0.5,
          "size": 5
         },
         "mode": "markers+text",
         "name": "18_Removing Unused Columns for Dataframes",
         "text": [
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          ""
         ],
         "textfont": {
          "size": 12
         },
         "type": "scattergl",
         "x": [
          4.996364593505859,
          4.798448085784912,
          3.968302011489868,
          4.61715030670166,
          3.7461414337158203,
          3.9532041549682617,
          5.069729328155518,
          4.486158847808838,
          5.783316135406494,
          4.864045143127441,
          5.025721549987793,
          3.9573237895965576,
          5.1150922775268555,
          4.55361270904541,
          4.0592803955078125,
          3.9972641468048096,
          3.692432165145874,
          4.5474090576171875,
          3.2062747478485107,
          4.755627632141113,
          4.857487201690674,
          4.180995464324951,
          5.053213119506836,
          3.615070343017578,
          5.640368461608887,
          4.3559088706970215,
          3.602038860321045,
          4.4546380043029785,
          4.525766849517822,
          4.572404384613037,
          4.58490514755249,
          4.412968158721924,
          4.695021629333496,
          4.910096168518066,
          3.7771999835968018,
          5.246004581451416,
          4.5667643547058105,
          4.690651893615723,
          4.488755226135254,
          3.8911497592926025,
          4.67437219619751,
          4.916666030883789,
          4.60520601272583,
          4.995370388031006,
          4.593504905700684,
          3.4566595554351807,
          4.6053361892700195,
          5.220355033874512,
          4.573578357696533,
          5.354570388793945,
          3.8859546184539795,
          5.122678756713867,
          3.805589199066162,
          3.8188157081604004,
          5.016273021697998,
          4.691943645477295,
          4.153029441833496,
          4.054573059082031
         ],
         "y": [
          6.491592884063721,
          6.72593879699707,
          6.488641262054443,
          5.945616722106934,
          6.126836776733398,
          7.0072126388549805,
          5.683966636657715,
          5.857635498046875,
          5.785533428192139,
          6.28078556060791,
          6.378283977508545,
          5.895598888397217,
          5.512928009033203,
          6.13314962387085,
          5.658375263214111,
          5.822316646575928,
          6.3093390464782715,
          5.406272888183594,
          5.283361434936523,
          6.4547929763793945,
          6.755329608917236,
          5.291975975036621,
          6.193652629852295,
          6.5411176681518555,
          6.810920238494873,
          6.013788223266602,
          6.106594562530518,
          5.678173542022705,
          5.893706798553467,
          5.704128265380859,
          6.243851184844971,
          6.428467273712158,
          5.908102035522461,
          5.6601128578186035,
          7.031060218811035,
          5.873944282531738,
          6.452305793762207,
          6.27807092666626,
          6.13712215423584,
          6.482021808624268,
          6.15435791015625,
          6.576827526092529,
          5.792205333709717,
          6.53790283203125,
          6.231086254119873,
          6.129164695739746,
          6.325809001922607,
          5.2286272048950195,
          6.081512928009033,
          6.616871356964111,
          5.55617618560791,
          6.097197532653809,
          6.390008449554443,
          6.36259651184082,
          6.348211288452148,
          6.143248081207275,
          6.235002040863037,
          6.334251880645752
         ]
        },
        {
         "hoverinfo": "text",
         "hovertext": [
          "Check the number of records in each dataframes.\nprint('Number of records in characters dataframe:', len(df_characters))\nprint('Number of records in locations dataframe:', len(df_locations))\nprint('Number of records in script dataframe:', len(df_script))\nprint('Number of records in episodes dataframe:', len(df_episodes))",
          "Define dimensionality of each dataset\nn_characters = len(df_characters)\nn_locations = len(df_locations)\nn_episodes = len(df_episodes)\nn_scripts = len(df_script)\n\nprint(f'DataFrame \"Characters\" contains {n_characters} rows')\nprint(f'DataFrame \"Locations\" contains {n_locations} rows')\nprint(f'DataFrame \"Episodes\" contains {n_episodes} rows')\nprint(f'DataFrame \"Script\" contains {n_scripts} rows')",
          "# Clean line\ndf_script = df_script[df_script[\"normalized_text\"] != \"\"].dropna()\n\n# Display some statistics\nprint(\"Number of episodes:\", df_episodes.shape[0])\nprint(\"Number of characters:\", df_characters.shape[0])\nprint(\"Number of locations:\", df_locations.shape[0])\nprint(\"Number of lines:\", df_script.shape[0])",
          "Display the number of records for each dataframe\nprint('Number of records in characters: {}'.format(len(df_characters)))\nprint('Number of records in locations: {}'.format(len(df_locations)))\nprint('Number of records in episodes: {}'.format(len(df_episodes)))\nprint('Number of records in script: {}'.format(len(df_script)))",
          "Printing dataframes and number of rows in each dataframe\nprint(f\"# of characters: {len(df_characters)}\")\nprint(f\"# of locations: {len(df_locations)}\")\nprint(f\"# of script_lines: {len(df_script)}\")\nprint(f\"# of episodes: {len(df_episodes)}\")",
          "Print the number of rows in each dataframe\nprint(f\"Number of rows in characters dataframe: {len(df_characters)}\")\nprint(f\"Number of rows in locations dataframe: {len(df_locations)}\")\nprint(f\"Number of rows in script dataframe: {len(df_script)}\")\nprint(f\"Number of rows in episodes dataframe: {len(df_episodes)}\")",
          "Check the number of entries in each dataset\nprint(f'Number of script lines: {len(df_script)}')\nprint(f'Number of characters: {len(df_characters)}')\nprint(f'Number of locations: {len(df_locations)}')\nprint(f'Number of episodes: {len(df_episodes)}')",
          "Print some basic information about the datasets\nprint(f'Characters: {len(df_characters)}')\nprint(f'Locations: {len(df_locations)}')\nprint(f'Script lines: {len(df_script)}')\nprint(f'Episodes: {len(df_episodes)}')",
          "Print the number of characters, locations, script lines and episodes\nprint('Number of characters:', len(df_characters))\nprint('Number of locations:', len(df_locations))\nprint('Number of script lines:', len(df_script))\nprint('Number of episodes:', len(df_episodes))",
          "Displaying the number of characters, locations, script lines, and episodes in the datasets\nprint('Number of characters:', len(df_characters))\nprint('Number of locations:', len(df_locations))\nprint('Number of script lines:', len(df_script))\nprint('Number of episodes:', len(df_episodes))",
          " Length of dataframes\nlen(df_characters), len(df_locations), len(df_script), len(df_episodes)",
          "Display number of rows in each dataset\nprint(\"Number of rows in characters dataset:\", len(df_characters))\nprint(\"Number of rows in locations dataset:\", len(df_locations))\nprint(\"Number of rows in script dataset:\", len(df_script))\nprint(\"Number of rows in episodes dataset:\", len(df_episodes))",
          "Check the number of records\nprint(\"Number of records in characters dataset:\", len(df_characters))\nprint(\"Number of records in locations dataset:\", len(df_locations))\nprint(\"Number of records in script dataset:\", len(df_script))\nprint(\"Number of records in episodes dataset:\", len(df_episodes))",
          "Display the number of records of each dataset\nprint('Number of records in characters dataset:', len(df_characters))\nprint('Number of records in locations dataset:', len(df_locations))\nprint('Number of records in script dataset:', len(df_script))\nprint('Number of records in episodes dataset:', len(df_episodes))",
          "Check data sample sizes\nprint(f'Characters: {len(df_characters)}')\nprint(f'Locations: {len(df_locations)}')\nprint(f'Script lines: {len(df_script)}')\nprint(f'Episodes: {len(df_episodes)}')",
          "n. of characters and n. of locations\nn_characters = len(df_characters)\nn_locations = len(df_locations)",
          "print('Loaded {:,} characters, {:,} locations, {:,} episodes, and {:,} script lines'.format(\n    len(df_characters), len(df_locations), len(df_episodes), len(df_script)\n))",
          "Display the number of characters, locations, script lines, and episodes\nlen(df_characters), len(df_locations), len(df_script), len(df_episodes)",
          " Display number of data points for each table\nprint(f\"Number of points in characters table: {len(df_characters)}\")\nprint(f\"Number of points in locations table: {len(df_locations)}\")\nprint(f\"Number of points in script table: {len(df_script)}\")\nprint(f\"Number of points in episodes table: {len(df_episodes)}\")",
          "Check the content of each table\nprint(f\"Characters table: {len(df_characters)} lines\")\nprint(f\"Locations table: {len(df_locations)} lines\")\nprint(f\"Script table: {len(df_script)} lines\")\nprint(f\"Episodes table: {len(df_episodes)} lines\")",
          "Display the number of rows in each of the datasets\nprint(\"Number of rows in characters dataset: \", len(df_characters))\nprint(\"Number of rows in locations dataset: \", len(df_locations))\nprint(\"Number of rows in script lines dataset: \", len(df_script))",
          "Print the number of elements in the dataset\nprint(f\"Number of characters: {len(df_characters)}\")\nprint(f\"Number of locations: {len(df_locations)}\")\nprint(f\"Number of script lines: {len(df_script)}\")\nprint(f\"Number of episodes: {len(df_episodes)}\")",
          "Check the number of rows before merging\nprint(len(df_characters))\nprint(len(df_locations))\nprint(len(df_script))\nprint(len(df_episodes))",
          " Check data\nprint(\"Number of characters: \", len(df_characters))\nprint(\"Number of locations: \", len(df_locations))\nprint(\"Number of episodes: \", len(df_episodes))\nprint(\"Number of script lines: \", len(df_script))",
          "Check the dataframe sizes\nprint('Characters:', len(df_characters))\nprint('Locations:', len(df_locations))\nprint('Script lines:', len(df_script))\nprint('Episodes:', len(df_episodes))",
          "Check the length of each DataFrame\nprint(f\"Number of characters: {len(df_characters)}\")\nprint(f\"Number of locations: {len(df_locations)}\")\nprint(f\"Number of script lines: {len(df_script)}\")\nprint(f\"Number of episodes: {len(df_episodes)}\")",
          "asic data exploration\nprint(f\"Number of characters: {len(df_characters)}\")\nprint(f\"Number of locations: {len(df_locations)}\")\nprint(f\"Number of script lines: {len(df_script)}\")\nprint(f\"Number of episodes: {len(df_episodes)}\")",
          "Show the number of data points in each dataset\nprint(len(df_characters), len(df_locations), len(df_script), len(df_episodes))",
          " Check the number of records mined in each dataset\nprint('Number of characters:', len(df_characters))\nprint('Number of locations:', len(df_locations))\nprint('Number of script lines:', len(df_script))\nprint('Number of episodes:', len(df_episodes))",
          "Display number of rows for each dataframe\nprint('Number of rows:')\nprint(f'Characters : {len(df_characters)}')\nprint(f'Locations : {len(df_locations)}')\nprint(f'Script : {len(df_script)}')\nprint(f'Episodes : {len(df_episodes)}')",
          "print('Characters:', len(df_characters))\nprint('Locations:', len(df_locations))\nprint('Script Lines:', len(df_script))\nprint('Episodes:', len(df_episodes))",
          "Check the number of lines of each csv file\nprint(\"Number of characters: \", len(df_characters))\nprint(\"Number of locations: \", len(df_locations))\nprint(\"Number of lines scripts: \", len(df_script))\nprint(\"Number of episodes: \", len(df_episodes))",
          "Visualize data\nprint(f'Number of episodes: {len(df_episodes)}')\nprint(f'Number of characters: {len(df_characters)}')\nprint(f'Number of locations: {len(df_locations)}')",
          "Get some info on the data sets\nprint(f'{len(df_script)} lines of script')\nprint(f'{len(df_episodes)} episodes')\nprint(f'{len(df_characters)} characters')\nprint(f'{len(df_locations)} locations')",
          " Explore the structure of the data\nprint(f\"Characters: {len(df_characters)}\")\nprint(f\"Locations: {len(df_locations)}\")\nprint(f\"Script lines: {len(df_script)}\")\nprint(f\"Episodes: {len(df_episodes)}\")",
          "Explore the dataset\nprint(f'Number of data points for characters: {len(df_characters)}')\nprint(f'Number of data points for locations: {len(df_locations)}')\nprint(f'Number of data points for script lines: {len(df_script)}')\nprint(f'Number of data points for episodes: {len(df_episodes)}')",
          " Print the basic data\nprint(\"# characters=\", len(df_characters))\nprint(\"# locations=\", len(df_locations))\nprint(\"# episodes=\", len(df_episodes))\nprint(\"# lines=\", len(df_script))",
          "# Debug information\nprint(f'Total characters in dataset {len(df_characters)}')\nprint(f'Total unique characters in dataset {df_characters.character.nunique()}')\nprint(f'Total locations in dataset {len(df_locations)}')\nprint(f'Total unique locations in dataset {df_locations.location.nunique()}')\nprint(f'Total script lines in dataset {len(df_script)}')\nprint(f'Total unique episodes in dataset {df_script.episode_id.nunique()}')\nprint(f'Total episodes in dataset {len(df_episodes)}')",
          " Checking the data\nprint(f'Characters: {len(df_characters)}')\nprint(f'Locations: {len(df_locations)}')\nprint(f'Script lines: {len(df_script)}')\nprint(f'Episodes: {len(df_episodes)}')",
          "# Output some metadata about the datasets\nprint('Characters count:', len(df_characters))\nprint('Locations count:', len(df_locations))\nprint('Episode count:', len(df_episodes))\nprint('Script lines count:', len(df_script))",
          "Print general info about datasets\nprint(f'Simpsons Characters: {len(df_characters)}')\nprint(f'Simpsons Locations: {len(df_locations)}')\nprint(f'Simpsons Script: {len(df_script)}')\nprint(f'Simpsons Episodes: {len(df_episodes)}')",
          "Show the number of script lines and episodes in the dataset\nprint(f\"Number of script lines: {df_script.shape[0]:,}\")\nprint(f\"Number of episodes: {df_episodes.shape[0]:,}\")",
          "Print the number of rows in each table\nprint(f\"The characters table has {len(df_characters)} rows.\")\nprint(f\"The locations table has {len(df_locations)} rows.\")\nprint(f\"The script table has {len(df_script)} rows.\")\nprint(f\"The episodes table has {len(df_episodes)} rows.\")",
          " Print the number of observations in each data frame\nprint(f\"Number of characters: {len(df_characters)}\")\nprint(f\"Number of locations: {len(df_locations)}\")\nprint(f\"Number of script lines: {len(df_script)}\")\nprint(f\"Number of episodes: {len(df_episodes)}\")",
          "Print number of characters, locations, script lines and episodes\nprint(len(df_characters), len(df_locations), len(df_script), len(df_episodes))",
          "Print out the sizes of the datasets to quickly ensure all datasets have been loaded correctly\nprint(f\"Characters Dataset: {len(df_characters)}\")\nprint(f\"Locations Dataset: {len(df_locations)}\")\nprint(f\"Script Dataset: {len(df_script)}\")\nprint(f\"Episodes Dataset: {len(df_episodes)}\")",
          "Check if the data loaded correctly\nprint(f'Characters: {len(df_characters)}')\nprint(f'Locations: {len(df_locations)}')\nprint(f'Script lines: {len(df_script)}')\nprint(f'Episodes: {len(df_episodes)}')",
          "Optional run to display the number of components in each dataframe\n# Display the number of components in each dataframe\nprint(\n    f'Number of components in the Simpsons character dataframe: {df_characters.size}\\n'\n    f'Number of components in the Simpsons location dataframe: {df_locations.size}\\n'\n    f'Number of components in the Simpsons script dataframe: {df_script.size}\\n'\n    f'Number of components in the Simpsons episode dataframe: {df_episodes.size}'\n)",
          "show some statistics for easy reference\nprint(f'Characters dataframe has {len(df_characters)} rows and '\n      f'{len(df_characters.columns)} columns.')\nprint(f'Locations dataframe has {len(df_locations)} rows and '\n      f'{len(df_locations.columns)} columns.')\nprint(f'Script dataframe has {len(df_script)} rows and '\n      f'{len(df_script.columns)} columns.')\nprint(f'Episodes dataframe has {len(df_episodes)} rows and '\n      f'{len(df_episodes.columns)} columns.')",
          " Show number of rows\nprint(f\"Number of characters: {len(df_characters)}\")\nprint(f\"Number of locations: {len(df_locations)}\")\nprint(f\"Number of script lines: {len(df_script)}\")\nprint(f\"Number of episodes: {len(df_episodes)}\")",
          "Show some statistics about the datasets\nprint(\"Number of characters:\", len(df_characters))\nprint(\"Number of locations:\", len(df_locations))\nprint(\"Number of script lines:\", len(df_script))\nprint(\"Number of episodes:\", len(df_episodes))",
          "Prune all bad data at the start\nprint(len(df_characters))\nprint(len(df_locations))\nprint(len(df_script))\nprint(len(df_episodes))",
          "collapse multi-line pandas DataFrames to a single line\nprint(f\"{len(df_characters)} characters, {len(df_locations)} locations, {len(df_script)} script lines, {len(df_episodes)} episodes\")",
          " Check file integrity\nlen(df_episodes)",
          "Show overview of the datasets\nprint(f'There are {len(df_characters)} characters, {len(df_locations)} locations, {len(df_script)} script lines and {len(df_episodes)} episodes.')",
          "Sanity check\nprint('Characters:', len(df_characters))\nprint('Locations:', len(df_locations))\nprint('Script:', len(df_script))\nprint('Episodes:', len(df_episodes))",
          "Len of each df\nlen(df_characters), len(df_locations), len(df_script), len(df_episodes)"
         ],
         "marker": {
          "opacity": 0.5,
          "size": 5
         },
         "mode": "markers+text",
         "name": "19_Count of Data Points and Components in Simpsons Dataset",
         "text": [
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          ""
         ],
         "textfont": {
          "size": 12
         },
         "type": "scattergl",
         "x": [
          1.2915425300598145,
          1.4263113737106323,
          0.5971155762672424,
          1.9016057252883911,
          2.1054065227508545,
          2.1449508666992188,
          1.5470598936080933,
          1.3887479305267334,
          1.629543423652649,
          2.020397424697876,
          2.3194544315338135,
          2.056279420852661,
          1.3461813926696777,
          1.9340955018997192,
          1.2066813707351685,
          1.6994863748550415,
          2.0357720851898193,
          1.65854811668396,
          1.7006295919418335,
          0.9183260798454285,
          2.5342812538146973,
          2.203254461288452,
          1.3303390741348267,
          1.4017471075057983,
          1.6245423555374146,
          1.690602421760559,
          2.120368003845215,
          2.3158109188079834,
          1.5205066204071045,
          2.242382049560547,
          1.9518892765045166,
          1.1518915891647339,
          1.6229774951934814,
          1.6144156455993652,
          1.61512291431427,
          2.0473952293395996,
          1.2083849906921387,
          1.7168513536453247,
          1.6001216173171997,
          1.9272713661193848,
          1.196394681930542,
          7.100746154785156,
          1.5889164209365845,
          2.0136590003967285,
          1.768629789352417,
          1.6264793872833252,
          1.4772003889083862,
          1.875760555267334,
          1.6371206045150757,
          2.364346504211426,
          1.7365076541900635,
          1.2129278182983398,
          1.9070353507995605,
          2.0958919525146484,
          2.1036317348480225,
          1.4208779335021973,
          2.019122838973999
         ],
         "y": [
          0.1448887437582016,
          0.49102696776390076,
          0.21020834147930145,
          0.20230089128017426,
          0.38654080033302307,
          0.09558753669261932,
          0.9809348583221436,
          1.356715202331543,
          0.6847859025001526,
          0.8940502405166626,
          1.4124809503555298,
          0.20512312650680542,
          0.5599039793014526,
          0.8102772831916809,
          1.2189899682998657,
          0.19591116905212402,
          0.8140259981155396,
          0.8239088654518127,
          0.33162516355514526,
          1.226394772529602,
          0.3336283564567566,
          0.8828747868537903,
          2.3850479125976562,
          1.0972018241882324,
          0.9500385522842407,
          0.6801576614379883,
          0.581610381603241,
          0.4704367220401764,
          1.0728251934051514,
          0.02126627415418625,
          1.1032708883285522,
          0.7803828716278076,
          0.11587388813495636,
          1.2178698778152466,
          0.8656951785087585,
          0.9761630892753601,
          1.0438086986541748,
          1.1787549257278442,
          0.8678173422813416,
          0.9972022175788879,
          1.2100175619125366,
          7.246188640594482,
          0.6163577437400818,
          0.4414823651313782,
          1.2112618684768677,
          1.3796993494033813,
          0.7804074287414551,
          0.12618803977966309,
          0.16124367713928223,
          0.217579647898674,
          0.8779920935630798,
          2.3588967323303223,
          0.6385468244552612,
          2.1600043773651123,
          1.4815988540649414,
          1.3119885921478271,
          1.4076725244522095
         ]
        },
        {
         "hoverinfo": "text",
         "hovertext": [
          "View first few rows of the Simpsons script DataFrame\ndf_script.head()",
          " Display the first few rows of the table\nprint(df_script.head())",
          " Display the first few rows of the dataframe 'df_script'.\ndf_script.head()",
          "Display the first few rows of the script lines dataframe\ndf_script.head()",
          " View the first few rows of the dataframe\ndf_script.head()",
          " Use pandas' head method to print the first 10 rows in df_script\ndf_script.head(10)",
          " Show first rows of \"script\" data\ndf_script.head()",
          " Display first rows of the scripts dataframe\ndf_script.head()",
          " Show first 10 rows of df_script.",
          " Display the first few rows of the script DataFrame\ndf_script.head()",
          "Display the first few rows of the script dataframe\ndf_script.head()",
          " Display the first few entries of the script data frame\ndisplay(df_script.head())",
          "Display the first few rows of the dataframe df_script\ndf_script.head()",
          " Optional: Display first rows of the \"script\" table to have a quick glance\nprint(df_script.shape)\ndf_script.head()",
          "The head method shows the first few rows of a DataFrame.",
          "# Display the number of lines and the first few rows of the df_script dataframe\nprint(df_script.shape)\ndf_script.head()",
          "View the first few rows of the dataframe\ndf_script.head()",
          "Display the first few rows\ndf_script.head()",
          " Display the first few rows of the scripts dataframe\ndf_script.head()",
          "Display first rows of DataFrame\ndf_script.head()",
          " Display the first entries of the dataframe containing the script of the Simpson series\ndf_script.head()",
          " Display the first few rows of the script dataframe\ndf_script.head()",
          "Display the first rows of the dataframe\ndf_script.head()",
          " Display the first few rows of the script dataframe\ndf_script.head()",
          "Display the first few rows to ensure everything is loaded correctly\ndf_script.head()",
          "Display the first few rows of the script dataframe\ndf_script.head()",
          "Display the first few rows of the script dataframe\ndf_script.head()",
          "Show the first few rows of the script dataframe\ndf_script.head()",
          "View the first 3 rows of the script dataframe\ndf_script.head(3)",
          " Display the first 10 rows of the \"df_script\" DataFrame\ndf_script.head(10)",
          "Show first few rows\ndf_script.head()",
          "Display the first few rows of the script dataframe\ndf_script.head()",
          "Display the first few records of the script dataframe\ndf_script.head()",
          " Displaying first rows of script dataframe\ndf_script.head()",
          " Show the first few rows of the dataframe \"df_script\"\ndf_script.head()",
          "Display the first few rows of the script data\nprint(df_script.head())",
          "Print the first 10 rows of the script dataframe\ndf_script.head(10)",
          " Quick visualization of the first few rows in the dataframe\ndf_script.head()",
          "Print the first few rows of the df script\ndf_script.head()",
          "Preview first rows of the dataframe\ndf_script.head()",
          "Remove the excess index column and display the first few rows of the dataframe\ndf_script = df_script.iloc[:, 1:]\ndf_script.head()",
          " Show first rows of the table\ndf_script.head()",
          "Show the first few rows of the dataframe containing the script data\ndf_script.head()",
          " Show the first rows of the dataframe\ndf_script.head()",
          "Display the first few rows of the script DataFrame\ndf_script.head()",
          " View the first few rows of the dataframe\ndf_script.head()",
          "Optional: Uncomment the line below to view the first few rows of the dataframe\n# df_script.head()",
          "View the first few rows of the script data\ndf_script.head()",
          "Display first rows of the script data\ndf_script.head()",
          "Remove quotes from 'raw_text'\ndf_script['raw_text'] = df_script['raw_text'].str.replace('\"', '')\n\n# Display the first rows of the dataframe\ndf_script.head()",
          "Display the first few rows of the script dataframe\ndf_script.head()",
          "Display the first few rows of the script dataframe\ndf_script.head()",
          "Show the first rows of the script dataframe\ndf_script.head()",
          "Optional: View the columns and first few rows of one of the dataframes\nprint(df_script.columns)\ndf_script.head()",
          "# Show first rows\ndf_script.head()",
          "View the first few rows of the script dataframe\ndf_script.head()",
          "Display the first few rows of the script lines dataframe\ndf_script.head()"
         ],
         "marker": {
          "opacity": 0.5,
          "size": 5
         },
         "mode": "markers+text",
         "name": "20_Viewing First Few Rows of a Script DataFrame",
         "text": [
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          ""
         ],
         "textfont": {
          "size": 12
         },
         "type": "scattergl",
         "x": [
          2.4351449012756348,
          1.4226861000061035,
          1.6170039176940918,
          1.7934201955795288,
          2.7668540477752686,
          1.4165362119674683,
          2.0695934295654297,
          2.261148452758789,
          1.7860466241836548,
          1.0028526782989502,
          0.9577360153198242,
          1.7825100421905518,
          1.134755253791809,
          2.4325413703918457,
          3.4443352222442627,
          2.3099236488342285,
          2.693686008453369,
          1.5346311330795288,
          1.4615343809127808,
          2.2268571853637695,
          2.627578020095825,
          1.0336635112762451,
          2.4958455562591553,
          1.0578296184539795,
          1.4754738807678223,
          1.1965824365615845,
          1.1285293102264404,
          1.714232087135315,
          3.052764892578125,
          1.3386410474777222,
          1.920456051826477,
          1.0725668668746948,
          2.0173869132995605,
          2.4790279865264893,
          1.5304888486862183,
          1.3672301769256592,
          1.0829824209213257,
          2.4070823192596436,
          1.0100743770599365,
          1.9994698762893677,
          2.0413975715637207,
          2.112647771835327,
          1.3728944063186646,
          2.3616268634796143,
          1.0090248584747314,
          2.5750815868377686,
          2.5762970447540283,
          2.468027114868164,
          2.0382232666015625,
          2.438171863555908,
          1.181130290031433,
          0.9386886358261108,
          2.4059314727783203,
          3.195483684539795,
          2.371671438217163,
          2.6406283378601074,
          1.9009884595870972
         ],
         "y": [
          -6.937604904174805,
          -7.34130334854126,
          -7.62872838973999,
          -7.860893249511719,
          -6.872167110443115,
          -6.293120384216309,
          -7.330382823944092,
          -7.534169673919678,
          -6.194797992706299,
          -7.955425262451172,
          -7.89570426940918,
          -8.084868431091309,
          -7.61369514465332,
          -6.916631698608398,
          -7.943167209625244,
          -7.4063262939453125,
          -7.080384731292725,
          -7.278337478637695,
          -8.179170608520508,
          -7.8754754066467285,
          -7.753664016723633,
          -7.740370273590088,
          -7.808587074279785,
          -8.033478736877441,
          -7.685925006866455,
          -8.075393676757812,
          -7.9451775550842285,
          -7.688457489013672,
          -7.038577079772949,
          -7.066810131072998,
          -7.134036064147949,
          -7.751503944396973,
          -8.021028518676758,
          -7.836834907531738,
          -7.559815883636475,
          -7.616153717041016,
          -7.036046981811523,
          -7.516470432281494,
          -7.178235054016113,
          -6.938614845275879,
          -8.01542854309082,
          -7.209499835968018,
          -7.892383575439453,
          -7.730891227722168,
          -7.850521564483643,
          -7.220051288604736,
          -7.145036220550537,
          -6.243863105773926,
          -7.557625770568848,
          -8.257046699523926,
          -7.943132400512695,
          -7.959168434143066,
          -7.346803188323975,
          -6.715278625488281,
          -7.5631866455078125,
          -6.878387928009033,
          -7.85456657409668
         ]
        },
        {
         "hoverinfo": "text",
         "hovertext": [
          "# show the first 5 lines of the dataframe\ndf_script.head()",
          "Declare print function for head of tables\ndef print_head(df, n=5):\n    print(df.shape)\n    display(df.head(n))",
          "Display up to 6 rows\ndf_script.head(6)",
          "Print the first 5 rows of the script dataframe\ndf_script.head()",
          "Show the first 5 rows of the script dataframe\ndf_script.head()",
          "display the first 5 rows of the script data frame\ndf_script.head()",
          "# Show the first 5 rows of the dataframe\ndf_script.head()",
          "View first 5 records of df_script\ndf_script.head(5)",
          "Show first 5 rows of dataframe to ensure everything's been read correctly\ndf_script.head()",
          " Show the first 5 rows of the script dataframe\ndf_script.head()",
          "Display the first 5 rows of each dataframe\ndf_script.head()",
          " Show the first 5 rows of the script dataframe\ndf_script.head(5)",
          "Preview the first 5 rows of the script data\ndf_script.head()",
          "Preview the first 5 rows of the main dataframe (for Simpsons script lines)\ndf_script.head()",
          "Print the first 5 rows of the script dataframe\nprint(df_script.head())",
          "# output the first 5 rows of the script dataframe\ndf_script.head()",
          "View the first 5 rows of the script dataframe\ndf_script.head()",
          "Display first 5 records\ndf_script.head()",
          "Print the first 5 entries of the script dataframe\ndf_script.head()",
          " Display the first five rows of the script data\ndf_script.head()",
          "# Print the first 5 lines of the dataframe to ensure it was properly imported\nprint(df_script.head())",
          " Display first 5 rows of the dataframe\ndf_script.head()",
          "inspect first 5 rows of script dataframe\ndf_script.head()",
          " Show first 5 rows of script_lines DataFrame\ndf_script.head()",
          "# Show first 5 rows\ndf_script.head(5)",
          " Show the first 5 lines of the script dataframe\ndf_script.head()",
          "# Outputs first n rows of a dataframe\ndef firstn(df, n=5):\n    return df.head(n)",
          " Display the top 5 rows of the script dataframe\ndf_script.head()",
          "Display the first 5 lines of the dataframe for inspection\ndf_script.head()",
          "Display the first 5 rows of each file to have a first look of the data\nprint('Loaded {} samples.'.format(len(df_script)))\ndf_script.head()",
          "Display the first 5 rows of the script dataframe\ndf_script.head()",
          "Display the first 5 rows of the \"script\" dataframe to understand its structure and content\ndf_script.head()",
          "Display the first 5 rows of the script dataframe\ndf_script.head()",
          "Display first 5 records of script lines (caption, raw_text, spoken_words)\ndf_script.head()",
          " Display the first 5 rows of the script dataset\ndf_script.head()",
          " Get the first 5 rows of the script dataframe\ndf_script.head()",
          "View first 5 rows of script data\ndf_script.head()",
          " Display the first 5 rows of the script dataframe\ndf_script.head()",
          "Preview the first 5 lines of the table\ndf_script.head()",
          "Print first 5 rows of the script data\ndf_script.head()",
          "Print first 5 rows of the script dataset\nscript_dataset = df_script\nprint(script_dataset.head())",
          "Create a Pandas DataFrame and display the first 5 rows\ndf_script = pd.DataFrame(df_script)\ndf_script.head()",
          "Display first 5 rows of df_script\ndf_script.head(5)",
          " Print first 5 rows from 'script' dataframe\ndf_script.head()",
          "Display first 5 rows of the script dataframe.\ndf_script.head()",
          " Display the first five rows of the script dataframe\ndf_script.head()",
          "Iterating through the pandas dataframe\nfor index, row in df_script.iterrows():\n    if index == 5:\n        break\n    # Do something by accessing the row\n    print(row)",
          "Show the first 5 rows of the script dataframe\ndf_script.head()",
          " Show first 5 rows of the dataframe\ndf_script.head()",
          "Display top 5 rows of dataframe\ndf_script.head()",
          "Display the first 5 rows of the table to understand its structure\ndf_script.head()",
          "# Display the first 5 records of the script lines dataframe\ndf_script.head()",
          "# Print first 5 rows of the dataframe\ndf_script.head()",
          " Show the top 5 rows of the dataframe to understand the data\ndf_script.head()",
          "display the 5 first rows\ndf_script.head()",
          " Display the first 5 rows of the script dataframe\ndf_script.head()",
          "Display the first 5 rows of the script dataframe\ndf_script.head()"
         ],
         "marker": {
          "opacity": 0.5,
          "size": 5
         },
         "mode": "markers+text",
         "name": "21_Displaying and Accessing Rows in a Pandas DataFrame",
         "text": [
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          ""
         ],
         "textfont": {
          "size": 12
         },
         "type": "scattergl",
         "x": [
          2.4135544300079346,
          2.667501211166382,
          1.505017638206482,
          1.7698371410369873,
          2.026007652282715,
          1.4771648645401,
          1.705269694328308,
          1.2983142137527466,
          1.5675982236862183,
          1.8156219720840454,
          1.089756727218628,
          1.5842723846435547,
          1.6214416027069092,
          1.9771144390106201,
          1.876360297203064,
          1.15935218334198,
          1.8164664506912231,
          1.469871163368225,
          1.3949456214904785,
          1.2287278175354004,
          2.101820230484009,
          1.0615745782852173,
          2.2742221355438232,
          2.105492115020752,
          1.5216829776763916,
          2.5431010723114014,
          1.5861048698425293,
          0.8840624690055847,
          2.474273681640625,
          1.6233888864517212,
          1.4842808246612549,
          2.211559534072876,
          1.1489962339401245,
          2.072702169418335,
          1.6964008808135986,
          2.2465105056762695,
          1.4768117666244507,
          1.0217325687408447,
          1.4684287309646606,
          1.812734603881836,
          1.884469747543335,
          1.2032525539398193,
          0.99114590883255,
          1.885084867477417,
          0.997814953327179,
          1.150706171989441,
          2.7994120121002197,
          2.0789637565612793,
          1.5793964862823486,
          0.902854859828949,
          1.6089742183685303,
          1.8518052101135254,
          1.8627734184265137,
          1.3538696765899658,
          1.1867197751998901,
          1.0628938674926758,
          1.30794358253479
         ],
         "y": [
          -5.296508312225342,
          -4.643836498260498,
          -5.995453834533691,
          -4.787648677825928,
          -4.526993274688721,
          -5.069785118103027,
          -4.717733860015869,
          -5.02066707611084,
          -4.309444904327393,
          -4.648416996002197,
          -4.476099967956543,
          -4.5966081619262695,
          -6.090609073638916,
          -5.417892932891846,
          -4.7180562019348145,
          -4.880780220031738,
          -4.886293888092041,
          -5.424799919128418,
          -4.471801280975342,
          -5.43386697769165,
          -4.752984046936035,
          -4.341275691986084,
          -4.9593963623046875,
          -4.972625255584717,
          -5.39437198638916,
          -5.264975547790527,
          -4.326778411865234,
          -4.4550909996032715,
          -6.005527496337891,
          -4.717727184295654,
          -4.403692722320557,
          -5.607059955596924,
          -4.575564861297607,
          -5.453977584838867,
          -5.227723598480225,
          -4.557793617248535,
          -5.415757656097412,
          -4.671983242034912,
          -5.662412643432617,
          -5.193491458892822,
          -5.31856632232666,
          -4.282494068145752,
          -5.110939979553223,
          -4.910624027252197,
          -4.574466705322266,
          -4.584682464599609,
          -5.045433044433594,
          -4.375415325164795,
          -4.511789321899414,
          -4.292446136474609,
          -5.831361293792725,
          -5.0149664878845215,
          -4.454107284545898,
          -4.299925327301025,
          -5.258622646331787,
          -4.823257923126221,
          -4.70697021484375
         ]
        },
        {
         "hoverinfo": "text",
         "hovertext": [
          " Retrieve a subset of the Simpsons massive dataset\nseed = 42  # Seed used for every random function\ndocs_fraction = 0.05  # Fraction of the complete dataset we want to use\n\n# Get a subset of all characters\ndf_characters_sub = df_characters.sample(frac=docs_fraction, random_state=seed)\n# Get a subset of all location\ndf_locations_sub = df_locations.sample(frac=docs_fraction, random_state=seed)\n# Get a subset of all episodes\ndf_episodes_sub = df_episodes.sample(frac=docs_fraction, random_state=seed)\n# Get a subset of all script lines\ndf_script_sub = df_script[df_script['episode_id'].isin(df_episodes_sub['id'])]  # Use only script lines from the subselected episodes",
          "Filter valid episode scripts\ndf_script = df_script[df_script['episode_id'].isin(df_episodes['id'])]",
          "Select season 2's data\nseason2_episode_ids = df_episodes[df_episodes.season == 2].index\nseason2_script = df_script[df_script['episode_id'].isin(season2_episode_ids)]",
          " Filter scripts to only use episodes from the TV show\ndf_script = df_script[df_script['episode_id'] <= 600].reset_index(inplace=False, drop=True)",
          " Look for data with NaNs in the episode data\ndf_script[df_script['episode_id'].isna()]",
          "Reduce the size of the dataset for the purpose of this lecture\ndf_script = df_script[df_script['episode_id'] < 150]",
          "Some cleanup\ndf_script = df_script[df_script['episode_id'].isin(df_episodes['id'])]",
          "Filter in script lines only\ndf_script = df_script[df_script['episode_id'].isin(df_episodes[df_episodes[\"original_air_date\"] <= '2003-04-27'][\"id\"])]",
          " filter some bad rows\ndf_script = df_script[df_script['episode_id'] != 's']\ndf_episodes = df_episodes[df_episodes['id'] != 's']",
          "Filter episodes from season 1 and 2\ndf_episodes_1_2 = df_episodes[(df_episodes['season']==1) | (df_episodes['season']==2)]",
          "Limit script to the episodes in the dataset\nall_ep_ids = df_episodes.id.values\ndf_script = df_script[df_script['episode_id'].isin(all_ep_ids)]",
          "# Filter out the data with invalid episode_id\nvalid_episode_ids = set(df_episodes.id)\ndf_script = df_script[df_script['episode_id'].isin(valid_episode_ids)].reset_index(drop=True)",
          "df_script_subset = df_script[df_script['episode_id'].isin(df_episodes['id'])]",
          "# Extracting the script for a specific episode\nepisode_id = 168\nscript = df_script[df_script['episode_id'] == episode_id]\nscript",
          "\ndf_script = df_script[df_script[\"episode_id\"].notna()]",
          "Subset of the first 100 episodes from \"The Simpsons\" dataset\ndf_episodes_subset = df_episodes[df_episodes['id'] <= 100]",
          "Extract just the lines of a single episode to make the example more managable\nepisode_mask = (df_script['episode_id'] == 1) & (df_script['character_id'] == 9)\ndf_script = df_script[episode_mask]",
          "Create a subset of episodes if needed\ndf_subset_episodes = df_episodes[df_episodes[\"id\"] <= 600].copy()",
          " Select only the first 10 episodes for simplicity\ndf_script = df_script[df_script[\"episode_id\"].isin(df_episodes[\"id\"].values[:10])].reset_index(inplace=False, drop=True)",
          " Filter and select dataset\n# Filter dataframe with the episodes of interest by their title\ndf_episodes_selected = df_episodes[df_episodes['title'] == 'Lisa the Simpson'].reset_index(inplace=False, drop=True)\n# We use only the first match\ndf_episodes_selected = df_episodes_selected.iloc[[0]]",
          "Remove episodes without a location\ndf_script = df_script[df_script['episode_id'].isin(df_locations['episode_id'])]",
          "Reduce data size to speed up training\ndf_script = df_script[df_script['episode_id'] < 150].reset_index(inplace=False, drop=True)",
          "Filter out episode titles that are in df_script but not in df_episodes",
          "Check if the episode ID from the script lines are in the episode dataframe\ndf_script_in_eps = df_script[df_script['episode_id'].isin(df_episodes['id'])]",
          "Filter from season 3 onwards\ndf_script = df_script[df_script.season >= 3]",
          "Limit the data to the first 20 seasons for efficiency\ndf_script = df_script[df_script['episode_id'] <= 44186]",
          " Select script from episode 1 and 2\ndf_script_12 = df_script[(df_script[\"episode_id\"]==1) | (df_script[\"episode_id\"]==2)].reset_index(inplace=False, drop=True)",
          "Filter relevant seasons and reset index\ndf_episodes = df_episodes[(df_episodes['season'] >= 3) & (df_episodes['season'] <= 28)].reset_index(inplace=False, drop=True)",
          " Filter only the script of the episode with the specified id\ndf_script_episode = df_script[df_script['episode_id'] == 11]",
          " Remove invalid episode_ids from df_script\ndf_script = df_script[df_script['episode_id'].isin(df_episodes['id'].values)]",
          "Filter out incorrect rows in df_episodes",
          "Select only 10 random episodes due to computation limits\nnp.random.seed(0)\ndf_episode_sample = df_episodes.loc[np.sort(np.random.choice(df_episodes.index, 10, replace=False))]\ndf_episode_sample.reset_index(inplace=True, drop=True)",
          "ensuring uniformity of data\ndf_script = df_script[df_script['episode_id'] <= 600]",
          "remove episode id = 1 as it contains no proper information i.e. script/season/episode name, etc\ndf_script = df_script[df_script['episode_id'] != 1]",
          "Select an episode at random\nnp.random.seed(42)\nepisode_id = np.random.choice(df_script['episode_id'].unique())\ndf_script[df_script['episode_id'] == episode_id].head(10)",
          " Filtered season scripts\ndf_script_filtered = df_script[df_script['episode_id'] <= df_script[df_script['season']==15]['episode_id'].max()]",
          " Remove invalid IDs from script\nvalid_ids = set(df_episodes['id'].unique())\n\ndf_script = df_script[df_script['episode_id'].isin(valid_ids)].reset_index(inplace=False, drop=True)",
          "Filter by the Simpsons TV show\ndf_script = df_script[df_script[\"episode_id\"].isin(df_episodes[df_episodes[\"imdb_rating\"] > 7.5][\"id\"])]",
          "Filter to have only the lines from the first seasons\ndf_script_first_season = df_script.loc[df_script['episode_id'] <= 138].copy()",
          "Filter some seasons\nseasons = list(range(3, 10)) + [11]\n\ndf_script = df_script[df_script.season.isin(seasons)]",
          "df_script = df_script[df_script[\"episode_id\"].isin(df_episodes[df_episodes[\"season\"].isin(range(2, 10))][\"id\"])]\ndf_script = df_script.reset_index(inplace=False, drop=True)",
          " Extract script for requested episode\nepisode_id = 12\ndf_episode_script = df_script[df_script['episode_id'] == episode_id]",
          " Filter the script dataframe to only keep the first 20 seasons\ndf_script = df_script[df_script['episode_id'] <= 441].reset_index(drop=True)",
          "ignore episodes with missing data\ndf_script = df_script[~df_script[\"episode_id\"].isnull()]",
          "Filter episode to have only the Simpsons (no specials)\ndf_episodes = df_episodes[~df_episodes['title'].str.contains('special')].reset_index(drop=True)",
          "Select Season 1\ndf_script_s1 = df_script[df_script['episode_id'].isin(df_episodes[df_episodes['season']==1]['id'])]",
          "Query the latest version of a dataset\nprint(df_script.query('episode_id == 75 and number_in_episode >= 2 and number_in_episode <= 5'))",
          "Create a subset of the script dataframe to contain only episodes 1 to 500",
          "Filter out lines from the script that were not included in a specific episode\ndf_script = df_script[df_script.episode_id.isin(df_episodes['id'])]",
          "Filter out the non-Simpsons episodes\ndf_episodes = df_episodes[df_episodes['id'].isin(df_script['episode_id'])]",
          "Only use the top 300 episodes to avoid memory errors\ndf_script = df_script[df_script['episode_id'] <= 300]",
          "Filter only by the \"The Simpsons\" show\ndf_episodes = pd.merge(df_episodes, df_script, on='episode_id')\ndf_episodes = df_episodes[df_episodes['title'].str.contains('Simpsons')]\n\ndf_episodes.groupby('title').agg({\n    'number': 'first',\n    'us_viewers_in_millions': 'first',\n    'views': 'first',\n    'imdb_rating': 'first'\n})",
          " Select only the first 6 seasons of the data\ndf_script = df_script[df_script['season'] <= 6]",
          " Filter data frame and display it\ndf_script_filtered = df_script[(df_script['episode_id'] == 652) & (df_script['number'] < 4)]\ndf_script_filtered",
          "Set the episode_id for: df_script, df_characters, df_locations",
          " Remove faulty:\ndf_script = df_script[df_script[\"episode_id\"] != 394]"
         ],
         "marker": {
          "opacity": 0.5,
          "size": 5
         },
         "mode": "markers+text",
         "name": "22_Filtering and selecting data from a script dataframe and episodes dataframe",
         "text": [
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          ""
         ],
         "textfont": {
          "size": 12
         },
         "type": "scattergl",
         "x": [
          4.423309803009033,
          4.704447269439697,
          4.24824857711792,
          4.672640800476074,
          4.752161026000977,
          3.7986366748809814,
          4.321940898895264,
          4.483236789703369,
          4.790399074554443,
          4.045003414154053,
          3.8645846843719482,
          4.388551712036133,
          4.254965305328369,
          3.9941561222076416,
          4.662503719329834,
          4.628684997558594,
          4.4661946296691895,
          4.327770233154297,
          3.7682950496673584,
          3.899674654006958,
          4.576763153076172,
          3.8196732997894287,
          5.542440891265869,
          4.958195686340332,
          5.729372978210449,
          4.591938495635986,
          3.6492502689361572,
          4.4342427253723145,
          4.723591327667236,
          4.460465431213379,
          5.680354118347168,
          3.7151038646698,
          3.9544789791107178,
          4.032543659210205,
          3.43544602394104,
          4.92094612121582,
          3.9415390491485596,
          4.6327338218688965,
          4.221273899078369,
          5.7418437004089355,
          4.257917404174805,
          4.345902442932129,
          4.366185188293457,
          4.8873162269592285,
          4.513179779052734,
          4.487303256988525,
          4.284242153167725,
          3.9720184803009033,
          5.553306579589844,
          4.969753742218018,
          4.011694431304932,
          4.374135971069336,
          4.995536804199219,
          4.908641338348389,
          4.434829235076904,
          3.9722065925598145
         ],
         "y": [
          5.32178258895874,
          4.742568016052246,
          4.642179012298584,
          4.54633092880249,
          4.377787113189697,
          4.008101940155029,
          4.926976680755615,
          4.69392728805542,
          4.861174583435059,
          4.0862932205200195,
          4.669753551483154,
          4.660613059997559,
          5.211302757263184,
          5.286466598510742,
          5.055657863616943,
          4.558268070220947,
          5.138178825378418,
          4.847379684448242,
          4.538914680480957,
          4.9747209548950195,
          4.947882652282715,
          4.048415660858154,
          4.853480815887451,
          4.696902751922607,
          4.260159492492676,
          4.194120407104492,
          4.910793781280518,
          4.614408493041992,
          4.508846759796143,
          4.961784839630127,
          4.181674480438232,
          4.25913143157959,
          4.241392135620117,
          4.946916103363037,
          4.902716159820557,
          4.731058597564697,
          4.281022548675537,
          4.722383975982666,
          4.930054664611816,
          3.8477869033813477,
          4.912614345550537,
          5.4674859046936035,
          4.523850440979004,
          4.834944725036621,
          5.254939556121826,
          4.438640594482422,
          4.507658958435059,
          3.9950313568115234,
          4.724238872528076,
          4.836579322814941,
          4.479801177978516,
          5.455804824829102,
          4.179740905761719,
          4.652534484863281,
          4.804934978485107,
          4.867802619934082
         ]
        },
        {
         "hoverinfo": "text",
         "hovertext": [
          " Take a look at the content from the characters file\ndf_characters.head()",
          "Explore the data\ndf_characters.head()",
          "Inspect content of the characters file\ndf_characters.head()",
          "Structure df_characters and df_locations to allow seaborn to easily plot the value_counts().",
          "\n# Quick look at the data\ndf_characters.head()",
          "# Let's take a look at the characters data\ndf_characters.head()",
          "Visualize characters data\ndf_characters.head()",
          "# Look at the first few lines of the characters data frame\ndf_characters.head()",
          " Data example: Characters\ndf_characters.head()",
          "Inspect the character data first\ndf_characters.head()",
          "View a few lines of the characters data\ndf_characters.head()",
          "Visualisation for df_characters",
          "Look at the data table for characters\ndf_characters.head()",
          " Quick peek at the characters\ndf_characters.head()",
          "View some of the data\ndf_characters.head()",
          "Inspect the head of df_characters\ndf_characters.head()",
          "# Let's take a look at the characters data\ndf_characters.head()",
          "Take a look at the character data\ndf_characters.head()",
          " Visualize the data\ndf_characters.head()",
          "A quick look at the characters data\ndf_characters.head()",
          "View Data\ndf_characters.head()",
          "See the first few lines of the characters data.\ndf_characters.head()",
          " Characters Avatar\ndf_characters['raw_character_text']",
          " Display our data to get an overview\ndf_characters.head()",
          "Let's display them to see their structure\ndf_characters.head()",
          "# Let's take a quick look at the datasets\ndf_characters.head()",
          "Explore the data\ndf_characters.head()",
          " Display the data structures\ndf_characters.head(3)",
          "ve a look at some data from characters table\ndf_characters.head()",
          " View a sample of the data in df_characters\ndf_characters.head()",
          "\n# Take a look at the characters data\ndf_characters.head()",
          "Examine the data\ndf_characters.head()",
          "Display the data to better understand its structure and the available features\ndf_characters.head()",
          "# Show sample data for characters\ndf_characters.head()",
          "Quick look at characters data\ndf_characters.head()",
          " Print few lines of data to see what is present\ndf_characters.head()",
          "Explore the data\ndf_characters.head()",
          "View some of the data in `df_characters`\ndf_characters.head(3)",
          "Inspect the characters data\ndf_characters.head()",
          "quick look at the characters data\ndf_characters.head()",
          "Visualize columns info\ndf_characters.head(3)",
          "Inspect data\ndf_characters.head()",
          "Data Overview\ndf_characters.head(3)",
          "Explore character data\ndf_characters.head()",
          "Take a look at the characters data\ndf_characters.head()",
          "Take a look at the first 5 rows of the characters data\ndf_characters.head()",
          " Visualize some of the data\ndf_characters.head()",
          "Explore the content of the characters file\ndf_characters.head()",
          "Inspect the characters data\ndf_characters.head()",
          "Quick look at the data\ndf_characters.head()",
          "Inspect the characters data\ndf_characters.head()",
          "Quick look at individual datasframes\ndf_characters.head()",
          "Quick look at the data\ndf_characters.head()",
          "take a peek at the characters file\ndf_characters.head()",
          "Exploring the data\ndf_characters.head()",
          "Quick peek at the data\ndf_characters.head()"
         ],
         "marker": {
          "opacity": 0.5,
          "size": 5
         },
         "mode": "markers+text",
         "name": "23_Quick look at characters data",
         "text": [
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          ""
         ],
         "textfont": {
          "size": 12
         },
         "type": "scattergl",
         "x": [
          6.85945463180542,
          6.646976947784424,
          6.855964183807373,
          7.61794900894165,
          6.083858966827393,
          5.90064811706543,
          6.236454963684082,
          6.1303534507751465,
          7.006819725036621,
          6.672004699707031,
          6.369762420654297,
          6.338871002197266,
          6.520618438720703,
          6.146114349365234,
          6.285116672515869,
          6.9978413581848145,
          5.774491310119629,
          6.549635887145996,
          6.151206016540527,
          6.14068603515625,
          6.707833766937256,
          6.775845050811768,
          6.485020637512207,
          6.865225791931152,
          6.8691582679748535,
          5.503170967102051,
          6.617019176483154,
          6.812349796295166,
          6.16746711730957,
          7.013315677642822,
          6.247045993804932,
          6.3494672775268555,
          6.268698215484619,
          7.004050254821777,
          6.0225653648376465,
          5.4848527908325195,
          6.664233207702637,
          6.757270336151123,
          6.354085922241211,
          6.261266231536865,
          6.387718677520752,
          6.676716327667236,
          6.684729099273682,
          6.23336124420166,
          6.410672664642334,
          6.2278971672058105,
          6.3066020011901855,
          6.595509052276611,
          6.222628116607666,
          6.615113735198975,
          6.267632961273193,
          5.962686061859131,
          6.539188385009766,
          6.762715816497803,
          6.184689998626709,
          6.514083385467529
         ],
         "y": [
          14.202584266662598,
          16.175125122070312,
          15.719932556152344,
          11.082923889160156,
          14.512222290039062,
          13.646206855773926,
          16.051074981689453,
          14.307866096496582,
          15.309733390808105,
          15.752102851867676,
          16.208171844482422,
          15.2194242477417,
          14.521798133850098,
          15.242461204528809,
          16.238309860229492,
          15.581985473632812,
          14.085143089294434,
          14.079329490661621,
          15.705262184143066,
          14.51197624206543,
          16.0841064453125,
          14.413224220275879,
          12.66801643371582,
          16.428382873535156,
          15.253148078918457,
          14.206905364990234,
          16.220258712768555,
          15.981389999389648,
          14.25679874420166,
          16.55709457397461,
          13.962193489074707,
          15.617330551147461,
          16.03689956665039,
          16.000980377197266,
          14.919489860534668,
          16.768192291259766,
          16.20933723449707,
          16.53737449645996,
          15.329023361206055,
          14.644875526428223,
          15.93625259399414,
          15.41639232635498,
          15.493714332580566,
          16.422147750854492,
          14.048283576965332,
          13.777264595031738,
          15.480576515197754,
          15.195688247680664,
          15.305057525634766,
          14.9542236328125,
          15.38880443572998,
          15.078269958496094,
          15.02216911315918,
          14.841837882995605,
          15.778167724609375,
          15.423921585083008
         ]
        },
        {
         "hoverinfo": "text",
         "hovertext": [
          "Check the head to ensure that everything is working fine\ndf_script.head()",
          "Check data import\ndf_script.head()",
          "check the script data\ndf_script.head()",
          "Check the content of a few scripts\ndf_script.head()",
          "Check that the dataframe was loaded correctly\ndf_script.head()",
          "# Verify the import\ndf_script.head()",
          "Check the content of the script dataset to see what it looks like\ndf_script.head(5)",
          "Check correct\ndf_script.head()",
          "Check that the imports and data load ran correctly\ndf_script.head()",
          " Check data\ndf_script.head()",
          "Check everything is ok.\ndf_script.head()",
          "#  Check if script has been loaded correctly\ndf_script.head()",
          "Check that the data was loaded correctly\ndf_script.head()",
          "Check the first row of the dataframe to ensure it loaded correctly\ndf_script.head(1)",
          "Clean the dialoguue data\ndf_script.head()",
          "Check if script was loaded correctly\ndf_script.head()",
          "Check the data\ndf_script.head()",
          " Check that the script lines dataframe loads correctly\ndf_script.head()",
          " Check data head\ndf_script.head()",
          "Check DataFrame contents to ensure they're correctly loaded\ndf_script.head()",
          " Check the data sample\ndf_script.head()",
          "Check that the content of the DataFrames was loaded correctly\ndf_script.head()",
          "Check if the script table is correct\ndf_script.head()",
          "Examine content of df_script\ndf_script.head()",
          "Check import of data\ndf_script.head()",
          "Checks the content of the script data\ndf_script.head()",
          "Check the data structure\ndf_script.head()",
          "Check the dataframe is correctly populated\ndf_script.head()",
          " Check if the script is loaded correctly\ndf_script.head()",
          "Check that the data has been loaded correctly\ndf_script.head()",
          " Check the structure of the script lines table\ndf_script.head()",
          "Check the data correctness\ndf_script.head()",
          "Check if the data is correctly loaded\ndf_script.head()",
          "Just checking the content of the file\ndf_script.head()",
          "Check content of the script data\ndf_script.head()",
          "check to see what the data look like\ndf_script.head()",
          "Check data\ndf_script.head()",
          " Check that the data is correctly loaded\ndf_script.head()",
          "# Ensure the script is correctly imported\ndf_script.head()",
          "Check the format of the script data\ndf_script.head()",
          "Check data and datatypes\ndf_script.head()",
          "Check the result\ndf_script.head()",
          "Checking that the data has been read in correctly\nprint(df_script.head())",
          "Use the variable to see that the CSVs have been read correctly\ndf_script.head()",
          "Check the first three rows of the script data to see what it looks like\ndf_script.head(3)",
          "# Check the structure of script data\ndf_script.head()",
          "Check the data\ndf_script.head()",
          "Check data integrity\ndf_script.head()",
          "Check the data format\nprint(df_script.head(5))",
          "Check the content of `df_script`",
          "Check dataframes load correctly\ndf_script.head()",
          "check the data\nprint(df_script.head())\n",
          "Check\ndf_script.head()",
          "Test that we have loaded the data correctly\ndf_script.head()",
          "Check what the script data looks like\ndf_script.head()",
          "checking my data\ndf_script.head()"
         ],
         "marker": {
          "opacity": 0.5,
          "size": 5
         },
         "mode": "markers+text",
         "name": "24_Checking if DataFrames are Loaded Correctly",
         "text": [
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          ""
         ],
         "textfont": {
          "size": 12
         },
         "type": "scattergl",
         "x": [
          6.3964738845825195,
          5.194164276123047,
          5.440454959869385,
          6.118719100952148,
          6.4613938331604,
          5.924180030822754,
          5.164108753204346,
          5.868110179901123,
          6.641439914703369,
          5.419548988342285,
          6.360776424407959,
          5.798281669616699,
          6.49969482421875,
          6.127405166625977,
          6.113677024841309,
          6.194140434265137,
          4.993010997772217,
          6.139575004577637,
          5.092963218688965,
          6.5001397132873535,
          4.822675704956055,
          6.059144496917725,
          5.860627174377441,
          5.9918389320373535,
          4.893693923950195,
          6.014484405517578,
          5.118703365325928,
          6.434439659118652,
          6.0128655433654785,
          6.211285591125488,
          5.593499183654785,
          5.7271294593811035,
          6.186899662017822,
          5.795718669891357,
          6.028670310974121,
          5.759280204772949,
          5.5154595375061035,
          6.310409069061279,
          5.942630290985107,
          5.494553089141846,
          6.270254135131836,
          5.601157188415527,
          5.605595111846924,
          6.345576763153076,
          5.134250164031982,
          5.73460054397583,
          5.047581672668457,
          5.536009311676025,
          4.924367904663086,
          6.928534507751465,
          6.099862575531006,
          5.190186977386475,
          5.537829875946045,
          6.008925437927246,
          5.555452823638916,
          5.281367778778076
         ],
         "y": [
          -2.954411745071411,
          -2.5193703174591064,
          -2.8956568241119385,
          -3.2984092235565186,
          -3.4112653732299805,
          -3.845644950866699,
          -3.2042367458343506,
          -4.077123641967773,
          -2.742764711380005,
          -2.6768221855163574,
          -3.4086573123931885,
          -3.6551296710968018,
          -2.493072986602783,
          -3.510982036590576,
          -2.229201078414917,
          -3.819425344467163,
          -2.4363465309143066,
          -3.2881486415863037,
          -2.5862343311309814,
          -3.3714756965637207,
          -2.7597715854644775,
          -2.9100329875946045,
          -3.6061112880706787,
          -3.9304075241088867,
          -2.574875831604004,
          -2.9187121391296387,
          -3.2122159004211426,
          -3.580369472503662,
          -4.031477451324463,
          -2.704052686691284,
          -3.771857738494873,
          -3.014758825302124,
          -3.087975263595581,
          -3.4369747638702393,
          -3.1474475860595703,
          -2.946042776107788,
          -2.5888614654541016,
          -2.639986991882324,
          -3.7316746711730957,
          -3.026017904281616,
          -2.2280118465423584,
          -3.733320951461792,
          -2.5024056434631348,
          -2.6292030811309814,
          -3.6026158332824707,
          -3.89853572845459,
          -2.6617279052734375,
          -2.704193115234375,
          -3.0799217224121094,
          -3.3553006649017334,
          -3.680245876312256,
          -2.606048822402954,
          -3.591552495956421,
          -2.7428410053253174,
          -3.6358437538146973,
          -2.6678261756896973
         ]
        },
        {
         "hoverinfo": "text",
         "hovertext": [
          "Custom imports",
          "Check if tqdm works",
          "Checking if the import is successful.",
          "Custom imports\nfrom tqdm import tqdm\nfrom collections import Counter",
          "Custom code\nfrom elephas.utils.rdd_utils import to_simple_rdd",
          "Checking the imported datasets",
          "Utils script\nfrom collections import Counter",
          "Check if the imports are working correctly.",
          "More imports",
          "from datetime import datetime",
          "Import dataset",
          "More local imports\nfrom scripts.features import *\nfrom scripts.cleaning import *",
          "...and more imports",
          "Set path to data and custom :func:`~utils` (for relative imports).",
          "Plugin Initialization\nimport nb_black",
          "Local imports",
          "Check what is imported",
          "specific imports\nfrom sklearn.cluster import KMeans\nfrom sklearn.feature_extraction.text import TfidfVectorizer",
          " from datetime import datetime",
          "Redo the imports with the correct syntax",
          "Check the imported datasets",
          "Checking that the content has been imported correctly",
          " Access local library\nimport sys",
          "General imports\nimport os",
          "Custom imports\nfrom tqdm import tqdm\nfrom collections import Counter",
          "# Elasticsearch imports\nfrom elasticsearch import Elasticsearch, helpers",
          "Check the imported data for each table",
          "Check the imported data",
          "Other imports and settings",
          "Set paths for easier importing",
          "# Use the OS module to handle operating system specific operations\nimport os",
          "General imports",
          "uer_import",
          "# Note - please ensure that the files have been placed in the correct path as mentioned in the code for the imports to work",
          "Check the import and data loading",
          "Testing whether these imports work",
          "Check to see if all imports were successful.\nprint('imports successful')",
          "Check file imports",
          " Add a newline after the data import statements for better organization",
          "Add other file imports and related code here",
          "import the functions\nfrom helpers import clean_text, wasserstein, simplify_movie_name",
          "\n# Custom imports\nfrom tqdm import tqdm ",
          "fromutils import *",
          "Custom imports\nfrom utils import preprocess_text",
          "Check the data when it has been imported",
          "Visualisations related imports",
          "Check if tables have been correctly imported",
          "\nprint(\"Import successful\")",
          "importing our custom classes and functions",
          " Implement more general imports to work with the data",
          "Locally generated Imports",
          " Additional imports for NLP analysis",
          "Requirement 1.3: The script must make use of a function from each of the imported libraries at least once.",
          " Additional custom imports for natural language processing (NLP)",
          "# Custom imports\nfrom tqdm import tqdm\nfrom collections import Counter"
         ],
         "marker": {
          "opacity": 0.5,
          "size": 5
         },
         "mode": "markers+text",
         "name": "25_Imports and Customizations",
         "text": [
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          ""
         ],
         "textfont": {
          "size": 12
         },
         "type": "scattergl",
         "x": [
          14.70295524597168,
          13.82082462310791,
          15.049053192138672,
          12.857961654663086,
          13.931292533874512,
          14.609430313110352,
          12.84495735168457,
          14.84095287322998,
          14.682218551635742,
          4.414766311645508,
          14.440153121948242,
          13.617237091064453,
          14.884347915649414,
          14.605710983276367,
          14.529716491699219,
          14.70358657836914,
          14.972538948059082,
          13.503116607666016,
          4.242519378662109,
          14.369199752807617,
          14.807424545288086,
          15.168638229370117,
          14.70258903503418,
          14.92013168334961,
          12.70404052734375,
          14.35944652557373,
          14.474533081054688,
          14.751163482666016,
          14.463390350341797,
          15.219956398010254,
          14.720163345336914,
          14.419102668762207,
          15.120826721191406,
          14.850394248962402,
          14.971211433410645,
          14.574213027954102,
          15.322253227233887,
          14.863853454589844,
          13.126646041870117,
          14.51988697052002,
          13.961563110351562,
          13.050002098083496,
          14.777826309204102,
          14.228017807006836,
          14.77574634552002,
          14.320943832397461,
          14.445364952087402,
          15.371255874633789,
          14.1726655960083,
          14.313922882080078,
          14.494230270385742,
          13.597235679626465,
          14.144688606262207,
          14.264119148254395,
          13.022720336914062
         ],
         "y": [
          3.9374945163726807,
          0.9501652717590332,
          2.554219961166382,
          10.238837242126465,
          4.504828929901123,
          0.5520570278167725,
          9.57943344116211,
          3.0327768325805664,
          3.2264676094055176,
          1.8136717081069946,
          1.031815767288208,
          3.742307424545288,
          3.596264600753784,
          4.154154300689697,
          4.298727035522461,
          3.5349643230438232,
          2.019432544708252,
          1.2294284105300903,
          2.0160975456237793,
          3.9683923721313477,
          0.6193233728408813,
          2.102005958557129,
          3.801069974899292,
          3.897582769393921,
          10.131543159484863,
          3.324669122695923,
          0.465243399143219,
          1.3643112182617188,
          3.5913965702056885,
          3.6126515865325928,
          4.126497745513916,
          3.3400096893310547,
          3.578310489654541,
          3.4891252517700195,
          1.7185484170913696,
          2.478431463241577,
          2.704578161239624,
          2.5698935985565186,
          4.024148941040039,
          3.716775894165039,
          4.513919353485107,
          10.321938514709473,
          4.1149749755859375,
          4.510646820068359,
          1.321529746055603,
          2.1040847301483154,
          0.9625265598297119,
          2.9577767848968506,
          3.7797234058380127,
          3.464221477508545,
          3.6299688816070557,
          4.351171493530273,
          3.7945144176483154,
          4.668375492095947,
          9.980782508850098
         ]
        },
        {
         "hoverinfo": "text",
         "hovertext": [
          "Inspect and clean data",
          "First we need to understand the data in order to decide on any data cleaning that may be necessary.",
          "Create a new clean data frame ready for later processing.",
          "\n# Various functions to clean data for analysis",
          "Discard data before 1989 because the data is too sparse and Springfield hasn't been revealed yet",
          "Data Cleaning and Preprocessing",
          "Data exploration and cleaning",
          " Time to redo them after reworking the the dirty data",
          "Data Preparation",
          " Data cleaning",
          "Clean Data",
          "Additional data cleaning",
          "Data Processing",
          "Cleaning data",
          "Remove any bad data points.",
          "Data preparation",
          "Clean up missing and bad data",
          "Data Preparation",
          "Data cleaning",
          " Some cleaning of fields and datatypes",
          "Data operations",
          " Data cleaning",
          "Inspect the data for any important details and initial data cleaning",
          "Data sanitization and exploration",
          "Data Preprocessing and Cleaning",
          "Mapping data for easier cleanup.",
          "Data exploration and data cleaning",
          "Checking the data and cleaning it",
          "Data Overview and Cleaning",
          "Data cleaning and formatting",
          "Data Processing",
          " Define functions to clean the data",
          "A 2-minute version of the cleaning procedure is initiated.",
          " Load the cleaned files",
          "Preprocess the data, e.g. remove unneeded columns, merge on shared information, etc.",
          "Sanitize data",
          "Data exploration and cleaning",
          "Cleaning data to remove any unnecessary columns and data.",
          "Clean the data",
          "Data cleaning and processing",
          "Some Data Cleaning",
          "Data pre-processing",
          "Data cleaning and pre-processing",
          "Data preparation",
          " Data Cleaning",
          "Inspecting and cleaning the data",
          "Data Cleaning",
          " Data Cleaning",
          "A quick look at the data shows that it needs a bit of cleaning up before it'll be very useful to us.",
          "Data cleaning and preparation",
          " Some initial cleanup",
          "Cleaning the data",
          "Cleaning the dataset",
          "Prepare data for modeling",
          "Data Cleaning and Processing"
         ],
         "marker": {
          "opacity": 0.5,
          "size": 5
         },
         "mode": "markers+text",
         "name": "26_Data Cleaning",
         "text": [
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          ""
         ],
         "textfont": {
          "size": 12
         },
         "type": "scattergl",
         "x": [
          13.465062141418457,
          13.468806266784668,
          11.369134902954102,
          12.854736328125,
          12.18978214263916,
          12.383943557739258,
          13.158087730407715,
          12.332196235656738,
          13.478543281555176,
          12.456894874572754,
          12.243098258972168,
          12.596424102783203,
          12.688684463500977,
          12.366033554077148,
          11.49886703491211,
          12.989477157592773,
          11.547563552856445,
          13.140456199645996,
          12.582751274108887,
          11.959831237792969,
          12.499743461608887,
          12.631625175476074,
          14.016563415527344,
          12.748041152954102,
          12.547826766967773,
          12.78632640838623,
          13.075212478637695,
          13.160482406616211,
          13.15837287902832,
          12.36966609954834,
          12.893723487854004,
          12.502191543579102,
          13.500602722167969,
          12.466981887817383,
          11.812737464904785,
          12.520455360412598,
          13.176706314086914,
          11.375940322875977,
          12.234492301940918,
          12.580971717834473,
          12.965673446655273,
          13.101846694946289,
          13.17431926727295,
          12.987152099609375,
          12.66504192352295,
          13.12686538696289,
          12.646554946899414,
          12.555350303649902,
          14.659417152404785,
          12.997575759887695,
          13.190327644348145,
          12.039960861206055,
          11.391408920288086,
          13.514525413513184,
          12.68675708770752
         ],
         "y": [
          0.8087747693061829,
          0.6871502995491028,
          0.7407957911491394,
          1.4320582151412964,
          1.1632922887802124,
          1.8176170587539673,
          1.4504860639572144,
          1.5226131677627563,
          1.8114031553268433,
          1.1318838596343994,
          1.5058507919311523,
          0.6728518009185791,
          0.9310681819915771,
          1.4713331460952759,
          1.3702956438064575,
          2.1142332553863525,
          1.2152199745178223,
          1.9790713787078857,
          1.1315762996673584,
          1.6318378448486328,
          1.0072557926177979,
          1.211706280708313,
          0.8356477618217468,
          1.8656120300292969,
          2.284539222717285,
          0.7878627777099609,
          1.0125821828842163,
          0.6932836771011353,
          1.1931183338165283,
          1.9243571758270264,
          1.4495649337768555,
          1.2948603630065918,
          1.5341682434082031,
          2.3609511852264404,
          1.6560304164886475,
          1.4509367942810059,
          1.2781652212142944,
          1.6127907037734985,
          0.9327532649040222,
          1.422743558883667,
          1.1432771682739258,
          1.6419291496276855,
          1.984221339225769,
          2.1910479068756104,
          0.9931579828262329,
          0.8217092752456665,
          1.3238153457641602,
          1.0678116083145142,
          0.46408575773239136,
          1.53147292137146,
          1.918985366821289,
          1.4863284826278687,
          0.9336421489715576,
          2.7306175231933594,
          1.4621374607086182
         ]
        },
        {
         "hoverinfo": "text",
         "hovertext": [
          " Reformat dataframe to have a consistent '_id' column\ndf_characters['_id'] = df_characters['id']\ndf_locations['_id'] = df_locations['id']\ndf_script['_id'] = df_script['id']\ndf_episodes['_id'] = df_episodes['id']\n\n# Set the indices to '_id'\ndf_characters.set_index('_id', inplace=True)\ndf_locations.set_index('_id', inplace=True)\ndf_script.set_index('_id', inplace=True)\ndf_episodes.set_index('_id', inplace=True)",
          "Change index name for better consistency\ndf_characters.index.name = 'character_id'\ndf_locations.index.name = 'location_id'\ndf_episodes.index.name = 'episode_id'\ndf_script.index.name = 'line_id'",
          "Set the `index` of each DataFrame to the `id` column\ndf_characters.set_index('id', inplace=True)\ndf_locations.set_index('id', inplace=True)\ndf_script.set_index('id', inplace=True)\ndf_episodes.set_index('id', inplace=True)",
          "Drop the index from the DataFrames\ndf_characters.reset_index(inplace=True, drop=True)\ndf_locations.reset_index(inplace=True, drop=True)\ndf_script.reset_index(inplace=True, drop=True)\ndf_episodes.reset_index(inplace=True, drop=True)",
          "Drop the unnecessary 'index' column from each dataframe\ndf_characters.drop('index', axis=1, inplace=True)\ndf_locations.drop('index', axis=1, inplace=True)\ndf_script.drop('index', axis=1, inplace=True)\ndf_episodes.drop('index', axis=1, inplace=True)",
          " Set the character_id column as the index for the characters and locations DataFrames\ndf_characters.set_index('id', inplace=True)\ndf_locations.set_index('id', inplace=True)",
          "del df_characters['Unnamed: 0']\ndel df_locations['Unnamed: 0']\ndel df_script['Unnamed: 0']\ndel df_episodes['Unnamed: 0']",
          "Smaller samples for testing\ndf_characters = df_characters.sample(100).reset_index(drop=True)\ndf_locations = df_locations.sample(100).reset_index(drop=True)\ndf_script = df_script.sample(1000).reset_index(drop=True)\ndf_episodes = df_episodes.reset_index(drop=True)",
          "Set the 'id' column as the index for each DataFrame\ndf_characters.set_index('id', inplace=True)\ndf_locations.set_index('id', inplace=True)\ndf_episodes.set_index('id', inplace=True)\ndf_script.set_index('id', inplace=True)",
          "Set the 'id' column as the index for each DataFrame\ndf_characters.set_index('id', inplace=True)\ndf_locations.set_index('id', inplace=True)\ndf_episodes.set_index('id', inplace=True)",
          "Set index for faster searches\ndf_characters.set_index('id', inplace=True)\ndf_locations.set_index('id', inplace=True)\ndf_episodes.set_index('id', inplace=True)",
          "Ensure that 'id' field is unique for all the dataframes\nassert df_characters['id'].nunique() == len(df_characters)\nassert df_locations['id'].nunique() == len(df_locations)\nassert df_script['id'].nunique() == len(df_script)\nassert df_episodes['id'].nunique() == len(df_episodes)",
          "# Correctly identify the index column\ndf_characters = df_characters.set_index('id')\ndf_locations = df_locations.set_index('id')\ndf_script = df_script.set_index('id')\ndf_episodes = df_episodes.set_index('id')",
          " ensure every dataframe has an 'id' column\ndf_characters['id'] = df_characters.index\ndf_locations['id'] = df_locations.index\ndf_script['id'] = df_script.index\ndf_episodes['id'] = df_episodes.index",
          "Cleans up a few things first\nfor df in [df_characters, df_locations, df_script, df_episodes]:\n    if 'Unnamed: 0' in df.columns:\n        df.drop(['Unnamed: 0'], axis=1, inplace=True)",
          "Set the 'id' column as index for faster lookups\ndf_characters.set_index('id', inplace=True)\ndf_locations.set_index('id', inplace=True)\ndf_episodes.set_index('id', inplace=True)",
          "Set index accordingly\ndf_characters.set_index('character_id', inplace=True)\ndf_locations.set_index('location_id', inplace=True)\ndf_script.set_index('id', inplace=True)\ndf_episodes.set_index('id', inplace=True)",
          " make it easier to access data by using index\ndf_episodes.set_index('id', inplace=True)\ndf_script.set_index('id', inplace=True)\ndf_characters.set_index('id', inplace=True)\ndf_locations.set_index('id', inplace=True)",
          " Set pandas to use 'id' as the index for all DataFrames\ndf_characters.set_index('id', inplace=True)\ndf_locations.set_index('id', inplace=True)\ndf_script.set_index('id', inplace=True)\ndf_episodes.set_index('id', inplace=True)",
          " Set the index to the unique identifier\ndf_characters.set_index('id', inplace=True)\ndf_locations.set_index('id', inplace=True)\ndf_episodes.set_index('id', inplace=True)\ndf_script.set_index('id', inplace=True)",
          "Remove column containing index\ndf_episodes = df_episodes.iloc[:, 1:]",
          "Manually set the index to the 'id' field\ndf_characters.set_index('id', inplace=True)\ndf_locations.set_index('id', inplace=True)\ndf_script.set_index('id', inplace=True)\ndf_episodes.set_index('id', inplace=True)",
          "Set the index of the datasets to the unique id of the associated elements\ndf_characters.set_index('id', inplace=True)\ndf_locations.set_index('id', inplace=True)\ndf_episodes.set_index('id', inplace=True)\ndf_script.set_index('id', inplace=True)",
          "Update index and print shapes\ndf_characters.reset_index(inplace=True, drop=True)\ndf_locations.reset_index(inplace=True, drop=True)\ndf_script.reset_index(inplace=True, drop=True)\ndf_episodes.reset_index(inplace=True, drop=True)\n\n# Print shapes\nprint(df_characters.shape)\nprint(df_locations.shape)\nprint(df_script.shape)\nprint(df_episodes.shape)",
          "Set the 'id' column as the index for each dataframe\ndf_characters.set_index('id', inplace=True)\ndf_locations.set_index('id', inplace=True)\ndf_script.set_index('id', inplace=True)\ndf_episodes.set_index('id', inplace=True)",
          "  Drop first column from all dataframes\ndf_characters = df_characters.iloc[:,1:]\ndf_locations = df_locations.iloc[:,1:]\ndf_script = df_script.iloc[:,1:]\ndf_episodes = df_episodes.iloc[:,1:]",
          "Set index to take full use of Pandas functionalities\ndf_characters.set_index('id', inplace=True)\ndf_locations.set_index('id', inplace=True)\ndf_script.set_index('id', inplace=True)\ndf_episodes.set_index('id', inplace=True)",
          "Delete the first column\ndf_characters = df_characters.iloc[:, 1:]\ndf_locations = df_locations.iloc[:, 1:]\ndf_script = df_script.iloc[:, 1:]\ndf_episodes = df_episodes.iloc[:, 1:]",
          " Set index to 'id' for all dataframes\ndf_script.set_index('id', inplace=True)\ndf_characters.set_index('id', inplace=True)\ndf_locations.set_index('id', inplace=True)\ndf_episodes.set_index('id', inplace=True)",
          "Set the 'id' column as index for easier access\ndf_characters.set_index('id', inplace=True)\ndf_locations.set_index('id', inplace=True)\ndf_script.set_index('id', inplace=True)\ndf_episodes.set_index('id', inplace=True)",
          "Check/Reset Index\ndf_characters = df_characters.reset_index(inplace=False, drop=True)\ndf_locations = df_locations.reset_index(inplace=False, drop=True)\ndf_script = df_script.reset_index(inplace=False, drop=True)\ndf_episodes = df_episodes.reset_index(inplace=False, drop=True)",
          "Set index for fast row selection and filtering\ndf_characters.set_index('id', inplace=True)\ndf_locations.set_index('id', inplace=True)\ndf_episodes.set_index('id', inplace=True)\ndf_script.set_index('id', inplace=True)",
          " Add dummy index to unique identify rows in the original dataframes\ndf_characters['orig_index'] = df_characters.index\ndf_locations['orig_index'] = df_locations.index\ndf_episodes['orig_index'] = df_episodes.index\ndf_script['orig_index'] = df_script.index",
          "Set index after loading the csv files\ndf_script.set_index('id',inplace=True)\ndf_characters.set_index('id', inplace=True)\ndf_locations.set_index('id',inplace=True)\ndf_episodes.set_index('id',inplace=True)",
          " Change index of all the dataframes to id of each corresponding entry\ndf_characters.set_index('id', inplace=True)\ndf_locations.set_index('id', inplace=True)\ndf_script.set_index('id', inplace=True)\ndf_episodes.set_index('id', inplace=True)",
          "Set consistent index name for all datasets\ndf_script.index.name = 'script_index'\ndf_locations.index.name = 'location_index'\ndf_characters.index.name = 'character_index'\ndf_episodes.index.name = 'episode_index'",
          "# Add index in each dataframe\ndf_characters.index.name = 'character_id'\ndf_locations.index.name = 'location_id'\ndf_script.index.name = 'line_id'\ndf_episodes.index.name = 'episode_id'",
          " remove 'id' column which is equivalent to the index\ndf_characters.drop('id',axis=1,inplace=True)\ndf_locations.drop('id',axis=1,inplace=True)\ndf_script.drop('id',axis=1,inplace=True)\ndf_episodes.drop('id',axis=1,inplace=True)",
          "# Reset index for all df except df_script\ndf_characters = df_characters.reset_index(inplace=False, drop=True)\ndf_locations = df_locations.reset_index(inplace=False, drop=True)\ndf_episodes = df_episodes.reset_index(inplace=False, drop=True)",
          "Remove the first index column from DataFrames\ndf_episodes = df_episodes.iloc[:,1:]\ndf_characters = df_characters.iloc[:,1:]\ndf_locations = df_locations.iloc[:,1:]\ndf_script = df_script.iloc[:,1:]",
          " Set index for faster access\ndf_characters.set_index('id', inplace=True)\ndf_locations.set_index('id', inplace=True)\ndf_episodes.set_index('id', inplace=True)",
          " Remove extra index column from dataframes\ndf_characters = df_characters.iloc[:,1:]\ndf_locations = df_locations.iloc[:,1:]\ndf_script = df_script.iloc[:,1:]\ndf_episodes = df_episodes.iloc[:,1:]",
          " Check that location_id and episode_id are meaningful indices\nprint(df_locations.index)\nprint(df_episodes.index)",
          "Set the index for optimal merge and search performance\ndf_characters.set_index('id', inplace=True)\ndf_locations.set_index('id', inplace=True)\ndf_episodes.set_index('id', inplace=True)",
          "set index to unique keys\ndf_characters = df_characters.set_index('id')\ndf_locations = df_locations.set_index('id')\ndf_script = df_script.set_index('id')\ndf_episodes = df_episodes.set_index('id')",
          "We'll use the 'episode_id' field as index for every dataframe\ndf_characters.set_index('episode_id', inplace=True)\ndf_locations.set_index('episode_id', inplace=True)\ndf_script.set_index('episode_id', inplace=True)\ndf_episodes.set_index('id', inplace=True)",
          " Set index of dataframe to id column\ndf_characters.set_index('id', inplace=True)\ndf_locations.set_index('id', inplace=True)\ndf_episodes.set_index('id', inplace=True)",
          " Create an index for quicker lookup\ndf_characters.set_index('id', inplace=True)\ndf_locations.set_index('id', inplace=True)\ndf_episodes.set_index('id', inplace=True)",
          " Remove 'id' column from all DataFrames\ndf_characters.drop(columns=['id'], inplace=True)\ndf_locations.drop(columns=['id'], inplace=True)\ndf_script.drop(columns=['id'], inplace=True)\ndf_episodes.drop(columns=['id'], inplace=True)",
          "Setting \"Unnamed: 0\" as index for all dataframes\ndf_characters.index = df_characters['Unnamed: 0']\ndf_locations.index = df_locations['Unnamed: 0']\ndf_script.index = df_script['Unnamed: 0']\ndf_episodes.index = df_episodes['Unnamed: 0']",
          "Setting the index for easier data retrieval and searches\ndf_characters.set_index('id', inplace=True)\ndf_locations.set_index('id', inplace=True)\ndf_episodes.set_index('id', inplace=True)",
          " Set id as index\ndf_characters.set_index('id', inplace=True)\ndf_locations.set_index('id', inplace=True)\ndf_episodes.set_index('id', inplace=True)\ndf_script.set_index('id', inplace=True)",
          "Clean the dataframes from potentially corrupted rows\ndf_script = df_script.dropna(subset=['character_id', 'location_id', 'id']).reset_index(inplace=False, drop=True)\ndf_episodes = df_episodes.dropna(subset=['id', 'original_air_date']).reset_index(inplace=False, drop=True)",
          "Set the index appropriately for each DataFrame\ndf_characters.set_index(\"id\", inplace=True)\ndf_locations.set_index(\"id\", inplace=True)\ndf_episodes.set_index(\"id\", inplace=True)\ndf_script.set_index(\"id\", inplace=True)",
          "Set the 'id' column as the index for each dataframe\ndf_characters.set_index('id', inplace=True)\ndf_locations.set_index('id', inplace=True)\ndf_script.set_index('id', inplace=True)\ndf_episodes.set_index('id', inplace=True)"
         ],
         "marker": {
          "opacity": 0.5,
          "size": 5
         },
         "mode": "markers+text",
         "name": "27_Dataframe Index and Column Transformation",
         "text": [
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          ""
         ],
         "textfont": {
          "size": 12
         },
         "type": "scattergl",
         "x": [
          2.784069061279297,
          3.26401948928833,
          2.583111047744751,
          3.143320322036743,
          3.2770698070526123,
          3.5142996311187744,
          4.181556224822998,
          3.5625476837158203,
          2.3893840312957764,
          2.909475803375244,
          3.282362461090088,
          3.021803379058838,
          3.0508172512054443,
          2.8756608963012695,
          3.9837639331817627,
          3.090808391571045,
          2.8710997104644775,
          2.7883288860321045,
          2.615098476409912,
          2.6578967571258545,
          3.6205923557281494,
          2.5078983306884766,
          2.3546700477600098,
          3.2655370235443115,
          2.671823740005493,
          3.491659641265869,
          2.6144859790802,
          3.420930862426758,
          2.555687427520752,
          2.6167376041412354,
          3.454026222229004,
          2.7890725135803223,
          2.431896209716797,
          2.166332721710205,
          2.6631698608398438,
          3.1509525775909424,
          3.1778345108032227,
          3.508185863494873,
          3.541217565536499,
          3.5109264850616455,
          2.949354410171509,
          3.276151180267334,
          2.949368715286255,
          3.217217206954956,
          3.0406014919281006,
          2.8973371982574463,
          3.061896800994873,
          2.988426685333252,
          3.586069107055664,
          3.443640947341919,
          3.1697514057159424,
          2.5692026615142822,
          4.040643692016602,
          2.569011926651001,
          2.754401683807373
         ],
         "y": [
          5.094765663146973,
          4.3764567375183105,
          4.7064313888549805,
          4.194234848022461,
          4.464869976043701,
          6.355252265930176,
          3.725029230117798,
          4.8514180183410645,
          4.613972187042236,
          5.026772499084473,
          3.3883018493652344,
          5.063963890075684,
          4.812560081481934,
          4.4738335609436035,
          4.414265155792236,
          3.4068377017974854,
          4.18333101272583,
          4.018765926361084,
          4.987891674041748,
          4.030632495880127,
          4.428308486938477,
          4.365354537963867,
          4.268104553222656,
          4.5341596603393555,
          5.100341320037842,
          4.554091453552246,
          4.298064708709717,
          4.3141069412231445,
          4.5053815841674805,
          4.215767860412598,
          4.632728576660156,
          3.9057836532592773,
          4.110715866088867,
          3.88399076461792,
          4.4205522537231445,
          3.8042125701904297,
          4.552589416503906,
          4.515686511993408,
          4.806241989135742,
          3.9962644577026367,
          3.594470739364624,
          4.352821350097656,
          4.680339336395264,
          3.676516056060791,
          4.783156394958496,
          4.920447826385498,
          4.723774433135986,
          3.6432793140411377,
          4.940341949462891,
          3.9347734451293945,
          4.0609917640686035,
          4.0726799964904785,
          5.015810012817383,
          4.423429012298584,
          5.0988359451293945
         ]
        },
        {
         "hoverinfo": "text",
         "hovertext": [
          "Checkin some dataframes basic info\ndf_characters.info(), df_locations.info(), df_script.info(), df_episodes.info()",
          "Print basic info on each dataframe\nprint(\"Characters\")\nprint(df_characters.info())\nprint(\"Locations\")\nprint(df_locations.info())\nprint(\"Script Lines\")\nprint(df_script.info())\nprint(\"Episodes\")\nprint(df_episodes.info())",
          " Print info of the datasets\nprint('Characters:')\nprint(df_characters.info())\nprint()\nprint('Locations:')\nprint(df_locations.info())\nprint()\nprint('Script:')\nprint(df_script.info())",
          "Display some information about the datasets\nprint(\"Characters info:\")\nprint(df_characters.info())\nprint(\"\\nLocations info:\")\nprint(df_locations.info())\nprint(\"\\nScript info:\")\nprint(df_script.info())\nprint(\"\\nEpisodes info:\")\nprint(df_episodes.info())",
          "Dataset information\nprint(df_characters.info())\nprint(df_locations.info())\nprint(df_script.info())\nprint(df_episodes.info())",
          "Display some basic information about the datasets\nprint('Characters')\nprint(df_characters.info())\nprint(df_characters.head())\nprint()\nprint('Locations')\nprint(df_locations.info())\nprint(df_locations.head())\nprint()\nprint('Script')\nprint(df_script.info())\nprint(df_script.head())\nprint()\nprint('Episodes')\nprint(df_episodes.info())\nprint(df_episodes.head())",
          " Display data details\ndf_characters.info()\ndf_locations.info()\ndf_script.info()\ndf_episodes.info()",
          " Evaluating data quality\ndf_characters.info(), df_locations.info(), df_script.info(), df_episodes.info()",
          "Print a summary of the data in each DataFrame\nprint('Characters:')\nprint(df_characters.info())\nprint('\\nLocations:')\nprint(df_locations.info())\nprint('\\nScript:')\nprint(df_script.info())\nprint('\\nEpisodes:')\nprint(df_episodes.info())",
          "View information of key tables\nprint('Characters')\ndisplay(df_characters.info())\ndisplay(df_characters.head())\n\nprint('Locations')\ndisplay(df_locations.info())\ndisplay(df_locations.head())",
          "We have the following dataframes available:\n# - df_characters: Information about the characters\n# - df_locations: Information about the locations\n# - df_script: Information about the script lines\n# - df_episodes: Information about the episodes",
          "Display basic information of each dataframe\n[df.info() for df in [df_characters, df_locations, df_script, df_episodes]]",
          " Display basic information about the datasets\nprint(df_characters.info())\nprint(df_locations.info())\nprint(df_script.info())\nprint(df_episodes.info())",
          "Display basic information about the dataframes\nprint('\\n---Characters---')\nprint(df_characters.info())\nprint(df_characters.head())\n\nprint('\\n---Locations---')\nprint(df_locations.info())\nprint(df_locations.head())\n\nprint('\\n---Script---')\nprint(df_script.info())\nprint(df_script.head())\n\nprint('\\n---Episodes---')\nprint(df_episodes.info())\nprint(df_episodes.head())",
          "Print basic info for each dataframe\nprint(\"Characters Dataset:\")\nprint(df_characters.info())\n\nprint(\"\\nLocations Dataset:\")\nprint(df_locations.info())\n\nprint(\"\\nScript Dataset:\")\nprint(df_script.info())\n\nprint(\"\\nEpisodes Dataset:\")\nprint(df_episodes.info())",
          " Profiling of data\nprint(\"Episodes\"); df_episodes.info()\nprint(\"\\nLocations\"); df_locations.info()\nprint(\"\\nCharacters\"); df_characters.info()\nprint(\"\\nScript\"); df_script.info()",
          " Display general information about the datasets\ndf_characters.info()\ndf_locations.info()\ndf_script.info()\ndf_episodes.info()",
          "Display the basic information about datasets\nprint(\"\\n- Simpsons Episodes - \")\nprint(df_episodes.info())\nprint(\"\\n- Simpsons Characters - \")\nprint(df_characters.info())\nprint(\"\\n- Simpsons Locations - \")\nprint(df_locations.info())\nprint(\"\\n- Simpsons Scripts - \")\nprint(df_script.info())",
          " Inspect DataFrame details\nprint(\"\\n\\n==== Characters ====\")\nprint(df_characters.info())\n\nprint(\"\\n\\n==== Locations ====\")\nprint(df_locations.info())\n\nprint(\"\\n\\n==== Episodes ====\")\nprint(df_episodes.info())\n\nprint(\"\\n\\n==== Script Lines ====\")\nprint(df_script.info())",
          " Display some general information about the datasets\nprint('Characters\\n')\nprint(df_characters.info())\nprint(df_characters.head())\nprint('\\nLocations\\n')\nprint(df_locations.info())\nprint(df_locations.head())\nprint('\\nScript\\n')\nprint(df_script.info())\nprint(df_script.head())\nprint('\\nEpisodes\\n')\nprint(df_episodes.info())\nprint(df_episodes.head())",
          " Show info for each dataframe\ndf_characters.info()\ndf_locations.info()\ndf_script.info()\ndf_episodes.info()",
          " Display general information about the datasets\nprint(\"Characters Data:\")\ndisplay(df_characters.info())\ndisplay(df_characters.head(3))\n\nprint(\"\\nLocations Data:\")\ndisplay(df_locations.info())\ndisplay(df_locations.head(3))\n\nprint(\"\\nScript Data:\")\ndisplay(df_script.info())\ndisplay(df_script.head(3))\n\nprint(\"\\nEpisodes Data:\")\ndisplay(df_episodes.info())\ndisplay(df_episodes.head(3))",
          "Inspect structure of each DataFrame\ndf_characters.info(), df_locations.info(), df_script.info(), df_episodes.info()",
          " Quick look at the data\nprint(df_characters.info())\nprint(df_locations.info())\nprint(df_script.info())\nprint(df_episodes.info())",
          "View dataframe info\nprint(df_characters.info())\nprint(df_locations.info())\nprint(df_script.info())\nprint(df_episodes.info())",
          "Some lines exploration\nprint(df_characters.info())\nprint(df_locations.info())",
          "Display general information about the datasets\nprint('[INFO] Characters')\ndf_characters.info()\nprint('\\n[INFO] Locations')\ndf_locations.info()\nprint('\\n[INFO] Script')\ndf_script.info()\nprint('\\n[INFO] Episodes')\ndf_episodes.info()",
          "Get some info of datas\nprint(df_characters.info())\nprint(df_locations.info())",
          "# Check the structure of the dataframes\nprint(df_characters.info())\nprint(df_locations.info())\nprint(df_script.info())\nprint(df_episodes.info())",
          " Print some information about the obtained datasets\nprint(\"Characters:\")\nprint(df_characters.info())\nprint(\"\\n_________________________\\nLocations:\")\nprint(df_locations.info())\nprint(\"\\n_________________________\\nScript:\")\nprint(df_script.info())\nprint(\"\\n_________________________\\nEpisodes:\")\nprint(df_episodes.info())",
          " View dataframe structure\nprint(df_characters.info())\nprint(df_locations.info())\nprint(df_script.info())\nprint(df_episodes.info())",
          "ECOMMENDATION_ID: rQs3QxgK\n# We get basic information about thtdf_characters.info()e datasets to know what we are dealing with\nprint('Characters:', df_characters.info())\n# print('Locations:', df_locations.info())\n# print('Script lines:', df_script.info())\n# print('Episodes:', df_episodes.info())",
          "Check dataframes information\nprint(df_characters.info())\nprint(df_locations.info())\nprint(df_script.info())\nprint(df_episodes.info())",
          "Print info about each dataframe\nprint('Characters:')\nprint(df_characters.info())\n\nprint('Locations:')\nprint(df_locations.info())\n\nprint('Script:')\nprint(df_script.info())\n\nprint('Episodes:')\nprint(df_episodes.info())",
          " Display some information about the datasets\nprint(\"\\nInformation about the dataset - Characters\")\ndf_characters.info()\n\nprint(\"\\n\\nInformation about the dataset - Locations\")\ndf_locations.info()\n\nprint(\"\\n\\nInformation about the dataset - Script lines\")\ndf_script.info()\n\nprint(\"\\n\\nInformation about the dataset - Episodes\")\ndf_episodes.info()",
          " show schema of characters\nprint(df_characters.dtypes)\nprint(df_characters.head())\n\n# show schema of locations\nprint(df_locations.dtypes)\nprint(df_locations.head())",
          " Print out a summary of each dataset\nprint(\"Characters:\")\nprint(df_characters.info())\n\nprint(\"\\nLocations\")\nprint(df_locations.info())\n\nprint(\"\\nScript\")\nprint(df_script.info())\n\nprint(\"\\nEpisodes\")\nprint(df_episodes.info())",
          "# Print the dataframes information to have a better understanding of their structure\nprint(df_characters.info())\nprint(df_locations.info())\nprint(df_script.info())\nprint(df_episodes.info())",
          " Quick overview of the characters dataset\nprint(df_characters.head())\n\n# Quick overview of the locations dataset\nprint(df_locations.head())\n\n# Quick overview of the script dataset\nprint(df_script.head())\n\n# Quick overview of the episodes dataset\nprint(df_episodes.head())",
          "Display basic information for each DataFrame\nprint(\"Characters DataFrame\")\ndf_characters.info()\nprint(\"Locations DataFrame\")\ndf_locations.info()\nprint(\"Script DataFrame\")\ndf_script.info()\nprint(\"Episodes DataFrame\")\ndf_episodes.info()",
          " Display basic information on the datasets\nprint(\"Characters Dataset\\n\")\nprint(df_characters.head())\nprint(\"\\n-------------------------------------\\n\")\nprint(\"Locations Dataset\\n\")\nprint(df_locations.head())\nprint(\"\\n-------------------------------------\\n\")\nprint(\"Script Dataset\\n\")\nprint(df_script.head())\nprint(\"\\n-------------------------------------\\n\")\nprint(\"Episodes Dataset\\n\")\nprint(df_episodes.head())",
          " Quick look at each dataframe\nprint('Characters')\nprint(df_characters.info())\nprint(df_characters.head(2))\n\nprint('Locations')\nprint(df_locations.info())\nprint(df_locations.head(2))",
          "Show content of each dataset\nprint(\"\\n[INFO] Show content of each data set.\")\nprint(\"\\n[INFO] 1. Simpsons characters.\")\nprint(df_characters.head())\nprint(\"\\n[INFO] 2. Simpsons locations.\")\nprint(df_locations.head())\nprint(\"\\n[INFO] 3. Simpsons episodes.\")\nprint(df_episodes.head())\nprint(\"\\n[INFO] 4. Simpsons script.\")\nprint(df_script.head())",
          " Display some info\ndf_characters.info()\ndf_locations.info()\ndf_script.info()\ndf_episodes.info()",
          "Show summary\nprint(df_characters.info())\nprint(df_locations.info())\nprint(df_script.info())\nprint(df_episodes.info())",
          " Display some basic information about our datasets\nprint(\"Characters:\")\nprint(df_characters.info())\nprint(df_characters.head())\nprint()\nprint(\"Locations:\")\nprint(df_locations.info())\nprint(df_locations.head())\nprint()\nprint(\"Script:\")\nprint(df_script.info())\nprint(df_script.head())\nprint()\nprint(\"Episodes:\")\nprint(df_episodes.info())\nprint(df_episodes.head())",
          "View general information of the datasets\nprint(df_characters.info())\nprint(df_locations.info())\nprint(df_script.info())\nprint(df_episodes.info())",
          "View some data info\nprint('Characters info')\nprint(df_characters.info())\n\nprint('\\n-------------------\\n')\nprint('Locations info')\nprint(df_locations.info())\n\nprint('\\n-------------------\\n')\nprint('Script info')\nprint(df_script.info())\n\nprint('\\n-------------------\\n')\nprint('Episodes info')\nprint(df_episodes.info())",
          " Quick view on the Simpsons Dataset\nprint(\"Characters' dataset:\")\nprint(df_characters.head())\nprint(\"\\nLocations' dataset:\")\nprint(df_locations.head())\nprint(\"\\nEpisodes' dataset:\")\nprint(df_episodes.head())\nprint(\"\\nScript' dataset:\")\nprint(df_script.head())",
          "View statistics of all DataFrames\nprint(\"\\n- Springfield's Data -\")\nprint(\"\\n- Characters -\\n\", df_characters.info())\nprint(\"\\n- Locations -\\n\", df_locations.info())\nprint(\"\\n- Episodes -\\n\", df_episodes.info())\nprint(\"\\n- Scripts -\\n\", df_script.info())",
          "Quickly show basic information for each data frame\nprint('characters:')\nprint(df_characters.info())\nprint('locations:')\nprint(df_locations.info())\nprint('script:')\nprint(df_script.info())\nprint('episodes:')\nprint(df_episodes.info())",
          "Display general information of the datasets\nprint('Characters dataset')\nprint(df_characters.info())\nprint(df_characters.head())\nprint('\\nLocations dataset')\nprint(df_locations.info())\nprint(df_locations.head())",
          "Obtain a high-level overview of the dataset\nprint(\"Characters dataset\")\nprint(df_characters.info())\n\nprint(\"Locations dataset\")\nprint(df_locations.info())\n\nprint(\"Script dataset\")\nprint(df_script.info())\n\nprint(\"Episodes dataset\")\nprint(df_episodes.info())",
          "Inspect the data types and missing values for each dataframe\nprint(df_characters.info())\nprint(df_locations.info())\nprint(df_script.info())\nprint(df_episodes.info())"
         ],
         "marker": {
          "opacity": 0.5,
          "size": 5
         },
         "mode": "markers+text",
         "name": "28_Displaying Dataset Information",
         "text": [
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          ""
         ],
         "textfont": {
          "size": 12
         },
         "type": "scattergl",
         "x": [
          -0.2339424043893814,
          0.11548926681280136,
          0.21175448596477509,
          0.49768099188804626,
          0.5545528531074524,
          -0.0204779002815485,
          -0.124634750187397,
          -0.5109909176826477,
          0.581092357635498,
          0.15880346298217773,
          0.5460432767868042,
          0.3446647524833679,
          0.33145132660865784,
          -0.16393689811229706,
          0.31403446197509766,
          0.11030048131942749,
          0.3812026083469391,
          0.23911507427692413,
          -0.08932315558195114,
          0.062275130301713943,
          0.41587305068969727,
          -0.03184965252876282,
          -0.06839149445295334,
          0.27969586849212646,
          0.3259279429912567,
          0.4675542116165161,
          -0.17255966365337372,
          0.5392019152641296,
          0.07414126396179199,
          0.2141529768705368,
          0.6358652710914612,
          -0.12568211555480957,
          0.22117982804775238,
          0.5065770149230957,
          0.16586557030677795,
          0.16028724610805511,
          0.32116565108299255,
          -0.23143474757671356,
          -0.8698492646217346,
          0.1742563247680664,
          -0.4931545853614807,
          0.6064234972000122,
          0.10189152508974075,
          0.3044971227645874,
          0.569337785243988,
          0.17935720086097717,
          -0.02453574538230896,
          0.3604015111923218,
          -0.011141432449221611,
          -0.1938295066356659,
          0.3307240307331085,
          0.34820204973220825,
          -0.1352907121181488,
          1.271924614906311
         ],
         "y": [
          1.8204057216644287,
          2.4684038162231445,
          3.013025999069214,
          2.492826461791992,
          2.3387746810913086,
          2.62257981300354,
          2.3485107421875,
          1.7325711250305176,
          2.7424182891845703,
          3.6584079265594482,
          2.5028908252716064,
          2.4382925033569336,
          2.2467055320739746,
          2.8244192600250244,
          2.430755376815796,
          2.557752847671509,
          2.3381242752075195,
          2.1935155391693115,
          3.100369453430176,
          2.6119167804718018,
          2.346329689025879,
          2.508232355117798,
          1.9035710096359253,
          1.8225092887878418,
          2.0551650524139404,
          3.4079809188842773,
          1.9088798761367798,
          3.1965160369873047,
          1.736861228942871,
          2.7232537269592285,
          2.030973196029663,
          2.187981367111206,
          1.7270845174789429,
          2.1350879669189453,
          2.4864189624786377,
          3.145673990249634,
          2.894460439682007,
          2.1219942569732666,
          2.381277084350586,
          2.2384238243103027,
          2.950800895690918,
          3.8348371982574463,
          2.0657668113708496,
          2.469125270843506,
          2.4781126976013184,
          2.702397346496582,
          2.4642245769500732,
          2.51108717918396,
          1.6233280897140503,
          1.961032748222351,
          2.2244999408721924,
          3.317039966583252,
          2.0684092044830322,
          1.6305917501449585
         ]
        },
        {
         "hoverinfo": "text",
         "hovertext": [
          "Check for null values in each dataframe\ndf_characters.isnull().sum()",
          " Check for nulls\nprint(df_script.isnull().sum())",
          "Get some information on each dataframe (i.e., data types and non-null values)",
          "# Checking for missing lines\n(df_script.isnull().sum() / len(df_script)) * 100",
          "Check if the script dataframe contains duplicate rows\nprint(f\"Number of duplicate rows in script dataframe: {df_script.duplicated().sum()}\")",
          "Check for null values in the dataframe",
          "check for null values",
          "Check if there are any NULL or empty rows in the script data\nprint(df_script.isnull().sum())",
          "check the number of null values in each column of the df_script dataframe\ndf_script.isnull().sum()",
          "Check for missing data\ndf_characters.isnull().sum()",
          " Check the character dataframe for NaN values\nprint(df_characters.isna().sum())",
          "Check for missing and null values\ndf_script.isnull().sum()",
          "Check to see if there are any missing values in the datasets\ndf_characters.isna().sum()",
          "方法\ndef missing_values_table(df):\n    mis_val = df.isnull().sum()\n    mis_val_percent = 100 * df.isnull().sum() / len(df)\n    mis_val_table = pd.concat([mis_val, mis_val_percent], axis=1)\n    mis_val_table_ren_columns = mis_val_table.rename(\n    columns = {0 : 'Missing Values', 1 : '% of Total Values'})\n    mis_val_table_ren_columns = mis_val_table_ren_columns[\n        mis_val_table_ren_columns.iloc[:,1] != 0].sort_values(\n    '% of Total Values', ascending=False).round(1)\n    print (\"Your selected dataframe has \" + str(df.shape[1]) + \" columns.\\n\"      \n        \"There are \" + str(mis_val_table_ren_columns.shape[0]) +\n          \" columns that have missing values.\")\n    return mis_val_table_ren_columns",
          "# Display the number of missing values in the script DataFrame\nprint(df_script.isnull().sum())",
          "Check for missing data\ndf_script.isnull().sum()",
          "Check missing values and df size",
          "Check for null values\nprint(df_script.isnull().sum())",
          "# Check for missing data\ndf_script.isnull().sum()",
          "Show missing values again\ndf_script.isnull().sum()",
          "Checking for any null values \ndf_script.isnull().sum()",
          "Count the number of non-null values in each column of the dataframe\ndf_script.info()",
          "Sanitizing script\ndf_script.isnull().sum()",
          "Check the number of missing values in each column\ndf_script.isnull().sum()",
          "Brief exploration and cleaning\n(df_script['timestamp_in_ms'].notna()).sum()",
          "Check for missing values\nmissing_values_df = pd.DataFrame(df_script.isnull().sum(), columns=['missing values'])\nmissing_values_df['percentage'] = round(missing_values_df['missing values'] / df_script.shape[0] * 100, 2)\nmissing_values_df = missing_values_df[missing_values_df['missing values'] > 0]\nmissing_values_df = missing_values_df.sort_values(by='missing values', ascending=False)\n\nmissing_values_df",
          "Check for missing values in the characters dataframe\ndf_characters.isnull().sum()",
          "Check missing values\ndf_script.isnull().sum()",
          "Check for missing values\ndf_script.isna().sum()",
          "Check integrity of the datasets\nprint(\"Checking Characters DataFrame...\")\nprint(df_characters.isnull().sum())",
          "Count the number of missing values in each column of df_script\ndf_script.isnull().sum()",
          "Check for missing values\ndf_script.isnull().sum()",
          "Check for null values in the dataframes\ndf_characters.isnull().sum()",
          " Check missing values in the dataset\ndf_script.isna().sum()",
          "check for missing values\ndf_script.isnull().sum()",
          "Inspect dataset for missing values\ndf_script.isna().sum()",
          "Check for missing data\ndf_script.isnull().sum()",
          "Check whether script dataframe has null values\ndf_script.isnull().sum()",
          "Check for missing values in the datasets\nprint(df_characters.isnull().sum())",
          "Check for missing data\ndf_script.isnull().sum()",
          " Check for missing data\ndf_characters.isnull().sum()",
          "Check if null values are present in the datasets\nprint(\"Null character_birth_date: \", df_characters['character_birth_date'].isnull().values.any())",
          "Checking number of null values in each dataframe",
          "check missing data\ndf_script.isnull().sum()",
          "Checking for nulls in each dataframe",
          "check missings\ndf_script.isnull().sum()",
          "Check for missing script lines and drop them\nmissing = df_script.isnull().sum()\nprint(missing[missing > 0])",
          " Checking for missing values in the dataset\nmissing_values = df_script.isnull().sum()\nmissing_values",
          "count the null values in the dataframe\ndf_script.isnull().sum()",
          "Check for missing values in the script data\ndf_script.isnull().sum()",
          "Check for missing values\ndf_script.isna().sum()",
          "Check for any NaN values in our dataset\ndf_script.isnull().sum()",
          "Check for null values in the characters dataframe\nprint(df_characters.isnull().sum())"
         ],
         "marker": {
          "opacity": 0.5,
          "size": 5
         },
         "mode": "markers+text",
         "name": "29_Check for Missing and Null Values in DataFrame",
         "text": [
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          ""
         ],
         "textfont": {
          "size": 12
         },
         "type": "scattergl",
         "x": [
          5.184031963348389,
          5.0659260749816895,
          7.056902885437012,
          5.180816650390625,
          5.737968444824219,
          6.190464019775391,
          7.175045013427734,
          5.017548084259033,
          5.245855808258057,
          4.8336567878723145,
          4.385003089904785,
          5.5238847732543945,
          5.15100622177124,
          4.907248020172119,
          5.771976470947266,
          5.401483535766602,
          6.80607795715332,
          5.252527236938477,
          5.444941520690918,
          5.543049335479736,
          5.492856979370117,
          5.506351470947266,
          5.459467887878418,
          5.453768253326416,
          5.711551189422607,
          5.5494914054870605,
          4.544777870178223,
          5.348074436187744,
          5.844726085662842,
          4.652575492858887,
          5.654541492462158,
          5.293722629547119,
          4.975550651550293,
          6.292358875274658,
          5.316681385040283,
          6.312320232391357,
          5.599031448364258,
          5.033103942871094,
          4.503864765167236,
          5.36607027053833,
          4.909510135650635,
          4.5067267417907715,
          6.197215557098389,
          5.402559280395508,
          6.157323360443115,
          5.118945598602295,
          5.6031036376953125,
          6.311395645141602,
          5.421248912811279,
          5.631776809692383,
          5.889983654022217,
          5.970271110534668,
          4.714488506317139
         ],
         "y": [
          0.4611976742744446,
          0.16545003652572632,
          -0.47437915205955505,
          1.0853471755981445,
          0.739834189414978,
          0.04438789188861847,
          0.20872101187705994,
          0.6654060482978821,
          0.27716004848480225,
          0.6108314394950867,
          1.4577165842056274,
          0.8480718731880188,
          1.308724045753479,
          0.6221964955329895,
          0.47130197286605835,
          1.124943733215332,
          0.186545729637146,
          0.4794311225414276,
          1.046724557876587,
          0.9772785305976868,
          0.45022258162498474,
          0.028396010398864746,
          1.0011324882507324,
          0.3626693785190582,
          2.0192437171936035,
          0.6816702485084534,
          0.5232946872711182,
          0.9476661682128906,
          0.8583502173423767,
          0.9571589827537537,
          0.49089986085891724,
          0.7796372771263123,
          0.2566029727458954,
          0.5984994769096375,
          0.6823825240135193,
          0.5325718522071838,
          1.119876503944397,
          0.3116740584373474,
          0.8581361770629883,
          1.0658681392669678,
          0.8944029211997986,
          0.424106240272522,
          0.29559072852134705,
          1.2088247537612915,
          0.12106037884950638,
          0.8739593029022217,
          1.0660828351974487,
          0.7077385783195496,
          -0.06869114190340042,
          0.7638186812400818,
          0.7217651009559631,
          1.423743486404419,
          0.7670757174491882
         ]
        },
        {
         "hoverinfo": "text",
         "hovertext": [
          "Display the first 5 rows of the characters dataframe\ndf_characters.head()",
          " Display the first 5 rows of the characters dataframe\ndf_characters.head()",
          "Display the first 5 rows of the characters dataframe\ndf_characters.head()",
          "# Display the first 5 rows of the 'df_characters' dataframe\ndf_characters.head()",
          "Display the first 5 rows of the characters dataframe\ndf_characters.head()",
          "Display the first 5 rows of the characters dataframe\ndf_characters.head()",
          "Display the first 5 rows of the characters dataframe\ndf_characters.head()",
          "Display the first 5 rows of the characters dataframe\ndf_characters.head()",
          "Display the first 5 rows of the characters dataframe\ndf_characters.head()",
          " Display the first 5 rows of the characters dataframe\ndf_characters.head()",
          "Display the first 5 rows of the characters dataframe\ndf_characters.head()",
          "Display the first 5 rows of the characters dataframe\ndf_characters.head()",
          "Display the first 5 rows of the characters dataframe\ndf_characters.head()",
          "Display the first 5 rows of the characters dataframe\ndf_characters.head()",
          "Display the first 5 rows of the characters data frame\ndf_characters.head()",
          "Display the first 5 rows of the characters dataframe\ndisplay(df_characters.head(5))",
          " display the first 5 rows of the characters dataframe\ndf_characters.head()",
          "Display the first 5 rows of the characters dataframe\ndf_characters.head()",
          " Display the first 5 rows of the characters dataframe\ndf_characters.head()",
          "Display the first 5 rows of the characters dataframe\ndf_characters.head()",
          "Display the first 5 rows of the characters dataframe\ndf_characters.head()",
          "Display the first 5 rows of the characters dataframe\ndf_characters.head()",
          "Display the first 5 rows of the characters DataFrame\ndf_characters.head()",
          "Display the first 5 rows of the characters dataframe\ndf_characters.head()",
          " Display the first 5 rows of the characters DataFrame\ndf_characters.head()",
          "display the columns and first 5 rows of the characters dataframe\ndf_characters.head()",
          "Display the first 5 rows of the characters dataframe\ndf_characters.head()",
          "Display the first 5 rows of the characters dataframe\ndf_characters.head()",
          "Display the first 5 rows of the characters dataframe\ndf_characters.head()",
          "Display the first 5 rows of the characters dataframe\ndf_characters.head()",
          "Display the first 5 rows of the characters DataFrame\ndf_characters.head(5)",
          "Display the first 5 rows of the characters DataFrame\ndf_characters.head()",
          "# Display the last 5 rows of the character DataFrame\ndf_characters.tail(5)",
          "Display the first 5 rows of the characters dataframe\ndf_characters.head()",
          " 1. Display the first 5 rows for the characters dataframe\ndf_characters.head()",
          "Display the first 5 rows of the characters DataFrame\ndf_characters.head()",
          "Display the first 5 rows of the characters dataframe\ndf_characters.head()",
          " Display the first 5 rows of the characters dataframe\ndf_characters.head()",
          "Display the first 5 rows of the characters dataframe\ndf_characters.head()",
          "display the first 5 rows of the characters dataframe\ndf_characters.head()",
          "Display the first 5 rows of the characters dataframe\ndf_characters.head()",
          "Display the first 5 rows of the characters dataframe\ndf_characters.head()",
          " Display the first 5 rows of the characters dataframe\ndf_characters.head()",
          " Display the first 5 rows of the characters DataFrame\ndf_characters.head()",
          "Display the first 5 rows of the characters dataframe\ndf_characters.head()",
          "Display the first 5 rows of the characters dataframe\ndf_characters.head()",
          " Display the first 5 rows of the characters DataFrame\ndf_characters.head()",
          "display the first 5 rows of the characters dataframe\ndf_characters.head()",
          "Display the first 5 rows of the characters dataframe\ndf_characters.head()",
          " Display the first 5 rows of the characters dataframe\ndf_characters.head()",
          "return the first 5 rows in the characters DataFrame\ndf_characters.head()",
          " Display the first 5 rows of the characters dataframe\ndf_characters.head()",
          "Display the first 5 rows of the characters dataframe\ndf_characters.head()"
         ],
         "marker": {
          "opacity": 0.5,
          "size": 5
         },
         "mode": "markers+text",
         "name": "30_Display first 5 rows of characters dataframe",
         "text": [
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          ""
         ],
         "textfont": {
          "size": 12
         },
         "type": "scattergl",
         "x": [
          -4.876651287078857,
          -4.567148685455322,
          -4.667683124542236,
          -3.6602795124053955,
          -4.452928066253662,
          -4.1182861328125,
          -4.587403774261475,
          -4.346122741699219,
          -4.383382797241211,
          -4.282879829406738,
          -4.475646495819092,
          -4.745121002197266,
          -4.4690093994140625,
          -4.645187854766846,
          -4.036176681518555,
          -3.752610445022583,
          -4.363402366638184,
          -4.501490116119385,
          -4.952155590057373,
          -4.599100589752197,
          -3.9540276527404785,
          -4.475374221801758,
          -4.567525386810303,
          -4.898858070373535,
          -4.863215446472168,
          -4.045646667480469,
          -4.452686309814453,
          -4.563261985778809,
          -4.588523864746094,
          -4.266140460968018,
          -3.936324119567871,
          -4.5099077224731445,
          -2.931309700012207,
          -4.696105480194092,
          -4.899159908294678,
          -4.510221481323242,
          -4.548337936401367,
          -4.535358905792236,
          -4.59193754196167,
          -4.840561389923096,
          -4.744821071624756,
          -4.826591491699219,
          -4.708256244659424,
          -4.516496181488037,
          -4.663671016693115,
          -4.3120012283325195,
          -4.37033748626709,
          -5.0295329093933105,
          -4.993360996246338,
          -4.568533897399902,
          -3.634176254272461,
          -4.779134273529053,
          -4.356351375579834
         ],
         "y": [
          13.337578773498535,
          13.219480514526367,
          12.785597801208496,
          13.479710578918457,
          13.110746383666992,
          13.289319038391113,
          13.058789253234863,
          13.202054977416992,
          12.869930267333984,
          13.401430130004883,
          13.347908020019531,
          13.257356643676758,
          13.736371994018555,
          13.000027656555176,
          13.083763122558594,
          13.211094856262207,
          13.11178970336914,
          13.353668212890625,
          13.26366901397705,
          13.370965003967285,
          13.19458293914795,
          12.983633041381836,
          12.931427001953125,
          13.60849380493164,
          13.300660133361816,
          12.79893970489502,
          13.4635591506958,
          13.736749649047852,
          13.65986156463623,
          13.620291709899902,
          13.139269828796387,
          13.687633514404297,
          13.00448226928711,
          13.707472801208496,
          12.938995361328125,
          13.650108337402344,
          12.757732391357422,
          13.381863594055176,
          13.058887481689453,
          12.910482406616211,
          13.570696830749512,
          13.626611709594727,
          13.015202522277832,
          13.71364688873291,
          13.427678108215332,
          13.433831214904785,
          13.082534790039062,
          13.529715538024902,
          13.136489868164062,
          13.410988807678223,
          13.770499229431152,
          13.325428009033203,
          13.05457592010498
         ]
        },
        {
         "hoverinfo": "text",
         "hovertext": [
          " Limit the amount of rows displayed for better display in Jupyter notebook\npd.set_option('display.max_rows', 5)\npd.set_option('display.max_columns', 500)",
          "Set pd display options for better data visualization in Jupyter notebooks",
          "Increase pandas display\npd.set_option('display.max_columns', None)",
          " Setting up pandas display options for easy debugging",
          "Optional: Set options for pandas.",
          "# Set some display parameters for pandas\npd.set_option('display.max_columns', None)",
          "Function to display dataframes in Jupyter notebooks with a cleaner format\ndef display_df(df):\n    return df.style.hide_index()",
          "Display settings for dataframes\npd.set_option('display.max_columns', None)",
          "Set some display options for better readability of DataFrames in Jupyter notebooks\npd.set_option('display.max_columns', 60)",
          "Option configuration for pandas",
          " Set display options for pandas dataframe\npd.set_option('display.max_columns', None)",
          "Some pandas options for better display and more helpful default behaviour.\npd.set_option('display.max_columns', None)\npd.options.mode.chained_assignment = None  # default='warn'",
          "Set custom options for pandas display and read the data.",
          "Set display options for dataframes",
          " pandas will default to truncating the output, so let's change it to display the all content of DataFrames in Jupyter.\npd.set_option('display.max_colwidth', None)",
          " Set some Pandas specific options for better display\npd.set_option('display.max_columns', None)",
          " Set default pandas option\npd.set_option('display.max_columns', None)",
          " Display settings for Pandas dataframes\npd.set_option('display.max_columns', None)",
          "Some configuration for pandas and numpy\npd.set_option('display.max_columns', None)\nnp.random.seed(42)",
          "Set display options for pandas dataframes, so that we'll be able to see the entire content.",
          "Show all the available pandas options",
          "Set options for pandas\npd.set_option('display.max_columns', None)",
          "Display settings for pandas dataframes\npd.set_option('display.max_columns', None)",
          "Setting display configuration to display all columns of the DataFrames in Jupyter notebook",
          "Some settings for all the dataframe display\npd.set_option('display.max_columns', None)\npd.set_option('display.max_rows', None)",
          "Display set-up for pandas dataframe\npd.set_option('display.max_columns', None)",
          "Display pandas outputs as we expect\npd.set_option('display.max_columns', None)",
          "Extend pandas show method to improve visibility of dataframe columns in Jupyter notebooks",
          "Set the pandas display options for the presentation of the data in the Jupyter Notebook",
          "Set display options for the dataframes",
          "Jupyter notebook configuration\npd.set_option('display.max_columns', None)",
          "Optional: Set custom Pandas options for viewing better DataFrame visualizations.",
          "Set pandas options to display all columns",
          "Set options for pandas\npd.set_option('display.max_columns', None)",
          "Set the display options to properly display dataframes",
          "Set display options for pandas dataframes\npd.set_option('display.max_columns', None)\npd.set_option('display.max_rows', None)",
          " Set option to display dataframe in Jupyter\npd.set_option('display.max_columns', None)",
          "Set parameters for dataframe pretty print\npd.set_option('display.max_columns', None)",
          "Display options for pandas data frames\npd.set_option('display.max_columns', None)",
          "Set Jupyter output display options for large dataframes\npd.set_option('display.max_columns', 500)\npd.set_option('display.max_rows', 500)\npd.set_option('display.width', 1000)",
          "Customize pandas display settings\npd.set_option('display.max_columns', None)",
          "Set pandas to display in Jupyter as many columns as possible\npd.set_option('display.max_columns', None)",
          "Setting some pandas display options for better readability of dataframes",
          "Display settings for the pandas dataframe viewer in Jupyter notebooks\npd.options.display.max_columns = None\npd.options.display.max_rows = None",
          " Set pandas settings (these could also be at the top of the file)\npd.set_option('display.max_columns', None)",
          "Pandas default display options\npd.options.display.max_columns = None\npd.options.display.max_rows = None",
          "Optional: display pandas tables in notebook format",
          "Set numpy and pandas options for better display\nnp.set_printoptions(precision=2)\npd.set_option('display.max_columns',None)",
          "Display multiple dataframe side-by-side\nfrom IPython.display import display_html\ndef display_side_by_side(*args):\n    html_str=''\n    for df in args:\n        html_str+=df.to_html()\n    display_html(html_str.replace('table','table style=\"display:inline\"'), raw=True)",
          "set some pandas options for better display\npd.set_option('display.max_columns', None)",
          "Setting to display all columns in Jupyter\npd.set_option('display.max_columns', None)",
          " Beautiful display for tables\ndef display_df(df):\n    display(HTML(df.to_html()))"
         ],
         "marker": {
          "opacity": 0.5,
          "size": 5
         },
         "mode": "markers+text",
         "name": "31_Setting display options for pandas dataframes in Jupyter notebooks",
         "text": [
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          ""
         ],
         "textfont": {
          "size": 12
         },
         "type": "scattergl",
         "x": [
          21.135744094848633,
          19.884416580200195,
          21.766904830932617,
          20.75545883178711,
          20.155105590820312,
          21.74372673034668,
          19.642507553100586,
          21.295440673828125,
          20.69594955444336,
          20.293672561645508,
          21.218551635742188,
          21.32832145690918,
          20.357309341430664,
          20.88637351989746,
          21.396183013916016,
          21.758607864379883,
          21.37647247314453,
          20.74715805053711,
          21.738855361938477,
          21.278812408447266,
          20.423105239868164,
          21.395620346069336,
          20.695096969604492,
          19.88885498046875,
          21.6904354095459,
          20.8597354888916,
          21.299644470214844,
          20.133729934692383,
          19.779794692993164,
          20.741167068481445,
          21.063650131225586,
          21.0644474029541,
          20.65278434753418,
          21.27392578125,
          20.755149841308594,
          21.586040496826172,
          20.68953514099121,
          21.061283111572266,
          20.61724853515625,
          20.791370391845703,
          21.05786895751953,
          20.623458862304688,
          20.51899528503418,
          20.397165298461914,
          21.48305892944336,
          21.4112548828125,
          20.144010543823242,
          22.4345760345459,
          19.71826171875,
          21.843786239624023,
          21.029720306396484,
          19.942886352539062
         ],
         "y": [
          1.3972641229629517,
          1.8598884344100952,
          1.4631035327911377,
          2.07861590385437,
          2.0367867946624756,
          1.5671992301940918,
          2.123624801635742,
          1.2006151676177979,
          1.8314857482910156,
          2.4009158611297607,
          1.5219647884368896,
          1.5807771682739258,
          1.8043733835220337,
          1.9937204122543335,
          2.042261838912964,
          1.2749333381652832,
          1.5122216939926147,
          1.7100014686584473,
          1.7448127269744873,
          1.2150053977966309,
          1.6616472005844116,
          1.1508110761642456,
          1.6668596267700195,
          1.8714821338653564,
          0.7018871307373047,
          1.2322421073913574,
          1.5542467832565308,
          1.6188079118728638,
          2.140228748321533,
          1.9122782945632935,
          1.1658458709716797,
          1.964806318283081,
          1.007370114326477,
          1.555975317955017,
          2.0988972187042236,
          1.1125447750091553,
          1.5516918897628784,
          1.429473638534546,
          1.5838207006454468,
          1.599435567855835,
          1.6982409954071045,
          1.1211113929748535,
          2.1685447692871094,
          1.76183021068573,
          1.0925134420394897,
          1.306138277053833,
          1.671925663948059,
          1.3528610467910767,
          2.1841444969177246,
          1.4039158821105957,
          1.0014429092407227,
          1.7863473892211914
         ]
        },
        {
         "hoverinfo": "text",
         "hovertext": [
          " Let's take a look at the structure of the dataframes.",
          "Let's take a look at the dataframes we have to understand how we can use them.",
          "Let's first take a look at the dataframes to understand their structure and content.",
          "Create temporally sorted dataframes to facilitate the creation of animations.",
          "Let's take a look at each dataframe.",
          "Let's take a look at the dataframes we have thus far.",
          " Let's now take a quick look at the structure and contents of these dataframes.",
          "Let's take a look at the dataframes to understand their structures.",
          "Let's first take a look at these dataframes to see what information we have available.",
          "let's look at the schema of the data from each of these dataframes",
          " Let's take a look at the dataframes",
          "Let's take a quick look at the dataframes to understand their structure.",
          "Now we have the datasets loaded into DataFrames, let's take a look at each one of them.",
          " Let's take a look at the structure of these DataFrames.",
          "Let's take a look at the structure of each of the DataFrames.",
          "Let's take a look at the contents of these DataFrames.",
          "Let's take a look at the shape of each DataFrame to understand how much data we're dealing with.",
          "Preliminary analysis of the dataframes",
          "Let's take a first look at this dataframe.",
          " Let's take a look at the structure of each dataframe.",
          "Let's look at the shape and content of these DataFrames",
          " Let's take a quick look at all of our dataframes.",
          "Let's take a look at the dataframes.",
          "Take a look at the dataframes",
          " Let's take a look at the structure of these dataframes.",
          " Let's take a look at the data in each of these dataframes.",
          "Look at a statististical summary of the dataframes",
          " Let's first inspect the structure of these dataframes.",
          " Let's take a look at each of these DataFrames to better understand the data.",
          "First, let's investigate the structure of the dataframes.",
          "Let's look at the structure of each of these DataFrames.",
          "Let's take a look at the contents of these DataFrames.",
          " Let's take a closer look at the structure of the DataFrames.",
          "Let's take a look at the structure of our dataframes.",
          "Let's take a look at the dataframes to understand their structure and the type of information we have.",
          " We'll have a look first at the structure and contents of these DataFrames.",
          "Now, let's take a look at the structure and content of each of these dataframes.",
          "Let's inspect these DataFrames to understand the data better.",
          " Let's take a look at the structure of these dataframes.",
          "Let's take a look at the structure of each dataframe.",
          "To get an insight, let's first look at how the various dataframes look like.",
          " Let's have a look at the loaded dataframes.",
          "Let's take a look at our dataframes.",
          " Let's take a look at the structure of the dataframes.",
          " Let's take a look at the structure of the dataframes.",
          "Let's take a look at the dataframes to see what we're working with.",
          "Potential dataframe for results then and there.",
          " Let's take a look at the dataframes.",
          "Let's have a look at the dataframes and the structure of the data.",
          " Let's take a peek at the first few lines of each dataframe to get an idea of what we are working with.",
          "Let's see the heads of the loaded dataframes.",
          "Take a look inside the dataframes."
         ],
         "marker": {
          "opacity": 0.5,
          "size": 5
         },
         "mode": "markers+text",
         "name": "32_Understanding DataFrame Structure and Contents",
         "text": [
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          ""
         ],
         "textfont": {
          "size": 12
         },
         "type": "scattergl",
         "x": [
          8.086592674255371,
          8.332544326782227,
          8.081216812133789,
          8.881608963012695,
          9.23000717163086,
          8.573931694030762,
          8.732950210571289,
          8.464344024658203,
          8.715126037597656,
          8.836215019226074,
          8.799703598022461,
          8.395939826965332,
          8.91659164428711,
          8.448334693908691,
          8.75487995147705,
          8.871628761291504,
          9.0609130859375,
          10.226725578308105,
          8.876250267028809,
          8.624671936035156,
          9.001622200012207,
          9.241601943969727,
          8.248371124267578,
          8.459453582763672,
          8.423135757446289,
          9.041170120239258,
          8.628405570983887,
          8.57874870300293,
          9.305646896362305,
          7.966257095336914,
          8.499218940734863,
          8.562601089477539,
          8.30514144897461,
          8.600820541381836,
          8.636622428894043,
          9.029511451721191,
          8.957318305969238,
          9.485212326049805,
          8.126582145690918,
          8.760835647583008,
          8.930438041687012,
          8.85533618927002,
          8.73744010925293,
          8.258875846862793,
          8.216928482055664,
          8.604883193969727,
          9.087496757507324,
          8.335180282592773,
          8.26430892944336,
          9.363357543945312,
          9.226922035217285,
          9.019438743591309
         ],
         "y": [
          -6.405035018920898,
          -5.9304046630859375,
          -6.96073579788208,
          -5.361023902893066,
          -5.855396747589111,
          -5.932663440704346,
          -6.250969886779785,
          -6.918048858642578,
          -6.422597408294678,
          -5.9525346755981445,
          -5.898843288421631,
          -7.221604347229004,
          -5.860758304595947,
          -5.868773937225342,
          -6.241703510284424,
          -5.8628106117248535,
          -6.907940864562988,
          -5.47430944442749,
          -6.291775703430176,
          -6.261773586273193,
          -5.612814426422119,
          -6.240742206573486,
          -6.072539806365967,
          -5.422571659088135,
          -6.114763259887695,
          -6.462291240692139,
          -6.0979228019714355,
          -5.793774604797363,
          -6.234692573547363,
          -6.190727233886719,
          -5.795897960662842,
          -5.991405010223389,
          -6.559952259063721,
          -5.988999366760254,
          -6.845744609832764,
          -5.858260154724121,
          -5.802600383758545,
          -6.061972618103027,
          -5.980025291442871,
          -6.209444522857666,
          -6.027027130126953,
          -5.978942394256592,
          -6.30300760269165,
          -6.374352931976318,
          -6.304781436920166,
          -6.368048667907715,
          -5.906326770782471,
          -6.073248863220215,
          -6.148410320281982,
          -6.055115699768066,
          -6.260621070861816,
          -5.383865833282471
         ]
        },
        {
         "hoverinfo": "text",
         "hovertext": [
          "Explicitly set encoding for docstring compatibility\ndf_characters = pd.read_csv('data/simpsons_characters.csv', encoding='utf-8').reset_index(drop=True)",
          "Since 'simpsons_script_lines.csv' is very large, we're going to use the first 100000 rows for the initial analysis\ndf_script = df_script[:100000]",
          " Load previously saved data from these pickles. Uncomment if you have ran the cells above and have pickled before\n\n# df_characters = pd.read_pickle('data/pickles/characters.pkl')\n# df_locations = pd.read_pickle('data/pickles/locations.pkl')\n# df_script = pd.read_pickle('data/pickles/script.pkl')",
          "# Setting up paths\ninput_filepath = 'data/simpsons_script_lines.csv'\noutput_filepath = 'data/simpsons_preprocessed_lines.csv'",
          "Joining lines with \"\\\"\ndf_script = pd.read_csv('data/simpsons_script_lines.csv').\\\n    reset_index(inplace=False, drop=True)",
          "Set the file paths to be used\nscript_path = 'data/simpsons_script_lines.csv'\ncharacters_path = 'data/simpsons_characters.csv'\nlocations_path = 'data/simpsons_locations.csv'\nepisodes_path = 'data/simpsons_episodes.csv'",
          "During the code above, the code loads the necessary datasets using pandas and the `read_csv` function. The datasets loaded include `simpsons_characters.csv`, `simpsons_locations.csv`, `simpsons_script_lines.csv`, and `simpsons_episodes.csv`. Each dataset is read into a pandas DataFrame and then reset the index to ensure a clean, continuous index.",
          " Load smaller datasets\ndf_characters_s = pd.read_csv('data/simpsons_characters_small.csv').reset_index(inplace=False, drop=True)\ndf_locations_s = pd.read_csv('data/simpsons_locations_small.csv').reset_index(inplace=False, drop=True)\ndf_script_s = pd.read_csv('data/simpsons_script_lines_small.csv').reset_index(inplace=False, drop=True)\ndf_episodes_s = pd.read_csv('data/simpsons_episodes_small.csv').reset_index(inplace=False, drop=True)",
          "data/simpsons_script_lines.csv is represented as 'data/simpsons_script_lines.csv'",
          "As an AI model, I don't have access to the local files on your machine. However, it seems like this code snippet is reading data from CSV files into pandas DataFrames. The code is using the 'read_csv' function of pandas to read from files called 'simpsons_characters.csv', 'simpsons_locations.csv', 'simpsons_script_lines.csv', and 'simpsons_episodes.csv'. These DataFrames are then reset to have a new index.",
          "Set the paths to the datasets\nEPISODES_DATASET_PATH = \"data/simpsons_episodes.csv\"\nSCRIPT_DATASET_PATH = \"data/simpsons_script_lines.csv\"\nCHARACTERS_DATASET_PATH = \"data/simpsons_characters.csv\"\nLOCATIONS_DATASET_PATH = \"data/simpsons_locations.csv\"",
          " Load locations and main characters CSV files\ndf_locations = pd.read_csv('data/simpsons_locations.csv')\ndf_characters = pd.read_csv('data/simpsons_characters.csv')",
          "filePath = data_path + '\\simpsons_script_lines.csv'",
          "# Selection of information useful for this task\ndata = df_script[['episode_id', 'character_id', 'raw_text']]\ndata = data.dropna()  # Remove missing (NaN) data\n\n# Database with relations between characters and locations\nrelations = pd.read_csv('data/simpsons_locations.csv', usecols=['location_id', 'name'])",
          " Use the same data in data/simpsons_script_lines.csv as used before\ndf_script.head()",
          "In this code, we are importing the necessary libraries and reading the data using pandas from the given CSV files. We are resetting the index of the dataframes and storing them in the variables df_characters, df_locations, df_script, and df_episodes respectively.",
          "def load_data():\n    #  Load data\n    df_characters = pd.read_csv('data/simpsons_characters.csv').reset_index(inplace=False, drop=True)\n    df_locations = pd.read_csv('data/simpsons_locations.csv').reset_index(inplace=False, drop=True)\n    df_script = pd.read_csv('data/simpsons_script_lines.csv').reset_index(inplace=False, drop=True)\n    df_episodes = pd.read_csv('data/simpsons_episodes.csv').reset_index(inplace=False, drop=True)\n    \n    return df_characters, df_locations, df_script, df_episodes",
          " Set environment variable to specify data location\nos.environ['SIMPSONS_SCRIPT_LINE_DATA'] = 'data/simpsons_script_lines.csv'",
          "Check the content of the 'simpsons_script_lines.csv' dataset\ndf_script.head()",
          "def read_data():\n    # characters, locations, script lines, and episodes\n    df_characters = pd.read_csv('data/simpsons_characters.csv').reset_index(inplace=False, drop=True)\n    df_locations = pd.read_csv('data/simpsons_locations.csv').reset_index(inplace=False, drop=True)\n    df_script = pd.read_csv('data/simpsons_script_lines.csv').reset_index(inplace=False, drop=True)\n    df_episodes = pd.read_csv('data/simpsons_episodes.csv').reset_index(inplace=False, drop=True)\n    return df_characters, df_locations, df_script, df_episodes",
          " Ensure that the dataset has the correct encoding to avoid errors when dealing with text data\ndf_script = pd.read_csv('data/simpsons_script_lines.csv', encoding='latin1')\ndf_script.head()",
          "# Load data\ndf_characters = pd.read_csv('data/simpsons_characters.csv').reset_index(inplace=False, drop=True)\ndf_locations = pd.read_csv('data/simpsons_locations.csv').reset_index(inplace=False, drop=True)\ndf_script = pd.read_csv('data/simpsons_script_lines.csv').reset_index(inplace=False, drop=True)\ndf_episodes = pd.read_csv('data/simpsons_episodes.csv').reset_index(inplace=False, drop=True)",
          "merge the information from `simpsons_events.csv` into `simpsons_script_lines.csv`\ndf_events = pd.read_csv('data/simpsons_events.csv').reset_index(inplace=False, drop=True)",
          "# This variable stores the file paths to the csv files in the data folder\nfile_paths = {\n    'characters': 'data/simpsons_characters.csv',\n    'locations': 'data/simpsons_locations.csv',\n    'script': 'data/simpsons_script_lines.csv',\n    'episodes': 'data/simpsons_episodes.csv'\n}",
          " save the script data to disk\nscript_file = 'data/simpsons_script.csv'\n\nif not os.path.isfile(script_file):\n    print(f\"Saving script data to {script_file}\")\n    df_script.to_csv(script_file, index=False)",
          "Get the size of the files\ndf_characters_size = os.path.getsize('data/simpsons_characters.csv') / (1024 * 1024)\ndf_locations_size = os.path.getsize('data/simpsons_locations.csv') / (1024 * 1024)\ndf_script_size = os.path.getsize('data/simpsons_script_lines.csv') / (1024 * 1024)\ndf_episodes_size = os.path.getsize('data/simpsons_episodes.csv') / (1024 * 1024)",
          "Inspect the content of the \"simpsons_script_lines.csv\" dataset\ndf_script.head()",
          "Declare paths to be used\nimport_path = 'data/simpsons_script_lines.csv'\nexport_path = 'data/simpsons_script_lines_preprocessed.csv'",
          "Inspect contents of the 'simpsons_script_lines.csv' file\ndf_script.head()",
          " A small hack as PySpark expects the file to end in \".parquet\" while pandas saves it just with \".gzip\".\nfilename = 'data/simpsons_script_lines.csv.gzip'\nif not os.path.isfile(filename):\n    import shutil\n    shutil.copy('data/simpsons_script_lines.csv.gzip_temp', filename)",
          " Load dialogues set\ndf_script = pd.read_csv('data/simpsons_script_lines.csv', error_bad_lines=False)\nprint(df_script.head())",
          "Create dataframe with important informations \ndf_episodes_clean = pd.read_csv('data/cleaned_episodes.csv').reset_index(inplace=False, drop=True)",
          "def load_simpsons_datasets():\n    # Load datasets\n    df_characters = pd.read_csv('data/simpsons_characters.csv').reset_index(inplace=False, drop=True)\n    df_locations = pd.read_csv('data/simpsons_locations.csv').reset_index(inplace=False, drop=True)\n    df_script = pd.read_csv('data/simpsons_script_lines.csv').reset_index(inplace=False, drop=True)\n    df_episodes = pd.read_csv('data/simpsons_episodes.csv').reset_index(inplace=False, drop=True)\n\n    return df_characters, df_locations, df_script, df_episodes",
          "Merge characters, locations and script\ndf_episodes = pd.read_csv('data/simpsons_episodes.csv').reset_index(inplace=False, drop=True)",
          "Check the Simpsons script data\ndf_script.head()",
          "\ndf_character_ep = pd.read_csv('data/simpsons_episodes_characters.csv')",
          "Load kaggle dataset\n#df_characters = pd.read_csv('/kaggle/input/the-simpsons-dataset/simpsons_characters.csv').reset_index(inplace=False, drop=True)\n#df_locations = pd.read_csv('/kaggle/input/the-simpsons-dataset/simpsons_locations.csv').reset_index(inplace=False, drop=True)\n#df_script = pd.read_csv('/kaggle/input/the-simpsons-dataset/simpsons_script_lines.csv').reset_index(inplace=False, drop=True)\n#df_episodes = pd.read_csv('/kaggle/input/the-simpsons-dataset/simpsons_episodes.csv').reset_index(inplace=False, drop=True)",
          "fixes a bug on the simpsons script which causes an index column to be loaded.",
          "Load a large csv file in chunks for memory efficiency.\n# reading in a loop\nchunks = []\nchunksize = 10**6\nfor chunk in pd.read_csv('data/simpsons_script_lines.csv', chunksize=chunksize):\n    chunks.append(chunk)",
          " Check the content of the 'simpsons_script_lines.csv' DataFrame\ndf_script.head()",
          " Load scripts since some characters don't appear in the provided script (about 500MB)\nif os.path.isfile('data/simpsons_script_lines_sc.csv'):\n    df_script_sc = pd.read_csv('data/simpsons_script_lines_sc.csv').reset_index(inplace=False, drop=True)\nelse:\n    df_script_sc = pd.read_csv('data/simpsons_script_lines.csv').sample(frac=0.25).reset_index(drop=True)\n    df_script_sc.to_csv('data/simpsons_script_lines_sc.csv')",
          "\nprint(\"The file simpsons_script_lines.csv has loads of columns: \", *df_script.columns, \"\\n\")",
          "Load the preprocessed script as it was computed before in script_preprocessing.ipynb\ndf_script_processed = pd.read_csv('data/simpsons_script_lines_preprocessed.csv')",
          "Load the data in memory\nimport zipfile\n\nwith zipfile.ZipFile('data/simpsons.zip', 'r') as zip_ref:\n    zip_ref.extractall('data/')",
          " switch data to built-in datasets if file not found\ndf_characters = df_characters if not df_characters.empty else pd.read_csv('https://raw.githubusercontent.com/bri-bri/ydata_synopsis/main/data/simpsons_characters.csv').reset_index(inplace=False, drop=True)\ndf_locations = df_locations if not df_locations.empty else pd.read_csv('https://raw.githubusercontent.com/bri-bri/ydata_synopsis/main/data/simpsons_locations.csv').reset_index(inplace=False, drop=True)\ndf_script = df_script if not df_script.empty else pd.read_csv('https://raw.githubusercontent.com/bri-bri/ydata_synopsis/main/data/simpsons_script_lines.csv').reset_index(inplace=False, drop=True)\ndf_episodes = df_episodes if not df_episodes.empty else pd.read_csv('https://raw.githubusercontent.com/bri-bri/ydata_synopsis/main/data/simpsons_episodes.csv').reset_index(inplace=False, drop=True)",
          "Check the first few entries of the Simpsons script dataset to understand its structure and contents\ndf_script.head()",
          "Data directiory\nroot_data_dir = '/kaggle/input/the-simpsons/thesimpsons/'\n\n# Check the content of the directory\nfor root, _, files in os.walk(root_data_dir):\n    level = root.replace(root_data_dir, '').count(os.sep)\n    indent = ' ' * 4 * (level)\n    logger.info('{}{}/'.format(indent, os.path.basename(root)))\n    subindent = ' ' * 4 * (level + 1)\n    for f in files:\n        logger.info('{}{}'.format(subindent, f))",
          " Helper for production side\ndef load_all():\n    \"\"\"\n    Load datasets from the input file\n    \"\"\"\n    global df_characters, df_locations, df_script, df_episodes\n    df_characters = pd.read_csv('data/simpsons_characters.csv').reset_index(inplace=False, drop=True)\n    df_locations = pd.read_csv('data/simpsons_locations.csv').reset_index(inplace=False, drop=True)\n    df_script = pd.read_csv('data/simpsons_script_lines.csv').reset_index(inplace=False, drop=True)\n    df_episodes = pd.read_csv('data/simpsons_episodes.csv').reset_index(inplace=False, drop=True)",
          "\n# from the 'simpsons_script_lines.csv' dataset, only keeping the first 5061 rows to decrease the dataset size and uploading time\ndf_script = df_script[:5061]",
          "Add GDP data to the dataframe\ngdp_per_capita_data = pd.read_csv('data/gdp_per_capita.csv')\n\n# Set the ISO 3166-2 codes as the index to facilitate combining the datasets\ngdp_per_capita_data.set_index('Country Code', inplace=True)\n\n# Convert any special or missing values (e.g. '..') to NaN\ngdp_per_capita_data.replace('..', np.NaN, inplace=True)\n\n# Save the converted data\ngdp_per_capita_data.to_csv('data/gdp_per_capita_cleaned.csv')",
          "Check the content of the 'simpsons_script_lines.csv' file\ndf_script.head()",
          "Preprocessed dataframe from Jasper's notebook\ndf_script = pd.read_parquet('../output/script_preprocessed.parquet')"
         ],
         "marker": {
          "opacity": 0.5,
          "size": 5
         },
         "mode": "markers+text",
         "name": "33_Reading and Loading Simpsons Data into Pandas DataFrames",
         "text": [
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          ""
         ],
         "textfont": {
          "size": 12
         },
         "type": "scattergl",
         "x": [
          11.820868492126465,
          11.696866989135742,
          10.785017013549805,
          13.363741874694824,
          11.715279579162598,
          13.59274959564209,
          10.668170928955078,
          11.395054817199707,
          12.601202011108398,
          10.653404235839844,
          13.520511627197266,
          11.474868774414062,
          13.23636531829834,
          10.617212295532227,
          11.592853546142578,
          10.636370658874512,
          11.06143569946289,
          13.628010749816895,
          11.612462997436523,
          10.900909423828125,
          11.335919380187988,
          11.038900375366211,
          11.565569877624512,
          13.255517959594727,
          12.41773509979248,
          11.07513427734375,
          11.618083953857422,
          13.275934219360352,
          11.867097854614258,
          12.318772315979004,
          11.611174583435059,
          10.986008644104004,
          10.994816780090332,
          11.35344409942627,
          10.984740257263184,
          11.25479507446289,
          10.99897575378418,
          4.550197601318359,
          11.46029281616211,
          11.480138778686523,
          11.56268310546875,
          12.070240020751953,
          11.64484691619873,
          11.151823043823242,
          11.02214527130127,
          11.372797966003418,
          13.659672737121582,
          10.913941383361816,
          11.571764945983887,
          10.262048721313477,
          11.727087020874023,
          7.709115028381348
         ],
         "y": [
          2.6719229221343994,
          3.4439237117767334,
          1.9465515613555908,
          4.548198699951172,
          2.4068048000335693,
          4.517540454864502,
          2.690600872039795,
          2.4775116443634033,
          4.268767833709717,
          2.5026016235351562,
          4.236260414123535,
          2.1197736263275146,
          4.551657676696777,
          1.800299882888794,
          3.766925811767578,
          1.8242595195770264,
          2.3054111003875732,
          4.528042793273926,
          4.011523723602295,
          2.0914108753204346,
          3.30757737159729,
          2.1737754344940186,
          2.066725254058838,
          4.603488445281982,
          3.9768824577331543,
          2.2366247177124023,
          4.114710807800293,
          4.546172618865967,
          4.349234580993652,
          3.507690906524658,
          3.5818793773651123,
          1.8551422357559204,
          2.5222387313842773,
          2.0351250171661377,
          3.293349027633667,
          2.349137306213379,
          2.032822847366333,
          3.3009934425354004,
          3.404301166534424,
          3.5794448852539062,
          2.6808841228485107,
          4.252054691314697,
          3.3544437885284424,
          2.890808582305908,
          2.165212869644165,
          3.6965034008026123,
          4.7652387619018555,
          2.020357131958008,
          3.1225638389587402,
          2.4252519607543945,
          4.009213924407959,
          -2.2677366733551025
         ]
        },
        {
         "hoverinfo": "text",
         "hovertext": [
          "Check if the indexes are correct in each dataframe\ndf_characters.head()",
          "Check the characters DataFrame\ndf_characters.head()",
          "Check result for each DataFrame\ndf_characters.head()",
          "Check dataframes\ndf_characters.head()",
          "Check the head of the characters dataframe",
          "  check the data that we have available in the characters dataframe\ndf_characters.head()",
          "Check the contents of the characters dataframe for any missing or NaN values\ndf_characters.head()",
          "Checking for the head of the characters dataframe",
          " Check the head of the characters dataframe",
          "Check dataframes structure\ndf_characters.head()",
          " Check the content of the characters dataframe\ndf_characters.head()",
          "Check the structure and contents of those DataFrames\ndf_characters.head()",
          "Check the contents of the Characters dataframe\ndf_characters.head()",
          "# You can ignore this cell, it is only for checking the available attributes and methods of a pandas DataFrame\n[df_characters.",
          "Check the content of the characters dataframe\nprint(df_characters.head())",
          "Check the shape and top rows of each dataframe\ndf_characters.head(), df_characters.shape",
          "Check the resulting DataFrames\ndf_characters.head()",
          "# Checking the df_characters dataframe\ndf_characters.head()",
          "Check the contents of df_characters dataframe\ndf_characters.head()",
          "Check the contents of the characters DataFrame\ndf_characters.head()",
          "Check the content of each dataframe\ndf_characters.head()",
          "df_main_chars = df_characters[df_characters['raw_character_text'].isin(main_chars)]\ndf_main_chars.head()",
          "\n# Check dataframe head\ndf_characters.head()",
          "Check the content of the characters dataframe\ndf_characters.head()",
          "Check dataframes\ndf_characters.head()",
          " Rerun the similar code and use the head and tail commands to check the data of each dataframe individually\ndf_characters.head()",
          "Checking the dataframes\ndf_characters.head()",
          "Check the head of the characters dataframe",
          "Check the contents of the characters DataFrame\ndf_characters.head()",
          "Check the dataframes\ndf_characters.head()",
          "Check how the dataframes look\ndf_characters.head()",
          "Check dataframes structure\nprint(df_characters.head(5))",
          "Check the dataframe\ndf_characters.head()",
          " Checking out the characters DataFrame\ndf_characters.head()",
          " Check the dataframes\ndf_characters.head()",
          " Check the content of the characters dataframe\ndf_characters.head()",
          "Check the schema of the characters DataFrame\ndf_characters.head()",
          "Check the dataframes\ndf_characters.head()",
          "Check the contents of the character dataframe\ndf_characters.head()",
          "Check some content from the characters DataFrame\ndf_characters.head()",
          "Check a sample of the characters dataframe\ndf_characters.head()",
          "Check the structure of the dataframes\ndf_characters.head()",
          "Check the structure of the characters DataFrame\ndf_characters.head()",
          "Check the general structure of the dataframes\ndf_characters.head()",
          "Check df_characters columns\ndf_characters.head()",
          " Check the content of the characters dataframe\ndf_characters.head()",
          " Check the characters dataframe\ndf_characters.head()",
          "Check the content of the characters dataframe\ndf_characters.head()",
          "Check the contents of the characters dataframe\ndf_characters.head()",
          "# Check the contents of the characters DataFrame\ndf_characters.head()"
         ],
         "marker": {
          "opacity": 0.5,
          "size": 5
         },
         "mode": "markers+text",
         "name": "34_Checking Contents of DataFrame df_characters.head()",
         "text": [
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          ""
         ],
         "textfont": {
          "size": 12
         },
         "type": "scattergl",
         "x": [
          4.757733345031738,
          4.061208248138428,
          4.284896373748779,
          4.450864791870117,
          7.799408912658691,
          4.776413440704346,
          5.1465959548950195,
          7.710172176361084,
          7.581775188446045,
          4.408321857452393,
          3.929699420928955,
          5.113029479980469,
          4.136486053466797,
          5.683410167694092,
          4.601309776306152,
          4.680375099182129,
          4.476693630218506,
          4.830851078033447,
          4.530284404754639,
          4.225846290588379,
          4.558837890625,
          5.667697429656982,
          4.710063934326172,
          4.046878814697266,
          4.447148323059082,
          5.60537052154541,
          4.425785064697266,
          7.851966857910156,
          3.9860517978668213,
          4.432746410369873,
          5.031250476837158,
          4.347570419311523,
          4.458076000213623,
          4.304304599761963,
          4.515711784362793,
          3.8474082946777344,
          3.982802152633667,
          4.606197357177734,
          4.164593696594238,
          3.602166175842285,
          4.29453182220459,
          4.460218906402588,
          4.116964817047119,
          4.44821310043335,
          4.2278733253479,
          4.063708305358887,
          4.41917085647583,
          3.92093825340271,
          4.091655731201172,
          4.746167182922363
         ],
         "y": [
          13.974294662475586,
          12.871267318725586,
          13.542811393737793,
          13.303690910339355,
          16.346881866455078,
          12.734954833984375,
          12.950510025024414,
          16.102651596069336,
          16.43183708190918,
          14.134781837463379,
          12.72856616973877,
          14.12719440460205,
          12.68209171295166,
          12.489493370056152,
          13.172330856323242,
          13.29951000213623,
          13.761204719543457,
          12.81688117980957,
          12.397904396057129,
          13.001928329467773,
          13.344801902770996,
          11.210136413574219,
          13.0244779586792,
          12.866900444030762,
          13.45068359375,
          13.898200988769531,
          13.666068077087402,
          16.247114181518555,
          12.770528793334961,
          13.542512893676758,
          15.017451286315918,
          14.20936393737793,
          13.418726921081543,
          13.052701950073242,
          13.57577896118164,
          13.090021133422852,
          13.105107307434082,
          13.510531425476074,
          13.165295600891113,
          12.773490905761719,
          12.909223556518555,
          14.296721458435059,
          13.778898239135742,
          14.329377174377441,
          12.956671714782715,
          12.961750030517578,
          12.896866798400879,
          12.819351196289062,
          12.56409740447998,
          12.487639427185059
         ]
        },
        {
         "hoverinfo": "text",
         "hovertext": [
          "Now let's take a look at the first few rows of each dataframe to understand the structure and content of the data.",
          "Let's take a look at the structure of each of these DataFrames and their first few rows.",
          " Let's take a look at the columns of each dataframe and some of its rows to understand the data.",
          " The first 3 lines of this code are meant to ensure that the spacing and the output of the dataframe are as expected.",
          "Let's take a look at the first few rows of each dataframe to understand the data structure.",
          "Let's start by taking a look at the first few rows of each dataframe to understand their structure and contents.",
          "Let's take a look at the first few rows of each DataFrame to understand its structure.",
          "Let us take a look at the first few rows from each dataframe to figure out their structure.",
          "Let's examine the first few rows of each DataFrame to better understand their structure.",
          " Now, let's take a look at the first few rows of each of these DataFrames to understand their structure and the kind of data they contain.",
          "Before continuing, let's take a look at the first few rows of each dataframe to understand their structure and contents.",
          "Understand the structure of each dataframe",
          " Now let's take a look at the first few rows of each dataframe to understand their structure and contents.",
          " Now let's take a look at the first few rows of each dataframe to understand their structure and contents.",
          "Let's take a look at the first few rows of each DataFrame to understand the data's structure.",
          "Let's take a look at the first few lines of each dataframe to understand their structure and contents.",
          "Let's look at the first few rows of each of these dataframes to understand their structure and contents.",
          "Let's take a look at the first few rows of each dataframe to understand the data structure.",
          "Let's take a look at the first 5 rows of each dataframe to understand their structure.",
          "Let's look at the first few rows of each of these dataframes to understand their structure better.",
          "Let's take a look at the first few rows of each DataFrame to understand their structure.",
          "Let's check the first few rows of each DataFrame to understand its structure better.",
          "Let's check the first few rows of each dataframe to understand its structure.",
          "We'll start by taking a look at the first few rows of each of the dataframes to understand their structure and the kind of data they contain.",
          "OK, now that we have loaded the data, let's take a look at the first few rows of each dataframe to understand its structure and the kind of data we're working with.",
          "Let's take a look at the first couple of rows in each dataframe to understand the structure and content.",
          " Let's inspect the first few rows of each DataFrame to understand their structure and contents.",
          "Let's take a look at the first lines from each DataFrame to understand their structure.",
          "Let's take a look at the first few rows in each dataframe to understand the data structure.",
          "Let's have a look at the first few rows of each DataFrame to understand their structure.",
          " Let's take a look at the first few rows of each DataFrame to understand their structure and contents.",
          "Let's take a look at the first rows of each dataframe to understand what data is available:",
          "Let's inspect the first few rows of each of these DataFrames to understand their structure and content.",
          " Let's take a look at the first few rows of each dataframe to understand their structure and contents.",
          "Let's take a look at the structure and first few rows of each DataFrame.",
          "Let's take a look at the structure of each of the dataframes by printing the first few rows.",
          "First, let's take a look at the first few rows of each DataFrame to understand their structure.",
          " Let's take a look at the first few rows of each dataframe to understand their structure and contents.",
          " Let's take a look at the first few rows of each DataFrame to understand the structure of the data.",
          "Let's start by taking a look at the first few rows of each of these DataFrames to understand their structure and contents.",
          " Let's inspect each DataFrame to understand its structure and the data it contains.",
          "Let's start by taking a look at the first few rows of each dataframe to understand its structure and the kind of data it contains.",
          "Let's inspect the first few lines of each dataframe to understand the structure of the data.",
          " We should also take a look at the first few lines of each DataFrame to understand their structure and data.",
          " We want to begin by exploring the contents of these DataFrames and understand how they are related to each other.",
          "Let's take a look at the first 5 rows of each dataframe to understand their structure and the type of data they contain.",
          " Let's take a look at the first few rows of each dataframe to understand its structure.",
          "Let's check the first few rows of each dataframe to understand its structure.",
          "Now we have all the data loaded. Let's explore each DataFrame to understand its structure and the kind of information it provides."
         ],
         "marker": {
          "opacity": 0.5,
          "size": 5
         },
         "mode": "markers+text",
         "name": "35_Understanding DataFrame Structure",
         "text": [
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          ""
         ],
         "textfont": {
          "size": 12
         },
         "type": "scattergl",
         "x": [
          8.490278244018555,
          9.759319305419922,
          8.936613082885742,
          9.603464126586914,
          9.199138641357422,
          9.646288871765137,
          9.19613265991211,
          9.212979316711426,
          9.388199806213379,
          9.055049896240234,
          8.86656379699707,
          9.266114234924316,
          8.709477424621582,
          8.772259712219238,
          8.824795722961426,
          8.696654319763184,
          8.950274467468262,
          9.314208030700684,
          9.628225326538086,
          9.304137229919434,
          8.967489242553711,
          9.635141372680664,
          9.115117073059082,
          9.655492782592773,
          9.098697662353516,
          8.378451347351074,
          9.345386505126953,
          8.928308486938477,
          9.036559104919434,
          8.799276351928711,
          8.855616569519043,
          9.690563201904297,
          9.433743476867676,
          8.748526573181152,
          9.55751895904541,
          9.92025089263916,
          9.167590141296387,
          8.727241516113281,
          8.918610572814941,
          9.304976463317871,
          9.291433334350586,
          9.415982246398926,
          9.463628768920898,
          8.829471588134766,
          9.556191444396973,
          9.25723934173584,
          9.072147369384766,
          9.24415111541748,
          8.798951148986816
         ],
         "y": [
          -8.067498207092285,
          -7.903286933898926,
          -7.940095901489258,
          -6.699848175048828,
          -8.096607208251953,
          -7.665851593017578,
          -8.484232902526855,
          -7.594503402709961,
          -8.40956974029541,
          -8.00793170928955,
          -7.863240718841553,
          -7.91525411605835,
          -8.126852035522461,
          -8.220252990722656,
          -7.941374778747559,
          -7.581000328063965,
          -8.428069114685059,
          -8.037834167480469,
          -8.292845726013184,
          -8.248051643371582,
          -8.284915924072266,
          -7.865992546081543,
          -7.913966655731201,
          -7.251325607299805,
          -7.261564254760742,
          -8.476263999938965,
          -8.294028282165527,
          -7.779058933258057,
          -8.017509460449219,
          -8.163792610168457,
          -8.049756050109863,
          -8.006806373596191,
          -8.692856788635254,
          -8.215058326721191,
          -8.385704040527344,
          -8.482470512390137,
          -7.920317649841309,
          -8.20523738861084,
          -8.016863822937012,
          -7.514474391937256,
          -7.293238639831543,
          -7.878721714019775,
          -7.742079257965088,
          -7.257626056671143,
          -6.910074710845947,
          -8.363265991210938,
          -8.459077835083008,
          -7.973238945007324,
          -7.076314926147461
         ]
        },
        {
         "hoverinfo": "text",
         "hovertext": [
          "Limit the number of script lines (for quicker testing)\ndf_script = df_script[:1000]",
          "Limit the number of script lines for this example\ndf_script = df_script.head(5000)",
          "Create a sampling of the data to speed up the process\ndf_script = df_script.sample(frac=1)",
          "Create a sample of the dataset for performance reasons\ndf_script_sample = df_script.sample(5000, random_state=42).reset_index(drop=True)",
          "Limit the rows for the script dataframe",
          "For demonstration purpose, we limit the analysis to a short subset\ndf = df_script.loc[:1000].copy()\ndf.head()",
          "Reduce dataframe size to first 1000 rows for testing\ndf_script = df_script.iloc[:1000]",
          "Limit the number of lines to use due to the large size of the data set\nnum_lines = 10000 ",
          "Remove unnecessary index column\ndf_script = df_script.iloc[:,1:]",
          "limit the number of rows to use for easy of computation\ndf_script_subset = df_script.iloc[:10000]",
          "Limit the number of rows to 5000 to speed up computations\ndf_script = df_script.head(5000)",
          "Limit of records to read from each data frame.\nLIMIT = int(1e6)",
          "Limit the number of script lines for this example\ndf_script = df_script.head(10000)",
          "df_script = df_script.sample(1000)  # Speed up computation",
          "Extract a smaller random sample of the data for faster visualization and exploration\ndf_script_sample = df_script.sample(n=10000, random_state=1)",
          "Limit number of script lines for testing purposes\ndf_script = df_script.head(5000)",
          "Limit the dataframe to the first 5,000 rows for faster experimentation\ndf_script = df_script.iloc[:5000]",
          "Limit rows to 50000 to avoid memory errors and makes things faster\ndf_script = df_script[:50000]",
          " For better performance, just use the latest 1000 lines of the script for now\ndf_script = df_script.loc[:1000]",
          "#split the huge script file to disable the huge warning of 15GB\ndf_script1 = df_script.iloc[:300000]\ndf_script2 = df_script.iloc[300000:]",
          " Define a sample size that you want to analyze to speed up computations\nsample_size = 10000",
          "subset making the code run faster\ndf_script_subset = df_script.iloc[:50000]",
          "Limit the number of script lines for now\ndf_script = df_script.iloc[:10000]",
          " Limiting the number of documents to 500 for performance reasons.\ndf_script = df_script.iloc[:500]",
          " Optional: limit the number of script lines to speed up computation\n# df_script = df_script.head(1000)",
          "Create a sample of the line dataframe that works fast\nnp.random.seed(1)\ndf_script_sample = df_script.sample(n=10000)",
          "Extract the first 1000 lines of the script for analysis\ndf_first_1000_lines = df_script.iloc[:1000]",
          "Limiting the database to only 5,000 lines",
          "Limit the number of script lines to 5,000 for speed reasons\ndf_script = df_script[:5000]",
          " Optionally, limit the number of script lines for faster performance\n# df_script = df_script[:5000]",
          "Limiting data to first 10,000 records for quicker results\ndf_script = df_script.head(10000)",
          " To make the script smaller, we will only use the first 10,000 rows of `df_script`.\ndf_script = df_script.iloc[:10000]",
          " Displaying only the first 1000 records for performance reasons\ndf_script = df_script.head(1000)",
          "Limit the number of script lines for now\n# df_script = df_script[:50000]",
          "Remove temporarily\nscript_subset = df_script.iloc[:5000].copy()",
          "Limiting the data in the script to only 10,000 rows to improve computational performance\ndf_script = df_script.head(10000)",
          "Limit the number of rows to 10000\ndf_script = df_script.head(10000)",
          "Limit the number of script lines to 10000 to speed up computation\ndf_script = df_script.sample(n=10000, random_state=1)",
          " Limit the number of rows to speed up the development of the notebook\n# df_script = df_script.head(15000)",
          "Limit the number of scripts to not run out of memory during these computations\ndf_script = df_script.iloc[:100000]",
          "Set the LIMIT constant\nLIMIT = 10000",
          " Limit the number of lines in the script dataframe for the sake of example\ndf_script = df_script.iloc[:10000]",
          " Limit rows for quick debugging\n# df_script = df_script[:100000]",
          "Extract a small subset for testing\ndf_script = df_script.head(100000)",
          " Limit the number of script lines for faster execution\nLIMIT = 50000\ndf_script = df_script.iloc[:LIMIT]",
          " Select first 10k\ndf_script = df_script.iloc[:10000]",
          "Limiting the number of records for the sake of memory and CPU limitations\ndf_script = df_script.sample(n=1000, random_state=1)",
          "Limit the number of script lines for faster processing time\ndf_script_limit = df_script.sample(n=600000, random_state=1)",
          "Limiting the amount of information for brevity\ndf_script = df_script.iloc[:300000]"
         ],
         "marker": {
          "opacity": 0.5,
          "size": 5
         },
         "mode": "markers+text",
         "name": "36_Limiting script lines for faster execution and performance",
         "text": [
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          ""
         ],
         "textfont": {
          "size": 12
         },
         "type": "scattergl",
         "x": [
          10.307635307312012,
          10.290107727050781,
          9.305685997009277,
          9.036771774291992,
          11.363842010498047,
          10.086194038391113,
          9.849550247192383,
          12.71995735168457,
          9.0731782913208,
          9.876240730285645,
          10.539981842041016,
          10.652807235717773,
          10.062104225158691,
          10.021661758422852,
          9.187986373901367,
          10.371774673461914,
          9.913310050964355,
          10.713641166687012,
          10.003043174743652,
          8.986693382263184,
          11.42265510559082,
          9.613036155700684,
          9.66965103149414,
          9.990010261535645,
          9.95866584777832,
          9.36842155456543,
          9.816726684570312,
          13.564237594604492,
          10.137303352355957,
          10.132026672363281,
          10.216279983520508,
          9.565088272094727,
          9.927800178527832,
          10.332923889160156,
          9.24945068359375,
          10.66537857055664,
          10.818658828735352,
          9.247617721557617,
          10.996757507324219,
          9.503803253173828,
          13.027130126953125,
          9.963713645935059,
          10.83211898803711,
          9.718313217163086,
          9.593160629272461,
          9.496809005737305,
          9.960003852844238,
          9.53223705291748,
          9.875603675842285
         ],
         "y": [
          -2.088829278945923,
          -1.8721286058425903,
          -1.8970619440078735,
          -2.065383195877075,
          -4.028171539306641,
          -1.8682026863098145,
          -1.9519318342208862,
          -0.11026950925588608,
          -1.6986557245254517,
          -2.2214865684509277,
          -2.172264814376831,
          -3.041924476623535,
          -2.24011492729187,
          -1.5585538148880005,
          -2.2448008060455322,
          -2.4241385459899902,
          -1.7899473905563354,
          -1.5348756313323975,
          -2.156175136566162,
          -1.821711540222168,
          -0.7227612137794495,
          -1.5885307788848877,
          -2.382920265197754,
          -2.1259067058563232,
          -2.0915212631225586,
          -2.166630983352661,
          -2.128401041030884,
          0.5662133693695068,
          -2.4323160648345947,
          -1.9002387523651123,
          -2.2995026111602783,
          -2.072517156600952,
          -2.6385064125061035,
          -2.401700019836426,
          -1.852374792098999,
          -2.0901834964752197,
          -2.665069818496704,
          -2.005016803741455,
          -2.1422839164733887,
          -1.5884959697723389,
          0.24841523170471191,
          -1.9710923433303833,
          -2.6956658363342285,
          -1.86866295337677,
          -1.8750017881393433,
          -1.8141844272613525,
          -2.1086926460266113,
          -1.8097707033157349,
          -2.013530969619751
         ]
        },
        {
         "hoverinfo": "text",
         "hovertext": [
          "Inspect the first few rows of the characters dataframe\nprint(df_characters.head())",
          "Inspect the first few records of the characters dataframe\ndf_characters.head()",
          "Inspect the first few rows of the characters DataFrame\ndf_characters.head()",
          "Inspect the first few rows of the characters DataFrame\ndf_characters.head()",
          "Inspecting the first elements of the characters dataframe\ndf_characters.head()",
          "Inspect first rows of characters dataframe\ndf_characters.head()",
          "Inspect the first few rows of the characters dataframe\ndf_characters.head()",
          "Examine the first few rows of the characters dataframe\ndf_characters.head()",
          "Looking at the first rows of the characters dataframe\ndf_characters.head()",
          "Inspect the first 2 rows of the characters dataframe\ndf_characters.head(2)",
          "inspect the first few rows of each dataframe\nprint(df_characters.head())",
          "Inspect the first few rows of the characters dataframe\ndf_characters.head()",
          "Inspect the first few rows of the characters dataframe\ndf_characters.head()",
          "Inspect the first few rows of the characters dataframe\ndf_characters.head()",
          "Inspect the first few rows of the characters data frame\ndf_characters.head()",
          "Inspect the first few rows of the characters dataframe\nprint(df_characters.head())",
          "Inspect the first few rows of the characters dataframe\ndf_characters.head()",
          "Inspect the first few rows of the first dataframe\ndf_characters.head()",
          "Inspect the first few rows of the characters DataFrame\ndf_characters.head()",
          "Exploring the first few rows of the dataframe\ndf_characters.head()",
          " Explore the first few rows of the characters dataframe\ndf_characters.head()",
          " Explore the first few rows of the characters DataFrame\ndf_characters.head()",
          "Quick look at the first rows of each DataFrame\ndf_characters.head()",
          "Inspect the first few rows of the character dataframe\ndf_characters.head()",
          "Inspect the first few rows of the characters dataframe\ndf_characters.head()",
          "Inspect the first few rows of the characters dataframe\ndf_characters.head()",
          "Inspecting the first few rows of the characters dataframe\ndf_characters.head()",
          "Inspect first few rows of the characters DataFrame\ndf_characters.head()",
          "Inspect the first few rows of the characters dataframe\ndf_characters.head()",
          "Inspect the first few rows of the characters dataframe\ndf_characters.head()",
          "Inspect the first few rows of the characters dataframe\nprint(df_characters.head())",
          "Inspect the first few rows of the characters dataframe\ndf_characters.head()",
          "# Print the first few rows of df_characters to see the data\ndf_characters.head()",
          "Inspect the first few rows of the characters dataframe\ndf_characters.head()",
          "Inspect the first few rows of the characters dataframe\ndf_characters.head()",
          "Inspect the first few rows of the characters dataframe\ndf_characters.head()",
          "Inspect the first few rows of the characters dataframe\ndf_characters.head()",
          "Inspect the first few rows of the characters dataframe\ndf_characters.head()",
          "inspect first few rows of the dataframe\ndf_characters.head()",
          "inspect the first rows of the characters DataFrame\ndf_characters.head()",
          "inspect the first few records of the dataframe\ndf_characters.head()",
          "Inspect the first few rows of the characters DataFrame\ndf_characters.head()",
          "Inspect first few rows of the characters data\nprint(df_characters.head())",
          "Inspect the first few rows of the characters dataframe\ndf_characters.head()",
          "Inspect the first few rows of the characters dataframe\ndf_characters.head()",
          "Inspect the first few rows of the characters dataframe\ndf_characters.head()",
          "Inspect the first few rows of the characters DataFrame\ndf_characters.head()",
          "Look at first rows of characters dataframe\ndf_characters.head()"
         ],
         "marker": {
          "opacity": 0.5,
          "size": 5
         },
         "mode": "markers+text",
         "name": "37_Inspecting the first few rows of the characters dataframe",
         "text": [
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          ""
         ],
         "textfont": {
          "size": 12
         },
         "type": "scattergl",
         "x": [
          5.52982234954834,
          5.152312278747559,
          6.367485046386719,
          6.237192153930664,
          5.6530842781066895,
          5.733865261077881,
          6.240199089050293,
          5.861572265625,
          5.794174671173096,
          6.0600266456604,
          4.9924235343933105,
          5.97402811050415,
          5.884415626525879,
          5.9925761222839355,
          5.99924898147583,
          5.623841285705566,
          6.222019672393799,
          5.875439643859863,
          6.184189319610596,
          5.661169052124023,
          5.895246505737305,
          6.042586803436279,
          5.9837965965271,
          6.055093288421631,
          6.014349460601807,
          6.023085117340088,
          5.637069225311279,
          6.212716579437256,
          5.782834529876709,
          6.048486709594727,
          5.673685073852539,
          5.748208999633789,
          4.758214950561523,
          6.129335880279541,
          5.618494033813477,
          5.823338508605957,
          6.027562618255615,
          5.821150302886963,
          5.666113376617432,
          5.6510491371154785,
          5.599775791168213,
          5.900448322296143,
          5.086878776550293,
          5.958242893218994,
          5.974723815917969,
          6.061375617980957,
          6.370828151702881,
          5.268534183502197
         ],
         "y": [
          19.73158073425293,
          20.02526092529297,
          20.43248748779297,
          20.212888717651367,
          19.11335563659668,
          20.10205841064453,
          20.43280029296875,
          19.902441024780273,
          19.592334747314453,
          20.62992286682129,
          19.81829071044922,
          20.49230194091797,
          20.06886100769043,
          19.962371826171875,
          19.915307998657227,
          19.717500686645508,
          20.387893676757812,
          19.985002517700195,
          20.351408004760742,
          19.521732330322266,
          19.676685333251953,
          19.8668270111084,
          18.986526489257812,
          20.126296997070312,
          20.33995819091797,
          20.355531692504883,
          19.72328758239746,
          20.21597671508789,
          20.555402755737305,
          20.799917221069336,
          19.69981575012207,
          20.53730010986328,
          17.807100296020508,
          20.656570434570312,
          20.383319854736328,
          20.370107650756836,
          20.217601776123047,
          20.5584774017334,
          19.825349807739258,
          19.69622039794922,
          20.49630355834961,
          20.434463500976562,
          18.80038833618164,
          20.558290481567383,
          20.45195198059082,
          20.10952377319336,
          20.48941421508789,
          19.502010345458984
         ]
        },
        {
         "hoverinfo": "text",
         "hovertext": [
          "Inspect the dataframes",
          "Inspect Dataframes",
          "Inspect the dataframes",
          "Inspect the dataframes",
          "We'll quickly inspect each of these dataframes.",
          " Let's quickly inspect the dataframes",
          "Start an analysis session using pandas and matplotlib",
          "Inspect the dataframes",
          "Inspect the dataframes",
          "We can now use the previously defined read-in data frames for further data processing and analysis.",
          "Quick look at the dataframes",
          "Inspect the dataframes",
          "Inspect dataframesidency and common features",
          "Inspect the dataframes",
          "Inspect all dataframes and their features",
          "Inspect dataframes",
          "Create a dataframe with the lines we intend to analyze.",
          "Explore the contents of the dataframes",
          "Inspect data frames",
          "Inspect the dataframes dtype",
          "Let's peek into each of the DataFrames",
          "Inspect the dataframes",
          "Inspect the dataframe shapes.",
          " Explore the content of the dataframes.",
          "Inspect dataframes",
          "Inspect the dataframes",
          "Inspect the dataframes",
          "Inspecting the dataframes",
          "Inspect the data frames",
          "Inspect Dataframes",
          "Inspect the content of the dataframes",
          "Inspect the dataframes",
          "Creating and inspecting the spark DataFrame",
          " Inspect what the dataframes look like",
          "Inspect the dataframes",
          "Inspect dataframes",
          "Inspecting the data frames",
          "Example of value you have access in the dataframe",
          "Inspect the dataframes",
          "Inspect dataframes",
          "Inspecting the dataframes",
          "Inspect the dataframes",
          "Inspecting the dataframes",
          "Quick look at the dataframes",
          "Inspect dataframes quickly",
          "Inspect the dataframes",
          "Quick look at the dataframes"
         ],
         "marker": {
          "opacity": 0.5,
          "size": 5
         },
         "mode": "markers+text",
         "name": "38_Inspecting dataframes",
         "text": [
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          ""
         ],
         "textfont": {
          "size": 12
         },
         "type": "scattergl",
         "x": [
          12.036731719970703,
          12.250479698181152,
          11.976851463317871,
          11.898503303527832,
          9.92145824432373,
          11.14684772491455,
          12.196951866149902,
          11.955998420715332,
          12.17284107208252,
          10.61785888671875,
          11.601024627685547,
          12.047249794006348,
          12.175793647766113,
          12.190118789672852,
          12.182814598083496,
          11.968573570251465,
          11.323012351989746,
          10.95122241973877,
          11.62868881225586,
          11.603882789611816,
          10.937749862670898,
          12.194242477416992,
          11.484018325805664,
          11.47034740447998,
          12.14205551147461,
          12.193249702453613,
          11.830077171325684,
          11.576996803283691,
          11.496964454650879,
          12.309840202331543,
          11.450864791870117,
          12.0066499710083,
          12.390521049499512,
          11.573474884033203,
          11.946626663208008,
          12.197314262390137,
          11.401444435119629,
          11.177440643310547,
          12.199378967285156,
          12.063528060913086,
          11.678120613098145,
          12.059015274047852,
          11.476141929626465,
          11.76013469696045,
          12.478339195251465,
          11.936599731445312,
          11.884117126464844
         ],
         "y": [
          -4.313653469085693,
          -3.729092836380005,
          -4.378213405609131,
          -4.320102214813232,
          -5.569831371307373,
          -4.894935607910156,
          -1.3514313697814941,
          -4.02227258682251,
          -4.265838146209717,
          -5.2313127517700195,
          -4.757190227508545,
          -4.529181003570557,
          -4.1571125984191895,
          -4.486554145812988,
          -3.7330641746520996,
          -3.91451358795166,
          -3.3867695331573486,
          -4.140089988708496,
          -4.656551837921143,
          -5.3172101974487305,
          -5.383452415466309,
          -4.229269504547119,
          -4.25579309463501,
          -4.706993103027344,
          -3.9695498943328857,
          -4.4212188720703125,
          -4.43568754196167,
          -4.244217872619629,
          -4.9003705978393555,
          -3.90455961227417,
          -4.234531402587891,
          -4.583675861358643,
          -3.8480377197265625,
          -4.572047710418701,
          -3.984408140182495,
          -3.772106647491455,
          -5.110513210296631,
          -4.4276533126831055,
          -4.420422077178955,
          -3.932861328125,
          -4.088303565979004,
          -4.202491760253906,
          -4.243202209472656,
          -5.042335033416748,
          -4.008543491363525,
          -4.624411582946777,
          -4.939743518829346
         ]
        },
        {
         "hoverinfo": "text",
         "hovertext": [
          "Merge dataframes to have all in one dataframe",
          "Merge the datasets to include all relevant information in one dataframe.",
          " Apply ?? over the different dataframes to look samples",
          "Merge dataframes to have all relevant information in one place",
          "Merge the datasets to get all the information in a single dataframe",
          "Create a single dataframe that contains all the information we need.",
          "Merge the dataset to get all the information in a single dataframe",
          " Join the dataframes to obtain a single unified dataframe containing all information.",
          "Merge the dataframes to get all the relevant information in one single dataframe",
          "merging the data to have all pertinent information in one dataframe",
          "Merge the datasets to get a single dataframe",
          "Create a simplified dataframe with only relevant information",
          "Merge the datasets to create a single dataframe with all the information we need.",
          " To achieve this, we'll use the `merge` function provided by Pandas to join our datasets together.",
          "Merge the tables to have all relevant information in one data frame",
          " Merge the datasets to get all the data in one dataframe",
          "Merge all data into one dataframe",
          "Merge all data into a single dataframe",
          " Merge the dataframes to get a single dataframe containing all the information we need.",
          "Apply slight transformation to each dataframe",
          "Merge all dataframes into a single one for more convenience",
          "Merge all dataframes into one, creating a unified dataframe with all information",
          "Merge dataframes to join the information into one dataframe",
          "We join the dataframes to have a unique dataframe containing all the relevant information.",
          "Merge all the information in a single DataFrame.",
          "Merge all dataframes into a single one",
          "Merge the related datasets into a single dataframe",
          "Merge datasets to have conversations with Chris on the same DataFrame",
          "Merge the datasets to create one single dataframe",
          "Create one big DataFrame containing all the informations needed for the following analysis:",
          "Merge the datasets to get all relevant information in one dataframe",
          " Integrating the data: combine the information from the different dataframes into a single dataframe.",
          "let's merge the dataframes to get a dataset with all information in one place.",
          "Combine the data from multiple dataframes into one dataframe for simplicity and ease of analysis.",
          "Merge the necessary data and filter the dataframe rows based on the conditions mentioned in the prompt.",
          "Concatenate CSVs to a single dataframe",
          "Merge the datasets to create a single dataframe with all the information we need.",
          " Combine the data in a single DataFrame for ease of manipulation.",
          "Merge all available data into one dataframe.",
          "I will merge some of the DataFrames, to be able to get all the necessary information in one DataFrame.",
          "Merge the datasets to include all relevant information in one dataframe.",
          "Create lists from the dataframes to transfer more complex df operations to SQL in order to improve speed",
          "Merge the datasets in order to have a unified dataframe containing all necessary information.",
          "merge all into one dataframe",
          " Merge the datasets to get all the relevant info in one dataframe",
          "Merge datasets to get all relevant information into one dataframe",
          "Merges all labeled data in one dataframe."
         ],
         "marker": {
          "opacity": 0.5,
          "size": 5
         },
         "mode": "markers+text",
         "name": "39_Merging Datasets for Unified Relevant Information",
         "text": [
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          ""
         ],
         "textfont": {
          "size": 12
         },
         "type": "scattergl",
         "x": [
          6.032012462615967,
          6.846232891082764,
          6.509474277496338,
          6.270779132843018,
          5.823029041290283,
          6.993074893951416,
          5.650112152099609,
          6.720371723175049,
          6.113433837890625,
          6.154332160949707,
          6.050146579742432,
          6.652238845825195,
          7.349278450012207,
          6.41610050201416,
          5.963758945465088,
          6.06508207321167,
          6.3286237716674805,
          6.273638725280762,
          7.12681245803833,
          6.394998073577881,
          6.8150410652160645,
          6.528215408325195,
          5.950683116912842,
          7.110945224761963,
          6.294124603271484,
          6.501258373260498,
          6.367574691772461,
          6.334481239318848,
          6.493757247924805,
          7.493745803833008,
          6.181403636932373,
          6.906250953674316,
          6.976377010345459,
          6.8154706954956055,
          7.323936939239502,
          5.8964457511901855,
          7.469964027404785,
          6.184072017669678,
          6.719444751739502,
          7.436315536499023,
          6.811254501342773,
          7.7270073890686035,
          7.241413593292236,
          6.115394115447998,
          5.993922710418701,
          6.3898138999938965,
          5.977782249450684
         ],
         "y": [
          -0.6244175434112549,
          -0.5259408354759216,
          -1.7343693971633911,
          -1.0461214780807495,
          -1.14264714717865,
          -0.6158241629600525,
          -0.848779022693634,
          -0.858574390411377,
          -1.1983050107955933,
          -1.3704018592834473,
          -0.6123759746551514,
          -0.8119328618049622,
          -0.6463798880577087,
          -0.8166868090629578,
          -0.764842689037323,
          -0.9761759042739868,
          -0.7970424890518188,
          -0.9197394251823425,
          -0.8461835384368896,
          -0.2821851968765259,
          -0.5280497670173645,
          -0.9723086953163147,
          -0.9251126050949097,
          -0.8268711566925049,
          -1.1203386783599854,
          -0.6636422276496887,
          -0.9571198225021362,
          -0.6476768851280212,
          -0.37721484899520874,
          -1.198652744293213,
          -0.4535690248012543,
          -1.0179747343063354,
          -0.47122636437416077,
          -1.252923607826233,
          0.3171935975551605,
          -1.2088888883590698,
          -0.7289235591888428,
          -1.1784236431121826,
          -0.9119614958763123,
          -0.7366694211959839,
          -0.683118999004364,
          -0.3927333950996399,
          -0.7205994725227356,
          -1.166391372680664,
          -0.599555492401123,
          -0.660507082939148,
          -0.9454323649406433
         ]
        },
        {
         "hoverinfo": "text",
         "hovertext": [
          " Display the script dataframe\ndf_script.head()",
          " Display several columns to see the data\ndf_script.head()",
          "Print the head of the dataframe containing the script lines.",
          " Show the script lines dataframe\ndf_script.head()",
          "View script head\ndf_script.head()",
          "Show data\ndf_script.head()",
          " Display script lines dataframe\ndf_script.head()",
          "Display dataframe\ndf_script.head()",
          "Display the script\ndf_script.head()",
          " Show df_scirpt for testing purposes\ndf_script.head()",
          " Show the head of the script\ndf_script.head()",
          "Display scripts dataframe\ndf_script.head(3)",
          "- Element displaysdf_script.head()",
          "View the script lines dataframe\ndf_script.head()",
          "Display the data\ndf_script.head()",
          "Display resulting dataframe head\ndf_script.head()",
          "View script dataframe\ndf_script.head()",
          "Show dataframe\ndf_script.head()",
          "View scripts\ndf_script.head()",
          "Display the scripts dataframe\ndf_script.head()",
          "Show the head of the script dataframe\ndf_script.head()",
          " Display data from the scripts\ndf_script.head()",
          " Show head of script dataframe\ndf_script.head()",
          "# Display some dataframes\ndf_script.head()",
          " Display scripts\ndf_script.head()",
          "View data\ndf_script.head()",
          " Print the head of the script data frame\ndf_script.head()",
          "Display head of the script data\ndf_script.head()",
          " Display script data\ndf_script.head()",
          "Display\ndf_script.head()",
          "Printing the head of the scripts dataframe\ndf_script.head()",
          "Display script dataframe\ndf_script.head()",
          " Display head of script dataframe\ndf_script.head()",
          " Show the head of the data\ndf_script.head()",
          "# View the overall script\ndf_script.head()",
          " Print head of script lines dataframe\ndf_script.head()",
          "Display head of scripts DataFrame\ndf_script.head()",
          "Display dataframe\ndf_script.head()",
          "View format of `script` DataFrame\ndf_script.head()",
          "Display the scripts dataframe\ndf_script.head()",
          "Format and display the script data\ndf_script.head()",
          "  display(df_script.head())",
          " Display head of lines\ndf_script.head()",
          "Display script dataframe\ndf_script.head()",
          "Display the scripts DataFrame\ndf_script.head()",
          "Display the data in the dataframe for script lines with a head function",
          " Display the dataframe\ndf_script.head()"
         ],
         "marker": {
          "opacity": 0.5,
          "size": 5
         },
         "mode": "markers+text",
         "name": "40_Displaying and Viewing Scripts DataFrame",
         "text": [
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          ""
         ],
         "textfont": {
          "size": 12
         },
         "type": "scattergl",
         "x": [
          7.10159158706665,
          4.108335494995117,
          6.456945419311523,
          6.359211444854736,
          6.16492223739624,
          5.420073986053467,
          6.57296085357666,
          7.181075572967529,
          6.070603847503662,
          5.638641834259033,
          6.403249263763428,
          6.508109092712402,
          6.512465476989746,
          6.893641948699951,
          5.350616455078125,
          7.512203693389893,
          6.310417175292969,
          7.072571277618408,
          5.9563889503479,
          6.816468715667725,
          6.721864223480225,
          5.817147254943848,
          6.892812252044678,
          7.301749229431152,
          6.235203266143799,
          5.29053258895874,
          6.255528450012207,
          6.005262851715088,
          5.880227088928223,
          6.272924423217773,
          6.429006099700928,
          7.107419490814209,
          6.927022457122803,
          5.6679792404174805,
          6.0586419105529785,
          6.477406024932861,
          6.8255934715271,
          7.281792163848877,
          6.519380569458008,
          6.876138210296631,
          6.057724475860596,
          6.601707458496094,
          5.846770763397217,
          7.041662693023682,
          6.737880229949951,
          7.055100917816162,
          7.083558559417725
         ],
         "y": [
          -5.431171894073486,
          -6.146592617034912,
          -4.980530738830566,
          -5.3153276443481445,
          -5.675449371337891,
          -5.653534889221191,
          -5.1899638175964355,
          -5.521719455718994,
          -5.796815872192383,
          -5.155693531036377,
          -5.920206546783447,
          -5.774731159210205,
          -5.188822269439697,
          -5.404221057891846,
          -5.62862491607666,
          -5.52716588973999,
          -5.7366862297058105,
          -5.718691349029541,
          -5.843449592590332,
          -5.469161510467529,
          -6.1931376457214355,
          -5.748252868652344,
          -6.231656074523926,
          -5.182701110839844,
          -5.793322563171387,
          -5.389368057250977,
          -6.116489410400391,
          -5.909636974334717,
          -5.257111549377441,
          -5.623581409454346,
          -6.318641185760498,
          -5.490557670593262,
          -6.044206142425537,
          -5.857246398925781,
          -5.80086088180542,
          -5.841912269592285,
          -6.003999710083008,
          -5.3337788581848145,
          -5.961062431335449,
          -5.383067607879639,
          -5.653589725494385,
          -5.366063594818115,
          -5.543338298797607,
          -5.231520652770996,
          -5.340133190155029,
          -5.37325382232666,
          -5.231209754943848
         ]
        },
        {
         "hoverinfo": "text",
         "hovertext": [
          "Visualising the occurences of character names with wordclouds",
          "Word cloud of the simpsons locations",
          "This script is intended to turn script lines into bag of words format, and then create word clouds.\n# To do so, we start by processing script lines to obtain bag of words.\n# We then implement a function to display the word cloud for a subset of episodes or a subset of speakers.",
          "visualize wordcloud of Simpson script data",
          "Caching the Word Embeddings to quickly iterate on the same computations.",
          "This process builds WordClouds for the 10 most common words of each script line, character, and location.",
          "We will be using the script dataset to extract insights and create a word cloud.",
          "Visualize the most common words in the script lines of The Simpsons using WordCloud",
          "Analyzing the character lines and building word clouds",
          "Visualizing The Most Common Words with WordClouds",
          "Word cloud visualization for the entire Simpsons script\nscript_texts = ' '.join([str(x) for x in df_script['normalized_text'].values])\nwordcloud = WordCloud(width = 2000, height = 1000, random_state=21, max_font_size=200).generate(script_texts)\nplt.figure(figsize=(20, 10))\nplt.imshow(wordcloud, interpolation=\"bilinear\")\nplt.axis('off')",
          "Creating the word cloud for the most common words in the script lines",
          " Collecting personal stopwords, frequent mispellings, common words referring to the simpsons, and imperatives",
          " Visualize the top 20 most common words in the script lines.",
          " Visualise the top k most frequently used words in script lines in a word cloud",
          "Creating wordcloud of character dialogue\n# Process of creating wordcloud\n# 1. merges the script lines dataframe with the characters dataframe \n# on the character, episode_id columns of the script lines dataframe and the \n# id column of the characters dataframe\n# 2. filter out characters where gender is not provided\n# 3. filter out script lines that are not spoken or have no spoken_words\n# 4. filter out episodes that have not been aired or have not started\n# 5. perform sentiment analysis on the spoken_words and assign the sentiment through a column\n# 6. create word cloud of the dialogue of a character",
          "Ways to handle and format a list of fastText word vectors.",
          "Visualize the most common words in the simpsons script lines",
          "Show Word Cloud for every Season Word Clouds for each season - top 100 lemmas displayed, sizes based on the number of occurrences in the whole season",
          "Visualize the most common words in the script lines using a word cloud",
          " Displaying the word cloud for the most common words in The Simpsons script lines",
          "Plot WordCloud of character for a specific episode",
          " Select the 4000 most common words in the dataset",
          "Visualize the distribution of the most common words in the script lines.",
          "Visualizing the Simpsons script: A wordcloud of the most popular words in the script",
          "To Do: Implement word cloud for Simpsons script lines",
          "This script uses the `WordCloud` package to visualize the most common words found in the Simpsons script.",
          "WordCloud of the Simpsons script\n# Word cloud of all the scripts spoken by each character\nall_scripts = ' '.join(df_script.normalized_text)\nwordcloud = WordCloud(width = 800, height = 400, random_state=21, max_font_size=110, background_color='white').generate(all_scripts)\n\nplt.figure(figsize=(10, 5))\nplt.imshow(wordcloud, interpolation=\"bilinear\")\nplt.axis('off')\nplt.show()",
          "Visualizing a word cloud for the script lines",
          " Visualize the most common words in the script lines",
          "Word clouds are a popular way to visualize word frequencies in a corpus of text. Let's create a word cloud for the Simpsons script lines to see which words are most common.",
          "Visualize The Word Frequency In The Script Lines",
          " Let's start by visualizing a word cloud of the most common words in the script lines.",
          "Code to set up NLP model and visualize word frequencies",
          "Visualize the most common words using a word cloud",
          "Visualize the most frequent words in the script lines.",
          "Let's check the top word frequency in the simpsons lines",
          "Milestone 1: WordClouds and Frequency Analysis\n# TODO: Create masks for the Gender of the Characters and their respective WordClouds for several episodes.\n\n# Store the punctuation characters to remove\npunctuation = '!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~'",
          "Counting lines of each script to measure which characters play an important role in The Simpsons series and plot a word cloud",
          "Show word cloud of the previous amount of words spoken by the character with the most words.",
          " WordCloud requires text data to generate word clouds. We will use the Simpsons script lines as our text data to generate word clouds for each character's dialogues.",
          " Wordcloud for simpsons words",
          "Transform plain text to a bag of words representation for each spring line",
          "Let's create a simple word cloud for the Simpsons script lines.",
          "Visualize the most spoken words by Homer Simpson",
          "Let's visualize the Word Clouds of the script lines of the Simpsons."
         ],
         "marker": {
          "opacity": 0.5,
          "size": 5
         },
         "mode": "markers+text",
         "name": "41_Creating word clouds to visualize the most common words in The Simpsons script lines",
         "text": [
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          ""
         ],
         "textfont": {
          "size": 12
         },
         "type": "scattergl",
         "x": [
          11.976263046264648,
          11.74006175994873,
          11.401910781860352,
          11.75656509399414,
          13.857025146484375,
          12.097304344177246,
          11.86818790435791,
          11.736124038696289,
          12.074068069458008,
          11.785432815551758,
          11.502893447875977,
          11.71960735321045,
          11.814306259155273,
          11.361498832702637,
          11.646943092346191,
          10.411840438842773,
          12.784497261047363,
          11.44338607788086,
          11.325026512145996,
          11.503033638000488,
          11.841824531555176,
          11.482954978942871,
          10.016590118408203,
          11.486820220947266,
          11.328177452087402,
          11.661595344543457,
          11.630561828613281,
          11.002745628356934,
          11.813436508178711,
          11.418243408203125,
          11.65188217163086,
          11.202274322509766,
          11.783683776855469,
          11.334502220153809,
          11.724919319152832,
          11.053911209106445,
          11.712742805480957,
          11.438692092895508,
          11.552094459533691,
          11.020508766174316,
          11.863682746887207,
          11.61345100402832,
          11.581400871276855,
          11.622941970825195,
          11.743551254272461,
          11.907538414001465
         ],
         "y": [
          7.23372220993042,
          7.747687339782715,
          6.768264293670654,
          6.999483585357666,
          7.5996198654174805,
          6.849567890167236,
          5.929366588592529,
          7.276258945465088,
          7.234426021575928,
          7.474515438079834,
          7.954387664794922,
          7.1294121742248535,
          7.03163480758667,
          6.181721210479736,
          6.857815742492676,
          6.731083869934082,
          6.775777816772461,
          6.975235462188721,
          7.7289934158325195,
          7.024982929229736,
          7.513401508331299,
          6.985223293304443,
          7.588737487792969,
          6.368051528930664,
          7.415952682495117,
          7.3017168045043945,
          7.73687219619751,
          7.845580101013184,
          6.688503742218018,
          6.718774318695068,
          7.443428993225098,
          6.6835432052612305,
          6.606510162353516,
          7.170963287353516,
          7.506092548370361,
          6.351377964019775,
          7.281590461730957,
          6.894266128540039,
          7.0233025550842285,
          7.602350234985352,
          6.952375411987305,
          7.185507774353027,
          6.784576892852783,
          7.57476806640625,
          6.778755187988281,
          7.623038291931152
         ]
        },
        {
         "hoverinfo": "text",
         "hovertext": [
          "Check the shape of dfs\nprint(df_characters.shape, df_locations.shape, df_script.shape,  df_episodes.shape)",
          "Check shape of the DataFrames\nprint(df_characters.shape)\nprint(df_locations.shape)\nprint(df_script.shape)\nprint(df_episodes.shape)",
          "Check dataframe shapes\nprint('Characters shape:', df_characters.shape)\nprint('Locations shape:', df_locations.shape)\nprint('Script shape:', df_script.shape)\nprint('Episodes shape:', df_episodes.shape)",
          "Check the shape of the dataframes\nprint(df_characters.shape)\nprint(df_locations.shape)\nprint(df_script.shape)\nprint(df_episodes.shape)",
          " Check shape of dataframes\nprint(f\"Characters: {df_characters.shape} | Locations: {df_locations.shape} | Script: {df_script.shape} | Episodes: {df_episodes.shape}\")",
          " Look at the shape of the dataframes\nprint(df_characters.shape)\nprint(df_locations.shape)\nprint(df_script.shape)\nprint(df_episodes.shape)",
          "Checking the shapes of the data\nprint(f'Shapes Characters: {df_characters.shape}, Locations: {df_locations.shape}, '\n      f'Script: {df_script.shape}, Episodes: {df_episodes.shape}')",
          "Check the dataframe shapes\nprint(\"Characters dataframe shape:\", df_characters.shape)\nprint(\"Locations dataframe shape:\", df_locations.shape)\nprint(\"Script dataframe shape:\", df_script.shape)\nprint(\"Episodes dataframe shape:\", df_episodes.shape)",
          "check shapes\nprint(f\"df_characters: {df_characters.shape}\")\nprint(f\"df_locations: {df_locations.shape}\")\nprint(f\"df_script: {df_script.shape}\")\nprint(f\"df_episodes: {df_episodes.shape}\")",
          "Check the shape of each dataframe\nprint(df_characters.shape)\nprint(df_locations.shape)\nprint(df_script.shape)\nprint(df_episodes.shape)",
          "Data validation and some general statistics\nprint('Episodes Dataframe shape: ', df_episodes.shape)\nprint('Script Dataframe shape: ', df_script.shape)",
          "check the shape of all the datasets\nprint('The shape of the character dataset is: {}'.format(df_characters.shape))\nprint('The shape of the location dataset is: {}'.format(df_locations.shape))\nprint('The shape of the script dataset is: {}'.format(df_script.shape))\nprint('The shape of the episodes dataset is: {}'.format(df_episodes.shape))",
          "Check the shape of all datasets\nprint(f'Shape of df_characters: {df_characters.shape}')\nprint(f'Shape of df_locations: {df_locations.shape}')\nprint(f'Shape of df_script: {df_script.shape}')\nprint(f'Shape of df_episodes: {df_episodes.shape}')",
          "Check the dataset shapes\nprint(df_characters.shape)\nprint(df_locations.shape)\nprint(df_script.shape)\nprint(df_episodes.shape)",
          "Check that the shape of each dataframe is correct\nprint(f'Shape of characters dataframe: {df_characters.shape}')\nprint(f'Shape of locations dataframe: {df_locations.shape}')\nprint(f'Shape of script dataframe: {df_script.shape}')\nprint(f'Shape of episodes dataframe: {df_episodes.shape}')",
          "Checking DataFrame shapes\nprint(f\"Characters: {df_characters.shape}\")\nprint(f\"Locations: {df_locations.shape}\")\nprint(f\"Script: {df_script.shape}\")\nprint(f\"Episodes: {df_episodes.shape}\")",
          "Check a few attributes of our datasets\nprint(df_characters.shape)\nprint(df_locations.shape)\nprint(df_script.shape)\nprint(df_episodes.shape)",
          " Check the shape of the datasets\nprint(\"Characters dataset shape: {}\".format(df_characters.shape))\nprint(\"Locations dataset shape: {}\".format(df_locations.shape))\nprint(\"Script dataset shape: {}\".format(df_script.shape))\nprint(\"Episodes dataset shape: {}\".format(df_episodes.shape))",
          "Check dataframe shapes\nprint('Characters:', df_characters.shape)\nprint('Locations:', df_locations.shape)\nprint('Script:', df_script.shape)\nprint('Episodes:', df_episodes.shape)",
          "View the dataset shapes\ndf_characters.shape, df_locations.shape, df_script.shape, df_episodes.shape",
          "Check the dataset shapes\nprint(df_characters.shape)\nprint(df_locations.shape)\nprint(df_script.shape)\nprint(df_episodes.shape)",
          " Check data\nprint(\"Characters shape\", df_characters.shape)\nprint(\"Locations shape\", df_locations.shape)\nprint(\"Scripts shape\", df_script.shape)\nprint(\"Episodes shape\", df_episodes.shape)",
          "Check the shapes of the datasets\nprint(df_characters.shape)\nprint(df_locations.shape)\nprint(df_script.shape)\nprint(df_episodes.shape)",
          "Check the shape of each DataFrame\nprint(\"Characters shape:\", df_characters.shape)\nprint(\"Locations shape:\", df_locations.shape)\nprint(\"Script shape:\", df_script.shape)\nprint(\"Episodes shape:\", df_episodes.shape)",
          "Print shapes of the dataframes to check if everything went okay\nprint(f\"Characters: {df_characters.shape}\")\nprint(f\"Locations:  {df_locations.shape}\")\nprint(f\"Script:     {df_script.shape}\")\nprint(f\"Episodes:   {df_episodes.shape}\")",
          "Check dataframe shape\nprint(df_characters.shape)\nprint(df_locations.shape)\nprint(df_script.shape)\nprint(df_episodes.shape)",
          "Inspecting the dataframe shapes\nprint(df_characters.shape)\nprint(df_locations.shape)\nprint(df_script.shape)\nprint(df_episodes.shape)",
          "Checking the shape of each DataFrame\nprint(f'Shapes: characters = {df_characters.shape}, locations = {df_locations.shape}, script = {df_script.shape}, episodes = {df_episodes.shape}')",
          "Check the shape of the dataframes\nprint('Characters:', df_characters.shape)\nprint('Locations:', df_locations.shape)\nprint('Script:', df_script.shape)\nprint('Episodes:', df_episodes.shape)",
          " Check data shapes\nprint(df_characters.shape)\nprint(df_locations.shape)\nprint(df_script.shape)\nprint(df_episodes.shape)",
          "To validate the shapes of each dataframe\nprint(df_characters.shape)\nprint(df_locations.shape)\nprint(df_script.shape)\nprint(df_episodes.shape)",
          "Check data shape\nprint('Characters:', df_characters.shape)\nprint('Locations:', df_locations.shape)\nprint('Episodes:', df_episodes.shape)\nprint('Script:', df_script.shape)",
          " Check dataframe shapes\nprint(\"Characters dataframe shape:\", df_characters.shape)\nprint(\"Locations dataframe shape:\", df_locations.shape)\nprint(\"Script dataframe shape:\", df_script.shape)\nprint(\"Episodes dataframe shape:\", df_episodes.shape)",
          "Check the shapes of the imported DataFrames\nprint(\"Shape of characters DataFrame: \", df_characters.shape)\nprint(\"Shape of locations DataFrame: \", df_locations.shape)\nprint(\"Shape of script DataFrame: \", df_script.shape)\nprint(\"Shape of episodes DataFrame: \", df_episodes.shape)",
          "Checking the data shapes\nprint('Characters:', df_characters.shape)\nprint('Locations:', df_locations.shape)\nprint('Script:', df_script.shape)\nprint('Episodes:', df_episodes.shape)",
          "Check the shape of the dataframes\nprint(df_characters.shape)\nprint(df_locations.shape)\nprint(df_script.shape)\nprint(df_episodes.shape)",
          " Check the shapes of the imported DataFrames\nprint(f'df_characters shape: {df_characters.shape}')\nprint(f'df_locations shape: {df_locations.shape}')\nprint(f'df_script shape: {df_script.shape}')\nprint(f'df_epsiodes shape: {df_episodes.shape}')",
          "Check the shape of each DataFrame\nprint('Characters:', df_characters.shape)\nprint('Locations:', df_locations.shape)\nprint('Script:', df_script.shape)\nprint('Episodes:', df_episodes.shape)",
          "Check the shape of each dataframe\nprint(\"Characters df shape:\", df_characters.shape)\nprint(\"Locations df shape:\", df_locations.shape)\nprint(\"Script df shape:\", df_script.shape)\nprint(\"Episodes df shape:\", df_episodes.shape)",
          "Check our datasets\nprint(\"Characters dataset shape\", df_characters.shape)\nprint(df_characters.head())\n\nprint(\"\\nLocations dataset shape\", df_locations.shape)\nprint(df_locations.head())\n\nprint(\"\\nScript dataset shape\", df_script.shape)\nprint(df_script.head())\n\nprint(\"\\nEpisodes dataset shape\", df_episodes.shape)\nprint(df_episodes.head())",
          "Let's check the shape of each DataFrame\nprint(\"Characters DataFrame:\", df_characters.shape)\nprint(\"Locations DataFrame:\", df_locations.shape)\nprint(\"Script DataFrame:\", df_script.shape)\nprint(\"Episodes DataFrame:\", df_episodes.shape)",
          "Check the number of characters and locations\nprint(\"Number of characters:\", df_characters.shape[0])\nprint(\"Number of locations:\", df_locations.shape[0])",
          "Check data shapes\nprint(\"Characters shape:\", df_characters.shape)\nprint(\"Locations shape:\", df_locations.shape)\nprint(\"Script shape:\", df_script.shape)\nprint(\"Episodes shape:\", df_episodes.shape)",
          "Check the number of rows and columns for each dataframe\nprint(f\"Simpsons Characters: {df_characters.shape}\")\nprint(f\"Simpsons Locations: {df_locations.shape}\")\nprint(f\"Simpsons Script Lines: {df_script.shape}\")\nprint(f\"Simpsons Episodes: {df_episodes.shape}\")",
          "Check the dataframes shape\nprint(\"Characters dataframe shape:\", df_characters.shape)\nprint(\"Locations dataframe shape:\", df_locations.shape)\nprint(\"Script dataframe shape:\", df_script.shape)\nprint(\"Episodes dataframe shape:\", df_episodes.shape)",
          "Verify shape of the datasets\nprint(df_characters.shape)\nprint(df_locations.shape)\nprint(df_script.shape)\nprint(df_episodes.shape)"
         ],
         "marker": {
          "opacity": 0.5,
          "size": 5
         },
         "mode": "markers+text",
         "name": "42_DataFrame Shapes",
         "text": [
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          ""
         ],
         "textfont": {
          "size": 12
         },
         "type": "scattergl",
         "x": [
          0.14087066054344177,
          0.03138910233974457,
          0.3799252510070801,
          -0.0022580858785659075,
          0.2981293797492981,
          -0.0873238742351532,
          0.08986799418926239,
          -0.007876421324908733,
          0.3063027560710907,
          0.3500370979309082,
          0.13668803870677948,
          -0.5403879284858704,
          -0.38768550753593445,
          -0.1647387444972992,
          -0.3277492821216583,
          0.3677707612514496,
          -0.35564732551574707,
          -0.3789258897304535,
          0.06338298320770264,
          -0.45178166031837463,
          -0.10984295606613159,
          0.39936092495918274,
          -0.035836733877658844,
          0.31371092796325684,
          0.09910832345485687,
          -0.033424053341150284,
          -0.5114248991012573,
          0.21822912991046906,
          -0.2160150408744812,
          0.618529736995697,
          0.4716050326824188,
          -0.15711535513401031,
          0.5245791077613831,
          -0.30103546380996704,
          -0.20922109484672546,
          0.28909996151924133,
          0.23106442391872406,
          0.43113216757774353,
          0.3009915053844452,
          -0.15324531495571136,
          -0.37679368257522583,
          1.1338388919830322,
          0.22441211342811584,
          -0.041712891310453415,
          -0.019985049962997437,
          -0.28863656520843506
         ],
         "y": [
          -0.614938497543335,
          -1.3384109735488892,
          -1.5048354864120483,
          -0.8064197897911072,
          -2.088562488555908,
          -0.8884950280189514,
          -2.5400006771087646,
          -1.4188193082809448,
          -2.5367534160614014,
          -1.1049503087997437,
          -1.1356384754180908,
          -2.0517568588256836,
          -2.3175673484802246,
          -1.1152063608169556,
          -2.1409778594970703,
          -2.3496432304382324,
          -0.7808475494384766,
          -1.5712790489196777,
          -1.3325098752975464,
          -0.8451853394508362,
          -1.2428401708602905,
          -1.2963786125183105,
          -1.33859121799469,
          -1.1606782674789429,
          -2.4351706504821777,
          -1.3559532165527344,
          -1.3461620807647705,
          -1.7554152011871338,
          -0.49146273732185364,
          -1.5296149253845215,
          -1.5585474967956543,
          -1.4059373140335083,
          -1.4821134805679321,
          -1.2862279415130615,
          -1.4658966064453125,
          -1.394873023033142,
          -1.6319270133972168,
          -0.8845163583755493,
          -0.666283905506134,
          -0.3513675928115845,
          -1.1981277465820312,
          -0.8948990106582642,
          -1.2693580389022827,
          -1.4560986757278442,
          -1.2261461019515991,
          -1.2357816696166992
         ]
        },
        {
         "hoverinfo": "text",
         "hovertext": [
          "General config\npd.set_option('display.max_colwidth', None)",
          "Display configuration\npd.options.display.max_columns = 999\npd.options.display.max_colwidth = 100",
          "def print_full(x):\n    pd.set_option('display.max_rows', len(x))\n    pd.set_option('display.max_columns', None)\n    pd.set_option('display.width', 2000)\n    pd.set_option('display.float_format', '{:20,.2f}'.format)\n    pd.set_option('display.max_colwidth', None)\n    print(x)\n    pd.reset_option('display.max_rows')\n    pd.reset_option('display.max_columns')\n    pd.reset_option('display.width')\n    pd.reset_option('display.float_format')\n    pd.reset_option('display.max_colwidth')",
          " Set series limits to view more data\npd.set_option('display.max_rows', 300)\npd.set_option('display.max_colwidth', 300)",
          "Set display.max_colwidth to None to display large columns in full\npd.set_option('display.max_colwidth', None)",
          "Expand the width of columns in order to view text data more completely\npd.options.display.max_colwidth = 400",
          " Display setup\npd.set_option('display.max_columns', None)\npd.set_option('display.max_colwidth', 60)",
          "Read Data\n# Set configurations\npd.set_option('display.max_colwidth', 100)\npd.set_option('display.max_columns', None)",
          "# Display options\npd.set_option('display.max_rows', None)\npd.set_option('display.max_columns', None)\npd.set_option('display.width', None)\npd.set_option('display.max_colwidth', None)",
          "Display max word in each column of the datasets\npd.options.display.max_colwidth = None",
          "Setting display options for the notebooks\npd.set_option('display.max_colwidth', None)",
          "Set text column width to see whole text\npd.set_option('display.max_colwidth', None)",
          "Set max column width to see more of the conversation\npd.set_option('max_colwidth', 150)",
          "Truncate script titles because of their length for printed result clarity\npd.set_option('display.max_colwidth', 50)",
          " Some nice-to-have package settings\npd.set_option('display.max_colwidth', None)",
          "Display options\npd.set_option('display.max_columns', 500)\npd.set_option('display.width', 1000)",
          "settings\npd.set_option('display.max_rows', 500)\npd.set_option('display.max_columns', 500)\npd.set_option('display.width', 1000)",
          "Setting for the length of the lines displayed\npd.options.display.max_colwidth = 200",
          "Set max display columns and width\npd.set_option('display.max_columns', 30)\npd.set_option('display.width', 180)",
          "Display settings\npd.set_option('display.max_columns', 500)\npd.set_option('display.max_colwidth', None)",
          "pd.set_option('display.max_columns', 500)\npd.set_option('display.max_colwidth', -1)",
          "Display setting\npd.set_option('display.max_rows', 1000)\npd.set_option('display.max_columns', 1000)\npd.set_option('display.width', 1000)",
          " Set the number of words after which a \"...\" should show in print\npd.set_option('display.max_colwidth', 20)",
          " Tweak the display parameters to always show at least a part of every column's content\npd.set_option('max_colwidth', 300)",
          "Display limitations\npd.set_option('display.max_columns', 100)\npd.set_option('display.max_rows', 50)\npd.set_option('display.min_rows', 150)\npd.set_option('display.max_colwidth', 200)",
          "Set maximum column width to display more content\npd.set_option('display.max_colwidth', 500)",
          " Display maximum columns and expanded width\npd.set_option('display.max_columns', None)\npd.set_option('display.width', None)",
          "Display settings\npd.set_option('display.max_columns', None)\npd.set_option('display.max_rows', None)\npd.set_option('max_colwidth', None)",
          "Set max display rows and increase display width\npd.set_option('display.max_rows', 500)\npd.set_option('display.max_colwidth', 400)",
          "Display width to show most of the conversation\nNone;pd.set_option('display.max_colwidth', None)",
          "Display settings for tables\npd.set_option('display.max_columns', None)\npd.set_option('display.expand_frame_repr', False)\npd.set_option('max_colwidth', -1)",
          "Set max_columns and max_colwidth\npd.set_option('display.max_columns', None)\npd.set_option('max_colwidth', None)",
          "Setting custom parameters for better visualization of head/tail\npd.set_option('display.max_columns', 500)\npd.set_option('display.width', 1000)",
          "# Set the max width of the columns for better visibility\npd.options.display.max_colwidth = 100",
          "Make the rows display up to 200 characters\npd.set_option('display.max_colwidth', 200)",
          "General configuration\nLARGE_SIZE = 22\nMEDIUM_SIZE = 18\nSMALL_SIZE = 14",
          " Settings for pretty print\nnp.set_printoptions(suppress=True)\npd.set_option('display.max_columns', None)\npd.set_option('display.expand_frame_repr', False)",
          "Visual representation and render output \npd.set_option('display.max_columns', None)\npd.set_option('display.expand_frame_repr', False)\npd.set_option('max_colwidth', -1)",
          "Visualization and styling parameters\ncolors = {\n    'background': '#111111',\n    'text': '#7FDBFF',\n    'data': '#FF851B',\n    'title': '#FF4136'\n}\n\n# Display settings\npd.set_option('display.max_colwidth', 120)",
          "Display settings\npd.set_option('display.max_columns', None)  # Unlimited max columns\npd.set_option('display.max_colwidth', None)  # Unlimited max column width",
          "# Display options\npd.set_option('max_colwidth', 100)",
          "Optional set display width and max columns for tables\npd.set_option('display.max_columns', 100)\npd.set_option('max_colwidth', 100)",
          " Set the maximum column width to avoid output or data representation issues",
          " Expand the max column width to display the entire script line\npd.set_option('display.max_colwidth', None)",
          "# Ensure that displayed column limit is sufficiently large\npd.set_option('display.max_colwidth', 200)",
          " Display options\npd.set_option('display.width', 1000)\npd.set_option('display.max_columns', 25)"
         ],
         "marker": {
          "opacity": 0.5,
          "size": 5
         },
         "mode": "markers+text",
         "name": "43_Column Width Settings in pandas",
         "text": [
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          ""
         ],
         "textfont": {
          "size": 12
         },
         "type": "scattergl",
         "x": [
          24.923343658447266,
          24.926837921142578,
          24.06861686706543,
          24.24928855895996,
          24.472463607788086,
          24.071012496948242,
          24.578510284423828,
          24.972856521606445,
          24.448816299438477,
          23.71773338317871,
          24.627906799316406,
          23.969308853149414,
          24.419851303100586,
          23.73470687866211,
          24.90412139892578,
          24.22237777709961,
          24.23670196533203,
          24.868806838989258,
          24.60073471069336,
          24.931495666503906,
          24.313966751098633,
          24.166419982910156,
          24.258520126342773,
          24.032772064208984,
          23.76055335998535,
          24.155521392822266,
          24.3533935546875,
          24.75244903564453,
          24.392780303955078,
          24.75349998474121,
          24.357872009277344,
          24.552326202392578,
          24.03055763244629,
          25.017045974731445,
          24.47770118713379,
          20.081592559814453,
          23.689170837402344,
          23.870222091674805,
          23.695363998413086,
          24.719379425048828,
          24.502086639404297,
          24.727258682250977,
          23.94036293029785,
          23.79828643798828,
          24.621334075927734,
          24.299293518066406
         ],
         "y": [
          2.4152982234954834,
          1.5366154909133911,
          1.6139999628067017,
          0.8370072841644287,
          2.436636447906494,
          2.7226338386535645,
          2.013266086578369,
          2.2118372917175293,
          1.6090258359909058,
          2.6403896808624268,
          2.2860207557678223,
          2.550234794616699,
          2.2580976486206055,
          2.3382890224456787,
          2.1024043560028076,
          1.5140812397003174,
          1.3127686977386475,
          2.0461337566375732,
          1.6697092056274414,
          2.0331873893737793,
          2.0355687141418457,
          1.3215785026550293,
          2.551344633102417,
          2.40334415435791,
          1.2500817775726318,
          1.9830536842346191,
          1.4329054355621338,
          1.7352091073989868,
          1.4307024478912354,
          2.042008399963379,
          1.4965152740478516,
          2.17541241645813,
          1.0208457708358765,
          2.361696481704712,
          1.4366763830184937,
          7.328390121459961,
          1.0036156177520752,
          1.660243272781372,
          2.5670902729034424,
          1.900577425956726,
          2.333009958267212,
          1.7939562797546387,
          2.15594744682312,
          1.7428427934646606,
          1.9717693328857422,
          1.4885399341583252
         ]
        },
        {
         "hoverinfo": "text",
         "hovertext": [
          "Setting up the model and analyzing the script data",
          "As the next step, we will now preprocess the script data before performing any analysis.",
          "We'll also need some basic NLP tools, such as tokenization and lemmatization, for analyzing the script lines.",
          "I will start by examining the script data.",
          "Let's first have a look at the scripts data.",
          "Create a small sample of the script for performances",
          "\n# Scraping script information\n#",
          "Let's have a look at the script data:",
          "Check script head",
          " For this analysis, we'll focus on the script dataset.",
          "The first part of the notebook examines the scripts to build a simple chatbot.",
          "Check for broken scripts",
          "Let's take a peek at the script data!",
          "We will start by analyzing the script data.",
          "We will start by analyzing the script data.",
          "Let's start by taking an example script line and it's metadata to demonstrate the quality of our dataset.",
          "Let's take a look at the script data.",
          "For this tutorial, we focus on the script data only.",
          "Exploring the script data",
          "Check the script dataset",
          "Let's take a look at the first few script lines.",
          " Let's first start by focusing on the script data.",
          "The first step is to preprocess the data, starting with the script lines.",
          "Visualizing the script data",
          "We'll start by performing some data exploration on the script data to get a feel for the data.",
          " we'll subset the data: only consider the complete script lines, and remove any stage directions.",
          "Check the script data",
          "Discover the script dataset:",
          " Check the data; specifically, the script data.",
          " Let's start by loading the script data and taking a look at the first few rows.",
          "In this section, we will explore the data in the script dataset.",
          " First we tokenize the script into words.",
          "Let's take a look at the format and content of the script data.",
          " The script would continue by exploring and analyzing the datasets, but the provided code is enough to load the necessary data and proceed with the analysis.",
          "Initializing model and processing scripts...",
          "This script will focus on analyzing the script data.",
          " Look at the first 5 script lines to get an overview.",
          "Em primeira instancia vamos fazer uma analise nos caracteres, depois analisaremos os locais e finalmente os scripts, por isto vou\n# separar cada uma em sua propria variavel para cada uma das analises.",
          " Check if script has bee properly loaded",
          "Let's take a quick look at the scripts data.",
          "Inspect content of scripts and extract relevant metadata",
          "We’ll start by analyzing the script data. Let’s take a look at the first few rows.",
          "Inspect the content of the script dataset.",
          " Check the contents of script data.",
          "Check the content of the script dataset."
         ],
         "marker": {
          "opacity": 0.5,
          "size": 5
         },
         "mode": "markers+text",
         "name": "44_Script Data Analysis",
         "text": [
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          ""
         ],
         "textfont": {
          "size": 12
         },
         "type": "scattergl",
         "x": [
          11.713957786560059,
          11.037578582763672,
          11.747978210449219,
          10.873004913330078,
          10.942771911621094,
          10.90621280670166,
          12.106085777282715,
          11.275537490844727,
          11.60612964630127,
          11.59518814086914,
          11.218128204345703,
          11.97763729095459,
          10.936929702758789,
          11.470226287841797,
          11.46262264251709,
          11.663690567016602,
          11.248075485229492,
          11.343193054199219,
          11.251490592956543,
          11.523151397705078,
          11.25745964050293,
          10.808794975280762,
          11.323410987854004,
          10.686594009399414,
          10.985153198242188,
          10.331514358520508,
          12.069548606872559,
          11.435314178466797,
          11.868456840515137,
          10.733024597167969,
          11.54741382598877,
          12.208420753479004,
          10.91492748260498,
          11.261086463928223,
          12.627660751342773,
          11.532792091369629,
          11.437690734863281,
          11.702821731567383,
          13.115314483642578,
          11.359150886535645,
          11.045951843261719,
          10.917412757873535,
          11.566876411437988,
          12.028555870056152,
          11.393641471862793
         ],
         "y": [
          3.1087024211883545,
          2.983736038208008,
          3.9738144874572754,
          3.091719388961792,
          3.159721851348877,
          3.661670207977295,
          3.3673951625823975,
          2.8001155853271484,
          2.6348209381103516,
          3.7085354328155518,
          3.663518190383911,
          2.5886361598968506,
          3.0506906509399414,
          2.9626290798187256,
          3.153958797454834,
          2.655566453933716,
          2.822068452835083,
          3.014195442199707,
          3.2658417224884033,
          1.929004192352295,
          3.593392848968506,
          3.288912296295166,
          3.0530858039855957,
          3.903860330581665,
          3.1942527294158936,
          2.9198572635650635,
          2.6163463592529297,
          2.169711112976074,
          2.6601150035858154,
          2.9578697681427,
          2.8524410724639893,
          4.4929399490356445,
          3.2305760383605957,
          2.722928524017334,
          3.2024195194244385,
          3.00057053565979,
          3.5009653568267822,
          3.1372406482696533,
          2.0519750118255615,
          3.0612094402313232,
          3.4621613025665283,
          3.1297669410705566,
          2.215458631515503,
          2.4068970680236816,
          2.524143934249878
         ]
        },
        {
         "hoverinfo": "text",
         "hovertext": [
          "Get the \"Characters\" and \"Locations\" columns from the \"Script\" DataFrame in order to study only those lines that are related to characters and locations.",
          "quick look at the dataframes\nprint(\"Characters: \\n\", df_characters.head())\nprint(\"\\nLocations: \\n\", df_locations.head())\nprint(\"\\nScript: \\n\", df_script.head())\nprint(\"\\nEpisodes: \\n\", df_episodes.head())",
          " Show the general overview of the data\nprint(\"Character dataframe:\")\nprint(df_characters.head(3))\nprint(\"\\nLocations dataframe:\")\nprint(df_locations.head(3))\nprint(\"\\nScript lines dataframe:\")\nprint(df_script.head(3))\nprint(\"\\nEpisodes dataframe:\")\nprint(df_episodes.head(3))",
          " Display an overview of the dataframes\nprint(\"Characters: \")\ndisplay(df_characters.head())\n\nprint(\"\\nLocations: \")\ndisplay(df_locations.head())\n\nprint(\"\\nScript: \")\ndisplay(df_script.head())\n\nprint(\"\\nEpisodes: \")\ndisplay(df_episodes.head())",
          "# Example data\nprint('Characters:')\nprint(df_characters.head(10))\nprint('\\nLocations:')\nprint(df_locations.head(10))\nprint('\\nScript:')\nprint(df_script.head(10))\nprint('\\nEpisodes:')\nprint(df_episodes.head(10))",
          " Show the head of each DataFrame\nprint('Characters:')\nprint(df_characters.head())\n\nprint('\\nLocations:')\nprint(df_locations.head())\n\nprint('\\nScript:')\nprint(df_script.head())\n\nprint('\\nEpisodes:')\nprint(df_episodes.head())",
          "Quick overview of the data\nprint(\"Characters\")\nprint(df_characters.head())\nprint(\"\\nLocations\")\nprint(df_locations.head())\nprint(\"\\nScript Lines\")\nprint(df_script.head())\nprint(\"\\nEpisodes\")\nprint(df_episodes.head())",
          "Quick overview of the data\nprint(\"Characters data:\")\nprint(df_characters.head())\nprint(\"\\nLocations data:\")\nprint(df_locations.head())\nprint(\"\\nScript data:\")\nprint(df_script.head())\nprint(\"\\nEpisodes data:\")\nprint(df_episodes.head())",
          "Print the characters dataframe\nprint('Characters dataframe')\nprint(df_characters.head())\n\n# Print the locations dataframe\nprint('\\nLocations dataframe')\nprint(df_locations.head())\n\n# Print the script dataframe\nprint('\\nScript dataframe')\nprint(df_script.head())\n\n# Print the episodes dataframe\nprint('\\nEpisodes dataframe')\nprint(df_episodes.head())",
          "Checking the first few lines of the DataFrames for sanity check.\nprint('Characters:')\nprint(df_characters.head(), end='\\n\\n')\n\nprint('Locations:')\nprint(df_locations.head(), end='\\n\\n')\n\nprint('Script lines:')\nprint(df_script.head(), end='\\n\\n')",
          "## Take a look at the data\nprint('Characters')\nprint(df_characters.head())\nprint('\\nLocations')\nprint(df_locations.head())\nprint('\\nScript')\nprint(df_script.head())\nprint('\\nEpisodes')\nprint(df_episodes.head())",
          "Print some lines of the script\nfor i in range(5):\n    print(f'{df_script.iloc[i].character_id} ({df_characters[df_characters.id == df_script.iloc[i].character_id].name.values[0]]}): {df_script.iloc[i].raw_text}')",
          " Let's take a look at the first few rows of each dataframe to understand the data better.\nprint(\"Characters:\")\nprint(df_characters.head())\n\nprint(\"\\nLocations:\")\nprint(df_locations.head())\n\nprint(\"\\nScript:\")\nprint(df_script.head())\n\nprint(\"\\nEpisodes:\")\nprint(df_episodes.head())",
          "Display\nprint(\"Characters\")\nprint(df_characters.head())\nprint(\"\\nLocations\")\nprint(df_locations.head())\nprint(\"\\nScript\")\nprint(df_script.head())\nprint(\"\\nEpisodes\")\nprint(df_episodes.head())",
          " Sample the data in order to understand its structure and contents\nprint(\"Sample from the characters dataframe:\")\nprint(df_characters.sample(5))\nprint(\"\\n\")\nprint(\"Sample from the locations dataframe:\")\nprint(df_locations.sample(5))\nprint(\"\\n\")",
          "inspect data\nprint(\"Characters data frame\")\nprint(df_characters.head())\nprint(\"\\nScript data frame\")\nprint(df_script.head())",
          " Check the dataframes\nprint('Characters:')\nprint(df_characters.head())\n\nprint('\\nLocations:')\nprint(df_locations.head())\n\nprint('\\nScript:')\nprint(df_script.head())\n\nprint('\\nEpisodes:')\nprint(df_episodes.head())",
          "Set of characters to consider when analyzing the script\ncharacters_set = set(df_characters[df_characters[\"is_main_cast\"] == True].index)\n\n# Set of locations to consider when analyzing the script\nlocations_set = set(df_locations[df_locations[\"normalized\"] == True].index)",
          " View a sample of each dataframe\nprint('\\nDataframe of Characters:')\nprint(df_characters.sample(5))\nprint('\\nDataframe of Locations:')\nprint(df_locations.sample(5))\nprint('\\nDataframe of Script Lines:')\nprint(df_script.sample(5))\nprint('\\nDataframe of Episodes:')\nprint(df_episodes.sample(5))",
          " Basic information on the datasets\nprint('Characters:')\nprint(df_characters.head(2).T)\nprint('\\nLocations:')\nprint(df_locations.head(2).T)\nprint('\\nScript lines:')\nprint(df_script.head(2).T)",
          "Objectives\n# Extract script lines where at least 2 of the characters are in the same location\n# Perform NER for each line by using Spacy\n# Calculate the entity frequency for the dataframe\n# Calculate the named entity frequency for each location that is shared between the characters\n# Analyze the results and visualize them",
          "Preview the data\nprint(\"Characters data\")\nprint(df_characters.head(2))\nprint(\"\\nLocations data\")\nprint(df_locations.head(2))\nprint(\"\\nScript data\")\nprint(df_script.head(2))\nprint(\"\\nEpisodes data\")\nprint(df_episodes.head(2))",
          "Inspect the dataframes for the first time\nprint('Characters dataframe')\nprint(df_characters.head(5))\nprint('\\n\\nLocations dataframe')\nprint(df_locations.head(5))\nprint('\\n\\nScript dataframe')\nprint(df_script.head(5))\nprint('\\n\\nEpisodes dataframe')\nprint(df_episodes.head(5))",
          "Test the import of the data\nprint(\"Characters:\")\nprint(df_characters.head(5))\nprint(\"\\nLocations:\")\nprint(df_locations.head(5))\nprint(\"\\nScript:\")\nprint(df_script.head(5))\nprint(\"\\nEpisodes:\")\nprint(df_episodes.head(5))",
          "# Explore each dataframe\nprint(\"Characters dataframe:\")\nprint(df_characters.head())\nprint(\"\\nLocations dataframe:\")\nprint(df_locations.head())\nprint(\"\\nScript dataframe:\")\nprint(df_script.head())\nprint(\"\\nEpisodes dataframe:\")\nprint(df_episodes.head())",
          " Display basic information for the dataframes\nprint('Characters dataframe:')\nprint(df_characters.head())\nprint('\\nLocations dataframe:')\nprint(df_locations.head())\nprint('\\nScript dataframe:')\nprint(df_script.head())\nprint('\\nEpisodes dataframe:')\nprint(df_episodes.head())",
          "# Investigate the data\nprint(\"Characters:\")\nprint(df_characters.head())\nprint(\"\\nLocations:\")\nprint(df_locations.head())\nprint(\"\\nScript:\")\nprint(df_script.head())\nprint(\"\\nEpisodes:\")\nprint(df_episodes.head())",
          "Checking the content of each data set\nprint(\"Characters: \")\nprint(df_characters.info())\nprint(df_characters.head(10))\n\nprint(\"\\nLocations: \")\nprint(df_locations.info())\nprint(df_locations.head(10))\n\nprint(\"\\nScript (lines): \")\nprint(df_script.info())\nprint(df_script.head(10))\n\nprint(\"\\nEpisodes: \")\nprint(df_episodes.info())\nprint(df_episodes.head(10))",
          "Inspecting the first 5 rows of all datasets to understand their structure\nprint(\"Characters Data:\")\nprint(df_characters.head())\nprint(\"\\nLocations Data:\")\nprint(df_locations.head())\nprint(\"\\nScript Data:\")\nprint(df_script.head())\nprint(\"\\nEpisodes Data:\")\nprint(df_episodes.head())",
          "Print headers and .head() of dataframes\nprint(\"\\nCharacters:\")\nprint(df_characters.head())\nprint(\"\\nLocations:\")\nprint(df_locations.head())\nprint(\"\\nScript:\")\nprint(df_script.head())\nprint(\"\\nEpisodes:\")\nprint(df_episodes.head())",
          "Inspect the data\nprint('Characters:')\nprint(df_characters.head())\nprint('\\nLocations:')\nprint(df_locations.head())\nprint('\\nScript:')\nprint(df_script.head())\nprint('\\nEpisodes:')\nprint(df_episodes.head())",
          " Check the content and the type of each of the DataFrames\nprint(\"Characters DataFrame\")\nprint(df_characters.head())\nprint(\"\\nLocations DataFrame\")\nprint(df_locations.head())\nprint(\"\\nScript DataFrame\")\nprint(df_script.head())\nprint(\"\\nEpisodes DataFrame\")\nprint(df_episodes.head())",
          "Visual exploration of the data\n# Display random samples of each dataframe\nprint('Characters dataframe :')\nprint(df_characters.sample(5))\nprint('\\nLocations dataframe :')\nprint(df_locations.sample(5))\nprint('\\nScript dataframe :')\nprint(df_script.sample(5))\nprint('\\nEpisodes dataframe :')\nprint(df_episodes.sample(5))",
          "# Print basic information about the data\nprint(\"Characters:\")\nprint(df_characters.info())\nprint(df_characters.head(2))\nprint(\"\\nScript:\")\nprint(df_script.info())\nprint(df_script.head(2))",
          "Take a look at the content of each dataframe\nprint(\"Characters dataframe:\")\nprint(df_characters.head())\nprint(\"\\nLocations dataframe:\")\nprint(df_locations.head())\nprint(\"\\nScript dataframe:\")\nprint(df_script.head())\nprint(\"\\nEpisodes dataframe:\")\nprint(df_episodes.head())",
          "Quick overview of the data\nprint(\"Characters\")\nprint(df_characters.head())\nprint(\"\\nLocations\")\nprint(df_locations.head())\nprint(\"\\nScript\")\nprint(df_script.head())\nprint(\"\\nEpisodes\")\nprint(df_episodes.head())",
          " Ensure data is loaded correctly\nprint(\"Characters:\")\nprint(df_characters.head())\n\nprint(\"\\nLocations:\")\nprint(df_locations.head())\n\nprint(\"\\nScript:\")\nprint(df_script.head())\n\nprint(\"\\nEpisodes:\")\nprint(df_episodes.head())",
          " We start by printing out the begining of each dataframe to see what we are working with\nprint('Characters head')\nprint(df_characters.head())\nprint('\\nLocations head')\nprint(df_locations.head())\nprint('\\nScript head')\nprint(df_script.head())\nprint('\\nEpisodes head')\nprint(df_episodes.head())",
          "Display of a few samples of datas\nprint('Dataset examples')\nprint('\\nCharacters')\nprint(df_characters.sample(5))\nprint('\\nLocations')\nprint(df_locations.sample(5))\nprint('\\nScript')\nprint(df_script.sample(5))\nprint('\\nEpisodes')\nprint(df_episodes.sample(5))",
          " Generate a sample of each data frame to understand its structure\nprint(\"Characters dataset\")\ndisplay(df_characters.sample(5))\n\nprint(\"\\nLocations dataset\")\ndisplay(df_locations.sample(5))\n\nprint(\"\\nScript dataset\")\ndisplay(df_script.sample(5))\n\nprint(\"\\nEpisodes dataset\")\ndisplay(df_episodes.sample(5))",
          "Explore the content of these 4 dataframes\nprint(\"Characters:\\n\", df_characters.head())\nprint(\"\\n\\nLocations:\\n\", df_locations.head())\nprint(\"\\n\\nScript:\\n\", df_script.head())\nprint(\"\\n\\nEpisodes:\\n\", df_episodes.head())",
          " Show head of each DataFrame\nprint(\"Characters DataFrame:\")\nprint(df_characters.head())\nprint(\"\\nLocations DataFrame:\")\nprint(df_locations.head())\nprint(\"\\nScript DataFrame:\")\nprint(df_script.head())\nprint(\"\\nEpisodes DataFrame:\")\nprint(df_episodes.head())",
          "Check the content of all DataFrames\nprint(\"Characters:\")\nprint(df_characters.head())\nprint(\"\\n\\nLocations:\")\nprint(df_locations.head())\nprint(\"\\n\\nScript:\")\nprint(df_script.head())\nprint(\"\\n\\nEpisodes:\")\nprint(df_episodes.head())",
          "Inspect the structure of each dataframe\nprint('\\nCharacters:')\nprint(df_characters.head(2))\nprint('\\nLocations:')\nprint(df_locations.head(2))\nprint('\\nScript:')\nprint(df_script.head(2))\nprint('\\nEpisodes:')\nprint(df_episodes.head(2))",
          " Checking the structure of the dataframes\nprint(\"Characters dataframe:\")\nprint(df_characters.info())\n\nprint(\"\\nLocations dataframe:\")\nprint(df_locations.info())\n\nprint(\"\\nScript dataframe:\")\nprint(df_script.info())\n\nprint(\"\\nEpisodes dataframe:\")\nprint(df_episodes.info())"
         ],
         "marker": {
          "opacity": 0.5,
          "size": 5
         },
         "mode": "markers+text",
         "name": "45_Extracting Characters and Locations from a Script Dataframe",
         "text": [
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          ""
         ],
         "textfont": {
          "size": 12
         },
         "type": "scattergl",
         "x": [
          6.734158992767334,
          -0.5955865383148193,
          -0.34837406873703003,
          -1.1181511878967285,
          -0.15267015993595123,
          -0.8622201085090637,
          -0.06237491965293884,
          -0.1494331657886505,
          -0.5271391868591309,
          -0.2507055699825287,
          -0.6414780616760254,
          0.19846144318580627,
          -0.9824293255805969,
          -0.47055748105049133,
          -0.28531545400619507,
          0.04655469208955765,
          -0.3303622603416443,
          4.428625106811523,
          -1.133981704711914,
          0.200717955827713,
          7.343880653381348,
          -0.647225558757782,
          -0.7062373161315918,
          -0.18966782093048096,
          -0.41544026136398315,
          -0.10984889417886734,
          -0.44521036744117737,
          -0.4077076315879822,
          -0.42767849564552307,
          -1.0961703062057495,
          -0.42322245240211487,
          -0.3543979227542877,
          -0.9492111206054688,
          -0.052982211112976074,
          -0.5445439219474792,
          -0.15644097328186035,
          -0.6155821084976196,
          -1.4563654661178589,
          -0.4029126763343811,
          -0.6775854825973511,
          -0.7666526436805725,
          -0.7518038153648376,
          -0.6645631790161133,
          -0.3112437427043915,
          -0.23560303449630737
         ],
         "y": [
          4.177752494812012,
          3.8773295879364014,
          4.179254531860352,
          3.8144121170043945,
          4.11764669418335,
          4.013886451721191,
          3.8255515098571777,
          3.512235164642334,
          4.592635631561279,
          3.322221517562866,
          3.9953787326812744,
          3.8019516468048096,
          4.40467643737793,
          4.11672306060791,
          4.013062477111816,
          4.247209548950195,
          4.320544719696045,
          8.330310821533203,
          4.14383602142334,
          3.453152894973755,
          3.7287864685058594,
          3.5857350826263428,
          4.327008247375488,
          3.651857614517212,
          4.671679973602295,
          4.2063751220703125,
          3.907723903656006,
          3.224119186401367,
          3.1565372943878174,
          4.117824554443359,
          3.9148924350738525,
          4.163427829742432,
          4.471096992492676,
          3.9379961490631104,
          4.736337184906006,
          3.946600914001465,
          3.051238775253296,
          3.2667458057403564,
          3.453467845916748,
          3.4217190742492676,
          3.818239450454712,
          3.9658963680267334,
          3.4044010639190674,
          4.5606465339660645,
          4.528338432312012
         ]
        },
        {
         "hoverinfo": "text",
         "hovertext": [
          "Create a spacy model for the English language and set a variable to files directory",
          "Because we're going to be doing some text processing notebooks, we will load in the natural language processing model from `spaCy`.",
          "Setup data for spacy processing",
          " We will use `spacy` library for text pre-processing, which is large and may take a little while to download.",
          "We need to load the spaCy model that we will use for natural language processing.",
          "Creating the model.",
          "Load the required models from spacy module",
          " Get this NLP party started!",
          "Setting up Spacy",
          "Set up a personal spacy model.",
          "Set up the spaCy model and the function to properly clean sentences.",
          "Set the configuration for the Spacy language model.",
          "Create an instance of the English spacy model",
          "Load the custom Spacy pipeline if available, if not initialize and save it for later.",
          "The below code snippet shows how we load the preprocessed models from the cache directory.",
          "Set PATH to use the spaCy linguistic models.",
          "Create an instance of the English class of the spacy load.",
          "Research on NLP and SpaCy, stemming and lemmatization libraries",
          "Creating a NLP model with spacy",
          "Initiate the spaCy model for natural language processing.",
          "Initialize a spaCy nlp pipeline for part of speech tagging, entity recognition and word vectors.",
          "Create a Spacy NLP object",
          "Define spacy model and stop words",
          " Initializes a spaCy pipeline with the English model",
          "Initialize a spaCy model for natural language processing.",
          "Download the large English model for spaCy",
          "Setting spacy configuration with English model",
          " Import necessary spacy models and libraries",
          "to run the language model.",
          " Process basic Natural Language tasks using Spacy",
          "Setting up a spacy pipeline with the English model.",
          "Declare and intialize a new spacy model",
          "Create Doc class from spacy annotations",
          "Setting up Spacy models",
          "Define the location of the pretrained model and load it",
          "Instantiate the nlp object of Spacy",
          "Text data will be manipulated with spaCy and some langague model (medium or large one) is needed to preceed.",
          " Load Wikipedia and GLoVe with Spacy's medium model",
          "Create a spacy model for pre-processing episodes",
          "Downloading the spacy model for English",
          "Creating a spacy model and disabling the component we don't need",
          "Spacy's nlp pipeline, thanks to this pipeline we can have access to the entities recognized.",
          " We will instantiate a `nlp` spacy model and then suppress and serach the tokens.",
          "Create an instance of the English class in spaCy.",
          "Load spacy model."
         ],
         "marker": {
          "opacity": 0.5,
          "size": 5
         },
         "mode": "markers+text",
         "name": "46_spaCy model initialization and loading for natural language processing",
         "text": [
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          ""
         ],
         "textfont": {
          "size": 12
         },
         "type": "scattergl",
         "x": [
          15.045308113098145,
          14.898653030395508,
          15.148223876953125,
          14.702064514160156,
          14.778682708740234,
          14.373710632324219,
          15.735002517700195,
          14.323984146118164,
          15.669864654541016,
          14.934501647949219,
          14.139091491699219,
          15.471179008483887,
          14.746536254882812,
          14.736063003540039,
          15.018552780151367,
          14.633416175842285,
          15.326717376708984,
          14.688769340515137,
          14.549510955810547,
          14.548715591430664,
          13.994731903076172,
          14.556648254394531,
          14.348505020141602,
          14.864407539367676,
          14.475577354431152,
          15.439414978027344,
          15.202442169189453,
          15.458382606506348,
          14.830754280090332,
          14.483535766601562,
          14.912699699401855,
          15.014997482299805,
          14.857605934143066,
          15.538288116455078,
          15.024648666381836,
          14.49424934387207,
          14.527445793151855,
          15.198837280273438,
          14.890663146972656,
          15.695369720458984,
          15.029340744018555,
          14.447453498840332,
          14.202256202697754,
          14.939602851867676,
          15.504903793334961
         ],
         "y": [
          5.989444732666016,
          6.2233805656433105,
          5.910624980926514,
          6.416168212890625,
          6.2821245193481445,
          4.294261455535889,
          5.99837589263916,
          5.4703874588012695,
          6.204326152801514,
          5.5261945724487305,
          5.850589752197266,
          6.71142578125,
          6.1375813484191895,
          6.702315807342529,
          5.136094093322754,
          6.265988826751709,
          6.756425380706787,
          6.468684673309326,
          6.113979816436768,
          5.865081310272217,
          6.053840160369873,
          6.472782135009766,
          6.196554660797119,
          6.122420787811279,
          6.324374675750732,
          6.121170520782471,
          6.453452110290527,
          5.6372199058532715,
          5.399272441864014,
          5.778430461883545,
          5.962226390838623,
          5.802724838256836,
          6.798213481903076,
          5.521500587463379,
          5.311738014221191,
          6.513366222381592,
          6.847531318664551,
          6.291131496429443,
          5.758270263671875,
          6.134984970092773,
          5.651664733886719,
          6.68509578704834,
          6.063405990600586,
          6.92961311340332,
          6.221106052398682
         ]
        },
        {
         "hoverinfo": "text",
         "hovertext": [
          "Display the dataframes\nprint(df_characters.head(10))\nprint(df_locations.head(10))\nprint(df_script.head(10))\nprint(df_episodes.head(10))",
          " Check the contents of the files\nprint(df_characters.head())\nprint(df_locations.head())\nprint(df_script.head())\nprint(df_episodes.head())",
          "check what the dataframes look like\nprint(df_characters.head())\nprint(df_locations.head())\nprint(df_script.head())\nprint(df_episodes.head())",
          "Check the structure of the dataframes\nprint(df_characters.head())\nprint(df_locations.head())\nprint(df_script.head())\nprint(df_episodes.head())",
          "Print the header of each loaded dataset\nprint('### Characters ###')\nprint(df_characters.head(), end='\\n\\n')\nprint('### Locations ###')\nprint(df_locations.head(), end='\\n\\n')\nprint('### script lines ###')\nprint(df_script.head(), end='\\n\\n')\nprint('### Episodes ###')\nprint(df_episodes.head(), end='\\n\\n')",
          "# Show head of data\nprint(df_characters.head())\nprint(df_locations.head())\nprint(df_script.head())\nprint(df_episodes.head())",
          " Sample the data\nprint(df_characters.head())\nprint(df_locations.head())\nprint(df_script.head())\nprint(df_episodes.head())",
          "Check data\nprint(df_characters.head())\nprint(df_locations.head())\nprint(df_script.head())\nprint(df_episodes.head())",
          "Inspect dataframes\nprint(df_characters.head(5))\nprint(df_locations.head(5))\nprint(df_script.head(5))\nprint(df_episodes.head(5))",
          "Check data\nprint(\"Characters\")\nprint(df_characters.head(5))\nprint(\"Locations\")\nprint(df_locations.head(5))\nprint(\"Script\")\nprint(df_script.head(5))\nprint(\"Episodes\")\nprint(df_episodes.head(5))",
          "\n# Let's start by taking a look at the dataframes\nprint(df_characters.head())\nprint(df_locations.head())\nprint(df_script.head())\nprint(df_episodes.head())",
          " Check the loaded data\nprint(\"\\n\\n============ Checking Characters data head ============\\n\\n\")\nprint(df_characters.head(5))\n\nprint(\"\\n\\n============ Checking Locations data head ============\\n\\n\")\nprint(df_locations.head(5))\n\nprint(\"\\n\\n============ Checking Script data head ============\\n\\n\")\nprint(df_script.head(5))\n\nprint(\"\\n\\n============ Checking Episodes data head ============\\n\\n\")\nprint(df_episodes.head(5))",
          "Check the data\nprint(df_characters.head())\nprint(df_locations.head())\nprint(df_script.head())\nprint(df_episodes.head())",
          "Get a sense for the data and the columns involved\nprint(df_characters.head(5))\nprint(df_locations.head(5))\nprint(df_script.head(5))\nprint(df_episodes.head(5))",
          "display the head of the dataframes\nprint(df_characters.head())\nprint(df_locations.head())\nprint(df_script.head())\nprint(df_episodes.head())",
          "Quick look at the data\nprint(df_characters.head())\nprint(df_locations.head())\nprint(df_script.head())\nprint(df_episodes.head())",
          "Check the dataframes\nprint(\"Characters dataframe\")\nprint(df_characters.head())\nprint()\nprint(\"Locations dataframe\")\nprint(df_locations.head())\nprint()\nprint(\"Episodes dataframe\")\nprint(df_episodes.head())\nprint()\nprint(\"Script dataframe\")\nprint(df_script.head())",
          "Check the data in each DataFrame\nprint(\"Characters\")\ndisplay(df_characters.head(4))\n\nprint(\"Locations\")\ndisplay(df_locations.head(4))\n\nprint(\"Script\")\ndisplay(df_script.head(4))\n\nprint(\"Episodes\")\ndisplay(df_episodes.head(4))",
          "Explore the data\nprint('Characters\\n', df_characters.head(), '\\n')\nprint('Locations\\n', df_locations.head(), '\\n')\nprint('Script\\n', df_script.head(), '\\n')\nprint('Episodes\\n', df_episodes.head())",
          "Check out the data\nprint(df_characters.head())\nprint(df_locations.head())\nprint(df_script.head())\nprint(df_episodes.head())",
          " Display (head) of those dataframes\nprint(df_characters.head())\nprint(df_locations.head())\nprint(df_script.head())\nprint(df_episodes.head())",
          "Check data structures\nprint(df_characters.head())\nprint(df_locations.head())\nprint(df_script.head())\nprint(df_episodes.head())",
          "Optional print dataframes for a quick overview\nprint(df_characters.head())\nprint(df_locations.head())\nprint(df_script.head())\nprint(df_episodes.head())",
          "Quick look at the data\nprint(df_characters.head())\nprint(df_locations.head())\nprint(df_script.head())\nprint(df_episodes.head())",
          "# First look at the data\nprint('First look at the data')\nprint(df_episodes.head(), '\\n\\n', df_episodes.info())\nprint(df_characters.head(), '\\n\\n', df_characters.info())\nprint(df_locations.head(), '\\n\\n', df_locations.info())\nprint(df_script.head(), '\\n\\n', df_script.info())",
          "Checking the data and its shape\nprint(df_characters.head(5))\nprint(df_locations.head(5))\nprint(df_script.head(5))\nprint(df_episodes.head(5))",
          "Look into the first few records\nprint(\"Characters\")\nprint(df_characters.head(5))\n\nprint(\"Locations\")\nprint(df_locations.head(5))\n\nprint(\"Script\")\nprint(df_script.head(5))\n\nprint(\"Episodes\")\nprint(df_episodes.head(5))",
          "Inspect data\nprint(df_characters.head())\nprint(df_locations.head())\nprint(df_script.head())\nprint(df_episodes.head())",
          " Headers of each dataframe\nprint(\"\\n### Characters\\n\", df_characters.columns.tolist())\nprint(\"\\n### Locations\\n\", df_locations.columns.tolist())\nprint(\"\\n### Script lines\\n\", df_script.columns.tolist())\nprint(\"\\n### Episodes\\n\", df_episodes.columns.tolist())",
          "Check all the datasets\nprint(\"df_characters\\n\")\ndisplay(df_characters.head(5))\nprint(\"\\n\\n\")\n\nprint(\"df_locations\\n\")\ndisplay(df_locations.head(5))\nprint(\"\\n\\n\")\n\nprint(\"df_script\\n\")\ndisplay(df_script.head(5))\nprint(\"\\n\\n\")\n\nprint(\"df_episodes\\n\")\ndisplay(df_episodes.head(5))",
          "Check dataframes\nprint(df_characters.head())\nprint(df_locations.head())\nprint(df_script.head())\nprint(df_episodes.head())",
          "Inspecting the data\nprint(df_characters.head())\nprint(df_locations.head())\nprint(df_script.head())\nprint(df_episodes.head())",
          "data exploration\nprint(df_characters.head())\nprint(df_locations.head())\nprint(df_script.head())\nprint(df_episodes.head())",
          " Display how the dataframe looks\nprint(df_characters.head())\nprint(df_locations.head())\nprint(df_episodes.head())\nprint(df_script.head())",
          " Print all the datasets\nprint('Character Data: ', df_characters.head())\nprint('Location Data: ', df_locations.head())\nprint('Script Data: ', df_script.head())\nprint('Episode Data: ', df_episodes.head())",
          "Print head of each dataframe\nprint(df_characters.head())\nprint(df_locations.head())\nprint(df_script.head())\nprint(df_episodes.head())",
          "Check the dataframes\nprint(df_characters.head())\nprint(df_locations.head())\nprint(df_script.head())\nprint(df_episodes.head())",
          "# Check data content\nprint(df_characters.head())\nprint(df_locations.head())\nprint(df_script.head())\nprint(df_episodes.head())",
          "Check what we have in each DataFrame\nprint(df_characters.head(5))\nprint(df_locations.head(5))\nprint(df_script.head(5))\nprint(df_episodes.head(5))",
          "View data structure\nprint(df_characters.head())\nprint(df_locations.head())\nprint(df_script.head())\nprint(df_episodes.head())",
          "Print out head of each dataframe\nprint(df_characters.head())\nprint(df_locations.head())\nprint(df_script.head())\nprint(df_episodes.head())",
          "Print sample data\nprint(df_characters.head(2))\nprint(df_locations.head(2))\nprint(df_script.head(2))\nprint(df_episodes.head(2))",
          " Sample the script, characters, and locations DataFrames\ndf_characters.head(), df_locations.head(), df_script.head()",
          "display basic statistics\nprint(df_characters.head())\nprint(df_locations.head())\nprint(df_script.head())\nprint(df_episodes.head())",
          "data overview\nprint(\"\\n======== Characters =======\")\nprint(df_characters.head(3))\n\nprint(\"\\n======== Locations =======\")\nprint(df_locations.head(3))\n\nprint(\"\\n======== Script =======\")\nprint(df_script.head(3))\n\nprint(\"\\n======== Episodes =======\")\nprint(df_episodes.head(3))"
         ],
         "marker": {
          "opacity": 0.5,
          "size": 5
         },
         "mode": "markers+text",
         "name": "47_Quick look at the data",
         "text": [
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          ""
         ],
         "textfont": {
          "size": 12
         },
         "type": "scattergl",
         "x": [
          -2.366691827774048,
          -1.6098476648330688,
          -1.5045956373214722,
          -1.9223926067352295,
          -1.0984892845153809,
          -1.8408454656600952,
          -1.4467439651489258,
          -2.0707221031188965,
          -1.9748588800430298,
          -1.2003018856048584,
          -2.3882627487182617,
          -0.998438835144043,
          -1.887805700302124,
          -1.1762880086898804,
          -2.3705825805664062,
          -1.708219051361084,
          -1.2031948566436768,
          -1.5560967922210693,
          -0.8762037754058838,
          -1.3366219997406006,
          -2.2428908348083496,
          -1.7621341943740845,
          -1.945219874382019,
          -1.4213203191757202,
          -0.8308795094490051,
          -1.5641111135482788,
          -1.2621756792068481,
          -1.7649095058441162,
          -1.1590911149978638,
          -1.1035844087600708,
          -1.6417779922485352,
          -1.5209084749221802,
          -1.9516514539718628,
          -2.1168766021728516,
          -0.7804171442985535,
          -2.407559633255005,
          -1.7748007774353027,
          -1.787912130355835,
          -1.829937219619751,
          -1.524970293045044,
          -2.5659847259521484,
          -1.7135794162750244,
          -2.1250104904174805,
          -1.1798479557037354,
          -1.2873289585113525
         ],
         "y": [
          2.9161336421966553,
          1.6721718311309814,
          1.3766778707504272,
          1.5664628744125366,
          2.2469451427459717,
          2.623532772064209,
          2.3044681549072266,
          1.5959581136703491,
          2.0547831058502197,
          2.0558278560638428,
          2.433938503265381,
          2.9424068927764893,
          1.6394518613815308,
          1.9865576028823853,
          2.70038104057312,
          2.276628255844116,
          1.4563658237457275,
          2.3089354038238525,
          2.870995283126831,
          2.2605679035186768,
          2.8605637550354004,
          1.3846055269241333,
          2.1389191150665283,
          2.3428661823272705,
          2.644294023513794,
          1.6915806531906128,
          2.7210116386413574,
          2.0863912105560303,
          2.509061098098755,
          2.795534610748291,
          1.4414196014404297,
          2.164456367492676,
          1.9615635871887207,
          2.61102032661438,
          2.47467041015625,
          2.914159059524536,
          1.4421628713607788,
          1.8678010702133179,
          1.7455099821090698,
          2.5057826042175293,
          3.018690347671509,
          2.1712682247161865,
          2.524636745452881,
          2.1491804122924805,
          2.54038143157959
         ]
        },
        {
         "hoverinfo": "text",
         "hovertext": [
          "Display 5 rows of the dataframe to check if the data is loaded successfully.",
          "Let's display the first 5 rows of each dataframe to understand what kind of data we are working with.",
          "Display the first 5 rows of each dataframe to understand their structure and the data they contain.",
          "Print the first 5 rows of each dataframe to understand the data",
          " Extract the first five items of each dataframe",
          " Display the first 5 rows of each dataframe to get a quick look at the data",
          "Let's use the head() method to display the first 5 rows of each DataFrame and understand how the data is structured.",
          " Display the first 5 rows of each dataframe to get an idea of the data",
          "Note: in the following dataframe printouts, instead of providing the full row, only the first \n# five items are printed.",
          "Display the first 5 rows of each dataframe to have an idea on the structure of the data.",
          "Display the first 5 rows of each dataframe to ensure everything loaded correctly.",
          "Display first 5 records of all the dataframes",
          "Print the first 5 rows of each dataframe to understand the data structure better",
          "Let's explore the data by showing the first 5 rows of each dataframe.",
          "Display the first 5 lines of each dataframe to understand the data better",
          " Display the first 5 rows of each dataframe to get a quick overview of the data",
          "Display the first 5 rows of each dataframe to understand the structure of the data.",
          "Let's take a glimpse of the first 5 rows of this dataframe-",
          "Display first 5 rows of each dataframe to understand the data",
          "Inspect dataframes first 5 rows",
          "Display the first 5 lines of each dataframe to understand its structure and the information available.",
          "Inspect each dataframe and display its first five rows",
          "Display the first 5 rows of each DataFrame to understand the data.",
          "Show the first 5 rows of each dataframe to get a sense of the data",
          "Get the first 5 rows of each DataFrame for a quick look at the data",
          " We start by displaying the 5 first lines of each dataframe.",
          "Explore the first 5 rows of each dataframe",
          "Display first 5 rows of each dataframe",
          "Show the first five rows of each dataframe to understand the data",
          " Display the first 5 rows of each dataframe",
          "Display the first 5 rows of each dataframe to understand the data",
          "Preview the first 5 rows of each dataframe",
          "Display the first 5 rows of each dataframe to understand the data",
          " Show the first 5 records for each DataFrame",
          " Display the first 5 rows of each dataframe to display the structure of the data.",
          "Display the first 5 rows of each dataframe to better understand the data",
          "Let's print the first 5 rows from each dataframe to better understand their structure.",
          "Let's display the first 5 rows of each dataframe to understand better the data structure.",
          "Show the first 5 rows of each dataframe to understand the data structure",
          "View the data.head() to check the first 5 rows of data\tload_data()",
          "Display the first 5 rows of each dataframe",
          "Print the first 5 rows of each dataframe to understand the data",
          " Display the first 5 rows of each dataframe to get an overview of the data",
          "This will display the first 5 rows of each dataframe with their names.",
          "Show the first 5 records of each dataframe to understand the structure and content of the data."
         ],
         "marker": {
          "opacity": 0.5,
          "size": 5
         },
         "mode": "markers+text",
         "name": "48_Understanding Dataframe Structure",
         "text": [
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          ""
         ],
         "textfont": {
          "size": 12
         },
         "type": "scattergl",
         "x": [
          13.179299354553223,
          13.350214958190918,
          13.719225883483887,
          13.920003890991211,
          13.40373706817627,
          14.262664794921875,
          13.655537605285645,
          14.128201484680176,
          13.666952133178711,
          13.93579387664795,
          13.75117015838623,
          14.105454444885254,
          13.923965454101562,
          12.93804931640625,
          13.648554801940918,
          14.629342079162598,
          13.790867805480957,
          13.654960632324219,
          14.188516616821289,
          13.555237770080566,
          13.32573413848877,
          14.18914794921875,
          13.918785095214844,
          14.616922378540039,
          13.969229698181152,
          13.041240692138672,
          13.805103302001953,
          14.221355438232422,
          14.050981521606445,
          14.281643867492676,
          14.159528732299805,
          14.68114948272705,
          14.276443481445312,
          14.122371673583984,
          14.186493873596191,
          14.320096015930176,
          13.610574722290039,
          13.573481559753418,
          13.570779800415039,
          13.179231643676758,
          14.051558494567871,
          13.97207260131836,
          14.287784576416016,
          14.261663436889648,
          14.06562328338623
         ],
         "y": [
          -6.813449382781982,
          -7.141805171966553,
          -7.245490550994873,
          -5.912996292114258,
          -6.537238597869873,
          -6.404334545135498,
          -7.1167168617248535,
          -6.3679423332214355,
          -5.855767726898193,
          -7.336101055145264,
          -7.075196743011475,
          -6.299884796142578,
          -6.330864906311035,
          -6.94727897644043,
          -7.077182769775391,
          -6.387020587921143,
          -7.244197368621826,
          -6.256067276000977,
          -6.366934776306152,
          -6.088922500610352,
          -7.783407688140869,
          -6.643470764160156,
          -6.6653547286987305,
          -6.312687873840332,
          -6.217311859130859,
          -7.55448579788208,
          -6.4729461669921875,
          -6.699467658996582,
          -6.759786605834961,
          -6.479487895965576,
          -6.494353294372559,
          -6.558698654174805,
          -6.450819969177246,
          -6.115588188171387,
          -7.444342136383057,
          -6.781304836273193,
          -6.613032341003418,
          -7.389528274536133,
          -7.08021354675293,
          -6.488542079925537,
          -6.4809956550598145,
          -5.86885404586792,
          -6.630331039428711,
          -6.9411821365356445,
          -7.097327709197998
         ]
        },
        {
         "hoverinfo": "text",
         "hovertext": [
          "select the necessary columns from the dataframes",
          "Remove unwanted columns from the dataframe",
          "Filtering out \"bad\" records on on df_script",
          "Remove unnecessary columns from dataframe",
          "Remove invalid rows from df_script",
          "Remove unnecessary columns from the dataframe",
          "Drop unwanted columns from the dataframes",
          " Remove unused columns from the dataframes",
          "Remove unnecessary columns from df_script",
          "Remove items which weren't referenced in another dataframe",
          "To get rid of some columns that we don't need in some dataframes",
          "filtering out bad data from each dataframe",
          "Remove unwanted columns and simplify the characters dataframe",
          "Remove useless columns in some dataframes",
          "Remove useless columns from each dataframe",
          "Smaller dataframes with the essential columns only",
          "Remove unnecessary columns from the dataframes",
          "Remove unwanted columns from each dataframe",
          "Remove unnecessary columns from the characters dataframe",
          "Remove unnecessary columns from dataframes",
          "Remove the 'Unnamed: 0' column from all dataframes since it is not needed",
          "Remove duplicate columns from the dataframes",
          "Filtering out of the dataframe to only retain the useful columns",
          "Remove the unamed column from dataframes",
          "Remove unnecessary columns and NA values from df_script",
          "Removing unnecessary unnamed columns if any from the dataframes.",
          "Remove unnecessary columns in some dataframes",
          "Remove unwanted columns from the characters, locations and script DataFrames",
          "Fixing name of the columns with right index numbers in dataframe and discarding unwanted columns",
          "Filter and remove rows with information unvailable in any df",
          "Remove all unnecessary columns from the dataframe",
          "Filtering raw dataframe",
          "Remove unnecessary columns and join the dataframes",
          "Remove columns that we don't need from the dataframes",
          "Don't truncate text fields in the DataFrame display",
          "Remove unwanted columns from the dataframes",
          " Remove unwanted column from the dataframes",
          "Remove redundant columns from the dataframe",
          "Filters irrelevant columns from the characters dataframe",
          "Select only the necessary columns for this MVP (Minimum Viable Product) in the df_script dataframe.",
          "Do some cleanup on the original DataFrames and drop unnecesary columns",
          "Remove unwanted columns from the dataframes",
          "Remove rows with missing values from the following DataFrames:",
          "Removing data that doesn't fit our use case from the dataframe"
         ],
         "marker": {
          "opacity": 0.5,
          "size": 5
         },
         "mode": "markers+text",
         "name": "49_Remove unnecessary columns from dataframes",
         "text": [
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          ""
         ],
         "textfont": {
          "size": 12
         },
         "type": "scattergl",
         "x": [
          7.761807441711426,
          7.806645393371582,
          8.182208061218262,
          7.619580268859863,
          7.290384292602539,
          7.583189487457275,
          8.300676345825195,
          8.20497989654541,
          7.362990856170654,
          7.709957599639893,
          8.03711986541748,
          9.142326354980469,
          7.249267101287842,
          8.157466888427734,
          7.996958255767822,
          8.044218063354492,
          7.776873588562012,
          8.1091890335083,
          7.120450019836426,
          7.708583354949951,
          7.684241771697998,
          7.411504745483398,
          8.257111549377441,
          7.654820442199707,
          7.114143371582031,
          7.434487342834473,
          7.954927444458008,
          7.039430141448975,
          7.854111194610596,
          8.182069778442383,
          7.609581470489502,
          8.670400619506836,
          7.348477840423584,
          7.995174407958984,
          21.29368782043457,
          7.752932548522949,
          7.6815690994262695,
          7.490294456481934,
          6.865366458892822,
          7.365446090698242,
          8.289543151855469,
          8.022821426391602,
          8.082329750061035,
          7.831474304199219
         ],
         "y": [
          0.8537012934684753,
          2.102628469467163,
          2.3619210720062256,
          1.5489884614944458,
          2.7569241523742676,
          1.5330678224563599,
          1.6444915533065796,
          1.3914583921432495,
          0.7894105315208435,
          1.7988777160644531,
          1.96201753616333,
          1.9998722076416016,
          2.5528173446655273,
          1.6495692729949951,
          1.2813087701797485,
          1.031281590461731,
          1.6804975271224976,
          1.9505939483642578,
          3.036843776702881,
          1.4672907590866089,
          2.7788822650909424,
          2.3695545196533203,
          1.5767855644226074,
          2.103708267211914,
          2.153841018676758,
          1.7984273433685303,
          1.5849277973175049,
          2.8164055347442627,
          1.5517969131469727,
          2.3380215167999268,
          1.3978091478347778,
          1.8883202075958252,
          1.3077973127365112,
          1.7297900915145874,
          2.4288549423217773,
          1.9655574560165405,
          2.0643436908721924,
          2.1440913677215576,
          4.038015842437744,
          2.268247365951538,
          1.0059505701065063,
          2.061445713043213,
          0.9587026238441467,
          1.6604262590408325
         ]
        },
        {
         "hoverinfo": "text",
         "hovertext": [
          " View the dataframes' head\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()",
          "Inspect df_script and df_episodes DataFrames\ndf_script.head()",
          "View dataframes head\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()",
          "Show all dataframes\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()",
          "A quick preview of the dataframes\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()",
          "Display the loaded pandas dataframes\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()",
          "Inspect data\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()",
          "View the data\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()",
          "View data in the different csv files\nprint(df_characters.head())\nprint(df_locations.head())\nprint(df_script.head())\nprint(df_episodes.head())",
          " Show header of all dataframes\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()",
          "Display all dataframes - Checking Data\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()",
          "view_dataframes(df_characters, df_locations, df_script, df_episodes)",
          "Display the dataframes\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()",
          "Show the available dataframes\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()",
          " Display a sample of the data for each dataframe\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()",
          "View the dataframes\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()",
          "Display data\ndf_characters.head()\ndf_locations.head()\ndf_script.head()\ndf_episodes.head()",
          " Display the data\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()",
          "Display the dataframes\ndf_script.head(), df_characters.head(), df_locations.head(), df_episodes.head()",
          "Displaying the content of the new dataframes\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()",
          "displaying all dataframes for exploration\ndf_characters.head(), \ndf_locations.head(), \ndf_script.head(), \ndf_episodes.head()",
          "view each dataframe\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()",
          "# Data preload\ncharacters = df_characters.to_dict(orient='records')\nlocations = df_locations.to_dict(orient='records')\nepisodes = df_episodes.to_dict(orient='records')\n\n# Show episodes' data\ndf_episodes.head()",
          "Display the loaded data\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()",
          "Display the data frames\ndf_characters, df_locations, df_script, df_episodes",
          " Show head of dataframes\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()",
          " Display the contents of the four DataFrames with the .head() method\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()",
          "View data tables\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()",
          "Inspecting Data\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()",
          "Inspect dataframes\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()",
          "Uncomment and run the following lines to display part of the content in each dataframe\n# df_episodes.head(3)\n# df_locations.head(3)\n# df_characters.head(3)\n# df_script.head(3)",
          "View some data from the locations DataFrame\ndf_locations.head()",
          "Display the head of the dataframes\ndf_episodes.head(), df_characters.head(), df_locations.head(), df_script.head()",
          "Display head of the dataframes\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()",
          "Displaying the data.\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()",
          "Display the data\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()",
          " Display the data\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()",
          " Take a quick look at the first few lines of each data frame\ndisplay(df_characters.head(5))\ndisplay(df_locations.head(5))\ndisplay(df_script.head(5))\ndisplay(df_episodes.head(5))",
          " Display the different dataframes\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()",
          "Inspect dataframes\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()",
          "Display data from all datasets\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()",
          "Show the head of each loaded dataframe\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()",
          "Explore data\n(df_characters[:5], df_locations[:5], df_script[:5], df_episodes[:5])",
          " view dataframes\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()"
         ],
         "marker": {
          "opacity": 0.5,
          "size": 5
         },
         "mode": "markers+text",
         "name": "50_Viewing Dataframes",
         "text": [
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          ""
         ],
         "textfont": {
          "size": 12
         },
         "type": "scattergl",
         "x": [
          -3.568922758102417,
          -2.5718157291412354,
          -3.2361984252929688,
          -3.3908028602600098,
          -3.749009847640991,
          -3.0756521224975586,
          -3.1894891262054443,
          -3.30222749710083,
          -2.9607105255126953,
          -2.9113762378692627,
          -3.675985336303711,
          -2.827846050262451,
          -2.7505886554718018,
          -3.0431673526763916,
          -2.3590056896209717,
          -3.317934989929199,
          -3.1164655685424805,
          -2.7139103412628174,
          -2.8584256172180176,
          -2.9593677520751953,
          -3.365762948989868,
          -3.5580458641052246,
          -3.361156702041626,
          -3.337397575378418,
          -1.9667760133743286,
          -3.503018379211426,
          -2.864806652069092,
          -3.041179656982422,
          -3.3810575008392334,
          -3.2981925010681152,
          -3.301616668701172,
          -2.6647543907165527,
          -3.323949098587036,
          -3.0189945697784424,
          -2.958655834197998,
          -3.1680688858032227,
          -3.060945987701416,
          -2.981626272201538,
          -3.164226531982422,
          -3.4169154167175293,
          -2.945474624633789,
          -3.4348175525665283,
          -2.9201974868774414,
          -3.2509045600891113
         ],
         "y": [
          2.1044061183929443,
          1.698046326637268,
          2.334959030151367,
          2.32855486869812,
          2.237921714782715,
          2.4496731758117676,
          1.8378651142120361,
          2.1963579654693604,
          2.1961255073547363,
          2.188776731491089,
          1.9865880012512207,
          2.3202924728393555,
          2.158670663833618,
          1.6708816289901733,
          2.914247751235962,
          1.764360785484314,
          2.328326463699341,
          2.1427159309387207,
          2.4575843811035156,
          2.646869659423828,
          2.455348014831543,
          2.1565780639648438,
          2.838961124420166,
          2.622147798538208,
          2.5547420978546143,
          2.3788578510284424,
          2.2179946899414062,
          2.5863516330718994,
          1.7422071695327759,
          2.1236870288848877,
          2.9221763610839844,
          2.0341126918792725,
          2.323164939880371,
          2.486987352371216,
          2.1625125408172607,
          2.264735698699951,
          2.1197733879089355,
          2.7617692947387695,
          2.2961204051971436,
          2.07275390625,
          2.8376760482788086,
          2.5475656986236572,
          2.700578212738037,
          2.5701420307159424
         ]
        },
        {
         "hoverinfo": "text",
         "hovertext": [
          "Get division lines from each script line.",
          "Create a subset of the script data that contains only the fields of interest",
          "preprocessing the script data",
          "Remove punctuation from the script lines and lowercase the text.",
          "Check if script lines contain uppercase words",
          " Extracting the text of the script lines for further analysis",
          "Display the list of available script lines.",
          "Clean up some of the script line columns to strings.",
          "Build corpus for script lines",
          " How many lines of script do we have?",
          "Check the first few script lines",
          "Display the script lines.",
          " preprocess each script line",
          "Preprocess script lines",
          "Create columns with lower and punctuation-free lines of scripts for faster and smoother processing.",
          "I'm going to clean the script data.",
          "Show top 20 script lines",
          "Let's clean the Script data first.",
          "Filtered script lines for performing text analysis",
          "Mixin external data into script data",
          "Lower case the script lines",
          "Display the first 5 script lines.",
          " Set the script type to string",
          "Show the first few script lines.",
          "We do this to avoid retyping these lines every time we make a change to our python scripts.",
          "print the number of script lines ",
          "Look at the first 5 script lines",
          "Let's print a single script line.",
          "Get a random script line",
          "Set up path to find the `style` module\nos.sys.path.append('script_parser')",
          " Display output of all lines of code and not just the output of the last line",
          " Reformat the script data to include only the information that is relevant to our project",
          "Script lines contain more information that we won't need for this analysis, so we'll filter the columns we want to keep.",
          "Start by checking the number of rows (i.e. lines, with one line being a character's speaking turn) in the script data.",
          " Hashing of the script line text column",
          "List first 5 script lines.",
          "Combining script lines with metadata",
          "Function to load the category of a script line from its line id.",
          "Categorize the script lines by character",
          "Set up the script column map for easier retrieval of script lines",
          "Takes around 30 seconds to import 1.3 million script lines",
          "let's see how the scripts looks with all the cleaned text",
          "Store all unique script IDs in a list for further processing.",
          "Set the script line ID as the index for easy retrieval of script lines"
         ],
         "marker": {
          "opacity": 0.5,
          "size": 5
         },
         "mode": "markers+text",
         "name": "51_Script line preprocessing and retrieval",
         "text": [
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          ""
         ],
         "textfont": {
          "size": 12
         },
         "type": "scattergl",
         "x": [
          10.697877883911133,
          9.544520378112793,
          10.859158515930176,
          10.566123008728027,
          10.346748352050781,
          10.974136352539062,
          10.586097717285156,
          10.204920768737793,
          11.545169830322266,
          10.648327827453613,
          10.917583465576172,
          11.343180656433105,
          10.96146297454834,
          10.721590995788574,
          9.403430938720703,
          10.61764144897461,
          10.792346000671387,
          10.171567916870117,
          10.769136428833008,
          9.805511474609375,
          10.760048866271973,
          10.914650917053223,
          11.356526374816895,
          10.935053825378418,
          11.022192001342773,
          10.644996643066406,
          11.170730590820312,
          11.287701606750488,
          10.369658470153809,
          12.369904518127441,
          10.948736190795898,
          9.948431968688965,
          10.30919361114502,
          10.341609001159668,
          10.327086448669434,
          11.0916109085083,
          10.548345565795898,
          9.45615005493164,
          10.233707427978516,
          9.914670944213867,
          11.949250221252441,
          10.668941497802734,
          8.804902076721191,
          8.634855270385742
         ],
         "y": [
          4.3030805587768555,
          2.341668128967285,
          3.1318166255950928,
          3.8405637741088867,
          4.6495161056518555,
          3.919025182723999,
          3.8685665130615234,
          3.5814151763916016,
          4.544612407684326,
          4.464941501617432,
          3.5971837043762207,
          3.7700130939483643,
          3.8205995559692383,
          3.7043521404266357,
          4.01765251159668,
          3.236752510070801,
          4.459152698516846,
          2.9841747283935547,
          3.8830933570861816,
          2.236253499984741,
          3.9679601192474365,
          4.235803604125977,
          2.9113264083862305,
          4.0495991706848145,
          3.6660821437835693,
          5.084746360778809,
          3.8292930126190186,
          4.338467121124268,
          3.920454263687134,
          3.834111213684082,
          4.619104862213135,
          2.675215482711792,
          3.23547101020813,
          3.744370698928833,
          4.13510274887085,
          4.264306545257568,
          4.044471740722656,
          3.766007661819458,
          4.376863479614258,
          3.525545835494995,
          3.5528926849365234,
          3.3823299407958984,
          3.178393840789795,
          3.476670742034912
         ]
        },
        {
         "hoverinfo": "text",
         "hovertext": [
          "We will start by exploring the data to understand its structure, contents, and how everything relates together.",
          "We will take a brief look at the data to understand its structure and contents.",
          "First, let's take a look at the data to understand its structure and the type of information it contains.",
          "Let's start by having an overview of the data.",
          "Let's take a look at the data to understand its structure.",
          "We'll need to do some data preprocessing before we can start the analysis.",
          " Let's take a quick look at the data and understand its structure.",
          "Let's take a look at the structure of our data.",
          "Let's take a look at the structure of our data.",
          "Let's start by exploring the data and understand its structure and contents.",
          "Explore the data to understand the structure and content.",
          " Now it would be a good time to look into the data to see how it is structured and what kind of data is actually stored inside.",
          " Let's first examine the structure of the data.",
          " The next step is to preprocess and explore the data to gain insights.",
          "Let's take a look at the data to understand its structure and content.",
          " Let's start by exploring the data and visualizing some interesting statistics.",
          " Sure, I can help you with that. What would you like to do next?",
          "Let's print some basic information to start with.",
          "The first step is to load the data into our notebook so we can begin exploring it.",
          "We'll start by exploring the data to understand its structure and contents.",
          "Let's take a quick look at the data to understand its structure.",
          "We will start by taking a look at the data to understand its structure and content.",
          " Now, we will prepare the data for analysis.",
          "Let's explore the data to understand its structure and content.",
          "We'll first take a look at how the data is structured and what it looks like.",
          "We will first review the data to understand its structure and content.",
          "Let's first explore the data to see what fields we have and what kind of data is in them.",
          "Let's start by taking a quick look at some of the data to understand its structure.",
          " We'll start by doing a bit of initial exploration of the data that we have.",
          " We will start our analysis by exploring the data and understanding its structure.",
          "We'll start by having a look at the data to understand its structure and content.",
          "Let's take a look at the data to understand its structure and content.",
          "We will start by doing some exploration of the data.",
          " For simplicity, only keep the data we'll need for this analysis.",
          " It's plain to observe that we may need an write to the database.",
          "Let's start by exploring the data.",
          " We will first clean and preprocess the data to get it into a form suitable for analysis.",
          "Let's first take a look at the structure of our data.",
          "The following will be about what we will do next.",
          "# We are now ready to start the analysis.",
          "Let's take a quick look at the data to understand its structure and content.",
          "Let's take a look at the data to understand its structure.",
          " Let's start by overviewing the data."
         ],
         "marker": {
          "opacity": 0.5,
          "size": 5
         },
         "mode": "markers+text",
         "name": "52_Understanding data structure through exploration",
         "text": [
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          ""
         ],
         "textfont": {
          "size": 12
         },
         "type": "scattergl",
         "x": [
          16.367496490478516,
          17.293601989746094,
          16.6379451751709,
          16.4094295501709,
          17.140050888061523,
          16.318157196044922,
          17.126617431640625,
          17.592845916748047,
          17.727073669433594,
          16.533781051635742,
          16.31174087524414,
          16.941280364990234,
          17.565988540649414,
          16.163387298583984,
          17.180803298950195,
          16.792022705078125,
          17.012224197387695,
          16.857585906982422,
          16.29237937927246,
          16.231691360473633,
          17.18279457092285,
          16.7889404296875,
          17.069913864135742,
          17.030263900756836,
          17.21541976928711,
          16.76862907409668,
          17.702104568481445,
          16.720369338989258,
          16.748754501342773,
          16.484878540039062,
          16.49380111694336,
          17.46137046813965,
          16.882905960083008,
          17.093425750732422,
          16.296768188476562,
          16.855731964111328,
          15.80381965637207,
          17.723548889160156,
          17.344194412231445,
          16.954591751098633,
          17.24069595336914,
          17.35976791381836,
          16.311355590820312
         ],
         "y": [
          -0.9341530203819275,
          -1.0464709997177124,
          -1.123314380645752,
          -1.0671433210372925,
          -0.8242862820625305,
          0.14185108244419098,
          -1.0039860010147095,
          -0.43273717164993286,
          -0.2784993648529053,
          -0.634485125541687,
          -0.9831566214561462,
          -0.3469304144382477,
          -0.7971687316894531,
          0.5262160301208496,
          -1.125167965888977,
          -1.3646034002304077,
          -0.3685495853424072,
          -1.1073158979415894,
          -0.9755256175994873,
          -0.757450520992279,
          -1.0175061225891113,
          -0.9304915070533752,
          0.2227095067501068,
          -0.85254967212677,
          -0.43575215339660645,
          -0.8905156850814819,
          -0.9076288342475891,
          -1.0510873794555664,
          -0.626855731010437,
          -0.28045618534088135,
          -0.8624212145805359,
          -0.6137742400169373,
          -0.5054419636726379,
          0.1642588973045349,
          0.13555863499641418,
          -0.5985727906227112,
          0.5923594832420349,
          -0.8342587351799011,
          0.025759048759937286,
          -0.35349905490875244,
          -0.6647472977638245,
          -0.6464464068412781,
          -1.073885440826416
         ]
        },
        {
         "hoverinfo": "text",
         "hovertext": [
          "Let's take a quick look at the data to understand what we are working with.",
          "Let's see what's inside the skript data.",
          "let's take a look at the data",
          "Let's take a peak at some of the data.",
          " Let's take a look at the data to understand what we are working with.",
          " Now we'll come up with a few potential questions to answer with the data.",
          " Let's have a look at the data.",
          "Let's have a look at the data.",
          " Let's check the data available.",
          "Inspecting the raw data to see what we have here...",
          "Lets take a sneak peak at the data.",
          "Let's have a first look at the data we have.",
          " Let's take a look at the data.",
          " Let's take a quick look at our data!",
          " Let's take a look at the data we have.",
          "Let's see what we are working with.",
          "Let's inspect the data.",
          "Let's have a look at the data.",
          "Let's take a closer look at the data we're working with.",
          " Let's examine the available data.",
          "Let's take a look at the data.",
          "Let's take a look at the data.",
          "now, let's get an overall sense of the data we're working with.",
          "let's explore data provided.",
          "Let's have a look at our data.",
          "Let's examine the data further.",
          "Let's take a brief look at the some sample data.",
          "Let's take a closer look at the data provided.",
          " Let's preview the data to understand what we have.",
          "Let's peek into the data to understand what we are working with.",
          "Let's have a look at the data.",
          "Let's take a look at the data.",
          " Let's take a look at the data.",
          "Let's take a look at some of the data.",
          "Let's take a look at what we're dealing with in each case",
          "Let's take a look at the available data.",
          "Now let's have a quick look at our data.",
          "Let's take a look at the data.",
          "Let's take a look at the data.",
          "Let's take a look at the data.",
          "We'll perform a quick check on the data.",
          "Let's explore the data we have.",
          "Let's get a glimpse of the data we have imported."
         ],
         "marker": {
          "opacity": 0.5,
          "size": 5
         },
         "mode": "markers+text",
         "name": "53_Let's take a closer look at the data we have",
         "text": [
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          ""
         ],
         "textfont": {
          "size": 12
         },
         "type": "scattergl",
         "x": [
          18.507755279541016,
          19.208471298217773,
          19.178699493408203,
          18.15928077697754,
          18.579540252685547,
          18.69768524169922,
          18.857397079467773,
          18.762353897094727,
          18.237794876098633,
          18.2632999420166,
          18.583877563476562,
          18.748428344726562,
          19.23695182800293,
          18.66236686706543,
          18.964752197265625,
          18.14246940612793,
          17.952129364013672,
          18.906328201293945,
          18.781980514526367,
          18.81633186340332,
          19.3489990234375,
          19.202411651611328,
          18.483182907104492,
          18.239389419555664,
          18.5670166015625,
          18.741334915161133,
          19.695383071899414,
          19.22199821472168,
          17.871625900268555,
          18.35550308227539,
          19.027376174926758,
          19.124353408813477,
          19.330810546875,
          19.2017765045166,
          18.283180236816406,
          19.03445816040039,
          18.54837417602539,
          19.312997817993164,
          19.24614143371582,
          19.29393196105957,
          17.928482055664062,
          18.324792861938477,
          18.553651809692383
         ],
         "y": [
          -0.41810306906700134,
          -0.9228184819221497,
          -0.7236592173576355,
          -1.4490290880203247,
          -0.3512154221534729,
          -0.7933068871498108,
          -0.28411707282066345,
          -0.54761803150177,
          -0.5371307134628296,
          -0.30810800194740295,
          -1.410544514656067,
          -1.3151921033859253,
          -0.4598301649093628,
          -1.1953389644622803,
          -1.0206912755966187,
          -0.30515724420547485,
          -0.4374193251132965,
          -0.25570443272590637,
          -0.4644215404987335,
          -0.37352725863456726,
          -0.7897578477859497,
          -0.6820533275604248,
          -0.5113072991371155,
          -0.3743768334388733,
          -0.6964592337608337,
          -0.04570608586072922,
          -0.5327322483062744,
          -0.6210864186286926,
          -0.36592912673950195,
          -0.372993141412735,
          -0.5191879868507385,
          -0.6666067838668823,
          -0.634140133857727,
          -0.7248015403747559,
          -0.006446369457989931,
          -0.8426835536956787,
          -0.9052994251251221,
          -0.5369043350219727,
          -0.824737012386322,
          -0.747484564781189,
          -0.5225858688354492,
          -0.3472018837928772,
          -0.7339603900909424
         ]
        },
        {
         "hoverinfo": "text",
         "hovertext": [
          "Ensure all data was loaded successfully\nprint('Characters:', df_characters.shape)\nprint('Locations:', df_locations.shape)\nprint('Script:', df_script.shape)\nprint('Episodes:', df_episodes.shape)",
          " Display the dataframe shapes\nprint(\"Characters:\", df_characters.shape)\nprint(\"Locations:\", df_locations.shape)\nprint(\"Script:\", df_script.shape)\nprint(\"Episodes:\", df_episodes.shape)",
          "print('Characters shape:', df_characters.shape)\nprint('Locations shape:', df_locations.shape)\nprint('Script shape:', df_script.shape)\nprint('Episodes shape:', df_episodes.shape)",
          "Kernel -> Restart & Run All to refresh DataFrame shapes\n# New episode shapes\nprint(f\"df_episodes shape: {df_episodes.shape}\")\n\n# New script shapes\nprint(f\"df_script shape: {df_script.shape}\")",
          "Display shapes\nprint(df_characters.shape)\nprint(df_locations.shape)\nprint(df_script.shape)\nprint(df_episodes.shape)",
          "print('df_characters shape: {}'.format(df_characters.shape))\nprint('df_locations shape: {}'.format(df_locations.shape))\nprint('df_script shape: {}'.format(df_script.shape))\nprint('df_episodes shape: {}'.format(df_episodes.shape))",
          "Inspect loaded data\nprint('characters:', df_characters.shape)\nprint('locations:', df_locations.shape)\nprint('script_lines:', df_script.shape)\nprint('episodes:', df_episodes.shape)",
          "Visualização do tamanho dos dataframes\nprint(\"df_characters.shape\", df_characters.shape)\nprint(\"df_locations.shape\", df_locations.shape)\nprint(\"df_script.shape\", df_script.shape)\nprint(\"df_episodes.shape\", df_episodes.shape)",
          "Explore the data structure\nprint(\"Characters:   \", df_characters.shape)\nprint(\"Locations:    \", df_locations.shape)\nprint(\"Script:       \", df_script.shape)\nprint(\"Episodes:     \", df_episodes.shape)",
          "Print data shapes\nprint('Characters:', df_characters.shape)\nprint('Locations:', df_locations.shape)\nprint('Script:', df_script.shape)\nprint('Episodes:', df_episodes.shape)",
          "Print shape of each dataframe\nprint(\"Characters:\", df_characters.shape)\nprint(\"Locations:\", df_locations.shape)\nprint(\"Script:\", df_script.shape)\nprint(\"Episodes:\", df_episodes.shape)",
          "Print file shapes\nprint('Characters:', df_characters.shape)\nprint('Locations:', df_characters.shape)\nprint('Script:', df_characters.shape)\nprint('Episodes:', df_characters.shape)",
          "print shape of each dataframe\nprint(\"Characters DataFrame Shape: \", df_characters.shape)\nprint(\"Locations DataFrame Shape: \", df_locations.shape)\nprint(\"Script DataFrame Shape: \", df_script.shape)\nprint(\"Episodes DataFrame Shape: \", df_episodes.shape)",
          "# Print shapes of the DataFrames\nprint(df_characters.shape)\nprint(df_locations.shape)\nprint(df_script.shape)\nprint(df_episodes.shape)",
          "print('Characters:', df_characters.shape)\nprint('Locations:', df_locations.shape)\nprint('Script:', df_script.shape)\nprint('Episodes:', df_episodes.shape)",
          "Display some simple informatoin basic infomraiton about the DataFrames\nprint(f'Characters dataframe shape: {df_characters.shape}')\nprint(f'Locations dataframe shape:  {df_locations.shape}')\nprint(f'Script dataframe shape:      {df_script.shape}')\nprint(f'Episodes dataframe shape:    {df_episodes.shape}')",
          "View some basic info\nprint('Script lines:', df_script.shape)\nprint('Episodes:', df_episodes.shape)\nprint('Characters:', df_characters.shape)\nprint('Locations:', df_locations.shape)",
          " Display the dataframes' shapes\nprint(df_characters.shape, df_locations.shape, df_script.shape, df_episodes.shape)",
          "Print shapes of dataframes\nprint(df_characters.shape)\nprint(df_locations.shape)\nprint(df_script.shape)\nprint(df_episodes.shape)",
          "View data shapes\nprint('Characters shape:', df_characters.shape)\nprint('Locations shape:', df_locations.shape)\nprint('Script shape:', df_script.shape)\nprint('Episodes shape:', df_episodes.shape)",
          "print('Script:', df_script.shape)\nprint('Locations:', df_locations.shape)\nprint('Characters:', df_characters.shape)\nprint('Episodes:', df_episodes.shape)",
          "Most of the data:\nprint('Characters:', df_characters.shape)\nprint('Locations:', df_locations.shape)\nprint('Script:', df_script.shape)\nprint('Episodes:', df_episodes.shape)",
          "\u000f# 1.2 Load all data into a pandas dataframes\n# Show the dataframes structure\nprint(f'df_characters.shape:   {df_characters.shape}')\nprint(f'df_locations.shape:    {df_locations.shape}')\nprint(f'df_script.shape:       {df_script.shape}')\nprint(f'df_episodes.shape:     {df_episodes.shape}')",
          " Print the shapes of our dataset\nprint(\"Characters shape:\", df_characters.shape)\nprint(\"Locations shape:\", df_locations.shape)\nprint(\"Script shape:\", df_script.shape)\nprint(\"Episodes shape:\", df_episodes.shape)",
          "# Print DataFrame characteristics\nprint_characters(df_characters)\nprint_locations(df_locations)\nprint_script(df_script)\nprint_episodes(df_episodes)",
          "Quick overview of the dataset\nprint('Characters:', df_characters.shape)\nprint('Locations:', df_locations.shape)\nprint('Script:', df_script.shape)\nprint('Episodes:', df_episodes.shape)",
          "Check the files\nprint('Characters: ', df_characters.shape)\nprint('Locations: ', df_locations.shape)\nprint('Script: ', df_script.shape)\nprint('Episodes: ', df_episodes.shape)",
          " Print the shape of the DataFrames\nprint(\"Characters df shape :\", df_characters.shape)\nprint(\"Locations df shape :\", df_locations.shape)\nprint(\"Script df shape :\", df_script.shape)\nprint(\"Episodes df shape :\", df_episodes.shape)",
          "Display some basic information about the datasets\nprint('Characters:', df_characters.shape)\nprint('Locations:', df_locations.shape)\nprint('Script lines:', df_script.shape)\nprint('Episodes:', df_episodes.shape)",
          "\n# Initially show the first 5 rows of the dataframes to get an understanding of the data\nprint('Character df shape:', df_characters.shape)\nprint('Location df shape:', df_locations.shape)\nprint('Script df shape:', df_script.shape)\nprint('Episode df shape:', df_episodes.shape)",
          "Display shape and info\nprint('Characters shape:', df_characters.shape)\nprint('Locations shape:', df_locations.shape)\nprint('Script shape:', df_script.shape)\nprint('Episodes shape:', df_episodes.shape)",
          "print('Script shape:', df_script.shape)\nprint('Character shape:', df_characters.shape)\nprint('Location shape:', df_locations.shape)\nprint('Episodes shape:', df_episodes.shape)",
          "Print the dataframes shapes\nprint('Characters df shape: ', df_characters.shape)\nprint('Locations df shape: ', df_locations.shape)\nprint('Script df shape: ', df_script.shape)\nprint('Episodes df shape: ', df_episodes.shape)",
          "Check the shape and headers\nprint('Shape of characters:', df_characters.shape)\nprint('Shape of locations:', df_locations.shape)\nprint('Shape of script lines:', df_script.shape)\nprint('Shape of episodes:', df_episodes.shape)\n\ndf_characters.head()",
          "summary of data\nprint(\"characters:\", df_characters.shape)\nprint(df_characters.head())\nprint(\"locations:\", df_locations.shape)\nprint(df_locations.head())\nprint(\"script:\", df_script.shape)\nprint(df_script.head())\nprint(\"episodes:\", df_episodes.shape)\nprint(df_episodes.head())",
          "Inspect DataFrame shapes\nprint(\"Characters:\", df_characters.shape)\nprint(\"Locations:\", df_locations.shape)\nprint(\"Script lines:\", df_script.shape)\nprint(\"Episodes:\", df_episodes.shape)",
          " Print the shape of each DataFrame\nprint(f'Shapes: Characters={df_characters.shape}, Locations={df_locations.shape}, Script={df_script.shape}, Episodes={df_episodes.shape}')",
          " Check loaded data\nprint('Characters: {}'.format(df_characters.shape))\nprint('Locations: {}'.format(df_locations.shape))\nprint('Script: {}'.format(df_script.shape))\nprint('Episodes: {}'.format(df_episodes.shape))",
          "Show the dataframes shape\nprint('Characters:', df_characters.shape)\nprint('Locations:', df_locations.shape)\nprint('Script:', df_script.shape)\nprint('Episodes:', df_episodes.shape)",
          "Print dataframe shapes\nprint(df_characters.shape)\nprint(df_locations.shape)\nprint(df_script.shape)\nprint(df_episodes.shape)",
          "Dataset content\nprint(\"characters shape:\", df_characters.shape)\nprint(\"locations shape:\", df_locations.shape)\nprint(\"script shape:\", df_script.shape)\nprint(\"episodes shape:\", df_episodes.shape)",
          " Explore data\nprint('Characters:', df_characters.shape)\nprint('Locations:', df_locations.shape)\nprint('Script:', df_script.shape)\nprint('Episodes:', df_episodes.shape)",
          "Quick overview of the datasets\nprint('Characters: {}'.format(df_characters.shape))\nprint('Locations: {}'.format(df_locations.shape))\nprint('Script: {}'.format(df_script.shape))\nprint('Episodes: {}'.format(df_episodes.shape))"
         ],
         "marker": {
          "opacity": 0.5,
          "size": 5
         },
         "mode": "markers+text",
         "name": "54_Printing DataFrame Shapes",
         "text": [
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          ""
         ],
         "textfont": {
          "size": 12
         },
         "type": "scattergl",
         "x": [
          -1.3384901285171509,
          -1.8642338514328003,
          -1.7905329465866089,
          -1.9408704042434692,
          -1.4230575561523438,
          -1.4187672138214111,
          -0.877078115940094,
          -1.3351496458053589,
          -1.0027775764465332,
          -1.1550627946853638,
          -1.555907964706421,
          -1.289237380027771,
          -1.5558726787567139,
          -1.3874056339263916,
          -1.363589882850647,
          -1.204456090927124,
          -1.1998575925827026,
          -1.677988886833191,
          -1.598214030265808,
          -1.3366223573684692,
          -1.5684175491333008,
          -1.1145777702331543,
          -1.1789331436157227,
          -0.6434641480445862,
          -1.3473104238510132,
          -0.5687178373336792,
          -0.9857050776481628,
          -1.1463266611099243,
          -0.647533118724823,
          -1.0200432538986206,
          -1.6065362691879272,
          -1.5555553436279297,
          -1.5179274082183838,
          -1.2520837783813477,
          -1.0581557750701904,
          -1.2769629955291748,
          -0.8837157487869263,
          -0.9913210868835449,
          -1.6131078004837036,
          -1.4928879737854004,
          -0.7778050303459167,
          -1.0978498458862305,
          -0.7773997783660889
         ],
         "y": [
          -1.0911865234375,
          -1.3799220323562622,
          -0.751899778842926,
          -1.3322538137435913,
          -1.4321845769882202,
          -1.4482169151306152,
          -0.6113200187683105,
          -1.04938805103302,
          -0.06480300426483154,
          -0.6084800958633423,
          -1.850102186203003,
          -0.874298632144928,
          -2.021571159362793,
          -1.7389428615570068,
          -0.29454588890075684,
          -1.6356325149536133,
          -0.8677178621292114,
          -1.0756150484085083,
          -1.6457598209381104,
          -1.0036128759384155,
          -0.7228574752807617,
          -0.5020142197608948,
          -1.8921602964401245,
          -1.049856424331665,
          -0.862068772315979,
          -0.6290793418884277,
          -0.6590784788131714,
          -1.7281959056854248,
          -0.2205725610256195,
          -1.253849983215332,
          -1.138428807258606,
          -0.89876788854599,
          -1.7036947011947632,
          -0.5844822525978088,
          0.6365618705749512,
          -1.2047953605651855,
          -2.10469126701355,
          -1.5326449871063232,
          -1.1776553392410278,
          -1.877638578414917,
          -0.7808217406272888,
          -0.6062220931053162,
          -1.3168327808380127
         ]
        },
        {
         "hoverinfo": "text",
         "hovertext": [
          "Define helper function to join script snippets",
          "Define some cosmetic global parameters.",
          " Setting up constants",
          " Extract Environment Variables",
          "Check internal constants",
          "Simple example functions to test the interaction of the extension with the specific environment.",
          "Setting up variables needed for pre-processing",
          "Integration of my methods",
          "Declare variable with all seasons",
          "Setting important variables",
          "Define constants",
          "Stat helper functions",
          "Define custom functions and classes",
          "Helper functions to display data in a nice format.",
          "Auxiliary functions to simplify and clean the code below.",
          "Declare globally-used variables",
          " Define Project Constants",
          "Create some global variables",
          "Load the saved variables",
          "Defining some functions",
          "Helper functions",
          " Helper functions and constants",
          "# Helper function to display information in percentage\ndef percent(x, pos=0):\n    \"\"\"The two args are the value and tick position.\n    Label ticks with the percentage of the total\"\"\"\n    return '%1.1f%%' % (x * 100)",
          "Definitions (for brevity)",
          "Declare input parameters",
          "Functions",
          " define a fixed value variable.",
          "Declare variable for working with the lemma of the words",
          "Setup constants",
          " Helper functions",
          " Setuptools' entry point\ndef main():\n    \"\"\"\n    Main function\n    \"\"\"",
          "Declare global variables",
          "Define constant strings for specific data fields.",
          "a single collaborator is going to be used in this example\nCOLLABORATOR_NAME = 'Colab1'",
          "Utility functions",
          "Check whether the Helper label shows up for APIWidget.",
          "Setting up variables",
          "define some helpful functions",
          "Functions for feature engineering",
          "Declare the global variables",
          "Helper functions and variables",
          "Auxiliary functions"
         ],
         "marker": {
          "opacity": 0.5,
          "size": 5
         },
         "mode": "markers+text",
         "name": "55_Helper functions, variables, and constants",
         "text": [
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          ""
         ],
         "textfont": {
          "size": 12
         },
         "type": "scattergl",
         "x": [
          10.831618309020996,
          14.304080963134766,
          13.5072021484375,
          14.525836944580078,
          13.807417869567871,
          13.813972473144531,
          13.621495246887207,
          12.514986991882324,
          11.656179428100586,
          13.863367080688477,
          13.121967315673828,
          13.329377174377441,
          13.800936698913574,
          13.749302864074707,
          12.269728660583496,
          13.944009780883789,
          13.601840019226074,
          14.306517601013184,
          14.599377632141113,
          13.597132682800293,
          13.456927299499512,
          13.46052074432373,
          13.644978523254395,
          13.544119834899902,
          13.501206398010254,
          13.339253425598145,
          13.636545181274414,
          13.157533645629883,
          13.433184623718262,
          13.74355411529541,
          14.163683891296387,
          13.942195892333984,
          12.532325744628906,
          13.615456581115723,
          13.481396675109863,
          14.264647483825684,
          14.143479347229004,
          13.62470817565918,
          14.080757141113281,
          13.663554191589355,
          13.429252624511719,
          13.195831298828125
         ],
         "y": [
          3.981930732727051,
          2.554899215698242,
          1.4934439659118652,
          3.5193655490875244,
          1.465889811515808,
          2.4639222621917725,
          2.691638708114624,
          1.8489937782287598,
          2.830963134765625,
          2.3601291179656982,
          1.7832961082458496,
          2.7939343452453613,
          3.0020318031311035,
          2.461987257003784,
          2.948946714401245,
          2.876476287841797,
          1.7004578113555908,
          2.843998908996582,
          2.179253101348877,
          2.575000047683716,
          2.6783370971679688,
          2.15691876411438,
          3.6933248043060303,
          2.4336748123168945,
          2.7109766006469727,
          2.372795820236206,
          2.088233232498169,
          3.162386417388916,
          1.9477940797805786,
          2.7047762870788574,
          3.634364366531372,
          2.9554264545440674,
          1.3686871528625488,
          4.519054412841797,
          2.91951847076416,
          3.310558319091797,
          2.3776094913482666,
          2.504566192626953,
          1.7935855388641357,
          2.942173719406128,
          2.5414977073669434,
          2.7433886528015137
         ]
        },
        {
         "hoverinfo": "text",
         "hovertext": [
          "Multiline mode DataFrame print\nfrom IPython.display import display",
          "# Ensure matplotlib works correctly with Jupyter\n%matplotlib inline",
          " The first cell of the Jupyter notebook, imports libraries and custom packages, loads the necessary data files using pandas, and sets up matplotlib for visualization.",
          "Display plots inline in Jupyter notebook",
          "Visualisation for the jupyter notebook",
          "Display multiples output at once.\nfrom IPython.core.interactiveshell import InteractiveShell\nInteractiveShell.ast_node_interactivity = \"all\"",
          "# Display markdown\nfrom IPython.display import display, Markdown",
          " Custom header\nfrom jupyterthemes import jtplot\njtplot.style(theme='chesterish', context='notebook', ticks=True, grid=False)",
          "# Make autocompletion work\n# Note: This is a temporary solution, the correct way to do it is by installing the plotnine package\nfrom plotnine import *",
          "Since we are using Jupyter notebooks, we add the magic command %matplotlib inline to ensure that matplotlib works correctly with Jupyter.",
          "Show version information for reproducibility\nprint(\"Pandas version: \", pd.__version__)\nprint(\"Matplotlib version: \", matplotlib.__version__)\nprint(\"Numpy version: \", np.__version__)",
          "*Note: If you're using a Jupyter notebook, make sure to run the `%matplotlib inline` command to display the visualization within the notebook.*",
          "Set configuration options for pandas and matplotlib",
          "# Ensure correct versions\nprint(f\"spacy=={spacy.__version__}\")\nprint(f\"pandas=={pd.__version__}\")\nprint(f\"numpy=={np.__version__}\")\nprint(f\"matplotlib=={matplotlib.__version__}\")",
          " To integrate plotly with matplotlib, we need to install another library.",
          "to make this last import work without error\nmatplotlib use the tkinter Agg backend\nmatplotlib.use('Agg')",
          "Jupyter notebook needs some modifications in the matplotlib settings to properly show the visualizations.",
          "Set custom matplotlib configurations",
          "Setting plot space to be for Jupyter notebook specifically",
          " Enable jupyter_contrib_nbextensions for easier notebook use\n!jupyter contrib nbextension install",
          "ensure matplotlib works correctly with Jupyter\n%matplotlib inline",
          "get_ipython().run_line_magic('matplotlib', 'inline')",
          "Specify how the plots should be displayed in jupyter notebook",
          "#enable interactive plotting in Jupyter notebook\nmatplotlib.use('nbagg')",
          " Jupyter-notebook-like help to visualize DataFrames easily\nfrom IPython.display import display",
          "skipping the possible \"locale is not supported\" warning\n# No longer needed in pandas 1.1.0\npd.plotting.register_matplotlib_converters()",
          "Display rich content\nfrom IPython.display import display",
          "Set environment variable for matplotlib\nos.environ['MPLCONFIGDIR'] = os.getcwd()",
          "# These imports will be useful in this notebook\nfrom pandas.plotting import register_matplotlib_converters\nregister_matplotlib_converters()",
          "Displays the output from the function instead of just showing the last plot\nmatplotlib.use('module://ipykernel.pylab.backend_inline')",
          " To avoid compatibility issues with matplotlib, you should specify the type of backend you want to use. For example:",
          "interactively display plots\n%matplotlib notebook",
          "jupyter nbconvert --to html notebook.ipynb",
          "Uncomment following line in case you are unable to see the plots\n# %matplotlib inline",
          "Setting the backend of matplotlib to a specific value to avoid any issues",
          "Ensuring the PI works well in Jupyter for Matplotlib rebinding the\n# show() function to bypass the one provided by Jupyter\ndef show():\n   plt.show()",
          "jupyter notebook compatible code\nfrom IPython.core.interactiveshell import InteractiveShell\nInteractiveShell.ast_node_interactivity = \"all\"",
          " Add the following line in order to keep the matplotlib plots in the notebook for \n# evaluation. Note that in regular Python we could use plt.show() which is not\n# needed in jupyter notebooks.\n%matplotlib inline",
          "Set IPython indentation mode to always indent after line breaks\nfrom IPython.core.interactiveshell import InteractiveShell\nInteractiveShell.ast_node_interactivity = 'all'",
          " All print() output will be written directly to the Jupyter notebook\nfrom IPython.core.interactiveshell import InteractiveShell\nInteractiveShell.ast_node_interactivity = \"all\"",
          "Set notebook-related options for pandas and matplotlib"
         ],
         "marker": {
          "opacity": 0.5,
          "size": 5
         },
         "mode": "markers+text",
         "name": "56_Using matplotlib inline in Jupyter notebooks",
         "text": [
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          ""
         ],
         "textfont": {
          "size": 12
         },
         "type": "scattergl",
         "x": [
          18.792829513549805,
          19.19129753112793,
          18.669837951660156,
          18.981332778930664,
          18.5098934173584,
          18.4696044921875,
          18.992694854736328,
          18.95737648010254,
          18.6528263092041,
          19.015390396118164,
          19.773096084594727,
          19.224245071411133,
          19.84844207763672,
          19.132434844970703,
          19.29238510131836,
          19.60658073425293,
          19.023563385009766,
          19.739919662475586,
          18.85093879699707,
          17.939491271972656,
          19.508407592773438,
          19.485382080078125,
          18.819978713989258,
          19.287857055664062,
          18.912059783935547,
          19.21149253845215,
          18.89687728881836,
          18.976749420166016,
          19.379138946533203,
          19.523937225341797,
          19.43851661682129,
          18.99565315246582,
          18.5031795501709,
          19.56513023376465,
          19.634544372558594,
          19.061418533325195,
          18.524394989013672,
          19.433490753173828,
          18.486257553100586,
          18.28207015991211,
          19.29773712158203
         ],
         "y": [
          2.326948404312134,
          4.23469877243042,
          3.0822770595550537,
          3.296292304992676,
          2.9326417446136475,
          2.6741082668304443,
          2.326882839202881,
          3.0750181674957275,
          3.4012041091918945,
          3.8655717372894287,
          3.2981340885162354,
          3.855947256088257,
          3.407790422439575,
          3.9756581783294678,
          3.750232458114624,
          3.886345624923706,
          3.273632049560547,
          4.238548278808594,
          3.6897900104522705,
          2.7169859409332275,
          4.0438032150268555,
          4.029007911682129,
          3.2802340984344482,
          3.5645573139190674,
          2.4227688312530518,
          4.043517112731934,
          2.2585015296936035,
          4.515571594238281,
          3.610352039337158,
          3.557884693145752,
          4.150632858276367,
          3.25358247756958,
          2.3672449588775635,
          3.990543842315674,
          4.648711204528809,
          3.870680093765259,
          2.658067226409912,
          3.604654550552368,
          2.3115785121917725,
          2.337576389312744,
          3.0087292194366455
         ]
        },
        {
         "hoverinfo": "text",
         "hovertext": [
          "Let's take a quick look at what our datasets contain.",
          "Data\n# Let's have a first look at the datasets.",
          "Let's see some basic information from each dataset.",
          "Let's take a first look at each of these datasets.",
          "Let us examine our datasets to see what's inside and what can be interesting",
          "let's have a brief look at the data sets",
          " Let's quickly look at what is contained in the datasets.",
          "Let's take the first look at the loaded datasets.",
          "Let's have a quick overview of each dataset.",
          " Let's get an overview of these datasets.",
          "Let's see how the datasets look.",
          " Let's apply some basic data explorations to see what is inside these datasets.",
          "Let's explore the content of these datasets.",
          "Let's explore the data to have an idea what is in the dataset.",
          "Let's first look at the structure of the datasets.",
          "Let's first get a feel for our datasets by taking a look at the first few lines.",
          "Let's first explore what each dataset looks like.",
          " Let's preview the datasets.",
          " Let's take a quick look at each of the datasets.",
          "Let's take a quick look at the various datasets.",
          "Let's take a quick look at our datasets.",
          "Let's take a quick look at the datasets we have.",
          "Let's have a look at the content of each of these datasets.",
          " Let's see what's in these datasets",
          "We will display our dataset here",
          "Let's explore the dataset one by one.",
          "Let's take a quick look at what these datasets contain.",
          "Let's have an overview of our datasets",
          "Let's take a look at these datasets.",
          "Let's see what these datasets actually contain.",
          "Let's get an overview of these datasets.",
          "Let's see an overview of these datasets.",
          "Let's first take a look at the schema of each dataset.",
          "Let's take a look at our datasets",
          " Let's take a look at these datasets.",
          "Let's see what our datasets look like.",
          "Let's see what's inside these datasets:",
          " Let's first take a look at the structure and content of each of these datasets.",
          "Let's take a glimpse at these datasets.",
          "Let's inspect our datasets"
         ],
         "marker": {
          "opacity": 0.5,
          "size": 5
         },
         "mode": "markers+text",
         "name": "57_exploring dataset content",
         "text": [
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          ""
         ],
         "textfont": {
          "size": 12
         },
         "type": "scattergl",
         "x": [
          16.35257911682129,
          16.346420288085938,
          16.4438533782959,
          16.80257797241211,
          16.619272232055664,
          16.58845329284668,
          15.79798412322998,
          15.650662422180176,
          16.948240280151367,
          16.980289459228516,
          16.1726131439209,
          15.90676212310791,
          16.591344833374023,
          15.921056747436523,
          15.80123233795166,
          16.11728858947754,
          16.216049194335938,
          16.58159065246582,
          16.527698516845703,
          16.886951446533203,
          16.647775650024414,
          16.9967041015625,
          16.949508666992188,
          16.410675048828125,
          16.196670532226562,
          16.516033172607422,
          16.668344497680664,
          16.87478256225586,
          17.101598739624023,
          16.467546463012695,
          16.74091911315918,
          17.220129013061523,
          15.886598587036133,
          16.609325408935547,
          17.05222511291504,
          16.506193161010742,
          16.085161209106445,
          16.32628059387207,
          16.73345947265625,
          16.156963348388672
         ],
         "y": [
          -3.116450548171997,
          -3.357179641723633,
          -3.037879705429077,
          -3.1712417602539062,
          -2.952908754348755,
          -3.7650790214538574,
          -3.3348121643066406,
          -2.527376651763916,
          -2.969689130783081,
          -3.0459389686584473,
          -2.967521905899048,
          -2.8442916870117188,
          -3.3893003463745117,
          -2.6904945373535156,
          -3.7609810829162598,
          -3.2712550163269043,
          -2.7110791206359863,
          -2.57605242729187,
          -3.4094979763031006,
          -3.2559092044830322,
          -3.373919725418091,
          -3.355903387069702,
          -3.2471375465393066,
          -3.602288246154785,
          -3.4413001537323,
          -3.3000731468200684,
          -3.6301727294921875,
          -3.541370153427124,
          -3.732182264328003,
          -3.4936444759368896,
          -3.0850775241851807,
          -3.4847724437713623,
          -3.2623894214630127,
          -3.20037841796875,
          -3.6619296073913574,
          -3.283799171447754,
          -3.584413528442383,
          -3.29632306098938,
          -3.324594736099243,
          -2.8251209259033203
         ]
        },
        {
         "hoverinfo": "text",
         "hovertext": [
          " Replace NaN values with empty strings\ndf_script = df_script.fillna('')",
          "Replace NaN with an empty string\ndf_script = df_script.replace(np.nan, '', regex=True)",
          "Replace NaN values with empty strings\ndf_script = df_script.fillna('')",
          "replace NaN values with empty strings\ndf_script.fillna('', inplace=True)",
          "Replace NaN values\ndf_characters.replace({np.nan: None}, inplace=True)\ndf_locations.replace({np.nan: None}, inplace=True)\ndf_script.replace({np.nan: None}, inplace=True)\ndf_episodes.replace({np.nan: None}, inplace=True)",
          "Ensure all NaN values are replaced with an empty string\ndf_script = df_script.fillna('')",
          "Clean the texts of NaN values\ndf_script.cleaned_text = df_script.cleaned_text.fillna('')",
          "Clean gender information\n# Convert empty strings in gender column to NaN\ndf_characters['gender'] = df_characters['gender'].apply(lambda x: np.NaN if x == '' else x)\n\n# Replace unknown genders with NaN\ndf_characters['gender'] = df_characters['gender'].replace('?', np.NaN)",
          "Replace NaN values in episode_id with -1\ndf_script['episode_id'].fillna(-1, inplace=True)",
          " Set `np.NaN` untuk string kosong\ndf_script.replace('', np.NaN, inplace=True)",
          "Replace NaN values\ndf_characters['normalized_name'] = df_characters['normalized_name'].fillna('')",
          "Add missing value to data\ndf_script.fillna('')",
          "Replace missing gender\ndf_characters.gender.replace({'non-specific': np.nan}, inplace=True)",
          "clean empty string rows\ndf_script.replace('', np.nan, inplace=True)\ndf_script.dropna(inplace=True)",
          "Replace NaN values with empty strings\ndf_script = df_script.fillna('')",
          "We should change NaNs for empty strings\ndf_script = df_script.fillna('')",
          "Replace NaN with empty string\ndf_script = df_script.replace(np.nan, '', regex=True)",
          "Label 'other' as gender for np.nan values in the gender column\ndf_characters['gender'] = df_characters['gender'].replace({np.nan: 'other'})",
          "Fill in the NaN values in the raw script data with empty strings to avoid issues with the text processing later on\ndf_script = df_script.fillna('')",
          "Clean dataframe \"df_script\" from NaN and duplicated data",
          "Replace NaN values with empty strings\ndf_script = df_script.fillna('')",
          " Set NaN strings to NaN values",
          "Replace NaN values with an empty string\ndf_script = df_script.fillna('')",
          " Replacing NaN with empty string\ndf_script.fillna(\"\", inplace=True)",
          "Replace NaN values with empty strings\ndf_script = df_script.fillna('')",
          " Preprocessing\n# Replacing NaN with np.nan\ndf_script = df_script.replace({pd.np.nan: None})",
          "We need to also force the conversion of str-``NaN`` to ``np.nan`` again as done during Data Cleaning.",
          " Replace NaN with empty string\ndf_script = df_script.fillna('')",
          "Fill \\'NA\\' values with empty strings\ndf_script = df_script.fillna('')",
          "Setting 'UNKNOWN' for NaN values, to avoid surprises later\ndf_script['raw_character_text'] = df_script['raw_character_text'].fillna('UNKNOWN')\ndf_script['raw_location_text'] = df_script['raw_location_text'].fillna('UNKNOWN')",
          "Replace NaN with empty string\ndf_script = df_script.fillna('')",
          " Turn NaN values into empty strings\ndf_script = df_script.fillna('')",
          "# Fill NaN with empty strings\ndf_script = df_script.fillna('')",
          "Replace nans with empty strings\ndf_characters.fillna(value=\"\", inplace=True)\ndf_locations.fillna(value=\"\", inplace=True)\ndf_script.fillna(value=\"\", inplace=True)\ndf_episodes.fillna(value=\"\", inplace=True)",
          "Replace NaN with empty strings\ndf_script = df_script.fillna('')",
          " Replace original_na values with Python's NaN valuemarker\ndf_characters.replace([r'\\N'], np.nan, inplace=True)\ndf_locations.replace([r'\\N'], np.nan, inplace=True)\ndf_script.replace([r'\\N'], np.nan, inplace=True)\ndf_episodes.replace([r'\\N'], np.nan, inplace=True)",
          "replacing empty string with NaN\ndf_script.replace(\"\", np.nan, inplace=True)",
          "Replace nans with empty strings\ndf_script = df_script.fillna('')",
          "Replace all NaN values with an empty string\ndf_script.fillna('', inplace=True)"
         ],
         "marker": {
          "opacity": 0.5,
          "size": 5
         },
         "mode": "markers+text",
         "name": "58_Replace NaN values with empty strings",
         "text": [
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          ""
         ],
         "textfont": {
          "size": 12
         },
         "type": "scattergl",
         "x": [
          5.99805212020874,
          6.340763568878174,
          6.24641752243042,
          5.858875274658203,
          5.659393310546875,
          6.398327350616455,
          6.5074028968811035,
          6.497527122497559,
          5.546412944793701,
          6.23769998550415,
          6.258854389190674,
          5.869754791259766,
          6.207024574279785,
          6.047995567321777,
          5.90074348449707,
          6.684896469116211,
          6.3791375160217285,
          6.322559833526611,
          6.494514465332031,
          6.945486068725586,
          6.204604625701904,
          6.470622539520264,
          5.959224700927734,
          5.7828450202941895,
          6.011282444000244,
          6.106019496917725,
          6.736347675323486,
          5.876905918121338,
          6.085987567901611,
          6.1954803466796875,
          6.1551833152771,
          6.321874141693115,
          5.845190048217773,
          5.346573829650879,
          6.319087028503418,
          5.25302267074585,
          6.316530227661133,
          6.093020439147949,
          6.053258419036865
         ],
         "y": [
          2.6230556964874268,
          3.4002716541290283,
          2.6459829807281494,
          3.0979695320129395,
          3.669498920440674,
          2.580272912979126,
          3.302725076675415,
          5.067682266235352,
          3.9083175659179688,
          3.0058412551879883,
          3.871382474899292,
          2.2623231410980225,
          4.5704731941223145,
          3.831120252609253,
          2.78702974319458,
          2.639688491821289,
          3.294832944869995,
          5.662113189697266,
          3.1154706478118896,
          2.532536506652832,
          2.7103848457336426,
          2.4617104530334473,
          2.462733268737793,
          2.728320598602295,
          2.618795156478882,
          3.0706393718719482,
          2.659553289413452,
          3.0300636291503906,
          2.8756260871887207,
          3.1806395053863525,
          3.081923246383667,
          2.258838415145874,
          2.4397308826446533,
          3.478301525115967,
          2.979205846786499,
          3.987675666809082,
          2.920830011367798,
          3.0786447525024414,
          2.508655548095703
         ]
        },
        {
         "hoverinfo": "text",
         "hovertext": [
          "Set random seed for reproducibility\nnp.random.seed(0)",
          " Set random seed for reproducibility\nnp.random.seed(0)",
          " Set random seed for reproducibility\nnp.random.seed(0)",
          " Set random seed for reproducibility\nnp.random.seed(0)",
          "Set random seed for reproducibility\nnp.random.seed(0)",
          "Set random seed for reproducibility\nnp.random.seed(0)",
          "Set random seed for reproducibility\nnp.random.seed(0)",
          "Set random seed for reproducibility\nnp.random.seed(0)",
          "Set random seed for reproducibility\nnp.random.seed(0)",
          " Set random seed for reproducibility\nnp.random.seed(0)",
          "Set random seed for reproducibility\nnp.random.seed(0)",
          "Set random seed for reproducibility\nnp.random.seed(0)",
          "Setting random seed for reproducibility\nnp.random.seed(0)",
          "Set random seed for reproducibility\nnp.random.seed(0)",
          "Set random seed for reproducibility\nnp.random.seed(0)",
          "Set random seed for reproducibility\nnp.random.seed(0)",
          " Set random seed for reproducibility\nnp.random.seed(0)",
          " Set random seed for reproducibility\nnp.random.seed(0)",
          " Set random seed for reproducibility\nnp.random.seed(0)",
          "Set random seed for reproducibility\nnp.random.seed(0)",
          " Set random seed for reproducibility\nnp.random.seed(0)",
          " Set random seed for reproducibility\nnp.random.seed(0)",
          "Set random seed for reproducibility\nnp.random.seed(0)",
          "set random seed for reproducibility\nnp.random.seed(0)",
          " Set random seed for reproducibility\nnp.random.seed(0)",
          " Set random seed for reproducibility\nnp.random.seed(0)",
          "Set random seed for reproducibility\nnp.random.seed(0)",
          "Set random seed for reproducibility\nnp.random.seed(0)",
          "Set random seed for reproducibility\nnp.random.seed(0)",
          "Set random seed for reproducibility\nnp.random.seed(0)",
          " Set random seed for reproducibility\nnp.random.seed(0)",
          "Set random seed for reproducibility\nnp.random.seed(0)",
          "Set random seed for reproducibility\nnp.random.seed(0)",
          " Set random seed for reproducibility\nnp.random.seed(0)",
          " Set random seed for reproducibility\nnp.random.seed(0)",
          "Set random seed for reproducibility\nnp.random.seed(0)",
          " Set random seed for reproducibility\nnp.random.seed(0)",
          "Set random seed for reproducibility\nnp.random.seed(0)",
          " Set random seed for reproducibility\nnp.random.seed(0)"
         ],
         "marker": {
          "opacity": 0.5,
          "size": 5
         },
         "mode": "markers+text",
         "name": "59_Setting random seed for reproducibility",
         "text": [
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          ""
         ],
         "textfont": {
          "size": 12
         },
         "type": "scattergl",
         "x": [
          32.43060302734375,
          32.445377349853516,
          32.30109786987305,
          32.761165618896484,
          32.63078689575195,
          32.094547271728516,
          31.807403564453125,
          32.69490432739258,
          32.09781265258789,
          32.67265701293945,
          32.59006118774414,
          31.645692825317383,
          32.1412353515625,
          31.926652908325195,
          32.310115814208984,
          32.568294525146484,
          32.18379592895508,
          32.243003845214844,
          32.23027038574219,
          32.55449295043945,
          32.24699401855469,
          32.008602142333984,
          32.15522766113281,
          31.685543060302734,
          32.293479919433594,
          32.373046875,
          32.478878021240234,
          32.243736267089844,
          32.50189208984375,
          32.091312408447266,
          32.31181335449219,
          32.056270599365234,
          32.037166595458984,
          32.16328811645508,
          31.78811264038086,
          31.975299835205078,
          32.67593002319336,
          32.40864562988281,
          32.55464172363281
         ],
         "y": [
          14.226208686828613,
          14.232354164123535,
          14.146671295166016,
          14.633275032043457,
          14.243759155273438,
          14.628693580627441,
          14.776082992553711,
          14.075785636901855,
          14.566924095153809,
          14.68737506866455,
          14.558796882629395,
          14.71842098236084,
          13.788216590881348,
          14.67795467376709,
          14.747591972351074,
          14.525257110595703,
          14.323404312133789,
          14.765800476074219,
          14.214624404907227,
          14.760272979736328,
          14.771308898925781,
          14.627769470214844,
          14.792393684387207,
          14.278910636901855,
          14.697455406188965,
          14.276999473571777,
          14.813602447509766,
          14.776106834411621,
          14.431392669677734,
          14.508299827575684,
          14.592157363891602,
          14.284341812133789,
          14.258102416992188,
          14.344918251037598,
          14.080315589904785,
          14.394161224365234,
          14.561406135559082,
          14.408828735351562,
          14.294722557067871
         ]
        },
        {
         "hoverinfo": "text",
         "hovertext": [
          "# Ensure the data has been imported correctly\nprint(df_characters.head())\nprint(df_locations.head())\nprint(df_script.head())\nprint(df_episodes.head())",
          "Check the imported data\nprint(df_characters.head())\nprint(df_locations.head())\nprint(df_script.head())\nprint(df_episodes.head())",
          "Check the imported data\nprint(\"Characters data\")\nprint(df_characters.head())\nprint(\"Locations data\")\nprint(df_locations.head())\nprint(\"Script data\")\nprint(df_script.head())\nprint(\"Episodes data\")\nprint(df_episodes.head())",
          "Check the import content\nprint(\"Characters: \", df_characters.head())\nprint(\"Locations: \", df_locations.head())\nprint(\"Script: \", df_script.head())\nprint(\"Episodes: \", df_episodes.head())",
          "Check the data has been loaded correctly\nprint(df_characters.head())\nprint(df_locations.head())\nprint(df_script.head())\nprint(df_episodes.head())",
          " Some dataframes are too large, and loading them temporarily consume a lot of memory.\n# print(df_characters.head())\n# print(df_locations.head())\n# print(df_script.head())\n# print(df_episodes.head())",
          "Check the imported dataframes\nprint(df_characters.head(3))\nprint(df_locations.head(3))\nprint(df_script.head(3))\nprint(df_episodes.head(3))",
          "Check that the data has been properly loaded\nprint(df_characters.head())\nprint(df_locations.head())\nprint(df_script.head())\nprint(df_episodes.head())",
          "Check that everything is loaded correctly\nprint(df_characters.head(1))\nprint(df_locations.head(1))\nprint(df_script.head(1))\nprint(df_episodes.head(1))",
          " Ensure reading worked correctly\nprint(df_characters.head())\nprint(df_locations.head())\nprint(df_script.head())\nprint(df_episodes.head())",
          "Check the files we have\nprint(\"Simpsons characters\")\nprint(df_characters.head())\nprint(\"\")\nprint(\"Simpsons locations\")\nprint(df_locations.head())\nprint(\"\")\nprint(\"Simpsons script\")\nprint(df_script.head())\nprint(\"\")\nprint(\"Simpsons episodes\")\nprint(df_episodes.head())",
          "# Ensure the data has been loaded correctly\nprint(df_characters.head())\nprint(df_locations.head())\nprint(df_script.head())\nprint(df_episodes.head())",
          "Check to make sure everything was read in properly\nprint(df_characters.head())\nprint(df_locations.head())\nprint(df_script.head())\nprint(df_episodes.head())",
          "Check the import results\nprint(df_characters.head())\nprint(df_locations.head())\nprint(df_script.head())\nprint(df_episodes.head())",
          "Check that the data has been read in correctly\nfor df in [df_characters, df_locations, df_script, df_episodes]:\n    print(df.head(2))\n    print('-'*50)",
          "Check whether data has been split correctly\nprint(df_script.head())\nprint(df_characters.head())\nprint(df_locations.head())\nprint(df_episodes.head())",
          "Check if the data files have been read correctly\nprint(df_characters.head())\nprint(df_locations.head())\nprint(df_script.head())\nprint(df_episodes.head())",
          "check that data read correctly\nprint(df_characters.head())\nprint(df_locations.head())\nprint(df_script.head())\nprint(df_episodes.head())",
          "Encode the text data to UTF-8 to handle any special characters\ndf_characters = df_characters.apply(lambda x: x.astype(str).str.encode('utf-8', errors='ignore').str.decode('utf-8'))\ndf_locations = df_locations.apply(lambda x: x.astype(str).str.encode('utf-8', errors='ignore').str.decode('utf-8'))\ndf_script = df_script.apply(lambda x: x.astype(str).str.encode('utf-8', errors='ignore').str.decode('utf-8'))\ndf_episodes = df_episodes.apply(lambda x: x.astype(str).str.encode('utf-8', errors='ignore').str.decode('utf-8'))",
          "Check if the data loaded properly\nprint(df_characters.head())\nprint(df_locations.head())\nprint(df_script.head())\nprint(df_episodes.head())",
          "Check if the data loaded correctly\nprint(\"Characters\")\ndisplay(df_characters.head(2))\nprint(\"Locations\")\ndisplay(df_locations.head(2))\nprint(\"Script\")\ndisplay(df_script.head(2))\nprint(\"Episodes\")\ndisplay(df_episodes.head(2))",
          "Check the imported dataframes\nprint(\"Characters\")\nprint(df_characters.head())\nprint(\"Locations\")\nprint(df_locations.head())\nprint(\"Script\")\nprint(df_script.head())\nprint(\"Episodes\")\nprint(df_episodes.head())",
          "Check that the imports worked\nprint(df_characters.head())\nprint(df_locations.head())\nprint(df_script.head())\nprint(df_episodes.head())",
          "Check if the data loaded properly\nprint(df_characters.head())\nprint(df_locations.head())\nprint(df_script.head())",
          "Checking that the data was in fact loaded\nprint(df_characters.head())\nprint(df_locations.head())\nprint(df_script.head())\nprint(df_episodes.head())",
          "Check the dataframes to see that everything is as expected\nprint(df_characters.head(5))\nprint(df_locations.head(5))\nprint(df_script.head(5))\nprint(df_episodes.head(5))",
          "Check dataframes loaded correctly\nprint(df_characters.head())\nprint(df_locations.head())\nprint(df_episodes.head())\nprint(df_script.head())",
          "Check if the data has been loaded correctly\nprint(df_characters.head())\nprint(df_locations.head())\nprint(df_script.head())\nprint(df_episodes.head())",
          "Ensure that the paths to the data files are correct\nfor df in [df_characters, df_locations, df_script, df_episodes]:\n    print(os.path.exists(df))",
          "Check that everything was loaded correctly\nprint(df_characters.head())\nprint(df_locations.head())\nprint(df_script.head())\nprint(df_episodes.head())",
          "Checking whether the data was loaded correctly\nprint(df_characters.head())\nprint(df_locations.head())\nprint(df_script.head())\nprint(df_episodes.head())",
          "Check if loaded correctly\nprint(df_characters)\nprint(df_locations)\nprint(df_script)\nprint(df_episodes)",
          "Check that the data has been loaded correctly\nprint(df_characters.head())\nprint(df_locations.head())\nprint(df_script.head())\nprint(df_episodes.head())",
          "Prints to make sure everything is working properly.\nprint(df_characters.head())\nprint(df_locations.head())\nprint(df_script.head())\nprint(df_episodes.head())",
          "Check data read correctly\nprint(df_characters.head())\nprint(df_locations.head())\nprint(df_script.head())\nprint(df_episodes.head())",
          "Ensure you're using the correct data types\ndf_characters.info()\ndf_locations.info()\ndf_script.info()\ndf_episodes.info()",
          "Checking that the data has been loaded correctly\nprint('Characters')\ndisplay(df_characters)\nprint('Locations')\ndisplay(df_locations)\nprint('Script')\ndisplay(df_script)\nprint('Episodes')\ndisplay(df_episodes)",
          "Check that the data has been loaded correctly\nprint(df_characters.sample(5))\nprint(df_locations.sample(5))\nprint(df_script.sample(5))\nprint(df_episodes.sample(5))",
          "Check that data has been loaded correctly\nprint(df_characters.head())\nprint(df_locations.head())\nprint(df_script.head())\nprint(df_episodes.head())"
         ],
         "marker": {
          "opacity": 0.5,
          "size": 5
         },
         "mode": "markers+text",
         "name": "60_Checking Data Loading",
         "text": [
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          ""
         ],
         "textfont": {
          "size": 12
         },
         "type": "scattergl",
         "x": [
          -1.6791292428970337,
          -1.5662851333618164,
          -1.4549353122711182,
          -1.8099654912948608,
          -2.3125216960906982,
          -2.2316172122955322,
          -1.8574059009552002,
          -2.053659200668335,
          -1.9877680540084839,
          -1.9338918924331665,
          -1.5071169137954712,
          -1.9059228897094727,
          -2.1449766159057617,
          -1.906856894493103,
          -1.8564645051956177,
          -2.1024296283721924,
          -2.5426416397094727,
          -2.443521738052368,
          -1.6505353450775146,
          -2.0512218475341797,
          -2.1234965324401855,
          -1.650363564491272,
          -1.8180875778198242,
          -2.265249729156494,
          -2.194744825363159,
          -2.0476138591766357,
          -1.9996525049209595,
          -2.5093069076538086,
          -2.309457778930664,
          -1.9996204376220703,
          -2.613140821456909,
          -2.63783597946167,
          -2.062615156173706,
          -1.7575148344039917,
          -1.9529451131820679,
          -2.38981032371521,
          -2.3808481693267822,
          -2.484692096710205,
          -2.123088836669922
         ],
         "y": [
          0.776931643486023,
          0.5682710409164429,
          0.526119589805603,
          0.9991512894630432,
          0.7416665554046631,
          0.7626150846481323,
          0.6868782043457031,
          0.4517901539802551,
          0.39242666959762573,
          0.4290897846221924,
          1.2760668992996216,
          1.110924482345581,
          0.711745023727417,
          0.6819756627082825,
          0.4174489676952362,
          0.8408636450767517,
          0.16228140890598297,
          0.4536355435848236,
          0.8263655304908752,
          0.6491729021072388,
          1.3931578397750854,
          0.6808066964149475,
          0.1928485631942749,
          1.023606777191162,
          0.8604363799095154,
          0.9723626971244812,
          0.9622378945350647,
          0.5800372958183289,
          0.133716881275177,
          0.21568986773490906,
          1.087041974067688,
          0.7668299078941345,
          0.6569889783859253,
          0.5992869734764099,
          0.7847009897232056,
          0.4364683926105499,
          1.001210331916809,
          0.44822484254837036,
          0.6192994713783264
         ]
        },
        {
         "hoverinfo": "text",
         "hovertext": [
          "Create a new column 'raw_character_text' in df_script that contains the character's text as it is.",
          "Convert raw_text to string\ndf_script['raw_text'] = df_script['raw_text'].astype(str)",
          "Set locations to lowercase\ndf_script['raw_location'] = df_script['raw_location'].str.lower()",
          "Convert 'raw_text' column to string type to avoid merge incompatibility later on\ndf_script['raw_text'] = df_script['raw_text'].astype(str)",
          "Remove recurring spaces and drop duplicates\ndf_script['normalized_text'] = df_script.raw_text.str.lower().str.replace(r\"\\s+\", \" \").str.strip()\ndf_script = df_script.drop_duplicates('normalized_text')",
          "Strip leading/trailing whitespaces in text\n\ndf_script['raw_text'] = df_script['raw_text'].str.strip()",
          "Create lowercase 'raw_text' column in df_script\ndf_script['raw_text'] = df_script['raw_text'].apply(lambda x: x.lower())",
          "Extract the 'raw_text' from 'df_script' DataFrame and convert it to a list",
          "Converts raw text into dataframes.",
          "Ensure all scripts are in the same format (remove leading/trailing whitespace, convert to lowercase, remove brackets and their contents)\n\ndf_script['raw_text'] = df_script['raw_text'].str.strip()\ndf_script['raw_text'] = df_script['raw_text'].str.lower()\ndf_script['raw_text'] = df_script['raw_text'].str.replace(r\"\\(.*\\)\", \"\")",
          " Remove the newline and tab tokens from script\ndf_script['normalized_text'] = df_script['normalized_text'].str.replace('\\n', ' ')\ndf_script['normalized_text'] = df_script['normalized_text'].str.replace('  ', ' ')",
          "Starting with basic text preproceessing on 'raw_text' in 'df_script'.",
          "Generate new column that concatenates raw_text and normalized_text\ndf_script['raw_and_normalized_text'] = df_script['raw_text'] + ' ' + df_script['normalized_text']",
          " Remove special characters from raw lines in script\ndf_script['raw_character_text'] = df_script['raw_character_text'].str.replace(r'\\r+|\\n+|\\t+','', regex=True)",
          " Remove punctuation and lowercase all text\ndf_script['normalized_text'] = df_script['raw_text'].str.replace('[^\\w\\s]','').str.lower()",
          "Set scripts to lower case\ndf_script['raw_text_lc'] = df_script.raw_text.str.lower()",
          "# Fix errors and clean character names\ndf_characters['name'] = df_characters['name'].apply(lambda x: x.strip().replace('-', ' ').replace('_', ' '))\ndf_script['normalized_text'] = df_script['normalized_text'].apply(lambda x: x.strip().replace('-', ' ').replace('_', ' '))",
          "# Frequent regex replacements\ndf_script['raw_text'] = df_script['raw_text'].str.replace(r'-', ' ', regex=True)",
          "Create a column for the script\ndf_script['text'] = df_script['normalized_text'].str.lower()",
          "Replace all newline characters with <br> and cache the pre-processed script\ndf_script.raw_text = df_script.raw_text.str.replace('\\n', '<br>')",
          "']]['raw_text'] = df_script['raw_text'].str.replace('[^\\w\\s]','')",
          "Put all the text data into lowercase\ndf_script['normalized_text'] = df_script['raw_text'].apply(lambda x: x.lower())",
          "Create a text variable for the script\nscript = \" \".join(df_script.raw_text)",
          " Extracting the text for analysis\nscript = df_script['raw_text'].to_list()",
          "Remove leading/trailing whitespaces from scripts\ndf_script['raw_text'] = df_script['raw_text'].apply(lambda x: x.strip())",
          "Clean the text in the 'raw_text' column by removing extra spaces and converting to lowercase\ndf_script['clean_text'] = df_script['raw_text'].str.replace('\\'', ' ').str.lower().str.replace('[^a-z ]', '')\ndf_script['clean_text'] = df_script['clean_text'].str.replace(' +', ' ')",
          "Convert to lower case\ndf_script = df_script.apply(lambda x: x.astype(str).str.lower())",
          " Unnest the raw script, as largely used by DrQA's datasets and readers\ndf_script_unnested = (df_script['raw_character_text']\n .str.split(';', expand=True)\n .stack()\n .reset_index(level=0)\n .set_index('level_0')\n .rename(columns={0:'raw_character_text'})\n)\ndf_script_unnested.index.name = 'index'\ndf_script_unnested['raw_character_text'] = df_script_unnested['raw_character_text'].str.strip()",
          " Remove newlines and leading/trailing whitespaces from character_short column\ndf_script['character_short'] = df_script['character_short'].str.strip().str.replace(r'\\n', '')",
          "Remove punctuation and lowercase the text\ndf_script['normalized_text'] = df_script['raw_text'].str.replace('[^\\w\\s]','').str.lower()",
          "# There is a known wrong character in the dataset\ndf_script['raw_character_text'] = df_script['raw_character_text'].str.replace('docter', 'doctor')\n\n# Lower case for character names and locations\ndf_characters['character_name'] = df_characters['character_name'].str.lower()\ndf_locations['raw_location_text'] = df_locations['raw_location_text'].str.lower()\ndf_script['raw_character_text'] = df_script['raw_character_text'].str.lower()\ndf_script['raw_location_text'] = df_script['raw_location_text'].str.lower()",
          " Extract only the first and second part of each script\ndf_script['part'] = df_script.apply(lambda x: x['raw_text'].split(' | ')[0], axis=1)",
          "Convert text to lower case\ndf_script['raw_text'] = df_script['raw_text'].str.lower()",
          "Create a lower case version\ndf_script['normalized_text'] = df_script['raw_text'].str.lower()",
          "Create the 'raw_text' field\ndf_script['raw_text'] = df_script['normalized_text'].str.replace('\\r\\n', ' ').str.lower()",
          "Remove unwanted characters\ncharacters_to_remove = ['(', ')', '[', ']', '\\\"', '\\'', '\\`']\nfor c in characters_to_remove:\n    df_script['raw_character_text'] = df_script['raw_character_text'].str.replace(c, '')\n\n# Lowercase the character names\ndf_script['raw_character_text'] = df_script['raw_character_text'].str.lower()",
          "Remove apostrophes\ndf_script_normalized = df_script\ndf_script_normalized['normalized_text'] = df_script_normalized['normalized_text'].str.replace(\"'\", \"\")",
          " Remove punctuation from 'raw_text' feature in the 'df_script' DataFrame\ndf_script['raw_text'] = df_script['raw_text'].str.replace('[^\\w\\s]','')",
          "Remove special values and characters from the 'raw_text' column of the script dataframe\ndf_script['raw_text'] = df_script['raw_text'].str.replace('-', ' ')\ndf_script['raw_text'] = df_script['raw_text'].str.replace('\\.\\.\\.', ' ')"
         ],
         "marker": {
          "opacity": 0.5,
          "size": 5
         },
         "mode": "markers+text",
         "name": "61_Text preprocessing and cleaning techniques using Python and pandas",
         "text": [
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          ""
         ],
         "textfont": {
          "size": 12
         },
         "type": "scattergl",
         "x": [
          6.457821846008301,
          6.65964412689209,
          5.8498358726501465,
          6.897541046142578,
          6.88016939163208,
          6.825691223144531,
          6.69600772857666,
          5.984645843505859,
          6.365423679351807,
          6.319680213928223,
          7.0597686767578125,
          6.419796466827393,
          6.932551383972168,
          6.659270286560059,
          6.778679847717285,
          6.368213653564453,
          6.229098320007324,
          6.167535781860352,
          6.665454387664795,
          7.249652862548828,
          6.323946475982666,
          6.589338302612305,
          6.043493270874023,
          5.608638763427734,
          6.505185127258301,
          6.5341362953186035,
          6.873495101928711,
          6.133548736572266,
          7.09357213973999,
          6.695156097412109,
          5.3964033126831055,
          5.1949591636657715,
          6.939053058624268,
          7.033497333526611,
          6.875370025634766,
          6.183206558227539,
          6.711818218231201,
          6.89279317855835,
          6.260565757751465
         ],
         "y": [
          9.923591613769531,
          9.038835525512695,
          9.052698135375977,
          9.030988693237305,
          9.465694427490234,
          8.849357604980469,
          9.093013763427734,
          8.237201690673828,
          9.098244667053223,
          9.493978500366211,
          9.40112590789795,
          8.696834564208984,
          8.05300521850586,
          9.242830276489258,
          9.662556648254395,
          8.9647216796875,
          9.260082244873047,
          9.376387596130371,
          8.618449211120605,
          8.852354049682617,
          9.201088905334473,
          8.744879722595215,
          7.389055252075195,
          7.826805114746094,
          8.724213600158691,
          9.765660285949707,
          8.856768608093262,
          8.706172943115234,
          8.869670867919922,
          9.600800514221191,
          8.821366310119629,
          7.4644455909729,
          8.90938663482666,
          8.875450134277344,
          9.199831008911133,
          9.360631942749023,
          9.753687858581543,
          9.438797950744629,
          9.61305046081543
         ]
        },
        {
         "hoverinfo": "text",
         "hovertext": [
          "Check the number of rows of each DataFrame",
          "Determine the number of records in each of the dataframes.",
          "Check the first few rows of each data frame",
          "Check the first few rows of each dataframe",
          " Verify the number of rows for each dataframe",
          "Check the first entries of each DataFrame",
          "Inspecting the first few rows of each DataFrame",
          "Checking the first few rows of each dataframe",
          "Limit the dataframe only to the first column",
          "Checking the first few rows of the dataframe for visual inspection",
          " Check the first few rows of each dataframe",
          "Looking at the first few records of each dataframe",
          "Check that the file in each DataFrame are ordered in the same way as the corresponding IDs",
          "Check the first rows of each DataFrame to understand what I'm dealing with",
          " Checking the number of rows in each dataframe",
          "Extract first `n` records from each dataframe",
          "Checking the first rows for the script dataframe.",
          "Checking the first few rows of each dataframe",
          "Checking the first entry of each dataframe",
          "Check the first few rows of each dataframe to get an understanding of the data",
          "Check the first few rows of each dataframe to understand how the data is structured",
          "Check basic informations (for instance, the first rows) of each dataframe",
          "Check the first rows for each dataframe",
          "Checking first few rows of each dataframe.",
          " Visual check of the first rows of the dataframes",
          " Checking the first few rows of each DataFrame to understand the data",
          " Check the content of the first DataFrame",
          " Check the first few rows of each DataFrame",
          " Checking the first few rows of the script dataframe",
          "Check the shape and the first rows of each DataFrame",
          "Check the first few lines of each dataframe",
          "Looking at the first rows of each dataframe",
          "Find the number of rows for each dataframe",
          "Check the first dataframes rows",
          " Check all dataframe's first entries to have an idea of their columns and data",
          "Checking out the first few rows of each dataframe",
          "Check the first few rows of each dataframe to understand the data",
          "Checking the first few rows of DataFrame.",
          "Check the first few lines of each dataframe"
         ],
         "marker": {
          "opacity": 0.5,
          "size": 5
         },
         "mode": "markers+text",
         "name": "62_Checking the First Few Rows of Each DataFrame for Understanding and Verification",
         "text": [
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          ""
         ],
         "textfont": {
          "size": 12
         },
         "type": "scattergl",
         "x": [
          12.427407264709473,
          11.686169624328613,
          12.49282169342041,
          12.564705848693848,
          12.368399620056152,
          12.249168395996094,
          12.839768409729004,
          12.669808387756348,
          12.032624244689941,
          12.452862739562988,
          12.669726371765137,
          12.728976249694824,
          7.136024475097656,
          12.535697937011719,
          12.220144271850586,
          13.035553932189941,
          12.153757095336914,
          12.329851150512695,
          11.87804889678955,
          12.957064628601074,
          12.892618179321289,
          12.992908477783203,
          12.335710525512695,
          12.264726638793945,
          12.383477210998535,
          12.767401695251465,
          11.22921371459961,
          12.671295166015625,
          12.279908180236816,
          12.34835433959961,
          12.707275390625,
          12.384848594665527,
          11.96112060546875,
          12.111831665039062,
          12.560070991516113,
          12.498257637023926,
          12.795807838439941,
          12.485763549804688,
          12.902875900268555
         ],
         "y": [
          -6.108978748321533,
          -5.67487907409668,
          -5.968267917633057,
          -6.761633396148682,
          -6.217940330505371,
          -6.311218738555908,
          -7.491508483886719,
          -6.373892307281494,
          -5.486801624298096,
          -6.740137577056885,
          -6.784916400909424,
          -7.885965347290039,
          0.10105220228433609,
          -6.341213703155518,
          -5.922259330749512,
          -8.030623435974121,
          -5.688318252563477,
          -6.46572732925415,
          -5.882345676422119,
          -6.992048263549805,
          -6.717426776885986,
          -6.572890281677246,
          -6.476093292236328,
          -6.4837646484375,
          -6.428190231323242,
          -6.337735652923584,
          -4.996685028076172,
          -6.678287506103516,
          -5.667212963104248,
          -5.87697172164917,
          -7.220124244689941,
          -7.174245834350586,
          -6.123039722442627,
          -5.996644020080566,
          -6.101694583892822,
          -6.881056308746338,
          -6.710640907287598,
          -6.164538383483887,
          -7.176046848297119
         ]
        },
        {
         "hoverinfo": "text",
         "hovertext": [
          "# Download and load the spacy model\n!python -m spacy download en_core_web_sm",
          "spacy.cli.download(\"en_core_web_sm\")",
          "rake is a Python implementation of the BLAST protein alignment algorithm.\n\n# Usage:\n# pip install biopython\n# python -m pip install biopython\n\n# Import BLAST tools\nfrom Bio.Blast import NCBIWWW, NCBIXML",
          "Language model\nimport spacy\n\n# Download the language model\n!python -m spacy download en_core_web_sm",
          "Download spacy model\npython -m spacy download en_core_web_md",
          "Enable or download spacy English language model\n# !python -m spacy download en ",
          " Required if you get errors that the 'en' model was not found\n# !python -m spacy download en",
          "!python -m spacy download en_core_web_sm",
          "Install spacy models\n!python -m spacy download en_core_web_sm",
          "Download 'en_core_web_md' before starting\nspacy.cli.download(\"en_core_web_md\")",
          "get request parameters\nrequest_args = request.args",
          " Installs the en_core_web_sm model for spaCy",
          "Install the French model for spaCy if not present\nif 'fr_core_news_sm' not in spacy.util.get_installed_models():\n    !python -m spacy download fr_core_news_sm",
          " Download the SpaCy model for English if not already downloaded\npython -m spacy download en",
          "View the installed spaCy models\n!python -m spacy validate",
          "download \"en_core_web_md\" model to make sure benchmarks are reproducible\n!python -m spacy download en_core_web_md",
          "Check if the package is installed properly\npackage_name = 'spacy'\ntry:\n    __import__(package_name)\nexcept ImportError:\n    print(f'{package_name} is not installed properly. Please re-install the package and try again.')",
          " Download 'en_core_web_sm'\n!python -m spacy download en_core_web_sm",
          "# Install language model and dictionary for Enlgish\n!python -m spacy download en",
          " Install the 'en_core_web_sm' model of spaCy\n!python -m spacy download en_core_web_sm",
          "ensure we're using the correct version of spacy for compatibility\n!pip install spacy==3.0.6",
          "Download the spacy model\n! python -m spacy download en_core_web_sm",
          " # Install spaCy languages\n!python -m spacy download en_core_web_sm",
          "Limpar dados desnecessários",
          "Enable or download the following models by running:\n# !python -m spacy download en_core_web_sm\n# !python -m spacy download en_core_web_md",
          "ModuleNotFoundError: No module named 'spacy'\n# Install spacy by typing it into the anaconda terminal\n# pip install -U spacy",
          " Enable the Levenshtein's measure for Bratko-Klic's algorithm\n# Note: Requires installing the jellyfish package\nos.system('pip install jellyfish')\nimport jellyfish",
          "Install textual analysis library and the the language model for English\n!python -m spacy download en",
          "Optional: install spacy language model\n!python -m spacy download en_core_web_sm",
          "Install spacy language model for NER\n!python -m spacy download en_core_web_sm",
          "! python -m spacy download en_core_web_md",
          "Install spaCy language model\n!python -m spacy download en",
          " Vocês também precisarão fazer o download do modelo de língua inglesa do spaCy. Você pode fazer isso executando o seguinte comando no terminal ou prompt de comando:\n\npython -m spacy download en",
          " Install the standard model (en_core_web_sm) in case it's not installed\n!python -m spacy download en_core_web_sm",
          "Install missing dependencies for spacy\n!python -m spacy download en_core_web_sm",
          "Download Spacy English model\n!python -m spacy download en",
          " conda install -c conda-forge spacy",
          "Download `en` model from spacy if not already in cache\ntry:\n    _ = spacy.load('en')\nexcept OSError:\n    _ = spacy.cli.download('en')",
          "Install spaCy models\n!python -m spacy download en_core_web_sm"
         ],
         "marker": {
          "opacity": 0.5,
          "size": 5
         },
         "mode": "markers+text",
         "name": "63_SpaCy model installation and download using Python",
         "text": [
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          ""
         ],
         "textfont": {
          "size": 12
         },
         "type": "scattergl",
         "x": [
          16.61798858642578,
          17.196369171142578,
          15.815980911254883,
          15.77065372467041,
          16.797922134399414,
          15.590470314025879,
          16.12801170349121,
          16.847185134887695,
          16.429418563842773,
          17.113292694091797,
          17.19656753540039,
          16.5408878326416,
          16.323997497558594,
          15.72236442565918,
          16.101337432861328,
          16.722997665405273,
          15.75405216217041,
          17.143779754638672,
          16.000703811645508,
          16.587505340576172,
          16.501813888549805,
          16.54607391357422,
          16.183277130126953,
          14.201560974121094,
          16.510263442993164,
          16.073543548583984,
          15.934922218322754,
          15.724776268005371,
          15.919354438781738,
          15.974334716796875,
          16.86297607421875,
          15.987236976623535,
          15.409761428833008,
          16.896324157714844,
          16.03798484802246,
          15.878495216369629,
          16.42547035217285,
          16.37091064453125,
          16.62274932861328
         ],
         "y": [
          6.025078296661377,
          6.247669219970703,
          5.577268123626709,
          6.106354236602783,
          6.254739761352539,
          5.927750110626221,
          5.560107707977295,
          5.933647632598877,
          5.944357395172119,
          6.090778350830078,
          6.753813743591309,
          5.801571846008301,
          6.043481826782227,
          5.717205047607422,
          5.346482753753662,
          6.349379539489746,
          5.921930313110352,
          6.110905647277832,
          6.306760311126709,
          6.00344181060791,
          6.4783220291137695,
          5.708595275878906,
          6.267420768737793,
          3.2691755294799805,
          6.226867198944092,
          6.127774715423584,
          6.272557258605957,
          5.667203426361084,
          5.941243648529053,
          6.538832664489746,
          6.2234697341918945,
          5.9784979820251465,
          5.047797203063965,
          6.037099838256836,
          5.671360492706299,
          5.749452590942383,
          6.475192546844482,
          5.884483337402344,
          6.05042839050293
         ]
        },
        {
         "hoverinfo": "text",
         "hovertext": [
          "Check the contents of the characters dataframe.",
          "Start by looking at the first few rows of the characters DataFrame.",
          "We'll look at the character and location dataframes first.",
          " Let's take a look at the first few rows of the characters dataframe.",
          "Inspect the characters dataframe.",
          "Let's see the first entries of the characters dataframe.",
          "Look at the first few rows of the characters dataframe.",
          "Look at the first 3 rows of the characters dataframe and check if there are missing values",
          "Inspect the structure of the characters DataFrame.",
          "Inspect the data types and missing values of the characters dataframe.",
          " Let's have a look at the first few rows of the characters dataframe.",
          "Let's have a look at the characters dataframe.",
          " Let's analyze the structure of the dataframe characters.",
          "A quick peak into the character dataframe",
          "Let's take a look at the first few lines of the characters and locations DataFrames.",
          "Let's take a look at the characters DataFrame.",
          " Display the characters and locations DataFrames",
          "Let's first display general info about the characters dataframe (e.g. no of entries, no of columns, columns names, data types, and memory usage).",
          "Let's check the contents of the characters dataframe.",
          " Let's look at the structure of the characters DataFrame.",
          "We can now have a look at the characters and locations dataframes.",
          "Inspecting the Characters data frame.",
          "Check the content of the characters dataframe.",
          " Look at the first 5 rows of the characters dataframe.",
          "Let's check how the characters dataframe looks like.",
          " Let's check the structure of the character dataframe.",
          "Let's take a look at the first 5 rows of the characters dataframe.",
          "Now it's time to explore the data. Let's start by inspecting the first few rows of the characters dataframe.",
          "Take a peek at the first 5 lines of the characters dataframe.",
          "Let's take a look at the first few rows of the characters dataframe to understand its structure.",
          "Let's check what the characters dataframe looks like.",
          "Inspect the contents of the characters DataFrame.",
          "Let's take a look at the characters dataframe.",
          "Inspect the DataFrame containing information about the characters.",
          "A quick view at both characters and locations dataframe",
          "Inspect the characters dataframe.",
          "Let's have a look at the first few rows of the characters dataframe.",
          "Let's start by taking a look at the first few rows of the characters dataframe.",
          "Quick look at the characters dataframe"
         ],
         "marker": {
          "opacity": 0.5,
          "size": 5
         },
         "mode": "markers+text",
         "name": "64_Inspecting Characters Dataframe",
         "text": [
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          ""
         ],
         "textfont": {
          "size": 12
         },
         "type": "scattergl",
         "x": [
          9.42365837097168,
          9.198859214782715,
          9.466574668884277,
          9.920368194580078,
          9.085854530334473,
          9.241987228393555,
          9.59837818145752,
          9.382999420166016,
          9.273334503173828,
          8.772741317749023,
          9.684764862060547,
          9.740488052368164,
          9.57009220123291,
          9.44812297821045,
          9.625691413879395,
          9.658949851989746,
          7.9820332527160645,
          8.914578437805176,
          9.875761032104492,
          9.721765518188477,
          9.299003601074219,
          9.577987670898438,
          9.636411666870117,
          9.79189682006836,
          9.963165283203125,
          10.251851081848145,
          9.5971040725708,
          9.73454761505127,
          10.012572288513184,
          10.033915519714355,
          10.0368013381958,
          9.12169075012207,
          9.94831371307373,
          9.396544456481934,
          8.5241060256958,
          9.249013900756836,
          9.899121284484863,
          9.704842567443848,
          8.831542015075684
         ],
         "y": [
          11.811844825744629,
          11.201746940612793,
          9.283239364624023,
          10.621103286743164,
          11.620381355285645,
          11.29350471496582,
          10.873164176940918,
          11.647847175598145,
          11.328289031982422,
          11.541409492492676,
          10.696471214294434,
          10.085413932800293,
          10.652458190917969,
          11.58337688446045,
          8.762014389038086,
          9.950177192687988,
          9.422100067138672,
          11.703633308410645,
          11.286874771118164,
          10.23757266998291,
          8.330366134643555,
          10.954604148864746,
          12.020398139953613,
          11.099528312683105,
          10.699868202209473,
          10.791202545166016,
          10.76372241973877,
          10.67199993133545,
          10.401944160461426,
          10.504465103149414,
          10.86543083190918,
          11.804788589477539,
          9.756877899169922,
          11.321810722351074,
          9.238076210021973,
          11.782657623291016,
          10.692018508911133,
          10.555977821350098,
          11.852884292602539
         ]
        },
        {
         "hoverinfo": "text",
         "hovertext": [
          "Setting up environment for plot\nmatplotlib.rcParams['figure.figsize'] = [20, 10]\nnlp = spacy.load('en_core_web_sm')",
          " Set the default figure size for matplotlib plots\nmatplotlib.rcParams['figure.figsize'] = (15, 10)",
          "Plot parameters\nfontsize = 15\nfigsize = (15, 8)",
          "Show big pictures\nmatplotlib.rcParams['figure.figsize'] = [40, 20]",
          "set the plot size for all the upcoming notebook\nplt.rcParams['figure.figsize'] = [10, 5]",
          "sns.set(style=\"whitegrid\")\nplt.figure(figsize=(8,5))",
          " Set up the figure and axis\nfig, (ax1, ax2) = plt.subplots(1, 2, figsize=(20, 10))",
          " Set the size of the graphs\nmatplotlib.rcParams['figure.figsize'] = (10, 5)",
          "Optional: use larger font size and set the default figure size\nplt.rcParams.update({'font.size': 22, 'figure.figsize': (10, 8)})",
          "# Jupyter scatter plot size\nmatplotlib.rcParams['figure.figsize'] = (10.0, 6.0)",
          " inline matplotlib\nmatplotlib.rcParams['figure.figsize'] = (13, 7)",
          "reate a new plot\nplt.figure( figsize=(20,10) )",
          "Use this to render graphs. Filter to \"x11\" if it doesn't render.plt.gca().get_figure_manager().window.showMaximized()",
          "Set the default figure size for matplotlib to (14,7)\nmatplotlib.rcParams['figure.figsize'] = (14, 7)",
          "Leave this cell to display images in notebook\nmatplotlib.rcParams['figure.figsize'] = (10, 10)",
          "matplotlib.rcParams['figure.figsize'] = (10, 7)",
          "Ensure matplotlib is correctly enabled in Jupyter notebooks\nmatplotlib.rcParams['figure.figsize'] = [10, 5]",
          " Visual settings\nmatplotlib.rcParams['figure.figsize'] = [10, 5]\nmatplotlib.rcParams['figure.dpi'] = 200",
          " graphical preferences\nmatplotlib.rcParams['figure.figsize'] = (10.0, 5.0)",
          "Visualize the correlation matrix of the dataset\nmatplotlib.rcParams['figure.figsize'] = [12, 7]\nmatplotlib.rcParams['figure.dpi'] = 80\ncorrelation_matrix = df_script.corr()\nplt.imshow(correlation_matrix, cmap='hot', interpolation='nearest')\nplt.colorbar()\nplt.title('Correlation matrix')\nplt.show()",
          "Set plot size\nmatplotlib.rcParams['figure.figsize'] = [10, 7]",
          "Setup Matplotlib\nmatplotlib.rcParams['figure.figsize'] = (10, 6)  # Use bigger plots",
          "Setting the figure sizes\nmatplotlib.rcParams['figure.figsize'] = (20, 15)",
          "Set figure size\nplt.rcParams[\"figure.figsize\"] = [15, 6]",
          "Rescale the large image for easier viewing.\nplt.figure(figsize=(12, 12))\nplt.imshow(img, interpolation='nearest')\nplt.axis('off')\nplt.show()",
          "Visualization settings\nmatplotlib.rcParams['figure.figsize'] = (10, 5)\n\n# Load the spaCy model\nnlp = spacy.load('en')",
          " General plotting settings\nmatplotlib.rcParams['figure.figsize'] = [10, 5]\nmatplotlib.rcParams['figure.dpi'] = 80",
          "Show matplotlib plots\nmatplotlib.rcParams['figure.figsize'] = (12, 12)",
          "Set up matplotlib\nmatplotlib.rcParams['figure.figsize'] = [10, 5]",
          "matplotlib.rcParams['figure.figsize'] = [12, 8]",
          "# General configuration\npd.set_option('display.max_columns', 100)\npd.set_option('display.max_colwidth', 1000)\nmatplotlib.rcParams['figure.figsize'] = (10.0, 5.0)",
          "Set figure size for all matplotlib figures\nmatplotlib.rcParams['figure.figsize'] = [10, 5]",
          "# Data Visualization Setup\nplt.style.use('fivethirtyeight')\nplt.rcParams[\"figure.figsize\"] = (14,7)",
          "Set up figure size\nmatplotlib.rcParams['figure.figsize'] = (10, 10)",
          "Set the default plot size for matplotlib for better visibility",
          "Create a subplot\nfig, ax = plt.subplots(nrows=1, ncols=1, figsize=(13, 20))",
          "set(base linewidth for matplotlib)\nmatplotlib.rcParams['lines.linewidth'] = 1.0",
          "Adjust size of plots in the notebook\nplt.rcParams['figure.figsize'] = [15, 8]"
         ],
         "marker": {
          "opacity": 0.5,
          "size": 5
         },
         "mode": "markers+text",
         "name": "65_matplotlib figures and sizes",
         "text": [
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          ""
         ],
         "textfont": {
          "size": 12
         },
         "type": "scattergl",
         "x": [
          19.584144592285156,
          19.81386947631836,
          20.32040023803711,
          19.46949005126953,
          19.744558334350586,
          19.89392852783203,
          19.594505310058594,
          19.593379974365234,
          20.385704040527344,
          19.390722274780273,
          19.795024871826172,
          19.721473693847656,
          19.957138061523438,
          19.748044967651367,
          19.345407485961914,
          19.387563705444336,
          19.369068145751953,
          19.394989013671875,
          19.456676483154297,
          19.64797019958496,
          19.193296432495117,
          19.67215347290039,
          19.737415313720703,
          20.00614356994629,
          19.632787704467773,
          19.05997657775879,
          19.684206008911133,
          19.72713279724121,
          19.32837677001953,
          19.297163009643555,
          19.96938133239746,
          19.519088745117188,
          19.893474578857422,
          19.513399124145508,
          19.6126708984375,
          19.437223434448242,
          19.46986961364746,
          19.995384216308594
         ],
         "y": [
          6.952796936035156,
          6.835124969482422,
          7.506413459777832,
          7.28658390045166,
          6.557328224182129,
          6.3797502517700195,
          6.332533359527588,
          6.887729167938232,
          6.635431289672852,
          6.500288009643555,
          7.377148628234863,
          6.677799224853516,
          6.3765869140625,
          7.111027717590332,
          6.758097171783447,
          7.23350715637207,
          6.145308017730713,
          6.972296714782715,
          6.801797866821289,
          6.084070682525635,
          6.817231178283691,
          6.685113430023193,
          7.246731281280518,
          6.975810527801514,
          6.952038288116455,
          6.672847270965576,
          6.853226661682129,
          6.78941535949707,
          6.904745101928711,
          7.3502197265625,
          6.53993558883667,
          7.0126519203186035,
          6.892078399658203,
          7.246325969696045,
          6.061252593994141,
          6.822967052459717,
          7.241033554077148,
          6.868173599243164
         ]
        },
        {
         "hoverinfo": "text",
         "hovertext": [
          "Define the main directory path where the datasets are located",
          " Paths\ndataset_name = 'thesimpsons'\nsaved_path = f'../Datasets/{dataset_name}/'",
          "te: replace 'data/' with the correct path if the data files are not located in the 'data' subdirectory.",
          " Data files\nos.listdir('data')",
          "Optional: If you are using Google Colab and your storage has a folder called 'gdrive', you are able to read the files from 'data/' through there, given the fact that the data folder is directly inside 'gdrive'.",
          "To use Google Colab's data from Google Drive\nfrom google.colab import drive\ndrive.mount('/content/drive')",
          "Creatign a path for the assets folder",
          "Set path to local data as the data folder is not in the working directory",
          " Data folder path\ndata_folder = 'data/'",
          "Optional line if 'data' folder is not in the same as the script and '(df_characters...)' is commented out\nbasepath = 'data/'",
          "Add your data directory to the path\ndata_path = './data'",
          "Set a path to the data directory.",
          "Look for file\nos.listdir('data')",
          "Data directory\nDATA_DIR = 'data'",
          "Set path to data dir\nDATA_DIR = 'data/'",
          "Setting up the data directory path\ndata_dirpath = \"data\"",
          " define data path\ndata_path = 'data'",
          "Check if working directory contains data files\nprint(os.listdir('data'))",
          "Ensure the correct path for the data folder is set by running the code below:\nos.path.abspath('data')",
          "Optional exploration - SysCall\nos.system(\"/bin/ls -lh\")",
          "# Change the input path here\ninput_path = \"data\"",
          "Create a variable with the file name to easily reference and open it",
          "Remove the data folder and create a clean data folder",
          "Check the folder structure and contents to see if data sets have been loaded successfully\nos.listdir('data')",
          "# Set data folder\ndata_folder = 'data/'",
          "data directories\nos.listdir(\"data/\")",
          "Check                               filenames\nfor eachfilename in os.listdir('data'):\n    print(eachfilename)",
          "Check for the presence of the 'data' directory",
          "Extract the data path\ndata_path = 'data/'",
          "Connect to Google Drive to save/load data\nfrom google.colab import drive\ndrive.mount('/content/drive')",
          "Create global variables for data directory and files\nDATA_DIR = \"data\"",
          "Check if files are present\nos.listdir(\"data\")",
          "Define the path of the data directory",
          "ndata_folders = ['data_copy', 'data_clean']",
          "define MAIN_DIR\nMAIN_DIR = 'data'",
          " Look at directory contents\n!ls data",
          "Set and display the top level directory for data assets",
          "Browse files in the data directory\nos.listdir('data')"
         ],
         "marker": {
          "opacity": 0.5,
          "size": 5
         },
         "mode": "markers+text",
         "name": "66_Setting the Path to Local Data in the Working Directory",
         "text": [
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          ""
         ],
         "textfont": {
          "size": 12
         },
         "type": "scattergl",
         "x": [
          16.062482833862305,
          16.338642120361328,
          16.04958724975586,
          16.056583404541016,
          16.085268020629883,
          15.735825538635254,
          16.37799644470215,
          16.25884246826172,
          16.426660537719727,
          16.05524253845215,
          16.320432662963867,
          16.197965621948242,
          15.615660667419434,
          16.523649215698242,
          16.717100143432617,
          16.464048385620117,
          16.554624557495117,
          15.518452644348145,
          15.916708946228027,
          15.561436653137207,
          16.525468826293945,
          14.60007095336914,
          15.853404998779297,
          15.68867301940918,
          16.547168731689453,
          15.990097999572754,
          15.595462799072266,
          15.740923881530762,
          16.8210506439209,
          15.89653205871582,
          15.631197929382324,
          15.416078567504883,
          16.587800979614258,
          16.888566970825195,
          16.23059844970703,
          15.451640129089355,
          16.77884292602539,
          15.889044761657715
         ],
         "y": [
          3.1063575744628906,
          2.8820691108703613,
          2.2564845085144043,
          2.7707693576812744,
          2.3114726543426514,
          2.2397327423095703,
          3.318902015686035,
          2.662095308303833,
          2.3834431171417236,
          1.791763424873352,
          2.643781900405884,
          2.8497347831726074,
          2.829826593399048,
          2.3464701175689697,
          2.4841744899749756,
          2.446030616760254,
          2.4411239624023438,
          2.6191134452819824,
          2.87475848197937,
          3.0091114044189453,
          2.4708402156829834,
          2.4323067665100098,
          2.5049145221710205,
          2.979886054992676,
          2.2351479530334473,
          3.0637311935424805,
          2.5312891006469727,
          2.448840379714966,
          2.8135170936584473,
          2.5958499908447266,
          2.3325018882751465,
          2.7244763374328613,
          2.651254177093506,
          2.333740711212158,
          2.5501058101654053,
          2.201531171798706,
          2.817958116531372,
          3.0385074615478516
         ]
        },
        {
         "hoverinfo": "text",
         "hovertext": [
          " Display the first 5 rows of each DataFrame\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()",
          " Visualize the first 5 rows of each dataframe\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()",
          "display first 5 rows of each dataframe\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()",
          "Display the first 5 rows of each dataframe to inspect their contents\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()",
          "Display the first five rows of each dataframe\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()",
          " Display the first 5 rows of each dataframe\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()",
          " Display first 5 records from all dataframes\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()",
          "Display first 5 rows of each DataFrame\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()",
          " Display the first 5 rows of each dataframe\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()",
          "\n# Display the first 5 records of each dataframe to get an initial feel for the data\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()",
          "Display the first 5 rows of each dataframe to understand its structure\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()",
          " Output the first 5 rows of each dataframe to understand the data structure\ndf_characters.head(5), df_locations.head(5), df_script.head(5), df_episodes.head(5)",
          " Display the first 5 rows of each DataFrame\ndf_episodes.head(), df_characters.head(), df_locations.head(), df_script.head()",
          "Display the first 5 rows of each of the 4 DataFrames\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()",
          " Display the first 5 rows of each DataFrame\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()",
          "Display the first 5 rows of each dataframe\ndf_script.head(), df_characters.head(), df_locations.head(), df_episodes.head()",
          "Display the first 5 rows of each dataframe to understand the data better\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()",
          "\n# Display the first 5 rows of each dataframe to understand its structure\ndf_characters.head(), df_locations.head(), df_episodes.head(), df_script.head()",
          "Display the first 5 rows of the dataframes to inspect them\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()",
          "Display the first 5 rows of each dataframe to understand their structure\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()",
          "Display the first 5 rows of each dataframe\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()",
          " Display the first 5 rows of each DataFrame\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()",
          "Display first 5 rows of each dataframe\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()",
          "Display first 5 rows of each dataframe\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()",
          "display first 5 rows of each dataframe\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()",
          " Display the first 5 rows of each dataframe\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()",
          "Display the first 5 rows of each dataframe\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()",
          "Display the first 5 rows of each DataFrame\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()",
          "# Display the first 5 rows of the characters dataframe\ndf_episodes.head()",
          "Display the first 5 rows of each dataframe\ndisplay(df_characters.head(), df_locations.head(), df_script.head(), df_episodes.head())",
          " Display the first five rows of each dataframe.\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()",
          "# Display the first 5 rows of each dataframe\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()",
          "Display the first 5 rows of each dataframe\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()",
          "Display the first 5 rows of each dataframe to understand its structure\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()",
          "Show the first 5 rows of each of these dataframes to understand better what data is available in them\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()",
          "Display the first 5 rows of each dataframe\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()",
          "Display the first 5 rows of each dataframe\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()",
          " Display the first 5 rows of the dataframes\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()"
         ],
         "marker": {
          "opacity": 0.5,
          "size": 5
         },
         "mode": "markers+text",
         "name": "67_Displaying first 5 rows of each dataframe to understand their structure and initial data records",
         "text": [
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          ""
         ],
         "textfont": {
          "size": 12
         },
         "type": "scattergl",
         "x": [
          -1.7278556823730469,
          -2.21586537361145,
          -1.5310367345809937,
          -2.406494140625,
          -1.3084663152694702,
          -1.7762494087219238,
          -1.4729210138320923,
          -1.6996372938156128,
          -1.7945243120193481,
          -1.1068975925445557,
          -2.6052258014678955,
          -2.7065374851226807,
          -1.235022783279419,
          -1.4592719078063965,
          -1.362317442893982,
          -1.677320122718811,
          -2.1862025260925293,
          -2.4726507663726807,
          -2.4607198238372803,
          -2.50642728805542,
          -1.4061585664749146,
          -1.5951400995254517,
          -1.6116235256195068,
          -1.6091139316558838,
          -1.566965937614441,
          -1.4278570413589478,
          -1.5799100399017334,
          -1.8404691219329834,
          -0.7182384133338928,
          -1.6318010091781616,
          -1.4564071893692017,
          -1.337769627571106,
          -1.3944941759109497,
          -2.401416301727295,
          -2.524622678756714,
          -1.614896297454834,
          -1.4912354946136475,
          -1.7987778186798096
         ],
         "y": [
          8.224812507629395,
          7.739753723144531,
          8.370863914489746,
          7.7050347328186035,
          7.786684513092041,
          8.012425422668457,
          8.294266700744629,
          8.635202407836914,
          8.2813720703125,
          7.800567626953125,
          7.0989089012146,
          6.885069370269775,
          7.733851432800293,
          8.20251178741455,
          8.093833923339844,
          7.768216133117676,
          7.876264572143555,
          6.875454902648926,
          7.539729118347168,
          7.198027610778809,
          8.16396427154541,
          8.070035934448242,
          8.543679237365723,
          8.552657127380371,
          8.469653129577637,
          7.918786525726318,
          7.981912136077881,
          7.972923278808594,
          6.8483805656433105,
          7.591723918914795,
          7.731717586517334,
          7.605307102203369,
          8.436371803283691,
          7.325934410095215,
          6.964156150817871,
          8.289958953857422,
          7.976806163787842,
          8.13857650756836
         ]
        },
        {
         "hoverinfo": "text",
         "hovertext": [
          "Display all columns of a dataframe\npd.set_option('display.max_columns', None)",
          " Display the first rows of the dataframe\npd.set_option('display.max_columns', None)",
          "Display output of all the lines in the dataframe\npd.set_option('display.max_rows', None)",
          "Display all dataframe columns\npd.set_option('display.max_columns', None)",
          "# Show entire dataframes in printed output\npd.set_option('display.max_columns', None)\npd.set_option('display.max_rows', None)",
          "Display all columns in dataframes\npd.set_option('display.max_columns', None)",
          "Display all the columns of the dataframe\npd.set_option('display.max_columns', None)",
          "Display all columns for the script dataframe\npd.set_option('display.max_columns', None)\ndf_script.head()",
          "Display some lines from the main dataframe\nwith pd.option_context(\"display.max_rows\", 3, \"display.max_columns\", 6):\n    display(df_script.head(2))",
          "Display all columns of the script dataframe to visualise what information is available\npd.set_option('display.max_columns', None)\ndf_script.head()",
          "Setting to display all columns in the dataframe\npd.set_option('display.max_columns', None)",
          "Display all columns of the dataframe\npd.set_option('display.max_columns', None)",
          "Display all the columns in the dataframes\npd.options.display.max_columns = None",
          "Display all columns and the first 5 rows\nwith pd.option_context('display.max_columns', None):\n    display(df_script.head())",
          "Display all columns (handy when dealing with large DataFrames)\npd.set_option('display.max_columns', None)",
          " Set output to display all columns in a dataframe\npd.set_option('display.max_columns', None)",
          "Show all columns for DataFrame\npd.set_option('display.max_columns', None)",
          "Display maximum columns when showing the dataframe\npd.set_option('display.max_columns', None)",
          "Displaying all columns in the dataframe\npd.set_option('display.max_columns', None)",
          " Display all columns of the dataframe\npd.set_option('display.max_columns', None)\n# Display all rows of the dataframe\npd.set_option('display.max_rows', None)",
          "Display for DataFrame\npd.options.display.max_columns = None",
          "Show all script lines\npd.set_option('display.max_colwidth', -1)\ndf_script.head()",
          "to display all columns in the dataframes\npd.set_option('display.max_columns', None)",
          "# Display all dataframe columns\npd.set_option('display.max_columns', None)",
          "Display all columns for each dataframe\npd.set_option('display.max_columns', None)",
          "Display all columns from the script DataFrame\npd.set_option('display.max_columns', None)",
          "Some initial configurations\npd.options.display.max_columns = None  # Shows all columns when printing the dataframe",
          " Display all columns of the dataframe\npd.set_option('display.max_columns', None)",
          "Display all columns of the dataframe\npd.set_option('display.max_columns', None)",
          "Display all the columns of the df_script dataframe\npd.set_option('display.max_columns', None)\ndf_script.head()",
          "Display all columns in dataframe\npd.set_option('display.max_columns', None)",
          "Display option to show all columns when displaying dataframe\npd.set_option('display.max_columns', None)",
          "Show all columns of each dataframe for easy access\npd.set_option('display.max_columns', None)",
          "Display all columns of the dataframes\npd.set_option('display.max_columns', None)",
          "Display all columns of the dataframes\npd.set_option('display.max_columns', None)",
          "Display all columns in the dataframes\npd.set_option('display.max_columns', None)",
          " Show all columns for the script dataframe\npd.set_option('display.max_columns', None)\npd.set_option('display.width', None)"
         ],
         "marker": {
          "opacity": 0.5,
          "size": 5
         },
         "mode": "markers+text",
         "name": "68_Displaying All Columns in DataFrames",
         "text": [
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          ""
         ],
         "textfont": {
          "size": 12
         },
         "type": "scattergl",
         "x": [
          20.882692337036133,
          21.560686111450195,
          21.52802276611328,
          21.2393798828125,
          21.366666793823242,
          20.912065505981445,
          21.503067016601562,
          21.367380142211914,
          21.291061401367188,
          21.583515167236328,
          21.475236892700195,
          21.126676559448242,
          21.35284996032715,
          21.922405242919922,
          21.678871154785156,
          20.72643280029297,
          21.05711555480957,
          21.806194305419922,
          21.13212776184082,
          21.160541534423828,
          20.917016983032227,
          22.26430320739746,
          21.559175491333008,
          21.641883850097656,
          20.66283416748047,
          21.10220718383789,
          21.650236129760742,
          21.16411781311035,
          21.212539672851562,
          21.308815002441406,
          21.068574905395508,
          20.892885208129883,
          20.875377655029297,
          21.087244033813477,
          20.970083236694336,
          21.201597213745117,
          21.452367782592773
         ],
         "y": [
          -0.9270766377449036,
          -0.7361519932746887,
          -0.47188079357147217,
          -0.5695235729217529,
          0.0375710166990757,
          -0.5351744294166565,
          -0.6882880330085754,
          -0.02401208132505417,
          -0.03033648431301117,
          -0.29648661613464355,
          -0.23653532564640045,
          -0.7774057984352112,
          -0.33706164360046387,
          -0.22181639075279236,
          -0.16239169239997864,
          -0.5631957650184631,
          -0.33401811122894287,
          -0.49414342641830444,
          -0.5272144079208374,
          -0.17060434818267822,
          -0.8806605935096741,
          0.7749148011207581,
          -0.2958887219429016,
          -0.492218554019928,
          -0.41512399911880493,
          -0.4905616343021393,
          -0.2662654221057892,
          -0.9342459440231323,
          -0.8208261132240295,
          0.007773657329380512,
          -0.410287082195282,
          -0.6252732276916504,
          -0.038349393755197525,
          -0.508271336555481,
          -0.3763267695903778,
          -0.5654769539833069,
          0.30721062421798706
         ]
        },
        {
         "hoverinfo": "text",
         "hovertext": [
          "Checking the first few rows of the characters dataframe.",
          "Check the character data first few rows",
          "Checking the first few rows of the characters dataframe to understand the data",
          " Check first few rows of 'df_characters' DataFrame",
          " Checking the first few rows of the characters dataframe.",
          "Inspecting the first rows of the characters dataframe",
          "Look at the first few rows of the characters dataframe",
          "Inspecting the first few records of the characters dataframe.",
          "Checking the first few rows of the characters data frame",
          "Check the first rows of the characters dataframe.",
          "Check the first few rows of the characters dataframe.",
          "Check the first rows of the characters dataframe",
          "Check the first few rows of the dataframe for characters.",
          " Check the first lines of the \"Characters\" dataframe",
          "Checking the first few rows of the characters dataframe",
          "Check the first 10 rows of the characters dataframe",
          " Checking the first few rows of the characters dataframe.",
          "Check first 3 rows of characters dataset",
          "Inspecting the first few rows of the characters dataframe.",
          "Check the first few rows of the characters DataFrame.",
          " Check the first few rows of the characters dataframe",
          "Checking the first few rows of the characters dataframe",
          "Inspecting first 3 rows of the characters DataFrame to understand the data",
          "Check the first few rows of the characters data frame",
          "Checking the first few rows of the characters dataframe",
          "Inspecting first few entries of `df_characters` DataFrame",
          "Checking the first few entries of the characters dataframe",
          " Checking the shape and the first entries of the characters dataframe",
          "Inspect the first 3 records of the characters dataframe",
          "Checking the first few rows of the characters dataframe",
          "Check a few rows of characters dataframe",
          "Check the first few rows of the characters data",
          "Inspect the first few entries of the characters dataframe",
          " Checking the first few rows of the characters dataframe",
          "check the first few lines of the characters dataframe",
          "Check the first few rows of the characters DataFrame",
          "Get first rows of the character dataframe"
         ],
         "marker": {
          "opacity": 0.5,
          "size": 5
         },
         "mode": "markers+text",
         "name": "69_Inspecting First Few Rows of Characters Dataframe",
         "text": [
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          ""
         ],
         "textfont": {
          "size": 12
         },
         "type": "scattergl",
         "x": [
          10.50864028930664,
          10.770980834960938,
          10.61121654510498,
          9.496203422546387,
          10.327014923095703,
          10.098763465881348,
          9.793718338012695,
          9.821124076843262,
          10.649405479431152,
          10.204010963439941,
          10.042797088623047,
          10.40900707244873,
          10.203191757202148,
          10.700946807861328,
          10.732756614685059,
          10.43332290649414,
          10.626641273498535,
          10.719687461853027,
          9.60627555847168,
          10.238051414489746,
          10.733332633972168,
          10.441387176513672,
          9.884191513061523,
          10.811697959899902,
          10.801546096801758,
          8.658689498901367,
          10.20620346069336,
          10.375251770019531,
          9.980929374694824,
          10.651496887207031,
          10.561728477478027,
          10.747671127319336,
          9.532249450683594,
          10.546831130981445,
          10.866031646728516,
          10.40326976776123,
          9.786614418029785
         ],
         "y": [
          12.273233413696289,
          10.139751434326172,
          12.356884956359863,
          12.780943870544434,
          12.178367614746094,
          12.58183479309082,
          12.391533851623535,
          12.577788352966309,
          11.292943000793457,
          11.953962326049805,
          12.177154541015625,
          11.939544677734375,
          12.164128303527832,
          12.035453796386719,
          12.310708045959473,
          12.08858585357666,
          11.95827579498291,
          10.698835372924805,
          12.506534576416016,
          12.152515411376953,
          11.696351051330566,
          11.786338806152344,
          12.525527954101562,
          11.265066146850586,
          11.845856666564941,
          13.400681495666504,
          12.506173133850098,
          12.265963554382324,
          12.582572937011719,
          12.17940616607666,
          12.151908874511719,
          9.983657836914062,
          12.752184867858887,
          12.064576148986816,
          11.72432804107666,
          11.759052276611328,
          12.64627742767334
         ]
        },
        {
         "hoverinfo": "text",
         "hovertext": [
          "Inspect the Characters dataframe",
          "Check the content of the dataframe of the characters",
          "Inspect characters dataframe",
          "Checking the structure of the characters dataframe",
          " Explore data - characters dataframe",
          " Explore the characters DataFrame",
          "Check the structure and dtypes of the character dataframe",
          "Checking the contents of the character dataframe",
          "Inspect the contents of the characters dataframe",
          "Check character dataframe",
          "Inspect the dataframe with the characters",
          " Exploring the characters dataframe",
          "Inspect the content of the `characters` dataframe",
          "Inspect dataframe for characters",
          "Inspect one of the dataframes (e.g. characters)",
          "Check the character dataframe",
          "Join dataframe to retrieve character's information",
          "Inspect the characters dataframe",
          "Inspection of the characters DataFrame",
          "Print out the Characters dataframe, note that this will return a huge table that might be slow to render",
          "View the structure of the characters dataframe",
          " Check the data from the characters dataframe",
          "Inspect the content of the characters dataframe",
          "Inspecting the characters dataframe",
          "Check basic info on characters and locations dataframe",
          "Inspect the structure of the characters DataFrame",
          "Inspect the structure of the characters data frame",
          "Inspecting the characters dataframe",
          "Checking the characters dataframe",
          " View the characters dataframe",
          "View the characters dataframe",
          "Checking the content of the characters dataframe",
          "Inspect the characters dataframe",
          "Inspecting the characters dataframe",
          "Examine the structure of the characters DataFrame",
          "Inspect the characters DataFrame",
          "Inspect the characters dataframe"
         ],
         "marker": {
          "opacity": 0.5,
          "size": 5
         },
         "mode": "markers+text",
         "name": "70_Inspecting Characters DataFrame",
         "text": [
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          ""
         ],
         "textfont": {
          "size": 12
         },
         "type": "scattergl",
         "x": [
          8.338890075683594,
          7.894205093383789,
          8.70333480834961,
          8.47362232208252,
          8.400975227355957,
          8.357034683227539,
          8.5504732131958,
          7.899231433868408,
          8.15046501159668,
          7.826694011688232,
          8.710350036621094,
          8.700607299804688,
          8.279435157775879,
          8.830009460449219,
          8.48591423034668,
          8.058377265930176,
          8.019495010375977,
          8.514809608459473,
          8.256784439086914,
          8.517154693603516,
          8.877249717712402,
          7.887796878814697,
          8.562024116516113,
          8.265174865722656,
          7.9822516441345215,
          9.070008277893066,
          9.191720008850098,
          8.425798416137695,
          7.728480339050293,
          8.173206329345703,
          8.51060962677002,
          7.834527492523193,
          8.50521183013916,
          8.1802978515625,
          8.977020263671875,
          8.623285293579102,
          8.409399032592773
         ],
         "y": [
          11.967757225036621,
          11.321012496948242,
          12.201253890991211,
          11.370869636535645,
          11.845512390136719,
          11.650723457336426,
          11.461333274841309,
          11.258990287780762,
          12.113365173339844,
          11.453107833862305,
          12.251338958740234,
          11.408177375793457,
          12.51573657989502,
          12.175222396850586,
          12.412423133850098,
          11.406275749206543,
          11.114632606506348,
          11.817266464233398,
          11.746221542358398,
          11.645546913146973,
          11.86683464050293,
          11.037632942199707,
          12.090213775634766,
          11.68492317199707,
          10.25896167755127,
          11.302700996398926,
          11.168944358825684,
          11.686553955078125,
          11.365904808044434,
          12.096288681030273,
          11.784900665283203,
          11.159967422485352,
          12.164945602416992,
          11.601274490356445,
          11.11004638671875,
          12.085393905639648,
          12.078544616699219
         ]
        },
        {
         "hoverinfo": "text",
         "hovertext": [
          " nlp = spacy.load('en')",
          " Dictionary to store tokenized documents\ntokenized_documents = {}\n\n# Load spacy models\nnlp = spacy.load('en')",
          "Create an English language class\nnlp = spacy.load('en')",
          "Optionally for spacy\nnlp = spacy.load('en')",
          " Set the `nlp` variable to the SpaCy model for English and disable parsing\nnlp = spacy.load('en', disable=['parser'])",
          "Enable the 'en' module if there's no model loaded\nif not 'nlp' in locals():\n    print(\"Loading English module...\")\n    nlp = spacy.load('en')",
          "Setup Spacy\nnlp = spacy.blank('en')",
          "Load Spacy's English language models\nnlp = spacy.load('en')",
          "Load the trained English tokenizer, tagger, parser, NER and word vectors",
          "For numerical method and manipulations\nfrom scipy.optimize import minimize\n\n# Natural Language Processing\nimport spacy\nnlp = spacy.load('en')",
          "Define ufoc\nUFOC = spacy.blank('en')",
          "Create an object of class 'spacy.lang.en.English' and name it 'nlp'.",
          "Load spacy model\nnlp = spacy.load('en')",
          "Global variable:\nnlp = spacy.load('en')",
          "Load spacy model\nnlp = spacy.load('en')",
          "# Load spacy pre-trained model\nnlp = spacy.load('en')",
          "Function to load pre-trained English NER model from spacy and apply it to a string",
          "Set up spaCy\nnlp = spacy.load('en')",
          "Load spacy model to get word embeddings",
          "Enable or download the spacy module by running the command below in the terminal:\n# python -m spacy download en\nimport spacy\nnlp = spacy.load(\"en\")",
          "Set up spacy\nnlp = spacy.blank(\"en\")",
          "Init spacy\nnlp = spacy.load('en')",
          "Proranpdopting for NLP for both character and location names to handle misspellings and sense\nnlp = spacy.load(\"en_core_web_md\")",
          "Set up Spacy\nnlp = spacy.load('en')",
          "Load the custom NLP pipeline\nnlp = spacy.load('simpsons')",
          " Inicializa spaCy\nnlp = spacy.load('en')",
          "setup spacy\nnlp = spacy.load('en')",
          " Load the pre-built NLP model - spacy.load('en')",
          "Declare the path to the word embeddings from Spacy",
          " Load the Spacy pre-trained model for English language\nnlp = spacy.load('en')",
          "Loading pre-trained English tokenizer, tagger, parser, NER and word vectors\nnlp = spacy.load('en')",
          "english pipeline\nnlp = spacy.blank(\"id\")",
          "# Set up the spacy model for preprocessing\nnlp = spacy.load('en')",
          "Setting up Spacy\nnlp = spacy.load('en')",
          "BERT model\nnlp = spacy.load('en_trf_bertbaseuncased_lg')"
         ],
         "marker": {
          "opacity": 0.5,
          "size": 5
         },
         "mode": "markers+text",
         "name": "71_Loading Spacy's English language model",
         "text": [
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          ""
         ],
         "textfont": {
          "size": 12
         },
         "type": "scattergl",
         "x": [
          15.991878509521484,
          15.129495620727539,
          15.734408378601074,
          15.709443092346191,
          14.984345436096191,
          15.362373352050781,
          15.639384269714355,
          15.456704139709473,
          14.543993949890137,
          15.280348777770996,
          15.95877456665039,
          15.178030967712402,
          15.670808792114258,
          15.59482192993164,
          15.870148658752441,
          15.705090522766113,
          15.300813674926758,
          15.803205490112305,
          15.04196548461914,
          15.539009094238281,
          15.597834587097168,
          16.063701629638672,
          16.053428649902344,
          15.61539077758789,
          15.40898323059082,
          15.763875007629395,
          15.82623291015625,
          15.62419319152832,
          15.155757904052734,
          15.291337966918945,
          15.224015235900879,
          16.053438186645508,
          15.338362693786621,
          15.467960357666016,
          15.595281600952148
         ],
         "y": [
          7.208773136138916,
          7.618193626403809,
          6.849852085113525,
          7.394243240356445,
          7.414340972900391,
          7.422755241394043,
          7.326460838317871,
          7.039181232452393,
          6.990739822387695,
          7.4243268966674805,
          7.548670768737793,
          6.7516303062438965,
          7.27786922454834,
          7.04081916809082,
          7.452914714813232,
          7.6307501792907715,
          7.498314380645752,
          7.063572883605957,
          7.773372650146484,
          7.0409016609191895,
          7.33116340637207,
          7.152633190155029,
          7.307089328765869,
          7.278883457183838,
          7.421642780303955,
          6.58275842666626,
          7.186563014984131,
          7.433906078338623,
          7.345640182495117,
          7.53912878036499,
          7.236217498779297,
          7.661019325256348,
          7.538403511047363,
          7.075535774230957,
          7.751138687133789
         ]
        },
        {
         "hoverinfo": "text",
         "hovertext": [
          "\n",
          ")",
          "(.....continues on)",
          " Remove unclosed parentheses in the code and join it together with backslashes",
          "It is not clear what the next steps are in the code, as the provided code seems to be incomplete.",
          "change the password to your student's ID number\npassword = 123456789",
          "60*'#'",
          " Rest of the code is not provided.",
          "I'm sorry, but I cannot execute this code as it is. I can only provide code completions and extensions.",
          "Code not available for this cell.",
          "Coding as per the companion's request.",
          " To be continued...",
          "to magnetic IDE...",
          "\n# CONFIGURATION\n#",
          "```",
          "Code to be continued...",
          "Just continue the code from the last line",
          "Leave the rest of the code as is",
          "to be continued...",
          "# Code continues...",
          "Since the error is regarding the format the above code is correct.",
          "In[2]:",
          "Code completion not necessary.",
          " What's the complete code?",
          "#API KEY not available for the moment. Hidden away for running purposes.\nSPOTIFY_API_KEY = '123456789abcdefghijklmnopqrstuvwxyz'",
          "tag::pre_requisites[]",
          "\n",
          "Code complete.",
          "main()",
          "I am skipping generated example code because it is too long.",
          "Tying a newline character at the end of this code causes the error or the format to be changed. Therefore, I will end it here.",
          "I am not able to provide the next part of the code as it seems to be referencing external data and files that I do not have access to.",
          ".*.",
          "Is there an error in the original code?",
          " Visual Studio code extension is used for easy live program completion."
         ],
         "marker": {
          "opacity": 0.5,
          "size": 5
         },
         "mode": "markers+text",
         "name": "72_Incomplete code and missing references",
         "text": [
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          ""
         ],
         "textfont": {
          "size": 12
         },
         "type": "scattergl",
         "x": [
          13.020367622375488,
          13.14573860168457,
          13.803272247314453,
          11.339685440063477,
          13.064044952392578,
          12.831473350524902,
          13.121179580688477,
          12.692340850830078,
          12.997091293334961,
          12.912694931030273,
          13.077089309692383,
          13.939080238342285,
          14.536310195922852,
          13.765397071838379,
          12.790642738342285,
          13.2886381149292,
          12.171957015991211,
          12.594696044921875,
          14.012255668640137,
          13.249664306640625,
          12.443346977233887,
          12.826835632324219,
          13.084575653076172,
          12.820024490356445,
          13.040234565734863,
          13.70356273651123,
          12.86023998260498,
          12.896315574645996,
          13.433311462402344,
          12.653314590454102,
          11.562372207641602,
          13.567562103271484,
          13.28121280670166,
          12.331242561340332,
          13.262022972106934
         ],
         "y": [
          3.3212852478027344,
          3.3850791454315186,
          3.09977650642395,
          4.917477130889893,
          4.115906238555908,
          4.411777496337891,
          3.2973124980926514,
          3.72277569770813,
          3.6358273029327393,
          3.63826322555542,
          3.0316572189331055,
          2.908987283706665,
          2.150113105773926,
          2.305323600769043,
          3.8802809715270996,
          3.391268730163574,
          4.035017013549805,
          3.956468105316162,
          2.9537465572357178,
          3.181697130203247,
          3.8113651275634766,
          3.0870890617370605,
          3.7149555683135986,
          3.760531187057495,
          4.482713222503662,
          3.943671226501465,
          3.0851519107818604,
          3.6771492958068848,
          3.4404585361480713,
          3.8438217639923096,
          4.497103214263916,
          3.716191530227661,
          3.201622486114502,
          3.87473201751709,
          3.2893714904785156
         ]
        },
        {
         "hoverinfo": "text",
         "hovertext": [
          "Checking the data shapes",
          "Checking the structure of the various datasets",
          "Visually inspect initial dataset shapes and feature names",
          "Inspecting the content of the datasets.",
          " Checking how each of the dataset looks like",
          "Displaying the 3 datasets per quick check.",
          "Checking a few stats about the datasets",
          "Inspect the datasets to understand their structure and contents.",
          " Check the result and the shape.",
          "Check the shape of the datasets",
          "Checking the general structure of the datasets",
          "Inspect the structure of the datasets",
          "Inspect the structure of the datasets",
          "Inspecting each of the datasets",
          "Inspect the structure and data types of the datasets",
          "Inspect the structure of the datasets.",
          "Inspecting the data shapes",
          "Checking the data shape and the headers",
          "Checking the data in the datasets",
          " Quick inspection of each data set",
          "Check the overview of each dataset",
          "Inspecting datasets",
          "Check the content of these datasets",
          "Checking the structure of the four datasets",
          " Checking contents of the dataset",
          "TODO: Examine dataset shapes and column names",
          "Inspect the datasets",
          "Try to print the shapes of the acquired datasets to get a feeling of the data",
          "Check the information contained in the transformed datasets",
          "Check the shape of the datasets",
          "Inspect datasets",
          "Quick inspection of the data sets to understand their structure and content",
          "Checking the heads of the datasets to better understand their structure.",
          "Checking the datasets",
          " Add some basic checks to the dataset"
         ],
         "marker": {
          "opacity": 0.5,
          "size": 5
         },
         "mode": "markers+text",
         "name": "73_Dataset Inspection and Shape Checking",
         "text": [
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          ""
         ],
         "textfont": {
          "size": 12
         },
         "type": "scattergl",
         "x": [
          13.51076602935791,
          14.623939514160156,
          14.467580795288086,
          14.694133758544922,
          14.523094177246094,
          14.611101150512695,
          14.76365852355957,
          15.075471878051758,
          14.133383750915527,
          13.911760330200195,
          14.948443412780762,
          14.580533027648926,
          14.418522834777832,
          14.246987342834473,
          14.818197250366211,
          14.830151557922363,
          14.009764671325684,
          13.333620071411133,
          14.086044311523438,
          14.855857849121094,
          14.465832710266113,
          14.902708053588867,
          14.625077247619629,
          14.778486251831055,
          14.434090614318848,
          14.112166404724121,
          14.982269287109375,
          14.437026977539062,
          14.251180648803711,
          14.135400772094727,
          15.093530654907227,
          14.923004150390625,
          14.903349876403809,
          14.500978469848633,
          14.322694778442383
         ],
         "y": [
          -2.072535514831543,
          -1.802114486694336,
          -1.7110012769699097,
          -1.9430872201919556,
          -1.501499056816101,
          -2.252902030944824,
          -1.941264033317566,
          -1.7594579458236694,
          -1.310049295425415,
          -1.6609082221984863,
          -2.098674774169922,
          -1.7604475021362305,
          -2.1239750385284424,
          -1.8972854614257812,
          -2.1284987926483154,
          -2.0775060653686523,
          -1.6472904682159424,
          -1.6537641286849976,
          -1.1332666873931885,
          -1.1322073936462402,
          -2.1251304149627686,
          -1.6629431247711182,
          -1.795783519744873,
          -2.4487860202789307,
          -1.2165549993515015,
          -1.2747857570648193,
          -1.7660472393035889,
          -2.3049161434173584,
          -1.3533436059951782,
          -1.6977211236953735,
          -1.2535676956176758,
          -1.496746301651001,
          -2.5623056888580322,
          -1.4688560962677002,
          -1.3979650735855103
         ]
        },
        {
         "hoverinfo": "text",
         "hovertext": [
          "Let's check what the scripts DataFrame looks like.",
          " Let's have a look at the structure of the script dataframe.",
          " Preprocess script lines dataframe",
          "Checking the script dataframe",
          " The script contains four dataframes, each corresponding to a table in the original database.",
          "Check the columns that we currently have in the script dataframe",
          "Change script lines dataframe in order to fasten operations",
          "Inspect the structure of the raw DataFrame for script lines.",
          "Let's check a basic description of the script dataframe.",
          "Inspect script dataframe",
          "Check the script dataframe",
          "Look at what we have in the script DataFrame",
          "Checking the first couple of scripts in the Simpsons DataFrame",
          "I will start analyzing the script data. Specifically, I will begin by examining the contents of the `df_script` DataFrame.",
          "Creating a dummy script dataframe for the splash screen",
          " In order to analyse the script, we will load the data into a dataframe for easier querying",
          "Find out which scripts are in our dataframe",
          "We'll start by taking a look at the first few rows of the script lines dataframe to understand its structure and the kind of data it contains.",
          "Let's see the first few characters of the script dataframe.",
          " Let's take a look at the first five rows of the script lines dataframe.",
          " Check the structure of the dataframe containing the script lines.",
          "Check the content of the script DataFrame",
          "Get relevant features from scripts dataframe",
          "Check some lines of the script DataFrame",
          "Inspect the script dataframe to understand its structure and the kind of information it contains.",
          "We will look into script dataframe first.",
          "Let's see how the script lines dataframe look like.",
          "We'll be using the df_script dataframe to analyze the script lines.",
          "Inspect the dataframe about the script lines",
          "For this demo we will work with the script lines dataframe.",
          "Inspect the content of the script dataframe to understand its structure and content.",
          "Inspect the script dataframe",
          "Check the script dataframe",
          "Inspect the first 3 lines of the dataframe containing the script lines.",
          "Check what's in the word script dataframe"
         ],
         "marker": {
          "opacity": 0.5,
          "size": 5
         },
         "mode": "markers+text",
         "name": "74_Data Analysis of Script Documents",
         "text": [
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          ""
         ],
         "textfont": {
          "size": 12
         },
         "type": "scattergl",
         "x": [
          8.763154029846191,
          8.461596488952637,
          7.837610244750977,
          8.765888214111328,
          8.340291976928711,
          8.619721412658691,
          7.599264621734619,
          8.23562240600586,
          8.124557495117188,
          8.726274490356445,
          9.029590606689453,
          8.696370124816895,
          8.926785469055176,
          8.349047660827637,
          7.81620454788208,
          8.221611022949219,
          8.505167007446289,
          8.469945907592773,
          8.61265754699707,
          8.793556213378906,
          8.613912582397461,
          8.593764305114746,
          8.303863525390625,
          8.699260711669922,
          8.57182502746582,
          8.628608703613281,
          8.215556144714355,
          7.967004776000977,
          8.290027618408203,
          8.396445274353027,
          8.096128463745117,
          8.239007949829102,
          8.565079689025879,
          8.44033432006836,
          8.694278717041016
         ],
         "y": [
          -2.5892481803894043,
          -3.201796293258667,
          -2.4813272953033447,
          -2.742488145828247,
          -1.892434000968933,
          -1.9165022373199463,
          -2.217242956161499,
          -3.169255018234253,
          -3.172572135925293,
          -3.152639865875244,
          -2.608088970184326,
          -3.0616533756256104,
          -1.8191543817520142,
          -3.026193618774414,
          -3.587738275527954,
          -3.165374755859375,
          -2.8085968494415283,
          -2.874122381210327,
          -3.1572988033294678,
          -3.107395887374878,
          -2.808803081512451,
          -2.9405078887939453,
          -2.7170801162719727,
          -2.6445531845092773,
          -3.394573211669922,
          -4.511107921600342,
          -2.776231527328491,
          -3.415682077407837,
          -3.2412803173065186,
          -3.708070993423462,
          -3.6356728076934814,
          -3.0131027698516846,
          -2.5114142894744873,
          -3.0460774898529053,
          -2.19919753074646
         ]
        },
        {
         "hoverinfo": "text",
         "hovertext": [
          "Check the data content",
          "Check the data a bit",
          "Inspection of the data.",
          "Check what the data looks like",
          "Check point 1",
          "Checking what the data looks like",
          "Inspect the data",
          "Checking the main data and the amont of data",
          "Check the data and its structure before performing any analysis",
          "Check a random sample to see all the columns",
          "Inspect the data samples.",
          "Check the data, its type and a few rows",
          " Multiple lines of code to explore and analyze the data will go here.",
          "Check data samples",
          "Checking data first.",
          " Data inspection",
          "Inspect the data files",
          "Inspect the data",
          "Inspect and verify datasests",
          "Display available data",
          "Check the data to take the appropriate action if needed",
          "Inspect the data",
          "Inspect the data",
          "Check the input data",
          "check the available data",
          "Add what data are available",
          "Data Inspection",
          "Check how the data looks like",
          "Data inspection",
          "Checking the data samples",
          "Inspect and process the data",
          "Inspect DataSource",
          "Inspect data",
          "Inspecting the data",
          "Inspecting the data..."
         ],
         "marker": {
          "opacity": 0.5,
          "size": 5
         },
         "mode": "markers+text",
         "name": "75_Data Inspection",
         "text": [
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          ""
         ],
         "textfont": {
          "size": 12
         },
         "type": "scattergl",
         "x": [
          14.47757339477539,
          14.772595405578613,
          15.1054048538208,
          14.515429496765137,
          14.477218627929688,
          14.220394134521484,
          15.32759952545166,
          14.454239845275879,
          14.679716110229492,
          10.91087818145752,
          14.776727676391602,
          11.687018394470215,
          14.459278106689453,
          14.16053295135498,
          14.889786720275879,
          14.847465515136719,
          15.249436378479004,
          15.258759498596191,
          14.834771156311035,
          14.507938385009766,
          14.184319496154785,
          15.261998176574707,
          15.356274604797363,
          14.409749984741211,
          15.207457542419434,
          15.159293174743652,
          14.771512031555176,
          15.170515060424805,
          15.042160987854004,
          13.900178909301758,
          14.46868896484375,
          15.343777656555176,
          14.845535278320312,
          14.90565299987793,
          15.376163482666016
         ],
         "y": [
          -0.4328339993953705,
          -0.1563359797000885,
          0.6629483699798584,
          0.05603447183966637,
          -0.6066752672195435,
          -0.5333916544914246,
          0.3389054536819458,
          -0.5507423877716064,
          -0.42820292711257935,
          -1.3725850582122803,
          0.28555208444595337,
          -0.7275973558425903,
          0.6515222191810608,
          -0.29032832384109497,
          -0.028097346425056458,
          0.4672733247280121,
          0.7393960356712341,
          0.08762335032224655,
          0.5938212275505066,
          -0.9614415764808655,
          0.10819603502750397,
          0.21261243522167206,
          0.44754916429519653,
          0.08557639271020889,
          -0.3414600193500519,
          -0.64189612865448,
          0.3803904950618744,
          -0.20026707649230957,
          -0.08761627227067947,
          -0.34971722960472107,
          0.5625091791152954,
          -0.1122853010892868,
          0.07116598635911942,
          -0.17818619310855865,
          0.37956953048706055
         ]
        },
        {
         "hoverinfo": "text",
         "hovertext": [
          "Split text lines into tokens using spaCy\nnlp = spacy.load('en_core_web_sm', disable=['ner', 'parser'])",
          "Create spaCy pipeline\nnlp = spacy.load('en_core_web_sm', disable=['ner', 'parser'])",
          " Optionally, ensure compatibility with spaCy by disabling components that we don't need\nnlp = spacy.load('en_core_web_sm', disable=['ner', 'parser'])",
          "define a tokenizer function using spacy\nnlp = spacy.load(\"en_core_web_sm\")\ndef spacy_tokenizer(sentence):\n    return [word.lemma_ for word in nlp(sentence) \n            if not (word.is_space or word.is_punct or word.is_stop)]",
          "# Setting up the NLP pipeline\nnlp = spacy.load(\"en_core_web_sm\", disable=[\"ner\", \"parser\"])",
          " Load pre-trained spacy word vectors\nnlp = spacy.load('en_core_web_md', disable=['tagger', 'parser', 'ner'])",
          "Parser to extract entities in a consistent manner.\nnlp = spacy.load('en_core_web_sm', disable=['ner', 'textcat'])",
          " Initialize spacy 'en' model, keeping only tagger component needed for lemmatization\nnlp = spacy.load('en', disable=['parser', 'ner'])",
          "\"\n# Set the global parameters\nglobal_params = {\n    'REPLACE_NAME': 'Nat',\n    'REPLACE_LOCATION': 'Boston',\n    'DEFAULT_SUB': 'PERSON',\n    'PLOT_FILENAME': 'nat_cloud.png',\n    'NLP_MODEL': 'en_core_web_sm',\n    'NLP_REGEX_RULE_PREFIX': '-',\n    'NLP_REGEX_RULE_INFIX': '@',\n    'POS_NAMES': ['NOUN', 'PROPN', 'ADJ']\n}",
          " Text processing tools\nnlp = spacy.load('en', disable=['parser', 'ner'])",
          " Optional: add spaCy language model for tokenization\nnlp = spacy.load('en_core_web_sm', disable=['parser', 'ner'])",
          "Create the NLP model\nnlp = spacy.load('en_core_web_sm', disable=['parser', 'ner'])",
          "Initialize spacy\nnlp = spacy.load('en_core_web_sm', disable=['parser', 'tagger', 'ner'])",
          "# Set to initial variables.\ncharacters_vocab = None\nword_to_ix = None",
          "Setup spaCy\nnlp = spacy.load('en_core_web_sm', disable=['parser', 'ner'])",
          "Tokenizer\nnlp = spacy.load('en_core_web_sm', disable=['tagger', 'parser', 'ner'])",
          "Initialization of spacy\nnlp = spacy.load('en_core_web_sm', disable=['ner', 'parser'])",
          "Setting up spaCy\n# We'll need spaCy's tokenizer and stopwords list\nnlp = spacy.load(\"en_core_web_sm\", disable=[\"tagger\", \"parser\", \"ner\"])",
          " Set up Spacy\nnlp = spacy.load('en', disable=['parser', 'tagger', 'ner'])",
          "Set up spaCy\nnlp = spacy.load('en_core_web_sm', disable=['parser', 'ner'])",
          "Setting up spaCy\nnlp = spacy.load('en_core_web_sm')\n\n# Disabling other pipes\nother_pipes = [pipe for pipe in nlp.pipe_names if pipe != 'ner']\nwith nlp.disable_pipes(*other_pipes):\n    doc = nlp(\"I am learning how to build chatbots\")\n    for ent in doc.ents:\n        print(ent.text, ent.start_char, ent.end_char, ent.label_)",
          "Install the spaCy package for text preprocessing\n# !pip install spacy\n# !python -m spacy download en_core_web_sm",
          "\n# Set up environment\nnlp = spacy.load('en_core_web_sm', disable=['parser', 'ner'])",
          "nlp = spacy.load('en_core_web_sm', disable=['parser', 'tagger', 'ner'])",
          "configure spacy\nnlp = spacy.load('en_core_web_sm',disable=['parser', 'tagger','ner'])",
          "# Disabling the tagger, parser and NER part of the pipeline. We just want to lemmatize\nnlp = spacy.load('en', disable=['tagger', 'parser', 'ner'])",
          "# Add separator for widely supported version info\n__pipeline = spacy.blank(\"en\")\n__pipeline.config[\"nlp\"][\"tokenizer\"][\"use_wildcard_tokenizer\"] = False",
          " set nlp object\nnlp = spacy.load('en', disable=['ner', 'parser'])",
          "# Text preprocessing\nnlp = spacy.load(\"en_core_web_sm\", disable=['parser', 'ner'])\n\ndef preprocess_text(text):\n    # Parsing with Spacy\n    doc = nlp(text.lower())",
          "# Global variables\nnlp = spacy.load('en_core_web_sm', disable=['parser', 'ner'])",
          "\n# Declare functions\n# Defining a function for cleaning and tokenizing the text\ndef clean_and_tokenize(text, nlp):\n    # Cleaning and parsing using SpaCy\n    text_cleaned = nlp(text)\n    return [token.lemma_ for token in text_cleaned if not token.is_punct and not token.is_stop and not token.is_space]\n\n# Defining a function for creating a bag of words\ndef create_bow(documents, nlp):\n    # Get the words from the documents\n    words = [word for document in documents for word in clean_and_tokenize(document, nlp)]\n    return Counter(words)\n\n# Load the SpaCy model\nnlp = spacy.load('en_core_web_sm')",
          "# create instance of the spacy model\nnlp = spacy.load('en_core_web_sm')\n\n# function to tokenize and clean the text\ndef preprocess_text(text):\n    # create spacy object\n    doc = nlp(text)\n    \n    # lemmatize and lowerize all the tokens\n    tokens = [token.lemma_.lower() for token in doc if not token.is_stop and token.is_alpha]\n    \n    return ' '.join(tokens)",
          "l Setup spaCy\n# print(\"Loading spaCy language model...\")\nnlp = spacy.load('en_core_web_sm', disable=['parser', 'ner'])",
          "Function that takes a list of spaCy tokens and returns a list of lemmatized strings\ndef lemmatize(token_list):\n    return [token.lemma_ for token in token_list]"
         ],
         "marker": {
          "opacity": 0.5,
          "size": 5
         },
         "mode": "markers+text",
         "name": "76_NLP Model Creation with spaCy",
         "text": [
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          ""
         ],
         "textfont": {
          "size": 12
         },
         "type": "scattergl",
         "x": [
          13.712637901306152,
          14.074933052062988,
          14.868562698364258,
          13.911666870117188,
          13.995176315307617,
          14.779809951782227,
          13.740431785583496,
          14.406482696533203,
          14.816374778747559,
          14.117419242858887,
          13.960542678833008,
          14.16884708404541,
          14.165754318237305,
          14.690145492553711,
          14.200873374938965,
          14.043462753295898,
          14.451935768127441,
          14.017735481262207,
          14.086362838745117,
          13.895566940307617,
          14.311984062194824,
          14.744114875793457,
          14.229413986206055,
          14.186121940612793,
          14.662117958068848,
          14.161456108093262,
          14.343263626098633,
          14.359224319458008,
          14.124405860900879,
          14.25960922241211,
          13.972125053405762,
          14.260988235473633,
          14.197300910949707,
          13.803922653198242
         ],
         "y": [
          7.518039226531982,
          8.143645286560059,
          8.340934753417969,
          7.15684700012207,
          8.409891128540039,
          7.9642333984375,
          8.002827644348145,
          7.986496925354004,
          8.319109916687012,
          7.946949005126953,
          7.623306751251221,
          7.936034679412842,
          8.289436340332031,
          7.582373142242432,
          8.346026420593262,
          7.705268859863281,
          8.329376220703125,
          8.013850212097168,
          7.717201232910156,
          8.048176765441895,
          8.741973876953125,
          7.16255521774292,
          8.487992286682129,
          8.041617393493652,
          7.811897277832031,
          8.157114028930664,
          7.1881608963012695,
          7.773998260498047,
          7.623091697692871,
          8.472232818603516,
          7.402298450469971,
          7.641462326049805,
          8.31015682220459,
          6.57757043838501
         ]
        },
        {
         "hoverinfo": "text",
         "hovertext": [
          "Get documents by location",
          "combine the script data with the character & location data.",
          "Merge the datasets to combine script lines with character and location information.",
          "Join the scripts with the character names and get rid of the other foreign columns.",
          "Combine the script data with the character and location information to determine where each character is mentioned.",
          "Merging the script with the character information",
          " Create a DataFrame that retrieves the main details about each script line as well as the character and location names.",
          " Join the tables such that we can have character and location information in the script table.",
          "Parse locations, characters and scripts",
          "Splitting the script into lines and joining with characters and locations",
          "Preprocess character names to standardize them for later integration with the script data.",
          "Merge the characters and script lines tables on the character_id key and reindex the resulting table.",
          "Create dataset of main character lines and locations from the script data",
          "Save scripts for each character",
          "Joining the character names to the script and drop those which are not known",
          "define the structure of the two tables containing the script and the characters involved.",
          "Merge the script lines with the corresponding characters and locations",
          "Characters and lines in script are in the same table, while the locations are separate.",
          " Merge characters/locations to script (using joins)",
          "Merge the script with characters and locations",
          " Merge data for better databasing - we will merge script and character/location databases",
          "Merge Locations and Script datasets to get the location of each scene",
          "Merge the script lines with character and location information",
          "Merge lines of the script with the characters and the locations",
          "Merge the script data with the character and location data to add character and location information to each line in the script.",
          "Merge the script with the characters (to retrieve the character names)",
          " For simple scripts such as the one below, how do we represent the lines of the next script across the known characters_data?",
          "\n# Add the content of the script to the corresponding characters and locations\n",
          "Find the script lines that reference locations.",
          "Combine the script with character names",
          "Merge the script data with the characters and locations data for better interpretability.",
          "Build an inverted index by character and by location using the script lines data.",
          "Merge the scripts and the characters' databases",
          "How to normalize the character names (lowercase, remove symbols, etc.) when working with the script data."
         ],
         "marker": {
          "opacity": 0.5,
          "size": 5
         },
         "mode": "markers+text",
         "name": "77_Merging script lines with character and location information",
         "text": [
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          ""
         ],
         "textfont": {
          "size": 12
         },
         "type": "scattergl",
         "x": [
          9.087021827697754,
          9.411465644836426,
          9.093790054321289,
          9.940622329711914,
          9.620594024658203,
          9.487531661987305,
          9.117963790893555,
          9.184000968933105,
          9.48613452911377,
          10.35677433013916,
          10.051877975463867,
          9.758857727050781,
          9.529073715209961,
          9.542470932006836,
          9.957559585571289,
          9.53803825378418,
          9.696166038513184,
          9.675581932067871,
          9.468500137329102,
          9.600967407226562,
          9.185218811035156,
          8.765183448791504,
          9.853632926940918,
          9.859643936157227,
          9.272672653198242,
          9.616833686828613,
          9.785211563110352,
          9.943909645080566,
          9.041754722595215,
          9.561434745788574,
          9.240269660949707,
          9.811113357543945,
          9.401066780090332,
          9.763077735900879
         ],
         "y": [
          5.29434061050415,
          4.338829517364502,
          3.4070186614990234,
          4.368606090545654,
          4.771373748779297,
          3.7961952686309814,
          3.741865396499634,
          4.153902053833008,
          4.5753679275512695,
          4.18886137008667,
          4.360902786254883,
          3.6962194442749023,
          4.441059589385986,
          3.91076922416687,
          4.729485034942627,
          3.9688382148742676,
          3.757607936859131,
          4.432345867156982,
          3.576917886734009,
          3.800318956375122,
          3.1301608085632324,
          2.8304355144500732,
          3.89190936088562,
          3.754812479019165,
          3.917649269104004,
          4.158411502838135,
          4.655673503875732,
          4.085212230682373,
          4.29032564163208,
          4.066328048706055,
          4.202014446258545,
          4.063683986663818,
          3.3784849643707275,
          4.738471984863281
         ]
        },
        {
         "hoverinfo": "text",
         "hovertext": [
          " Set Seed to Reproduce Results\nseed = 42",
          "Set seed for reproducibility",
          "Set a seed for reproducibility",
          " Set the random seed for reproducibility",
          "# Set random state\nSEED = 42",
          "Set the seed for reproducibility.",
          " Set the seed for reproducibility",
          "Set the seed for reproducibility",
          "Set seed for reproducibility",
          "Set the global seed for reproducibility",
          "Set the seed for reproducing the results",
          "Recommended: set a fixed seed for reproducibility in pyspark.",
          "Set SEED for reproducibility\nSEED = 42",
          " Set SEED for reproducibility\nSEED = 42",
          " Set a seed for reproducibility",
          "Set a seed for reproducibility",
          "Setting the seed for reproducability",
          " Optional: set seed for reproducibility\nseed = 42",
          "Set the seed for reproducibility",
          "Define a seed for reproducibility.",
          "Set the seed for reproducibility",
          "Set a seed for reproducibility",
          "Set a seed for reproducibility.",
          "Global variables\nSEED = 42",
          "Set seeding for reproducibility",
          "Set seed for reproducibility",
          "Set the seed for reproducibility",
          "Set a seed for reproducibility",
          " Set a seed for reproducibility",
          "Setting seed for reproducibility\nseed = 123",
          " Set a seed for reproducibility",
          "We should also set the random seed for reproducibility.",
          "Set seed for reproducibility",
          "Set a seed for reproducibility"
         ],
         "marker": {
          "opacity": 0.5,
          "size": 5
         },
         "mode": "markers+text",
         "name": "78_Set seed for reproducibility",
         "text": [
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          ""
         ],
         "textfont": {
          "size": 12
         },
         "type": "scattergl",
         "x": [
          29.88882827758789,
          30.48980712890625,
          30.567218780517578,
          30.859146118164062,
          29.97127914428711,
          30.949337005615234,
          30.76685333251953,
          30.650543212890625,
          30.506813049316406,
          30.81772804260254,
          30.329721450805664,
          30.91193389892578,
          30.08548927307129,
          30.099632263183594,
          30.416086196899414,
          30.851806640625,
          30.677438735961914,
          30.13934326171875,
          30.53650665283203,
          30.68409538269043,
          30.613019943237305,
          30.338459014892578,
          30.75348663330078,
          29.38602066040039,
          30.266124725341797,
          30.44319725036621,
          30.841590881347656,
          30.792694091796875,
          30.54951286315918,
          30.438169479370117,
          30.896791458129883,
          30.89623260498047,
          30.710186004638672,
          30.5303897857666
         ],
         "y": [
          10.442427635192871,
          9.201745986938477,
          9.679695129394531,
          10.9758939743042,
          10.995898246765137,
          10.04773235321045,
          10.0509614944458,
          10.179848670959473,
          9.250494956970215,
          10.279848098754883,
          10.28048038482666,
          9.844923973083496,
          10.37459659576416,
          10.465076446533203,
          9.511488914489746,
          9.414594650268555,
          9.940595626831055,
          10.155457496643066,
          10.108765602111816,
          9.285221099853516,
          10.137129783630371,
          9.606194496154785,
          9.837078094482422,
          10.294355392456055,
          9.111503601074219,
          9.476110458374023,
          10.211893081665039,
          9.65097427368164,
          9.538825988769531,
          10.477869987487793,
          9.751089096069336,
          10.381739616394043,
          9.170452117919922,
          9.842508316040039
         ]
        },
        {
         "hoverinfo": "text",
         "hovertext": [
          "Merge characters(2) and locations(2) to the script DataFrame, so that every line is associated with a character and a location.",
          " Join the characters and script dataframes with the script data.",
          "Select the character names and the raw lines from the script data frame and join with the characters data frame to get the characters' gender.",
          "Add character name to script lines dataframe",
          "Mergeing characters and locations dataframe to script line so that we have the character and location for each line",
          "Convert the \"2 of 3\" designed datasets (name of characters and locations) in dataframes into sets for a better handling",
          "Merge information for characters and locations with the script dataframe",
          "Reduce characters and script dataframe to relevant size",
          "Generate a dataframe containing script lines with the character and location names.",
          " Names of the columns in the dataframe of characters",
          " Clean and process the character and raw script dataframes",
          "Some of the character names are in lowercase in the script, while they are in uppercase in the characters DataFrame. Let's convert all names to lowercase for consistency.",
          "Merge the characters, locations, and script dataframes to create a master dataframe",
          "Join characters, locations, and scripts into a single dataframe for simplicity",
          " Merge the datasets to include the names of the characters and locations in the script DataFrame for better analysis.",
          "Merge the information of the script, characters, and locations into one dataframe for easy access.",
          "Merging the script lines with the characters and locations DataFrames for better readability and analysis.",
          "Creating a single df with characters and locations",
          "Merge the characters and script dataframes",
          " Perform a naive join between script and characters, this will allow us to include the character information with each row in the dataframe.",
          "Create a column representing the full names of the characters in the script dataframe.",
          "Joining character and location names to the main script dataframe",
          "Create a new DataFrame with the main characters and their gender and the script line text",
          "Separate script lines dataframe into lines by character, and save lines as text files",
          "concatenate locations and script dataframes",
          "Merge characters and location information into the script dataframe",
          "Join the location of each line using locations.csv and export to csv",
          "Create dummy variables for the characters lines' in the script dataframe",
          "For this example, we will only use the 'name' column of the 'characters' Dataframe and the 'raw_text' column of the 'script' Dataframe.",
          " Add an additional column to the script dataframe which holds the character name.",
          "Sort alignments into character-based dataframes, and write to csv",
          "Merge the scripts, characters, and locations in a single dataframe.",
          "Add a \"name\" column to the characters and locations dataframe for merging convenience"
         ],
         "marker": {
          "opacity": 0.5,
          "size": 5
         },
         "mode": "markers+text",
         "name": "79_Merging character and location information into script dataframe",
         "text": [
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          ""
         ],
         "textfont": {
          "size": 12
         },
         "type": "scattergl",
         "x": [
          7.449080944061279,
          8.076681137084961,
          8.028572082519531,
          7.226657390594482,
          8.180720329284668,
          7.981646537780762,
          7.903458118438721,
          6.822743892669678,
          8.325915336608887,
          8.612908363342285,
          7.559965133666992,
          7.563356399536133,
          7.252801895141602,
          7.431761264801025,
          8.311171531677246,
          8.082427024841309,
          8.448230743408203,
          6.279619216918945,
          7.313492774963379,
          7.891541481018066,
          7.947711944580078,
          7.857019901275635,
          6.703791618347168,
          7.544699668884277,
          7.610719680786133,
          7.816886901855469,
          9.154695510864258,
          7.346680164337158,
          7.367929935455322,
          7.903077125549316,
          7.530174732208252,
          7.408890247344971,
          7.903390407562256
         ],
         "y": [
          4.021371364593506,
          3.6692097187042236,
          7.084130764007568,
          5.127600193023682,
          3.831630229949951,
          2.505190849304199,
          3.098853826522827,
          2.1212849617004395,
          4.0282697677612305,
          4.130286693572998,
          2.02778697013855,
          5.877852916717529,
          3.2331395149230957,
          3.2027440071105957,
          3.164034605026245,
          2.3654890060424805,
          2.971980333328247,
          10.55276870727539,
          2.662395715713501,
          4.8476481437683105,
          4.707028388977051,
          3.3534817695617676,
          6.434786319732666,
          4.725803375244141,
          3.154661178588867,
          3.0385007858276367,
          3.741532325744629,
          5.3833489418029785,
          5.671769142150879,
          5.356980800628662,
          2.4694571495056152,
          2.737700939178467,
          3.6102848052978516
         ]
        },
        {
         "hoverinfo": "text",
         "hovertext": [
          "df_script.info()",
          "A quick look at what the script df looks like",
          "# I realized that df_script is very large, so let's free up some memory\ndel df_script",
          "View dataframe information\ndf_script.info()",
          "Display the general information of the script\ndf_script.info()",
          " Enforce typing for `df_script` for an `integer` index",
          "Inspect script line data\ndf_script.info()",
          "Parse the csv\ndf_script.info()",
          "Display the dataframe and data types of each column\ndf_script.info()",
          "Chaging paths in df_script table",
          "\ndf_script.shape",
          "df_script.shape",
          "df_script with some cleaning",
          "What is the shape of the scripts dataframe?\ndf_script.shape",
          "df_script.shape",
          "Show info/\ndf_script.info()",
          "View dataframe info\ndf_script.info()",
          "View dataframe info\ndf_script.info()",
          "Remove the first four columns from  `df_script` since they are redundant.",
          " Display information about the script dataset\ndf_script.info()",
          "View DataFrame information\ndf_script.info()",
          "Basic info on df_script\nprint(df_script.info())",
          "Display the dataframe info to understand its structure and columns\ndf_script.info()",
          "df_script.info()",
          " df_script.info()",
          "Display basic info about the script dataframe\ndf_script.info()",
          "df_script",
          "Gather info on df_script",
          " Show the DataFrame columns, non-null count, data type and memory usage\ndf_script.info()",
          "View the dataframe columns and data types\nprint(df_script.info())",
          "Apply `Contract` and `df_script` dataframes",
          " Print schema\nprint(df_script.dtypes)",
          "df_script"
         ],
         "marker": {
          "opacity": 0.5,
          "size": 5
         },
         "mode": "markers+text",
         "name": "80_Viewing DataFrame Information with df_script.info()",
         "text": [
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          ""
         ],
         "textfont": {
          "size": 12
         },
         "type": "scattergl",
         "x": [
          6.4632439613342285,
          6.1798601150512695,
          7.786293029785156,
          6.946784973144531,
          6.424148082733154,
          6.5475969314575195,
          5.934631824493408,
          6.4147233963012695,
          7.342039585113525,
          6.95847225189209,
          5.4220476150512695,
          5.542842864990234,
          7.235498905181885,
          5.277689456939697,
          5.295881271362305,
          6.421877384185791,
          6.801224231719971,
          6.807892799377441,
          7.507466793060303,
          6.406448841094971,
          6.847883224487305,
          6.664882659912109,
          7.25312614440918,
          6.125986576080322,
          6.403055191040039,
          7.119863510131836,
          6.660174369812012,
          6.082752227783203,
          6.856935501098633,
          6.739634990692139,
          7.033949375152588,
          7.00176477432251,
          6.767521858215332
         ],
         "y": [
          -2.1710052490234375,
          -2.2868998050689697,
          -1.6089210510253906,
          -2.273883819580078,
          -2.4183273315429688,
          -0.8704093098640442,
          -2.545106887817383,
          -2.08969783782959,
          -2.0184168815612793,
          -1.5877779722213745,
          -2.128291130065918,
          -2.2998974323272705,
          -0.7963678240776062,
          -2.5661416053771973,
          -2.1352696418762207,
          -2.031041383743286,
          -2.5501084327697754,
          -2.2810797691345215,
          -1.045294165611267,
          -2.703740358352661,
          -2.399578094482422,
          -2.3953793048858643,
          -2.446377992630005,
          -2.247683048248291,
          -1.9783600568771362,
          -2.6507856845855713,
          -1.9186046123504639,
          -2.571802854537964,
          -2.1018435955047607,
          -2.0484113693237305,
          -2.6048269271850586,
          -1.9776467084884644,
          -1.8448253870010376
         ]
        },
        {
         "hoverinfo": "text",
         "hovertext": [
          "Inspecting the structure of each table",
          "Sanity check on the tables",
          " La structure des données est à présent chargée.",
          "Printing out the Structure of the tables",
          "Inspect the structure of each table",
          "Inspect the table schema",
          " Let's take a look at each table to understand its structure and content.",
          "Explore the content of each table to understand what they contain.",
          "Let's take a look at the schema of these tables.",
          "Let's print the tables on the notebook to inspect them.",
          "Let's see what's inside each data table.",
          "Let's print the first couple of lines of each of these tables to see what we're working with.",
          "there are 27 tables, most related will be:\n#   (label, brightness, contrast, homogen_datatype)",
          "Let's preview each table to understand the data we're working with.",
          " Now let's see the structure of each table to better understand the data.",
          "Inspect the tables' heads",
          "Let's take a look at a few lines from each table to understand its structure.",
          "Check how the tables look like",
          "A sample of the data tables.",
          "Redimensionnement de la table `Locations`",
          "Let's see what these tables look like.",
          " Take a look at the first few rows of each table",
          "Inspect the data for each table",
          "Display the first record of each table to understand the data",
          "Checking the structure of this table.",
          "Read one example of each table",
          "Check the content of all tables to see if everything is consistent",
          "Inspect the table schemas and dtypes to determine how to perform joins between tables.",
          "Show sample of tables",
          "Inspect collected tables and preview elements",
          "Let's see the content of each table.",
          "Let's take a quick look at the structure of these tables",
          "Check the head of the table to get an idea of the table schemata"
         ],
         "marker": {
          "opacity": 0.5,
          "size": 5
         },
         "mode": "markers+text",
         "name": "81_Data Table Inspection and Structure Analysis",
         "text": [
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          ""
         ],
         "textfont": {
          "size": 12
         },
         "type": "scattergl",
         "x": [
          13.239872932434082,
          13.71512222290039,
          12.719456672668457,
          13.269515991210938,
          13.043038368225098,
          13.555951118469238,
          13.389208793640137,
          13.217522621154785,
          13.771236419677734,
          13.72839641571045,
          14.365307807922363,
          13.452657699584961,
          14.062822341918945,
          13.894010543823242,
          13.826559066772461,
          13.517143249511719,
          13.32589054107666,
          13.360347747802734,
          13.76303768157959,
          13.538129806518555,
          13.591842651367188,
          13.311129570007324,
          13.290037155151367,
          12.890518188476562,
          13.194561004638672,
          13.031949043273926,
          13.793078422546387,
          13.460588455200195,
          12.813446044921875,
          13.478028297424316,
          13.46566390991211,
          13.39826774597168,
          13.192498207092285
         ],
         "y": [
          -0.9994205236434937,
          -0.318936288356781,
          2.5217695236206055,
          -1.623113989830017,
          -1.0423425436019897,
          -1.1288443803787231,
          -1.310187578201294,
          -1.29691481590271,
          -1.3487908840179443,
          -0.615664541721344,
          -1.7432339191436768,
          -1.1589140892028809,
          -1.8203752040863037,
          -1.431296944618225,
          -1.343661904335022,
          -1.0465927124023438,
          -1.4284371137619019,
          -0.8312987685203552,
          -1.9045583009719849,
          -0.39826008677482605,
          -1.1368540525436401,
          -1.9645227193832397,
          -1.401178002357483,
          -2.523318290710449,
          -0.7827089428901672,
          -1.2167576551437378,
          -0.25301438570022583,
          -1.573307991027832,
          -1.8497980833053589,
          -1.1543899774551392,
          -1.2218939065933228,
          -1.0694162845611572,
          -1.1464910507202148
         ]
        },
        {
         "hoverinfo": "text",
         "hovertext": [
          " Display the first few rows of the dataframe\ndf_script.head()",
          " Display the first few rows of the dataframe for inspection\ndf_script.head()",
          "Display the first few rows of the dataframe\ndf_script.head()",
          " Display the first few rows of the dataframe\ndf_script.head()",
          " Display the first few columns of the dataframe\ndf_script.head()",
          "# Display first few rows of the dataframe\ndf_script.head()",
          " Display the first few rows of the dataframe\ndf_script.head()",
          " Display the first few rows of the dataframe\ndf_script.head()",
          " Display the first few rows of the dataframe\ndf_script.head()",
          "Display the first few rows of the dataframe\ndf_script.head()",
          " Display the first few rows of the dataframe\ndf_script.head()",
          "Using the `head` function to display the first few rows of the dataframe.",
          " Display the first few rows of the dataframe\ndf_script.head()",
          "Display the first few rows of the dataframe\ndf_script.head()",
          "Display the first few rows of the dataframe\ndf_script.head()",
          " Display the first few rows of the dataframe\ndf_script.head()",
          "Display the first few rows of the dataframe\ndf_script.head()",
          " Display first few rows of the dataframe to understand the data better.\ndf_script.head()",
          " Display the first few cells of the dataframe\ndf_script.head()",
          " Display the first few rows of the dataframe\ndf_script.head()",
          " Display the first few rows of the dataframe\ndf_script.head()",
          "Display the first few rows of the dataframe\ndf_script.head()",
          "Display the first few rows of the dataframe for inspection\ndf_script.head()",
          "Display first few rows of the dataframe\ndf_script.head()",
          "Display the first few rows of the dataframe\ndf_script.head()",
          " Display the first few rows of the dataframe\ndf_script.head()",
          "Display the first few rows of the dataframe\ndf_script.head()",
          "Display the first few rows of the dataframe\ndf_script.head()",
          " Display the first few rows of the dataframe\ndf_script.head()",
          "Display the first few rows of the dataframe\ndf_script.head()",
          "Display first few rows of the dataframe\ndf_script.head()",
          "# Display the first few rows of the dataframe\ndf_script.head()",
          "Display the first few rows of the dataframe\ndf_script.head()"
         ],
         "marker": {
          "opacity": 0.5,
          "size": 5
         },
         "mode": "markers+text",
         "name": "82_Displaying first few rows of a dataframe for inspection",
         "text": [
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          ""
         ],
         "textfont": {
          "size": 12
         },
         "type": "scattergl",
         "x": [
          2.7635061740875244,
          2.6113362312316895,
          2.62290620803833,
          2.94160532951355,
          2.5354056358337402,
          2.374073028564453,
          2.6658525466918945,
          2.6670289039611816,
          2.65482497215271,
          2.952667236328125,
          2.808898687362671,
          3.131113290786743,
          2.609163522720337,
          2.627300500869751,
          2.581435203552246,
          2.830073595046997,
          2.6058778762817383,
          2.7061729431152344,
          3.0018043518066406,
          2.5633301734924316,
          2.510190725326538,
          2.4447498321533203,
          2.598755359649658,
          2.4727888107299805,
          2.164726972579956,
          2.466344118118286,
          2.4011547565460205,
          2.795971393585205,
          2.220950126647949,
          2.2609381675720215,
          2.41330623626709,
          2.5843443870544434,
          2.627669334411621
         ],
         "y": [
          -9.215170860290527,
          -9.057024955749512,
          -9.27488899230957,
          -9.18947696685791,
          -8.510449409484863,
          -8.983591079711914,
          -9.73569393157959,
          -9.692481994628906,
          -9.701557159423828,
          -9.332051277160645,
          -9.383618354797363,
          -9.025899887084961,
          -9.390061378479004,
          -9.382649421691895,
          -9.631143569946289,
          -9.90355110168457,
          -9.418619155883789,
          -8.117258071899414,
          -9.68333911895752,
          -9.611658096313477,
          -9.463418006896973,
          -9.33251953125,
          -9.246129989624023,
          -8.957252502441406,
          -9.408262252807617,
          -9.373417854309082,
          -9.44393253326416,
          -9.641417503356934,
          -9.67042350769043,
          -9.747932434082031,
          -8.788442611694336,
          -8.889748573303223,
          -9.484675407409668
         ]
        },
        {
         "hoverinfo": "text",
         "hovertext": [
          "Display the head of the characters dataframe\ndf_characters.head()",
          "Inspect and display the head of the characters dataframe\ndf_characters.head()",
          " Display head of characters table\ndf_characters.head()",
          "display(df_characters.head(3))",
          "Display the head of the characters dataframe to understand its structure\ndf_characters.head()",
          "Display the head of each dataframe to understand what's in the dataset\nprint(\"Characters dataframe:\")\ndisplay(df_characters.head())",
          " Display the head of the characters dataframe\ndf_characters.head()",
          "Display the head of the characters dataframe\ndf_characters.head()",
          " Display dataframes\ndf_characters.head()",
          "Display head of character dataframe\ndf_characters.head()",
          "Display the header of the characters DataFrame\ndf_characters.head()",
          "Display sizes\ndf_characters.head()",
          "Display the dataframes\ndf_characters.head()",
          " Visualize head of the characters dataframe\ndf_characters.head()",
          "Display\ndf_characters.head()",
          " display dataframe\ndf_characters.head()",
          " Display the head of the characters dataframe\ndf_characters.head()",
          " Display df_characters head",
          "Displaying the head of the DataFrame characters\ndf_characters.head()",
          "Display dataframe 'df_characters'\ndf_characters.head()",
          " Display the head of the characters DataFrame\ndf_characters.head()",
          "Display the head of the characters dataframe\ndf_characters.head()",
          " Display the head of the characters dataframe\ndf_characters.head()",
          "Display the head of the DataFrame df_characters\ndf_characters.head()",
          " Display the DataFrame to make sure the conversion looks good.\ndf_characters.head()",
          " Display dataframe headers\ndf_characters.head()",
          " Displaying the head of the characters dataframe\ndf_characters.head()",
          "# Show a bit of the df_characters dataframe\ndf_characters.head()",
          "\n# Display head of the characters DataFrame\ndf_characters.head()",
          " Visualizng dataframes with `head()` will print nicely as tables in Jupyter\ndf_characters.head()",
          " Display the character dataframe\ndf_characters.head(3)",
          " Show how the DataFrame df_characters looks like\ndf_characters.head()",
          " Display the head of the characters dataframe\ndf_characters.head()"
         ],
         "marker": {
          "opacity": 0.5,
          "size": 5
         },
         "mode": "markers+text",
         "name": "83_Displaying and Visualizing Data with df_characters.head()",
         "text": [
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          ""
         ],
         "textfont": {
          "size": 12
         },
         "type": "scattergl",
         "x": [
          6.676629543304443,
          6.8439507484436035,
          6.912802219390869,
          6.0152153968811035,
          6.5582733154296875,
          5.768374919891357,
          6.413740634918213,
          6.564698219299316,
          5.811235427856445,
          6.626692295074463,
          6.491819858551025,
          6.209475994110107,
          5.845520973205566,
          6.4534382820129395,
          6.364377498626709,
          5.913095474243164,
          6.373362064361572,
          6.624331951141357,
          6.241811275482178,
          5.579162120819092,
          6.455739498138428,
          6.260459899902344,
          6.707291603088379,
          6.079246520996094,
          5.618868350982666,
          5.931694984436035,
          6.618053436279297,
          6.1235127449035645,
          6.545167922973633,
          4.5456061363220215,
          5.813880443572998,
          5.7409772872924805,
          6.478457450866699
         ],
         "y": [
          18.07135772705078,
          17.455846786499023,
          17.51514434814453,
          16.6712703704834,
          16.688627243041992,
          16.573171615600586,
          17.70240592956543,
          18.061519622802734,
          17.23711585998535,
          17.933202743530273,
          17.439998626708984,
          16.532726287841797,
          17.186906814575195,
          16.844024658203125,
          17.115697860717773,
          17.27257537841797,
          17.984025955200195,
          17.130889892578125,
          17.520172119140625,
          17.13848876953125,
          17.860445022583008,
          17.933691024780273,
          17.682815551757812,
          17.67650604248047,
          16.697086334228516,
          17.375957489013672,
          17.63776969909668,
          16.88197135925293,
          17.48505973815918,
          17.431407928466797,
          17.081390380859375,
          16.8292179107666,
          17.833251953125
         ]
        },
        {
         "hoverinfo": "text",
         "hovertext": [
          "Preview the characters dataframe\ndf_characters.head()",
          "Preview the characters dataframe\ndf_characters.head()",
          "Preview the character dataframe\ndf_characters.head()",
          "Show a preview of the characters dataframe\ndf_characters.head()",
          " Preview the characters dataframe\ndf_characters.head()",
          "Preview all DataFrames\nprint('Characters DataFrame shape:', df_characters.shape)\ndf_characters.head()",
          "Preview the characters dataframe\ndf_characters.head()",
          " Preview the characters dataframe\ndf_characters.head()",
          "Preview dataframe with characters",
          "Preview the characters dataframe\ndf_characters.head()",
          "Preview the characters dataframe\ndf_characters.head()",
          " Preview the \"characters\" DataFrame",
          "Preview the dataframes\ndf_characters.head()",
          "Preview the dataframes\ndf_characters.head()",
          "A preview of the first dataframe\ndf_characters.head()",
          "Preview the characters dataframe\ndf_characters.head()",
          "Preview the characters dataframe\ndf_characters.head()",
          "Preview the characters DataFrame\ndf_characters.head()",
          "Preview the characters dataframe\ndf_characters.head()",
          "Previewing the characters dataframe",
          "Preview the characters dataframe\ndf_characters.head()",
          "Preview the characters dataframe\ndf_characters.head()",
          "Preview of the characters dataframe\ndf_characters.head()",
          "Preview the characters dataframe\ndf_characters.head()",
          "Preview the dataframes\ndf_characters.head()",
          "Preview the characters dataframe",
          " Preview the characters dataframe\ndf_characters.head()",
          "Preview dataframes\ndf_characters.head()",
          "Preview the characters dataframe\ndf_characters.head()",
          "Display a preview of the characters DataFrame\ndf_characters.head()",
          "Preview the characters dataframe\ndf_characters.head()",
          "Get a preview of the df_characters dataframe\ndf_characters.head()"
         ],
         "marker": {
          "opacity": 0.5,
          "size": 5
         },
         "mode": "markers+text",
         "name": "84_Previewing characters dataframe",
         "text": [
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          ""
         ],
         "textfont": {
          "size": 12
         },
         "type": "scattergl",
         "x": [
          10.99124526977539,
          11.219799995422363,
          10.838188171386719,
          11.21875286102295,
          11.076668739318848,
          11.082854270935059,
          10.879049301147461,
          10.643820762634277,
          1.8600963354110718,
          11.001108169555664,
          10.85493278503418,
          1.9272032976150513,
          11.264578819274902,
          11.283699035644531,
          11.613411903381348,
          11.157147407531738,
          10.767996788024902,
          11.0277738571167,
          11.26252269744873,
          2.2309370040893555,
          10.976332664489746,
          10.791021347045898,
          11.29644775390625,
          10.893956184387207,
          11.313627243041992,
          2.008113145828247,
          10.7728910446167,
          11.4656400680542,
          11.278440475463867,
          11.491013526916504,
          11.115241050720215,
          10.964302062988281
         ],
         "y": [
          23.702638626098633,
          23.441120147705078,
          23.570072174072266,
          23.31835174560547,
          23.615219116210938,
          22.261743545532227,
          23.422391891479492,
          23.43815803527832,
          13.32519817352295,
          23.317401885986328,
          23.646953582763672,
          13.730624198913574,
          22.54891014099121,
          22.57936668395996,
          22.633668899536133,
          23.564573287963867,
          23.657934188842773,
          23.351980209350586,
          23.46044158935547,
          13.433771133422852,
          23.47669792175293,
          23.748666763305664,
          23.213891983032227,
          23.41613006591797,
          22.53155517578125,
          13.338483810424805,
          23.797975540161133,
          22.70286750793457,
          23.941604614257812,
          23.30008316040039,
          23.603435516357422,
          23.02193832397461
         ]
        },
        {
         "hoverinfo": "text",
         "hovertext": [
          "Drop unnecessary columns\ndf_characters = df_characters.drop(columns=['image_url'])\ndf_locations = df_locations.drop(columns=['image_url'])\ndf_episodes = df_episodes.drop(columns=['image_url'])",
          " Check for any null values and drop if any\ndf_characters = df_characters.dropna()\ndf_locations = df_locations.dropna()\ndf_script = df_script.dropna()\ndf_episodes = df_episodes.dropna()",
          "Drop unnecessary columns to save memory\ndf_script.drop(columns=['align', 'raw_text', 'timestamp_in_ms', 'speaking_line', 'character_image_url', 'episode_id', 'location_id', 'production_code', 'original_air_year', 'id'], inplace=True)",
          "Remove episodes that have no information about writers, \n# directors or production codes, since this information is necessary for further steps\ndf_episodes.dropna(subset=['writer', 'director', 'production_code'], inplace=True)",
          "Do initial exploration of the data\ndf_script = df_script.drop(columns=['index', 'id', 'image_id', 'raw_text'])\nprint(df_script.head())\nprint('\\nNumber of dialogues: {}'.format(df_script.shape[0]))",
          " Drop any missing values in these important fields\nprint(df_script.shape)\ndf_script = df_script.dropna(subset=['episode_id', 'character_id', 'raw_text'])\nprint(df_script.shape)",
          "drop the first 3 (out of 27) columns as they are not useful: id, episode_id and number",
          " Drop unnecessary columns from characters and locations\ndf_characters.drop(columns=['normalized_name', 'voice_actor_id', 'image_url', 'slug', 'gender', 'celeb_id', 'start_int', 'end_int', 'credit_id'], inplace=True)\ndf_locations.drop(columns=['image_url', 'slug'], inplace=True)",
          "Delete first column (index) and unnecessary columns\ndf_script = df_script.drop(columns=['id', 'episode_id', 'number', 'raw_text'])",
          "# Remove empty episodes in script\ndf_script = df_script.dropna(subset=['episode_id'])",
          "Remove useless columns for this script\ndf_script.drop(['id', 'episode_id', 'number'], axis=1, inplace=True)",
          "Remove unnecessary columns\ndf_characters.drop(columns=['id', 'image_url', 'imdb_url'], inplace=True)\ndf_locations.drop(columns=['id'], inplace=True)\ndf_script.drop(columns=['id', 'episode_id', 'number', 'raw_text', 'timestamp_in_ms'], inplace=True)\ndf_episodes.drop(columns=['id', 'image_url', 'video_url', 'imdb_url', 'production_code'], inplace=True)",
          "Remove the rows with no locations\ndf_script_dropped = df_script.dropna(subset=['raw_location_text'])\n\n# Split the data - to remove this step, replace dfs with df_script\ndfs = {\n    'simpsons_characters': df_characters,\n    'simpsons_locations': df_locations,\n    'simpsons_script_lines': df_script_dropped,\n    'simpsons_episodes': df_episodes\n}",
          "Remove unwanted columns\ndf_script = df_script.drop(columns=['id', 'episode_id', 'number', 'raw_text', 'timestamp_in_ms', 'speaking_line', 'character_id', 'location_id', 'raw_character_text', 'raw_location_text', 'normalized_text'])",
          "# Remove unnecessary numeric columns\ndf_characters = df_characters.drop(columns=['id'])\ndf_locations = df_locations.drop(columns=['id'])\ndf_script = df_script.drop(columns=['id', 'episode_id', 'number', 'raw_text','timestamp_in_ms'])\ndf_episodes = df_episodes.drop(columns=['id'])",
          "Drop unnecessary column\ndf_script.drop(columns=['id', 'episode_id', 'number'], inplace=True)",
          "df_script = df_script.drop(['id', 'episode_id', 'number', 'raw_text'], axis=1)",
          " Remove invalid entries from the script\ndf_script_valid = df_script.dropna(subset=['raw_text'])\n\n# Convert seasons to integers, removing any trailing and leading whitespace\ndf_episodes['season'] = df_episodes['season'].str.strip().astype(int)",
          "Remove unwanted columns from the dataframes\ndf_characters.drop(['raw_character_text', 'raw_location_text', 'spoken_words'], axis=1, inplace=True)\ndf_locations.drop(['normalized_text'], axis=1, inplace=True)\ndf_script.drop(['timestamp_in_ms', 'speaking_line', 'character_id', 'episode_id', 'location_id', 'raw_text'], axis=1, inplace=True)\ndf_episodes.drop(['image_url'], axis=1, inplace=True)",
          " Remove 'overseas_episode_production_code' column\ndf_episodes.drop(['overseas_episode_production_code'], axis=1, inplace=True)",
          "Drop unused columns\ndf_characters = df_characters.drop(columns=['id'])\ndf_locations = df_locations.drop(columns=['id'])\ndf_script = df_script.drop(columns=['id', 'timestamp_in_ms', 'speaking_line', 'character_id', 'location_id', 'raw_text'])\n\n# Print the DataFrame shape\nprint(df_characters.shape)\nprint(df_locations.shape)\nprint(df_script.shape)\nprint(df_episodes.shape)",
          " Set the missing episode in df_characters DataFrame",
          " Remove unwanted columns\ndf_script.drop(columns=['id', 'episode_id', 'number'], inplace=True)",
          "Remove non-essential columns\ndf_script = df_script.drop(columns=['id', 'episode_id', 'number', 'raw_text', 'timestamp_in_ms'])",
          "Drop columns that are not necessary for this particular analysis:\ndf_episodes.drop(['original_air_year', 'production_code', 'thumbnail_address', 'video_address'], axis=1, inplace=True)\ndf_script.drop(['number', 'raw_text', 'timestamp_in_ms', 'speaking_line', 'character_image_url', 'location_id', 'raw_character_text', 'raw_location_text', 'spoken_words', 'normalized_text'], axis=1, inplace=True)\ndf_locations.drop(['number', 'image_url', 'modification_date', 'special'], axis=1, inplace=True)\ndf_characters.drop(['number', 'image_url', 'gender', 'hair', 'modification_date', 'imdb_url'], axis=1, inplace=True)",
          "Remove unwanted columns\ndf_script = df_script.drop(columns=['id', 'episode_id'])",
          "Remove unnecessary columns from dfs\ndf_characters = df_characters.drop(columns=['id'])\ndf_locations = df_locations.drop(columns=['id'])\ndf_script = df_script.drop(columns=['id', 'number', 'raw_text', 'timestamp_in_ms', 'speaking_line', 'character_id', 'location_id', 'production_code', 'original_air_date'])\ndf_episodes = df_episodes.drop(columns=['id', 'image_url', 'video_url'])",
          " Remove all lines with missing values in the following columns\ncolumns_to_clean = ['episode_id', 'number', 'raw_text']\n\ndf_script = df_script.dropna(subset=columns_to_clean)",
          "Dropping lines that have not been assigned to an episode\ndf_script = df_script.dropna(subset=['episode_id'])",
          "Drop rows with missing values\ndf_characters = df_characters.dropna(subset=['name'])\ndf_locations = df_locations.dropna(subset=['name'])\ndf_script = df_script.dropna(subset=['raw_text', 'character_id', 'location_id', 'episode_id'])\ndf_episodes = df_episodes.dropna(subset=['title'])",
          " Remove unwanted columns from the dataframes\ncolumns_to_drop = ['id', 'number', 'raw_text', 'timestamp_in_ms']\n\ndf_characters.drop(columns=columns_to_drop, inplace=True, errors='ignore')\ndf_locations.drop(columns=columns_to_drop, inplace=True, errors='ignore')\ndf_script.drop(columns=columns_to_drop, inplace=True, errors='ignore')\ndf_episodes.drop(columns=columns_to_drop, inplace=True, errors='ignore')",
          "Remove unwanted columns\ndf_script = df_script[['episode_id', 'character_id', 'location_id', 'raw_text']]\n\n# Drop rows with missing values\ndf_script = df_script.dropna()"
         ],
         "marker": {
          "opacity": 0.5,
          "size": 5
         },
         "mode": "markers+text",
         "name": "85_Remove unnecessary columns from dataframes",
         "text": [
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          ""
         ],
         "textfont": {
          "size": 12
         },
         "type": "scattergl",
         "x": [
          4.560877323150635,
          4.7589311599731445,
          5.205194473266602,
          4.892553806304932,
          5.761860370635986,
          4.960466384887695,
          5.546411037445068,
          4.952663898468018,
          4.860647678375244,
          4.841768741607666,
          5.126678466796875,
          4.532940864562988,
          5.032098293304443,
          5.143403053283691,
          4.554090976715088,
          5.014378547668457,
          5.092947959899902,
          4.7469611167907715,
          4.536129474639893,
          4.6229705810546875,
          4.714929103851318,
          3.9488680362701416,
          4.930564880371094,
          5.0857768058776855,
          4.722996711730957,
          4.9286208152771,
          4.591665267944336,
          5.651342391967773,
          5.281432151794434,
          4.380221366882324,
          4.827287673950195,
          5.14180850982666
         ],
         "y": [
          6.2978034019470215,
          5.304986476898193,
          4.9472198486328125,
          4.998878479003906,
          6.435298442840576,
          5.2618327140808105,
          4.495777130126953,
          5.925455093383789,
          4.795116424560547,
          4.958743095397949,
          4.529782772064209,
          5.702368259429932,
          5.77142333984375,
          5.653761386871338,
          5.321275234222412,
          4.829691410064697,
          5.372673511505127,
          5.917134761810303,
          5.887298583984375,
          4.647308826446533,
          6.0650434494018555,
          4.8297905921936035,
          4.548862934112549,
          4.721524238586426,
          5.887401103973389,
          4.723366737365723,
          5.567392826080322,
          5.260092735290527,
          4.954878330230713,
          5.561882972717285,
          4.954217910766602,
          5.29162073135376
         ]
        },
        {
         "hoverinfo": "text",
         "hovertext": [
          "Data Preprocessing",
          " Preprocess columns for easier access",
          "Data loading and preprocessing",
          "Data Preprocessing",
          "Preprocessing\n# ",
          "Pravdepodobne som niekde spravil chybu, pretože z tejto časti neviem odhadnúť, čo sa stalo. Prosím, odkážte ma na predchádzajúci riadok.",
          " Preprocessing",
          " Data Preprocessing",
          "Preprocessing function",
          " Transform raw data before feature creation",
          "Data Preprocessing",
          " Preprocess the data",
          "Define code snippets to preprocess the data further",
          "Load and preprocess data",
          "Data Preprocessing",
          "Data preprocessing tasks",
          "Some preprocessing",
          "Data preprocessing",
          "The first step is to preprocess the data.",
          "--------------  Preprocessing  --------------",
          " Apply initial preprocessing steps",
          "Data Preprocessing",
          "------------------ Preprocessing ---------------------",
          "Preprocessing\n# We first need to see what the data looks like.",
          "Data Preprocessing",
          "Data preprocessing",
          "Data Preprocessing",
          "Preprocess data",
          "Part 1: Data preprocessing",
          "Data Preprocessing",
          "1. Data overview and preprocessing"
         ],
         "marker": {
          "opacity": 0.5,
          "size": 5
         },
         "mode": "markers+text",
         "name": "86_Data Preprocessing",
         "text": [
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          ""
         ],
         "textfont": {
          "size": 12
         },
         "type": "scattergl",
         "x": [
          12.758255958557129,
          11.665373802185059,
          13.599937438964844,
          12.735369682312012,
          13.53492546081543,
          14.665803909301758,
          13.36258602142334,
          12.812582015991211,
          13.37210464477539,
          13.286238670349121,
          12.893505096435547,
          13.039057731628418,
          12.343972206115723,
          13.430072784423828,
          12.725640296936035,
          12.767115592956543,
          13.558923721313477,
          12.923962593078613,
          13.603104591369629,
          13.651080131530762,
          13.306731224060059,
          12.653759002685547,
          13.655179023742676,
          13.09111213684082,
          12.488248825073242,
          12.493277549743652,
          12.639408111572266,
          12.491811752319336,
          12.945975303649902,
          12.920466423034668,
          13.445855140686035
         ],
         "y": [
          2.1246237754821777,
          2.267090320587158,
          1.8486483097076416,
          2.4868040084838867,
          3.2822105884552,
          4.194388389587402,
          3.2680301666259766,
          2.4863851070404053,
          3.176862955093384,
          2.532388925552368,
          2.728464365005493,
          2.6726317405700684,
          2.788774251937866,
          2.282271385192871,
          2.0121800899505615,
          2.5498266220092773,
          2.9220738410949707,
          2.2794528007507324,
          2.218939781188965,
          3.450866937637329,
          3.14060115814209,
          2.6105191707611084,
          3.628563642501831,
          2.560192584991455,
          2.2041094303131104,
          2.270270586013794,
          2.321791887283325,
          2.86380934715271,
          2.5428481101989746,
          2.3175272941589355,
          2.131645441055298
         ]
        },
        {
         "hoverinfo": "text",
         "hovertext": [
          "Print first records of df_episodes dataframe\ndf_episodes.head()",
          " Display the dataframe of episodes using the head() function to display the first 5 rows.",
          "Preview the first 5 lines of the episodes DataFrame\ndf_episodes.head()",
          " Display the first few rows of the dataframe\ndf_episodes.head()",
          "The head method can be used to display the first few rows of the dataframe.\n# Display the first 10 rows of the dataframe\ndf_episodes.head(10)",
          "Display the first few rows of the dataframe\ndf_episodes.head()",
          "Display the first 5 rows of the episodes dataframe\ndf_episodes.head()",
          "Inspecting first few rows of dataset\ndf_episodes.head()",
          "Print the first 5 rows of the episodes dataframe to understand how the data is structured\ndf_episodes.head()",
          "Display the first few rows of the episodes dataframe to understand the data.",
          "Display first rows by episodes dataframe",
          "Preview the first 5 lines of df_episodes\ndf_episodes.head()",
          "Display the first rows of the episodes dataframe\ndf_episodes.head()",
          "\n# Display the first rows of the table 'Episodes'\ndf_episodes.head()",
          "# Show the first 5 rows of the episodes dataframe\ndf_episodes.head()",
          " Preview the first 5 lines of the dataframe\ndf_episodes.head()",
          "Displaying the first lines of the episodes dataframe",
          "Display the first few lines of the episodes dataframe\ndf_episodes.head()",
          "# Display the first 5 rows of the episodes dataframe\ndf_episodes.head()",
          "Displaying the first rows of the DataFrame to get a sense of the data distribution \ndf_episodes.head()",
          "Display the first 5 rows of the episodes dataframe\ndf_episodes.head()",
          "Display the first few rows of the episodes data\ndf_episodes.head()",
          " Show top 10 rows of the episodes dataframe\ndf_episodes.head(10)",
          "Show the first few rows of the episodes DataFrame\ndf_episodes.head()",
          "Displaying the first 5 rows of the episodes dataframe to visualize the data",
          "# Display the first few rows of the dataframe\ndf_episodes.head()",
          "Print the first rows of the episodes DataFrame\ndf_episodes.head()",
          "Check the number of episodes in the dataset and the first few lines of the dataframe",
          " Display first 5 records.\ndf_episodes.head()",
          " Show the top 5 rows of the episodes DataFrame\ndf_episodes.head()",
          "Explore first 10 records of the dataset\ndf_episodes.head(10)"
         ],
         "marker": {
          "opacity": 0.5,
          "size": 5
         },
         "mode": "markers+text",
         "name": "87_Displaying first rows of episodes dataframe",
         "text": [
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          ""
         ],
         "textfont": {
          "size": 12
         },
         "type": "scattergl",
         "x": [
          0.7544695138931274,
          0.7758128643035889,
          0.8478504419326782,
          0.9641799330711365,
          0.7536119222640991,
          0.7682178020477295,
          0.4596982002258301,
          1.3519238233566284,
          0.3134922981262207,
          1.9391690492630005,
          1.8813989162445068,
          1.0363306999206543,
          0.9183180332183838,
          1.2452945709228516,
          0.5239543318748474,
          0.5376942157745361,
          2.4584453105926514,
          1.0956838130950928,
          0.303911417722702,
          0.866626501083374,
          0.3928956985473633,
          1.1431125402450562,
          -0.278196781873703,
          1.1744351387023926,
          1.4652491807937622,
          0.8963108062744141,
          1.1321953535079956,
          2.753528356552124,
          0.7350298762321472,
          -0.20742909610271454,
          1.707277774810791
         ],
         "y": [
          4.3399739265441895,
          4.8993635177612305,
          4.235754013061523,
          4.276859283447266,
          4.675269603729248,
          4.5204949378967285,
          5.1930999755859375,
          3.879967212677002,
          5.189580917358398,
          3.8328564167022705,
          4.084076404571533,
          3.921868085861206,
          4.535006523132324,
          4.338977813720703,
          5.169179916381836,
          4.465951442718506,
          4.127415657043457,
          4.4888505935668945,
          5.459396839141846,
          4.170071601867676,
          4.990525722503662,
          4.0079755783081055,
          5.630600929260254,
          4.371062755584717,
          4.491871356964111,
          4.472735404968262,
          4.365350246429443,
          3.0969362258911133,
          4.7416510581970215,
          5.691103458404541,
          3.7023909091949463
         ]
        },
        {
         "hoverinfo": "text",
         "hovertext": [
          "function to convert string to lowercase and strip white space\ndef lowercase_and_strip(column):\n    return column.astype(str).str.lower().str.strip()",
          " Function to pre-process text\ndef clean_text(text):\n    # Remove numbers\n    text = ''.join(word for word in text if not word.isdigit())\n    # Remove punctuation and make everything lower case\n    return ''.join(word.lower() for word in text if word.isalpha() or word.isspace())",
          "Custom functions\n# Custom functions\ndef clean_text(text):\n    \"\"\"Clean text data by removing special characters and extra whitespace.\"\"\"\n    return ' '.join(\n        word for word in text.split()\n        if (\n            not word.startswith('@')\n            and not word.startswith('http')\n            and not word.startswith('www')\n        )\n    )",
          "Clean text data",
          "Clean text data and remove special characters, punctuation, etc.",
          "Define a function to clean and preprocess text data",
          "Light text preprocessing",
          " Remove unwanted or unnecessary characters from `raw_text` dictionary values and convert them to lowercase",
          "Remove punctuation and format text data",
          "Function to preprocess text data",
          "Clean text",
          "Data prep: lowercase, remove punctuation, remove stop words",
          "Function to convert text to lowercase and remove punctuation and extra spaces",
          "Make everything lower case.",
          "Turning off the scientific notation (e) when displaying numbers",
          "Text preprocessing: removing useless characters and reducing words to their root form.",
          "Text preprocessing and cleaning",
          "Functions to clean and preprocess text data",
          "Helper function to clean text.",
          "remove punctuation and numbers from the text",
          "Slight clean up to ensure consistency (convert to lower case)",
          "Clean data and preprocess text",
          " Strip leading whitespace characters",
          "Remove all characters but keep the letters, make it lowercase and strip\ndef clean_line(line):\n    return ''.join(char for char in line if char.isalpha()).lower().strip()",
          "Define function to pre-process the text",
          "Character job_text cleaning",
          " Set text cleaning settings\nnlp = spacy.load(\"en_core_web_md\", disable=[\"parser\", \"ner\"])\n\n# Constants\nwhite_list_chars = [\n    \"bart\", \"homer\", \"marge\", \"maggie\", \"lisa\", \"krusty\", \"burns\",\n    \"millhouse\", \"apu\", \"moe\", \"ned\", \"edna\", \"skinner\", \"ralph\",\n    \"barney\", \"todd\", \"rod\", \"hans\", \"troy\", \"citizen\", \"abraham\",\n    \"lenny\", \"carl\", \"lionel\", \"selma\", \"patty\", \"milhouse\", \"montgomery\",\n    \"clancy\", \"waylon\", \"apu_nahasapeemapetilon\"\n]\n\n# Function to preprocess texts\ndef clean_text(text: str) -> str:\n    # Convert to lowercase\n    text = text.lower()\n    \n    # Remove punctuation, digits and special characters\n    text = \" \".join(token.lemma_ for token in nlp(text) if token.is_alpha)\n    \n    return text",
          "Text preprocssing",
          "Define functions to preprocess text data",
          "Functions to make the text easier to process",
          "Helper function to clean a line of text and process it with spaCy"
         ],
         "marker": {
          "opacity": 0.5,
          "size": 5
         },
         "mode": "markers+text",
         "name": "88_Text Preprocessing",
         "text": [
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          ""
         ],
         "textfont": {
          "size": 12
         },
         "type": "scattergl",
         "x": [
          9.055501937866211,
          11.503246307373047,
          11.40230655670166,
          11.48188304901123,
          11.182724952697754,
          12.167765617370605,
          12.596962928771973,
          9.618392944335938,
          11.154021263122559,
          12.213286399841309,
          11.804208755493164,
          10.76392650604248,
          10.396976470947266,
          10.852636337280273,
          10.891509056091309,
          12.760499954223633,
          12.173151016235352,
          12.132431030273438,
          12.035967826843262,
          11.047120094299316,
          10.470544815063477,
          11.8558931350708,
          9.348918914794922,
          10.441200256347656,
          12.720267295837402,
          11.481521606445312,
          12.226584434509277,
          12.717737197875977,
          12.725225448608398,
          12.5943021774292,
          12.382244110107422
         ],
         "y": [
          6.735701560974121,
          5.624926567077637,
          5.58055305480957,
          3.8380959033966064,
          4.4334564208984375,
          4.233659744262695,
          4.296097755432129,
          6.12894344329834,
          4.542234420776367,
          3.7740046977996826,
          4.788051605224609,
          4.771390438079834,
          5.508068084716797,
          4.867087364196777,
          4.6529998779296875,
          4.467979907989502,
          4.679388999938965,
          3.9930756092071533,
          4.796713829040527,
          4.790691375732422,
          4.235605716705322,
          3.771718978881836,
          7.109116077423096,
          6.202260494232178,
          4.433672904968262,
          5.048855781555176,
          6.353689193725586,
          4.246476650238037,
          3.6882174015045166,
          4.95515251159668,
          5.044402122497559
         ]
        },
        {
         "hoverinfo": "text",
         "hovertext": [
          "Display all columns\npd.set_option('display.max_columns', None)",
          "Display all columns for visibility\npd.set_option('display.max_columns', None)",
          "Display all columns to know which one to remove\npd.set_option('display.max_columns', None)",
          "Show all columns\npd.set_option('display.max_columns', None)",
          "# Display all columns\npd.set_option('display.max_columns', None)",
          "display all columns\npd.options.display.max_columns = None",
          "Display all columns as there might be many columns in the datasets\npd.set_option('display.max_columns', None)",
          "Display all columns to understand the dataset better\npd.set_option('display.max_columns', None)",
          "Display all columns\npd.set_option('display.max_columns', None)",
          "Display all columns to be able to choose\npd.options.display.max_columns = None",
          "Auxiliary code to display all columns\npd.set_option('display.max_columns', None)",
          "Display all columns so that we can make an informed decision on what to use\npd.options.display.max_columns = None",
          "Ensure we can see all the columns\npd.set_option('display.max_columns', 500)",
          "Display all columns to understand the structure of the data\npd.options.display.max_columns = None",
          "Display all available columns\npd.options.display.max_columns = None",
          "Show all columns explicitly\npd.set_option('display.max_columns', None)",
          "Set this option to characteristic_size so as to show at most the characteristic number of relevant columns.",
          " Show all columns\npd.set_option('display.max_columns', None)",
          "Displays all columns\npd.set_option('display.max_columns', None)",
          " Set option to display all columns in the notebook\npd.set_option('display.max_columns', None)",
          "Set to display all columns\npd.set_option('display.max_columns', None)",
          "isplay all columns\npd.set_option('display.max_columns', None)",
          "Set parameter to display all columns",
          "Set the display options when displaying all columns.",
          "Show all columns\npd.options.display.max_columns = None",
          "Show all available columns\npd.set_option('display.max_columns', None)",
          "Display all tables\npd.set_option('display.max_columns', None)",
          "Show more columns\npd.set_option('display.max_columns', None)",
          "Display all columns for a better view\npd.options.display.max_columns = None",
          "Set option to display all columns at any time",
          " Display all columns\npd.set_option('display.max_columns', None)"
         ],
         "marker": {
          "opacity": 0.5,
          "size": 5
         },
         "mode": "markers+text",
         "name": "89_display options for columns in pandas dataframe",
         "text": [
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          ""
         ],
         "textfont": {
          "size": 12
         },
         "type": "scattergl",
         "x": [
          22.87675666809082,
          22.449907302856445,
          23.10712242126465,
          23.07203483581543,
          23.382965087890625,
          22.494346618652344,
          22.648529052734375,
          23.164470672607422,
          22.914901733398438,
          22.536046981811523,
          22.796037673950195,
          23.1783447265625,
          23.998991012573242,
          23.02702522277832,
          22.645036697387695,
          22.814197540283203,
          23.309181213378906,
          22.668094635009766,
          23.08765411376953,
          22.467866897583008,
          23.179702758789062,
          23.377323150634766,
          22.294147491455078,
          22.465713500976562,
          22.652141571044922,
          22.64725685119629,
          23.0423526763916,
          23.262256622314453,
          22.81560707092285,
          22.00054931640625,
          23.036008834838867
         ],
         "y": [
          -1.6988674402236938,
          -1.9359233379364014,
          -1.4123995304107666,
          -2.067390203475952,
          -1.435486078262329,
          -2.1372177600860596,
          -1.1000834703445435,
          -1.3833969831466675,
          -1.6443594694137573,
          -1.617776870727539,
          -1.7875508069992065,
          -1.8213677406311035,
          -0.9208330512046814,
          -1.7077007293701172,
          -1.7746589183807373,
          -1.9320803880691528,
          -1.3477863073349,
          -1.8261351585388184,
          -1.370652198791504,
          -0.8773791193962097,
          -1.3358757495880127,
          -1.7931302785873413,
          -1.595520257949829,
          -1.2646852731704712,
          -1.8978101015090942,
          -1.7480899095535278,
          -1.9493367671966553,
          -1.6200876235961914,
          -2.0516510009765625,
          -1.0203107595443726,
          -1.5159962177276611
         ]
        },
        {
         "hoverinfo": "text",
         "hovertext": [
          " Top-5 rows of the characters DataFrame\ndf_characters.head()",
          "Display top rows of the characters dataframe\ndf_characters.head()",
          " Print top 5 rows of the characters dataset\ndf_characters.head()",
          " Display top 5 rows of characters dataframe\ndf_characters.head()",
          "Display the top 5 records of each dataframe\ndf_characters.head()",
          "Check top few rows of the dataframe of simpsons_characters",
          "Filter for \"Lisa Simpson\" character\ndf_lisa_lines = df_script[df_script['character_id'] == 9]\n\n# Show the top 5 rows\ndf_lisa_lines.head()",
          "Checking top 5 records to understand data better\ndf_characters.head()",
          "Display top 5 rows of characters dataframe\ndf_characters.head()",
          " The top few rows of the character dataset\nprint(df_characters.head())",
          "Print the top 5 rows of the characters dataframe\ndf_characters.head()",
          "View top few rows of character dataset\ndf_characters.head()",
          "View the top 5 rows of the characters DataFrame\ndf_characters.head()",
          " Display top of the Characters DF\ndf_characters.head()",
          " Show the top 5 rows of the characters dataframe\ndf_characters.head()",
          "Show the top 20 rows of the characters dataframe\ndf_characters.head(20)",
          "Show the top 5 rows of the characters dataframe\ndf_characters.head()",
          " View top rows of characters dataframe\ndf_characters.head()",
          "Check top 5 records of each dataset\ndf_characters.head()",
          "Print the top 5 rows of the characters dataframe\ndf_characters.head()",
          "Inspect top rows of df_characters\ndf_characters.head()",
          "Show top 10 rows of Simpsons character dataframe\ndf_characters.head(10)",
          "Display the top 5 rows of the characters dataframe\ndf_characters.head()",
          " Display top 5 rows of characters dataframe",
          "top 5 rows of the characters dataframe\ndf_characters.head()",
          " Display the top few rows of the DataFrame\ndf_characters.head()",
          "View top few rows of characters dataframe\ndf_characters.head()",
          " Print the top 5 records of the characters dataframe\nprint(df_characters.head(5))",
          "Display the top 5 rows of the 'characters' dataframe\ndf_characters.head()",
          " Display the top 5 rows of the characters dataframe\ndf_characters.head()",
          "top 5 rows of the characters dataframe\ndf_characters.head()"
         ],
         "marker": {
          "opacity": 0.5,
          "size": 5
         },
         "mode": "markers+text",
         "name": "90_Viewing top rows of characters dataframe",
         "text": [
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          ""
         ],
         "textfont": {
          "size": 12
         },
         "type": "scattergl",
         "x": [
          2.3039779663085938,
          2.6924374103546143,
          1.8662035465240479,
          2.5362436771392822,
          1.9361791610717773,
          2.0934839248657227,
          2.511104106903076,
          1.3560583591461182,
          2.389124870300293,
          3.2997961044311523,
          1.611586093902588,
          2.503565788269043,
          2.488032579421997,
          3.4339828491210938,
          2.0054938793182373,
          2.0557286739349365,
          2.182497262954712,
          2.918945074081421,
          0.9195274114608765,
          1.8655000925064087,
          3.030829668045044,
          1.5407049655914307,
          2.166063070297241,
          3.0854554176330566,
          2.113986015319824,
          2.6457903385162354,
          2.7146048545837402,
          1.759408712387085,
          2.391841173171997,
          2.10517954826355,
          2.1785166263580322
         ],
         "y": [
          14.334050178527832,
          15.422988891601562,
          14.801796913146973,
          14.652112007141113,
          14.301068305969238,
          13.426156044006348,
          13.753087997436523,
          13.692858695983887,
          14.622097969055176,
          15.633853912353516,
          15.015874862670898,
          16.047786712646484,
          14.885125160217285,
          15.893425941467285,
          14.409622192382812,
          14.403365135192871,
          14.310914993286133,
          15.481498718261719,
          13.893656730651855,
          14.893007278442383,
          16.086515426635742,
          13.830946922302246,
          14.698101043701172,
          14.360917091369629,
          14.16971492767334,
          15.283724784851074,
          15.475069046020508,
          14.525745391845703,
          14.662880897521973,
          14.674236297607422,
          14.1421537399292
         ]
        },
        {
         "hoverinfo": "text",
         "hovertext": [
          "Set some options for pandas\npd.set_option('display.max_columns', 999)\npd.set_option('display.max_rows', 999)",
          " Set the display options of pandas to have a\n# larger number of elements and to display more columns\npd.options.display.max_rows = 999\npd.options.display.max_columns = 999",
          " Display maximum 5 rows and columns of a data frame\npd.set_option('display.max_columns', 5)\npd.set_option('display.max_rows', 5)",
          "To avoid truncating the display of DataFrames, we're going to tell pandas to display up to 100 columns and 100 rows.\npd.set_option('display.max_columns', 100)\npd.set_option('display.max_rows', 100)",
          "Increases the range of the rows displayed when 'print' displays the dataframe.",
          " This will cause pandas  to pretty print upto 200 columns and 100 rows.",
          "Increase the max number of columns to display for the PD dataframes, as follows",
          " Set the maximum number of rows and columns displayed when printing DataFrames\npd.set_option('display.max_rows', 500)",
          "# Set the maximum number of rows and columns displayed when printing a DataFrame\npd.set_option('display.max_rows', 300)\npd.set_option('display.max_columns', 300)",
          " Function to display large dataframes in a more human friendly way.\ndef display_df(df, n_lines = 5):\n    pd.set_option('display.max_colwidth', 200)\n    if (len(df) > n_lines*2):\n        display(df[:n_lines])\n        print('...')\n        display(df[-n_lines:])\n    else:\n        display(df)\n    pd.reset_option('display.max_colwidth')",
          " Set the display options for the dataframes to print all the columns and to show the max number of rows",
          "Limit the number of rows displayed when printing DataFrames\npd.options.display.max_rows = 10",
          "Limit the number of rows displayed for the dataframes to a maximum of 5\npd.set_option('max_rows', 5)",
          "Limits the number of displayed rows in a pandas DataFrame to improve the output readability\npd.set_option('display.max_rows', 5)",
          " Set the max display of rows in pandas display to 10",
          " Set max display of rows and columns for pandas dataframes\npd.set_option('display.max_rows', 10)\npd.set_option('display.max_columns', 10)",
          "Setting to display the max amount of columns as 200, this is just for ease of viewing the dataframe.",
          " Set pandas display options to better show long data\npd.set_option('display.max_columns', 500)",
          "Configure pandas to display all columns and show dataframes'\n# up to a maximum of 10 rows (for readability)\npd.set_option('display.max_columns', None)\npd.set_option('display.max_rows', 10)",
          " Display expanded rows and columns when displaying DataFrames\npd.set_option('display.max_columns', 500)\npd.set_option('display.max_rows', 150)",
          " Set a limit on the number of rows and columns displayed by pandas DataFrames\npd.set_option('display.max_rows', 10)\npd.set_option('display.max_columns', 100)",
          "Sets up dataframe display\npd.set_option('display.max_columns', 500)",
          "Options for pandas\npd.set_option('display.max_rows', 200)\npd.set_option('display.max_columns', 200)",
          "Setting limit of rows and columns to see when displaying dataframes\npd.set_option('display.max_columns', 100)\npd.set_option('display.max_rows', 100)",
          "Set some pandas defaults for nicer printing\npd.set_option('display.max_columns', 500)\npd.set_option('display.max_rows', 500)",
          " Set the display options for large DataFrames\npd.set_option('display.max_columns', None)",
          "Enable the processing of large datasets by pandas\npd.options.display.max_rows = 10",
          "Set maximum columns/rows to display for dataframes\npd.set_option('display.max_columns', 500)\npd.set_option('display.max_rows', 500)",
          "pd.set_option('max_rows', 10)  # show at most 10 rows for each DataFrame in this notebook",
          "# Display up to 35 columns (if the dataframe has more than 35 columns)\npd.set_option('display.max_columns', 35)\n\n# Display up to 200 rows\npd.set_option('display.max_rows', 200)",
          "Limit the amount of displayed rows for each dataframe\npd.set_option('display.max_rows', 10)"
         ],
         "marker": {
          "opacity": 0.5,
          "size": 5
         },
         "mode": "markers+text",
         "name": "91_Setting maximum number of rows and columns for displaying DataFrames in Pandas",
         "text": [
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          ""
         ],
         "textfont": {
          "size": 12
         },
         "type": "scattergl",
         "x": [
          22.379833221435547,
          22.383193969726562,
          22.600208282470703,
          22.082050323486328,
          22.366390228271484,
          22.5244083404541,
          22.35542869567871,
          22.864151000976562,
          22.390869140625,
          22.246051788330078,
          22.516359329223633,
          23.0684871673584,
          22.47665786743164,
          22.80872917175293,
          22.754478454589844,
          22.582944869995117,
          22.285507202148438,
          22.552236557006836,
          21.806257247924805,
          22.871360778808594,
          22.471694946289062,
          22.783061981201172,
          22.59061050415039,
          22.56148910522461,
          22.68963050842285,
          22.629301071166992,
          22.41215705871582,
          22.638837814331055,
          22.736812591552734,
          22.39357566833496,
          22.8104305267334
         ],
         "y": [
          0.7414491772651672,
          1.1418581008911133,
          -0.21964260935783386,
          1.1344141960144043,
          0.1015501618385315,
          0.8222919702529907,
          0.4714851677417755,
          0.35604822635650635,
          0.13907533884048462,
          1.0612276792526245,
          0.4214368760585785,
          0.12921567261219025,
          -0.07308097183704376,
          0.0026709793601185083,
          0.3813946843147278,
          0.16437716782093048,
          0.4001637399196625,
          1.3861150741577148,
          0.49646785855293274,
          0.4809293746948242,
          0.33364251255989075,
          -0.12379888445138931,
          0.6215729713439941,
          -0.03418263420462608,
          0.9034382104873657,
          0.48680630326271057,
          0.9334600567817688,
          0.29420962929725647,
          0.16746720671653748,
          0.21205438673496246,
          -0.0638347789645195
         ]
        },
        {
         "hoverinfo": "text",
         "hovertext": [
          "Show the first few characters of each dataframe\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()",
          " Displaying the first few rows of each dataframe\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()",
          "Display the first few rows of each dataframe\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()",
          "imple display the first few rows of each DataFrame for a quick inspection\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()",
          "Display the first few rows of each dataframe\ndf_episodes.head(), df_characters.head(), df_locations.head(), df_script.head()",
          " Display the first 3 rows of each dataframe\ndisplay(df_characters.head(3),\n        df_locations.head(3),\n        df_script.head(3),\n        df_episodes.head(3))",
          " Display first rows of all DataFrames related to the Simpsons dataset\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()",
          " Display the first few rows of each dataframe\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()",
          " Display first few rows of each dataframe\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()",
          "Show first few rows of each dataframe\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()",
          " Display the first few rows of each dataframe\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()",
          " Display the first few characters of the episodes dataframe\ndf_episodes.head()",
          "Display first few rows of each dataframe\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()",
          "Displaying the first few rows of each data set\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()",
          " Display the first few rows of each dataframe\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()",
          " Display the first few characters of each dataframe\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()",
          "Display first rows of each dataframe\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()",
          "Display the first few rows of the dataframes\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()",
          "Show the first rows for each dataframe\ndf_list = [df_characters, df_locations, df_script, df_episodes]",
          "Return the first few records\nfor df in [df_characters, df_locations, df_script, df_episodes]:\n    display(df.head())",
          "Show the first couple of rows of each dataframe\ndf_episodes.head(), df_script.head(), df_characters.head(), df_locations.head()",
          " Show the first few rows of each dataframe\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()",
          "Show the first few rows of each dataframe\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()",
          "Show first data in each dataframe\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()",
          "Display the first few rows of each dataframe\ndf_characters.head(), df_locations.head(), df_episodes.head(), df_script.head()",
          "Display the first few rows of each dataframe\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()",
          " Display the first few records of each dataframe\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()",
          "display the first few rows of each dataframe\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()",
          " Display the first few rows of each dataframe\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()",
          " Display first few rows of each dataset\ndf_episodes.head(), df_characters.head(), df_locations.head(), df_script.head()"
         ],
         "marker": {
          "opacity": 0.5,
          "size": 5
         },
         "mode": "markers+text",
         "name": "92_Displaying first few rows of related dataframes",
         "text": [
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          ""
         ],
         "textfont": {
          "size": 12
         },
         "type": "scattergl",
         "x": [
          -3.0961551666259766,
          -3.5398523807525635,
          -3.817349910736084,
          -4.148089408874512,
          -3.799283742904663,
          -3.6029231548309326,
          -3.676621437072754,
          -3.8520240783691406,
          -4.012237548828125,
          -4.2775444984436035,
          -3.917235851287842,
          -1.3148393630981445,
          -4.041881084442139,
          -3.500420331954956,
          -3.747182607650757,
          -2.9241068363189697,
          -3.8454535007476807,
          -4.076230049133301,
          -4.269696235656738,
          -4.061245918273926,
          -3.6226022243499756,
          -3.930316686630249,
          -3.779844045639038,
          -4.374457359313965,
          -3.8215830326080322,
          -4.0669074058532715,
          -4.006932735443115,
          -3.8224267959594727,
          -3.698197603225708,
          -3.4744367599487305
         ],
         "y": [
          6.9273810386657715,
          7.08547830581665,
          7.467024326324463,
          7.371377944946289,
          7.887430667877197,
          6.908595085144043,
          7.812162399291992,
          7.333422660827637,
          7.673900127410889,
          7.599391460418701,
          7.430133819580078,
          5.933964729309082,
          7.653641223907471,
          7.087433815002441,
          7.311695575714111,
          6.722973823547363,
          7.336970329284668,
          7.064126491546631,
          7.610344409942627,
          7.742070198059082,
          7.563851356506348,
          7.31175422668457,
          7.596118927001953,
          7.128333568572998,
          7.509984970092773,
          7.446109771728516,
          7.819452285766602,
          7.574499607086182,
          7.568714618682861,
          7.256825923919678
         ]
        },
        {
         "hoverinfo": "text",
         "hovertext": [
          "Load pre-trained spacy model\nnlp = spacy.load('en_core_web_sm')",
          "Set up spacy model\nnlp = spacy.load('en_core_web_md')",
          "Load the pre-trained Spacy NLP model\nnlp = spacy.load('en_core_web_md')",
          "Load pre-trained model\nnlp = spacy.load('en_core_web_md')",
          "Load the pre-trained spacy model\nnlp = spacy.load('en_core_web_sm')",
          " Load model\nnlp = spacy.load('en_core_web_md')",
          " Optional, you can run below, if you want to use the medium model. It takes some time to load.\nnlp = spacy.load('en_core_web_md')",
          " Load the spaCy model\nnlp = spacy.load('en_core_web_md')",
          " text processing and nlp\nnlp = spacy.load('en_core_web_md')",
          "Define and load the model\nnlp = spacy.load('en_core_web_md')",
          "# We use spacy's medium English model\nnlp = spacy.load('en_core_web_md')",
          "Spacy model\nnlp = spacy.load(\"en_core_web_md\")",
          "Load the serialized version of the SpaCy pre-trained model 'en_core_web_md'\nnlp = spacy.load('en_core_web_md')",
          "# Load the spacy model (medium model is sufficient, small would be too small and big too large)\nnlp = spacy.load(\"en_core_web_md\")",
          "Load Spacy\nnlp = spacy.load('en_core_web_md')",
          "Load spaCy model\nnlp = spacy.load('en_core_web_md')",
          " Load the pre-trained Spacy model\nnlp = spacy.load('en_core_web_sm')",
          "Load the pre-trained spaCy NLP model\nnlp = spacy.load('en_core_web_sm')",
          "Initialize spacy\nnlp = spacy.load('en_core_web_md')",
          "Set up spacy\nnlp = spacy.load('en_core_web_md')",
          "Load spacy\nnlp = spacy.load(\"en_core_web_md\")",
          " Load the pre-trained spacy NLP model\nnlp = spacy.load('en_core_web_sm')",
          "Load pre-trained spaCy model\nnlp = spacy.load('en_core_web_sm')",
          "\n# Caching pre-trained model\nnlp = spacy.load('en_core_web_sm')",
          "Load language model\n# This may take a while\nnlp = spacy.load('en_core_web_md')",
          "Create a new instance of the nlp pipeline\nnlp = spacy.load('en_core_web_md')",
          "Load the pre-trained spacy model\nnlp = spacy.load('en_core_web_md')",
          "NLP model\nnlp = spacy.load('en_core_web_md')",
          "spacy.load('en_core_web_md')\nnlp = spacy.load('en')",
          "Path to where the pre-trained model is stored.\npath_to_model = 'model'\n\n# Load the pre-trained model\nnlp = spacy.load(path_to_model)"
         ],
         "marker": {
          "opacity": 0.5,
          "size": 5
         },
         "mode": "markers+text",
         "name": "93_spacy load pretrained NLP model",
         "text": [
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          ""
         ],
         "textfont": {
          "size": 12
         },
         "type": "scattergl",
         "x": [
          16.517311096191406,
          17.7513484954834,
          16.917016983032227,
          16.880752563476562,
          16.546619415283203,
          17.636606216430664,
          17.69428825378418,
          17.72275733947754,
          18.166465759277344,
          17.864648818969727,
          17.954679489135742,
          17.99054718017578,
          17.267492294311523,
          18.194265365600586,
          18.110904693603516,
          17.628780364990234,
          16.651485443115234,
          16.179414749145508,
          17.993680953979492,
          17.972349166870117,
          18.069061279296875,
          16.146251678466797,
          16.447477340698242,
          16.377641677856445,
          17.717973709106445,
          17.41860580444336,
          17.01343536376953,
          17.66870880126953,
          17.722929000854492,
          16.188806533813477
         ],
         "y": [
          7.4272050857543945,
          7.77129602432251,
          7.751218795776367,
          7.31459903717041,
          7.943729877471924,
          7.63766622543335,
          7.217322826385498,
          7.594123840332031,
          8.066932678222656,
          7.719091415405273,
          8.011152267456055,
          7.871971607208252,
          7.707732200622559,
          7.774460315704346,
          7.959009647369385,
          7.692429065704346,
          7.837639808654785,
          7.986832141876221,
          8.178874969482422,
          7.981590747833252,
          8.163033485412598,
          8.183004379272461,
          7.683818340301514,
          7.395164966583252,
          8.0018949508667,
          7.8849406242370605,
          7.673384666442871,
          7.641910076141357,
          8.22282600402832,
          6.909470558166504
         ]
        },
        {
         "hoverinfo": "text",
         "hovertext": [
          "Creating the wordclouds requires some data-wrangling, so I'm going to start by providing me  the functions for pre-processing the data.",
          "Utils\nfrom utils import get_text_entities, clean_dialogue, plot_wordcloud",
          "Installation TIP - if you don't have wordcloud installed, you might need to run !pip install wordcloud in a notebook cell.",
          "Setting the parameters for the word cloud.",
          "Set the stopwords and create the word cloud.",
          "Create word cloud function",
          "Question 5: Should we preprocess the text data further before we create a Wordcloud?",
          "Setting up the Word Cloud parameters and extracting the tokens\nwordcloud = WordCloud(width = 800, height = 800, \n                background_color ='white', \n                stopwords = stopwords, \n                min_font_size = 10)",
          "Function to display and store word cloud",
          "Set up wordcloud\nfont_path = '/usr/share/fonts/truetype/dejavu/DejaVuSans-Bold.ttf'\nwordcloud = WordCloud(\n    width = 900,\n    height = 500,\n    background_color = 'black',\n    stopwords = STOPWORDS,\n    contour_width = 0.5,\n    contour_color = 'steelblue',\n    collocations = False,\n    colormap = 'viridis',\n    font_path = font_path\n)",
          "Create the word cloud function using the WordCloud package.",
          "Define the path to the word frequency image that we will generate using WordCloud.",
          "Set text variable and create a word cloud.",
          "Sets the amount of words to display in WordCloud and also the font size.",
          "Create a background WordCloud for an image.",
          "Set up the WordCloud with the parameters specified in the task",
          "Wordcloud setup\nwc = WordCloud(width=800, height=400, max_words=200, background_color='white')",
          "Create and init default wordcloud configuration\nwc_default_config = {\n    \"max_words\": 100,\n    \"width\" : 800,\n    \"height\" : 400,\n    \"collocations\" : False #\"False colocations\" are a pair or more of words that are commonly co-located in a text. In general, they tend to appear together more than would be expected by chance\n}",
          " from wordcloud import WordCloud",
          "Creating an instance of the WordCloud class.",
          "Set the max budget for the individual wordclouds\nmax_b = 100",
          "# To create the wordclouds we will need the large language model \n# and some additional utility code from the course NLP repository\n!wget https://github.com/SDS-AAU/SDS-master/raw/master/M3/nlp/nlp.py -O nlp/nlp.py\n!wget https://github.com/SDS-AAU/SDS-master/raw/master/M3/nlp/sdsai_ofehome.py -O nlp/sdsai_ofehome.py",
          "Create an instance of the WordCloud class and model the word cloud using the script data",
          "Create an instance of the WordCloud class",
          "Define a function to create a word cloud from a given text",
          "Set the dimension of word cloud to be created.",
          "Helper functions to create WordClouds",
          "Create an instance of the WordCloud class.",
          "Set up a basic word cloud using WordCloud.",
          "Set up the word cloud dictionary and the function to plot it."
         ],
         "marker": {
          "opacity": 0.5,
          "size": 5
         },
         "mode": "markers+text",
         "name": "94_Creating a Word Cloud",
         "text": [
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          ""
         ],
         "textfont": {
          "size": 12
         },
         "type": "scattergl",
         "x": [
          12.569016456604004,
          13.366557121276855,
          13.318922996520996,
          12.880955696105957,
          12.695133209228516,
          13.001433372497559,
          12.698562622070312,
          13.03169059753418,
          13.016080856323242,
          13.021075248718262,
          13.013912200927734,
          12.299534797668457,
          12.787455558776855,
          12.704282760620117,
          12.74463939666748,
          13.334756851196289,
          12.87796401977539,
          12.420695304870605,
          13.48798942565918,
          13.488014221191406,
          12.967490196228027,
          13.156044006347656,
          13.308241844177246,
          13.106772422790527,
          12.401341438293457,
          12.96860122680664,
          13.111029624938965,
          13.2726469039917,
          12.996909141540527,
          12.494791984558105
         ],
         "y": [
          6.744438171386719,
          6.154358863830566,
          6.8847575187683105,
          7.370049953460693,
          7.843613624572754,
          7.556560039520264,
          5.836143493652344,
          7.56648063659668,
          7.689146041870117,
          7.177070140838623,
          7.3732171058654785,
          7.5557661056518555,
          7.525168418884277,
          7.423478603363037,
          7.548572063446045,
          6.913782596588135,
          7.5382256507873535,
          7.258279323577881,
          6.700088977813721,
          6.995993614196777,
          7.076213836669922,
          6.970451831817627,
          6.959115028381348,
          7.272034168243408,
          7.334074974060059,
          7.9084086418151855,
          6.848330974578857,
          7.027601718902588,
          6.931781768798828,
          8.256111145019531
         ]
        },
        {
         "hoverinfo": "text",
         "hovertext": [
          "Inspect first few rows of each dataframe\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()",
          "Inspect the first few rows of each dataframe\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()",
          "inspect the first few lines of each dataframe\ndf_script.head(), df_characters.head(), df_locations.head(), df_episodes.head()",
          "View the dataset headers and the first five records in the dataframes.\ndf_episodes.head(), df_characters.head(), df_locations.head(), df_script.head()",
          " inspect datasets' first few rows\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()",
          "Look at the first few rows of each dataframe\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()",
          "Extracting the character, location, and episode data from the script data\ncharacters = sorted(df_script.raw_character_text.unique())\nlocations = sorted(df_script.raw_location_text.unique())\nepisodes = sorted(df_script.raw_location_text.unique())",
          "Inspect the first few rows of each dataframe\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()",
          "Look at first 5 rows of each dataframe\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()",
          "Inspecting the data for first rows\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()",
          "Inspect the first few rows of each dataframe\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()",
          "inspect the first few entries of each dataframe\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()",
          "Inspect the first few rows of each DataFrame\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()",
          "Inspect the first few rows of each dataframe\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()",
          "Look at the first 5 rows of each dataframe\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()",
          "Explore the first few rows of each dataframe\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()",
          "Inspect the first five rows of each dataframe\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()",
          "Explore the first rows of each dataframe\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()",
          "Browse the first few rows of each DataFrame\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()",
          "Inspect first few rows of each dataframe\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()",
          "Let's display the heads of the DataFrames to have a first look at the data\ndf_locations.head(), df_characters.head(), df_episodes.head(), df_script.head()",
          "Inspect the first few rows of each dataframe\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()",
          "Inspect the first few lines of each dataframe\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()",
          "Inspect the first rows of each dataframe\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()",
          "View the top 5 records of all the Dataset\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()",
          "Look at the first 5 rows of each dataframe\ndf_script.head(), df_characters.head(), df_locations.head(), df_episodes.head()",
          "Let's display the first couple of rows of each of our dataframes to see what they look like:\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()",
          "First let's display the first few rows of each dataframe, to inspect what kind of information we've got:\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()",
          " Check out the first few rows of each DataFrame\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()",
          "Look at the first 5 rows in each dataset\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()"
         ],
         "marker": {
          "opacity": 0.5,
          "size": 5
         },
         "mode": "markers+text",
         "name": "95_Exploring Dataframes with First Few Rows",
         "text": [
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          ""
         ],
         "textfont": {
          "size": 12
         },
         "type": "scattergl",
         "x": [
          -4.333655834197998,
          -4.279210090637207,
          -4.259525775909424,
          -3.345651388168335,
          -3.4029524326324463,
          -3.9178946018218994,
          1.3232128620147705,
          -4.3237624168396,
          -3.4700779914855957,
          -4.077340126037598,
          -4.248616695404053,
          -4.103243827819824,
          -4.416697025299072,
          -4.190308094024658,
          -3.549823760986328,
          -3.9798920154571533,
          -3.5455570220947266,
          -4.389713764190674,
          -4.2498602867126465,
          -4.314661502838135,
          -4.136541843414307,
          -4.204813480377197,
          -4.19199800491333,
          -4.434942245483398,
          -3.123142957687378,
          -3.7226569652557373,
          -4.031577110290527,
          -4.357059001922607,
          -3.7083518505096436,
          -3.0781211853027344
         ],
         "y": [
          4.4754319190979,
          4.165947437286377,
          3.226093292236328,
          3.848781108856201,
          4.026841163635254,
          3.373667001724243,
          5.709084510803223,
          4.031835556030273,
          3.828016757965088,
          3.9724016189575195,
          3.9658360481262207,
          3.592031478881836,
          4.260091304779053,
          4.089324951171875,
          3.6567747592926025,
          4.099430561065674,
          4.305058479309082,
          4.128446102142334,
          4.49118709564209,
          4.543044090270996,
          3.0162148475646973,
          3.999661445617676,
          3.1492292881011963,
          4.134511947631836,
          3.3363564014434814,
          3.526167154312134,
          3.4855051040649414,
          3.418379783630371,
          2.856879234313965,
          3.2101802825927734
         ]
        },
        {
         "hoverinfo": "text",
         "hovertext": [
          " Display the first few rows of the dataframe to understand its structure\ndf_characters.head()",
          "Display the first few rows of the characters dataset to understand its structure\nprint(df_characters.head())",
          "Display the first few rows of the characters dataframe to understand its structure\ndf_characters.head()",
          "Show the first few rows of the dataset to understand its structure\ndf_characters.head()",
          "Display the first few rows of the characters dataframe to understand its structure\ndf_characters.head()",
          " Print the first few entries of the characters table to understand its structure and the information available.\ndf_characters.head()",
          "Display the first few rows of the dataframe to understand its structure and content\ndf_characters.head()",
          "Displaying the first few rows of the characters DataFrame to understand its structure\ndf_characters.head()",
          "Load the data and display the first few rows to understand the structure of the data\ndf_characters.head()",
          " Display the first few rows of each dataframe to understand their structure\ndf_characters.head()",
          "Display the first few rows of the dataframe to understand its structure.\ndf_characters.head()",
          " Display the first few rows of the dataframe to understand its structure and contents\ndf_characters.head()",
          " Display the first few lines of each dataframe to understand better their structure\ndf_characters.head()",
          "Display the first few rows of the dataframe to understand its attributes and values\ndf_characters.head()",
          "Display the first few entries of each table to understand its structure and content\ndf_characters.head()",
          "Display the first few lines of the characters data frame to understand its structure\ndf_characters.head()",
          "Show the first few elements of the characters dataframe to understand its structure\ndf_characters.head()",
          " Display the first few rows of each dataframe to understand the data better\ndf_characters.head()",
          " Display the first few rows of each DataFrame to understand its structure\ndf_characters.head()",
          "display the first few rows of each dataframe to understand its structure\ndf_characters.head()",
          "View the first few rows of the dataframe to understand the data better\ndf_characters.head()",
          "Display the first few rows of each dataframe to understand its structure and contents.\ndf_characters.head()",
          "View the first 5 rows of the characters DataFrame to understand its structure and content\ndf_characters.head()",
          " Display the first few rows of the characters DataFrame to understand its structure.\ndf_characters.head()",
          "Display the first few rows of each dataframe to understand their structure\ndf_characters.head()",
          "Looking at the first few rows of the characters dataset to understand its structure and contents\nprint(df_characters.head())",
          " Print first rows of the dataframe to understand the data structure\nprint(df_characters.head())",
          "Inspect the first few rows of each dataframe to understand its structure and content\ndf_characters.head()",
          " Display the first few rows of the dataframe to understand its structure\ndf_characters.head()",
          " Visualize the first few rows of each dataframe to understand its structure\ndf_characters.head()"
         ],
         "marker": {
          "opacity": 0.5,
          "size": 5
         },
         "mode": "markers+text",
         "name": "96_Understanding the structure of the characters dataframe by displaying its first few rows",
         "text": [
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          ""
         ],
         "textfont": {
          "size": 12
         },
         "type": "scattergl",
         "x": [
          3.574429512023926,
          4.007792949676514,
          3.8884124755859375,
          4.002033710479736,
          4.0418477058410645,
          3.487870693206787,
          3.698249340057373,
          3.781529426574707,
          3.7633090019226074,
          3.4761743545532227,
          3.5688376426696777,
          3.358102798461914,
          3.6608848571777344,
          3.5519511699676514,
          1.8956738710403442,
          3.863896369934082,
          4.313465595245361,
          3.81215500831604,
          3.746429443359375,
          3.575802803039551,
          4.169159412384033,
          3.404700517654419,
          3.9931297302246094,
          3.4981331825256348,
          3.6482796669006348,
          4.425571441650391,
          3.7324233055114746,
          3.6830272674560547,
          3.8140108585357666,
          4.209090232849121
         ],
         "y": [
          17.274738311767578,
          16.248178482055664,
          16.95166015625,
          16.51905632019043,
          17.09714126586914,
          15.834543228149414,
          17.219833374023438,
          16.977346420288086,
          16.909900665283203,
          17.082401275634766,
          17.298934936523438,
          17.30058479309082,
          17.352401733398438,
          17.517383575439453,
          15.212467193603516,
          17.076658248901367,
          17.13949966430664,
          17.201467514038086,
          17.003189086914062,
          16.89081382751465,
          17.792509078979492,
          17.2458553314209,
          16.782533645629883,
          17.01953887939453,
          16.973770141601562,
          15.529043197631836,
          17.79618263244629,
          16.48579978942871,
          17.426847457885742,
          16.65070343017578
         ]
        },
        {
         "hoverinfo": "text",
         "hovertext": [
          "Merge the datasets",
          "Merge the datasets to get more context and consistency",
          "Merge datasets",
          "merging the datasets and looking at some examples",
          "FIREST, let's take a look at the schema of the data we have and decide how we should best merge it all together.",
          "Merge all the datasets to get the full dataset",
          "Merge datasets to get one big dataset",
          "Merge the datasets",
          "Merge the datasets to obtain a single dataset containing all the information needed for analysis.",
          " Merge the datasets based on their respective keys.",
          "Merge the datasets to make it more useful for analysis.",
          " Preprocesing - Merge datasets",
          "Merge all datasets",
          "Merge the datasets.",
          "Merge the datasets to get all the information at one place.",
          "Merging the datasets based on the IDs to create one large dataset.",
          " Merge the datasets",
          "Fixing types and merging datasets",
          "Merge datasets to simplify analysis",
          "Merge the datasets",
          " Combining all the different datasets",
          " Combine and sort the datasets based on the key IDs",
          "Merge the datasets together to create a single coherent dataset.",
          "Merge the files",
          "Merge datasets",
          " Merge data to enrich dataset",
          " Merge the datasets",
          "Merge the datasets on foreign keys",
          "Merge all the datasets based on the common column (id)"
         ],
         "marker": {
          "opacity": 0.5,
          "size": 5
         },
         "mode": "markers+text",
         "name": "97_Merging Datasets",
         "text": [
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          ""
         ],
         "textfont": {
          "size": 12
         },
         "type": "scattergl",
         "x": [
          9.661069869995117,
          9.943281173706055,
          9.923524856567383,
          9.40796947479248,
          10.290925979614258,
          9.61958122253418,
          9.359965324401855,
          9.714651107788086,
          9.549478530883789,
          9.8305082321167,
          10.11577320098877,
          9.921493530273438,
          9.5466890335083,
          10.139270782470703,
          9.633233070373535,
          9.631067276000977,
          9.830734252929688,
          10.16858196258545,
          9.961773872375488,
          9.56831169128418,
          9.506620407104492,
          9.424209594726562,
          9.88292121887207,
          10.354565620422363,
          9.990755081176758,
          10.195311546325684,
          9.752998352050781,
          9.90147590637207,
          9.423203468322754
         ],
         "y": [
          -0.775830864906311,
          -0.6854009032249451,
          -0.42464616894721985,
          -0.6092526912689209,
          -0.11851540207862854,
          -0.9616194367408752,
          -0.4040786623954773,
          -0.5475029945373535,
          -0.4392533600330353,
          -0.43285563588142395,
          -0.6143152713775635,
          -0.06472219526767731,
          -0.4443051517009735,
          -0.7524576187133789,
          -0.7456499934196472,
          -0.3939402997493744,
          -0.6604800820350647,
          -0.21498598158359528,
          -0.5134743452072144,
          -0.49228930473327637,
          -0.4488627314567566,
          -0.42758500576019287,
          -0.880443811416626,
          -0.18344685435295105,
          -0.39458951354026794,
          -0.4449831545352936,
          -0.5500125288963318,
          -0.37450045347213745,
          -0.11473696678876877
         ]
        },
        {
         "hoverinfo": "text",
         "hovertext": [
          "Hide warnings\nimport warnings\nwarnings.filterwarnings('ignore')",
          " optionally suppress some warnings\nimport warnings\nwarnings.simplefilter(\"ignore\", UserWarning)",
          "Hide warnings\nimport warnings\nwarnings.filterwarnings('ignore')",
          "Remove annoying SettingWithCopyWarning",
          " Disabling the Warnings\nimport warnings\nwarnings.filterwarnings('ignore')",
          "\nimport warnings\nwarnings.filterwarnings('ignore')",
          "مimport warnings\nwarnings.filterwarnings('ignore')",
          "Hide all warnings\nimport warnings\nwarnings.filterwarnings('ignore')",
          "Ignore certain warnings\nimport warnings\nwarnings.filterwarnings('ignore')",
          "\nimport warnings\nwarnings.filterwarnings('ignore')",
          "Set styles and ignore warnings",
          "Ignore the warnings\nimport warnings\nwarnings.filterwarnings('ignore')",
          "Ignore deprication warnings\nimport warnings\nwarnings.filterwarnings(\"ignore\", category=DeprecationWarning)",
          "I disabled the warning about the settingwithcopywarning.",
          "Project settings\nimport warnings\nwarnings.filterwarnings(\"ignore\")",
          " Ignore the warnings\nimport warnings\nwarnings.filterwarnings('ignore')",
          "Ignore warnings\nimport warnings\nwarnings.filterwarnings('ignore')",
          "ignore warnings\nimport warnings\nwarnings.filterwarnings('ignore')",
          "Ignore all future warnings to improve readibility, since they clutter the output too much\nimport warnings\nwarnings.simplefilter(action='ignore', category=FutureWarning)",
          "Hide warnings (this is usually a bad idea, but just for this exercise)",
          "Optional: Disable warnings\nimport warnings\nwarnings.filterwarnings('ignore')",
          "# Enable extra logging for debugging (set to False for normal operation)\nDEBUG = False",
          " To display logger output\nimport logging",
          "import warnings",
          "Hide warning messages\nimport warnings\nwarnings.filterwarnings('ignore')",
          "%%\n#warning\n",
          "Set up logging\nimport logging",
          " Set logging level\nimport logging\nlogging.getLogger().setLevel(logging.CRITICAL)",
          "Hide warnings\nimport warnings\nwarnings.filterwarnings('ignore')"
         ],
         "marker": {
          "opacity": 0.5,
          "size": 5
         },
         "mode": "markers+text",
         "name": "98_Warning Management",
         "text": [
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          ""
         ],
         "textfont": {
          "size": 12
         },
         "type": "scattergl",
         "x": [
          18.20047950744629,
          17.33910369873047,
          18.162078857421875,
          17.41359519958496,
          17.080373764038086,
          17.202030181884766,
          16.966175079345703,
          18.19146156311035,
          17.409963607788086,
          17.162460327148438,
          18.095867156982422,
          17.346099853515625,
          17.232872009277344,
          17.40007209777832,
          16.98790740966797,
          17.302175521850586,
          17.3153133392334,
          17.554349899291992,
          17.787757873535156,
          17.804706573486328,
          17.320131301879883,
          16.557353973388672,
          16.094633102416992,
          16.529760360717773,
          17.720901489257812,
          17.110618591308594,
          15.646132469177246,
          16.293508529663086,
          17.834304809570312
         ],
         "y": [
          4.6925177574157715,
          4.530151844024658,
          4.576405048370361,
          4.932920932769775,
          4.385833263397217,
          4.99395751953125,
          4.808770179748535,
          4.438063621520996,
          4.797119140625,
          4.953085899353027,
          4.390002727508545,
          4.652158260345459,
          4.713348865509033,
          4.678589344024658,
          4.910923004150391,
          4.95424747467041,
          4.953551769256592,
          4.9461517333984375,
          4.938572883605957,
          4.554496765136719,
          4.714183807373047,
          3.956993818283081,
          3.483384370803833,
          4.488191604614258,
          4.418269634246826,
          4.557476997375488,
          3.5913596153259277,
          4.244793891906738,
          4.6425018310546875
         ]
        },
        {
         "hoverinfo": "text",
         "hovertext": [
          "We will explore the dataframes first by looking at the first few rows of each dataframe.",
          " Let's start by looking at what's in the dataframes",
          " First, let's take a look at the data quickly by looking at the first few entries of each dataframe.",
          " Let's start by inspecting the structure of the dataframes.",
          "We start by examining the first few rows of each dataframe.",
          "Let's start by looking at the first few entries of each DataFrame.",
          " Let's start by having a look at a few rows of each of our dataframes.",
          " Let us first take a look at the structure of the data of each dataframe.",
          "Let's start by taking a quick look at the first rows of each dataframe.",
          "Start by exploring the first few rows of each dataframe.",
          " Let's start by exploring the data in each DataFrame to see what we're working with.",
          " Let's start by taking a look at the structure and content of each of these dataframes.",
          "We can then start by exploring the content of each Dataframe.",
          "We'll start by exploring the data in each of these dataframes.",
          " Let's start by taking a look at the first few rows of each dataframe.",
          "We'll start by taking a look at the first few lines of each of our DataFrames.",
          " Let's start by taking a look at the first few rows of each dataframe.",
          " Let's start by taking a look at the first few rows of each DataFrame.",
          "Let's start by looking at the structure of the dataframes and the first few rows of each dataframe.",
          " Let's start by taking a look at the first few rows of each of these DataFrames.",
          "Let's start by taking a look at the structure of each dataframe.",
          "First, let's explore the data and look at the first few rows of each dataframe.",
          " Let's start by taking a look at the first few rows of each dataframe.",
          "We will start by inspecting the unique values contained in these dataframes.",
          "We can now start to take a look at the data with a simple head of each dataframe.",
          "Let's start by taking a look at the first few lines of each dataframe.",
          "To get started, let's take a look at the first few rows of each dataframe to understand what kind of data we're working with.",
          "Let's start by taking a look at the first few rows of each dataframe.",
          "Let's first familiarize with data topics by first exploring the structure of each DataFrame."
         ],
         "marker": {
          "opacity": 0.5,
          "size": 5
         },
         "mode": "markers+text",
         "name": "99_Exploring DataFrames and Familiarizing with First Few Rows",
         "text": [
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          ""
         ],
         "textfont": {
          "size": 12
         },
         "type": "scattergl",
         "x": [
          11.259450912475586,
          10.380650520324707,
          10.845484733581543,
          10.4737548828125,
          11.166749954223633,
          10.820326805114746,
          10.433431625366211,
          9.390506744384766,
          10.754404067993164,
          11.041187286376953,
          9.69946002960205,
          9.651482582092285,
          10.406722068786621,
          10.265117645263672,
          10.549931526184082,
          10.705994606018066,
          10.70769214630127,
          10.432762145996094,
          10.694390296936035,
          10.718547821044922,
          9.805927276611328,
          11.076194763183594,
          10.81908130645752,
          10.58425521850586,
          9.733772277832031,
          10.294679641723633,
          9.858682632446289,
          10.445281028747559,
          10.206629753112793
         ],
         "y": [
          -6.115280628204346,
          -5.530313968658447,
          -6.2470550537109375,
          -5.904116153717041,
          -6.711877822875977,
          -5.8226470947265625,
          -5.366241455078125,
          -6.067050933837891,
          -6.366959571838379,
          -6.16065788269043,
          -5.983598232269287,
          -6.405943870544434,
          -5.395447254180908,
          -5.762035846710205,
          -5.821423530578613,
          -4.941518306732178,
          -6.086155891418457,
          -6.165702819824219,
          -6.354584217071533,
          -6.246475696563721,
          -6.216190814971924,
          -6.663430690765381,
          -5.920864582061768,
          -5.698042392730713,
          -5.767192363739014,
          -5.629558086395264,
          -6.471927165985107,
          -5.810512542724609,
          -6.713274955749512
         ]
        },
        {
         "hoverinfo": "text",
         "hovertext": [
          "# Function to display the wordcloud\ndef plot_wordcloud(wordcloud):\n    plt.imshow(wordcloud, interpolation='bilinear')\n    plt.axis(\"off\")",
          " Generate wordcloud of the most common character names\nwordcloud = WordCloud(background_color='white',\n                      width=1600,\n                      height=800,\n                      max_words=50).generate_from_frequencies(dict(df_characters['name'].value_counts(normalize=False)))\n\nplt.figure(1, figsize=(16, 8))\nplt.imshow(wordcloud)\nplt.axis('off')\nplt.show()",
          "Visualizations\n# Wordcloud of the most common words of the script\nall_words = ' '.join(df_script['normalized_text'].values)\nwordcloud = WordCloud(width = 1000, height = 500).generate(all_words)\n\nplt.figure(figsize=(15,8))\nplt.imshow(wordcloud, interpolation='bilinear')\nplt.axis('off')",
          "WordCloud generates word cloud data.\nnlp = spacy.load(\"en_core_web_sm\")\n\n# Remove duplicates and missing values in the data\ndf_script = df_script.drop_duplicates(['episode_id', 'number']).dropna()\n\n# Iterating over each row and generating the word cloud for every episode\nfor episode_id, episode_df in tqdm(df_script.groupby('episode_id'), total=len(df_script['episode_id'].unique())):\n    text = ' '.join(episode_df['raw_text'])\n    \n    doc = nlp(text)\n    \n    words = [token.text for token in doc if token.is_alpha and not token.is_stop and len(token.text) > 2]\n    \n    word_freq = Counter(words)\n    \n    wc = WordCloud(width=800, height=800, margin=10).generate_from_frequencies(word_freq)\n    \n    plt.imshow(wc, interpolation='bilinear')\n    plt.axis('off')\n    plt.savefig(f'episode_wordclouds/{episode_id}.png')",
          "Dependencies:\n# pandas\n# numpy\n# spacy\n# matplotlib\n# wordcloud\n# tqdm",
          "Helper function\ndef show_wordcloud(text):\n    # Create and generate a word cloud image:\n    wordcloud = WordCloud().generate(text)\n\n    # Display the generated image:\n    plt.imshow(wordcloud, interpolation='bilinear')\n    plt.axis(\"off\")\n    plt.show()",
          "Create a word cloud of the most common words in the script lines\nscript = \" \".join(df_script.raw_text.values)\nwordcloud = WordCloud(width = 2000, height = 1000, random_state=1, background_color='black',\n                      colormap='Set2', collocations=False, stopwords = WordCloud.STOPWORDS,\n                     max_words=50).generate(script)\n\n# Plot the word cloud\nplt.figure(figsize=(20, 10), facecolor=None)\nplt.imshow(wordcloud, interpolation=\"bilinear\")\nplt.axis('off')\nplt.tight_layout(pad=0)\n\nplt.show()",
          "Words clouds for most common words in Simpson show\n# Prepare data\ntext = ' '.join(df_script.raw_text.fillna(''))\n\n# Generate word cloud\nwordcloud = WordCloud(width = 800, height = 400, \n                background_color ='black', \n                min_font_size = 10).generate(text)\n\n# plot the WordCloud image                        \nplt.figure(figsize = (8, 8), facecolor = None) \nplt.imshow(wordcloud) \nplt.axis(\"off\") \nplt.tight_layout(pad = 0)",
          "Function to display word cloud for a given text\ndef plot_wordcloud(text, title, ax, max_words=200, stopwords=None):\n    # Generate the word cloud\n    wordcloud = WordCloud(width=800, height=400, background_color='white', max_words=max_words, colormap='viridis', stopwords=stopwords).generate(text)\n\n    # Display the word cloud using matplotlib\n    ax.imshow(wordcloud, interpolation='bilinear')\n    ax.set_title(title)\n    ax.axis('off')\n    return ax",
          "Define a function to plot word cloud for given text.",
          " Set up a nice background for the wordcloud\nbackground = np.array(Image.open('data/homer.png'))",
          "A 100% of the wordcloud is being shown\nmatplotlib.rcParams['figure.figsize'] = [20, 12]",
          "Merge characters and script tables on character_id\ndf = pd.merge(df_script, df_characters, left_on='character_id', right_on='id')\n\n# Get the main characters' names\nmain_characters = list(df['name'].value_counts().head(10).index)\n\n# Plot function\ndef plot_wordclouds(data, title):\n    # Instantiate wordcloud\n    wc = WordCloud(background_color='white', max_words=100)\n\n    # Generate word cloud\n    wc.generate_from_frequencies(data)\n\n    # Plot\n    plt.figure(figsize=(10, 5))\n    plt.imshow(wc, interpolation='bilinear')\n    plt.axis('off')\n    plt.title(title)",
          " Helper function to display an image\ndef display_wordcloud(wordcloud):\n    plt.figure(figsize=(10, 5))\n    plt.imshow(wordcloud, interpolation='bilinear')\n    plt.axis(\"off\")",
          "Word cloud function\ndef plot_wordcloud(words, title, save_as=None):\n    word_cloud = WordCloud(width = 1000, height = 500, background_color='black', stopwords=STOPWORDS).generate(words)\n\n    plt.figure(figsize=(15,8))\n    plt.imshow(word_cloud)\n    plt.title(title, fontdict={'size':20})\n    plt.axis('off')\n\n    if save_as:\n        plt.savefig(save_as, format='png')\n        plt.close()\n    else:\n        plt.show()",
          "Visualisationgies\nfontsize, collocations=False, random_state=42).generate_from_frequencies(word_freq)\nplt.figure(figsize=(12,10))\nplt.imshow(wordcloud, interpolation='bilinear')\nplt.axis(\"off\")\nplt.show()",
          "Function to display a word cloud\ndef plot_wordcloud(text, title, image_name):\n    wordcloud = WordCloud(width = 800, height = 800, \n                background_color ='black', \n                stopwords = None, \n                min_font_size = 10).generate(text)\n    # set the figsize\n    plt.figure(figsize = (8, 8), facecolor = None) \n    plt.imshow(wordcloud) \n    plt.axis(\"off\") \n    plt.tight_layout(pad = 0) \n    plt.title(title, fontsize=20)\n    plt.savefig(f'images/{image_name}.png')\n    plt.show()",
          " Visualize the number of lines per character\ncharacter_name = 'homer simpson'\ncharacter_lines = df_script[df_script['character_id'] == character_name]['raw_character_text']\n\n# Generate the word cloud\nwordcloud = WordCloud(width = 1000, height = 500).generate(' '.join(character_lines))\n\n# Plot the word cloud\nplt.figure(figsize=(15, 5))\nplt.imshow(wordcloud, interpolation='bilinear')\nplt.axis(\"off\")",
          "cosine similarity between two word vectors\ndef get_cosine_similarity(x, y):\n    return np.dot(x, y) / (np.linalg.norm(x) * np.linalg.norm(y))",
          "Wordcloud on character's names\n# Convert the list of character's names to a single string\nall_names = df_characters['name'].str.cat(sep=' ')\n\n# Create a WordCloud object\nwordcloud = WordCloud(width=800, height=400, max_font_size=150, background_color='black').generate(all_names)\n\n# Display the word cloud using matplotlib\nplt.figure(figsize=(10, 5))\nplt.imshow(wordcloud, interpolation='bilinear')\nplt.axis('off')\nplt.show()",
          "Set up the wordcloud\nfig, ax = plt.subplots(1, 1, figsize=(15, 15))\nwc = WordCloud(width=800, height=800, background_color='white', max_words=150, relative_scaling=0.5).generate(' '.join(df_script['raw_text'].values))\nax.imshow(wc)\nax.axis('off')",
          " Helper function to display a word cloud\ndef plot_wordcloud(wordcloud):\n    plt.figure(figsize=(10, 5))\n    plt.imshow(wordcloud, interpolation='bilinear')\n    plt.axis(\"off\")",
          "peat word cloud code for character dialogues\nwordcloud = WordCloud(width = 1000, height = 500, max_font_size = 110, collocations = False).generate(characters_dialogues_text)\nplt.figure(figsize=(16, 8))\nplt.imshow(wordcloud, interpolation=\"bilinear\")\nplt.axis('off')",
          "# Set up word cloud\nmatplotlib.rcParams['figure.figsize'] = (12, 12)\nwordcloud = WordCloud(width = 4000, height = 4000, \n                background_color ='white', \n                stopwords = None, \n                min_font_size = 10)",
          "Generating the wordcloud for an episode script line\ndef generate_wordcloud(episode_id, char_name=None, loc_name=None):\n    \"\"\"\n    Generate the wordcloud for a specific episode and an optional character and location appearing in it\n    \n    Args:\n    - episode_id: integer, identifier of the episode\n    - char_name: string, name of the character\n    - loc_name: string, name of the location\n\n    Returns:\n    - wordcloud: wordcloud object\n    - doc: spacy document\n    - counter_words: counter object\n    \"\"\"\n    # Retuning results\n    return wordcloud, doc, counter_words",
          "Extracts the text column of a dataframe, creates a word cloud and plots it.",
          "Functions for plotting WordClouds",
          " Helper function to visualize a word cloud\ndef plot_wordcloud(wordcloud):\n    plt.figure(figsize=(10, 5))\n    plt.imshow(wordcloud, interpolation='bilinear')\n    plt.axis(\"off\")",
          "Utility functions\ndef generate_wordcloud(text):\n    wordcloud = WordCloud(width=800, height=400, max_font_size=100, background_color=\"white\").generate(text)\n    plt.figure(figsize=(15, 10))\n    plt.imshow(wordcloud, interpolation=\"bilinear\")\n    plt.axis('off')\n    plt.show()"
         ],
         "marker": {
          "opacity": 0.5,
          "size": 5
         },
         "mode": "markers+text",
         "name": "100_Word Cloud Visualization",
         "text": [
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          ""
         ],
         "textfont": {
          "size": 12
         },
         "type": "scattergl",
         "x": [
          12.379876136779785,
          11.50748348236084,
          11.802128791809082,
          11.363069534301758,
          13.233839988708496,
          12.794885635375977,
          11.801785469055176,
          11.227839469909668,
          12.655973434448242,
          12.152748107910156,
          12.306230545043945,
          13.333630561828613,
          11.578533172607422,
          12.991352081298828,
          12.602958679199219,
          11.921881675720215,
          12.613144874572754,
          11.424859046936035,
          10.381272315979004,
          11.822972297668457,
          12.262601852416992,
          12.69612979888916,
          12.63847827911377,
          13.269821166992188,
          11.996261596679688,
          11.989029884338379,
          12.711278915405273,
          12.62272834777832,
          12.581278800964355
         ],
         "y": [
          8.013984680175781,
          8.67724895477295,
          8.864444732666016,
          8.165803909301758,
          9.607728004455566,
          7.885747909545898,
          8.807385444641113,
          8.362333297729492,
          8.72825813293457,
          7.894323825836182,
          8.090410232543945,
          8.544379234313965,
          8.937419891357422,
          8.069887161254883,
          8.40478515625,
          8.641398429870605,
          8.640169143676758,
          8.753889083862305,
          8.963132858276367,
          8.922073364257812,
          8.769492149353027,
          8.339259147644043,
          7.439551830291748,
          8.567313194274902,
          7.273816108703613,
          8.648787498474121,
          8.408419609069824,
          8.488212585449219,
          8.101818084716797
         ]
        },
        {
         "hoverinfo": "text",
         "hovertext": [
          "A_D = {'she': 'Marge', 'her': 'Marge', \"he\": \"Homer\", \"him\": \"Homer\"}",
          " Character we are interested in\ncharacter_name = \"Bart Simpson\"",
          " Select only the lines for the 8 main characters\nmain_characters = [\n    'marge simpson',\n    'homer simpson',\n    'bart simpson',\n    'lisa simpson',\n    'maggie simpson',\n    'ned flanders',\n    'seymour skinner',\n    'milhouse van houten'\n]",
          "Select only The Simpsons family member\nmain_characters = [\n    'marge', 'homer', 'bart', 'lisa', 'maggie', \n    'abraham', 'patty', 'selma', 'krusty'\n]\n\n# Scraped from URL\nplayable_characters = [\n    'ned', 'apu', 'moe', 'skinner', 'flanders',\n    'barney', 'lenny', 'carl', 'duffman', \n    'snake', 'otto', 'manjula', 'bont', 'herman', \n    'jasper', 'hibbert', 'milhouse', 'ralph', \n    'wiggum', 'frink', 'edna', 'lovejoy', 'nelson', \n    'carlson', 'quimby', 'stampy', 'krabappel', \n    'snake', 'willie'\n]\n\n# Combine the two lists of characters\ncharacters = main_characters + playable_characters\n",
          "Reduce dataset to only relevant characters\ncharacters = [\n    \"Lisa Simpson\",\n    \"Bart Simpson\",\n    \"Marge Simpson\",\n    \"Homer Simpson\",\n    \"Maggie Simpson\",\n    \"Charles Montgomery Burns\",\n    \"Milhouse Van Houten\",\n    \"Ned Flanders\",\n    \"Principal Skinner\",\n    \"Lenny Leonard\",\n    \"Carl Carlson\",\n    \"Waylon Smithers\",\n    \"Krusty the Clown\",\n    \"Grampa Simpson\",\n    \"Dr. Julius Hibbert\",\n    \"Selma Bouvier\",\n    \"Patty Bouvier\",\n    \"Kent Brockman\",\n    \"Edna Krabappel\",\n    \"Nelson Muntz\",\n    \"Sherri and Terri\",\n    \"Jimbo Jones\",\n    \"Martin Prince\",\n    \"Seymour Skinner\",\n    \"Rod Flanders\",\n    \"Todd Flanders\",\n    \"Moe Szyslak\",\n    \"Barney Gumble\",\n    \"Kirk Van Houten\",\n    \"Luann Van Houten\",\n    \"Apu Nahasapeemapetilon\",\n    \"Ralph Wiggum\",\n    \"Chief Wiggum\",\n    \"Snake Jailbird\",\n    \"Judge Constance Harm\"\n]",
          "\n# Retaining only the main characters from Simpsons character data\nmain_characters = [\n    \"marge\", \n    \"homer\",\n    \"bart\",\n    \"lisa\",\n    \"maggie\",\n    \"skinner\",\n    \"ned\",\n    \"burns\",\n    \"moe\",\n    \"krusty\",\n    \"milhouse\",\n    \"chief\",\n    \"abraham\",\n    \"edna\",\n    \"ralph\",\n    \"apu\",\n    \"barney\",\n    \"nelson\",\n    \"kent\",\n    \"waylon\"\n]",
          "hansoo = ['Homer Simpson', 'Marge Simpson', 'Bart Simpson', 'Lisa Simpson', 'Maggie Simpson', \n          'Ned Flanders', 'Krusty the Clown', 'Milhouse Van Houten', 'Chief Wiggum', 'Grampa Simpson', \n          'Lenny Leonard', 'Mayor Quimby', 'Nelson Muntz', 'Principal Skinner', 'Sideshow Bob', \n          'C. Montgomery Burns', 'Comic Book Guy', 'Edna Krabappel', 'Moe Szyslak', 'Apu Nahasapeemapetilon', \n          'Kent Brockman', 'Waylon Smithers', 'Ralph Wiggum', 'Groundskeeper Willie', 'Martin Prince', \n          'Doctor Hibbert', 'Officer Lou', 'Mrs. Krabappel']",
          "Extract main characters\nmain_characters = [\"homer\", \"marge\", \"bart\", \"lisa\", \"maggie\", \"skinner\", \"ned\", \"burns\", \"milhouse\", \"moe\", \n                   \"krusty\", \"edna\", \"sideshow\", \"apu\", \"chief\", \"barney\", \"carl\", \"lenny\", \"duffman\", \"selma\", \n                   \"patty\", \"ralph\", \"nelson\", \"todd\", \"mcbain\", \"groundskeeper\", \"maggie's\", \"waylon\", \"rod\", \n                   \"troy\", \"helen\", \"fat tony\", \"lionel\", \"gary\", \"karl\", \"frink\"]",
          " Apply Character and Location Filter\ncharacter_list = ['homer simpson', 'marge simpson', 'bart simpson', 'lisa simpson', 'maggie simpson', 'grampa simpson',\n                  'ned flanders', 'moe szyslak', 'krusty the clown', 'chief wiggum',\n                  'lenny leonard', 'carl carlson', 'waylon smithers', 'milhouse van houten', 'edna krabappel',\n                  'kent brockman', 'nelson muntz', 'apu nahasapeemapetilon', 'sideshow bob',\n                  'reverend lovejoy', 'mrs. krabappel', 'principal skinner', 'mrs. simpson', 'hugo simpson']\n\nlocation_list = ['simpson home', 'moe\\'s tavern', 'springfield nuclear power plant', 'kwik-e-mart',\n                 'springfield elementary school', 'kitchen', 'jake\\'s unisex hair palace', 'springfield street']",
          "Dude, select the specific character we are  gonna be using\ncharacter_name = \"Bart Simpson\"",
          "Filter out boring Simpsons characters",
          "Extract the main characters\nmain_characters = ['marge', 'homer', 'bart', 'lisa', 'maggie', 'skinner', 'ned', 'krabappel', 'burns', 'milhouse', 'moe',\n                   'comic', 'carl', 'lenny', 'apu', 'duffman', 'barney', 'abraham', 'edna', 'jimbo', 'nelson', 'patty',\n                   'selma', 'waylon', 'mrburns', 'reverend', 'snake', 'willie', 'karl', 'ralph', 'troy', 'lionel', 'hawk',\n                   'artie', 'snowball', 'herb', 'maggie', 'frink', 'jasper', 'kishimoto', 'montgomery', 'hans', 'lou',\n                   'krusty', 'barney', 'barney', 'mayor', 'sideshow', 'krustofsky', 'robert', 'lucas', 'luann']\ndf_script = df_script[df_script.raw_character_text.str.lower().isin(main_characters)]",
          "Define character name either KILLER (The murderer or being killed) or VICTIM (The person being killed or the victim of the murderer).",
          " Extracting the main characters and locations\nmain_characters = [\n    'marge', 'homer', 'bart', 'lisa', 'maggie',\n    'ned', 'flanders', 'moe', 'krusty', 'milhouse',\n    'chief', 'edna', 'selma', 'patty', 'lenny',\n    'carl', 'cletus', 'professor', 'snake', 'apu',\n    'rainier', 'seymour', 'waylon', 'nelson', 'ralph',\n    'barney', 'patty', 'martin', 'hans'\n]\n\nmain_locations = [\n    'Simpson House', 'Springfield Elementary School', 'Springfield Nuclear Power Plant',\n    'Kwik-E-Mart', 'Moe\\'s Tavern', 'Springfield Retirement Castle', 'Springfield',\n    '742 Evergreen Terrace', 'Springfield Town Hall', 'Burns Manor', 'Ned Flanders\\' House'\n]",
          "Create character roles\nmain_characters = [\n    \"marge_simpsons\", \"homer_simpsons\", \"bart_simpson\",\n    \"lisa_simpson\", \"maggie_simpson\", \"abraham_grampa_simpson\",\n    \"ned_flanders\", \"moe_szyslak\", \"krusty_the_clown\",\n    \"chief_wiggum\", \"charles_montgomery_burns\", \"milhouse_van_houten\",\n    \"seymour_skinner\", \"nelson_muntz\", \"edna_krabappel\",\n    \"lenny_leonard\", \"carl_carlson\", \"waylon_smithers\", \"kent_brockman\"\n]\n\nsupporting_characters = [\n    \"apu_nahasapeemapetilon\", \"comic_book_guy\", \"ralph_wiggum\",\n    \"english\", \"snake_jailbird\", \"kent_brockman\", \"mayor_quimby\",\n    \"barney_gumble\", \"selma_bouvier\", \"patty_bouvier\",\n    \"martin_prince\", \"troy_mcclure\", \"lionel_hutz\", \"groundskeeper_willie\",\n    \"fat_tony\", \"professor_john_frink\", \"dr_julius_hibbert\",\n    \"cletus_spuckler\", \"otto_mann\"\n]\n\n# This role list is not exhaustive\nminor_characters = [\n    \"apu_nahasapeemapetilon\", \"milhouse_van_houten\",\n    \"comic_book_guy\", \"snake_jailbird\", \"troy_mcclure\",\n    \"kent_brockman\", \"martin_prince\", \"ralph_wiggum\",\n    \"mayor_quimby\", \"edna_krabappel\"\n]",
          "Visualise the top characters in The Simpsons",
          "Select main characters identified by the community\nmain_characters = [\"bart\", \"homer\", \"marge\", \"lisa\", \"maggie\", \"krusty\", \"burns\", \"milhouse\", \"chief\", \"skinner\", \"n edna\", \"bob\", \"apu\", \"moe\", \"ned\"]",
          "Get the names of the characters in the Simpsons",
          "Extract main characters\nmain_characters = [\n    \"marge\", \"bart\", \"homer\", \"lisa\", \"maggie\",\n    \"kirk\", \"otto\", \"duffman\", \"selma\", \"patty\",\n    \"milhouse\", \"krusty\", \"apu\", \"moe\", \"carl\",\n    \"lenny\", \"ned\", \"cletus\", \"barney\", \"ralph\",\n    \"wiggum\", \"skinner\", \"hibbert\", \"frink\", \"snake\",\n    \"burns\", \"nelson\", \"edna\", \"rod\", \"todd\",\n    \"lovejoy\", \"apu\", \"frink\", \"fat tony\", \"duff\",\n    \"flanders\", \"bob\", \"artie\", \"sanjay\", \"ruth\",\n    \"sideshow\", \"tahiti bob\", \"tahiti bob\", \"disco stu\", \"wiggum\",\n    \"skinner\", \"krustofski\", \"lampwick\", \"krusty\", \"mccallister\", \n    \"lenford\", \"leopold\", \"selma\", \"patty\", \"shary\", \"edna\",\n    \"horatio\", \"junun\", \"roscoe\", \"chase\", \"chase\", \"thompson\", \n    \"frederick\", \"harvest\", \"eve\", \"martha\", \"lou\"\n]",
          "Where are Simpsons Characters mentioned the most.",
          "hood_character(e.g. Homer Simpson, Marge Simpson, Mr. Burns), name of the characterhood_location(e.g. Street Name, House of Ned Flanders), name of the location, dialogue(Text by character), timestamp_in_ms(Millisecond of dialogue)",
          "Limiting the data to only Marge, Lisa, and Bart.",
          "Find the set of all episodes that feature the character \"Marge\"",
          "Selecting the main characters of the Simpsons",
          "Find the most common professions of characters in The Simpsons",
          "Filter for the regular characters only\nmain_characters = [\n    'marge', 'homer', 'bart', 'lisa', 'maggie', 'chief_wiggum', 'moe', 'ned', 'skinner',\n    'patty', 'selma', 'milhouse', 'krusty', 'burns', 'moe', 'ted', 'apu', 'barney', 'lenny',\n    'carl', 'waylon_smithers', 'nelson', 'jimbo', 'martin', 'professor_frink', 'snake', \n    'cletus', 'edna', 'rainier_wolfcastle', 'simpsons'\n]",
          "Filter the main characters of the Simpsons series",
          "filter main characters\nmain_characters = [\n    \"marge\",\n    \"homer\",\n    \"bart\",\n    \"lisa\",\n    \"maggie\",\n    \"grampa\",\n    \"abraham jay simpson\",\n    \"krusty\",\n    \"sideshow bob\",\n    \"charles montgomery burns\",\n    \"milhouse\",\n    \"chief wiggum\",\n    \"ned flanders\",\n    \"apu\",\n    \"moe\",\n    \"professor frink\",\n    \"barney\",\n    \"troy mcclure\",\n    \"lionel hutz\",\n    \"selma\",\n    \"patty\",\n    \"mayor quimby\",\n    \"waylon smithers\",\n    \"edna krabappel\",\n    \"dr. hibbert\",\n    \"reverend lovejoy\",\n    \"kent brockman\",\n    \"miss hoover\",\n    \"miss krabappel\",\n    \"groundskeeper willie\",\n    \"otto\",\n    \"maude flanders\",\n]",
          "Define name of character\nname = \"Homer Simpson\""
         ],
         "marker": {
          "opacity": 0.5,
          "size": 5
         },
         "mode": "markers+text",
         "name": "101_The Simpsons - Main Characters and Locations",
         "text": [
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          ""
         ],
         "textfont": {
          "size": 12
         },
         "type": "scattergl",
         "x": [
          8.643101692199707,
          10.420002937316895,
          9.212230682373047,
          9.105023384094238,
          9.539421081542969,
          9.665777206420898,
          10.222909927368164,
          9.293213844299316,
          9.788054466247559,
          9.960262298583984,
          9.599343299865723,
          8.492979049682617,
          10.448936462402344,
          9.921319961547852,
          9.918675422668457,
          10.70262336730957,
          9.624757766723633,
          10.316170692443848,
          9.168722152709961,
          10.364977836608887,
          10.17924690246582,
          10.210149765014648,
          9.158071517944336,
          10.034828186035156,
          10.685494422912598,
          9.547979354858398,
          9.607952117919922,
          9.663928985595703,
          10.263893127441406
         ],
         "y": [
          7.5059638023376465,
          6.52034330368042,
          6.474789619445801,
          7.077290058135986,
          6.8491621017456055,
          6.8204264640808105,
          7.1845574378967285,
          7.047359466552734,
          6.666128158569336,
          6.802826881408691,
          6.0943169593811035,
          7.313738822937012,
          7.092144966125488,
          7.090976715087891,
          7.008194923400879,
          6.585662841796875,
          7.171591758728027,
          6.232266902923584,
          7.104981422424316,
          6.508814334869385,
          6.271312236785889,
          6.276293754577637,
          5.736482620239258,
          6.570858001708984,
          6.699488639831543,
          7.067413806915283,
          6.056260585784912,
          6.849367618560791,
          6.835646629333496
         ]
        },
        {
         "hoverinfo": "text",
         "hovertext": [
          "Show the first rows of the characters dataframe\ndf_characters.head()",
          " Show first rows of the characters DataFrame\ndf_characters.head()",
          " Show first elements of df_characters\ndf_characters.head()",
          "# Show first rows\ndf_characters.head()",
          " Show first rows of characters dataframe\ndf_characters.head()",
          " Display the first rows from the characters dataframe\ndf_characters.head()",
          " Show first rows\ndf_characters.head()",
          "Displaying the first data frame (characters)\ndf_characters.head()",
          "Show the first rows of the characters dataframe\ndf_characters.head()",
          " Show first data frame\ndf_characters.head()",
          " Show the first rows of the characters data frame\ndf_characters.head()",
          "Show first row of data\ndf_characters.head(1)",
          "Display the first rows of the characters DataFrame\ndf_characters.head()",
          "Show the df_characters first entries\ndf_characters.head()",
          "Basic EDA\n# Show the first entries for the characters dataframe\ndf_characters.head()",
          "display the first rows of the df_characters dataframe\ndf_characters.head()",
          "# Show the first rows of the characters DataFrame\ndf_characters.head()",
          " Show the first entries for the characters table\ndf_characters.head()",
          " Display first rows of the characters dataframe\ndf_characters.head()",
          "- Display the first rows of the characters dataframe\ndf_characters.head()",
          "Display first and last rows of the characters DataFrame\nprint(df_characters.head(1))\nprint(df_characters.tail(1))",
          " Show first rows of the dataframe 'df_characters'\ndf_characters.head()",
          " Display first rows of df_characters\ndf_characters.head()",
          " Show first rows of df\ndf_characters.head()",
          " Display the first rows of the characters dataframe\ndf_characters.head()",
          " Displaying first characters in df_characters\ndf_characters.head()",
          "Display the first rows of the characters DataFrame\ndf_characters.head()",
          "Show first rows of the characters dataframe\ndf_characters.head()",
          "Show first rows of characters df\ndf_characters.head()"
         ],
         "marker": {
          "opacity": 0.5,
          "size": 5
         },
         "mode": "markers+text",
         "name": "102_Displaying first rows of data frame",
         "text": [
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          ""
         ],
         "textfont": {
          "size": 12
         },
         "type": "scattergl",
         "x": [
          1.4701731204986572,
          1.0362175703048706,
          1.2293680906295776,
          2.0556187629699707,
          1.1102837324142456,
          1.858521580696106,
          1.754404067993164,
          0.44396743178367615,
          1.500954508781433,
          0.6796530485153198,
          0.6826711893081665,
          1.6121550798416138,
          1.4772117137908936,
          0.9257336258888245,
          1.6388859748840332,
          1.2955219745635986,
          2.0729007720947266,
          1.5153634548187256,
          1.2465717792510986,
          1.7419281005859375,
          -3.5981087684631348,
          1.2841817140579224,
          1.262014627456665,
          1.5577994585037231,
          1.5582503080368042,
          1.036644697189331,
          1.4408676624298096,
          1.2603219747543335,
          1.3262771368026733
         ],
         "y": [
          19.190786361694336,
          18.976327896118164,
          18.463090896606445,
          17.84781837463379,
          18.917322158813477,
          18.451507568359375,
          17.85350227355957,
          19.067787170410156,
          19.21439552307129,
          19.03858757019043,
          19.23196792602539,
          17.444808959960938,
          18.391019821166992,
          18.097858428955078,
          18.959041595458984,
          18.40220069885254,
          18.247486114501953,
          17.364116668701172,
          18.504802703857422,
          18.5029354095459,
          21.967857360839844,
          18.961782455444336,
          17.81719207763672,
          18.221601486206055,
          18.331480026245117,
          18.536148071289062,
          18.51145362854004,
          18.972808837890625,
          18.318540573120117
         ]
        },
        {
         "hoverinfo": "text",
         "hovertext": [
          " Visualize number of lines per character\nline_counts = df_script['character_id'].value_counts()\nline_counts = line_counts.reset_index()\nline_counts.columns=['character_id', 'count']\nline_counts = line_counts.merge(df_characters, on='character_id')\nline_counts = line_counts.sort_values(by='count', ascending=False)\n\nfig, ax = plt.subplots(1,1,figsize=(15,10))\nax.bar(line_counts['name'][:30], line_counts['count'][:30])\nax.set_xlabel('Character')\nax.set_ylabel('Number of lines')\nax.set_title('Number of lines per character')\nax.set_xticklabels(line_counts['name'][:30], rotation=90)\nplt.show()",
          "Visualize the ten most frequent characters, locations and spoken words\n\n# Characters\ntop_characters = df_script['raw_character_text'].value_counts().head(10)\ntop_characters.plot(kind='barh', figsize=(12, 6), title='10 most frequent characters')\nplt.show()",
          " Get the top 10 characters with the most lines in the script\ntop10_characters = df_script['raw_character_text'].value_counts().head(10)\n\n# Define a bar plot for the top10_characters\nplt.figure(figsize=(10,10))\ntop10_characters.plot(kind='bar')\n\n# Set the title and labels\nplt.title('Top 10 Main Characters by Number of Lines')\nplt.xlabel('Character name')\nplt.ylabel('Number of lines')\n\n# Show the bar plot\nplt.show()",
          "Visualize each character's distribution of lines in the dataset\ndf_characters_count = df_script['raw_character_text'].value_counts()\ndf_characters_count = df_characters_count[df_characters_count > 50]  # Filter low count characters\n\n# Sort by value count\ndf_characters_count.sort_values(inplace=True)\n\n# Plot histogram\nplt.barh(df_characters_count.index, df_characters_count.values)\nplt.title('Character line count distribution')\nplt.xlabel('Line count')\nplt.ylabel('Character')\nplt.show()",
          " Visualize the number of lines per character\n# Number of dialog lines per character (in descending order)\nlines_per_character = df_script['character_id'].value_counts()\n\n# Only keep the 20 most frequent characters\ntop_20_characters = lines_per_character.head(20)\ntop_20_characters_list = top_20_characters.index.tolist()\n\n# Data frame containing only the top 20 characters\ntop_20_characters_df = df_script[df_script['character_id'].isin(top_20_characters_list)]\n\n# Count the number of lines per character\nlines_per_character = top_20_characters_df['character_id'].value_counts()\n\n# Create a barplot of the number of lines per character\nplt.figure(figsize=(20,10))\nplt.bar(lines_per_character.index, lines_per_character.values)\nplt.xticks(rotation=90)\nplt.xlabel('Character')\nplt.ylabel('Number of lines')\nplt.title('Number of dialog lines per character')\nplt.show()",
          " Visualizing the 10 most frequent locations\ntop_10_locations = list(dict(Counter(df_script['raw_location_text'])).items())\ntop_10_locations.sort(key=lambda x: x[1], reverse=True)\ntop_10_locations = top_10_locations[:10]\n\nplt.bar([x[0] for x in top_10_locations], [x[1] for x in top_10_locations])\nplt.xticks(rotation=90)\nplt.show()",
          " Visualize the top 20 characters in terms of number of lines in the show\ntop_characters = df_script['character_id'].value_counts().head(20)\ntop_characters = top_characters.to_frame().merge(df_characters, how='left', left_index=True, right_on='id').iloc[:,1]\ntop_characters = top_characters[::-1]\n\nplt.figure(figsize=(10, 8))\nplt.barh(top_characters.index, top_characters.values, color='skyblue')\nplt.xlabel('Number of lines', fontsize=12)\nplt.title('Top 20 characters by number of lines', fontsize=16)\nplt.gca().invert_yaxis()",
          " Compute the top 10 characters, using the number of words in their lines\ntop_10_characters = df_script[df_script['raw_character_text'].isin(df_characters['character'])]\ntop_10_characters = top_10_characters.groupby('raw_character_text').apply(lambda x: x['word_count'].sum()).reset_index(name='num_words')\ntop_10_characters = top_10_characters.sort_values(by='num_words', ascending=False)\ntop_10_characters = top_10_characters.head(10)",
          "Get a feel of the data\nprint(df_script.head(3))\n\n# Plot the 10-most frequent characters\nplt.figure(figsize=(18, 6))\ntop_characters = df_script['raw_character_text'].value_counts().head(10)\ntop_characters.plot(kind='bar')\nplt.title('Top-10 most frequent characters')\nplt.show()",
          " Visualize Content\nplt.hist(df_script['character_id'].value_counts().values, bins=np.arange(0, 500, 10))\nplt.xlabel('Utterances per character')\nplt.ylabel('Number of characters')\nplt.title('Utterances per character')",
          "Visualize the top 20 characters by number of lines\nplt.figure(figsize=(14, 8))\ntop_characters = df_script['character_id'].value_counts().head(20)\ntop_characters_names = [df_characters[df_characters['id'] == i]['name'].values[0] for i in top_characters.index]\ntop_characters_names\nplt.bar(top_characters_names, top_characters.values)\nplt.xticks(rotation=90)\nplt.title('Top 20 characters by number of lines')\nplt.show()",
          " Visualise the top 10 characters by number of spoken words\ndf_script.groupby(\"character_id\")[\"word_count\"].sum().nlargest(10).sort_values().plot(kind=\"barh\", color=\"skyblue\")\nplt.xlabel(\"Number of words\")\nplt.title(\"Top 10 Characters by Number of Spoken Words\")\nplt.show()",
          " Visualize the number of lines per character\ndf_script['character_id'] = df_script['character_id'].fillna(-1).astype(int)\ndf_script['character_id'] = df_script['character_id'].replace(-1, 'NA')\nlines_per_character = df_script['character_id'].value_counts()\n\nplt.bar(np.arange(30), lines_per_character[:30])\nplt.xticks(np.arange(30), lines_per_character.index[:30], rotation='vertical')\nplt.ylabel('Number of lines')\nplt.title('Number of lines per character')",
          "Visualise lines and word count\nline_lengths = df_script['raw_text'].str.len()\nword_lengths = df_script['raw_text'].str.split().apply(lambda x : len(x) if x != [''] else 0)\n\nplt.figure(figsize=(20, 5))\n\nplt.subplot(1, 2, 1)\nline_lengths.plot(kind='hist', bins=100, ax=plt.gca())\nplt.title('Line lengths')\n\nplt.subplot(1, 2, 2)\nword_lengths.plot(kind='hist', bins=100, ax=plt.gca())\nplt.title('Word lengths')\n\nplt.show()",
          "Visualize the top 30 characters by number of appearances\ntop_30_characters = df_script.speaking_line_id.value_counts()[:30]\n\nfig, ax = plt.subplots(figsize=(20, 10))\nax.bar(top_30_characters.index, top_30_characters.values, color='b')\n\nax.set(title='Top 30 characters by number of appearances', xlabel='Character id', ylabel='Number of appearances')\nax.grid(True)\nplt.xticks(rotation=90)",
          "# Visualize the number of lines per character\nline_counts = df_script['character_id'].value_counts()\n\nplt.hist(line_counts, bins=100, range=(1, 100))\nplt.yscale('log')\nplt.title('Number of Lines per Character')\nplt.xlabel('Number of Lines')\nplt.ylabel('Number of Characters')\nplt.show()",
          "Visualization of the class distribution\nplt.figure(figsize=(12,5))\nax = df_script['raw_character_text'].value_counts().plot(kind='bar',\n                                    color=list(plt.rcParams['axes.prop_cycle'].by_key()['color']),\n                                    title='Distribution of the character speaking')\n\nax.set_xlabel(\"Character name\")\nax.set_ylabel(\"Frequency\")\nplt.show()",
          "Look at the number of words per line and sentence in the script data\ndf_script['words_per_line'] = df_script['normalized_text'].map(lambda x: len(x.split()))\ndf_script['words_per_sentence'] = df_script['normalized_text'].map(lambda x: len(x.split('.')))\n\n# Plot histograms for the number of words per line and sentence\nplt.figure(figsize=(14, 6))\n\nplt.subplot(1, 2, 1)\nplt.hist(df_script['words_per_line'], bins=200, color='skyblue', edgecolor='black')\nplt.title('Distribution of words per line')\nplt.xlabel('# words')\nplt.ylabel('Frequency')\n\nplt.subplot(1, 2, 2)\nplt.hist(df_script['words_per_sentence'], bins=200, color='lightgreen', edgecolor='black')\nplt.title('Distribution of words per sentence')\nplt.xlabel('# words')\nplt.ylabel('Frequency')\n\nplt.show()",
          " Visualization 1: Top 10 Characters by Number of Lines\ntop_10_characters_by_lines = df_script['normalized_name'].value_counts().head(10)\ntop_10_characters_by_lines.plot(kind='bar', figsize=(20,10))\nplt.xticks(rotation=45)\nplt.title('Top 10 Characters by Number of Lines')\nplt.xlabel('Character Name')\nplt.ylabel('Number of Lines')\nplt.show()",
          "Create a bar chart with the 10 most frequent characters",
          "Draw countplots for characters and locations\nplt.figure(figsize=(18, 10))\nplt.subplot(2, 1, 1)\nsns.countplot(y='raw_character_text', data=df_script, palette='dark:salmon_r', order=df_script['raw_character_text'].value_counts().index)\nplt.title('Character Counts')\n\nplt.subplot(2, 1, 2)\nsns.countplot(y='raw_location_text', data=df_script, palette='dark:salmon_r', order=df_script['raw_location_text'].value_counts().index)\nplt.title('Location Counts')\n\nplt.tight_layout()\nplt.show()",
          "Visualise the frequency of each character in the script dataset\nchar_distribution = dict(df_script['raw_character_text'].value_counts())\ntop_10_char, top_10_count = list(char_distribution.keys())[:10], list(char_distribution.values())[:10]\n\nfig, ax = plt.subplots(figsize=(16, 8))\nax.bar(np.arange(len(top_10_char)), top_10_count, color='purple')\nax.set_xlabel('Top 10 Characters', fontsize=24)\nax.set_ylabel('Frequency', fontsize=24)\nax.set_title('Top 10 Characters by Frequency', fontsize=36)\nax.set_xticks(np.arange(len(top_10_char)))\nax.set_xticklabels(top_10_char, rotation=45, ha='right', fontsize=16)\nax.set_yticklabels(np.arange(0, max(top_10_count)+10, 10), fontsize=16)\nplt.show()",
          "Visualize the top 10 characters by number of lines\ndf_character_lines = df_script.groupby('character_id')['id'].count().reset_index()\ndf_character_lines = df_character_lines.sort_values('id', ascending=False).head(10)\ndf_character_lines = df_character_lines.merge(df_characters, left_on='character_id', right_on='id')\ndf_character_lines = df_character_lines.set_index('name')\n\nplt.figure(figsize=(15, 8))\nplt.bar(df_character_lines.index, df_character_lines['id'], color='orange')\nplt.title('Top 10 Characters by Number of Lines')\nplt.xlabel('Character')\nplt.ylabel('Number of Lines')\nplt.xticks(rotation=45)\nplt.show()",
          "Get top 10 characters with the most lines\ntop_characters = df_script['character_id'].value_counts().head(10)\n\n# Get top 10 locations with the most lines\ntop_locations = df_script['location_id'].value_counts().head(10)",
          "Visualize the top 10 characters with the most lines in the script\ntop_10_characters = df_script['character_id'].value_counts().head(10)\ntop_10_characters_names = [df_characters[df_characters['id'] == character_id]['name'].values[0] for character_id in top_10_characters.index]\n\nplt.figure(figsize=(20,10))\nplt.bar(top_10_characters_names, top_10_characters.values)\nplt.title('Top 10 characters with the most lines in the script')\nplt.xlabel('Character')\nplt.ylabel('Number of lines')\nplt.xticks(rotation=45)\nplt.show()",
          " Visualize most common characters\ntop_characters = df_script['character_id'].value_counts().head(50)\ncharacters = [df_characters[df_characters['id']==i]['name'].values[0] for i in top_characters.index]\n\nplt.figure(figsize=(16, 8))\nplt.bar(characters, top_characters.values)\nplt.xticks(rotation=90)\nplt.show()",
          "Visualize the proportion of lines for each character\ndf_characters_counts = pd.merge(df_script, \n                                df_characters, \n                                left_on='character_id', \n                                right_on='id').groupby('name').count()['id'].sort_values()\n\nplot = df_characters_counts.plot(\n    kind='pie',\n    figsize=(12,12),\n    title='Proportion of lines for each character',\n    autopct=lambda p: '{:.0f}% ({:.0f})'.format(p, p/100 * df_characters_counts.sum())\n    )\n\n# Change font size\nfor text in plot.texts:\n    text.set_fontsize(10)\n\nplt.show()",
          "Plotting a bar plot of the 10 most common characters in the dataset",
          " Visualise data\nplt.figure(figsize=(12, 5))\nplt.subplot(1, 2, 1)\nplt.hist(df_script.speaking_line)\nplt.title('Speaking lines', fontsize=15)\nplt.xlabel('')\n\nplt.subplot(1, 2, 2)\nplt.hist(df_script.character_id.value_counts(), bins=50)\nplt.title('Number of lines per character', fontsize=15)\nplt.xlabel('Number of lines')\nplt.show()"
         ],
         "marker": {
          "opacity": 0.5,
          "size": 5
         },
         "mode": "markers+text",
         "name": "103_Visualize Top 10 Most Frequent Characters and Locations",
         "text": [
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          ""
         ],
         "textfont": {
          "size": 12
         },
         "type": "scattergl",
         "x": [
          8.511809349060059,
          8.554950714111328,
          8.397950172424316,
          8.5649995803833,
          8.284225463867188,
          8.385420799255371,
          8.832091331481934,
          8.406907081604004,
          8.03725814819336,
          8.336569786071777,
          8.690234184265137,
          8.422739028930664,
          8.212994575500488,
          9.313957214355469,
          8.5502290725708,
          8.364097595214844,
          8.522762298583984,
          9.227652549743652,
          8.508044242858887,
          8.651039123535156,
          8.241987228393555,
          8.3405122756958,
          8.96445083618164,
          7.837363243103027,
          8.338552474975586,
          8.228824615478516,
          8.623820304870605,
          8.434703826904297,
          8.810032844543457
         ],
         "y": [
          9.915648460388184,
          9.642269134521484,
          10.041417121887207,
          9.536641120910645,
          10.465049743652344,
          10.073498725891113,
          10.205717086791992,
          9.45187759399414,
          9.997629165649414,
          9.930891990661621,
          10.371847152709961,
          9.049988746643066,
          9.902921676635742,
          9.084840774536133,
          10.211469650268555,
          9.546281814575195,
          10.281460762023926,
          9.585968017578125,
          10.116621017456055,
          10.026596069335938,
          10.126358985900879,
          10.698701858520508,
          10.339704513549805,
          10.177817344665527,
          10.231120109558105,
          10.199393272399902,
          9.68986988067627,
          9.984234809875488,
          9.657095909118652
         ]
        },
        {
         "hoverinfo": "text",
         "hovertext": [
          " Look at the first few rows of `df_characters` dataframe\ndf_characters.head()",
          "\n# To look into the dataframes, we just run the cell\n# Characters DataFrame\ndf_characters.head()",
          "\n# Let's take a look at the first rows of the characters dataframe\ndf_characters.head()",
          " Take a look at the first 5 rows of the characters dataframe\ndf_characters.head()",
          "look into the first 10 rows of the characters dataframe\ndf_characters.head(10)",
          " Look at the first few rows of the characters dataframe\ndf_characters.head()",
          "Look at the first few records of the characters dataframe\ndf_characters.head()",
          " Take a look at the first 5 rows of the characters dataframe\ndf_characters.head()",
          "Look at the first 5 rows of the characters dataframe\ndf_characters.head()",
          " Let's take a look at the first 5 rows of our character dataframe to see what it looks like.\ndf_characters.head()",
          "Look at the characters dataframe\ndf_characters.head()",
          " Look at the first few rows of the characters DataFrame\ndf_characters.head()",
          "Check out the first few rows of each dataframe\ndf_characters.head()",
          "Check out the first few rows of the characters dataframe\ndf_characters.head()",
          "Take a look at the first rows from `df_characters` DataFrame\ndf_characters.head()",
          "Take a look at the characters dataframe\ndf_characters.head()",
          " Look at the first few rows of the characters dataframe\ndf_characters.head()",
          "Have a quick look at the dataframes\ndf_characters.head(3)",
          "Look at the first five rows of the characters dataframe\ndf_characters.head()",
          " Look at the first few rows of the characters DataFrame\ndf_characters.head()",
          "Look at first characters in the datasets to decide which column to use as character in script dataframe\ndf_characters.head()",
          "Take a look at the dataframes\ndf_characters.head()",
          "Look at first entries of the characters DataFrame\ndf_characters.head()",
          " Take a look at the first 5 rows of the characters dataframe\ndf_characters.head()",
          " Look at the first few rows of the dataframe\ndf_characters.head()",
          " Look at the first few rows of the characters dataframe\ndf_characters.head()",
          " Look at the first 5 elements in the characters dataframe\ndf_characters.head()",
          "Look at the few first rows of the first dataframe\ndf_characters.head()"
         ],
         "marker": {
          "opacity": 0.5,
          "size": 5
         },
         "mode": "markers+text",
         "name": "104_Exploring the Characters DataFrame",
         "text": [
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          ""
         ],
         "textfont": {
          "size": 12
         },
         "type": "scattergl",
         "x": [
          7.944317817687988,
          6.679063320159912,
          7.419121265411377,
          7.54856014251709,
          7.72353458404541,
          7.533504009246826,
          7.5911970138549805,
          7.655891418457031,
          7.400634765625,
          7.977952480316162,
          6.978768825531006,
          7.57210111618042,
          6.742335319519043,
          7.075654983520508,
          7.560824394226074,
          7.191456317901611,
          7.407100677490234,
          6.470273494720459,
          7.7739996910095215,
          7.410120964050293,
          7.749509811401367,
          6.9876179695129395,
          7.223089694976807,
          7.619692325592041,
          7.3210930824279785,
          7.634094715118408,
          7.996654510498047,
          7.673671722412109
         ],
         "y": [
          15.121504783630371,
          14.826333999633789,
          14.718987464904785,
          14.18032169342041,
          14.477776527404785,
          14.987637519836426,
          14.725440979003906,
          14.295348167419434,
          14.57816219329834,
          14.093201637268066,
          14.864343643188477,
          14.937108993530273,
          14.748271942138672,
          14.928584098815918,
          15.616180419921875,
          14.495792388916016,
          14.898000717163086,
          14.464129447937012,
          14.443862915039062,
          15.0556640625,
          15.057145118713379,
          14.570791244506836,
          15.498979568481445,
          14.093417167663574,
          14.92122745513916,
          15.04038143157959,
          14.652641296386719,
          15.376038551330566
         ]
        },
        {
         "hoverinfo": "text",
         "hovertext": [
          "Examine the data\ndf_script.head()",
          "Exploring the data\ndf_script.head()",
          "Explore the data\ndf_script.head()",
          " Sneak peek at the data\ndf_script.head()",
          "Get an overview of the data\ndf_script.head()",
          " Explore the structure of the data\ndf_script.head()",
          "Data overview\ndf_script.head()",
          "Inspect data\ndf_script.head()",
          "Exploring the core data selected for analysis & sentiment analysis -\ndf_script.head(5), df_characters.head(5), df_locations.head(5)",
          "Inspect the script data\ndf_script.head()",
          "Explore the data\ndf_script.head()",
          "Inspect scripts data\ndf_script.head()",
          "Inspect basic structure of the data\ndf_script.head()",
          "Show some lines to get a feeling of how the data looks like\ndf_script.head(2)",
          "look at the data\ndf_script.head()",
          "Take a look at the structure of script data\ndf_script.head()",
          "Inspect the data\ndf_script.head()",
          "Initial data observation\ndf_script.head()",
          "Inspect data\ndf_script.head()",
          "Quick look on the data\nprint(df_script.head())",
          "Inspect some sample data\ndf_script.head()",
          "Explore the data\ndf_script.head()",
          "Data overview\ndf_script.head()",
          "A sample of the data\ndf_script.head()",
          "Examine the data\ndf_script.head()",
          "Inspecting the data\ndf_script.head()",
          "Inspect the script data\ndf_script.head()",
          "Inspect the contents and structure of the script data\ndf_script.head()"
         ],
         "marker": {
          "opacity": 0.5,
          "size": 5
         },
         "mode": "markers+text",
         "name": "105_Exploring and Inspecting the Data Structure and Overview",
         "text": [
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          ""
         ],
         "textfont": {
          "size": 12
         },
         "type": "scattergl",
         "x": [
          4.559761047363281,
          4.491542816162109,
          4.820623397827148,
          4.5365800857543945,
          4.943301200866699,
          4.425585746765137,
          4.797522068023682,
          4.604745864868164,
          3.926410436630249,
          4.926853656768799,
          4.72053337097168,
          4.580038547515869,
          4.272663116455078,
          4.7787322998046875,
          4.6485724449157715,
          4.7880048751831055,
          4.375329971313477,
          4.292624473571777,
          4.309040546417236,
          4.901632308959961,
          4.440881252288818,
          4.734719276428223,
          4.515934467315674,
          4.281351089477539,
          4.39902925491333,
          4.415194988250732,
          4.858642578125,
          4.703709602355957
         ],
         "y": [
          -3.969758987426758,
          -4.880652904510498,
          -4.655694007873535,
          -4.374232292175293,
          -4.579421520233154,
          -5.073383331298828,
          -5.140114784240723,
          -4.417810440063477,
          -4.355982303619385,
          -4.238132953643799,
          -4.5983381271362305,
          -4.152450084686279,
          -4.651652812957764,
          -5.500093460083008,
          -4.700406074523926,
          -5.187998294830322,
          -4.104741096496582,
          -4.568782329559326,
          -4.291242599487305,
          -4.171590805053711,
          -4.851149082183838,
          -4.671384811401367,
          -4.9080023765563965,
          -5.098244667053223,
          -3.9915034770965576,
          -4.442054271697998,
          -4.385031223297119,
          -4.511026859283447
         ]
        },
        {
         "hoverinfo": "text",
         "hovertext": [
          "Display available columns for each dataset\nfor name, df in {\n    'characters': df_characters,\n    'locations': df_locations,\n    'script': df_script,\n    'episodes': df_episodes\n}.items():\n    print(f'{name}: {df.columns.values}\\n')",
          "Display available columns in each dataframe\nprint(\"Characters columns:\", df_characters.columns)\nprint(\"Locations columns:\", df_locations.columns)\nprint(\"Script columns:\", df_script.columns)\nprint(\"Episodes columns:\", df_episodes.columns)",
          "Display all columns for each dataframe\nfor df in [df_characters, df_locations, df_script, df_episodes]:\n    print(df.columns)",
          "Inspect general information from the datasets\nprint('characters columns',df_characters.columns)\nprint('\\n\\nlocations columns',df_locations.columns)\nprint('\\n\\nscript lines columns',df_script.columns)\nprint('\\n\\nepisodes columns',df_episodes.columns)",
          "Functions and Classes\ndef getNameMap(df_map, key_col, value_col):\n    '''\n    Get a dictionary using two columns one for the key and one for the value\n    Parameters\n    ----------\n    df_map: pd.DataFrame\n            DataFrame with the key-value mapping\n    key_col: str\n            Name of the column with the keys\n    value_col:str\n            Name of the column with the values\n            \n    Returns\n    -------\n    name_map: Dictionary\n            Dictionary with the mapping of the DataFrame\n    '''\n    name_map = dict(zip(df_map[key_col], df_map[value_col]))\n    return name_map",
          " print the dataframe columns\nprint(df_characters.columns)\nprint(df_locations.columns)\nprint(df_script.columns)\nprint(df_episodes.columns)",
          " view available data columns for characters, locations, and script\nprint(df_characters.columns)\nprint(df_locations.columns)\nprint(df_script.columns)",
          "\n# Let's start by checking which columns we have in each dataframe\nprint('Characters:', df_characters.columns)\nprint('Locations:', df_locations.columns)\nprint('Script:', df_script.columns)\nprint('Episodes:', df_episodes.columns)",
          "Check for duplicate columns\nassert len(df_characters.columns.unique()) == len(df_characters.columns)\nassert len(df_locations.columns.unique()) == len(df_locations.columns)\nassert len(df_script.columns.unique()) == len(df_script.columns)\nassert len(df_episodes.columns.unique()) == len(df_episodes.columns)",
          "Explore column names\nprint('Characters:', df_characters.columns.tolist())\nprint('Locations:', df_locations.columns.tolist())\nprint('Script lines:', df_script.columns.tolist())\nprint('Episodes:', df_episodes.columns.tolist())",
          "Columns in df_episodes\nfor col in df_episodes.columns:\n    print(col)",
          " Check columns and example of some of the dataframes\nprint(df_characters.columns, df_characters.head())\nprint(df_locations.columns, df_locations.head())\nprint(df_script.columns, df_script.head())\nprint(df_episodes.columns, df_episodes.head())",
          "Look at the available data\nprint(df_characters.columns)\nprint(df_locations.columns)\nprint(df_script.columns)\nprint(df_episodes.columns)",
          "Display available columns for each dataset\nprint('Characters:', df_characters.columns.tolist())\nprint('Locations:', df_locations.columns.tolist())\nprint('Script:', df_script.columns.tolist())\nprint('Episodes:', df_episodes.columns.tolist())",
          "Print the columns of the characters, lines, and episodes DataFrames to understand their structure\nprint(df_characters.columns)\nprint(df_script.columns)\nprint(df_episodes.columns)",
          "Encoding all the dataframes by ASR for simplicity\ndf_characters = df_characters.astype('category')\ndf_locations = df_locations.astype('category')\ndf_episodes = df_episodes.astype('category')",
          " Check columns of each dataframe\nprint(\"Characters columns:\", df_characters.columns)\nprint(\"Locations columns:\", df_locations.columns)\nprint(\"Script columns:\", df_script.columns)\nprint(\"Episodes columns:\", df_episodes.columns)",
          "Display the column names for each dataframe\nprint(\"Characters data:\\n\", df_characters.columns)\nprint(\"\\nLocations data:\\n\", df_locations.columns)\nprint(\"\\nScript data:\\n\", df_script.columns)\nprint(\"\\nEpisodes data:\\n\", df_episodes.columns)",
          "List all data that exists in each dataframe\nprint(\"##################### COLUMNS NAMES #############################\")\nprint(\"Characters columns: \", df_characters.columns)\nprint()\nprint(\"Locations columns: \", df_locations.columns)\nprint()\nprint(\"Script lines columns: \", df_script.columns)\nprint()\nprint(\"Episodes columns: \", df_episodes.columns)",
          "Check the columns present in the datasets\nprint('Characters:', df_characters.columns)\nprint('Locations:', df_locations.columns)\nprint('Script:', df_script.columns)\nprint('Episodes:', df_episodes.columns)",
          "Display data information\nprint(\"\\n\\nDimensions and columns of each dataset:\")\nprint(\"Characters: \", df_characters.shape, df_characters.columns)\nprint(\"Locations: \", df_locations.shape, df_locations.columns)\nprint(\"Script: \", df_script.shape, df_script.columns)\nprint(\"Episodes: \", df_episodes.shape, df_episodes.columns)",
          "Check if all columns are read correctly\nprint(\"Columns in characters: \", df_characters.columns.tolist())\nprint(\"Columns in locations: \", df_locations.columns.tolist())\nprint(\"Columns in script: \", df_script.columns.tolist())\nprint(\"Columns in episodes: \", df_episodes.columns.tolist())",
          "Display columns to identify the data available in each DataFrame\nprint(\"Characters DataFrame columns: \", df_characters.columns)\nprint(\"Locations DataFrame columns: \", df_locations.columns)\nprint(\"Script DataFrame columns: \", df_script.columns)\nprint(\"Episodes DataFrame columns: \", df_episodes.columns)",
          "Display column names\nprint(\"Columns in character dataframe:\")\nprint(df_characters.columns)\nprint(\"\\nColumns in location dataframe:\")\nprint(df_locations.columns)\nprint(\"\\nColumns in script dataframe:\")\nprint(df_script.columns)\nprint(\"\\nColumns in episodes dataframe:\")\nprint(df_episodes.columns)",
          " Show all columns to know what can be used from each table\nfor column in [df_characters.columns, df_locations.columns, df_script.columns, df_episodes.columns]:\n    print(column)\n    print()",
          "Display available columns for each dataset\nprint(df_characters.columns)\nprint(df_locations.columns)\nprint(df_script.columns)\nprint(df_episodes.columns)",
          " LIst of dataframes and their column names\ndfs = {\"characters\": df_characters, \"locations\": df_locations, \"script\": df_script, \"episodes\": df_episodes}\nfor name, df in dfs.items():\n    print(f\"{name}: {', '.join(df.columns)}\")"
         ],
         "marker": {
          "opacity": 0.5,
          "size": 5
         },
         "mode": "markers+text",
         "name": "106_Displaying Available Columns in DataFrames",
         "text": [
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          ""
         ],
         "textfont": {
          "size": 12
         },
         "type": "scattergl",
         "x": [
          -0.2304614782333374,
          0.09420689940452576,
          -0.14105962216854095,
          0.44844186305999756,
          8.057129859924316,
          0.07553255558013916,
          -0.042120955884456635,
          -0.0707123801112175,
          1.5382736921310425,
          -0.1431073397397995,
          0.5564835667610168,
          -0.886882483959198,
          -0.12355294823646545,
          -0.0003935809072572738,
          -0.11466700583696365,
          -0.8676285147666931,
          -0.31728583574295044,
          0.05788344889879227,
          -0.12394297122955322,
          -0.5934926867485046,
          0.14210544526576996,
          0.3433820307254791,
          0.13134895265102386,
          -0.21774546802043915,
          0.25902649760246277,
          0.12100449949502945,
          -0.6220157742500305
         ],
         "y": [
          1.4661147594451904,
          0.8773830533027649,
          1.096808671951294,
          1.1528676748275757,
          -3.2946219444274902,
          1.127245545387268,
          1.1127619743347168,
          0.8284948468208313,
          1.5636404752731323,
          1.3971607685089111,
          1.3311190605163574,
          1.213375210762024,
          1.0101200342178345,
          0.8297896385192871,
          0.9076611995697021,
          0.17046010494232178,
          0.6392046213150024,
          1.2853600978851318,
          0.824411153793335,
          0.9232059121131897,
          0.8555446267127991,
          0.6847931146621704,
          0.8619967699050903,
          0.7075130343437195,
          0.9011450409889221,
          0.8658589124679565,
          1.5686367750167847
         ]
        },
        {
         "hoverinfo": "text",
         "hovertext": [
          "Visualisation of the data",
          "modules required for data visualization and analysis",
          "Some basic visualisations to understand our datasets better.",
          "Visualizing and understanding the data",
          "Realizamos un préstamo de alias para la apariencia del set de datos en los cuadernos de jupyter.",
          " Visualisation code",
          "Visualization Functions",
          "Visualizing the data",
          "Visualize some example data.",
          "\n# Import the required modules for processing data and creating visualizations",
          "Visualizing the data",
          " Enable the TQDM notebook extension to visualize loop processing.",
          " Visualisation Preliminaries",
          "Visualizacion de los datos",
          "Display the dimension of each data infront",
          " Test and visualize data",
          "Visualise the data in the table",
          "Visualization function",
          " Visualization Utils",
          "Visualizing data, to understand it better!",
          "Visualize the data",
          "Seeing that the function was removed, I can only assume it was some form of data exploration or manipulation. If you have a specific function in mind, feel free to ask for its inclusion.",
          "Visualise the data",
          "Visualizing data",
          "Visualization functions",
          "Merge the data to combine fields and for better visualization.",
          "That's all for now - let's get started with the data visualization!"
         ],
         "marker": {
          "opacity": 0.5,
          "size": 5
         },
         "mode": "markers+text",
         "name": "107_Data visualization and analysis modules",
         "text": [
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          ""
         ],
         "textfont": {
          "size": 12
         },
         "type": "scattergl",
         "x": [
          13.070243835449219,
          13.45595645904541,
          14.210951805114746,
          13.615537643432617,
          11.937664031982422,
          13.408892631530762,
          13.469878196716309,
          13.046247482299805,
          13.373151779174805,
          13.851926803588867,
          12.952922821044922,
          13.720954895019531,
          13.451550483703613,
          13.205758094787598,
          8.21146297454834,
          12.877177238464355,
          12.985392570495605,
          13.474151611328125,
          13.305908203125,
          13.61233139038086,
          12.96953010559082,
          13.516057014465332,
          13.145965576171875,
          12.974310874938965,
          13.339570045471191,
          11.933808326721191,
          14.457539558410645
         ],
         "y": [
          -0.1443328708410263,
          0.11930351704359055,
          -0.5502026081085205,
          -0.053750671446323395,
          3.2328014373779297,
          1.0505539178848267,
          0.8232929706573486,
          0.22668743133544922,
          0.07047662883996964,
          0.3805467188358307,
          0.09560474753379822,
          10.275705337524414,
          0.58518385887146,
          0.7993467450141907,
          -3.6297380924224854,
          -0.1445235162973404,
          -0.8125825524330139,
          0.5759824514389038,
          0.852715015411377,
          -0.15667755901813507,
          -0.0867658481001854,
          1.2763783931732178,
          -0.19821088016033173,
          -0.0012061846209689975,
          0.9166548252105713,
          0.4483276307582855,
          -0.20414140820503235
         ]
        },
        {
         "hoverinfo": "text",
         "hovertext": [
          "Display the first few rows of the dataframe containing the characters in the Simpsons dataset.",
          "Preview the 'simpsons_characters.csv' dataset\ndf_characters.head()",
          "Preview of Simpsons Characters data\ndf_characters.head()",
          " Display the first 5 entries of the 'simpsons_characters.csv' file\ndf_characters.head()",
          " Preview the 'simpsons_characters.csv' table\ndf_characters.head()",
          " Show the first 5 rows of the 'simpsons_characters' DataFrame\ndf_characters.head()",
          "Display in Jupyter notebook the top 5 rows of the Simpsons characters dataset\ndf_characters.head()",
          "Inspect the first 5 rows of 'simpsons_characters.csv'\ndf_characters.head()",
          "Display first 5 rows of Simpsons characters dataframe\ndf_characters.head()",
          "# Display the first few lines of the Simpsons characters dataset\ndf_characters.head()",
          " Examine the first few rows of data from the 'simpsons_characters.csv' file\ndf_characters.head()",
          "Data understanding\n# Characters in the Simpsons\ndf_characters.head()",
          " Check the first 5 rows of Simpsons characters dataset\ndf_characters.head()",
          "gallery of Simpson's character\ndf_characters.head()",
          "View a sample of the Simpsons characters dataset\ndf_characters.head()",
          "Checking the first 5 rows of the \"simpsons_characters.csv\" file\ndf_characters.head()",
          " Display the first few lines of the \"simpsons_characters.csv\" dataset\ndf_characters.head()",
          "Display sample rows for Simpsons characters\ndf_characters.head()",
          "Display the first 5 lines of simpsons_characters table\ndf_characters.head()",
          "# Display the characters of the Simpsons series\ndf_characters.head()",
          "Display records for Simpsons character data\ndf_characters.head()",
          "# Show first 5 entries of 'simpsons_characters.csv'\ndf_characters.head()",
          "Show first rows of Simpsons Characters dataset\ndf_characters.head()",
          "Preview the Simpsons characters dataset\ndf_characters.head()",
          " Display the first 5 rows of the Simpsons characters dataset\ndf_characters.head()",
          " Check the first 5 rows of the \"Simpsons Characters\" dataset\ndf_characters.head()",
          "Display the first records of the Simpsons characters dataset\ndf_characters.head()"
         ],
         "marker": {
          "opacity": 0.5,
          "size": 5
         },
         "mode": "markers+text",
         "name": "108_Previewing the Simpsons Characters dataset by checking the first 5 rows",
         "text": [
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          ""
         ],
         "textfont": {
          "size": 12
         },
         "type": "scattergl",
         "x": [
          2.918248414993286,
          2.050823211669922,
          2.6404662132263184,
          1.1335434913635254,
          2.138974905014038,
          0.14009569585323334,
          1.4279134273529053,
          1.2455254793167114,
          0.11690948158502579,
          2.485582113265991,
          1.6997779607772827,
          3.570204019546509,
          1.2904993295669556,
          2.8961124420166016,
          2.66680645942688,
          1.2069737911224365,
          1.9649267196655273,
          2.137021064758301,
          0.8119683265686035,
          3.093038320541382,
          2.703291654586792,
          1.2921215295791626,
          1.980006217956543,
          2.2174341678619385,
          1.2354000806808472,
          1.6657190322875977,
          1.9647272825241089
         ],
         "y": [
          13.42001724243164,
          13.287306785583496,
          13.418495178222656,
          13.120311737060547,
          13.112663269042969,
          13.83404541015625,
          13.853577613830566,
          13.168496131896973,
          13.43781566619873,
          13.399670600891113,
          13.411250114440918,
          13.75157356262207,
          13.473976135253906,
          13.167394638061523,
          13.203353881835938,
          13.231056213378906,
          13.544754981994629,
          13.443480491638184,
          13.222322463989258,
          13.554545402526855,
          13.3301420211792,
          12.884966850280762,
          14.031536102294922,
          13.376455307006836,
          13.500741004943848,
          13.317797660827637,
          13.684525489807129
         ]
        },
        {
         "hoverinfo": "text",
         "hovertext": [
          "Display a sample of each dataframe to know the data features",
          " Display basic information about dataframes",
          " Display general information of each dataframe.\ndef display_df_info(df, name):\n    print(name)\n    print(df.info())\n    display(df.head(5))",
          "A function to display basic info about a dataframe\ndef df_summary(df, title=\"\"):\n    print(f'\\033[1m{title}\\033[0m')\n    print(df.info())",
          "Display some records of each dataframe to understand the data",
          " Let's display basic informations for every dataframe",
          "def get_info(df: pd.DataFrame, info: str):\n    \"\"\"\n    Prints the shape, the columns names and the first 5 rows of a DataFrame.\n\n    :param df: The DataFrame to get information from.\n    :param info: The name of the DataFrame.\n    \"\"\"\n    print(f'{info} shape:', df.shape, '\\n\\n')\n    print(f'{info} columns:', df.columns, '\\n\\n')\n    print(f'{info}:', df.head(), '\\n\\n')",
          "Display available columns per dataframe for reference when inspecting the data.",
          " Display basic informations about the dataframes",
          "Check the basic information in each dataset\ndef info_data(dataframe, name):\n    print(\"Exploring the Data\")\n    print(\"Overview of the data \"+name+\":\" )\n    return (dataframe.head())",
          "To display some basic information about the dataframes",
          "display available dataframes\ndir()",
          " Displaying basic information from each dataframe",
          "printing out attributes of the dataframes",
          "Displaying all the dataframes as there should be direct download source available is allowed under `data` folder.",
          "Load the data and display the different DataFrames.",
          "Display some samples of each dataframes.",
          "# Simple function to inspect the data frames\ndef inspect_data(df, name):\n    print(f\"{name} dataframe info\".center(50, '='))\n    print(df.info())\n    print(f\"{name} dataframe describe\".center(50, '='))\n    print(df.describe(include='all'))",
          "Sample the dataframe and identify the column names and their associated meanings",
          "Display all the dataframes to understand what is actually present in them",
          "Specify input and output dataframes",
          "Show simple breakdowns of dataframes",
          " Display basic information for all DataFrames",
          "Display some basic information about each dataframe",
          "Display a sample of each dataframe to understand the data",
          " Show dataframes schemas",
          "View the content of the dataframes"
         ],
         "marker": {
          "opacity": 0.5,
          "size": 5
         },
         "mode": "markers+text",
         "name": "109_Displaying Basic Information about DataFrames",
         "text": [
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          ""
         ],
         "textfont": {
          "size": 12
         },
         "type": "scattergl",
         "x": [
          9.519330024719238,
          9.216100692749023,
          8.128742218017578,
          8.6817626953125,
          9.37283706665039,
          9.399144172668457,
          7.752174377441406,
          8.67491340637207,
          9.4753999710083,
          8.732339859008789,
          9.93781852722168,
          9.484886169433594,
          9.055548667907715,
          9.605557441711426,
          9.185159683227539,
          10.112642288208008,
          9.571236610412598,
          8.886601448059082,
          9.271385192871094,
          9.21653938293457,
          9.84017562866211,
          9.642743110656738,
          8.863529205322266,
          8.855016708374023,
          9.566315650939941,
          9.782716751098633,
          10.221638679504395
         ],
         "y": [
          -4.158840179443359,
          -4.068958282470703,
          -3.922122001647949,
          -3.8597679138183594,
          -4.632263660430908,
          -3.71893048286438,
          -3.2048513889312744,
          -3.343386173248291,
          -4.197732448577881,
          -3.863006353378296,
          -4.161005973815918,
          -3.668623924255371,
          -4.063244342803955,
          -3.963313579559326,
          -3.437166452407837,
          -3.672628164291382,
          -4.159616470336914,
          -4.024783134460449,
          -3.393700122833252,
          -3.6612892150878906,
          -3.054628372192383,
          -3.7078490257263184,
          -3.5935001373291016,
          -3.8762660026550293,
          -4.153101921081543,
          -4.012218952178955,
          -3.8656864166259766
         ]
        },
        {
         "hoverinfo": "text",
         "hovertext": [
          "check that the data is as expected\ndf_characters.head()",
          "Confirming the data has been loaded correctly\ndf_characters.head()",
          "Check if all the csv files in data were loaded correctly\ndf_characters.head()",
          "Check that the data has been properly loaded\ndf_characters.head()",
          " Check the loaded data\ndf_characters.head()",
          "Check if everything is reand correctly\ndf_characters.head()",
          "Check data has been read correctly\ndf_characters.head()",
          "Check if data loaded correctly\ndf_characters.head()",
          "Check files have been correctly loaded\ndf_characters.head()",
          "Test to ensure the data has been read correctly\ndf_characters.head()",
          "Verify the data has been correctly loaded.\ndf_characters.head()",
          "Check if the data has been read correctly\ndf_characters.head()",
          "Check if data has been loaded successfully\ndf_characters.head()",
          " Check that the data has been loaded correctly\nprint(df_characters.head())",
          "algunas veces aparece un error en la lectura del dataframe con formato incorrecto o inesperado, por lo que se debe ajustar el formato con un encoding específico.",
          " Check the loaded data\ndf_characters.head()",
          "Check that the datasets have been loaded properly\ndf_characters.head()",
          "Check if data was correctly loaded\ndf_characters.head()",
          "checks the right columns have been loaded\ndf_characters.head()",
          " Verify that the data was read correctly\ndf_characters.head()",
          "Check the loaded data\ndf_characters.head()",
          "check if datraframe loaded correctly\nprint(df_characters.head())",
          "Check that the datasets have been loaded correctly\ndf_characters.head()",
          "Check the data loaded correctly\ndf_characters.head()",
          "Checking if the CSV files have been loaded correctly\ndf_characters.head()",
          "Check that the dfs are read correctly\ndf_characters.head()",
          " Check if the dataset was loaded correctly\ndf_characters.head()"
         ],
         "marker": {
          "opacity": 0.5,
          "size": 5
         },
         "mode": "markers+text",
         "name": "110_Data Loading Verification",
         "text": [
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          ""
         ],
         "textfont": {
          "size": 12
         },
         "type": "scattergl",
         "x": [
          5.799869537353516,
          5.802257537841797,
          5.757038593292236,
          5.597143173217773,
          5.363808631896973,
          5.979368686676025,
          5.600564956665039,
          5.139566421508789,
          5.146988391876221,
          6.000870227813721,
          5.571400165557861,
          5.542672157287598,
          5.197514533996582,
          5.438724994659424,
          6.220273017883301,
          4.967629432678223,
          5.706663131713867,
          5.149702072143555,
          5.467155456542969,
          5.637289524078369,
          5.1295270919799805,
          5.157169342041016,
          5.477534770965576,
          5.3702216148376465,
          5.385786533355713,
          5.814745903015137,
          5.418811321258545
         ],
         "y": [
          12.12595272064209,
          11.459691047668457,
          11.11116886138916,
          11.944530487060547,
          11.816699028015137,
          12.177643775939941,
          12.178095817565918,
          11.893818855285645,
          11.580305099487305,
          12.434450149536133,
          11.839555740356445,
          12.205245971679688,
          12.33322811126709,
          11.696845054626465,
          10.83957576751709,
          12.127385139465332,
          11.768420219421387,
          11.965310096740723,
          11.920572280883789,
          11.821120262145996,
          12.351300239562988,
          11.812304496765137,
          11.736287117004395,
          11.921586036682129,
          11.516275405883789,
          11.833911895751953,
          11.656401634216309
         ]
        },
        {
         "hoverinfo": "text",
         "hovertext": [
          "Initializing spaCy\nnlp = spacy.load(\"en_core_web_sm\")",
          "Set up spaCy\nnlp = spacy.load(\"en_core_web_sm\")",
          " Configure spacy\nnlp = spacy.load('en_core_web_sm')",
          " Set up spacy\nnlp = spacy.load('en_core_web_sm')",
          "Set up spacy\nnlp = spacy.load('en_core_web_sm')",
          " Spacy nlp only needs to be initiated once\nnlp = spacy.load('en_core_web_sm')",
          "Load spaCy\nnlp = spacy.load(\"en_core_web_sm\")",
          "Set up Spacy\nnlp = spacy.load('en_core_web_sm')",
          "\n# Setting up Spacy\nnlp = spacy.load(\"en_core_web_sm\")",
          "Set up spaCy\nnlp = spacy.load('en_core_web_sm')",
          "Set up spacy\nnlp = spacy.load('en_core_web_sm')",
          " Set up spaCy\nnlp = spacy.load('en_core_web_sm')",
          "# Set up Spacy\nnlp = spacy.load('en_core_web_sm')",
          "# Initialize spaCy\nnlp = spacy.load(\"en_core_web_sm\")",
          " Load spacy\nnlp = spacy.load('en_core_web_sm')",
          " Setting up spacy\nnlp = spacy.load(\"en_core_web_sm\")",
          "Load Spacy\nnlp = spacy.load('en_core_web_sm')",
          "Setup\nnlp = spacy.load(\"en_core_web_sm\")",
          "# Initialize spaCy's tokenizer\nnlp = spacy.load('en_core_web_sm')",
          " Set up spaCy\nnlp = spacy.load(\"en_core_web_sm\")",
          "Set up Spacy\nnlp = spacy.load(\"en_core_web_sm\")",
          "# Setup spacy\nnlp = spacy.load('en_core_web_sm')",
          "Load spacy core\nnlp = spacy.load(\"en_core_web_sm\")",
          "Setting up Spacy\nnlp = spacy.load('en_core_web_sm')",
          "Initialize spacy\nnlp = spacy.load('en_core_web_sm')",
          "Initializing spacy\nnlp = spacy.load(\"en_core_web_sm\")",
          "Set up spacy\nnlp = spacy.load('en_core_web_sm')"
         ],
         "marker": {
          "opacity": 0.5,
          "size": 5
         },
         "mode": "markers+text",
         "name": "111_Spacy setup",
         "text": [
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          ""
         ],
         "textfont": {
          "size": 12
         },
         "type": "scattergl",
         "x": [
          16.79141616821289,
          15.974617004394531,
          16.431299209594727,
          16.99842071533203,
          17.065610885620117,
          17.06920051574707,
          15.889931678771973,
          16.871864318847656,
          16.063087463378906,
          17.298080444335938,
          17.036821365356445,
          17.37435531616211,
          17.394004821777344,
          16.70250701904297,
          16.598299026489258,
          16.24810791015625,
          16.447032928466797,
          15.684924125671387,
          16.564559936523438,
          15.829743385314941,
          15.728108406066895,
          16.8100643157959,
          16.37225914001465,
          17.028451919555664,
          17.074918746948242,
          17.11077880859375,
          16.981155395507812
         ],
         "y": [
          8.838020324707031,
          8.386384010314941,
          8.223529815673828,
          8.904696464538574,
          8.739694595336914,
          8.718904495239258,
          8.816792488098145,
          9.03272533416748,
          8.300973892211914,
          8.686285018920898,
          8.730499267578125,
          9.048877716064453,
          9.043575286865234,
          8.79102611541748,
          9.073973655700684,
          8.425259590148926,
          9.100201606750488,
          7.87978458404541,
          8.505563735961914,
          8.444119453430176,
          8.367593765258789,
          8.575639724731445,
          8.78641414642334,
          8.65949821472168,
          8.610089302062988,
          8.721877098083496,
          9.047334671020508
         ]
        },
        {
         "hoverinfo": "text",
         "hovertext": [
          "View the content of each dataset\ndf_characters.head()",
          "Explore the structure of the datasets\ndf_characters.head()",
          "Inspect the character dataset\ndf_characters.head()",
          " Quick exploration of the characters dataset\ndf_characters.head()",
          "Inspect a few entries in the characters dataset\ndf_characters.head()",
          "Summary statistics of the characters dataset\ndf_characters.head()",
          "A quick view of the characters dataset\ndf_characters.head()",
          "Exploring the datasets\ndf_characters.head()",
          "Inspecting the character dataset\ndf_characters.head()",
          "Explore the characters dataset\ndf_characters.head()",
          "Explore the characters dataset\ndf_characters.head()",
          "# Let's display each dataset to understand its structure\ndf_characters.head()",
          "View dataset\ndf_characters.head()",
          "Explore the characters dataset\ndf_characters.head()",
          "Overview of the characters dataset\nprint(df_characters.shape)\ndf_characters.head()",
          "Let's see how the characters dataset looks like\ndf_characters.head()",
          "Quick peek at the character dataset\ndf_characters.head()",
          "Quick overview of the characters dataset\ndf_characters.head()",
          "Initial exploration of the datasets\ndf_characters.head()",
          "Explore the datasets\ndf_characters.head()",
          "Brief look at our datasets\ndf_characters.head()",
          "Inspect the contents of the Character dataset\ndf_characters.head()",
          "Explore the dataset\ndf_characters.head()",
          "Sample of the characters dataset\ndf_characters.head()",
          "Show examples of each dataset\ndf_characters.head()",
          "A sample of the characters dataset\ndf_characters.head()",
          "Explore the characters dataset\ndf_characters.head()"
         ],
         "marker": {
          "opacity": 0.5,
          "size": 5
         },
         "mode": "markers+text",
         "name": "112_Exploring Characters Dataset with df_characters.head()",
         "text": [
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          ""
         ],
         "textfont": {
          "size": 12
         },
         "type": "scattergl",
         "x": [
          5.135653972625732,
          4.982851982116699,
          5.183717250823975,
          4.962274074554443,
          5.189783573150635,
          5.03621768951416,
          5.356815814971924,
          4.902403831481934,
          4.95690393447876,
          4.609320163726807,
          4.917878150939941,
          4.949100494384766,
          5.790241718292236,
          4.736451625823975,
          5.488430023193359,
          5.4747161865234375,
          5.1188154220581055,
          5.361203193664551,
          5.271289348602295,
          4.880404949188232,
          4.971792697906494,
          5.62370491027832,
          4.918378829956055,
          5.116976261138916,
          4.6881103515625,
          5.336688995361328,
          4.746137619018555
         ],
         "y": [
          15.30492115020752,
          14.499214172363281,
          14.542190551757812,
          14.859920501708984,
          14.892168045043945,
          14.70409870147705,
          15.481633186340332,
          15.006077766418457,
          14.679647445678711,
          14.989038467407227,
          15.104727745056152,
          15.056818962097168,
          15.457401275634766,
          14.95963191986084,
          14.725896835327148,
          14.316985130310059,
          15.236235618591309,
          14.908285140991211,
          15.02234935760498,
          14.614309310913086,
          14.31050968170166,
          14.496283531188965,
          14.78415584564209,
          14.562529563903809,
          15.030397415161133,
          14.363509178161621,
          15.191940307617188
         ]
        },
        {
         "hoverinfo": "text",
         "hovertext": [
          " Filter only the contributions of the main characters\nmain_characters = ['marge', 'homer', 'bart', 'lisa', 'maggie', 'sideshow', 'ned', 'krusty', 'milhouse', 'chief']\ndf_script_main_characters = df_script[df_script['raw_character_text'].str.lower().isin(main_characters)]",
          " Extract all lines side by side and all names\nsimpsons_lines = list(df_script['raw_text'])\nsimpsons_characters = list(df_script['raw_character_text'])",
          "Selecting only the lines spoken by Homer\ndf_homer = df_script[df_script['raw_character_text'] == 'Homer Simpson'].reset_index(drop=True)",
          "Extract all lines concerning Marge from the script dataframe",
          "Extract only parts of the script featuring the Simpson family\ndf_simpsons_script = df_script[(df_script.raw_character_text == 'Marge')\n                      | (df_script.raw_character_text == 'Homer')\n                      | (df_script.raw_character_text == 'Bart')\n                      | (df_script.raw_character_text == 'Lisa')\n                      | (df_script.raw_character_text == 'Maggie')]",
          "# Create a DataFrame with the lines relevant to the character 'Homer Simpson' \nhomer_lines = df_script[df_script['character_id'] == 2].reset_index(inplace=False, drop=True)",
          "Filter lines that are spoken by the main characters\nmain_characters = df_characters[df_characters['char_is_primary']==1]",
          "Filter main characters\nmain_characters = [\"Lisa\", \"Bart\", \"Homer\", \"Marge\", \"Maggie\", \"Mr. Burns\"]\n\ndf_script_main_characters = df_script[df_script.raw_character_text.isin(main_characters)]",
          " Select main characters only\nmain_characters = [\n    \"marge\", \"homer\", \"bart\", \"lisa\", \"maggie\", \"skinner\", \"ned\", \"burns\",\n    \"milhouse\", \"moe\", \"krusty\", \"ralph\", \"apu\", \"barney\", \"nelson\", \"todd\",\n    \"edna\", \"bob\", \"itchy\", \"patty\", \"selma\", \"lionel\", \"patty\", \"selma\",\n    \"tilly\", \"sideshow\", \"abe\", \"krabappel\", \"carl\", \"lenny\", \"frink\"\n]\n\n# Filter main characters lines\ndf_script_main = df_script[df_script.raw_character_text.str.lower().isin(main_characters)]\n\n# Filter non trivial lines\ndf_script_main = df_script_main[df_script_main.spoken_words.str.len() > 2]",
          "Reduce the script data for a character-centric analysis\nmain_characters = ['marge', 'homer', 'bart', 'lisa', 'maggie', 'skinner', 'patty', 'selma', 'ned', 'krabappel', 'burns', 'milhouse']\nscript_idx = (df_script.raw_character_text.str.lower().isin(main_characters)) | (df_script.raw_character_text.isna())\ndf_script = df_script[script_idx]\n\n# Parse the data for a character-centric analyis\ndf_script.reset_index(drop=True, inplace=True)",
          "Filtering characters with name \"Lisa\" in 'The Simpsons' dataset\nlisa_id = df_characters[df_characters['character_name'].str.contains('lisa', case=False)]['id'].values[0]\n\nlisa_lines = df_script[df_script['character_id'] == lisa_id]",
          " Create a DataFrame consisting of only Bart's lines.\nbart_id = df_characters[df_characters.character_name == 'Bart Simpson'].character_id.values[0]",
          "# Select only lines spoken by Homer\nhomer_script_lines = df_script[df_script['raw_character_text'] == 'Homer Simpson']",
          "Clean script\ndf_script = df_script[df_script['utterance'].str.find('SIMPSON') != 0]\ndf_script = df_script[df_script['utterance'].str.find('HOMER') != 0]\ndf_script = df_script[df_script['utterance'].str.find('BART') != 0]\ndf_script = df_script[df_script['utterance'].str.find('LISA') != 0]\ndf_script = df_script[df_script['utterance'].str.find('MARGE') != 0]",
          "select only the lines spoken by Homer Simpson\ndf_homer = df_script[df_script['character_id'] == 2]\n\n# inspect the result\ndf_homer.head()",
          "# We will provide examples based on quotes involving 'Homer Simpson'.\nhomer_id = df_characters.loc[df_characters['character_name'].str.contains('Homer Simpson')].index[0]\nhomer_quotes = df_script.loc[df_script['character_id'] == homer_id]\nhomer_quotes.head()",
          "# Strip plotlines (out of memory exception, beware!)\nMAX_LINES = 100000\ndf_script = df_script[:MAX_LINES]\ndf_script = df_script[df_script['character_id'] != 2]  # Remove lines by Homer\ndf_script = df_script[df_script['raw_text'] != '']  # Remove empty lines",
          "Extract script with characters and their gender\ndf_script_characters = df_script.merge(df_characters, left_on='character_id', right_on='id')\n\n# Filter only episodes in English\ndf_script_characters = df_script_characters[df_script_characters['episode_id'].isin(df_episodes[df_episodes['original_air_date']!='un-aired']['id'])]\n\n# Remove non-spoken lines\ndf_script_characters = df_script_characters[-df_script_characters.raw_text.str.contains('Marge:[\\s\\S]*|Homer:[\\s\\S]*|Bart:[\\s\\S]*|Lisa:[\\s\\S]*|Maggie:[\\s\\S]*|Gerald:[\\s\\S]*|Carl: [\\s\\S]*|Lenny:[\\s\\S]*|Seymour:[\\s\\S]*|Moe:[\\s\\S]*|Chief Wiggum: [\\s\\S]*|Montgomery Burns:[\\s\\S]*|Waylon Smithers:[\\s\\S]*|Krusty:[\\s\\S]*|Ned:[\\s\\S]*|Rev. Lovejoy:[\\s\\S]*|Edna: [\\s\\S]*|Milhouse:[\\s\\S]*|Skinner:[\\s\\S]*|Patty:[\\s\\S]*|Selma:[\\s\\S]*|Barney:[\\s\\S]*|Apu:[\\s\\S]*|Nelson:[\\s\\S]*|Jimbo:[\\s\\S]*|Dolph:[\\s\\S]*|Kearney:[\\s\\S]*|Rod:[\\s\\S]*|Todd:[\\s\\S]*|Maude:[\\s\\S]*|Helen:[\\s\\S]*|Miss.Hoover:[\\s\\S]*|Sherri:[\\s\\S]*|Terri:[\\s\\S]*|Martin:[\\s\\S]*|Santa\\'s Little Helper:[\\s\\S]*|Patty and Selma:[\\s\\S]*|Groundskeeper Willie:[\\s\\S]*|Bob:[\\s\\S]*|Frank:[\\s\\S]*|Dr. Hibbert:[\\s\\S]*|Jasper:[\\s\\S]*|Cletus:[\\s\\S]*|Sideshow Bob:[\\s\\S]*|Mayor Quimby:[\\s\\S]*|Snake:[\\s\\S]*|Disco Stu:[\\s\\S]*|Reverend Lovejoy:[\\s\\S]*|Wiggum:[\\s\\S]*|Ap...",
          "Choosing a subset of the characters to focus on\ncharacters_focus = [\n    'Lisa_Simpson',\n    'Bart_Simpson',\n    'Homer_Simpson',\n    'Marge_Simpson',\n    'C._Montgomery_Burns',\n    'Seymour_Skinner',\n    'Ned_Flanders',\n    'Moe_Szyslak',\n    'Grampa_Simpson',\n    'Milhouse_Van_Houten',\n    'Krusty_The_Clown',\n    'Chief_Wiggum',\n    'Waylon_Smithers'\n]\n\n# Reduce the dataframes to what we need\ndf_script = df_script[df_script['raw_character_text'].isin(characters_focus)]\ndf_characters = df_characters[df_characters['name'].isin(characters_focus)]\ndf_characters['character_id'] = df_characters['id']\ndf_locations = df_locations[df_locations['normalized_name'].str.contains('springfield', case=False, na=False)]\ndf_script = df_script[df_script['episode_id'].isin(df_locations['episode_id'])]",
          "Keep only Homer speaking lines\nhomer_utterances = df_script[(df_script['character_id'] == df_characters[df_characters['raw_character_text'] == 'Homer Simpson'].iloc[0]['id'])]",
          "Unify character IDs in 'df_script' CRUCIAL TO EXECUTE FIRST\ndf_script['character_id'] = np.where(df_script.raw_character_text == 'Other_Spuckler', 132,\n                               np.where(df_script.raw_character_text == 'Sherri/Terri', 140,\n                                        np.where(df_script.raw_character_text == 'Question\\'s Voice', 180,\n                                                 np.where(df_script.raw_character_text == 'French President', 321,\n                                                          df_script.character_id))))\ndf_script['character_id'].replace(df_characters.set_index('character_id').raw_character.str.split().to_dict()['Homer'], 1, inplace=True)\ndf_script['character_id'].replace(df_characters.set_index('character_id').raw_character.str.split().to_dict()['Marge'], 2, inplace=True)\ndf_script['character_id'].replace(df_characters.set_index('character_id').raw_character.str.split().to_dict()['Bart'], 8, inplace=True)\ndf_script['character_id'].replace(df_characters.set_index('character_id').raw_character.str.split().to_dict()['Lisa'], 9, inplace=True)\ndf_script['character_id'].replace(df_characters.set_index('character_id').raw_character.str.split().to_dict()['Maggie'], 10, inplace=True)\ndf_script['character_id'].replace(df_characters.set_index('character_id').raw_character.str.split().to_dict()['Santa\\'s Little Helper'], 14, inplace=True)\ndf_script['character_id'].replace(df_characters.set_index('character_id').raw_character.str.split().to_dict()['Seymour Skinner'], 15, inplace=True)\ndf_script['character_id'].replace(df_characters.set_index('character_id').raw_character.str.split().to_dict()['Ned Flanders'], 16, inplace=True)\ndf_script['character_id'].replace(df_characters.set_index('character_id').raw_character.str.split().to_dict()['Grampa'], 17, inplace=True)\ndf_script['character_id'].replace(df_characters.set_index('character_id').raw_character.str.split().to_dict()[\"Krusty the Clown\"], 20, inplace=True)\ndf_script['character_id'].replace(df_characters.set_index('character_id').raw_character.str.split().to_dict()['Rev. Timothy Lovejoy'], 21, inplace=True)\ndf_script['character_id'].replace(df_characters.set_index('character_id').raw_character.str.split().to_dict()['Edna Krabappel'], 22, inplace=True)\ndf_script['character_id'].replace(df_characters.set_index('character_id').raw_character.str.split().to_dict()['Kent Brockman'], 25, inplace=True)",
          "Remove any neutral or irrelevant sentences and characters from the scripts\ndf_script = df_script[~df_script['raw_text'].str.contains(\"MAGGIE|MARGE|LISA|HOMER|BART|MAYOR QUIMBY|AINSWORTH|MAN'S VOICE|WOMAN'S VOICE|ALLURING VOICE|BART AND LISA|SQUEAKY VOICE|SFX|TALKING TO MAIN DOOR|SFX\")]",
          " Generate a DataFrame with only the data we are interested in\ndf_script_mentions = df_script[(df_script.raw_character_text != ' ') & \n                     (df_script.raw_character_text != 'Marge_Simpson') & \n                     (df_script.raw_character_text != 'Lisa_Simpson') & \n                     (df_script.raw_character_text != 'Bart_Simpson') & \n                     (df_script.raw_character_text != 'Homer_Simpson') & \n                     (df_script.raw_character_text != 'Couch_Gag')].reset_index(inplace=False, drop=True)",
          "Extract lines for specific character\nhomer = df_script[df_script['character_id'] == 2]\nmarge = df_script[df_script['character_id'] == 1]\nbart = df_script[df_script['character_id'] == 8]\nlisa = df_script[df_script['character_id'] == 9]\nmaggie = df_script[df_script['character_id'] == 16]",
          "Limiting to main characters\nmain_characters = [\n    'marge',\n    'homer',\n    'bart',\n    'lisa',\n    'maggie',\n    'krusty',\n    'moe',\n    'lenny',\n    'carl',\n    'ned',\n    'burns',\n    'skinner',\n    'apu',\n    'abe',\n    'barney',\n    'milhouse',\n    'nelson',\n    'ralph',\n    'jimbo',\n    'patty',\n    'selma',\n    'patty_selma',\n    'martin',\n    'todd',\n    'melt',\n    'milhouse_dad',\n    'milhouse_mom',\n    'skinner_mother',\n    'clancy',\n    'snake',\n    'mrs_krabappel',\n    'principal_knobbe',\n    'captain_mccallister',\n    'fat_tony',\n    'comic_book_guy',\n    'miss_hoover'\n]\n\ndf_script_main = df_script[\n    df_script.raw_character_text.str.lower().isin(main_characters)\n]",
          "Select only Homer's lines \ndf_homer = df_script[df_script.character_id == 2]",
          "# Name of the character we want to analyze\ncharacter_name = 'Lisa Simpson'\n\n# Filter the scripts df for the selected character\ndf_character = df_script[df_script.raw_character_text == character_name]"
         ],
         "marker": {
          "opacity": 0.5,
          "size": 5
         },
         "mode": "markers+text",
         "name": "113_Character-Centric Analysis on Simpson's Main Characters",
         "text": [
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          ""
         ],
         "textfont": {
          "size": 12
         },
         "type": "scattergl",
         "x": [
          6.179996013641357,
          5.023408889770508,
          5.5216288566589355,
          6.358156204223633,
          5.796576976776123,
          5.176877975463867,
          6.740157604217529,
          6.082879543304443,
          6.344040870666504,
          5.4819488525390625,
          5.281001091003418,
          4.968353748321533,
          6.1307501792907715,
          5.852427005767822,
          5.761517524719238,
          5.191442012786865,
          4.633995532989502,
          5.213858604431152,
          5.07314920425415,
          5.467442989349365,
          4.737197399139404,
          6.289778709411621,
          5.203256130218506,
          5.370481491088867,
          7.189770221710205,
          5.845903396606445,
          5.4268646240234375
         ],
         "y": [
          8.929422378540039,
          7.410016059875488,
          7.294764995574951,
          6.53528356552124,
          7.661623477935791,
          6.917562961578369,
          8.943082809448242,
          8.474607467651367,
          8.131318092346191,
          7.91060733795166,
          8.071154594421387,
          7.423593521118164,
          7.452406406402588,
          7.918712615966797,
          7.021749496459961,
          7.723353862762451,
          7.140495777130127,
          7.767259120941162,
          8.112671852111816,
          7.527571201324463,
          7.590237140655518,
          7.818728923797607,
          7.437047481536865,
          7.241001129150391,
          7.889196395874023,
          7.236144065856934,
          8.323680877685547
         ]
        },
        {
         "hoverinfo": "text",
         "hovertext": [
          "Creation of the spacy model\nnlp = spacy.load('en_core_web_sm')",
          "Load spacy model\nnlp = spacy.load('en_core_web_sm')",
          "Load Spacy model\nnlp = spacy.load(\"en_core_web_sm\")",
          "Load spacy model\nnlp = spacy.load('en_core_web_sm')",
          "Load Spacy model\nnlp = spacy.load('en_core_web_sm')",
          "Load spacy models\nnlp = spacy.load('en_core_web_sm')",
          "Initialize spaCy model\nnlp = spacy.load(\"en_core_web_sm\")",
          "nitialize spaCy model\nnlp = spacy.load('en_core_web_sm')",
          "Load NLP models\nnlp = spacy.load(\"en_core_web_sm\")",
          "Path to spacy model\nnlp = spacy.load('en_core_web_sm')",
          "load spacy model\nnlp = spacy.load('en_core_web_sm')",
          " Load spaCy model\nnlp = spacy.load('en_core_web_sm')",
          "Load Spacy model\nnlp = spacy.load('en_core_web_sm')",
          " Initialize models\nnlp = spacy.load('en_core_web_sm')",
          " Load Spacy NLP model\nnlp = spacy.load('en_core_web_sm')",
          "Path to Spacy model\nnlp = spacy.load('en_core_web_sm')",
          "Explicitly load in the required spacy model.\nnlp = spacy.load(\"en_core_web_sm\")",
          "Home directory\nhome = os.path.expanduser('~')\n\n# Spacy model\nnlp = spacy.load('en_core_web_sm')",
          "Load spacy model\nnlp = spacy.load(\"en_core_web_sm\")",
          "Load spaCy model\nnlp = spacy.load(\"en_core_web_sm\")",
          "Initialization of Spacy model\nnlp = spacy.load('en_core_web_sm')",
          "Load SpaCy NLP model\nnlp = spacy.load('en_core_web_sm')",
          "Load spacy model\nnlp = spacy.load('en_core_web_sm')",
          "Load Spacy model\nnlp = spacy.load('en_core_web_sm')",
          "Load spaCy model\nnlp = spacy.load('en_core_web_sm')",
          "Load embeddings model\nnlp = spacy.load('en_core_web_lg')",
          "Load the spaCy model\nnlp = spacy.load(\"en_core_web_sm\")"
         ],
         "marker": {
          "opacity": 0.5,
          "size": 5
         },
         "mode": "markers+text",
         "name": "114_Spacy load encore web sm model",
         "text": [
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          ""
         ],
         "textfont": {
          "size": 12
         },
         "type": "scattergl",
         "x": [
          16.02137565612793,
          15.826312065124512,
          16.012617111206055,
          15.765942573547363,
          15.621726036071777,
          15.65906047821045,
          16.721397399902344,
          16.4298095703125,
          15.76655101776123,
          16.17735481262207,
          15.861745834350586,
          15.89155101776123,
          15.678619384765625,
          16.347013473510742,
          15.526432037353516,
          16.00252914428711,
          16.327470779418945,
          16.92928123474121,
          16.32887077331543,
          16.315776824951172,
          16.607145309448242,
          15.63028621673584,
          15.594108581542969,
          15.750321388244629,
          15.851972579956055,
          15.29311752319336,
          16.3033447265625
         ],
         "y": [
          9.832995414733887,
          10.459482192993164,
          10.382193565368652,
          10.452584266662598,
          10.472428321838379,
          10.009184837341309,
          9.85717487335205,
          10.230237007141113,
          9.328131675720215,
          9.437338829040527,
          10.546607971191406,
          10.274618148803711,
          10.096699714660645,
          9.831827163696289,
          9.738936424255371,
          9.412623405456543,
          9.949809074401855,
          9.148561477661133,
          10.344496726989746,
          10.420075416564941,
          9.921873092651367,
          9.882956504821777,
          10.293730735778809,
          10.292949676513672,
          10.227765083312988,
          9.047389030456543,
          10.197250366210938
         ]
        },
        {
         "hoverinfo": "text",
         "hovertext": [
          "inspect the first 5 rows of the df_characters dataframe\ndf_characters.head()",
          "# Access the first 5 characters\ndf_characters.head()",
          "Inspect the first 5 rows of the characters dataframe\ndf_characters.head()",
          "Inspect first 5 rows of character dataset\ndf_characters.head()",
          "Inspect the first 5 rows of the characters dataframe\ndf_characters.head()",
          "Inspect the first five rows of the characters DataFrame\ndf_characters.head()",
          "Inspect first 5 rows of the characters dataframe\ndf_characters.head()",
          "Inspect the first 5 rows of the characters DataFrame\ndf_characters.head()",
          "Inspect the first 5 rows of the characters dataframe\ndf_characters.head()",
          "Inspect the first 5 rows of the characters DataFrame\ndf_characters.head()",
          "Explore the first 5 rows of the characters dataframe\ndf_characters.head()",
          "Inspect the first 5 rows of the characters DataFrame\ndf_characters.head()",
          "Inspect the first 5 rows of the characters dataframe\ndf_characters.head()",
          "Inspect the first 5 rows of the characters dataframe\ndf_characters.head()",
          "Explore the first 5 rows of the characters dataframe\ndf_characters.head()",
          "Examine the first 5 rows of the characters dataframe\ndf_characters.head()",
          "Inspect the first 5 rows of df_characters\ndf_characters.head()",
          " inspect the first 5 rows of the characters dataframe\ndf_characters.head()",
          "Inspect the first 5 lines of df_characters\ndf_characters.head()",
          "Inspect the first 5 rows of the characters dataframe\ndf_characters.head()",
          " Visual inspection of the first 5 rows of the `df_characters` dataframe\ndf_characters.head()",
          "Inspect the first 5 rows of the characters dataframe\ndf_characters.head()",
          "Inspect the first 5 records of the characters dataframe\ndf_characters.head()",
          "# Inspect first 5 rows of df_characters\ndf_characters.head()",
          "Inspect the content of the first 5 rows of the characters dataframe\ndf_characters.head()",
          "Inspect the first 5 rows of the characters dataframe\ndf_characters.head()",
          "Df tail for inspection\nprint(df_characters.tail(5))"
         ],
         "marker": {
          "opacity": 0.5,
          "size": 5
         },
         "mode": "markers+text",
         "name": "115_Character dataframe inspection",
         "text": [
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          ""
         ],
         "textfont": {
          "size": 12
         },
         "type": "scattergl",
         "x": [
          0.6956695914268494,
          -0.03723438084125519,
          0.8823257088661194,
          0.5350973606109619,
          1.1150500774383545,
          1.224211573600769,
          1.2234772443771362,
          1.2560548782348633,
          1.0884413719177246,
          1.1310174465179443,
          0.9381269812583923,
          0.761724054813385,
          1.1814669370651245,
          1.1949998140335083,
          0.7673284411430359,
          1.0103856325149536,
          0.6303859353065491,
          0.8933296799659729,
          0.5250437259674072,
          1.3013672828674316,
          0.7018909454345703,
          0.960599958896637,
          0.6974563598632812,
          0.3922559916973114,
          0.9777366518974304,
          0.9336279630661011,
          -0.5677937269210815
         ],
         "y": [
          11.703015327453613,
          12.452908515930176,
          11.601638793945312,
          11.949932098388672,
          11.387921333312988,
          11.396007537841797,
          11.285147666931152,
          11.575774192810059,
          11.656160354614258,
          11.405633926391602,
          11.220762252807617,
          11.244062423706055,
          11.345375061035156,
          11.508708000183105,
          11.080466270446777,
          11.314806938171387,
          12.281004905700684,
          11.566841125488281,
          12.533651351928711,
          11.444034576416016,
          11.493406295776367,
          11.674065589904785,
          12.102018356323242,
          11.9744291305542,
          11.227108001708984,
          11.460305213928223,
          12.484833717346191
         ]
        },
        {
         "hoverinfo": "text",
         "hovertext": [
          "Information about the datasets",
          "Basic overview of datasets",
          "Exploring the dataset and quick looks at the data.",
          "Initial exploration of datasets",
          "Exploring the obtained datasets",
          "Explore datasets dimensions",
          "\n# Some basic information about the datasets",
          " Some basic exploration of the datasets",
          " Exploring the datasets",
          "Quick analysis of the input datasets",
          "Profiling the different dataset",
          "Exploring the datasets",
          "Explore the datasets",
          "General analysis on the datasets.",
          "Initial investigation of the datasets",
          "Example of using the dataset.",
          "Dataset Exploration",
          "Explore datasets",
          "Exploring the dataset",
          "Exploring the datasets",
          "Description of the datasets",
          "Exploring the content of the datasets",
          "Description of the datasets.",
          "Explore the content of the datasets",
          "Exploring the dataset.",
          "Some basic info of the datasets",
          "Exploring dataset"
         ],
         "marker": {
          "opacity": 0.5,
          "size": 5
         },
         "mode": "markers+text",
         "name": "116_Exploring Datasets",
         "text": [
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          ""
         ],
         "textfont": {
          "size": 12
         },
         "type": "scattergl",
         "x": [
          15.887296676635742,
          16.177001953125,
          16.33953094482422,
          16.892873764038086,
          16.63550567626953,
          15.982524871826172,
          15.493408203125,
          16.335607528686523,
          16.84232521057129,
          15.783390998840332,
          16.162471771240234,
          16.693904876708984,
          16.260343551635742,
          16.696603775024414,
          16.130088806152344,
          15.711280822753906,
          16.795677185058594,
          16.463960647583008,
          16.738548278808594,
          16.623886108398438,
          15.805662155151367,
          16.21881866455078,
          15.673367500305176,
          15.64235782623291,
          16.972909927368164,
          15.973705291748047,
          16.862510681152344
         ],
         "y": [
          -2.531475067138672,
          -2.4935646057128906,
          -1.888274073600769,
          -1.8766999244689941,
          -2.138035774230957,
          -2.908308267593384,
          -2.918982744216919,
          -2.0866689682006836,
          -2.2512104511260986,
          -2.309039831161499,
          -2.677255630493164,
          -1.972651720046997,
          -2.2485032081604004,
          -2.3618149757385254,
          -2.220625400543213,
          -2.256962776184082,
          -0.585424542427063,
          -2.01444935798645,
          -2.0234951972961426,
          -2.1832125186920166,
          -2.498851776123047,
          -2.4563019275665283,
          -2.595200777053833,
          -2.139259099960327,
          -2.284135341644287,
          -2.3715837001800537,
          -1.6796207427978516
         ]
        },
        {
         "hoverinfo": "text",
         "hovertext": [
          "Convert timestamp_in and timestamp_out columns to datetime format",
          "Filtering dataset to include only the first 20 seasons\ndf_episodes_first_20_seasons = df_episodes[df_episodes['season'] <= 20]\n# converting date of release to a datetime object\ndf_episodes_first_20_seasons['original_air_date'] = pd.to_datetime(df_episodes_first_20_seasons['original_air_date'])\n\ndf_episodes_first_20_seasons.head()",
          " convert date from string to datetime in episodes data\ndf_episodes['original_air_date'] = pd.to_datetime(df_episodes['original_air_date'])",
          "Create a column for the episode's season and convert the date to a datetime type\ndf_episodes['season'] = df_episodes['production_code'].str.slice(2, 4)\ndf_episodes['original_air_date'] = pd.to_datetime(df_episodes['original_air_date'], infer_datetime_format=True)",
          " One-hot encode the year and season\ndf_episodes = df_episodes.join(pd.get_dummies(df_episodes.season, prefix='season'))\ndf_episodes = df_episodes.join(pd.get_dummies(df_episodes.air_date.dt.year, prefix='year'))",
          "Convert the episode air date to datetime object\ndf_episodes['original_air_date'] = pd.to_datetime(df_episodes['original_air_date'])\n\n# Show first 5 characters in the characters dataset\ndf_characters.head()",
          "Fix dates\ndf_episodes['original_air_date'] = pd.to_datetime(df_episodes['original_air_date'], errors='coerce')\ndf_episodes.moveToFirstAirenDate = pd.to_datetime(df_episodes.moveToFirstAirenDate, errors='coerce')",
          "Remove very beginning of date from date column in df_episodes\ndf_episodes['date'] = df_episodes['date'].apply(lambda x: str(x)[10:] if pd.notnull(x) else x)",
          "Change format of air_date to date and change TZ to UTC\ndf_episodes['original_air_date'] = pd.to_datetime(df_episodes['original_air_date'], errors='coerce')\ndf_episodes['original_air_date'] = df_episodes['original_air_date'].dt.tz_localize('US/Pacific').dt.tz_convert('UTC')",
          " Converts strings to datetime\ndf_episodes['original_air_date'] = pd.to_datetime(df_episodes['original_air_date'], format='%Y-%m-%d')",
          " Convert the date and time attribute to datetime\ndf_episodes['original_air_date'] = pd.to_datetime(df_episodes['original_air_date'])",
          " Convert the date from string to datetime\ndf_episodes['original_air_date'] = pd.to_datetime(df_episodes['original_air_date'])",
          "Convert timestamps to datetime\ndf_script['timestamp_in_ms'] = pd.to_numeric(df_script['timestamp_in_ms'], errors='coerce').fillna(0).astype(np.int64)\ndf_script['timestamp'] = pd.to_datetime(df_script['timestamp_in_ms'], unit='ms')\n\n# Convert timestamps to datetime\ndf_episodes['original_air_date'] = pd.to_datetime(df_episodes['original_air_date'], errors='coerce')",
          "Convert date attributes to datetime\ndf_episodes['original_air_date'] = pd.to_datetime(df_episodes['original_air_date'])",
          "Change the episode air date to a datetime object\ndf_episodes['original_air_date'] = pd.to_datetime(df_episodes['original_air_date'], infer_datetime_format=True)",
          "Converts date attributes to Python date objects\ndf_episodes['original_air_date'] = pd.to_datetime(df_episodes['original_air_date'])\n\n# Drop unnecessary columns and rename others\ndf_episodes.drop(['id', 'image_url', 'video_url'], axis=1, inplace=True)\ndf_episodes.rename(columns={'id_s': 'episode_id', 'id': 'character_id', 'name': 'character_name'}, inplace=True)",
          "Change episodes to its datetime column\ndf_episodes['original_air_date'] = pd.to_datetime(df_episodes['original_air_date'])",
          "Create a list with episodes dates\nep_dates = df_episodes['original_air_date'].tolist()\nep_dates",
          "Format date\ndf_episodes.is_airing = pd.to_datetime(df_episodes.is_airing, errors='coerce')\ndf_episodes.production_code = pd.to_numeric(df_episodes.production_code, errors='coerce')",
          "Create a datetime object from the air date of each episode",
          "Convert to datetime the air_date and create a timestamp index",
          "Ensure that the dataframe the correct dtypes\ndf_episodes['original_air_year'] = pd.to_numeric(df_episodes['original_air_year'], errors='coerce')\ndf_episodes['production_code'] = pd.to_numeric(df_episodes['production_code'], errors='coerce')\ndf_script['timestamp_in_ms'] = pd.to_numeric(df_script['timestamp_in_ms'], errors='coerce')",
          "Change the format of the air_date column to datetime\ndf_episodes['air_date'] = pd.to_datetime(df_episodes['air_date'])",
          "Create a column with only the year of the episode for ease of analysis\ndf_episodes['year'] = df_episodes['original_air_date'].apply(lambda x: int(x.split('-')[0]))",
          "Change epsiode air date to datetime\ndf_episodes['original_air_date'] = pd.to_datetime(df_episodes['original_air_date'])",
          "# Time idx's\ntime_since_release = pd.to_datetime(df_episodes.timestamp, unit='s') - pd.to_datetime(df_episodes.timestamp, unit='s').min()\nyears_since_release = time_since_release.dt.days / 365.25",
          "Convert datePublished column to pandas datetime\ndf_episodes['datePublished'] = pd.to_datetime(df_episodes['datePublished'])"
         ],
         "marker": {
          "opacity": 0.5,
          "size": 5
         },
         "mode": "markers+text",
         "name": "117_Converting dates to datetime in episodes data",
         "text": [
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          ""
         ],
         "textfont": {
          "size": 12
         },
         "type": "scattergl",
         "x": [
          4.298065662384033,
          4.163503646850586,
          4.06547212600708,
          3.539191484451294,
          3.4440629482269287,
          3.9458861351013184,
          3.9160916805267334,
          3.7483408451080322,
          3.6490159034729004,
          4.052380561828613,
          3.762505292892456,
          3.7637665271759033,
          4.118590831756592,
          3.8082773685455322,
          3.818223237991333,
          3.574470281600952,
          3.8873565196990967,
          3.634592056274414,
          3.7004847526550293,
          3.942063808441162,
          3.929079532623291,
          3.8140621185302734,
          3.713643789291382,
          3.2809507846832275,
          3.78752064704895,
          3.5986647605895996,
          3.959878444671631
         ],
         "y": [
          2.1872217655181885,
          3.2337818145751953,
          1.978622317314148,
          2.690556526184082,
          3.067110538482666,
          2.277524709701538,
          2.3953564167022705,
          3.10538649559021,
          2.115021228790283,
          1.8243334293365479,
          1.9365777969360352,
          2.2882487773895264,
          2.125812292098999,
          1.8821439743041992,
          1.9939191341400146,
          2.3321287631988525,
          2.5427656173706055,
          2.9556546211242676,
          1.819912314414978,
          2.242981195449829,
          1.8467248678207397,
          2.229362964630127,
          1.9186484813690186,
          3.588785171508789,
          2.1663668155670166,
          2.2444777488708496,
          1.93282151222229
         ]
        },
        {
         "hoverinfo": "text",
         "hovertext": [
          "Preview the first 5 rows of the characters dataset\ndf_characters.head()",
          "Preview first 5 entries of df_characters\ndf_characters.head()",
          "Preview the first 5 rows of the characters dataframe\ndf_characters.head()",
          "Preview the first 5 rows of the characters dataframe\ndf_characters.head()",
          "Preview the first 5 rows of the characters dataframe\ndf_characters.head()",
          "Preview the first three rows of the characters data\ndf_characters.head(3)",
          "Preview the first 5 lines of the characters dataframe\ndf_characters.head()",
          "Preview the first 5 rows of the characters dataframe\ndf_characters.head()",
          "Preview the first 5 rows of 'df_characters' DataFrame\ndf_characters.head()",
          "Preview the first few rows of the characters dataframe\ndf_characters.head()",
          "Preview the first 5 rows of the characters dataframe\ndf_characters.head()",
          "Preview the first 5 rows of the characters dataframe\ndf_characters.head()",
          "Preview the first five rows of the characters dataframe\ndf_characters.head()",
          "Preview the first 5 rows of the characters dataframe\ndf_characters.head()",
          "Preview the first 5 rows of the characters dataframe\ndf_characters.head()",
          "Preview the first 5 rows of the characters dataframe\ndf_characters.head()",
          "Preview the first 5 rows of the characters dataframe\ndf_characters.head()",
          "Preview the first 5 rows of the dataset\ndf_characters.head()",
          "Previewing the first 5 lines of the dataframe containing the characters and the first 5 lines of the dataframe containing the locations",
          "Preview the first 5 rows of the characters dataframe\ndf_characters.head()",
          "Preview the first 5 rows of the characters dataframe\ndf_characters.head()",
          " Preview the first 5 rows of the characters dataframe\ndf_characters.head()",
          " Preview the first 5 rows of the characters dataframe\ndf_characters.head()",
          "Preview the first 5 rows of the characters dataframe\ndf_characters.head()",
          " Preview the first 5 rows of the characters dataset\ndf_characters.head()",
          "Preview the first 5 rows of the characters dataframe\ndf_characters.head()"
         ],
         "marker": {
          "opacity": 0.5,
          "size": 5
         },
         "mode": "markers+text",
         "name": "118_Previewing the first 5 rows of the characters dataframe",
         "text": [
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          ""
         ],
         "textfont": {
          "size": 12
         },
         "type": "scattergl",
         "x": [
          -7.438317775726318,
          -7.7040510177612305,
          -7.773566722869873,
          -7.125810146331787,
          -7.357280254364014,
          -7.244059085845947,
          -6.917205333709717,
          -7.516027927398682,
          -7.1372551918029785,
          -7.650065898895264,
          -7.558701515197754,
          -7.257658958435059,
          -7.102442741394043,
          -7.440272808074951,
          -7.576173782348633,
          -7.61530065536499,
          -7.447253227233887,
          -7.399932861328125,
          -5.717746257781982,
          -7.519309997558594,
          -7.344157695770264,
          -7.50693941116333,
          -7.460546493530273,
          -7.570826530456543,
          -7.1813764572143555,
          -7.420230865478516
         ],
         "y": [
          7.149905681610107,
          6.457686901092529,
          6.840263366699219,
          6.908172130584717,
          6.540593147277832,
          7.315430641174316,
          6.450938701629639,
          6.576046466827393,
          6.3310160636901855,
          6.680788516998291,
          6.8190531730651855,
          6.515664577484131,
          6.298465728759766,
          6.4968671798706055,
          6.716794013977051,
          6.866822242736816,
          6.662441730499268,
          6.987102031707764,
          6.255563735961914,
          6.7746124267578125,
          6.625888824462891,
          6.58855676651001,
          6.668496131896973,
          6.736334800720215,
          7.2176432609558105,
          6.447887420654297
         ]
        },
        {
         "hoverinfo": "text",
         "hovertext": [
          "# The 'df_script' dataframe contains all the script lines. Let's take a look at the first few rows.\ndf_script.head()",
          " Look at the script data frame\ndf_script.head()",
          "Quick overview of the script dataframe\ndf_script.head()",
          " Explore the content of one of the dataframes\ndf_script.head()",
          "Inspect the contents of the scriptlines DataFrame to understand its structure and the kind of data it contains.\ndf_script.head()",
          "Sample of script dataframe\ndf_script.head()",
          "Inspect dataframe\ndf_script.head()",
          "The structure for the script line dataframe is:\ndf_script.head()",
          "Look at the first few rows of the script dataframe\ndf_script.head()",
          " Look at the first 5 rows of the script dataframe\ndf_script.head()",
          "Check the head of the script dataframe to understand its structure\ndf_script.head()",
          " Explore the dataframe\ndf_script.head()",
          " Look at the head of the script dataframe to understand its structure\ndf_script.head()",
          "Inspecting the structure of script lines dataframe\ndf_script.head()",
          "Optional - Explore a dataframe\ndf_script.head()",
          "Inspecting the DataFrame head\ndf_script.head()",
          " Merge dataframes to get all the information in one place\n# Let's analyze the line by line script data\ndf_script.head()",
          " Review the merged dataframe\ndf_script.head()",
          "Check the first few lines of the dataframe to understand its structure\ndf_script.head()",
          "Quick 'n dirty peek at the script dataframe\ndf_script.head()",
          "Let's have a look at the content of the script dataframe:\ndf_script.head()",
          "Take a peek at the first few rows of the \"script\" dataframe\ndf_script.head()",
          "Look at the top 5 rows of df_script\ndf_script.head()",
          "Quick look at the scripts dataframe\ndf_script.head()",
          "# Assessing the dataframe quickly\ndf_script.head()",
          "let's focus on the script dataframe for now\ndf_script.head()"
         ],
         "marker": {
          "opacity": 0.5,
          "size": 5
         },
         "mode": "markers+text",
         "name": "119_Exploring and Reviewing DataFrames in Python",
         "text": [
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          ""
         ],
         "textfont": {
          "size": 12
         },
         "type": "scattergl",
         "x": [
          5.940707683563232,
          5.349546432495117,
          5.998857498168945,
          6.637335300445557,
          5.714324951171875,
          5.875072479248047,
          6.60667085647583,
          5.628426551818848,
          4.992537498474121,
          4.719744682312012,
          5.481146812438965,
          6.142026424407959,
          5.202146053314209,
          5.621458053588867,
          6.251135349273682,
          6.380434989929199,
          6.272228717803955,
          6.247647285461426,
          4.935079097747803,
          6.271449565887451,
          6.0105509757995605,
          5.771035194396973,
          4.884444713592529,
          5.6391825675964355,
          6.631340980529785,
          6.039464473724365
         ],
         "y": [
          -4.996739864349365,
          -4.998600959777832,
          -5.634850025177002,
          -4.780200958251953,
          -4.438992023468018,
          -6.219767093658447,
          -5.301758766174316,
          -4.950715065002441,
          -5.267045497894287,
          -5.1885762214660645,
          -4.556173801422119,
          -5.40593147277832,
          -4.761643886566162,
          -5.031070232391357,
          -5.5533905029296875,
          -4.856078147888184,
          -4.0460381507873535,
          -4.838844299316406,
          -4.633986949920654,
          -5.281553268432617,
          -4.995001792907715,
          -5.303869247436523,
          -4.857287883758545,
          -5.605619430541992,
          -5.822227954864502,
          -5.830677032470703
         ]
        },
        {
         "hoverinfo": "text",
         "hovertext": [
          "Test out the dataframes",
          " Checking all DataFrames",
          "Check a sample of the data for each dataframe",
          "Checking the simpons dataframe data.",
          " Print the shape of the dataframes to check if the files are read correctly",
          "Check the content inside the dataframe",
          " Check that everything worked by printing a snippet of each DataFrame",
          " Check the content of the dataframes",
          " Validate the integration by printing a few lines of each dataframe",
          "Checking the content of the dataframes",
          " Check the information in each dataframe.",
          " Check what's in the dataframes",
          "Check how the dataframes are looking",
          "Check if we have the correct dataframes",
          "Checking dataframes",
          "Check the dataframe schema",
          "Check the general information of the Python DataFrames",
          "Check dataframes shape and types",
          "Check what the dataframes look like",
          "Check the content of each DataFrame",
          "Check the contents of each dataframe",
          "Checking the shape of each dataframe",
          "# Room for checking the contents of the dataframes",
          "Checking the dataframes",
          "Checking Python version for compatibility",
          "Check content of dataframe with confirmed deduplication"
         ],
         "marker": {
          "opacity": 0.5,
          "size": 5
         },
         "mode": "markers+text",
         "name": "120_Dataframe Checking and Deduplication",
         "text": [
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          ""
         ],
         "textfont": {
          "size": 12
         },
         "type": "scattergl",
         "x": [
          10.940844535827637,
          10.199901580810547,
          9.980046272277832,
          10.904794692993164,
          10.766112327575684,
          9.811761856079102,
          10.013586044311523,
          9.86974048614502,
          9.99400806427002,
          10.090570449829102,
          10.285046577453613,
          10.125527381896973,
          10.662156105041504,
          9.898860931396484,
          10.169995307922363,
          10.076619148254395,
          10.491256713867188,
          10.640633583068848,
          10.487356185913086,
          9.954168319702148,
          10.066174507141113,
          10.686403274536133,
          9.969463348388672,
          10.327869415283203,
          10.547057151794434,
          9.334877967834473
         ],
         "y": [
          -3.772329330444336,
          -3.2522943019866943,
          -3.135481595993042,
          -3.7709267139434814,
          -3.91416072845459,
          -3.228377342224121,
          -3.4384782314300537,
          -3.578956127166748,
          -3.5104503631591797,
          -3.4556164741516113,
          -4.705386161804199,
          -3.8599936962127686,
          -4.02166748046875,
          -2.979374647140503,
          -3.292083740234375,
          -3.9329326152801514,
          -3.830974817276001,
          -2.8060712814331055,
          -4.230959892272949,
          -3.5076022148132324,
          -3.2558369636535645,
          -3.8886361122131348,
          -3.0416276454925537,
          -3.617450475692749,
          -2.7079415321350098,
          -2.577840805053711
         ]
        },
        {
         "hoverinfo": "text",
         "hovertext": [
          "Let's start by looking at the first few rows of the characters, locations, script, and episodes DataFrames.",
          "Check the first 5 entries of the characters, locations, script and episodes datasets.",
          "Check for names, locations and episode mentioned in the script data",
          "Exploring the data: characters, locations, and episodes.",
          "###############################################################################\n# Unique Characters, Locations, Episodes\n###############################################################################",
          " For the characters and locations datasets, we only want characters that are in at least 5 episodes, and locations that appeared in at least 3 episodes.",
          "# Given a character, determining how many unique locations that character has been to.",
          "This data consists of four tables: characters, locations, script lines, and episodes.",
          "Show the number of scenes, number of characters, and number of locations.",
          "Filter episodes where the character interacts with a location.",
          " Now, let's take a look on characters, script, episode and locations DataFrames.",
          "Build lookup tables for characters, locations, and episodes",
          " Assign colors to characters, locations, and episodes so that plots are understandable.",
          "Explore characters, locations, script lines, and episodes dataframes",
          " Let's display the number of characters, locations, script lines and episodes.",
          "Let's display the first few rows of characters, locations, script and episodes dataframes.",
          " Encode characters, locations and episodes",
          "Extract main locations from the episodes and count the number of episodes in each location.",
          "Query: Total number of characters, locations and episodes available in the dataset",
          "Let's explore the data by displaying information about the characters, locations, episodes, and script lines.",
          "This will allow us to see how many unique and major characters, episodes, and locations we are working with.",
          "Next, let's see how many unique characters, locations, and episodes are present in the dataset.",
          " Take a look at the characters, locations, script and episodes dataframes",
          "Check the number of characters, locations and episodes",
          "Define the main characters, seasons, and locations for the analysis.",
          "Let's take a look at the characters, locations, script and episodes DataFrames."
         ],
         "marker": {
          "opacity": 0.5,
          "size": 5
         },
         "mode": "markers+text",
         "name": "121_Determining Number of Unique Characters, Locations, and Episodes",
         "text": [
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          ""
         ],
         "textfont": {
          "size": 12
         },
         "type": "scattergl",
         "x": [
          8.536088943481445,
          8.160601615905762,
          8.470663070678711,
          8.852123260498047,
          8.75790023803711,
          8.320247650146484,
          8.405075073242188,
          8.525565147399902,
          8.993034362792969,
          8.325020790100098,
          9.010275840759277,
          8.248486518859863,
          9.904749870300293,
          8.265877723693848,
          8.749332427978516,
          8.519735336303711,
          8.220047950744629,
          7.972224235534668,
          8.480436325073242,
          8.503751754760742,
          8.496302604675293,
          8.819243431091309,
          8.793339729309082,
          8.453666687011719,
          9.17996883392334,
          8.939080238342285
         ],
         "y": [
          5.975276947021484,
          5.473281383514404,
          4.943573951721191,
          5.825862407684326,
          5.143496990203857,
          5.060222148895264,
          6.072122573852539,
          5.350042819976807,
          5.516519546508789,
          5.172798156738281,
          6.654595375061035,
          5.535815238952637,
          6.389922142028809,
          5.569836616516113,
          5.657204627990723,
          5.616372585296631,
          5.579838275909424,
          5.465085506439209,
          5.768927574157715,
          5.807010650634766,
          5.323390007019043,
          5.711135387420654,
          6.043769836425781,
          5.872736930847168,
          5.53485107421875,
          6.19073486328125
         ]
        },
        {
         "hoverinfo": "text",
         "hovertext": [
          "Check if datasets were loaded properly\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()",
          "Check that the dataframes were loaded successfully\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()",
          "Check dataframes are correctly loaded\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()",
          "Check files have been correctly loaded\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()",
          "Check if dataframes are correctly loaded\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()",
          "Reduce the size of the datasets for testing, not required for final use\ndf_script = df_script.head(10000)\ndf_episodes = df_episodes.head(1000)",
          "Check if all dataframes have been imported correctly\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()",
          " Ensure all csv files were correctly loaded\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()",
          "Check that the dataframes were imported correctly\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()",
          "Check all files have been loaded properly\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()",
          "Check if each dataframe was correctly loaded\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()",
          "Check if the dataframes have been read correctly\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()",
          "Check if all dataframes have been loaded successfully\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()",
          "Check that the dataframes have been loaded correctly\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()",
          "# ensure all dataset load correctly\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()",
          "Check if all files are properly loaded\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()",
          " Check the imported datasets\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()",
          "Check if all datasets have been loaded correctly\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()",
          "Check the loaded dataframes' contents\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()",
          "Check first few lines of all imported datasets\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()",
          "Check if the dataframe is loaded correctly\ndf_episodes.head()",
          "Check if all datasets were loaded correctly\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()",
          " Check if all datasets have been successfully loaded\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()",
          " Test the dataframes loaded correctly\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()",
          "check if all finishes properly\n[df_characters.shape, df_locations.shape, df_script.shape, df_episodes.shape]",
          "Check that all imports have been successful\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()"
         ],
         "marker": {
          "opacity": 0.5,
          "size": 5
         },
         "mode": "markers+text",
         "name": "122_Checking successful import of datasets and dataframes",
         "text": [
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          ""
         ],
         "textfont": {
          "size": 12
         },
         "type": "scattergl",
         "x": [
          -2.552370071411133,
          -3.0873024463653564,
          -3.118304491043091,
          -3.2535288333892822,
          -2.973231792449951,
          -1.6763741970062256,
          -3.001051902770996,
          -3.3817131519317627,
          -3.2551355361938477,
          -2.684530019760132,
          -3.1070432662963867,
          -3.377678394317627,
          -2.798814296722412,
          -3.069920539855957,
          -2.80023455619812,
          -2.94333553314209,
          -2.6049370765686035,
          -2.4209530353546143,
          -3.5871410369873047,
          -2.556807279586792,
          -2.0918312072753906,
          -2.6814048290252686,
          -2.7550241947174072,
          -3.344977378845215,
          -1.2540723085403442,
          -2.4475090503692627
         ],
         "y": [
          0.5509411096572876,
          -0.3996216952800751,
          -0.1240118071436882,
          -0.38485074043273926,
          -0.19013874232769012,
          1.0965230464935303,
          0.010510760359466076,
          -0.448354572057724,
          -0.3713385760784149,
          -0.3496339023113251,
          0.14085285365581512,
          -0.19916076958179474,
          -0.014321934431791306,
          -0.16004574298858643,
          0.5097247362136841,
          -0.3632259964942932,
          0.9432334303855896,
          -0.04202777147293091,
          0.13251619040966034,
          0.7013619542121887,
          0.3596314787864685,
          0.18106386065483093,
          0.18302080035209656,
          -0.30313628911972046,
          0.07290638238191605,
          -0.03529808670282364
         ]
        },
        {
         "hoverinfo": "text",
         "hovertext": [
          "Create a connection to the PostgreSQL database",
          "Connections -- Create PostgreSQL tables and upload the DataFrames",
          " Create an engine to run SQL queries on the database\nfrom sqlalchemy import create_engine",
          " Define the database file\ndb_file = \"simpsons.sqlite\"",
          "Connections and configurations for your database",
          "# Ensure the PostgreSQL server is running\n!service postgresql start",
          "connectionstring = \"postgresql://user:password@localhost/simpsons\"\n",
          "import sqlite3",
          "Connect to sqlite db\nimport sqlite3\n\nconn = sqlite3.connect('data/simpsons_script_database.db')",
          "Create a connection to Postgres database using sqlalchemy library.",
          "Create a connection to the database and extract the script lines",
          "Set verbose=True for SQL debugging\nos.environ['SQLALCHEMY_ECHO'] = 'True'\n\n# Create a connector using the preferred settings\n!username='' password='' host AWS_Web_Services_key='' Database_name='' !pip install records\nimport records  # from Database name ORM determined which database it should be connected and ORM performs this operation on behalf of us\n\ndef db_connector(*args, **kwargs):\n    return records.Database(*args, **kwargs)",
          "Create a limited number of connections and a limited number of command functions.",
          "# Ensure sqlite3 works in Jupyter\n%load_ext sql\n\n# Connect to the pre-loaded SQLite database\n%sql sqlite:///data/simpsons-database.db",
          "# Connect to local PostgreSQL database\nfrom sqlalchemy import create_engine\nengine = create_engine('postgresql://localhost/simpsons')\nconn = engine.connect()",
          " Connect to the SQLite database using the sqlalchemy package using the create_engine function in the sqlalchemy module.",
          "Create a connection to the database",
          "Create a connection to the PostgreSQL database",
          "Create an in-memory SQLite database that we can use to execute SQL queries\nfrom sqlalchemy import create_engine\n\n# This is a simple way to store and manipulate data.\n# We could also use this in-memory storage to filter data and create useful\n# transformations that we could then export to a more scalable solution\nengine = create_engine('sqlite://', echo=False)",
          "Create a connection to a database",
          "Create a connection to the SQLite database containing the data\nconn = sqlite3.connect('data/simpsons.sqlite')",
          "# Creating a connection\nfrom sqlalchemy import create_engine\nengine = create_engine('sqlite:///data/simpsons.db')",
          " Connect to the database",
          "Add relative path for SQL connections\nimport sys\nsys.path.append('..')",
          " Connect to our DB\ncon = sqlite3.connect(\"data/simpsons_script_database.db\")\n\n# Create cursor\ncur = con.cursor()",
          "Connect to SQL Database"
         ],
         "marker": {
          "opacity": 0.5,
          "size": 5
         },
         "mode": "markers+text",
         "name": "123_Database Connection in SQL and SQLAlchemy",
         "text": [
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          ""
         ],
         "textfont": {
          "size": 12
         },
         "type": "scattergl",
         "x": [
          15.652950286865234,
          15.050455093383789,
          14.945097923278809,
          14.49500846862793,
          15.904143333435059,
          14.834376335144043,
          15.324872016906738,
          14.683259963989258,
          14.79421615600586,
          15.457202911376953,
          15.574248313903809,
          15.04781723022461,
          13.312265396118164,
          14.389641761779785,
          15.073479652404785,
          15.059395790100098,
          15.795384407043457,
          15.530210494995117,
          15.049764633178711,
          15.727405548095703,
          14.759247779846191,
          14.879535675048828,
          15.83303165435791,
          15.215120315551758,
          14.51424789428711,
          15.88532543182373
         ],
         "y": [
          -5.620190143585205,
          -5.390946865081787,
          -5.098666667938232,
          -4.6594157218933105,
          -5.600085258483887,
          1.7481704950332642,
          -5.444742679595947,
          -4.812591075897217,
          -4.864520072937012,
          -5.34506893157959,
          -4.906728744506836,
          -4.4987688064575195,
          1.070399522781372,
          -4.62131404876709,
          -5.135873794555664,
          -5.209005355834961,
          -5.4594926834106445,
          -5.633216857910156,
          -5.215784549713135,
          -5.511723041534424,
          -4.979032039642334,
          -4.955245494842529,
          -5.587146282196045,
          2.6598100662231445,
          -5.065469741821289,
          -5.499955177307129
         ]
        },
        {
         "hoverinfo": "text",
         "hovertext": [
          "Initially reset the index of the DataFrames for consistency.",
          "Read data from CSV files and reset index to ensure the data is correctly formatted for further processing.",
          "Load the datasets and reset their indices to start from 0.",
          "It is a good practice to reset the index of DataFrames after reading them from CSV files, as it will avoid potential issues with index misalignment.",
          " Load the data from the CSV files and reset the index of each DataFrame.",
          "TODO: Make sure the dataframe indexes are reset.",
          "Load dataset and reset index",
          "Reading the datasets from CSV files and resetting the index of each DataFrame.",
          " Remove the index from csv load",
          " remove index from csv imports",
          "Loading the CSV files and resetting the index to ensure the data is correctly loaded and indexed.",
          "We start by loading the datasets using pandas `read_csv` function. Then we reset the index using the `reset_index` method to have a fresh index.",
          "The first step is to load the data into DataFrames using pandas. We then reset the index of each DataFrame to ensure everything is properly aligned.",
          "Load the data into dataframes and reset the index to ensure the indexes are correct.",
          "\n#* Here we read in the data using pandas read_csv function and reset the index on the dataframes.",
          "We have imported the necessary libraries and now we are loading the datasets using pandas.read_csv() function and resetting the index for each dataframe.",
          "First, we read in the data from CSV files into pandas DataFrames. We reset the index and drop the previous index to ensure the index remains continuous integers.",
          "In this code, we are reading CSV files into pandas dataframes using the `pd.read_csv` method. This allows us to work with the data from these files using the DataFrame data structure provided by the pandas library. We also use the `reset_index` method to reset the index of the dataframes.",
          "Delete the index from the CSV files",
          "Since there is no specific file path for the datasets, the code reads the CSV files with the 'read_csv' function from the pandas library and then resets the index of the resulting dataframes.",
          "We are reading the datasets from CSV files and resetting the index of each dataframe.",
          "Drop the index column from the dataframes that was read with the csv.",
          " Remove the column that has been passed as an index from the CSV file",
          " For some reason, the index column `Unnamed: 0` is created during csv\n#  reading; we need to remove this from the dataframes.",
          "use read_csv from pandas to read in the csv files and reset the index of each dataframe",
          "Since we are working with data from the Simpsons TV show, we are importing the required data from CSV files using pandas. This code snippet reads the data from CSV files and resets the index of each dataframe."
         ],
         "marker": {
          "opacity": 0.5,
          "size": 5
         },
         "mode": "markers+text",
         "name": "124_Resetting Indexes and Loading CSV Files Using Pandas",
         "text": [
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          ""
         ],
         "textfont": {
          "size": 12
         },
         "type": "scattergl",
         "x": [
          9.090780258178711,
          9.940231323242188,
          10.286890029907227,
          9.508089065551758,
          9.673428535461426,
          8.651991844177246,
          10.051798820495605,
          9.954014778137207,
          9.763023376464844,
          9.743000984191895,
          10.041171073913574,
          9.614950180053711,
          9.306693077087402,
          9.060161590576172,
          9.392765045166016,
          9.797850608825684,
          9.300214767456055,
          10.231364250183105,
          9.691749572753906,
          9.997987747192383,
          9.842305183410645,
          9.399858474731445,
          9.259191513061523,
          9.669715881347656,
          9.754194259643555,
          10.193870544433594
         ],
         "y": [
          0.25638118386268616,
          1.0417848825454712,
          0.5689087510108948,
          0.38451817631721497,
          0.7897080779075623,
          -0.4089658260345459,
          1.0765310525894165,
          0.8928532600402832,
          1.5348845720291138,
          1.2350053787231445,
          1.467846155166626,
          0.673940122127533,
          0.628818690776825,
          0.35135161876678467,
          0.6311666965484619,
          0.9088286757469177,
          0.7553173303604126,
          1.0568995475769043,
          1.3298677206039429,
          0.812429666519165,
          0.9038732647895813,
          0.5664175748825073,
          1.2878975868225098,
          0.4213230609893799,
          0.8560345768928528,
          1.855394721031189
         ]
        },
        {
         "hoverinfo": "text",
         "hovertext": [
          "Merge episodes with script\ndf_episodes = df_episodes.rename(columns={'id':'episode_id'})\ndf_script = pd.merge(df_script, df_episodes, on='episode_id')",
          "Merge episodes and scripts\ndf_episodes.rename(columns={'id':'episode_id'}, inplace=True)\ndf = pd.merge(df_script, df_episodes, on='episode_id')\n\n# Display the first rows of the dataframe\ndf.head()",
          " Merge episodes and scripts into a single dataframe\ndf_episodes.rename(columns={'id': 'episode_id'}, inplace=True)\ndf = pd.merge(df_script, df_episodes, on='episode_id')",
          "Add status to script lines dataframe\ndf_script = df_script.merge(df_episodes[['id', 'production_code', 'season', 'number_in_season', 'number_in_series', 'air_date']], left_on='episode_id', right_on='id', suffixes=(False, False)).fillna(\"\")\ndf_script.rename(columns={'production_code': 'episode_production_code', \n                          'id': 'episode_id', \n                          'season': 'episode_season', \n                          'number_in_season': 'episode_number_in_season', \n                          'number_in_series': 'episode_number_in_series', \n                          'air_date': 'episode_air_date'}, inplace=True)",
          "Change Name of the First Column for Each Dataframe\ndf_characters.rename(columns={'id': 'character_id'}, inplace=True)\ndf_locations.rename(columns={'id': 'location_id'}, inplace=True)\ndf_script.rename(columns={'id': 'line_id'}, inplace=True)\ndf_episodes.rename(columns={'id': 'episode_id'}, inplace=True)",
          "Merge lines with episodes\nepisode_lines=pd.merge(df_script, df_episodes, left_on='episode_id', right_on='id').rename(columns={\"id_x\": \"line_id\"}).rename_axis('id').reset_index(drop = True)",
          "Rename speaker and episode_id columns for clarity\ndf_script = df_script.rename(columns={'episode_id': 'id', 'character_id': 'speaker_id'})",
          " Simplify DataFrame and lowercase the episode name\ndf_characters = df_characters[['id', 'name']].rename({'id': 'character_id', 'name': 'character_name'}, axis=1)\n\n# Simplify DataFrame and lowercase the episode name\ndf_episodes = df_episodes[['id', 'title', 'original_air_date', 'production_code']].rename({'id': 'episode_id', 'title': 'episode_title'}, axis=1)\ndf_episodes['episode_title'] = df_episodes['episode_title'].str.lower()",
          "Following code will rename the column 'id' to 'episode_id'.",
          "df_script.rename(columns={\"episode_id\": \"id\"}, inplace=True)",
          "define primary key (episode_id and number)\ndf_episodes = df_episodes.rename(columns={'id':'episode_id'})\ndf_episodes = df_episodes.set_index('episode_id', drop=False)",
          "\n# Merge scripts with other tables for better style\ndf_script = pd.merge(df_script, df_episodes, \n                     left_on='episode_id', right_on='id',\n                     suffixes=('_script_line', '_ep')).drop(columns=['id_ep']).rename(columns={'name': 'episode_name', 'number': 'episode_number', 'id_script_line': 'id'})\n\ndf_script = pd.merge(df_script, df_characters, \n                     left_on='character_id', right_on='id',\n                     suffixes=('_script', '_character')).drop(columns=['id_character']).rename(columns={'name': 'character_name', 'normalized_name': 'character_normalized_name', 'id_script': 'id_character'})",
          "Filtering relevant columns from df_script\ndf_script = df_script[['episode_id', 'number', 'raw_text', 'character_id', 'location_id']].rename(\n    columns={'number': 'id', 'raw_text': 'dialogue'}\n)\n\n# Remame Episode id to not conflict with location_id\ndf_script = df_script.rename(columns={'episode_id': 'episode'})",
          "Rename wrongly named character_id column\ndf_episodes = df_episodes.rename(columns={'id': 'episode_id'})",
          "Rename 'id' to 'episode_id' and 'season' to 'episode_season' to enable easier linking between metadata\ndf_episodes = df_episodes.rename(columns={'id': 'episode_id', 'season': 'episode_season'})",
          "Join episodes data to script data\ndf_episodes = df_episodes.rename({'id':'episode_id'}, axis=1)",
          "# Merge scripts and episodes tables\ndf_episodes.rename(columns={'id': 'episode_id'}, inplace=True)\ndf_joined = df_script.merge(df_episodes, on='episode_id', how='left')",
          "Merge the script lines with character names and episode titles\ndf = df_script.merge(df_characters[['id', 'name']], left_on='character_id', right_on='id').rename(columns={'name': 'character_name'})\ndf = df.merge(df_episodes[['id', 'title']], left_on='episode_id', right_on='id').rename(columns={'title': 'episode_title'})",
          "Create character-episode mapping dataframe\ndf_char_ep = df_script[['episode_id', 'character_id']].copy()\ndf_char_ep.dropna(inplace=True)\ndf_char_ep['character_id'] = df_char_ep['character_id'].astype(int)\ndf_ep_char_map = (df_episodes[['id', 'title']]\n                  .merge(df_char_ep, how='left', left_on='id', right_on='episode_id')\n                  .drop(columns=['id'])\n                  .rename(columns={'title': 'episode_title', 'episode_id': 'episode_id'})\n                  .groupby('character_id')['episode_title']\n                  .apply(list)\n                  .reset_index(name='episode_titles'))",
          "Merge script lines with corresponding episodes and characters\ndf_episodes = df_episodes.rename(columns={'id': 'episode_id'})\n\ndf_script = pd.merge(df_script, df_episodes, on='episode_id')\ndf_script = pd.merge(df_script, df_characters, on='character_id')",
          "Merge episodes and script\ndf_episodes = df_episodes.rename(columns={'id':'episode_id'})\ndf = df_script.merge(df_episodes, on='episode_id')",
          "Rename the \"id\" columns to uniquely identify each table\ndf_characters.rename(columns={'id':'character_id'}, inplace=True)\ndf_locations.rename(columns={'id':'location_id'}, inplace=True)\ndf_script.rename(columns={'id':'line_id'}, inplace=True)\ndf_episodes.rename(columns={'id':'episode_id'}, inplace=True)",
          "Merge lines and episodes\ndf_episodes.rename(columns={'id':'episode_id'}, inplace=True)\ndf_script_lines_episodes = df_script.merge(df_episodes, on='episode_id')",
          "# identifiers should be slugs as per README\ndf_characters.rename(columns= {'id': 'character_id'}, inplace=True)\ndf_locations.rename(columns= {'id': 'location_id'}, inplace=True)\ndf_episodes.rename(columns= {'id': 'episode_id'}, inplace=True)",
          "Filter out bad script lines\ndf_script_good = df_script.loc[df_script['speaking_line'] == 'true']\n# Remove bad characters\ndf_script_good = df_script_good[df_script_good['normalized_text'] != \"\"]\n# Remove non-primary characters\ndf_script_good = df_script_good[df_script_good['raw_character_text'] != \"\"]\n# Rename text column\ndf_script_good = df_script_good.rename({'normalized_text': 'text'}, axis=1)\n# add episode number and name to script lines\ndf_script_good = pd.merge(df_script_good, df_episodes[['id', 'title', 'season', 'number']], left_on='episode_id', right_on='id')",
          "Merge script with episodes, characters and locations\ndf_episodes = df_episodes.rename(columns={'id':'episode_id'})\n\ndf = df_script.merge(\n    df_episodes[['episode_id', 'title', 'original_air_date']],\n    on='episode_id',\n    how='inner'\n    )"
         ],
         "marker": {
          "opacity": 0.5,
          "size": 5
         },
         "mode": "markers+text",
         "name": "125_Dataframe script filtering and merging",
         "text": [
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          ""
         ],
         "textfont": {
          "size": 12
         },
         "type": "scattergl",
         "x": [
          2.7968409061431885,
          2.709890842437744,
          2.6740031242370605,
          2.6029844284057617,
          3.5442583560943604,
          2.3356218338012695,
          4.100426197052002,
          2.971254825592041,
          4.346131801605225,
          3.8206732273101807,
          3.2569098472595215,
          2.5614538192749023,
          3.5653395652770996,
          3.440988063812256,
          3.2591769695281982,
          2.892756938934326,
          2.0382466316223145,
          2.9053609371185303,
          2.2902023792266846,
          2.4660725593566895,
          2.6598002910614014,
          3.600020408630371,
          2.927276849746704,
          3.6857924461364746,
          3.1353611946105957,
          2.4396464824676514
         ],
         "y": [
          6.929141044616699,
          6.505040645599365,
          6.440577030181885,
          6.612170219421387,
          7.688538074493408,
          6.861416339874268,
          7.411660194396973,
          7.394497871398926,
          6.101051330566406,
          6.8121232986450195,
          6.504754543304443,
          7.401603698730469,
          7.089146614074707,
          7.222687721252441,
          6.891625881195068,
          7.05506706237793,
          6.89152717590332,
          7.167520999908447,
          7.417190074920654,
          6.993344783782959,
          6.8988847732543945,
          7.852784156799316,
          7.318382263183594,
          7.874285697937012,
          7.679521083831787,
          6.8870649337768555
         ]
        },
        {
         "hoverinfo": "text",
         "hovertext": [
          "Print the first 3 lines of df_characters\ndf_characters.head(3)",
          " Display the first few lines of the characters dataframe\ndf_characters.head()",
          "Display the first few lines of the characters dataframe\ndf_characters.head()",
          "Print the first few lines of the characters dataframe\nprint(df_characters.head())",
          " Display the first few lines of the characters DataFrame\ndf_characters.head()",
          "Show the first three lines of the characters dataframe\ndf_characters.head(3)",
          " Show first lines of characters dataframe\ndf_characters.head()",
          " Show the first lines of the characters dataframe\ndf_characters.head()",
          "# Display the first few lines of the characters dataframe\ndf_characters.head()",
          "\n# Show the first few lines of the characters DataFrame\ndf_characters.head()",
          "Print the first few lines of the characters data frame\nprint(df_characters.head())",
          "Display the first few lines of the dataframe with the character data\ndf_characters.head()",
          " Display the first few lines of the characters dataframe\ndf_characters.head()",
          "Show the first lines of the `df_characters` dataframe\ndf_characters.head()",
          " View the first few lines of the characters dataframe\ndf_characters.head()",
          " Display a few lines of the characters dataframe\ndf_characters.head()",
          " Show the first lines of the characters dataframe\ndf_characters.head()",
          "Display the first few lines of the dataframe\ndf_characters.head()",
          "function to display character lines\ndef display_lines(df, character_name, lines_to_display=10):\n    display(df[df['raw_character_text'] == character_name].head(lines_to_display))",
          " Show the first lines of the characters dataframe\nprint(df_characters.head())",
          "Show the first few lines of the characters dataframe\ndf_characters.head()",
          "Show the first few lines of the characters dataframe\ndf_characters.head()",
          "Show the first lines of the characters data\ndf_characters.head()",
          "Display the first few lines of the characters dataframe\ndf_characters.head()",
          "View the first few lines of the characters dataframe\ndf_characters.head()"
         ],
         "marker": {
          "opacity": 0.5,
          "size": 5
         },
         "mode": "markers+text",
         "name": "126_Displaying First Lines of Characters DataFrame",
         "text": [
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          ""
         ],
         "textfont": {
          "size": 12
         },
         "type": "scattergl",
         "x": [
          3.3728435039520264,
          4.662578582763672,
          4.743408203125,
          4.932660102844238,
          4.8677897453308105,
          3.9039719104766846,
          4.986626148223877,
          4.8410964012146,
          5.029470443725586,
          4.480601787567139,
          4.977197647094727,
          4.953747749328613,
          4.794363498687744,
          4.726765155792236,
          5.401170253753662,
          4.420092582702637,
          4.868357181549072,
          4.690937519073486,
          5.383749485015869,
          5.323917388916016,
          4.974795818328857,
          5.025029182434082,
          4.759945392608643,
          4.755401134490967,
          5.503162384033203
         ],
         "y": [
          15.707175254821777,
          18.616437911987305,
          18.659992218017578,
          18.481473922729492,
          18.572824478149414,
          15.833566665649414,
          18.144243240356445,
          18.2210693359375,
          18.271907806396484,
          18.222381591796875,
          18.489559173583984,
          18.076522827148438,
          18.391239166259766,
          18.216392517089844,
          18.178104400634766,
          17.956480026245117,
          17.81639289855957,
          18.77000617980957,
          16.683170318603516,
          17.89786720275879,
          18.31475830078125,
          18.39488410949707,
          17.718795776367188,
          18.659454345703125,
          18.531009674072266
         ]
        },
        {
         "hoverinfo": "text",
         "hovertext": [
          "Check the content of the dataframes and the columns\ndf_script.head()",
          "Optional: Use this line of code to check the content of a dataframe to get a look at the data organization\n#df_script.head()",
          "Check the content of the df_script DataFrame\ndf_script.head()",
          "Check the script dataframe\ndf_script.head()",
          "# Check the general structure of the script dataframe\ndf_script.head()",
          "Check a sample of data from each dataframe\ndf_script.head()",
          "Check the content of one of the DataFrames\ndf_script.head()",
          "Checking the script data\nprint(\"We have\", len(df_script), \"script lines\")\ndf_script.head()",
          "Check if dataframe have been sorted correctly\ndf_script.head()",
          " Check the structure of one of the dataframes\ndf_script.head()",
          "Check the data in one of the dataframes, e.g. df_script\nprint(df_script.head())",
          " Check dataframes\ndf_script.head()",
          "Check the dataframes\ndf_script.head()",
          "check the structure of the scripts dataframe\ndf_script.head()",
          "Check how the script dataframe looks like\ndf_script.head()",
          "Check the script lines dataframe\ndf_script.head()",
          " Check content of one of the dataframes\ndf_script.head(10)",
          "Check the structure of script dataframe\ndf_script.head()",
          " Check the script dataframe structure\ndf_script.head()",
          "Verify the script dataframe\ndf_script.head()",
          "Check loaded DataFrame\ndf_script.head()",
          "Check the structure of the script dataframe\ndf_script.head()",
          "Check the dataframes content\nprint(df_script.head())",
          "# Check the content of script lines\nprint(df_script.head())",
          "Check the content of the script lines DataFrame\ndf_script.head()"
         ],
         "marker": {
          "opacity": 0.5,
          "size": 5
         },
         "mode": "markers+text",
         "name": "127_Checking the content of dataframes and script lines",
         "text": [
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          ""
         ],
         "textfont": {
          "size": 12
         },
         "type": "scattergl",
         "x": [
          7.228628158569336,
          6.786321640014648,
          6.748007774353027,
          6.786210536956787,
          6.283726692199707,
          7.446746349334717,
          7.364880561828613,
          5.919062614440918,
          6.416945457458496,
          6.505677223205566,
          7.056969165802002,
          7.094861030578613,
          7.041805267333984,
          6.440719127655029,
          6.038825511932373,
          6.628655433654785,
          6.898049354553223,
          6.220829963684082,
          6.443415641784668,
          6.863491058349609,
          6.598354816436768,
          6.271266460418701,
          6.999148845672607,
          6.3072829246521,
          6.633388996124268
         ],
         "y": [
          -3.600691795349121,
          -4.079802989959717,
          -3.7331066131591797,
          -4.202878475189209,
          -5.034589767456055,
          -4.169976711273193,
          -3.9482390880584717,
          -3.5736236572265625,
          -3.917785406112671,
          -4.339724540710449,
          -3.512173891067505,
          -4.252784252166748,
          -4.196264743804932,
          -4.506126880645752,
          -4.3041157722473145,
          -4.176680088043213,
          -3.6678266525268555,
          -4.591907024383545,
          -4.527326583862305,
          -4.290981292724609,
          -3.9088616371154785,
          -4.50018835067749,
          -3.624927520751953,
          -3.45236873626709,
          -3.8873744010925293
         ]
        },
        {
         "hoverinfo": "text",
         "hovertext": [
          "Inspect the first few rows of each dataframe to understand their structure and contents.\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()",
          "Let's display the first few elements of the following DataFrames to understand what data we are working with:\n# - df_characters\n# - df_locations\n# - df_script\n# - df_episodes",
          "Let's look at the first few rows of each dataframe to understand the data better.\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()",
          "Take a look at the first couple of lines in each of the dataframe to see what kind of data we'll be working with\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()",
          "Inspect the first few lines of each dataframe to understand their structure\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()",
          "Inspect the first few rows of each DataFrame to understand their structures and contents\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()",
          "Examine the structure of the dataframes\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()",
          "check the first few rows of each dataframe to understand their structure\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()",
          "Check the contents of each dataframe to understand their structure\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()",
          "Inspect the first few rows of each dataframe to understand their structure and contents\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()",
          "Inspect the first few rows of each dataframe to understand its structure and content\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()",
          "Just taking a look at the first few rows of each DataFrame to understand the data better\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()",
          "Check the first few entries in each dataframe to understand their structure\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()",
          "Look at the head of each dataset to understand their structure\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()",
          "# Let's start by displaying the first rows of each dataframe to understand the structure of the data\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()",
          "check the first 5 lines of the dataframes to understand their structure\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()",
          "Inspect the first few lines of each dataframe to understand its structure and content\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()",
          "# Let's print the head of each dataframe to better understand the structure of the data\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()",
          " quick look to our datasets\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()",
          "Inspect the first few rows of each dataframe to understand its structure\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()",
          "Look at the first 5 lines of the first 3 DataFrames to understand their structure\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()",
          "\n# Let's start by taking a look at the structure of our dataframes\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()",
          " Take a look at the dataframes to understand their structure and content\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()",
          "# Now let's take a look at the first few rows of each dataframe to understand their structure\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()",
          "Inspect the first few rows of each dataframe to understand its structure\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()"
         ],
         "marker": {
          "opacity": 0.5,
          "size": 5
         },
         "mode": "markers+text",
         "name": "128_Examining DataFrame Structures and Contents",
         "text": [
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          ""
         ],
         "textfont": {
          "size": 12
         },
         "type": "scattergl",
         "x": [
          -4.693421840667725,
          -4.80125093460083,
          -4.837740898132324,
          -4.542218208312988,
          -5.025663375854492,
          -4.929191589355469,
          -4.186244964599609,
          -4.90725040435791,
          -4.9452805519104,
          -4.817490100860596,
          -4.668123722076416,
          -4.750157833099365,
          -4.9559807777404785,
          -3.6547300815582275,
          -5.017954349517822,
          -5.347050666809082,
          -4.756539821624756,
          -4.405951976776123,
          -2.959012269973755,
          -5.177726745605469,
          -5.493203163146973,
          -4.20457649230957,
          -4.487898349761963,
          -5.107964992523193,
          -5.142871856689453
         ],
         "y": [
          2.8593640327453613,
          3.2694969177246094,
          2.5142598152160645,
          2.084609031677246,
          2.518136501312256,
          2.715009927749634,
          2.0258076190948486,
          2.3454270362854004,
          2.1290295124053955,
          2.9342494010925293,
          2.7990264892578125,
          2.310232639312744,
          2.3186285495758057,
          2.4880640506744385,
          3.0129852294921875,
          2.4408488273620605,
          2.997812509536743,
          2.8332409858703613,
          2.42928409576416,
          2.6977288722991943,
          2.5341732501983643,
          1.9970965385437012,
          2.4117588996887207,
          2.593017339706421,
          2.6107897758483887
         ]
        },
        {
         "hoverinfo": "text",
         "hovertext": [
          " Merge script and episode data\ndf_script_episode = df_script.merge(df_episodes, how='left', on='episode_id')",
          "Merge script and episodes\ndf_script_episodes = pd.merge(df_script, df_episodes, how = 'left', on = ['episode_id'])",
          "Preprocess data\n# Simpsons script data\n# 1. Merge script and episodes data\ndf_script_episodes = pd.merge(df_script, df_episodes, how='left', on='episode_id')",
          "Merge the tables\ndf = df_script.merge(df_episodes, how='left', on='episode_id')",
          " create new (and final) dataframe by merging 'df_episodes' and 'df_script' dataframes using a left join merging on 'episode_id' column\ndf_final = pd.merge(df_episodes, df_script, on='episode_id', how='left')",
          "merge episodes\ndf_script_ep = pd.merge(df_script, \n                        df_episodes, \n                        on='episode_id', \n                        how='left')",
          "Merge episodes and scripts\ndf = pd.merge(df_script, df_episodes, on=\"episode_id\", how=\"left\")",
          " Merge 'df_script' with 'df_episodes'\ndf_merged = df_script.merge(df_episodes, on='episode_id', how='left')",
          "Merge script lines with episode data\ndf_script_full = df_script.merge(df_episodes,\n                                 on='episode_id',\n                                 how='left')",
          "# Join tables script and episodes\ndf_script_episodes = df_script.merge(df_episodes, on='episode_id', how='left')\ndf_script_episodes.head()",
          "Merge episode information into main script dataframe\ndf_script = df_script.merge(df_episodes, on='episode_id', how='left')",
          "Merge datasets\ndf = df_script.merge(df_episodes, on='episode_id', how='left')",
          "Merge episodes and scripts\ndf = df_episodes.merge(df_script, on='episode_id', how='left')",
          "Merge script lines with episode data\ndf = df_script.merge(df_episodes, on='episode_id', how='left')\n\n# Split data into training and validation sets\nnp.random.seed(0)\ndf_train = df.sample(frac=0.8, random_state=0)\ndf_val = df.drop(df_train.index)\n\n# Ensure we have a good mix of classes\nprint(df_train['raw_character_text'].value_counts(normalize=True))",
          " Merge data together\ndf_merged = df_script.merge(df_episodes, how='left', on='episode_id')",
          " Merge episodes with scripts\ndf_episodes['id'] = df_episodes.id.astype(float)\ndf_script['episode_id'] = df_script.episode_id.astype(float)\n\ndf_merged = pd.merge(df_script,\n                     df_episodes,\n                     how='left',\n                     left_on='episode_id',\n                     right_on='id')",
          "Join dataset to have episodes info in script dataset\ndf_script = df_script.merge(df_episodes, on='episode_id', how='left')",
          " Merge script lines and episodes\ndf_script_episodes = df_script.merge(df_episodes, on='episode_id', how='left')",
          "Merge script lines with episodes\ndf_script = pd.merge(df_script, df_episodes,\n                     on='episode_id',\n                     how='left')",
          "Merge episode data into script\ndf_script = df_script.merge(df_episodes, on='episode_id', how='left')",
          " Merge the episode details into the main script lines dataframe\ndf_script = df_script.merge(df_episodes, on='episode_id', how='left')",
          "Join episode and script data\ndf = df_script.merge(df_episodes, on='episode_id', how='left')",
          "Merge lines and episodes\ndf_merged = df_script.merge(df_episodes, how='left', on='episode_id')",
          " Merge df_script with df_episodes to add more context to the lines of dialogue\ndf = pd.merge(df_script, df_episodes, on='episode_id', how='left')",
          "Merge df_script and df_episodes on episode_id, using a left join\ndf_merged = df_script.merge(df_episodes, on='episode_id', how='left')"
         ],
         "marker": {
          "opacity": 0.5,
          "size": 5
         },
         "mode": "markers+text",
         "name": "129_Merging episode and script data",
         "text": [
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          ""
         ],
         "textfont": {
          "size": 12
         },
         "type": "scattergl",
         "x": [
          0.4638417959213257,
          0.9063484072685242,
          1.4790353775024414,
          0.9597618579864502,
          0.6437272429466248,
          0.7107852697372437,
          0.7918097972869873,
          0.4460260570049286,
          0.8284249305725098,
          0.461753249168396,
          0.09792892634868622,
          0.5774238109588623,
          0.6757708787918091,
          1.284374475479126,
          0.4225122034549713,
          0.9710209369659424,
          0.20610320568084717,
          0.8884138464927673,
          0.9835450649261475,
          0.5424767136573792,
          0.49462199211120605,
          0.7401543259620667,
          0.8424035906791687,
          1.7075400352478027,
          0.6186347007751465
         ],
         "y": [
          6.688244819641113,
          6.81558895111084,
          6.81016731262207,
          6.594943523406982,
          6.223280429840088,
          6.561631202697754,
          6.598525524139404,
          6.760115623474121,
          6.7968573570251465,
          6.449312210083008,
          6.670931339263916,
          6.848578929901123,
          6.542118072509766,
          6.902904510498047,
          6.406463146209717,
          6.3847198486328125,
          6.4656572341918945,
          6.9289679527282715,
          6.7995734214782715,
          6.746291637420654,
          6.9155592918396,
          6.250787258148193,
          6.503448486328125,
          6.860167980194092,
          6.259646415710449
         ]
        },
        {
         "hoverinfo": "text",
         "hovertext": [
          "Check the loaded data",
          "Just checking if the data loaded properly",
          "print('Data loaded successfully!')",
          " Check if the data is correctly loaded",
          "Setting and checking if the data is loaded correctly",
          " Check the data to ensure everything is loaded correctly",
          "Checking if the data has been loaded properly",
          "Check all of the databases have been correctly loaded",
          "Checking loading of data done correctly",
          "check the data files and whether they all have been loaded successfully",
          "Checking if the data is loaded correctly",
          "Let's make sure it's loaded correctly",
          " Check the data to examine if it has been loaded correctly.",
          "Check if the data was properly loaded",
          "Checkpoint: All data is loaded and looks fine",
          " Check whether the data has been read successfully",
          "Checking the data to see if it has been loaded correctly",
          "Check the loaded data",
          "Run some code to verify everything is loaded as expected",
          "Check the recent data before starting the work.",
          "Check if the code execution meets the objective",
          "Load it as read access to avoid writing permissions",
          "Check data you just loaded",
          " Check that the data was loaded correctly",
          " Verify data loading"
         ],
         "marker": {
          "opacity": 0.5,
          "size": 5
         },
         "mode": "markers+text",
         "name": "130_Checking data loading success",
         "text": [
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          ""
         ],
         "textfont": {
          "size": 12
         },
         "type": "scattergl",
         "x": [
          14.81464958190918,
          15.094761848449707,
          15.360278129577637,
          15.260427474975586,
          15.304988861083984,
          15.148916244506836,
          14.833666801452637,
          14.78794002532959,
          14.994352340698242,
          15.008035659790039,
          14.810356140136719,
          15.345308303833008,
          14.726801872253418,
          15.365111351013184,
          14.381695747375488,
          14.336088180541992,
          14.558980941772461,
          15.128889083862305,
          14.228198051452637,
          15.477396011352539,
          13.282888412475586,
          14.514168739318848,
          15.499650955200195,
          15.114394187927246,
          15.235625267028809
         ],
         "y": [
          1.0260357856750488,
          1.1496163606643677,
          1.3639228343963623,
          1.4681527614593506,
          1.2495150566101074,
          1.360141634941101,
          1.3531149625778198,
          1.0133583545684814,
          0.9835673570632935,
          1.2195202112197876,
          1.6452504396438599,
          1.7343088388442993,
          1.4966020584106445,
          1.3038203716278076,
          0.39130932092666626,
          1.4662086963653564,
          1.4318313598632812,
          1.2483911514282227,
          1.7988489866256714,
          0.8123717308044434,
          1.650225043296814,
          1.6235419511795044,
          1.0151190757751465,
          1.1993873119354248,
          1.0004448890686035
         ]
        },
        {
         "hoverinfo": "text",
         "hovertext": [
          "Merge dataframes",
          "Merge the dataframes",
          "Merge dataframes",
          "Merge dataframes together",
          "Merge dataframes to simplify the analysis of the data",
          "Merge DataFrames",
          "Merge dataframes",
          "to-do: combine dataframes",
          "Merge dataframes",
          "Merge dataframes",
          "Merge data frames to simplify the code and remove duplicate ids",
          " Merge these dataframes into a single one",
          "Merge dataframes to improve data analysis capabilities.",
          "Merge DataFrames",
          "Merge data frames",
          "Creating a full df from merging the other dfs.",
          "Merge data frames",
          " Merge the dataframes",
          " Merge the dataframes",
          "Merge dataframes",
          "Merge dataframes for easy data manipulation",
          "Merge dataframes",
          "Merge the relevant dataframes",
          " Function to merge and filter the DataFrames",
          "Merge necessary dataframes and columns"
         ],
         "marker": {
          "opacity": 0.5,
          "size": 5
         },
         "mode": "markers+text",
         "name": "131_Merge DataFrames",
         "text": [
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          ""
         ],
         "textfont": {
          "size": 12
         },
         "type": "scattergl",
         "x": [
          4.643605709075928,
          5.265430450439453,
          4.652855396270752,
          4.883501052856445,
          5.611950874328613,
          4.7349467277526855,
          4.486887454986572,
          5.106680393218994,
          4.568136692047119,
          4.8088202476501465,
          5.183515548706055,
          5.681605815887451,
          5.305211544036865,
          4.587846755981445,
          4.847280025482178,
          5.538570880889893,
          4.755825519561768,
          5.292321681976318,
          5.2253289222717285,
          4.793635845184326,
          4.837456703186035,
          4.642491817474365,
          6.172657012939453,
          4.364240646362305,
          5.023201942443848
         ],
         "y": [
          -0.9334073066711426,
          -0.9637270569801331,
          -0.8964526653289795,
          -0.628010094165802,
          -0.7732753753662109,
          -0.7741983532905579,
          -0.8477637767791748,
          -0.6543827056884766,
          -0.8622108101844788,
          -0.8246363997459412,
          -0.38209739327430725,
          -1.0487829446792603,
          -0.8513745069503784,
          -0.6962922215461731,
          -0.8947795033454895,
          -1.0502742528915405,
          -0.8549826145172119,
          -1.1008013486862183,
          -1.0377507209777832,
          -0.7787824273109436,
          -0.7312837243080139,
          -0.9482619166374207,
          -0.8172478079795837,
          -0.9991927146911621,
          -0.4589427709579468
         ]
        },
        {
         "hoverinfo": "text",
         "hovertext": [
          "Now we will display the first 5 rows of the characters dataframe.",
          "Show the first 5 rows of the characters dataframe",
          "Displays the first 5 records in the characters dataframe.",
          "\n# Display each of the 5 datasets\nprint('Characters:')",
          "We  will now display the first 5 rows of the characters dataframe.",
          " Show the first 5 rows of the characters dataframe",
          "Display the 5 first rows of the dataframe containing the characters",
          "Display the first 5 rows of the dataframe containing the characters.",
          "Inspect the first 5 rows of the characters dataframe",
          "Inspect first 5 rows of the characters dataframe",
          "Inspect the first 5 records of the characters dataframe",
          "Inspecting the first 5 rows of the characters DataFrame",
          "View the first 5 rows of the characters dataframe.",
          "Visually show the first 5 rows of the characters dataframe.",
          " Display first 5 lines of characters dataset",
          "Insepct the first 5 records of the character dataframe",
          "View the first 5 characters DataFrame rows.",
          "View first 5 records of characters dataframe",
          "Get the first five rows of the characters dataframe.",
          "Inspect first 5 rows of the characters dataframe",
          "Let's view the first 5 rows of the characters DataFrame.",
          "Displaying the first five rows of the characters dataframe",
          "Display the first 5 rows of the dataframe containing the characters.",
          "View the first 5 rows of the characters dataframe",
          " Show first 5 rows of the characters DataFrame."
         ],
         "marker": {
          "opacity": 0.5,
          "size": 5
         },
         "mode": "markers+text",
         "name": "132_Inspecting DataFrame Rows",
         "text": [
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          ""
         ],
         "textfont": {
          "size": 12
         },
         "type": "scattergl",
         "x": [
          11.100550651550293,
          11.892704010009766,
          11.418839454650879,
          10.246140480041504,
          11.327408790588379,
          11.855826377868652,
          12.279489517211914,
          11.731614112854004,
          11.404314041137695,
          11.699921607971191,
          11.324785232543945,
          11.319766998291016,
          11.612056732177734,
          11.313278198242188,
          10.773189544677734,
          11.3078031539917,
          11.441530227661133,
          11.633155822753906,
          11.574689865112305,
          11.736200332641602,
          10.823905944824219,
          11.563177108764648,
          11.765948295593262,
          11.795243263244629,
          11.64050579071045
         ],
         "y": [
          11.609676361083984,
          11.568779945373535,
          11.48983383178711,
          10.455327033996582,
          11.517274856567383,
          11.721722602844238,
          11.800646781921387,
          11.699145317077637,
          12.345884323120117,
          12.527995109558105,
          12.472213745117188,
          12.92929458618164,
          11.845868110656738,
          11.102901458740234,
          10.064428329467773,
          12.784875869750977,
          11.67297649383545,
          11.854378700256348,
          12.161402702331543,
          12.560771942138672,
          11.706421852111816,
          11.214630126953125,
          11.66673469543457,
          11.541056632995605,
          11.385855674743652
         ]
        },
        {
         "hoverinfo": "text",
         "hovertext": [
          " To verify the data has been imported correctly, let's take a look at each DataFrame using the .head() method.",
          "function: load_dataframes_cache: Load and cache dataframe functions\ndef load_dataframes_cache(f):\n    def wrapper(*args, **kw):\n        if os.path.exists(f.__name__):\n            print(f'Load {f.__name__} from cache')\n            return pd.read_pickle(f.__name__)\n        else:\n            df = f(*args, **kw)\n            print(f'Save {f.__name__} to cache')\n            df.to_pickle(f.__name__)\n            return df\n    return wrapper",
          "Check if the dataframes are loaded correctly",
          "Check the loaded dataframes",
          "Inspect the content of the loaded DataFrames",
          "Check the loaded dataframes",
          "Check the types of the loaded dataframes",
          "Checking the dataframe, that it loads with the top of it",
          "Checking the imported dataframes",
          "Evaluating the dimensions of the imported dataframes to ensure data has been loaded successfully.",
          "Check the size of the imported DataFrames",
          "Check if dataframes were correctly loaded",
          "Check the dataframes are correctly loaded",
          "Checking if the dataframes are loaded correctly",
          "# Run this cell to verify if pandas module is imported or not within the current environment\n\"pandas\" in locals()",
          "Check the loaded dataframes",
          "Check dimensions",
          "Check the imported dataframes",
          " Checking dataframes dimensions",
          "Notification that the dataframes have been loaded",
          "A fresh copy of the DataFrame is saved on-disk every time we preprocess the data, so we can load from that in future runs instead of having to re-run the code above.",
          "CHECKPOINT: all dataframes are loaded",
          "Check if main dataframe loads correctly",
          "Check if the dataframes have been properly loaded"
         ],
         "marker": {
          "opacity": 0.5,
          "size": 5
         },
         "mode": "markers+text",
         "name": "133_DataFrame Loading and Caching",
         "text": [
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          ""
         ],
         "textfont": {
          "size": 12
         },
         "type": "scattergl",
         "x": [
          10.529433250427246,
          10.422648429870605,
          11.235673904418945,
          11.515605926513672,
          11.62653636932373,
          11.546151161193848,
          11.063419342041016,
          11.334214210510254,
          10.920963287353516,
          10.684497833251953,
          10.448598861694336,
          11.506646156311035,
          11.364829063415527,
          11.36999225616455,
          11.391538619995117,
          11.433772087097168,
          9.373636245727539,
          10.896387100219727,
          9.572644233703613,
          11.620675086975098,
          9.365551948547363,
          11.885371208190918,
          11.47974681854248,
          11.43968391418457
         ],
         "y": [
          -3.448674201965332,
          -2.46734619140625,
          -2.4516654014587402,
          -2.600738525390625,
          -3.4073233604431152,
          -2.712951898574829,
          -2.4162821769714355,
          -3.080605983734131,
          -3.321889877319336,
          -3.0407516956329346,
          -3.635502338409424,
          -2.6348061561584473,
          -2.4452061653137207,
          -2.650632381439209,
          -3.267554521560669,
          -2.6623826026916504,
          -3.8768320083618164,
          -3.252962589263916,
          -4.198194980621338,
          -2.824026584625244,
          -2.294495105743408,
          -1.9907348155975342,
          -2.56817626953125,
          -2.742392063140869
         ]
        },
        {
         "hoverinfo": "text",
         "hovertext": [
          " Check first 5 rows of the characters dataset\ndf_characters.head()",
          " Check the first five rows of the characters dataframe\ndf_characters.head()",
          "check the first 5 rows of one of the dataframes\ndf_characters.head()",
          "Check the first 5 rows of the characters DataFrame\ndf_characters.head()",
          "Check the first five rows of the characters DataFrame\ndf_characters.head()",
          "Checking the first 5 rows of 'df_characters' dataframe\ndf_characters.head()",
          "Check the first 5 rows of the characters dataframe\ndf_characters.head()",
          "Check the first 5 rows of the characters dataframe\ndf_characters.head()",
          "Check the first 5 records of the characters dataframe\ndf_characters.head()",
          "Checking the first 5 rows of the characters dataframe\ndf_characters.head()",
          "Check the first 5 rows of the characters dataframe\ndf_characters.head()",
          "Check the first five rows of the characters dataframe\ndf_characters.head()",
          "# Checking the first 5 rows of the characters dataframe\ndf_characters.head()",
          "Check the first 5 rows of the characters DataFrame\ndf_characters.head()",
          "Check the first 5 rows of the characters dataframe\ndf_characters.head()",
          "Check the first 5 rows of the characters dataframe.\ndf_characters.head()",
          "Check the first 5 rows of df_characters DataFrame\ndf_characters.head()",
          "Checking the first 5 rows of the characters dataframe.\ndf_characters.head(5)",
          "Check the content of the first 5 rows\nprint(df_characters.head())",
          "Checking the first 5 rows of the characters dataframe\ndf_characters.head()",
          "Check first 5 rows of the Characters dataframe\ndf_characters.head()",
          "Check the first 5 rows of the characters DataFrame\ndf_characters.head()",
          "Check the first five rows of the characters dataframe\ndf_characters.head()",
          " Check the first five rows of the characters DataFrame\ndf_characters.head()"
         ],
         "marker": {
          "opacity": 0.5,
          "size": 5
         },
         "mode": "markers+text",
         "name": "134_Checking first five rows of characters DataFrame",
         "text": [
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          ""
         ],
         "textfont": {
          "size": 12
         },
         "type": "scattergl",
         "x": [
          -3.1834664344787598,
          -3.745138168334961,
          -3.108116626739502,
          -3.5831875801086426,
          -3.3326237201690674,
          -2.998074769973755,
          -3.514110803604126,
          -3.4979264736175537,
          -3.9759740829467773,
          -2.9773964881896973,
          -3.625002384185791,
          -3.8054308891296387,
          -3.4879937171936035,
          -3.5488338470458984,
          -3.4394032955169678,
          -3.285032033920288,
          -3.2957239151000977,
          -2.971536636352539,
          -3.3307223320007324,
          -3.201354503631592,
          -3.4288828372955322,
          -3.695300579071045,
          -3.4068453311920166,
          -3.8467469215393066
         ],
         "y": [
          16.497554779052734,
          16.379961013793945,
          16.494901657104492,
          16.662633895874023,
          16.396839141845703,
          16.42283058166504,
          16.890066146850586,
          16.598665237426758,
          16.817447662353516,
          16.15978240966797,
          16.742740631103516,
          16.837228775024414,
          16.86941146850586,
          16.713960647583008,
          16.746334075927734,
          16.66363525390625,
          16.572782516479492,
          16.3997745513916,
          16.589139938354492,
          16.345930099487305,
          16.574003219604492,
          16.68754768371582,
          16.45623779296875,
          16.2686767578125
         ]
        },
        {
         "hoverinfo": "text",
         "hovertext": [
          "Check the dataframes\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()",
          "# Print heads to verify\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()",
          "check the resulting DataFrames\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()",
          "Check the head of each dataframe\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()",
          "Check loaded data\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()",
          "Check contents of each dataframe\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()",
          "Check data load success\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()",
          "Check the head of each dataset\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()",
          "Check if all the data is present\ndf_episodes.head(), df_characters.head(), df_locations.head(), df_script.head()",
          "Check the structure of characters, locations, scripts and episodes datasets\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()",
          " Check Data\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()",
          "Check the dataframes contents\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()",
          "Check dataframes head\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()",
          "Check head of dataframes\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()",
          "Check the dataframes\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()",
          "Checking the loaded datasets\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()",
          "Check the contents of these dataframes\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()",
          "Check the dataframes\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()",
          "Check a few initial lines of each dataframe\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()",
          "Check the dataframes\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()",
          "Check content of these tables\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()",
          "Check the head of the 4 dataframes\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()",
          "Check the original dataframes\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()",
          " Check the resulting DataFrames\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()"
         ],
         "marker": {
          "opacity": 0.5,
          "size": 5
         },
         "mode": "markers+text",
         "name": "135_Checking Loaded Dataframes and Contents",
         "text": [
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          ""
         ],
         "textfont": {
          "size": 12
         },
         "type": "scattergl",
         "x": [
          -4.054387092590332,
          -3.2323551177978516,
          -4.331573486328125,
          -3.9949116706848145,
          -3.585763454437256,
          -4.018771171569824,
          -3.9821560382843018,
          -3.428889751434326,
          -3.215033769607544,
          -3.023785352706909,
          -3.617741107940674,
          -3.9730703830718994,
          -4.205862998962402,
          -4.438479900360107,
          -4.019550323486328,
          -3.5126969814300537,
          -3.9637486934661865,
          -4.041010856628418,
          -3.6688573360443115,
          -4.035815238952637,
          -3.4020137786865234,
          -4.568245887756348,
          -4.550241470336914,
          -4.169509410858154
         ],
         "y": [
          0.6022949814796448,
          1.2582814693450928,
          0.9521486759185791,
          1.1198452711105347,
          0.17965413630008698,
          1.2120047807693481,
          0.2610040009021759,
          1.2416149377822876,
          0.48379215598106384,
          0.9098802208900452,
          0.8005971908569336,
          0.7621608376502991,
          0.9809558391571045,
          0.4288319945335388,
          0.4009476602077484,
          0.4673061966896057,
          0.9233754873275757,
          0.5580773949623108,
          1.4173479080200195,
          0.5665238499641418,
          1.3740249872207642,
          0.8285477757453918,
          0.6836704015731812,
          0.8031752705574036
         ]
        },
        {
         "hoverinfo": "text",
         "hovertext": [
          "Let's take a look at the data first.",
          "let's take a first look at the data.",
          " Let's start by looking at the data.",
          " Let's take a look at the data first.",
          "Let's take a look at the data first.",
          "Let's take a first look at the data.",
          "We will first briefly look at the data.",
          "Let's take a look at the data first.",
          "Time to start by looking at the data.",
          "Let's take a look at the data first.",
          "Let's first check out the data to see what we're working with.",
          "Let's take a first look at the data.",
          " Let's take a first look at the data.",
          "Let's start by taking a look at the data we have available.",
          "Let's take a look at the data first.",
          "We first take a look at the available data.",
          "Let's take a look at the data first:",
          "Let's first take a look at the data.",
          "Let's first take a look at the data.",
          "Let's first have a look at the data.",
          "Let's inspect the data first.",
          "Let's start by taking a look at the data.",
          "Check the data format and potential issues in the data.",
          " We should begin with a quick about the data."
         ],
         "marker": {
          "opacity": 0.5,
          "size": 5
         },
         "mode": "markers+text",
         "name": "136_Taking a Quick Look at Available Data",
         "text": [
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          ""
         ],
         "textfont": {
          "size": 12
         },
         "type": "scattergl",
         "x": [
          18.174333572387695,
          18.285171508789062,
          17.80579948425293,
          18.42475128173828,
          18.336326599121094,
          18.341747283935547,
          17.79219627380371,
          18.383827209472656,
          17.99864959716797,
          18.169418334960938,
          18.42029571533203,
          18.37105941772461,
          18.63021469116211,
          18.214139938354492,
          18.301889419555664,
          18.350244522094727,
          18.002887725830078,
          18.331645965576172,
          18.330293655395508,
          17.994556427001953,
          17.312952041625977,
          17.681047439575195,
          17.039087295532227,
          17.53730583190918
         ],
         "y": [
          -1.9775704145431519,
          -1.8804922103881836,
          -1.5802536010742188,
          -2.1054749488830566,
          -2.1893694400787354,
          -2.0486505031585693,
          -1.3229079246520996,
          -2.098900556564331,
          -1.6781328916549683,
          -1.9550559520721436,
          -1.4272712469100952,
          -2.018474817276001,
          -2.1190547943115234,
          -1.1538878679275513,
          -2.038390636444092,
          -1.3082236051559448,
          -2.024062156677246,
          -1.863743543624878,
          -1.8049061298370361,
          -1.5842453241348267,
          -1.1407935619354248,
          -1.355485200881958,
          -1.173092007637024,
          -1.111267328262329
         ]
        },
        {
         "hoverinfo": "text",
         "hovertext": [
          "Inspecting the content of the csv files",
          " Display a preview of the data loaded from the csv files",
          "Process CSV files",
          "Notice that 'data' is a directory containing the necessary CSV files.",
          " Check against csv files",
          "View data fetched from CSVs",
          "Load the data from the CSV files",
          "Checking data after loading from csv files.",
          "Check what we are loading from the script csv file",
          "Characters and Locations CSVs are already preprocessed. Let's display some examples to understand the data better.",
          "Remove the .csv from the name of the file so that now we only have the table name.",
          "Checking if all the csv files were read correctly",
          " check the content of the CSVs",
          "The top-level directory containing the CSV files is called \"data\". If you are using a different directory, please replace \"data\" with the appropriate directory name.",
          "Create a MongoDB database and import the data from CSV files",
          "I misunderstood the purpose of this script. The goal is to interact with the CSV files and create visualizations, so I will remove the unnecessary imports and invalid code.",
          "This will raise an error because the CSV files are not available, so let's remove it.",
          "Now let's take a look at the content of each CSV file.",
          "Set the script data type to string, to ensure it's correctly read from the CSV",
          "Make sure that the csv files are in a folder named data",
          "Let's just go ahead and display the headers for each CSV file to understand their structure and data types.",
          "Where are the .csv files stored?",
          "Display all the imported csv files",
          " Set this locally\ncsv_exist_local = False"
         ],
         "marker": {
          "opacity": 0.5,
          "size": 5
         },
         "mode": "markers+text",
         "name": "137_CSV file inspection and loading",
         "text": [
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          ""
         ],
         "textfont": {
          "size": 12
         },
         "type": "scattergl",
         "x": [
          12.779403686523438,
          12.531380653381348,
          12.127059936523438,
          12.038446426391602,
          12.909465789794922,
          12.614483833312988,
          12.245766639709473,
          12.854531288146973,
          12.379684448242188,
          11.891037940979004,
          11.122182846069336,
          12.651912689208984,
          12.571825981140137,
          11.880341529846191,
          12.381355285644531,
          12.131123542785645,
          11.66995906829834,
          12.168335914611816,
          11.798994064331055,
          11.798944473266602,
          12.430543899536133,
          12.209089279174805,
          12.470467567443848,
          11.372767448425293
         ],
         "y": [
          0.2263508290052414,
          0.039301589131355286,
          0.4734697639942169,
          1.0022954940795898,
          0.7972633838653564,
          -0.1112280935049057,
          0.29148343205451965,
          0.8048301935195923,
          1.0621484518051147,
          0.7963618040084839,
          0.9499576091766357,
          0.6516370177268982,
          0.43695083260536194,
          0.6727781891822815,
          0.4572416841983795,
          0.6149821281433105,
          0.9872930645942688,
          0.09761424362659454,
          1.7214903831481934,
          0.7237508296966553,
          -0.17460285127162933,
          0.08363638073205948,
          0.1123371571302414,
          1.1413729190826416
         ]
        },
        {
         "hoverinfo": "text",
         "hovertext": [
          "Set seed for reproducibility\nnp.random.seed(0)",
          " Set seed for reproducibility\nnp.random.seed(0)",
          " Set seed for reproducibility\nnp.random.seed(0)",
          " Set seed for reproducibility\nnp.random.seed(0)",
          "Set seed for reproducibility\nnp.random.seed(0)",
          " Set seed for reproducibility\nnp.random.seed(0)",
          "Set seed for reproducibility\nnp.random.seed(0)",
          " Setting the seed for reproducibility\nnp.random.seed(0)",
          "Set seed for reproducibility\nnp.random.seed(0)",
          "Set seed for reproducibility\nnp.random.seed(0)",
          "Set seed for reproducibility\nnp.random.seed(0)",
          "Set seed for reproducibility\nnp.random.seed(0)",
          "Set seed for reproducibility\nnp.random.seed(0)",
          "Set seed for reproducibility\nnp.random.seed(0)",
          "Set seed for reproducibility\nnp.random.seed(0)",
          "Set seed for reproducibility of the results\nnp.random.seed(0)",
          " Set seed for reproducibility\nnp.random.seed(10)",
          "Set seed for reproducibility\nnp.random.seed(0)",
          " set seed for reproducibility\nnp.random.seed(0)",
          "Set seed for reproducibility\nnp.random.seed(0)",
          "Set seed for reproducibility\nnp.random.seed(0)",
          " Set seed for reproducibility\nnp.random.seed(0)",
          "Set seed for reproducibility\nnp.random.seed(0)",
          "Set seed for reproducibility\nnp.random.seed(0)"
         ],
         "marker": {
          "opacity": 0.5,
          "size": 5
         },
         "mode": "markers+text",
         "name": "138_Set seed for reproducibility",
         "text": [
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          ""
         ],
         "textfont": {
          "size": 12
         },
         "type": "scattergl",
         "x": [
          28.2721004486084,
          28.7279109954834,
          28.406269073486328,
          28.235944747924805,
          28.600160598754883,
          28.767892837524414,
          28.731733322143555,
          30.049850463867188,
          28.906780242919922,
          28.63652801513672,
          28.761241912841797,
          28.33858871459961,
          28.410320281982422,
          28.568769454956055,
          28.24629020690918,
          29.114084243774414,
          29.163978576660156,
          28.65705680847168,
          28.42076301574707,
          28.644147872924805,
          28.451488494873047,
          28.47608184814453,
          28.931184768676758,
          28.491310119628906
         ],
         "y": [
          15.485279083251953,
          15.22203540802002,
          15.547811508178711,
          15.481668472290039,
          15.113791465759277,
          15.625452041625977,
          15.460299491882324,
          6.599971771240234,
          15.663237571716309,
          15.283769607543945,
          15.506590843200684,
          15.397055625915527,
          15.334004402160645,
          15.5084228515625,
          15.347254753112793,
          14.892563819885254,
          15.094770431518555,
          15.470074653625488,
          15.20506477355957,
          15.570164680480957,
          15.593697547912598,
          15.21005630493164,
          15.313395500183105,
          15.33174991607666
         ]
        },
        {
         "hoverinfo": "text",
         "hovertext": [
          "Exploring data",
          "Exploring the data.",
          "Data ingestion is complete, moving on to data exploration and analysis.",
          "Create smaller subsets for exploration and model building",
          "Some basic data exploration",
          "Initial data exploration",
          "Data visualization and exploration",
          "Data exploration",
          " Data exploration",
          "Limiting and exploring the data",
          "Data exploration and analysis",
          "Data Insights and Statistics",
          "Exploring the data",
          "Exploration and data visualization",
          "Data Exploration",
          "## 2. Data exploration",
          "Conducting data exploration and analysis",
          "Data Exploration",
          "Data investigation",
          "Data Exploration",
          "Explore data available.",
          "Data Analysis",
          "Data exploration",
          "Data exploration"
         ],
         "marker": {
          "opacity": 0.5,
          "size": 5
         },
         "mode": "markers+text",
         "name": "139_Data Exploration",
         "text": [
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          ""
         ],
         "textfont": {
          "size": 12
         },
         "type": "scattergl",
         "x": [
          16.45584487915039,
          16.345687866210938,
          17.08681297302246,
          16.566516876220703,
          16.53919219970703,
          16.776782989501953,
          16.965763092041016,
          16.608800888061523,
          16.78994369506836,
          16.969938278198242,
          16.991968154907227,
          16.23509979248047,
          16.322343826293945,
          17.078224182128906,
          16.718637466430664,
          15.453298568725586,
          17.114837646484375,
          16.781583786010742,
          15.621644020080566,
          16.72022247314453,
          16.69939613342285,
          16.136037826538086,
          16.570995330810547,
          16.750898361206055
         ],
         "y": [
          0.5798994898796082,
          0.4274490475654602,
          0.8812509179115295,
          0.4976399540901184,
          0.605413556098938,
          0.40514248609542847,
          1.2251348495483398,
          0.9834534525871277,
          0.9813635945320129,
          0.40750351548194885,
          1.2026654481887817,
          0.26951223611831665,
          0.3630843460559845,
          1.1802462339401245,
          1.047790765762329,
          1.104931116104126,
          1.1775327920913696,
          1.0378023386001587,
          0.5580305457115173,
          0.8660833835601807,
          0.43601733446121216,
          0.9966181516647339,
          0.9076805710792542,
          1.055632472038269
         ]
        },
        {
         "hoverinfo": "text",
         "hovertext": [
          "Now, let's take a look at the first few rows of each dataframe.",
          "Let's take a look at the first 5 rows of these dataframes.",
          " Let's take a quick look at the first few rows of each dataframe.",
          "Let's check the first couple of rows of each data frame.",
          "Let's check the first rows of each dataframe.",
          "Let's take a look at the first few rows of each data frame.",
          "Let's take a look at the first few rows of each dataframe",
          " Let's take a look at the first few rows of each dataframe.",
          "Let's look at the first few rows of each imported dataframes",
          " Let's look at the first few records of each dataframe.",
          " Let's take a look at the first few rows of each dataframe.",
          " Let's preview the first few entries of each dataframe to understand the data better.",
          "Let's take a look at the first few rows of each dataframe.",
          " Let's take a look at the first few rows of each dataframe:",
          "Let's see the first few entries in each of these dataframes.",
          "Let's take a look at the first few rows of each dataframe.",
          "Let's take a look at the first few rows of each dataframe.",
          "We'll use strict lists for the values instead of DataFrames for quick retrieval times.",
          "Now let's take a look at the first few rows of each of these DataFrames.",
          "Let's take a look at the first few rows of each of these DataFrames.",
          "Let's take a look at the first few rows of each DataFrame.",
          "Let's take a look at the first 5 rows of each of these DataFrames.",
          "Let's take a peek at the first few entries in each dataframe."
         ],
         "marker": {
          "opacity": 0.5,
          "size": 5
         },
         "mode": "markers+text",
         "name": "140_DataFrames - Quick preview of imported records",
         "text": [
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          ""
         ],
         "textfont": {
          "size": 12
         },
         "type": "scattergl",
         "x": [
          10.744146347045898,
          11.267884254455566,
          10.82295036315918,
          10.982661247253418,
          11.339229583740234,
          10.402342796325684,
          11.055011749267578,
          10.837363243103027,
          11.329635620117188,
          10.631114959716797,
          11.09158706665039,
          10.671825408935547,
          10.584084510803223,
          10.836368560791016,
          10.34668254852295,
          10.792407989501953,
          10.801600456237793,
          10.043593406677246,
          10.801986694335938,
          10.269776344299316,
          10.805042266845703,
          11.487988471984863,
          10.697412490844727
         ],
         "y": [
          -7.4696197509765625,
          -7.219715118408203,
          -7.1963629722595215,
          -7.290215969085693,
          -6.701440811157227,
          -7.188508033752441,
          -7.630742073059082,
          -7.578613758087158,
          -7.756576061248779,
          -7.348124980926514,
          -7.893383979797363,
          -7.667957782745361,
          -7.508994102478027,
          -7.898781776428223,
          -6.949785232543945,
          -7.680249214172363,
          -7.6877007484436035,
          -6.847700595855713,
          -7.29056453704834,
          -7.199352741241455,
          -7.6643242835998535,
          -7.273447513580322,
          -6.715263366699219
         ]
        },
        {
         "hoverinfo": "text",
         "hovertext": [
          "Checking for missing values in the datasets\nprint(df_characters.isnull().sum())\nprint(df_locations.isnull().sum())\nprint(df_script.isnull().sum())\nprint(df_episodes.isnull().sum())",
          " Check if null values exist in the datasets\nprint(\"The number of null values in df_characters is:\", df_characters.isnull().sum().sum())\nprint(\"The number of null values in df_locations is:\", df_locations.isnull().sum().sum())\nprint(\"The number of null values in df_script is:\", df_script.isnull().sum().sum())\nprint(\"The number of null values in df_episodes is:\", df_episodes.isnull().sum().sum())",
          "Calculating number of missing values in each DataFrame\nnull_characters = df_characters.isnull().sum().sum()\nnull_locations = df_locations.isnull().sum().sum()\nnull_episodes = df_episodes.isnull().sum().sum()\nnull_script = df_script.isnull().sum().sum()",
          "Check the number of null values in each dataframe\nprint(df_characters.isnull().sum())\nprint(df_locations.isnull().sum())\nprint(df_script.isnull().sum())\nprint(df_episodes.isnull().sum())",
          "Check missing data\nprint(df_characters.isna().sum())\nprint(df_locations.isna().sum())\nprint(df_script.isna().sum())\nprint(df_episodes.isna().sum())",
          "Check for nulls\nprint(df_characters.isnull().sum(), '\\n')\nprint(df_locations.isnull().sum(), '\\n')\nprint(df_script.isnull().sum(), '\\n')\nprint(df_episodes.isnull().sum(), '\\n')",
          "Check for missing values in the datasets\nprint('Missing values for characters:')\nprint(df_characters.isnull().sum())\nprint('Missing values for locations:')\nprint(df_locations.isnull().sum())\nprint('Missing values for script:')\nprint(df_script.isnull().sum())\nprint('Missing values for episodes:')\nprint(df_episodes.isnull().sum())",
          "Check for missing values in the datasets\nprint('Missing values in the characters dataset:', df_characters.isnull().values.any())\nprint('Missing values in the locations dataset:', df_locations.isnull().values.any())\nprint('Missing values in the script dataset:', df_script.isnull().values.any())\nprint('Missing values in the episodes dataset:', df_episodes.isnull().values.any())",
          " Print the missing values percentage of each dataframe\nprint('Characters:', df_characters.isna().mean())\nprint('Locations:', df_locations.isna().mean())\nprint('Script:', df_script.isna().mean())\nprint('Episodes:', df_episodes.isna().mean())",
          "Check for missing data\nprint(df_episodes.info())",
          "Check missing values\nprint(\"NaN Values in characters: \",df_characters[df_characters.isna().any(axis=1)].shape[0])\nprint(\"NaN Values in locations: \",df_locations[df_locations.isna().any(axis=1)].shape[0])\nprint(\"NaN Values in script: \",df_script[df_script.isna().any(axis=1)].shape[0])\nprint(\"NaN Values in episodes: \",df_episodes[df_episodes.isna().any(axis=1)].shape[0])",
          "Check for NaN in each dataframe\nprint(df_characters.isna().sum())\nprint(df_locations.isna().sum())\nprint(df_script.isna().sum())\nprint(df_episodes.isna().sum())",
          "Check the presence of null values in the datasets\nprint('Characters:', df_characters.isnull().values.any())\nprint('Locations:', df_locations.isnull().values.any())\nprint('Script:', df_script.isnull().values.any())\nprint('Episodes:', df_episodes.isnull().values.any())",
          "Checking for any null values\nprint(df_characters.isnull().sum())\nprint(df_locations.isnull().sum())\nprint(df_script.isnull().sum())\nprint(df_episodes.isnull().sum())",
          "Check the data type and print as the number of missing values in each column\nprint(f'df_characters: {df_characters.shape}')\nprint(df_characters.dtypes, end='\\n\\n')\nprint(df_characters.isna().sum(), end='\\n\\n')\n\nprint(f'df_locations: {df_locations.shape}')\nprint(df_locations.dtypes, end='\\n\\n')\nprint(df_locations.isna().sum(), end='\\n\\n')\n\nprint(f'df_episodes: {df_episodes.shape}')\nprint(df_episodes.dtypes, end='\\n\\n')\nprint(df_episodes.isna().sum(), end='\\n\\n')\n\nprint(f'df_script: {df_script.shape}')\nprint(df_script.dtypes, end='\\n\\n')\nprint(df_script.isna().sum(), end='\\n\\n')",
          "Check for any missing or incomplete data in the characters, locations, script, and episodes dataframes",
          "Checking for any null rows in the dataset\nprint(\"Number of null rows in script dataset:\", df_script.isnull().sum().sum())\nprint(\"Number of null rows in character dataset:\", df_characters.isnull().sum().sum())\nprint(\"Number of null rows in location dataset:\", df_locations.isnull().sum().sum())\nprint(\"Number of null rows in episodes dataset:\", df_episodes.isnull().sum().sum())",
          "# cheek NaN values in dataframes\nprint('Characters NaN values: ' + str(sum(df_characters.isna().sum())))\nprint('Locations NaN values: ' + str(sum(df_locations.isna().sum())))\nprint('Script NaN values: ' + str(sum(df_script.isna().sum())))\nprint('Episodes NaN values: ' + str(sum(df_episodes.isna().sum())))",
          "checking for missing data\ndf_satistics = pd.DataFrame()\ndf_satistics['characters'] = dict(count = df_characters.shape[0])\ndf_satistics['locations'] = dict(count = df_locations.shape[0])\ndf_satistics['episodes'] = dict(count = df_episodes.shape[0])\ndf_satistics['script_lines'] = dict(count = df_script.shape[0])\n\ndf_satistics",
          "Check for null values in our datasets\nprint(\"Null values in characters DataFrame:\\n\", df_characters.isna().sum(), \"\\n\")\nprint(\"Null values in locations DataFrame:\\n\", df_locations.isna().sum(), \"\\n\")\nprint(\"Null values in script DataFrame:\\n\", df_script.isna().sum(), \"\\n\")\nprint(\"Null values in episodes DataFrame:\\n\", df_episodes.isna().sum())",
          "check for missing data in episodes data frame",
          "Check for missing values in each dataframe\nprint(df_characters.isnull().sum())\nprint(df_locations.isnull().sum())\nprint(df_script.isnull().sum())\nprint(df_episodes.isnull().sum())",
          "Check for null values\nprint('Null values in df_characters:', df_characters.isnull().sum().sum())\nprint('Null values in df_locations:', df_locations.isnull().sum().sum())\nprint('Null values in df_script:', df_script.isnull().sum().sum())\nprint('Null values in df_episodes:', df_episodes.isnull().sum().sum())"
         ],
         "marker": {
          "opacity": 0.5,
          "size": 5
         },
         "mode": "markers+text",
         "name": "141_Checking for Missing and Null Values in Datasets",
         "text": [
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          ""
         ],
         "textfont": {
          "size": 12
         },
         "type": "scattergl",
         "x": [
          3.5490505695343018,
          3.838474988937378,
          3.484362840652466,
          3.999230146408081,
          3.641775369644165,
          3.724104166030884,
          3.489365816116333,
          3.829927921295166,
          3.5295724868774414,
          2.595982074737549,
          4.766057968139648,
          4.25053596496582,
          4.079675674438477,
          4.00111722946167,
          3.0820584297180176,
          2.8290724754333496,
          3.652219772338867,
          4.515271186828613,
          2.9974710941314697,
          3.919351816177368,
          3.264561176300049,
          3.542954921722412,
          3.8827285766601562
         ],
         "y": [
          1.0562785863876343,
          0.4925668239593506,
          0.665583074092865,
          0.5156201124191284,
          1.25780189037323,
          0.7266167998313904,
          1.0349501371383667,
          0.89180588722229,
          0.7986899614334106,
          1.71975839138031,
          1.4461003541946411,
          1.5330034494400024,
          0.8487464189529419,
          0.9083819389343262,
          1.260246992111206,
          1.2463605403900146,
          0.3139422833919525,
          1.7982724905014038,
          0.9596925973892212,
          0.9581233859062195,
          1.712884545326233,
          0.7006100416183472,
          0.7615945339202881
         ]
        },
        {
         "hoverinfo": "text",
         "hovertext": [
          "Load the Spacy model for English language\nnlp = spacy.load(\"en_core_web_sm\")",
          "# Load English language model and spacy parser\nnlp = spacy.load('en_core_web_sm')\nnlp.max_length = 10000000",
          "Create an instance of language model\nnlp = spacy.load('en_core_web_sm')",
          "Load the spacy language model\nnlp = spacy.load('en_core_web_sm')",
          "Load spacy language model\nnlp = spacy.load('en_core_web_sm')",
          "# Load the English model\nnlp = spacy.load('en_core_web_sm')",
          " Load Spacy language model\nnlp = spacy.load('en_core_web_sm')",
          "Load the spaCy English model\nnlp = spacy.load('en_core_web_sm')",
          "Declare the language model\nnlp = spacy.load('en_core_web_sm')",
          " Import the spacy language model\nnlp = spacy.load('en_core_web_sm')",
          " Load Spacy English model\nnlp = spacy.load('en_core_web_sm')",
          "Load Spacy in English\nnlp = spacy.load('en_core_web_sm')",
          "define language model\nnlp = spacy.load('en_core_web_sm')",
          "\n# Load the language model\nnlp = spacy.load('en_core_web_sm')",
          " Load spaCy's English NLP model\nnlp = spacy.load('en_core_web_sm')",
          "# Language model for extracting Named Entities\nnlp = spacy.load(\"en_core_web_sm\")",
          " Load Spacy English \"Core Web\" Model\nnlp = spacy.load('en_core_web_sm')",
          " Load Spacy model for English language\nnlp = spacy.load('en_core_web_sm')",
          "Load language model\nnlp = spacy.load('en_core_web_sm')",
          "language model\nnlp = spacy.load('en_core_web_sm')",
          "Load spacy language model\nnlp = spacy.load('en_core_web_sm')",
          "Language-specific imports and variables\nimport en_core_web_sm\nnlp = en_core_web_sm.load()\n\n# Utility function\ndef flatten(l):\n    return [item for sublist in l for item in sublist]",
          " Import Spacy's large english model\nnlp = spacy.load('en_core_web_lg')"
         ],
         "marker": {
          "opacity": 0.5,
          "size": 5
         },
         "mode": "markers+text",
         "name": "142_Language Model Loading with Spacy",
         "text": [
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          ""
         ],
         "textfont": {
          "size": 12
         },
         "type": "scattergl",
         "x": [
          14.657806396484375,
          14.895315170288086,
          14.507210731506348,
          14.333196640014648,
          14.42487907409668,
          14.822637557983398,
          14.416641235351562,
          14.379626274108887,
          14.907707214355469,
          14.697129249572754,
          14.584158897399902,
          14.581840515136719,
          14.556845664978027,
          14.873346328735352,
          14.44473934173584,
          14.738743782043457,
          14.790095329284668,
          14.689874649047852,
          14.446453094482422,
          14.36218547821045,
          14.296236991882324,
          14.724068641662598,
          14.748052597045898
         ],
         "y": [
          9.068906784057617,
          9.003006935119629,
          9.92281723022461,
          10.449079513549805,
          10.137666702270508,
          10.115257263183594,
          10.043099403381348,
          10.030842781066895,
          10.33591365814209,
          10.128904342651367,
          9.670342445373535,
          9.792060852050781,
          10.324738502502441,
          10.340140342712402,
          9.511213302612305,
          9.184881210327148,
          10.152633666992188,
          9.322660446166992,
          10.302884101867676,
          10.018431663513184,
          10.202341079711914,
          9.642961502075195,
          8.937734603881836
         ]
        },
        {
         "hoverinfo": "text",
         "hovertext": [
          " Display the first 5 rows of each dataframe\ndisplay(df_characters.head())\ndisplay(df_locations.head())\ndisplay(df_script.head())\ndisplay(df_episodes.head())",
          "Displaying the first 5 records of each dataframe\nprint('Characters')\nprint(df_characters.head(5))\nprint('Locations')\nprint(df_locations.head(5))\nprint('Script')\nprint(df_script.head(5))\nprint('Episodes')\nprint(df_episodes.head(5))",
          " Display the first 5 rows of each dataframe\ndisplay(df_characters.head())\ndisplay(df_locations.head())\ndisplay(df_script.head())\ndisplay(df_episodes.head())",
          "Display the first 5 rows of each dataframe\nprint(\"Characters\")\ndisplay(df_characters.head(5))\nprint(\"Locations\")\ndisplay(df_locations.head(5))\nprint(\"Episodes\")\ndisplay(df_episodes.head(5))\nprint(\"Scripts\")\ndisplay(df_script.head(5))",
          "View the first 5 rows of each dataframe\nprint('Characters')\ndisplay(df_characters.head())\nprint('Locations')\ndisplay(df_locations.head())\nprint('Script')\ndisplay(df_script.head())\nprint('Episodes')\ndisplay(df_episodes.head())",
          "Displaying the first 5 rows of each dataset\ndisplay(df_characters.head())\ndisplay(df_locations.head())\ndisplay(df_script.head())\ndisplay(df_episodes.head())",
          "Show the first 5 rows of each dataframe\ndisplay(df_characters.head())\ndisplay(df_locations.head())\ndisplay(df_script.head())\ndisplay(df_episodes.head())",
          " Display first 5 records of each dataframe\nprint(\"Characters dataframe\")\ndisplay(df_characters.head())\n\nprint(\"Locations dataframe\")\ndisplay(df_locations.head())\n\nprint(\"Script dataframe\")\ndisplay(df_script.head())\n\nprint(\"Episodes dataframe\")\ndisplay(df_episodes.head())",
          "Display 5 random rows for each dataframe\nprint('The characters dataframe:')\ndisplay(df_characters.sample(5))\n\nprint('The locations dataframe:')\ndisplay(df_locations.sample(5))\n\nprint('The script dataframe:')\ndisplay(df_script.sample(5))\n\nprint('The episodes dataframe:')\ndisplay(df_episodes.sample(5))",
          "display first 5 rows of each dataframe\ndisplay(df_characters.head())\ndisplay(df_locations.head())\ndisplay(df_script.head())\ndisplay(df_episodes.head())",
          "Print first 5 rows of characters, locations, script lines and episodes dataframes",
          " Show the first 5 rows of each dataframe\ndisplay(df_characters.head())\ndisplay(df_locations.head())\ndisplay(df_script.head())\ndisplay(df_episodes.head())",
          "Display first 5 records of each dataframe\ndisplay(df_characters.head())\ndisplay(df_locations.head())\ndisplay(df_script.head())\ndisplay(df_episodes.head())",
          "Display first 5 rows of each dataframe\ndisplay(df_characters.head())\ndisplay(df_locations.head())\ndisplay(df_script.head())\ndisplay(df_episodes.head())",
          "Display the first 5 rows of each DataFrame to understand the kind of data available\nprint('Characters:')\ndisplay(df_characters.head())\nprint('Locations:')\ndisplay(df_locations.head())\nprint('Script Lines:')\ndisplay(df_script.head())\nprint('Episodes:')\ndisplay(df_episodes.head())",
          " Display dimensions and first 5 records of each data frame\nprint('Characters:', df_characters.shape)\nprint('Locations:', df_locations.shape)\nprint('Script:', df_script.shape)\nprint('Episodes:', df_episodes.shape)\n\nprint('Displaying Simpsons Characters')\nprint(df_characters.head())\nprint('Displaying Simpsons Locations')\nprint(df_locations.head())\nprint('Displaying Simpsons Script')\nprint(df_script.head())\nprint('Displaying Simpsons Episodes')\nprint(df_episodes.head())",
          "Display first 5 records of each dataframe to understand its structure\nprint(\"Characters\")\ndisplay(df_characters.head())\n\nprint(\"Locations\")\ndisplay(df_locations.head())\n\nprint(\"Script\")\ndisplay(df_script.head())\n\nprint(\"Episodes\")\ndisplay(df_episodes.head())",
          " Display the first 5 rows of each DataFrame.\ndisplay(df_characters.head())\ndisplay(df_locations.head())\ndisplay(df_script.head())\ndisplay(df_episodes.head())",
          " Display first 5 rows of each dataframe\ndfs = {'characters': df_characters, 'locations': df_locations, 'script': df_script, 'episodes': df_episodes}\nfor name, dframe in dfs.items():\n    print('\\n' + name.upper())\n    print(dframe.head())",
          "Preview first 5 rows of each dataframe\nprint(\"--- Characters ---\")\ndisplay(df_characters.head())\n\nprint(\"--- Locations ---\")\ndisplay(df_locations.head())\n\nprint(\"--- Script ---\")\ndisplay(df_script.head())\n\nprint(\"--- Episodes ---\")\ndisplay(df_episodes.head())",
          "Preview the first 5 rows of each dataframe to see what we are working with\nprint(\"Characters\")\ndisplay(df_characters.head())\n\nprint(\"Locations\")\ndisplay(df_locations.head())\n\nprint(\"Script\")\ndisplay(df_script.head())\n\nprint(\"Episodes\")\ndisplay(df_episodes.head())",
          "Display the first 5 rows of each dataframe\ndfs = {'Characters': df_characters, 'Locations': df_locations, 'Script': df_script, 'Episodes': df_episodes}\nfor name, df in dfs.items():\n    print(name)\n    print(df.head())\n    print('\\n')",
          "Display first 5 rows of each DataFrame to understand their structure\nprint(\"Characters data:\")\ndisplay(df_characters.head())\n\nprint(\"Locations data:\")\ndisplay(df_locations.head())\n\nprint(\"Script data:\")\ndisplay(df_script.head())\n\nprint(\"Episodes data:\")\ndisplay(df_episodes.head())"
         ],
         "marker": {
          "opacity": 0.5,
          "size": 5
         },
         "mode": "markers+text",
         "name": "143_Displaying Simpsons Dataframes",
         "text": [
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          ""
         ],
         "textfont": {
          "size": 12
         },
         "type": "scattergl",
         "x": [
          -2.2193288803100586,
          -1.3823151588439941,
          -2.1083688735961914,
          -1.7041186094284058,
          -1.9848350286483765,
          -2.721090793609619,
          -2.285038948059082,
          -1.5664441585540771,
          -1.5037225484848022,
          -1.8274171352386475,
          -1.5884507894515991,
          -2.6236226558685303,
          -1.6456860303878784,
          -1.5797226428985596,
          -1.8349275588989258,
          -1.3149430751800537,
          -1.9217519760131836,
          -1.9582886695861816,
          -1.4178218841552734,
          -2.5699470043182373,
          -2.4102182388305664,
          -1.1724110841751099,
          -1.8088419437408447
         ],
         "y": [
          6.957778453826904,
          6.495814323425293,
          7.03509521484375,
          6.23745584487915,
          6.026312828063965,
          6.6552252769470215,
          6.812996864318848,
          6.429218769073486,
          5.5715765953063965,
          6.599073886871338,
          6.320324420928955,
          6.600833415985107,
          6.774575710296631,
          7.1476149559021,
          6.240574836730957,
          5.73254919052124,
          6.117015838623047,
          6.909290790557861,
          6.635645389556885,
          5.665081977844238,
          5.534636497497559,
          6.441135406494141,
          6.0554280281066895
         ]
        },
        {
         "hoverinfo": "text",
         "hovertext": [
          "Drop duplicates from all tables\ndf_characters.drop_duplicates(subset='character_id', inplace=True)\ndf_locations.drop_duplicates(subset='location_id', inplace=True)\ndf_script.drop_duplicates(subset='line_id', inplace=True)\ndf_episodes.drop_duplicates(subset='episode_id', inplace=True)",
          "Drop duplicate lines and NaN values from the script\ndf_script.drop_duplicates(subset=['id', 'episode_id'], inplace=True)\ndf_script.dropna(subset=['raw_text', 'normalized_text'], inplace=True)",
          "removing duplicate entries based on the 'id' column\ndf_characters = df_characters.drop_duplicates(subset='id')\ndf_locations = df_locations.drop_duplicates(subset='id')\ndf_script = df_script.drop_duplicates(subset='id')\ndf_episodes = df_episodes.drop_duplicates(subset='id')",
          "Check if all dfs have unique string ids",
          "Ensure the 'id' column is unique for all dataframes",
          "Create a deep copy of df_script and drop duplicate rows based on 'id' column\ndf_script_unique = df_script.copy()\ndf_script_unique.drop_duplicates(subset='id', keep='last', inplace=True)",
          "Remove duplicates from script dataframe\ndf_script.drop_duplicates(subset=['episode_id', 'number', 'raw_text'], inplace=True)",
          "Ensure all scripts have a unique identifier\ndf_script = df_script.drop_duplicates(subset='id')",
          " Data preprocess\ndf_script = df_script.rename(columns={'id': 'id_script'})\ndf_script = df_script.drop_duplicates(subset='raw_text')",
          "Remove any possible duplicate rows in the dataframes\ndf_characters.drop_duplicates(subset =\"id\", keep = False, inplace = True)\ndf_locations.drop_duplicates(subset =\"id\", keep = False, inplace = True)\ndf_script.drop_duplicates(subset =\"id\", keep = False, inplace = True)\ndf_episodes.drop_duplicates(subset =\"id\", keep = False, inplace = True)",
          "Remove duplicates from script\ndf_script = df_script.drop_duplicates(subset=['character_id', 'raw_text'])",
          "Deletes all columns containing duplicates in both datasets\ndf_characters = df_characters.drop_duplicates()\ndf_locations = df_locations.drop_duplicates()",
          " drop duplicate values from the script dataframe\ndf_script.drop_duplicates(subset=['raw_text'], keep='first', inplace=True)",
          "Remove duplicate rows\ndf_script.drop_duplicates(subset=['character_id', 'episode_id', 'raw_text'], inplace=True)",
          "Remove unnecessary columns and rows from the characters DataFrame\ndf_characters = df_characters.drop(columns=['id', 'image_url', 'index'])\ndf_characters.dropna(inplace=True)\ndf_characters.drop_duplicates(subset =\"name\", keep = 'first', inplace = True)",
          "Remove duplicates from dataframe",
          " Remove duplicate entries in character and location dataframes\ndf_characters = df_characters.drop_duplicates(subset='raw_character_text')\ndf_locations = df_locations.drop_duplicates(subset='raw_location_text')",
          "Remove duplicate script lines if any\ndf_script.drop_duplicates(subset='id', keep=False, inplace=True)",
          "Remove duplicates from characters, locations and episodes dataframes\ndf_characters.drop_duplicates(subset=['name'], inplace=True)\ndf_locations.drop_duplicates(subset=['name'], inplace=True)\ndf_episodes.drop_duplicates(subset=['title'], inplace=True)",
          "unique writers\ndf_script.writer_id.unique()",
          "Remove potential duplicate rows from characters, locations, episodes dataframes\ndf_characters.drop_duplicates(inplace=True)\ndf_locations.drop_duplicates(inplace=True)\ndf_episodes.drop_duplicates(inplace=True)",
          "Remove any duplicate rows\ndf_script.drop_duplicates(inplace=True)",
          " Remove duplicate character and location names\ndf_characters.drop_duplicates(subset =\"name\", inplace = True)\ndf_locations.drop_duplicates(subset =\"name\", inplace = True)"
         ],
         "marker": {
          "opacity": 0.5,
          "size": 5
         },
         "mode": "markers+text",
         "name": "144_Removing Duplicate Rows and Values in Dataframes",
         "text": [
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          ""
         ],
         "textfont": {
          "size": 12
         },
         "type": "scattergl",
         "x": [
          6.011853218078613,
          6.475913047790527,
          5.90300178527832,
          6.321181297302246,
          6.272099494934082,
          6.168031215667725,
          5.841244697570801,
          6.368790626525879,
          5.735710144042969,
          6.273908615112305,
          6.187617778778076,
          6.163234710693359,
          6.414609909057617,
          5.714129447937012,
          5.384355068206787,
          6.9088006019592285,
          6.011588096618652,
          6.302712440490723,
          5.649504661560059,
          6.005177021026611,
          5.688501834869385,
          6.389903545379639,
          5.92415189743042
         ],
         "y": [
          6.115876197814941,
          5.428709506988525,
          6.027288913726807,
          4.15475606918335,
          2.74692964553833,
          4.823970794677734,
          5.318986415863037,
          4.6993513107299805,
          5.128721237182617,
          5.664516925811768,
          6.230840682983398,
          6.284775733947754,
          5.509791851043701,
          5.8447113037109375,
          6.73848295211792,
          3.6452481746673584,
          6.795186996459961,
          5.152220726013184,
          6.082017421722412,
          5.404045104980469,
          5.820321083068848,
          4.852562427520752,
          6.8009443283081055
         ]
        },
        {
         "hoverinfo": "text",
         "hovertext": [
          "Set random seed for reproducibility\nnp.random.seed(0)",
          "Set random seed for reproducibility\nnp.random.seed(0)",
          "Setting random seed for reproducibility\nnp.random.seed(0)",
          " Set random state for reproducibility\nnp.random.seed(0)",
          "Set random seed for reproducibility\nnp.random.seed(0)",
          "Set random seed for reproducibility\nnp.random.seed(0)",
          "Set random seed for reproducibility\nnp.random.seed(0)",
          " Set random seed for reproducibility\nnp.random.seed(0)",
          "Set random seed for reproducibility\nnp.random.seed(0)",
          "Set random seed for reproducibility\nnp.random.seed(0)",
          "Set random seed for reproducibility\nnp.random.seed(0)",
          "Set random seed for reproducibility\nnp.random.seed(0)",
          "Set random seed for reproducibility\nnp.random.seed(0)",
          "Set random seed for reproducibility\nnp.random.seed(0)",
          "Set random seed for reproducibility\nnp.random.seed(0)",
          "Set random seed for reproducibility\nnp.random.seed(0)",
          "Setting random seed for reproducibility\nnp.random.seed(0)",
          "Set random seed for reproducibility\nnp.random.seed(0)",
          "Set random seed for reproducibility\nnp.random.seed(0)",
          "Set random seed for reproducibility\nnp.random.seed(0)",
          " Set a pre-defined random state for reproducibility",
          "Set random seed for reproducibility\nnp.random.seed(0)",
          "Set random seed for reproducibility\nnp.random.seed(0)"
         ],
         "marker": {
          "opacity": 0.5,
          "size": 5
         },
         "mode": "markers+text",
         "name": "145_Setting random seed for reproducibility",
         "text": [
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          ""
         ],
         "textfont": {
          "size": 12
         },
         "type": "scattergl",
         "x": [
          32.441612243652344,
          32.19854736328125,
          32.04437255859375,
          31.616230010986328,
          32.34445571899414,
          32.22469711303711,
          31.980932235717773,
          32.11025619506836,
          32.417728424072266,
          32.46681213378906,
          32.2376594543457,
          32.097415924072266,
          32.130435943603516,
          32.26409912109375,
          32.4200325012207,
          32.099510192871094,
          32.32742691040039,
          32.15043640136719,
          32.09943771362305,
          32.18280792236328,
          31.59956169128418,
          32.19760513305664,
          32.212364196777344
         ],
         "y": [
          13.137787818908691,
          13.242997169494629,
          14.04147720336914,
          13.515433311462402,
          13.473072052001953,
          13.569721221923828,
          13.612604141235352,
          14.146363258361816,
          13.691664695739746,
          13.404744148254395,
          13.205784797668457,
          13.214498519897461,
          13.40043830871582,
          13.473856925964355,
          13.550578117370605,
          13.532320022583008,
          14.328460693359375,
          13.288575172424316,
          13.625518798828125,
          13.101011276245117,
          12.809103965759277,
          13.671055793762207,
          13.632975578308105
         ]
        },
        {
         "hoverinfo": "text",
         "hovertext": [
          "Set default fontsize for better readability of charts\nmatplotlib.rcParams.update({'font.size': 14})",
          "Set up matplotlib\nfont = {'family' : 'normal',\n        'weight' : 'bold',\n        'size'   : 22}\n\nmatplotlib.rc('font', **font)",
          "Set up matplotlib parameters to make the plots look better\nmatplotlib.rcParams['figure.figsize'] = (15, 10)\nmatplotlib.rcParams['font.size'] = 10\nmatplotlib.rcParams['figure.facecolor'] = '#00000000'",
          "Set the font for saving as pdf. Set properties for rendering of fonts\n\nmatplotlib.rcParams['pdf.fonttype'] = 42  # Embedded subset (only the used characters)",
          "For plotting\nfont = {'family' : 'normal',\n        'weight' : 'bold',\n        'size'   : 22}\n\nmatplotlib.rc('font', **font)",
          "Set up styles\nplt.style.use('fivethirtyeight')\nmatplotlib.rcParams.update({\n    'font.size': 12,\n    'figure.figsize': (15, 5),\n    'axes.labelsize': 10,\n    'axes.titlesize': 14,\n    'xtick.labelsize': 10,\n    'ytick.labelsize': 10,\n    'legend.fontsize': 10\n})",
          " Set up variables\nfontsize = 40\nfont_path = 'data/JetBrainsMono-Bold.ttf'",
          "Configure matplotlib rcParams for a consistent style throughout the notebook\nmatplotlib.rcParams.update({\n    'font.size': 16,\n    'figure.figsize': (10, 8),\n    'axes.grid': True,\n    'axes.axisbelow': True,\n    'axes.labelsize': 16,\n    'axes.titlesize': 20,\n    'axes.linewidth': 2,\n    'lines.linewidth': 3,\n    'lines.markersize': 10,\n    'xtick.labelsize': 16,\n    'ytick.labelsize': 16,\n    'legend.fontsize': 16\n})",
          " Set default font size for plots\nmatplotlib.rcParams.update({'font.size': 12})",
          "Set font for entire script\nmatplotlib.rcParams['font.family'] = 'DejaVu Sans'",
          " Set font style\nfont = {\n    'family': 'DejaVu Sans',\n    'weight': 'normal',\n    'size': 14\n}\nmatplotlib.rc('font', **font)",
          "Show installed fonts\n[f.name for f in matplotlib.font_manager.fontManager.ttflist]",
          "'Jupyter lab' theme\nplt.rcParams.update({'axes.titlesize': 'large', 'figure.titlesize': 'large'})",
          "Set custom matplotlib settings\nmatplotlib.rcParams.update({\n    'font.size': 14,\n    'figure.figsize': (10, 8),\n    'figure.facecolor': '#00000000',\n    'axes.labelsize': 12,\n    'axes.labelcolor': '#ffffff',\n    'axes.labelweight': 'bold',\n    'axes.titlesize': 16,\n    'axes.titlecolor': '#ffffff',\n    'axes.titleweight': 'bold',\n    'xtick.labelsize': 10,\n    'ytick.labelsize': 10,\n    'legend.fontsize': 12,\n    'legend.title_fontsize': 14\n})",
          "Set the font family and size for matplotlib plots\nplt.rcParams['font.family'] = 'Arial'\nplt.rcParams['font.size'] = 12",
          "matplotlib.rcParams.update({'font.size': 22})",
          "Plot settings\nmatplotlib.rcParams['axes.labelsize'] = 14\nmatplotlib.rcParams['xtick.labelsize'] = 12\nmatplotlib.rcParams['ytick.labelsize'] = 12\nmatplotlib.rcParams['text.color'] = 'k'",
          "Set up default plotting parameters\nmatplotlib.rc('font', **{'size': 12})\nmatplotlib.rc('grid', **{'color': '0.75', 'linestyle': '-', 'linewidth': 0.5})\nmatplotlib.rc('figure', **{'figsize': (10, 6)})\nmatplotlib.rc('axes', **{'facecolor': '0.95', 'edgecolor': '0.85', 'grid': True})\nmatplotlib.rc('axes', **{'titlesize': 'large', 'labelsize': 'large'})\nmatplotlib.rc('xtick', **{'color': '0.2', 'labelsize': 'large'})\nmatplotlib.rc('ytick', **{'color': '0.2', 'labelsize': 'large'})\nmatplotlib.rc('legend', **{'fontsize': 'large', 'numpoints': 1, 'shadow': True, 'fancybox': True})\nmatplotlib.rc('image', **{'cmap': 'Greys', 'interpolation': 'none', 'aspect': 'equal'})",
          "Define the font to use for plots\nplt.rcParams['font.family'] = 'DejaVu Sans'",
          "# set up matplotlib parameters to fit these charts in readme\n\nmatplotlib.rcParams.update({'font.size': 22})",
          "Set default font size for better visualization\nfont = {'size': 11}\nmatplotlib.rc('font', **font)",
          "SetFont\nmatplotlib.rcParams['font.family'] = ['Noto Sans CJK JP']",
          " Settings for visualization\nfont = {'size': 60}\nmatplotlib.rc('font', **font)"
         ],
         "marker": {
          "opacity": 0.5,
          "size": 5
         },
         "mode": "markers+text",
         "name": "146_Font size and style customization in matplotlib",
         "text": [
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          ""
         ],
         "textfont": {
          "size": 12
         },
         "type": "scattergl",
         "x": [
          20.97139549255371,
          21.159191131591797,
          20.239734649658203,
          21.254878997802734,
          21.327939987182617,
          21.098934173583984,
          21.246702194213867,
          20.829730987548828,
          21.058151245117188,
          21.550321578979492,
          21.3242244720459,
          21.455583572387695,
          20.40627098083496,
          21.001811981201172,
          20.852493286132812,
          20.887102127075195,
          20.960052490234375,
          20.839685440063477,
          21.428382873535156,
          20.920133590698242,
          21.080781936645508,
          21.518756866455078,
          20.855297088623047
         ],
         "y": [
          6.729861736297607,
          7.562346935272217,
          6.781768321990967,
          7.192374229431152,
          7.482904434204102,
          6.439345836639404,
          7.376909255981445,
          6.398699760437012,
          7.241337299346924,
          7.4584150314331055,
          7.444786548614502,
          7.662421703338623,
          6.570269584655762,
          6.817641258239746,
          7.024448871612549,
          6.807738304138184,
          6.387447357177734,
          6.403350830078125,
          7.056567668914795,
          7.1784796714782715,
          7.257977485656738,
          7.537403106689453,
          7.448300838470459
         ]
        },
        {
         "hoverinfo": "text",
         "hovertext": [
          "Extract the first few elements of the dataframe to get an understanding of the data",
          "Inspect the first few entries of each dataframe to understand the data",
          "Inspect the first few rows of each dataframe to understand the data",
          "Looking at the first few rows of each dataframe to understand the data",
          "Inspect the first few rows of each dataframe to understand the data",
          " Viewing the first few rows of each dataframe to get an understanding of the data",
          "Inspect the first few rows of each dataframe to understand the data",
          "Inspect the first few rows of each DataFrame to understand the data",
          "Inspect the first few rows of each dataframe to understand their structure and available data",
          "Inspect the first few rows of each dataframe to understand the data",
          "Viewing the first few rows of the dataframes to understand the data",
          "Inspect dataframes' first few rows",
          "Inspect the first few rows of each dataframe to understand the data",
          "Inspect the first few rows of each dataframe to understand the data",
          "Inspect the first few rows of each dataframe to understand the data",
          "Inspect the first few rows of each DataFrame to understand the data",
          "Inspect the first few rows of each dataframe to understand the data",
          "Inspect the first few rows of each dataframe to understand the data",
          "Inspect the first rows of the dataframe to get an idea of the data",
          "Return the first few rows of each dataframe to inspect the data.",
          "Analyse the first rows of the dataframes to get an idea of the data",
          "Inspecting the dataframe for the first time"
         ],
         "marker": {
          "opacity": 0.5,
          "size": 5
         },
         "mode": "markers+text",
         "name": "147_Inspecting and Understanding Dataframes",
         "text": [
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          ""
         ],
         "textfont": {
          "size": 12
         },
         "type": "scattergl",
         "x": [
          13.85085678100586,
          14.09046745300293,
          13.850995063781738,
          13.873594284057617,
          13.762792587280273,
          13.32719898223877,
          13.745247840881348,
          13.474336624145508,
          13.365487098693848,
          13.665928840637207,
          13.34047794342041,
          13.315351486206055,
          13.816150665283203,
          13.708907127380371,
          13.947284698486328,
          14.068138122558594,
          13.768095016479492,
          13.623017311096191,
          13.607625961303711,
          13.032980918884277,
          14.047930717468262,
          12.917128562927246
         ],
         "y": [
          -8.403707504272461,
          -8.575931549072266,
          -8.56259822845459,
          -8.637699127197266,
          -8.637001991271973,
          -9.10066032409668,
          -8.642220497131348,
          -8.679598808288574,
          -8.155694961547852,
          -8.514054298400879,
          -8.899322509765625,
          -8.159876823425293,
          -8.341720581054688,
          -8.867256164550781,
          -8.591957092285156,
          -8.697001457214355,
          -8.382872581481934,
          -8.805574417114258,
          -8.197052955627441,
          -8.580652236938477,
          -8.46461009979248,
          -7.520492076873779
         ]
        },
        {
         "hoverinfo": "text",
         "hovertext": [
          "Display the first 5 records of the characters data\ndf_characters.head()",
          "display first 5 records of the characters table\ndf_characters.head()",
          "display only the first 5 records of df_characters\ndf_characters.head()",
          "Show the first 5 records of the dataset\ndf_characters.head()",
          "Show the first 5 records of the characters dataframe\ndf_characters.head()",
          " Show the first 5 records of the characters dataframe\ndf_characters.head()",
          "Print the first 5 records of the characters data frame\ndf_characters.head()",
          " Display first 5 records for characters dataset\ndf_characters.head()",
          "Display the first 5 records for the characters dataframe\ndf_characters.head()",
          "Display the first 5 records of the characters DataFrame\ndf_characters.head()",
          " Show first 5 entries of df_characters dataframe\ndf_characters.head()",
          "Display first 5 records of the dataframe\ndf_characters.head()",
          "Display the first 5 records of the characters dataframe\ndf_characters.head()",
          "# Display the first 5 records of the characters dataframe\ndf_characters.head()",
          "# Display first 5 records of characters dataframe\ndf_characters.head()",
          "\n# Displaying first 5 records\ndf_characters.head()",
          "View the first 5 rows of the characters dataset\ndf_characters.head()",
          "View the first 5 records of characters dataset\ndf_characters.head()",
          "Data Preprocessing\n# Show the first 5 records of the characters dataframe\ndf_characters.head()",
          "View the first 5 records of characters dataframe\ndf_characters.head()",
          "Show first 5 records of the characters dataframe\ndf_characters.head(5)",
          "View the first 5 records of 'df_characters'\ndf_characters.head()"
         ],
         "marker": {
          "opacity": 0.5,
          "size": 5
         },
         "mode": "markers+text",
         "name": "148_Displaying first 5 records of characters dataframe",
         "text": [
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          ""
         ],
         "textfont": {
          "size": 12
         },
         "type": "scattergl",
         "x": [
          -0.46077314019203186,
          -0.3602733910083771,
          -0.46854835748672485,
          0.007403270807117224,
          -0.47519996762275696,
          -0.5331493616104126,
          -0.5847964286804199,
          -0.5563086867332458,
          -0.7108553051948547,
          -0.6106283068656921,
          -0.7906253337860107,
          -0.715080201625824,
          -0.3563164472579956,
          -0.7613869309425354,
          -1.0326294898986816,
          -0.5320226550102234,
          -0.2496436983346939,
          -0.05657004192471504,
          -0.5566718578338623,
          -0.10227066278457642,
          -0.771187961101532,
          0.09480631351470947
         ],
         "y": [
          13.589499473571777,
          13.495728492736816,
          13.688666343688965,
          13.294045448303223,
          13.711019515991211,
          13.467495918273926,
          13.394388198852539,
          13.12983512878418,
          13.945377349853516,
          13.523053169250488,
          13.032712936401367,
          13.915251731872559,
          13.673069953918457,
          13.765704154968262,
          13.544051170349121,
          13.403267860412598,
          12.510452270507812,
          13.141472816467285,
          13.67098617553711,
          12.984471321105957,
          13.9107027053833,
          13.214269638061523
         ]
        },
        {
         "hoverinfo": "text",
         "hovertext": [
          "Filter some locations which contain non-ASCII characters\ndf_locations_filtered = df_locations[df_locations['name'].apply(lambda x: x.isascii())].copy()\n\n# Extract character names\ncharacters = df_characters['name'].tolist()\n",
          "Filter only the canonical ones\ndf_characters = df_characters[df_characters['is_canon']]\n\n# Convert the title of characters to lowercase\ndf_characters['normalized_name'] = df_characters['name'].str.lower()\n\n# Display the dataframe\ndf_characters.head()",
          "Ensure actors are consistently mapped with the same name\ndf_script[\"raw_character_text\"].replace({\"brad goodman\": \"brad goodman psychiatrist\"}, inplace=True)\ndf_script[\"raw_character_text\"].replace({\"brad goodman psychiatrist\": \"brad goodman\"}, inplace=True)",
          " Some useful variables\nnames = list(df_characters.raw_character_text)\nlocations = list(df_locations.raw_location_text)",
          " Reset character and location names to lowercase for easier matching\ndf_characters['name'] = df_characters['name'].str.lower()\ndf_locations['name'] = df_locations['name'].str.lower()",
          "Check if rows in script DF contain either characters or locations\ncharacter_names = list(df_characters['character_name'].values)\nlocation_names = list(df_locations['raw_location_text'].values)",
          " Strip invalid characters from character names and location names\ndf_characters['name_stripped'] = df_characters['name'].str.replace('[^\\w\\s]', '')\ndf_locations['name_stripped'] = df_locations['name'].str.replace('[^\\w\\s]', '')",
          "# Fix issue with character names\ndf_characters['normalized_name'] = df_characters['normalized_name'].replace('lisa & bart', 'lisa, bart')\n\n# Display first few characters\ndf_characters.head()",
          "Remove casing in the `character_name` column\ndf_characters['character_name'] = df_characters['character_name'].str.lower()",
          "Converts 'raw_location_text' into a column of entity name\ndf_script['location_entity'] = df_script['raw_location_text'].apply(lambda x: [i['text'] for i in sp(x).ents if i.label_ == 'GPE'])",
          "Split names into first and last names\ndf_characters[['first_name', 'last_name']] = df_characters.character.str.split(\"_\", expand=True)",
          "Setting characters and locations to lowercase\ndf_characters['normalized_name'] = df_characters['name'].str.lower().str.strip()\ndf_characters['normalized_name'] = df_characters['normalized_name'].str.replace(\" \", \"_\")\n\ndf_locations['normalized_name'] = df_locations['name'].str.lower().str.strip()\ndf_locations['normalized_name'] = df_locations['normalized_name'].str.replace(\" \", \"_\")",
          "Ensure that characters and locations have names\ndf_characters['name'] = df_characters['name'].apply(lambda x: x.lower() if isinstance(x, str) else '')\ndf_locations['name'] = df_locations['name'].apply(lambda x: x.lower() if isinstance(x, str) else '')",
          "Filter leading and trailing white spaces from character and location names\ndf_characters['character'] = df_characters['character'].str.strip()\ndf_locations['raw_location_text'] = df_locations['raw_location_text'].str.strip()",
          " Extract characters, locations, and raw text from script data\ncharacters = [str(c).lower() for c in df_characters['character_name']]\nlocations = [str(l).lower() for l in df_locations['raw_location_text']]\nraw_text = [str(t).lower() for t in df_script['raw_text']]",
          " Strip leading/trailing whitespaces from character names and location names\ndf_characters['name'] = df_characters['name'].str.strip()\ndf_locations['name'] = df_locations['name'].str.strip()",
          "Concatenate last_name and first_name strings\ndf_script['character_name'] = df_script['raw_character_text'].str.lower().str.replace(\" \",\"\")",
          " Lowercase character names in the characters dataframe\ndf_characters['name'] = df_characters['name'].str.lower()",
          "Normalize character names\ndef normalize_characters(df):\n    df['normalized_name'] = df.name.str.lower()\n    df['normalized_name'] = df.normalized_name.str.replace(r\"[^\\w\\s]\", '', regex=True)\n\nnormalize_characters(df_characters)",
          "Setting series characters to lower case\ndf_characters['normalized_name'] = df_characters['name'].apply(lambda x: x.lower())",
          " Mapping for names and locations\ndf_characters['raw_character_text'].replace({'\\s{2,}': ' ', '^ ': '', '$ ': ''}, inplace=True, regex=True)\ndf_locations['raw_location_text'].replace({'\\s{2,}': ' ', '^ ': '', '$ ': ''}, inplace=True, regex=True)\ndf_script['raw_character_text'].replace({'\\s{2,}': ' ', '^ ': '', '$ ': ''}, inplace=True, regex=True)\ndf_script['raw_location_text'].replace({'\\s{2,}': ' ', '^ ': '', '$ ': ''}, inplace=True, regex=True)",
          " Concatenate location name and normalized_text and split them with a space\ndf_script['location_text'] = df_script['raw_location_text'] + ' ' + df_script['normalized_text']\n\n# Normalizes text field\n# Converts string to lowercase and removes leading and trailing white spaces\ndf_script['location_text'] = df_script['location_text'].str.lower().str.strip()"
         ],
         "marker": {
          "opacity": 0.5,
          "size": 5
         },
         "mode": "markers+text",
         "name": "149_White space cleaning and normalization of character and location names",
         "text": [
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          ""
         ],
         "textfont": {
          "size": 12
         },
         "type": "scattergl",
         "x": [
          5.441267013549805,
          5.816910266876221,
          5.102316856384277,
          4.988377571105957,
          5.345216274261475,
          5.243838310241699,
          5.687524318695068,
          6.393563270568848,
          5.983271598815918,
          4.932221412658691,
          6.083251953125,
          5.681478500366211,
          5.073404312133789,
          5.610692501068115,
          4.911318778991699,
          5.4198102951049805,
          5.789468288421631,
          5.964823246002197,
          6.177909851074219,
          6.006689071655273,
          5.358386993408203,
          4.912301540374756
         ],
         "y": [
          8.785908699035645,
          9.467453002929688,
          8.24570369720459,
          8.77359676361084,
          8.966145515441895,
          8.319130897521973,
          9.272574424743652,
          9.296453475952148,
          9.094239234924316,
          8.514686584472656,
          9.943096160888672,
          9.294791221618652,
          8.80637264251709,
          9.020118713378906,
          8.50672721862793,
          8.857248306274414,
          9.664390563964844,
          9.104177474975586,
          9.883024215698242,
          9.766139030456543,
          8.891979217529297,
          9.252331733703613
         ]
        },
        {
         "hoverinfo": "text",
         "hovertext": [
          "Link the episodes to the script lines\ndf_script['episode'] = df_script.apply(lambda row: df_episodes.iloc[row['episode_id']].number, axis=1)",
          "Create new columns with episode title and writer names\ndf_script['episode_title'] = df_script['episode_id'].map(df_episodes.set_index('id')['title'])\ndf_script['writers'] = df_script['episode_id'].map(df_episodes.set_index('id')['writers'])",
          "Create a \"debut\" column in df_characters containing the episode_id of the character's debut episode.",
          "# Join the dataframes for simpsons\ndf = df_script.set_index('episode_id').join(df_episodes.set_index('id'), lsuffix='script', rsuffix='ep')\ndf = df.join(df_characters.set_index('id'), on='character_id')",
          " Separate script based on character IDs and episode IDs\nmain_chars = list(df_characters[df_characters['main']] 'id')\n\n\nep_ids = list(df_episodes['id'])\nscripts = {}\n\nfor ep_id in ep_ids:\n    # print(ep_id)\n    \n    df_ep_script = df_script[df_script['episode_id'] == ep_id]\n    \n    if len(df_ep_script) == 0:\n        scripts[ep_id] = ''\n        continue\n    \n    for char_id in main_chars:\n        df_char_ep_script = df_ep_script[df_ep_script['character_id'] == char_id]\n        script = df_char_ep_script['spoken_words'].values\n        script = ' '.join([x for x in script if type(x) == str])\n        \n        scripts[(ep_id, char_id)] = script",
          " Create a new column for episode titles in df_script\ndf_script['episode_title'] = df_script['episode_id'].map(df_episodes.set_index('id')['title'])",
          "# Add episode title to script dataframe\ndf_script = df_script.join(df_episodes.set_index('id'), on='episode_id')",
          "alldata = df_script.join(df_episodes.set_index('id'), on='episode_id', rsuffix='_episode')\nalldata = alldata.join(df_characters.set_index('id'), on='character_id', rsuffix='_character')",
          "Setting the 'character_id' column in 'episode' dataframe to match 'id' in 'character' dataframe.",
          "Map the episode names to each script line\ndf_script['episode_name'] = df_script['episode_id'].map(df_episodes.set_index('id')['title'])\n\n# Remove the \\r formatting used in the script\ndf_script['raw_text'] = df_script['raw_text'].str.replace('\\r', '')",
          "Create a joining table between the episodes and script lines DataFrame\ndf_episodes['id'] = df_episodes['id'].astype(str)\ndf_script['episode_id'] = df_script['episode_id'].astype(str)\n\ndf_episodes_script = df_episodes.set_index('id').join(\n    df_script.set_index('episode_id'),\n    rsuffix='_episode',\n    how='right'\n)",
          "Join df_script with df_episodes to add episode information to df_script\ndf_joined = df_script.set_index('episode_id').join(df_episodes.set_index('id'), rsuffix='_episode')",
          "Create a dictionary mapping episode_id to episode_name to replace\n# episode_id with episode_names in both episode_ids and episode_names\nepisode_id_to_name = df_episodes.set_index('id')['title'].to_dict()\n\n# Replace episode_id with episode_name\ndf_script['episode_id'] = df_script['episode_id'].replace(episode_id_to_name)",
          "Create a dictionary for each episode to easier lookup\nepisode_to_script = {}\nfor idx in tqdm(df_script.index):\n    if df_script.loc[idx, 'episode_id'] not in episode_to_script:\n        episode_to_script[df_script.loc[idx, 'episode_id']] = []\n    episode_to_script[df_script.loc[idx, 'episode_id']].append(idx)",
          "Combine script lines with metadata\ndf_joined = df_script.set_index('episode_id').join(\n    df_episodes.set_index('id'),\n    rsuffix='_ep'\n).join(\n    df_characters.set_index('id'),\n    rsuffix='_ch'\n).join(\n    df_locations.set_index('id'),\n    rsuffix='_loc'\n).reset_index()",
          "Create a dictionary that maps episode_id to episode\nepisode_dict = dict()\nfor index, row in df_episodes.iterrows():\n    episode = dict(row)\n    episode_dict[episode['id']] = episode",
          "# Create a column with the name of the episode based on the id\ndf_script['name_of_episode'] = df_script['episode_id'].apply(lambda x: df_episodes[df_episodes['id'] == x].iloc[0]['title'])",
          "Move 'The simpsons' to the front of the list\ndf_episodes['title'] = df_episodes['title'].apply(lambda x: 'The Simpsons' if 'The Simpsons' in x else x)\ndf_episodes['title'] = df_episodes['title'].apply(lambda x: 'The Simpsons' if x == 'Duh, The Simpsons' else x)",
          "Dictionary that maps episode ids to episode codes\nepid_to_code = dict(zip(df_episodes.id, df_episodes.production_code))",
          "reate a new column for the episode_df mapping to imdb_id\ndf_episodes['imdb_id'] = df_episodes['id'].apply(lambda x: 'tt' + str(1000000+x))",
          "Create a new column in df_script for the episode number\nepisode_map = {row['id']: row['episode_id'] for index, row in df_script.iterrows()}\ndf_script['episode_number'] = df_script['id'].map(lambda x: episode_map[x])\n\n# Create a new column in df_script for the character\ncharacter_map = {row['id']: row['raw_character_text'] for index, row in df_script.iterrows()}\ndf_script['character'] = df_script['id'].map(lambda x: character_map[x])",
          " Add episode titles to script lines table\ndf_script['title'] = df_script.apply(lambda row: df_episodes[df_episodes['id'] == row['episode_id']]['title'].values[0], axis=1)"
         ],
         "marker": {
          "opacity": 0.5,
          "size": 5
         },
         "mode": "markers+text",
         "name": "150_Mapping episode information to script data",
         "text": [
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          ""
         ],
         "textfont": {
          "size": 12
         },
         "type": "scattergl",
         "x": [
          3.000730037689209,
          3.2226815223693848,
          4.601562976837158,
          3.1578433513641357,
          3.7804670333862305,
          3.28601336479187,
          3.1290132999420166,
          2.898942470550537,
          3.70625901222229,
          3.6411516666412354,
          2.3846232891082764,
          2.6624395847320557,
          3.6256508827209473,
          3.3549139499664307,
          2.067754030227661,
          3.682650089263916,
          3.162635326385498,
          3.7481772899627686,
          4.240124702453613,
          3.525926351547241,
          3.387267589569092,
          3.217374086380005
         ],
         "y": [
          5.747582912445068,
          5.95086145401001,
          4.782751560211182,
          6.168579578399658,
          6.783947944641113,
          6.006971836090088,
          5.356024742126465,
          5.886251926422119,
          5.608462333679199,
          6.607821941375732,
          5.839211463928223,
          5.321618556976318,
          5.869588851928711,
          5.571496963500977,
          6.135619163513184,
          4.995089054107666,
          5.913662433624268,
          6.306452751159668,
          5.3631205558776855,
          5.474001407623291,
          5.686814308166504,
          5.918015480041504
         ]
        },
        {
         "hoverinfo": "text",
         "hovertext": [
          "Display all columns for the script dataframe to have a better understanding of the dataframe",
          " Display the columns of the script data frame\ndf_script.columns",
          "Display the columns of the script dataframe\ndf_script.columns",
          "Display available scripts lines dataset columns\ndf_script.columns",
          "Uncomment this line to see the column names\n# df_script.columns",
          "Display available columns\ndf_script.columns",
          "# What are the names of the columns in the script Dataframe?\nprint(df_script.columns.tolist())",
          "Check the columns' names to see what to analyze\ndf_script.columns",
          "Create and display the dataframe with all the information from a full script.",
          "Get the text data from the script dataframe.",
          "Check all the columns in the script dataframe\nprint(df_script.columns)",
          "Display all the columns in the script dataframe",
          "Display available CSVs through their dataframes\ndf_script.columns",
          "# Let's see what data do we have\nprint('Columns:')\nfor column in df_script.columns:\n    print(f'\\t{column}')",
          "Set the script and entity to load into the DataFrame, and the column titles",
          " Display columns\ndf_script.columns",
          "Check the available data columns\nprint(df_script.columns)",
          "Columns of dataframe script\nprint(df_script.columns.tolist())",
          "ention about the script\nscript_columns = df_script.columns\nprint(df_script.columns)",
          "View which columns are present\ndf_script.columns",
          "View available columns\ndf_script.columns",
          "Keep original column names for later reference\noriginal_columns = df_script.columns"
         ],
         "marker": {
          "opacity": 0.5,
          "size": 5
         },
         "mode": "markers+text",
         "name": "151_Displaying available columns in a dataframe",
         "text": [
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          ""
         ],
         "textfont": {
          "size": 12
         },
         "type": "scattergl",
         "x": [
          8.609477043151855,
          7.82847785949707,
          8.152079582214355,
          7.114867210388184,
          7.79664945602417,
          7.94819450378418,
          7.550351142883301,
          7.64393949508667,
          7.794671058654785,
          7.536932468414307,
          7.873256206512451,
          8.357060432434082,
          7.55158805847168,
          7.41082239151001,
          8.938947677612305,
          7.878685474395752,
          7.959029197692871,
          7.657830238342285,
          7.659542560577393,
          7.67077112197876,
          7.785582542419434,
          8.183842658996582
         ],
         "y": [
          -2.7196638584136963,
          -2.626612663269043,
          -2.335017442703247,
          -3.045325517654419,
          -1.5477886199951172,
          -2.5213940143585205,
          -2.3679375648498535,
          -1.9046666622161865,
          -3.0230417251586914,
          -2.679586410522461,
          -2.4241433143615723,
          -2.2560184001922607,
          -2.8235182762145996,
          -2.2660200595855713,
          -2.1411683559417725,
          -2.026644229888916,
          -1.9444658756256104,
          -2.2267048358917236,
          -1.7815858125686646,
          -1.8791946172714233,
          -2.485806465148926,
          -0.6371946930885315
         ]
        },
        {
         "hoverinfo": "text",
         "hovertext": [
          " Display the dimension of the dataset\nprint(\"Characters dimension: \", df_characters.shape)\nprint(\"Locations dimension: \", df_locations.shape)\nprint(\"Episodes dimension: \", df_episodes.shape)\nprint(\"Script dimension: \", df_script.shape)",
          "Display the dimensions of the data with the .shape attribute",
          " Display dimension of datasets\nprint(f\"Characters: {df_characters.shape}\")\nprint(f\"Locations: {df_locations.shape}\")\nprint(f\"Script: {df_script.shape}\")\nprint(f\"Episodes: {df_episodes.shape}\")",
          "Looking at the dimensions of the tables\nprint('Dimensions of characters table:', df_characters.shape)\nprint('Dimensions of locations table:', df_locations.shape)\nprint('Dimensions of script table:', df_script.shape)\nprint('Dimensions of episodes table:', df_episodes.shape)",
          "View the dimensions of the dataframes\nprint(\"Characters dimensions: \", df_characters.shape)\nprint(\"Locations dimensions: \", df_locations.shape)\nprint(\"Script dimensions: \", df_script.shape)\nprint(\"Episodes dimensions: \", df_episodes.shape)",
          "characters and locations dimensions\nprint('Dimension of characters data:', df_characters.shape)\nprint('Dimension of locations data:', df_locations.shape)",
          " Display dimensions of datasets\nprint(\"Characters:\", df_characters.shape)\nprint(\"Locations:\", df_locations.shape)\nprint(\"Script:\", df_script.shape)\nprint(\"Episodes:\", df_episodes.shape)",
          " Data dimensions\nprint(f'Simpsons characters: {df_characters.shape}')\nprint(f'Simpsons locations: {df_locations.shape}')\nprint(f'Simpsons script lines: {df_script.shape}')\nprint(f'Simpsons episodes: {df_episodes.shape}')",
          "Dimensions\nprint(df_script.shape)\nprint(df_characters.shape)\nprint(df_locations.shape)\nprint(df_episodes.shape)",
          "Data Dimensions\nprint('Dimensions of the Data')\nprint('Characters:', df_characters.shape)\nprint('Locations:', df_locations.shape)\nprint('Script:', df_script.shape)\nprint('Episodes:', df_episodes.shape)",
          "Inspect Data\nprint(f'Dimensions of the Simpsons characters dataset: {df_characters.shape}')\nprint(f'Dimensions of the Simpsons locations dataset: {df_locations.shape}')\nprint(f'Dimensions of the Simpsons script dataset: {df_script.shape}')\nprint(f'Dimensions of the Simpsons episodes dataset: {df_episodes.shape}')",
          "Initial overview of the data\nprint(\"Characters dimension: {}\".format(df_characters.shape))\nprint(\"Locations dimension: {}\".format(df_locations.shape))\nprint(\"Script dimension: {}\".format(df_script.shape))\nprint(\"Episodes dimension: {}\".format(df_episodes.shape))",
          "Show dimensions of data tables\ndf_characters.shape, df_locations.shape, df_script.shape, df_episodes.shape",
          " Get first look of the simpsons script dataframe\nprint(\"DataFrame Dimension (Rows, Columns):\", df_script.shape)\nprint(\"\\nDataFrame Columns:\\n\", df_script.columns)\ndf_script.head()",
          "Print dimensions of DataFrames\nprint('Characters:\\t', df_characters.shape)\nprint('Locations:\\t', df_locations.shape)\nprint('Script:\\t\\t', df_script.shape)\nprint('Episodes:\\t', df_episodes.shape)",
          " display the dimensions of the dataframes\nprint(df_characters.shape, df_locations.shape, df_script.shape, df_episodes.shape)",
          "View dimensions of dataframes\nprint('Characters :', df_characters.shape)\nprint('Locations :', df_locations.shape)\nprint('Lines :', df_script.shape)\nprint('Episodes :', df_episodes.shape)",
          "View dimensions of the various data frames\nprint(df_characters.shape)\nprint(df_locations.shape)\nprint(df_script.shape)\nprint(df_episodes.shape)",
          "Display the dimensions of each dataframe\nprint(\"Characters:\", df_characters.shape)\nprint(\"Locations:\", df_locations.shape)\nprint(\"Script lines:\", df_script.shape)\nprint(\"Episodes:\", df_episodes.shape)",
          "Checking dataframes dimensions\nprint('Dimensions characters:', df_characters.shape)\nprint('Dimensions locations:', df_locations.shape)\nprint('Dimensions script:', df_script.shape)\nprint('Dimensions episodes:', df_episodes.shape)",
          "Display the dimensions of each table in the dataset\nprint(\"Dimensions of characters table: \", df_characters.shape)\nprint(\"Dimensions of locations table: \", df_locations.shape)\nprint(\"Dimensions of script table: \", df_script.shape)\nprint(\"Dimensions of episodes table: \", df_episodes.shape)",
          "Display main dataframes dimensions\nprint(\"Characters df dimensions : {}\".format(df_characters.shape))\nprint(\"Locations df dimensions : {}\".format(df_locations.shape))\nprint(\"Script df dimensions: {}\".format(df_script.shape))\nprint(\"Episodes df dimensions: {}\".format(df_episodes.shape))"
         ],
         "marker": {
          "opacity": 0.5,
          "size": 5
         },
         "mode": "markers+text",
         "name": "152_Dimensions of Dataset Tables",
         "text": [
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          ""
         ],
         "textfont": {
          "size": 12
         },
         "type": "scattergl",
         "x": [
          2.130742073059082,
          2.9499785900115967,
          2.326277494430542,
          1.0544260740280151,
          1.718104362487793,
          1.6657695770263672,
          2.089747905731201,
          1.7804584503173828,
          1.4260873794555664,
          1.185620665550232,
          1.8844600915908813,
          1.9413820505142212,
          1.9692909717559814,
          1.5376085042953491,
          1.448327660560608,
          2.304565191268921,
          1.974353551864624,
          2.2694082260131836,
          2.227093458175659,
          1.3062931299209595,
          1.768572211265564,
          2.162320852279663
         ],
         "y": [
          -1.6502132415771484,
          -1.9680125713348389,
          -1.9604625701904297,
          -0.5598593950271606,
          -1.5229072570800781,
          -1.1942050457000732,
          -1.8228940963745117,
          -1.7896270751953125,
          -1.468566656112671,
          -1.4522299766540527,
          -1.651814579963684,
          -1.8219215869903564,
          -1.2803572416305542,
          -1.0484164953231812,
          -1.6737695932388306,
          -1.7462807893753052,
          -1.8498778343200684,
          -1.8501681089401245,
          -1.4983400106430054,
          -1.6404798030853271,
          -1.2051646709442139,
          -1.7597576379776
         ]
        },
        {
         "hoverinfo": "text",
         "hovertext": [
          "Ensure matplotlib uses the 'seaborn-bright' style\nplt.style.use('seaborn-bright')",
          "Configuro los estilos de los gráficos\nmatplotlib.style.use('seaborn-bright')",
          "\n# Plots configuration\nplt.style.use('seaborn')",
          "Set seaborn style for matplotlib plots\nplt.style.use('seaborn')",
          "Set Seaborn aesthetics",
          " Set the style of the the plot\nmatplotlib.style.use('seaborn-whitegrid')",
          "sns.set(style=\"darkgrid\")",
          "Set the style of the visualization\nmatplotlib.style.use('seaborn-muted')",
          "# Set seaborn aesthetic parameters to defaults\nsns.set()",
          "sns.set()",
          "Setting the style\nplt.style.use('seaborn')",
          "# Value decomposition expansion over time by use of the scatterplot\nplt.scatter(lambda x: x, emmys, plt.style.use('seaborn-deep', lambda x: x))",
          "# Data visualization\nimport seaborn as sns",
          "Visualizing Data\n# Setting up themes\nplt.style.use('seaborn-whitegrid')",
          " optional: run seaborn theme set\nimport seaborn as sns\nsns.set()",
          " Set default style for plots\nplt.style.use('seaborn')",
          "# Setting the style of the visualizations\nplt.style.use('seaborn')",
          "Set seaborn style for our plots\nmatplotlib.style.use('seaborn')",
          "Set seaborn aesthetic parameters to defaults\nimport seaborn as sns\nsns.set()",
          "Use the default theme\nplt.style.use('seaborn')",
          "optional: using Seaborn for better plot styling\nimport seaborn as sns",
          "Set a custom color palette for Seaborn and matplotlib\nplt.rcParams['axes.prop_cycle'] = plt.cycler(color=plt.cm.tab10.colors)"
         ],
         "marker": {
          "opacity": 0.5,
          "size": 5
         },
         "mode": "markers+text",
         "name": "153_Seaborn Aesthetics and Plot Styles",
         "text": [
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          ""
         ],
         "textfont": {
          "size": 12
         },
         "type": "scattergl",
         "x": [
          21.098512649536133,
          20.97355079650879,
          20.61709213256836,
          20.550710678100586,
          20.145912170410156,
          20.6978759765625,
          19.76002311706543,
          20.709753036499023,
          19.756019592285156,
          19.542909622192383,
          20.146032333374023,
          8.049649238586426,
          20.368051528930664,
          20.60674476623535,
          19.772567749023438,
          20.189476013183594,
          20.62319564819336,
          20.718303680419922,
          19.965749740600586,
          20.140291213989258,
          20.290943145751953,
          21.078899383544922
         ],
         "y": [
          5.097160339355469,
          5.485813140869141,
          5.720045566558838,
          5.256948947906494,
          5.287786483764648,
          5.191267967224121,
          5.801849365234375,
          5.256758689880371,
          5.484505653381348,
          5.373658657073975,
          5.7121124267578125,
          10.054250717163086,
          5.424590110778809,
          5.261982440948486,
          5.3515496253967285,
          5.349886417388916,
          5.506638526916504,
          5.190442085266113,
          5.443023204803467,
          5.475142955780029,
          5.557628154754639,
          4.704298496246338
         ]
        },
        {
         "hoverinfo": "text",
         "hovertext": [
          "Show the first few lines of the table to get an idea of the data present.",
          "Print the number of lines in each of the tables",
          "Display the first few rows of each table to get an idea of the data",
          " CHeck first few rows of each table",
          "Inspecting first few records",
          "Display the first few lines of each table to get an idea of the data",
          "Checking the first 5 rows in the table",
          "Check the first 5 lines of the content for each table",
          "Check top 5 rows",
          "Print the schema and first few rows of each table",
          "Show the results of the first table.",
          "Check all the tables first 5 rows",
          "Check the first row",
          "Display a node like: 'Number of rows & columns in each table'",
          "Let's check the first rows of each table",
          " Show the first few rows of each table",
          " Print out the first couple of values from each table to get an understanding of the data.",
          "Check the first few rows of each table",
          "Checking the first 5 records",
          " Display the first few lines of each table to get a sense of the data",
          "Checking the first few rows",
          "Checking the first few rows."
         ],
         "marker": {
          "opacity": 0.5,
          "size": 5
         },
         "mode": "markers+text",
         "name": "154_Checking the first few rows of each table",
         "text": [
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          ""
         ],
         "textfont": {
          "size": 12
         },
         "type": "scattergl",
         "x": [
          12.833351135253906,
          12.771578788757324,
          13.04359245300293,
          12.850296974182129,
          13.143531799316406,
          12.7712984085083,
          13.1466703414917,
          12.863715171813965,
          13.108017921447754,
          12.776474952697754,
          12.620698928833008,
          13.144089698791504,
          13.170801162719727,
          12.764579772949219,
          13.14868450164795,
          12.814899444580078,
          12.891847610473633,
          12.799145698547363,
          13.341773986816406,
          12.910406112670898,
          12.846433639526367,
          13.005119323730469
         ],
         "y": [
          -1.7284224033355713,
          -2.0996484756469727,
          -2.527104139328003,
          -3.372250556945801,
          -3.816416025161743,
          -2.1250815391540527,
          -3.973173141479492,
          -3.272430896759033,
          -4.333677768707275,
          -2.169750690460205,
          -2.3884570598602295,
          -3.792113780975342,
          -3.5182342529296875,
          -2.2937207221984863,
          -3.207848072052002,
          -2.6543445587158203,
          -2.1147823333740234,
          -3.386105537414551,
          -4.3761162757873535,
          -2.3021609783172607,
          -3.863835334777832,
          -2.9484870433807373
         ]
        },
        {
         "hoverinfo": "text",
         "hovertext": [
          "Check out the contents of these DataFrames\nprint('Characters:')\ndisplay(df_characters.head())\nprint('Locations:')\ndisplay(df_locations.head())\nprint('Script:')\ndisplay(df_script.head())\nprint('Episodes:')\ndisplay(df_episodes.head())",
          "Show some basic information about the datasets\nprint('Characters')\ndisplay(df_characters.head())\nprint('Locations')\ndisplay(df_locations.head())\nprint('Script')\ndisplay(df_script.head())\nprint('Episodes')\ndisplay(df_episodes.head())",
          " Display snippets of each dataframe\nprint(\"\\nSimpsons characters dataframe\")\ndisplay(df_characters.head())\nprint(\"\\nSimpsons locations dataframe\")\ndisplay(df_locations.head())\nprint(\"\\nSimpsons script dataframe\")\ndisplay(df_script.head())\nprint(\"\\nSimpsons episodes dataframe\")\ndisplay(df_episodes.head())",
          "Display available data\nprint(\"Characters\")\ndisplay(df_characters.head(5))\nprint(\"Locations\")\ndisplay(df_locations.head(5))\nprint(\"Script\")\ndisplay(df_script.head(5))\nprint(\"Episodes\")\ndisplay(df_episodes.head(5))",
          "Display basic information about the datasets\nprint('Characters')\ndisplay(df_characters.head())\nprint('Locations')\ndisplay(df_locations.head())\nprint('Script')\ndisplay(df_script.head())\nprint('Episodes')\ndisplay(df_episodes.head())",
          "Check the datasets\nprint(\"Characters:\")\ndisplay(df_characters.head())\n\nprint(\"Locations:\")\ndisplay(df_locations.head())\n\nprint(\"Script:\")\ndisplay(df_script.head())\n\nprint(\"Episodes:\")\ndisplay(df_episodes.head())",
          " Visualize available datasets\nprint(\"Characters:\")\ndisplay(df_characters.head(3))\nprint(\"Locations:\")\ndisplay(df_locations.head(3))\nprint(\"Script:\")\ndisplay(df_script.head(3))\nprint(\"Episodes:\")\ndisplay(df_episodes.head(3))",
          "Show a small preview of the dataframes\nprint('--- Characters ---')\ndisplay(df_characters.head())\nprint('\\n\\n--- Locations ---')\ndisplay(df_locations.head())\nprint('\\n\\n--- Script ---')\ndisplay(df_script.head())\nprint('\\n\\n--- Episodes ---')\ndisplay(df_episodes.head())",
          "Quick overview of the data\nprint(\"Characters:\")\ndisplay(df_characters.head())\n\nprint(\"Locations:\")\ndisplay(df_locations.head())\n\nprint(\"Script:\")\ndisplay(df_script.head())\n\nprint(\"Episodes:\")\ndisplay(df_episodes.head())",
          "Preview the datasets\nprint(\"\\nPreview of 'simpsons_characters.csv'\")\nprint(df_characters.head())\nprint(\"\\nPreview of 'simpsons_locations.csv'\")\nprint(df_locations.head())\nprint(\"\\nPreview of 'simpsons_script_lines.csv'\")\nprint(df_script.head())\nprint(\"\\nPreview of 'simpsons_episodes.csv'\")\nprint(df_episodes.head())",
          " Display some general information about the dataframes\nprint(\"Characters\")\ndisplay(df_characters.head())\nprint(\"Locations\")\ndisplay(df_locations.head())\nprint(\"Script\")\ndisplay(df_script.head())\nprint(\"Episodes\")\ndisplay(df_episodes.head())",
          " Display available datasets\nprint('Characters:')\ndisplay(df_characters.head())\nprint('\\nLocations:')\ndisplay(df_locations.head())\nprint('\\nScript:')\ndisplay(df_script.head())\nprint('\\nEpisodes:')\ndisplay(df_episodes.head())",
          " Display available data files\nprint(f'Characters:')\ndisplay(df_characters.head(2))\nprint(f'Locations:')\ndisplay(df_locations.head(2))\nprint(f'Script:')\ndisplay(df_script.head(2))\nprint(f'Episodes:')\ndisplay(df_episodes.head(2))",
          "Check data samples\nprint(\"Characters:\")\ndisplay(df_characters.sample(5))\n\nprint(\"Locations:\")\ndisplay(df_locations.sample(5))\n\nprint(\"Script lines:\")\ndisplay(df_script.sample(5))\n\nprint(\"Episodes:\")\ndisplay(df_episodes.sample(5))",
          "Get an overview of the dataset\nprint('>>> DataFrame Characters')\ndisplay(df_characters.head())\nprint('\\n')\nprint('>>> DataFrame Locations')\ndisplay(df_locations.head())\nprint('\\n')\nprint('>>> DataFrame Script')\ndisplay(df_script.head())\nprint('\\n')\nprint('>>> DataFrame Episodes')\ndisplay(df_episodes.head())",
          " Take a look at the first few records of each dataset\nprint(\"Characters\")\ndisplay(df_characters.head())\n\nprint(\"Locations\")\ndisplay(df_locations.head())\n\nprint(\"Script\")\ndisplay(df_script.head())\n\nprint(\"Episodes\")\ndisplay(df_episodes.head())",
          "Inspect the content of each of these dataframes\nprint(\"Characters\")\ndisplay(df_characters.head())\n\nprint(\"Locations\")\ndisplay(df_locations.head())\n\nprint(\"Script\")\ndisplay(df_script.head())\n\nprint(\"Episodes\")\ndisplay(df_episodes.head())",
          "Explore the dataset\n# Display all the dataframes in a user friendly manner\nprint(\"Characters\")\ndisplay(df_characters.head(5))\nprint(\"Locations\")\ndisplay(df_locations.head(5))\nprint(\"Script\")\ndisplay(df_script.head(5))\nprint(\"Episodes\")\ndisplay(df_episodes.head(5))",
          " Display available dataframes in the dataset\nprint('Characters:')\ndisplay(df_characters.head(2))\nprint('Locations:')\ndisplay(df_locations.head(2))\nprint('Scripts:')\ndisplay(df_script.head(2))\nprint('Episodes:')\ndisplay(df_episodes.head(2))",
          "Print the characters, locations, and script DataFrames\nprint('Characters DataFrame')\ndisplay(df_characters.head())\n\nprint('Locations DataFrame')\ndisplay(df_locations.head())\n\nprint('Script DataFrame')\ndisplay(df_script.head())\n\nprint('Episodes DataFrame')\ndisplay(df_episodes.head())",
          " Display our imported data\nprint('Characters')\ndisplay(df_characters.head(3))\nprint('Locations')\ndisplay(df_locations.head(3))\nprint('Episodes')\ndisplay(df_episodes.head(3))\nprint('Script')\ndisplay(df_script.head(3))",
          "Inspect the structure and contents of the dataframes\nprint('Characters:')\ndisplay(df_characters.head())\n\nprint('Locations:')\ndisplay(df_locations.head())\n\nprint('Script:')\ndisplay(df_script.head())\n\nprint('Episodes:')\ndisplay(df_episodes.head())"
         ],
         "marker": {
          "opacity": 0.5,
          "size": 5
         },
         "mode": "markers+text",
         "name": "155_Exploring and Visualizing Datasets related to Characters, Locations, Script, and Episodes",
         "text": [
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          ""
         ],
         "textfont": {
          "size": 12
         },
         "type": "scattergl",
         "x": [
          -1.4363622665405273,
          -0.7993249297142029,
          -1.6003996133804321,
          -1.4285719394683838,
          -0.6470935940742493,
          -1.3944565057754517,
          -0.9689885377883911,
          -1.0439815521240234,
          -1.2396427392959595,
          -1.0673824548721313,
          -1.1690675020217896,
          -0.9193677306175232,
          -0.7682196497917175,
          -1.3290244340896606,
          -0.7809360027313232,
          -1.1980751752853394,
          -1.6511858701705933,
          -1.4393333196640015,
          -1.549432396888733,
          -0.8878928422927856,
          -1.588923692703247,
          -1.8199639320373535
         ],
         "y": [
          3.1340973377227783,
          2.822704553604126,
          3.5931477546691895,
          3.0359413623809814,
          2.7128708362579346,
          2.5181078910827637,
          3.2820255756378174,
          3.511915445327759,
          2.6999306678771973,
          2.582904100418091,
          3.123263120651245,
          3.1874494552612305,
          2.7216055393218994,
          2.854828119277954,
          3.2936906814575195,
          3.1234395503997803,
          2.936577558517456,
          3.3211357593536377,
          3.075303554534912,
          3.27947735786438,
          2.719923496246338,
          3.1809146404266357
         ]
        },
        {
         "hoverinfo": "text",
         "hovertext": [
          " View the first few rows of the characters dataframe\ndf_characters.head()",
          " Viewing the first few rows of the characters dataframe\ndf_characters.head()",
          "View the first few rows of the characters dataframe\ndf_characters.head()",
          "View the first few rows of the characters DataFrame\ndf_characters.head()",
          " View the first few rows of the characters dataframe\ndf_characters.head()",
          "View first few rows of characters dataframe\ndf_characters.head()",
          "# View the first few rows of the characters dataframe\ndf_characters.head()",
          "View the first few rows of the characters dataframe\ndf_characters.head()",
          "View the first few rows of the characters dataframe\ndf_characters.head()",
          " View the first few rows of the characters dataframe\ndf_characters.head()",
          "View the first few rows of the characters dataframe\ndf_characters.head()",
          " View the first few rows of the characters DataFrame\ndf_characters.head()",
          "View the first few rows of the characters DataFrame\ndf_characters.head()",
          "View the first few rows of the characters dataframe\ndf_characters.head()",
          " View the first few rows of the characters DataFrame\ndf_characters.head()",
          "View the first few rows of the characters DataFrame\ndf_characters.head()",
          "View the first few columns of the characters DataFrame\ndf_characters.head()",
          "View the first few rows of the characters dataframe\ndf_characters.head()",
          "View columns and first few rows of characters dataframe\ndf_characters.head()",
          "View the first few rows of the characters DataFrame\ndf_characters.head()",
          "View the first few rows of the characters dataframe\ndf_characters.head()"
         ],
         "marker": {
          "opacity": 0.5,
          "size": 5
         },
         "mode": "markers+text",
         "name": "156_View first few rows of characters dataframe",
         "text": [
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          ""
         ],
         "textfont": {
          "size": 12
         },
         "type": "scattergl",
         "x": [
          -0.4991813600063324,
          -0.5275329947471619,
          -0.6391401290893555,
          -1.0810071229934692,
          -0.6494967341423035,
          -0.631754994392395,
          -0.9395402669906616,
          -0.7640265226364136,
          -0.6288470029830933,
          -0.9955008029937744,
          -0.6171648502349854,
          -0.7124055624008179,
          -0.6843714714050293,
          -0.9858194589614868,
          -0.8395410180091858,
          -0.8279484510421753,
          0.12575778365135193,
          -0.5996870994567871,
          -0.8316001296043396,
          -0.9372739791870117,
          -0.9929168820381165
         ],
         "y": [
          19.633638381958008,
          19.464923858642578,
          19.907438278198242,
          19.693096160888672,
          19.755434036254883,
          19.823930740356445,
          19.908435821533203,
          19.43121337890625,
          19.84752082824707,
          19.90033721923828,
          19.596769332885742,
          19.498985290527344,
          19.78263282775879,
          19.93568229675293,
          19.833120346069336,
          19.615108489990234,
          19.257640838623047,
          19.68009376525879,
          19.557491302490234,
          19.646366119384766,
          19.885087966918945
         ]
        },
        {
         "hoverinfo": "text",
         "hovertext": [
          "Display the first few rows of the dataset\ndf_characters.head()",
          " Display the first few rows of the characters dataset\ndf_characters.head()",
          "## Displaying the first rows of the characters dataset\ndf_characters.head()",
          "Display the first few rows of the character dataset\ndf_characters.head()",
          " Show the first few characters of the main datasets\ndf_script.head()",
          "Show the first few rows of the characters data\ndf_characters.head()",
          "Display the first few rows of the characters dataset\ndf_characters.head()",
          "Print the first few records of the characters dataset\ndf_characters.head()",
          " Show first rows of the characters dataset\ndf_characters.head()",
          " Display the first few records of the characters dataset\ndf_characters.head()",
          " Display the first few rows of the characters dataset\ndf_characters.head()",
          "Optional: Display first few rows of the datasets\ndf_characters.head()",
          "View first few rows of the characters dataset\ndf_characters.head()",
          "Display the first few rows of the characters dataset\ndf_characters.head()",
          "Show the first few rows of the characters dataset\ndf_characters.head()",
          "Display the first few records of the characters dataset\ndf_characters.head()",
          "Display the first few rows of the character dataset\ndf_characters.head()",
          "Show the first rows of the characters dataset\ndf_characters.head()",
          "Display the first few rows of the characters dataset\ndf_characters.head()",
          " Show the first rows of the characters dataset\ndf_characters.head()",
          " Display the first few records of the characters dataset\ndf_characters.head()"
         ],
         "marker": {
          "opacity": 0.5,
          "size": 5
         },
         "mode": "markers+text",
         "name": "157_Displaying first few records of a dataset",
         "text": [
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          ""
         ],
         "textfont": {
          "size": 12
         },
         "type": "scattergl",
         "x": [
          1.9189027547836304,
          1.637923240661621,
          2.000821590423584,
          1.5108295679092407,
          2.0690598487854004,
          1.2983115911483765,
          1.6184223890304565,
          0.44918185472488403,
          1.784721851348877,
          0.7296227812767029,
          1.3986722230911255,
          2.687182903289795,
          1.4802383184432983,
          1.677210807800293,
          1.7907555103302002,
          0.780956506729126,
          1.5010627508163452,
          2.116666078567505,
          1.7284932136535645,
          2.1413214206695557,
          0.8055081367492676
         ],
         "y": [
          16.366031646728516,
          16.286367416381836,
          16.58822250366211,
          16.34865951538086,
          16.032922744750977,
          17.05014991760254,
          16.342124938964844,
          16.711423873901367,
          15.902573585510254,
          16.39717674255371,
          16.21540069580078,
          16.05712127685547,
          17.05554962158203,
          16.363258361816406,
          16.223066329956055,
          16.214252471923828,
          16.41427230834961,
          16.029296875,
          16.279476165771484,
          16.076993942260742,
          16.34720802307129
         ]
        },
        {
         "hoverinfo": "text",
         "hovertext": [
          "ill the missing values in the DataFrame",
          "Statistics and missing values count for all DataFrames",
          "Inspect data types and missing values",
          "Visualize missing data",
          "Inspect the structure of the data and look for inconsistencies and missing values.",
          "Check missing values in the dataframes",
          " Check for missing values",
          "Inspect the dataframes, check for missing values, etc.",
          "Check duplicates and missing data in each dataframe",
          "Visualize missing values",
          "Checking for missing values in our data.",
          " Check for and handle missing values",
          " Visualize missing values as a matrix",
          "Visualize the missing values in the dataframes\nimport missingno as msno",
          "Visualizing the missing values in the dataframe",
          "Inspect data types and missing values in the scripts dataset",
          "Visualize the missing data\nimport missingno as msno",
          " Checking for script dataset duplicate and missing values",
          "Visualizing missing values in the data",
          "Check for missing values",
          "Check for missing values in the dataset"
         ],
         "marker": {
          "opacity": 0.5,
          "size": 5
         },
         "mode": "markers+text",
         "name": "158_Checking for Missing Values in Data",
         "text": [
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          ""
         ],
         "textfont": {
          "size": 12
         },
         "type": "scattergl",
         "x": [
          7.72733736038208,
          6.944982051849365,
          9.537525177001953,
          11.616392135620117,
          9.604952812194824,
          7.619349002838135,
          8.704948425292969,
          8.491642951965332,
          8.260185241699219,
          10.667884826660156,
          9.204778671264648,
          8.775834083557129,
          11.068090438842773,
          7.504082202911377,
          7.794968128204346,
          8.361350059509277,
          10.945893287658691,
          7.8286662101745605,
          11.571369171142578,
          8.511195182800293,
          8.232645034790039
         ],
         "y": [
          0.18052728474140167,
          0.20656242966651917,
          0.30188798904418945,
          -0.1882636398077011,
          -0.014185081236064434,
          0.061323828995227814,
          0.18861790001392365,
          -0.9920535087585449,
          -0.4710424244403839,
          0.07710236310958862,
          0.5210962295532227,
          0.5328441858291626,
          -0.042831942439079285,
          -0.010235832072794437,
          -0.1285119205713272,
          -0.13952641189098358,
          0.052655138075351715,
          0.5761470198631287,
          -0.021124333143234253,
          0.5638304948806763,
          0.6021936535835266
         ]
        },
        {
         "hoverinfo": "text",
         "hovertext": [
          "Quick look at the data",
          " Quick overview of the data",
          "Information about the data.",
          " Look at the data",
          "Quick Look at the Data",
          "Quick exploration of the data",
          "Quick peek at the data",
          "Looking at the data",
          "The data came from Kaggle and is, to the best of my knowledge, a cleaned version of the original one.",
          "\"\"\"Look at the data.\"\"\"",
          "Data overview",
          " Let's get an overview of the data",
          " Quick look at the data",
          "Data overview",
          "Looking at the data",
          "Look at the data",
          "Some Quick Overviews",
          " Spotless data ;)",
          "Quick overlook of the data",
          "This data was made available by Alexandru Papiu and we can find this data in kaggle community.",
          "Quick spot check into data."
         ],
         "marker": {
          "opacity": 0.5,
          "size": 5
         },
         "mode": "markers+text",
         "name": "159_Quick overview of cleaned Kaggle data by Alexandru Papiu",
         "text": [
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          ""
         ],
         "textfont": {
          "size": 12
         },
         "type": "scattergl",
         "x": [
          16.266599655151367,
          16.658645629882812,
          16.00696563720703,
          15.880793571472168,
          16.534488677978516,
          16.228439331054688,
          16.41375732421875,
          15.746810913085938,
          15.32181453704834,
          15.719721794128418,
          16.132848739624023,
          16.1610164642334,
          16.471643447875977,
          16.084243774414062,
          15.702157020568848,
          15.881316184997559,
          16.58664894104004,
          15.805012702941895,
          16.0960693359375,
          17.122783660888672,
          15.853364944458008
         ],
         "y": [
          -1.368470311164856,
          -1.2630579471588135,
          -0.8774941563606262,
          -0.7252278327941895,
          -1.044816017150879,
          -0.7925166487693787,
          -0.9752205610275269,
          -0.40884512662887573,
          0.19141729176044464,
          -0.3921144902706146,
          -0.46419841051101685,
          -0.863466203212738,
          -1.3424980640411377,
          -0.08728592097759247,
          -0.5720992088317871,
          -0.6458735466003418,
          -1.7985085248947144,
          -0.4178667366504669,
          -1.0428056716918945,
          -1.7426859140396118,
          -0.8635014295578003
         ]
        },
        {
         "hoverinfo": "text",
         "hovertext": [
          "limiting number of rows is generally a good practice in data exploration\npd.options.display.max_rows = 10",
          "Set this option to see all rows\npd.set_option('display.max_rows', 500)",
          "Set maximum row and column display\npd.set_option('display.max_rows', 1000)\npd.set_option('display.max_columns', 1000)",
          "Set maximum display columns for easier visualization\npd.set_option('display.max_columns', 500)",
          "optional\npd.set_option('display.max_rows', 300)",
          "Limit the maximal number of columns displayed to 50\npd.set_option('display.max_columns', 50)",
          "Set params\npd.set_option('display.max_columns', 500)\npd.set_option('display.max_rows', 500)\ntqdm.pandas()",
          "Set the max displayed columns to 100 and the rows to 50",
          "limit the number of lines being displayed\npd.options.display.max_rows = 10",
          "Display settings for the number of columns and rows\npd.set_option('display.max_columns', 500)\npd.set_option('display.max_rows', 500)",
          "Set the max row display\npd.set_option('display.max_row', 1000)",
          "Set number of rows to be displayed in the output\npd.set_option('display.max_rows', 1000)",
          "# Display up to 50 characters\npd.set_option('display.max_rows', 50)",
          "limits the number of different items in a list",
          "Enable large screen support\npd.set_option('display.max_rows', 500)",
          "SOME_DISPLAY = 5",
          " Display max 500 columns/rows\npd.set_option('display.max_columns', 500)\npd.set_option('display.max_rows', 500)",
          " Display new max rows\npd.set_option('display.max_rows', 500)",
          "Set pd to print 100 columns max\npd.set_option('display.max_columns', 100)",
          "Limit number of rows to display to make the data more manageable\npd.options.display.max_rows = 10",
          "Set max display columns\npd.set_option('display.max_columns', 500)"
         ],
         "marker": {
          "opacity": 0.5,
          "size": 5
         },
         "mode": "markers+text",
         "name": "160_Set max display limits for rows and columns",
         "text": [
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          ""
         ],
         "textfont": {
          "size": 12
         },
         "type": "scattergl",
         "x": [
          23.566184997558594,
          23.886690139770508,
          24.01424789428711,
          23.913833618164062,
          23.909000396728516,
          23.631269454956055,
          23.227989196777344,
          23.51032257080078,
          22.865127563476562,
          24.123626708984375,
          23.695207595825195,
          23.68672752380371,
          24.076812744140625,
          22.09851837158203,
          24.020233154296875,
          23.43776512145996,
          23.67490577697754,
          23.794944763183594,
          23.934791564941406,
          23.25365447998047,
          24.054216384887695
         ],
         "y": [
          0.15308059751987457,
          -0.0016481727361679077,
          0.45817914605140686,
          0.04922202602028847,
          0.3375745713710785,
          -0.013664478436112404,
          0.5111352205276489,
          0.12439267337322235,
          -0.0754522904753685,
          0.6741486191749573,
          0.16918377578258514,
          0.029400547966361046,
          0.7786768674850464,
          -0.3222790062427521,
          0.683201014995575,
          0.19840842485427856,
          0.3427870273590088,
          0.25093764066696167,
          -0.12228527665138245,
          0.09342534095048904,
          -0.29553547501564026
         ]
        },
        {
         "hoverinfo": "text",
         "hovertext": [
          "Show the first few rows of each DataFrame to understand its structure and information.",
          "Display the first few rows of the dataframe to understand the structure of the data.",
          "Optional: Display the first few rows of each dataframe to understand the data structure.",
          "Display the first few rows of each dataframe to understand its structure and the type of data it contains.",
          "Display the first few rows of each dataframe to understand its structure and the kind of data we're working with.",
          "Displays the first few rows of the dataframe to understand the structure of the dataframe.",
          " Display the first few rows of each dataframe to understand its structure and the available columns.",
          "Display the first few rows of each dataframe to understand its structure and what kind of data it contains",
          " Display the first few rows of each dataframe to understand its structure and data",
          " Display the first dataframe to understand the structure of the data.",
          "Display the top 10 rows of each dataframe to understand their structure and data",
          "Optional: Display the first few rows of each dataframe to understand their structure and contents.",
          "Display first few rows of each dataframe to understand structure and contents",
          "Display the first few rows of each dataframe to understand its structure.",
          " Display the first few rows of each dataframe to understand their structure and contents.",
          " Display the first few rows of each dataframe to understand their structure and contents.",
          "Displays the first few rows of the dataframe to inspect its structure and content.",
          "Display the top rows of each dataframe to understand the structure of the data.",
          "Display the first few rows of each dataframe to understand their structure and contents.",
          "Display the first few rows of each dataframe to understand its structure and contents.",
          " Show top few rows of each dataframe to understand the structure of the data."
         ],
         "marker": {
          "opacity": 0.5,
          "size": 5
         },
         "mode": "markers+text",
         "name": "161_Understanding DataFrame Structure and Contents",
         "text": [
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          ""
         ],
         "textfont": {
          "size": 12
         },
         "type": "scattergl",
         "x": [
          11.500126838684082,
          11.111540794372559,
          11.16531753540039,
          11.066915512084961,
          11.114181518554688,
          11.029837608337402,
          11.491634368896484,
          11.38267707824707,
          11.65401840209961,
          11.192800521850586,
          12.134291648864746,
          11.24881649017334,
          11.265656471252441,
          11.548627853393555,
          11.053634643554688,
          11.286284446716309,
          11.271014213562012,
          12.005553245544434,
          11.173286437988281,
          11.115736961364746,
          11.91620922088623
         ],
         "y": [
          -8.779826164245605,
          -8.83800220489502,
          -9.152668952941895,
          -8.76955795288086,
          -8.629667282104492,
          -9.270248413085938,
          -9.48823356628418,
          -8.515066146850586,
          -8.74223518371582,
          -8.077221870422363,
          -7.58551549911499,
          -9.348607063293457,
          -9.459637641906738,
          -8.793540000915527,
          -9.267308235168457,
          -9.342491149902344,
          -9.406109809875488,
          -6.835646152496338,
          -9.168482780456543,
          -9.238252639770508,
          -7.439104080200195
         ]
        },
        {
         "hoverinfo": "text",
         "hovertext": [
          " Reverse episodes index so it matches the script pd (by date)",
          " Set index Episode and Processed text for df_script",
          "Setting the episode_id as index for querying",
          "Set the index of the episodes dataframe to use the episode_id as index",
          "Set the index of your dataframe to be the column episode_id if it's not already the case.",
          "Create an index for each episode\ndf_episodes.set_index('id', inplace=True)",
          "Set a proper index for the episode DataFrame, as the plot will rely on it",
          "Set the episode ID as the index to make lookups easier\ndf_script.set_index('episode_id', inplace=True)",
          "Fixing the index of episodes due to the duplicate indexes",
          "Set up the episods' index as integer",
          " Set index of episodes to 'id' for faster searching.",
          "Add an index to episodes dataframe",
          "Fix the index of the episodes' dataframe after concatenating the test and training data.",
          "Set index for faster filtering\ndf_episodes.set_index('id', inplace=True)\ndf_script.set_index('episode_id', inplace=True)",
          "Reset the index for episodes to ensure all indexes are unique\ndf_episodes.reset_index(inplace=True)",
          "define UTC dates and reset index for simpsons_episodes if not done previously",
          " Set index of episodes to be the same as in the other two files",
          "Inspected the first values of each dataframe in search for the 'elusive' episode_id.",
          "Setting index on the episodes dataframe",
          "Using the index as the ID for each entity, i.e., character, location, and episode.",
          " set index to episode_id for easier access\ndf_episodes = df_episodes.set_index('id')"
         ],
         "marker": {
          "opacity": 0.5,
          "size": 5
         },
         "mode": "markers+text",
         "name": "162_Indexing and Resetting in DataFrame",
         "text": [
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          ""
         ],
         "textfont": {
          "size": 12
         },
         "type": "scattergl",
         "x": [
          4.525151252746582,
          3.871873140335083,
          5.0972819328308105,
          4.304747104644775,
          3.908655881881714,
          3.5137743949890137,
          3.912165641784668,
          3.7137291431427,
          4.378773212432861,
          4.639345169067383,
          4.533145904541016,
          3.884643077850342,
          4.359279155731201,
          3.2602455615997314,
          3.8383536338806152,
          5.0141191482543945,
          4.838074684143066,
          3.9366261959075928,
          4.056404113769531,
          5.7807135581970215,
          3.5284993648529053
         ],
         "y": [
          3.4539175033569336,
          3.918675184249878,
          2.976116895675659,
          3.271402359008789,
          3.6480021476745605,
          3.802278518676758,
          3.401843309402466,
          4.158703327178955,
          3.179048538208008,
          2.572040557861328,
          3.0808732509613037,
          3.463951349258423,
          3.2109251022338867,
          3.7341227531433105,
          3.6798880100250244,
          3.2514758110046387,
          3.3166146278381348,
          3.7830843925476074,
          3.1354317665100098,
          2.5081048011779785,
          3.777298927307129
         ]
        },
        {
         "hoverinfo": "text",
         "hovertext": [
          "Filter the script to only keep the lines with characters and locations available in their respective datasets",
          "Limiting the script dataset to only the scenes taking place in a location.",
          "Clean the script (remove noisy data and keep only dialogues)",
          "Select only the parts of the script with at least two words.",
          " Limit the script data to only containing the main characters",
          " Filter out the script lines that are between the major characters, and keep only the ones that are in between locations.",
          "Removing script lines which are not associated with any speaking character.",
          "filter out script entries that dont have an associated location or character",
          "Filter out the script lines in locations.",
          "Remove 'blacklisted' or special characters from the script lines",
          "Filter the lines with locations",
          " Select the unique lines with dialogues from all scripts and drop missing values",
          "Filtering the scripts with null information and multiple characters",
          "For a selected subset of characters, extract a subset of the scripts only containing dialogs of these characters",
          "Only include the parts of the script that have been spoken by a character.",
          "Selecting scripts from the most frequently occurring characters and locations",
          "Remove script lines that have not spoken by characters and locations that are not known.",
          "Filter empty script lines",
          "Optional: Remove all production- and location-related script lines (scenes, songs, technical annotations, ...).",
          "Filter out the script with no character_id.",
          "Filter the locations to keep only the ones present in the script lines dataset."
         ],
         "marker": {
          "opacity": 0.5,
          "size": 5
         },
         "mode": "markers+text",
         "name": "163_Script Filtering and Extraction",
         "text": [
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          ""
         ],
         "textfont": {
          "size": 12
         },
         "type": "scattergl",
         "x": [
          9.025103569030762,
          9.39809513092041,
          9.976207733154297,
          9.493170738220215,
          9.48157024383545,
          9.31624698638916,
          9.552197456359863,
          9.158123970031738,
          9.493682861328125,
          9.960846900939941,
          9.734395980834961,
          9.288612365722656,
          9.456613540649414,
          9.165423393249512,
          8.985746383666992,
          9.597994804382324,
          9.635445594787598,
          9.662671089172363,
          10.055353164672852,
          8.95869255065918,
          9.32651138305664
         ],
         "y": [
          3.863973617553711,
          3.408518075942993,
          4.026115417480469,
          4.869715690612793,
          4.441686630249023,
          3.970362424850464,
          4.788110256195068,
          4.231793403625488,
          3.906494617462158,
          4.4571428298950195,
          3.959343671798706,
          3.9692490100860596,
          4.2364935874938965,
          4.4820170402526855,
          4.811144828796387,
          4.59600830078125,
          4.611828327178955,
          4.183321952819824,
          4.1249871253967285,
          4.9405341148376465,
          3.4978978633880615
         ]
        },
        {
         "hoverinfo": "text",
         "hovertext": [
          "pd.set_option('display.max_columns', None)",
          "Don't worry about the lines below, as they're only effecting how the backend works and nothing for you to worry about.\npd.options.display.max_columns = None  # Make sure we can see all of the columns",
          "pd.set_option('display.max_columns', None)",
          "pd.set_option('max_columns', None)",
          "pd.set_option(\"display.max_columns\", None)",
          " extended information to usersupport uniterrupted work.\npd.set_option('display.max_columns', None)",
          "pd.set_option('display.max_columns', None)",
          "Display max columns at pd\npd.set_option('display.max_columns', None)",
          "\npd.set_option('display.max_columns', None)",
          "pd.set_option('display.max_columns', None)",
          "pd.set_option('display.max_columns', None)",
          "pd.set_option('display.max_columns', None)",
          "pd.set_option('display.max_columns', None)",
          "pd.set_option('display.max_columns', None)",
          "pd.set_option('display.max_columns', None)",
          "Display options\npd.set_option('display.max_columns', None)",
          "Set\npd.set_option('display.max_columns', None)",
          "pd.set_option('display.max_columns', None)",
          "pd.set_option('display.max_columns', None)",
          "pd.set_option('display.max_columns', None)",
          "pd.set_option('display.max_columns', None)"
         ],
         "marker": {
          "opacity": 0.5,
          "size": 5
         },
         "mode": "markers+text",
         "name": "164_Display options and extended information in pandas set_option() function",
         "text": [
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          ""
         ],
         "textfont": {
          "size": 12
         },
         "type": "scattergl",
         "x": [
          25.05600929260254,
          25.288021087646484,
          25.090452194213867,
          25.36391258239746,
          24.934993743896484,
          24.692100524902344,
          25.05375099182129,
          24.772174835205078,
          25.330408096313477,
          25.252878189086914,
          25.165327072143555,
          25.10237693786621,
          25.041034698486328,
          25.031702041625977,
          24.98268699645996,
          24.81760597229004,
          24.925819396972656,
          24.872440338134766,
          25.095108032226562,
          24.986597061157227,
          24.821269989013672
         ],
         "y": [
          -2.011855125427246,
          -1.6954916715621948,
          -2.1901943683624268,
          -2.424919366836548,
          -2.2704615592956543,
          -1.356410264968872,
          -2.2132339477539062,
          -1.5691163539886475,
          -2.2435290813446045,
          -2.140321731567383,
          -2.1399295330047607,
          -1.9109537601470947,
          -1.993043303489685,
          -2.0301761627197266,
          -2.144124746322632,
          -1.6210771799087524,
          -1.6512832641601562,
          -1.9041460752487183,
          -2.1162917613983154,
          -1.8868240118026733,
          -2.0806772708892822
         ]
        },
        {
         "hoverinfo": "text",
         "hovertext": [
          " Display the first few rows of each dataframe to understand the data\nprint(df_characters.head())\nprint(df_locations.head())\nprint(df_script.head())\nprint(df_episodes.head())",
          " Display the first few characters of the dataframes\ndisplay(df_characters.head())\ndisplay(df_locations.head())\ndisplay(df_script.head())\ndisplay(df_episodes.head())",
          "Sanity check: show the first rows of each dataframe\ndisplay(df_characters.head())\ndisplay(df_locations.head())\ndisplay(df_script.head())\ndisplay(df_episodes.head())",
          "Setting the print to display the first 3 rows by default\nprint(df_characters.head(3))\nprint(df_locations.head(3))\nprint(df_script.head(3))\nprint(df_episodes.head(3))",
          " Display the first few rows of each dataframe to understand their structure and contents\ndisplay(df_characters.head())\ndisplay(df_locations.head())\ndisplay(df_script.head())\ndisplay(df_episodes.head())",
          "Display the first few rows of each dataframe\ndisplay(df_characters.head())\ndisplay(df_locations.head())\ndisplay(df_script.head())\ndisplay(df_episodes.head())",
          "# Show first rows of the datasets\ndisplay(df_characters.head())\ndisplay(df_locations.head())\ndisplay(df_script.head())\ndisplay(df_episodes.head())",
          " Displaying the first rows of the dataframe\nprint('Characters')\ndisplay(df_characters.head())\nprint('Locations')\ndisplay(df_locations.head())\nprint('Script')\ndisplay(df_script.head())\nprint('Episodes')\ndisplay(df_episodes.head())",
          " Display the first few rows of each dataframe to understand its structure\nprint(\"Characters\")\ndisplay(df_characters.head())\n\nprint(\"Locations\")\ndisplay(df_locations.head())\n\nprint(\"Script\")\ndisplay(df_script.head())\n\nprint(\"Episodes\")\ndisplay(df_episodes.head())",
          "display the first few rows of each dataframe\ndisplay(df_characters.head())\ndisplay(df_locations.head())\ndisplay(df_script.head())\ndisplay(df_episodes.head())",
          " Show the first 3 rows of all datasets\ndisplay(df_characters.head(3))\ndisplay(df_locations.head(3))\ndisplay(df_script.head(3))\ndisplay(df_episodes.head(3))",
          "Display the first few rows of each dataframe to understand its structure and content\nprint('Characters')\ndisplay(df_characters.head())\nprint('Locations')\ndisplay(df_locations.head())\nprint('Script')\ndisplay(df_script.head())\nprint('Episodes')\ndisplay(df_episodes.head())",
          "Display the first few records of each DataFrame to understand its structure\nprint(\"Simpsons Characters DataFrame\")\ndisplay(df_characters.head())\n\nprint(\"Simpsons Locations DataFrame\")\ndisplay(df_locations.head())\n\nprint(\"Simpsons Script DataFrame\")\ndisplay(df_script.head())\n\nprint(\"Simpsons Episodes DataFrame\")\ndisplay(df_episodes.head())",
          " Display the first few rows of each dataframe\ndisplay(df_characters.head())\ndisplay(df_locations.head())\ndisplay(df_script.head())\ndisplay(df_episodes.head())",
          "display first few rows of each table\ndisplay(df_characters.head())\ndisplay(df_locations.head())\ndisplay(df_script.head())\ndisplay(df_episodes.head())",
          "# Display the first few rows of each dataframe\ndisplay(df_characters.head())\ndisplay(df_locations.head())\ndisplay(df_script.head())\ndisplay(df_episodes.head())",
          "Show the first few rows of each dataframe\ndisplay(df_characters.head())\ndisplay(df_locations.head())\ndisplay(df_script.head())\ndisplay(df_episodes.head())",
          "Display the first few rows of each dataframe to understand their structure\nprint('Characters:')\ndisplay(df_characters.head())\n\nprint('Locations:')\ndisplay(df_locations.head())\n\nprint('Script:')\ndisplay(df_script.head())\n\nprint('Episodes:')\ndisplay(df_episodes.head())",
          "# Show first rows of the characters, locations, and script dataframes\nprint(df_characters.head())\nprint(df_locations.head())\nprint(df_script.head())",
          "Display the first few rows of each dataframe to get an idea of their contents\nprint(\"characters.csv\")\ndisplay(df_characters.head())\n\nprint(\"\\nlocations.csv\")\ndisplay(df_locations.head())\n\nprint(\"\\nscript_lines.csv\")\ndisplay(df_script.head())\n\nprint(\"\\nepisodes.csv\")\ndisplay(df_episodes.head())",
          " Display the first few rows of each dataframe\n# print(\"\\n\\nFirst few rows of each dataframe:\")\n# print(df_characters.head())\n# print(df_locations.head())\n# print(df_script.head())\n# print(df_episodes.head())"
         ],
         "marker": {
          "opacity": 0.5,
          "size": 5
         },
         "mode": "markers+text",
         "name": "165_Displaying dataframes",
         "text": [
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          ""
         ],
         "textfont": {
          "size": 12
         },
         "type": "scattergl",
         "x": [
          -2.9425880908966064,
          -2.7831594944000244,
          -2.8486995697021484,
          -2.4279637336730957,
          -3.097991704940796,
          -2.607471227645874,
          -2.4626822471618652,
          -2.4508087635040283,
          -2.2507877349853516,
          -2.690838098526001,
          -2.847385883331299,
          -2.3358325958251953,
          -1.963830828666687,
          -2.5440163612365723,
          -2.6356141567230225,
          -2.5821290016174316,
          -2.896531581878662,
          -2.503776788711548,
          -2.430556297302246,
          -2.6758437156677246,
          -2.7052483558654785
         ],
         "y": [
          5.49453592300415,
          5.393352031707764,
          5.57857084274292,
          5.46525764465332,
          5.806013107299805,
          5.426482677459717,
          5.330854415893555,
          5.555346965789795,
          5.44632625579834,
          5.6177802085876465,
          6.129795551300049,
          5.370866298675537,
          5.826336860656738,
          5.525663375854492,
          5.957922458648682,
          5.203031063079834,
          5.323747634887695,
          5.409553527832031,
          6.174466609954834,
          5.706587791442871,
          5.699623107910156
         ]
        },
        {
         "hoverinfo": "text",
         "hovertext": [
          "\nimport nltk\nnltk.download('punkt')",
          "Instanciating a list of stopwords to be removed from the scripts",
          "List of stopwords\nimport nltk\nnltk.download('stopwords')\nfrom nltk.corpus import stopwords\nstop_words = set(stopwords.words('english'))",
          " Text preprocessing\nimport re\nimport string\n\nimport nltk\n\nfrom nltk.corpus import stopwords, wordnet\nfrom nltk.tokenize import word_tokenize\nfrom nltk.stem import WordNetLemmatizer\n\n# Download required resources\nnltk.download('punkt')\nnltk.download('stopwords')\nnltk.download('wordnet')",
          "# List of stopwords\nstopwords = spacy.lang.en.stop_words.STOP_WORDS",
          " Add extra data to stopwords. These words will be ignored in the analysis.",
          "Get the list of stopwords from Spacy.",
          "Create a generic stop words list to remove common words from our text analysis\nstop_words = [\"i\", \"me\", \"my\", \"myself\", \"we\", \"our\", \"ours\", \"ourselves\", \"you\", \"your\", \"yours\", \"yourself\", \"yourselves\", \"he\", \"him\", \"his\", \"himself\", \"she\", \"her\", \"hers\", \"herself\", \"it\", \"its\", \"itself\", \"they\", \"them\", \"their\", \"theirs\", \"themselves\", \"what\", \"which\", \"who\", \"whom\", \"this\", \"that\", \"these\", \"those\", \"am\", \"is\", \"are\", \"was\", \"were\", \"be\", \"been\", \"being\", \"have\", \"has\", \"had\", \"having\", \"do\", \"does\", \"did\", \"doing\", \"a\", \"an\", \"the\", \"and\", \"but\", \"if\", \"or\", \"because\", \"as\", \"until\", \"while\", \"of\", \"at\", \"by\", \"for\", \"with\", \"about\", \"against\", \"between\", \"into\", \"through\", \"during\", \"before\", \"after\", \"above\", \"below\", \"to\", \"from\", \"up\", \"down\", \"in\", \"out\", \"on\", \"off\", \"over\", \"under\", \"again\", \"further\", \"then\", \"once\", \"here\", \"there\", \"when\", \"where\", \"why\", \"how\", \"all\", \"any\", \"both\", \"each\", \"few\", \"more\", \"most\", \"other\", \"some\", \"such\", \"no\", \"nor\", \"not\", \"only\", \"own\", \"same\", \"so\", \"than\", \"too\", \"very\", \"s\", \"t\", \"can\", \"will\", \"just\", \"don\", \"should\", \"now\"]",
          "Use the NLTK library to download the stopwords data\nimport nltk\nnltk.download('stopwords')",
          "tokenization by nltk and punctuation removal\nimport nltk\nfrom nltk.corpus import stopwords\nfrom nltk.tokenize import word_tokenize, sent_tokenize\nnltk.download('stopwords')\nnltk.download('punkt')\nstop_words = set(stopwords.words('english'))",
          "Declare the file path to the stopwords file\nstopwords_file = \"stopwords.txt\"",
          "# Stopwords in the English language\nimport nltk\nnltk.download('stopwords')",
          "Import stop words from NLTK",
          "Define stop words and punctuation to be excluded from analysis\nstop_words = spacy.lang.en.stop_words.STOP_WORDS\npunctuations = spacy.lang.en.punctuation.PUNCT_PREFIXES",
          " A famous collection of stopwords\nfrom nltk.corpus import stopwords",
          " Set of stopwords found in Spacy for english language\nspacy_stopwords = spacy.lang.en.stop_words.STOP_WORDS",
          "Unload all the NLTK stopwords\nimport nltk\nfrom nltk.corpus import stopwords\n\n#nltk.download('stopwords')\n\nstopwords = set(stopwords.words('english'))",
          "from stop_words import get_stop_words",
          " Set the environment variable for NLTK data file",
          "Setting up the wordcloud stopwords\nfrom wordcloud import STOPWORDS\n\nnlp = spacy.load('en')\nstop_words = spacy.lang.en.STOP_WORDS # getting spacy's stop words\nstop_words |= STOPWORDS # using the union operator to combine the stop words",
          "Remove common words that are called \"stop words\", such as 'the', 'a', 'an', 'in', etc."
         ],
         "marker": {
          "opacity": 0.5,
          "size": 5
         },
         "mode": "markers+text",
         "name": "166_stopwords and tokenization in nltk",
         "text": [
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          ""
         ],
         "textfont": {
          "size": 12
         },
         "type": "scattergl",
         "x": [
          13.89887523651123,
          13.169647216796875,
          13.091130256652832,
          13.399161338806152,
          13.394978523254395,
          13.269500732421875,
          13.54698657989502,
          12.785493850708008,
          13.286529541015625,
          13.207923889160156,
          13.088226318359375,
          13.445417404174805,
          13.431800842285156,
          13.657519340515137,
          13.400131225585938,
          13.736536979675293,
          13.268147468566895,
          12.937230110168457,
          14.406271934509277,
          13.531617164611816,
          13.249885559082031
         ],
         "y": [
          6.158905029296875,
          6.337124347686768,
          6.2603325843811035,
          6.225193500518799,
          6.863002777099609,
          6.367856025695801,
          6.998641490936279,
          6.2262959480285645,
          5.9696946144104,
          6.397089958190918,
          5.90431022644043,
          6.2308526039123535,
          5.73134708404541,
          6.939128398895264,
          5.579013824462891,
          7.457499980926514,
          6.31405782699585,
          6.043551445007324,
          5.654999256134033,
          7.55471658706665,
          6.530399322509766
         ]
        },
        {
         "hoverinfo": "text",
         "hovertext": [
          "Sample the data to get a sense of what's in it\ndf_script.sample(10)",
          " Load sample script lines\ndf_script.sample(10)",
          "rsample 10% of script\ndf_script = df_script.sample(frac=0.1, random_state=0)",
          " Sample the dataset\nsample_size = 10000\n\ndf_script = df_script.sample(sample_size)",
          "\ndf_script.sample(10)",
          "Create new dataframe with a fraction of the script lines for testing\ndf_script_test = df_script.sample(frac=0.1, replace=True, random_state=1)\n\n# Save \"name\" and \"line\" columns to separate variables for testing\ntest_names = df_script_test.name.values\ntest_lines = df_script_test.raw_text.values",
          " Grabs a random sample from the dataframe\nsample_line = df_script.sample()",
          "Visualise 5 random rows of script dataset\ndf_script.sample(5)",
          " Sample the dataset\ndf_script.sample(10)",
          "Sample the dataframe to understand its structure\ndf_script.sample(10)",
          " Display some sampling of the data\ndf_script.sample(5)",
          "Inspect a few rows\ndf_script.sample(5, random_state=20)",
          " Print dfs to see sample data and how they look",
          " Optional:\ndf_script = df_script.sample(frac=0.1)",
          "Select few random rows for a visual inspection\ndf_script.sample(10)",
          "suffle the data\ndf_script = df_script.sample(frac=1, random_state=0)",
          "View a sample\nprint(df_script.sample(5))",
          "Create a sample of the dataframe\ndf_script_sample = df_script.sample(n=1000, random_state=0)",
          "Displaying 10 random rows from the script dataframe\ndf_script.sample(10)",
          "Set interim sampling levels\nn = 10000\nfrac = n / len(df_script)"
         ],
         "marker": {
          "opacity": 0.5,
          "size": 5
         },
         "mode": "markers+text",
         "name": "167_Sampling Techniques in Data Analysis",
         "text": [
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          ""
         ],
         "textfont": {
          "size": 12
         },
         "type": "scattergl",
         "x": [
          7.343501567840576,
          6.897884845733643,
          8.235881805419922,
          8.540549278259277,
          7.426180362701416,
          8.140003204345703,
          8.15054988861084,
          8.29798698425293,
          7.359003067016602,
          7.458512783050537,
          7.714158535003662,
          8.461801528930664,
          7.054387092590332,
          7.891790390014648,
          8.43325424194336,
          8.405168533325195,
          7.237240314483643,
          8.945250511169434,
          8.33165168762207,
          8.73758602142334
         ],
         "y": [
          -3.3945465087890625,
          -3.4815456867218018,
          -2.4258012771606445,
          -2.5357048511505127,
          -2.834319829940796,
          -2.3127458095550537,
          -2.7840042114257812,
          -3.0197813510894775,
          -2.8013997077941895,
          -3.433164596557617,
          -3.3480587005615234,
          -2.7995569705963135,
          -3.411097526550293,
          -2.6231842041015625,
          -3.2910099029541016,
          -2.185546636581421,
          -3.5491836071014404,
          -2.2664401531219482,
          -2.8720483779907227,
          -2.6564602851867676
         ]
        },
        {
         "hoverinfo": "text",
         "hovertext": [
          "Return the first 5 rows of the characters DataFrame\ndf_characters.head()",
          "Show the first 5 rows of the characters dataframe\ndf_characters.head()",
          "Show the first 5 characters of the characters dataframe\ndf_characters.head()",
          "Show the first 5 rows of the characters dataframe\ndf_characters.head()",
          "Show the first 5 rows of the df_characters dataframe\ndf_characters.head()",
          "the first 5 rows of the characters dataframe\ndf_characters.head()",
          "Show the first 5 rows of the characters dataframe\ndf_characters.head()",
          " Example: Show the first 5 rows of the characters dataframe\ndf_characters.head()",
          "Show the first 5 rows of the characters dataframe\ndf_characters.head()",
          " Show the first 5 rows of the characters dataframe\ndf_characters.head()",
          " Show the first 5 rows of the characters dataframe\ndf_characters.head()",
          "Show first 5 rows of the dataframe 'df_characters'\ndf_characters.head()",
          "Show the first 5 rows of the characters dataframe\ndf_characters.head()",
          "Show the first 5 rows of \"df_characters\" dataframe\ndf_characters.head()",
          " Show the first 5 characters in the characters dataframe\ndf_characters.head()",
          "Show the first 5 rows of the characters DataFrame\ndf_characters.head()",
          "Show the first 5 rows of the characters dataframe\ndf_characters.head()",
          " Show the first 5 rows of the characters dataframe\ndf_characters.head()",
          " Show first 5 rows of the characters dataframe\ndf_characters.head()",
          "Show the first 5 rows of the characters dataframe\ndf_characters.head()"
         ],
         "marker": {
          "opacity": 0.5,
          "size": 5
         },
         "mode": "markers+text",
         "name": "168_Showing first 5 rows of df_characters dataframe",
         "text": [
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          ""
         ],
         "textfont": {
          "size": 12
         },
         "type": "scattergl",
         "x": [
          -2.715162992477417,
          -1.9743032455444336,
          -2.607344150543213,
          -2.049912929534912,
          -2.1595325469970703,
          -1.7084282636642456,
          -2.1445016860961914,
          -2.1876120567321777,
          -1.8944642543792725,
          -1.776665210723877,
          -2.2491633892059326,
          -2.447416305541992,
          -2.0726516246795654,
          -2.380211353302002,
          -2.642387866973877,
          -1.8927407264709473,
          -2.0540902614593506,
          -1.970302939414978,
          -2.237868070602417,
          -1.9885817766189575
         ],
         "y": [
          14.271329879760742,
          14.731141090393066,
          14.212651252746582,
          14.538216590881348,
          14.459877967834473,
          14.062969207763672,
          14.454543113708496,
          14.897817611694336,
          14.509367942810059,
          14.669143676757812,
          14.87621784210205,
          14.824350357055664,
          14.59162425994873,
          14.588189125061035,
          14.109798431396484,
          14.549430847167969,
          14.577387809753418,
          14.423524856567383,
          14.709283828735352,
          14.644209861755371
         ]
        },
        {
         "hoverinfo": "text",
         "hovertext": [
          "Set index for fast access",
          "Setting the index to use for the DataFrames",
          " Set the index of each dataframe to be the unique identifier",
          "Change the index of each dataframe to the index of the respective dataframe",
          "Set the first column as the index in all DataFrames for easier access",
          "creating index for the original dataframes",
          "Create Indexers for each Dataframe",
          "Set index for every dataframe",
          "Ensure identical index for all the dataframes",
          "Set the index for each dataframe to be the unique identifier for each entry",
          " Set the dataframe's index to the `id` column, these ids will then be used to link data in the other dataframes",
          "Set the index on the de-serialized dataframes",
          "We can set the index of each dataframe to the id for faster access.",
          "Set the index of the dataframes to match the ID of the columns in the dataset",
          " Set the index of the DataFrames appropriately",
          "Setting index on the dataframes",
          "Ensure dataframes are sorted by index",
          "Set index of DataFrames for optimization",
          " Change the index of the dataframes",
          "Process data.frames and set index if necessary"
         ],
         "marker": {
          "opacity": 0.5,
          "size": 5
         },
         "mode": "markers+text",
         "name": "169_Setting Index in DataFrames for Easier Access",
         "text": [
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          ""
         ],
         "textfont": {
          "size": 12
         },
         "type": "scattergl",
         "x": [
          7.623882293701172,
          7.058816432952881,
          6.233285903930664,
          6.710427761077881,
          7.151636123657227,
          6.627624988555908,
          6.446594715118408,
          6.415239334106445,
          6.321221828460693,
          6.376902103424072,
          6.29528284072876,
          6.440662860870361,
          6.601818561553955,
          6.527780055999756,
          6.783246994018555,
          6.962713718414307,
          6.831077575683594,
          6.936522960662842,
          7.281335830688477,
          6.74755859375
         ],
         "y": [
          1.7733790874481201,
          0.652562141418457,
          1.6609747409820557,
          0.7696477770805359,
          1.0109931230545044,
          1.0641306638717651,
          0.9247004985809326,
          1.0127081871032715,
          0.9981905817985535,
          1.3979240655899048,
          1.1107676029205322,
          0.8343105316162109,
          1.4742761850357056,
          1.2331844568252563,
          0.9311723113059998,
          0.9885795712471008,
          0.6043030023574829,
          0.8157527446746826,
          0.9621025323867798,
          1.0466374158859253
         ]
        },
        {
         "hoverinfo": "text",
         "hovertext": [
          "Set some pandas options for printing and set the random seed for reproducibility.",
          "Set the seed for reproducibility\nnp.random.seed(0)",
          " Set seeds for numpy and python to keep results consistent\nnp.random.seed(42)\nPYTHONHASHSEED = 0",
          "Set the random seed for reproducibility\nnp.random.seed(0)",
          "# Set the seed for reproducibility\nnp.random.seed(0)",
          "Set the seed for reproducibility\nnp.random.seed(0)",
          " Set the seed for reproducibility\nnp.random.seed(0)",
          "Set the seed for reproducibility\nnp.random.seed(0)",
          "Set the seed for reproducibility\nnp.random.seed(0)",
          "\n# Set the seed for reproducibility\nnp.random.seed(0)",
          "Setting the Seed\nnp.random.seed(0)",
          "Make the models deterministic\nspacy.util.fix_random_seed(0)\nnp.random.seed(0)",
          "# Set random seed for reproducibility\nnp.random.seed(0)",
          " Ensure reproducibility\nnp.random.seed(0)",
          "# Set seed for reproducibility\nnp.random.seed(1)",
          "For reproducibility\nnp.random.seed(0)",
          "# Set seed for reproducibility\nnp.random.seed(0)",
          "# Set numpy random seed for reproducibility\nnp.random.seed(0)",
          "Set the seed for reproducibility\nnp.random.seed(0)",
          "Set the random seed for reproducibility\nnp.random.seed(0)"
         ],
         "marker": {
          "opacity": 0.5,
          "size": 5
         },
         "mode": "markers+text",
         "name": "170_Set random seed for reproducibility",
         "text": [
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          ""
         ],
         "textfont": {
          "size": 12
         },
         "type": "scattergl",
         "x": [
          29.455411911010742,
          29.728260040283203,
          30.015209197998047,
          30.227344512939453,
          29.586475372314453,
          29.90559196472168,
          29.98832893371582,
          29.909608840942383,
          29.75234031677246,
          29.84612274169922,
          30.385896682739258,
          30.400741577148438,
          29.75929069519043,
          29.636018753051758,
          29.76075553894043,
          29.71537971496582,
          29.6204833984375,
          30.164390563964844,
          29.7547550201416,
          30.16813087463379
         ],
         "y": [
          14.26641845703125,
          13.956289291381836,
          14.036482810974121,
          13.964090347290039,
          13.745992660522461,
          14.070528030395508,
          14.106740951538086,
          13.978471755981445,
          13.968982696533203,
          13.690884590148926,
          13.35882568359375,
          13.631790161132812,
          13.872949600219727,
          13.953290939331055,
          13.40658950805664,
          13.289591789245605,
          13.730766296386719,
          13.891190528869629,
          13.836024284362793,
          13.760771751403809
         ]
        },
        {
         "hoverinfo": "text",
         "hovertext": [
          "Inspect the characters dataframe\ndf_characters.head()",
          "Inspect head of characters dataframe",
          "Inspect the characters dataframe\ndf_characters.head()",
          "Examine the contents of the character dataframe\ndf_characters.head()",
          "Inspect characters DataFrame\ndf_characters.head()",
          "Display the dataframes for inspection\ndf_characters.head()",
          "Inspect the characters DataFrame\ndf_characters.head()",
          "Inspect character dataframe\ndf_characters.head()",
          "Inspect data frames\ndf_characters.head()",
          "Inspect the characters dataframe\ndf_characters.head()",
          "Inspect a sample of the characters dataframe\ndf_characters.head()",
          "Inspect the header of the characters DataFrame\ndf_characters.head()",
          "Inspect the head of the characters dataframe\ndf_characters.head()",
          " Inspect the contents of the characters dataframe\ndf_characters.head()",
          "Inspect the characters dataframe\ndf_characters.head()",
          "Visually inspect the characters dataframe\ndf_characters.head()",
          "inspect the contents of the characters dataframe\ndf_characters.head()",
          "Clean the characters dataframe.\ndf_characters.head()",
          "Inspect the character dataframe\ndf_characters.head()",
          "Sample the characters dataframe\ndf_characters.head()"
         ],
         "marker": {
          "opacity": 0.5,
          "size": 5
         },
         "mode": "markers+text",
         "name": "171_Dataframe Inspection - Characters",
         "text": [
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          ""
         ],
         "textfont": {
          "size": 12
         },
         "type": "scattergl",
         "x": [
          7.584526062011719,
          7.685035228729248,
          7.416502952575684,
          7.63468074798584,
          7.72910213470459,
          6.618320941925049,
          7.275755882263184,
          7.733532428741455,
          6.720857620239258,
          7.456474304199219,
          7.682794570922852,
          7.1436920166015625,
          7.450260639190674,
          7.37629508972168,
          7.699041843414307,
          7.16752815246582,
          7.348798751831055,
          7.12831974029541,
          7.834368705749512,
          7.591669082641602
         ],
         "y": [
          16.3670711517334,
          16.819101333618164,
          16.292524337768555,
          16.65833854675293,
          16.746257781982422,
          16.800580978393555,
          16.632688522338867,
          16.63951873779297,
          16.140029907226562,
          16.465051651000977,
          16.53818702697754,
          16.76111602783203,
          16.74750328063965,
          16.272674560546875,
          16.304821014404297,
          16.885778427124023,
          16.714040756225586,
          15.589430809020996,
          16.35167694091797,
          16.345417022705078
         ]
        },
        {
         "hoverinfo": "text",
         "hovertext": [
          "Display first few lines of the dataframe\ndf_script.head()",
          " Display the first few lines of the script dataframe to understand its structure\ndf_script.head()",
          "# Show first lines of script data\ndf_script.head()",
          "# Display first lines of the script dataframe\ndf_script.head()",
          "To see the first lines of each dataframe, we can run \"\"\"\"df.head()\"\"\"\" for each one",
          " Show first few example script lines\ndf_script.head()",
          "Display the first few lines of the dataframe to inspect its structure\ndf_script.head()",
          "Show first script lines\ndf_script.head(3)",
          "Output the first few lines of the script dataframe\ndf_script.head()",
          "Display the first lines of the script dataframe\ndf_script.head()",
          "Display first few lines of the dataframe df_script\ndf_script.head()",
          " Show the first few script lines\ndf_script.head()",
          "Display the first few lines of the script data to understand its structure\ndf_script.head()",
          "Display the first 3 lines of the dataframe\ndf_script.head(3)",
          "Displaying the first lines of the script dataframe\ndf_script.head()",
          "Show how one line of dialogue is structured\ndf_script.head(1)",
          "Display first lines of scripts dataframe\ndf_script.head()",
          "Show the first few lines of the script data\ndf_script.head()",
          "\n# Display the first few lines of the script DataFrame\ndf_script.head()",
          " View the first few lines of the dataframe\nprint(df_script.head())"
         ],
         "marker": {
          "opacity": 0.5,
          "size": 5
         },
         "mode": "markers+text",
         "name": "172_Displaying and Understanding the Structure of Script Data",
         "text": [
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          ""
         ],
         "textfont": {
          "size": 12
         },
         "type": "scattergl",
         "x": [
          3.473773956298828,
          3.6822056770324707,
          3.5987377166748047,
          3.712156295776367,
          4.138952732086182,
          3.9988059997558594,
          3.7697038650512695,
          3.70576548576355,
          3.7831406593322754,
          3.621339797973633,
          3.5563249588012695,
          4.104409217834473,
          3.9117541313171387,
          3.5230872631073,
          3.6980810165405273,
          4.576615810394287,
          3.754611015319824,
          3.7588212490081787,
          3.237908363342285,
          3.373729705810547
         ],
         "y": [
          -7.569962978363037,
          -6.371269226074219,
          -6.672444820404053,
          -7.3328471183776855,
          -7.213306903839111,
          -6.272376537322998,
          -6.823077201843262,
          -6.403500080108643,
          -7.497042655944824,
          -7.2153520584106445,
          -7.393689155578613,
          -6.103972434997559,
          -5.915139675140381,
          -7.178066730499268,
          -7.039739608764648,
          -6.1359710693359375,
          -7.065986156463623,
          -6.692335605621338,
          -7.015751361846924,
          -7.151259422302246
         ]
        },
        {
         "hoverinfo": "text",
         "hovertext": [
          " Checking the structure of the dataframes",
          "Inspect the structure of the dataframes",
          "Inspect the structure of the dataframes",
          "Inspect the structure of the dataframes",
          "Check DataFrame structure for each dataset",
          "Format the dataframes to ensure consistency and quality",
          " Inspect the structure of the dataframes",
          "Inspect each DataFrame and their respective columns",
          "Inspect structure of each dataframe",
          "Inspect the structure of each of the dataframes",
          " Examine the structure of these DataFrames",
          "Exploring the structure of the dataframes",
          "Checking the general structure of each dataframe",
          "Format dataframe columns and values",
          "Inspect the format and structure of the data in the dataframes",
          "Inspect the structure of some of the loaded dataframes",
          "Inspect the structure of the dataframes",
          " inspect the structures of the dataframes",
          "display the dataframes to observe the structure",
          "Inspect the structure of each dataframe"
         ],
         "marker": {
          "opacity": 0.5,
          "size": 5
         },
         "mode": "markers+text",
         "name": "173_Inspecting structures and formats of dataframes",
         "text": [
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          ""
         ],
         "textfont": {
          "size": 12
         },
         "type": "scattergl",
         "x": [
          10.87340259552002,
          11.377523422241211,
          11.1096773147583,
          11.38238525390625,
          10.861418724060059,
          7.380947589874268,
          11.186677932739258,
          11.147836685180664,
          11.076993942260742,
          11.169854164123535,
          11.196871757507324,
          10.847957611083984,
          10.90658187866211,
          9.322275161743164,
          10.72724437713623,
          11.646650314331055,
          11.046062469482422,
          11.349681854248047,
          10.84945011138916,
          11.019571304321289
         ],
         "y": [
          -4.68939733505249,
          -4.882611274719238,
          -5.036645889282227,
          -4.695309162139893,
          -4.298998832702637,
          -0.0890614464879036,
          -4.980273723602295,
          -4.529543876647949,
          -5.050948143005371,
          -4.850188255310059,
          -5.287839412689209,
          -5.208118915557861,
          -4.732382297515869,
          -3.0341637134552,
          -4.322575569152832,
          -4.474049091339111,
          -4.714877605438232,
          -4.737412452697754,
          -5.56851863861084,
          -4.8003830909729
         ]
        },
        {
         "hoverinfo": "text",
         "hovertext": [
          "Checking the head of the dataframe",
          "This will allow us to simply call head(), tail() or sample() on our dataframe instead of remembering the name of the index column.",
          "Check the head of the dataframe",
          "Checking head of each dataframe to understand the data",
          "Inspect dataframes head",
          "Displays the head of the dataframes to understand how the data looks like",
          "Checking the head of the dataframe",
          "List the head of each dataframe",
          " Display the head of each dataframe to verify data was loaded correctly",
          " Display the head of each dataframe, by calling the head() function on each dataframe.",
          "Checking the data shape and head of each dataframe",
          "Display the dimensions and the head of the dataframes",
          "Inspect the head of each dataframe to understand the data",
          "Displaying the dataframe head as well as the metadata of each dataframe",
          "Visualize the dataframe elements using head()",
          "View dataframes headers",
          "Print the head of the first dataframe to inspect the structure and data",
          " Displaying a simple head of the dataframes",
          " Sample the data by printing the head of each dataframe",
          "Display the head of each dataframe to quickly check if the import was successful"
         ],
         "marker": {
          "opacity": 0.5,
          "size": 5
         },
         "mode": "markers+text",
         "name": "174_Inspecting dataframe headers",
         "text": [
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          ""
         ],
         "textfont": {
          "size": 12
         },
         "type": "scattergl",
         "x": [
          8.49724006652832,
          7.215272426605225,
          8.207539558410645,
          8.888967514038086,
          8.34422492980957,
          8.424135208129883,
          8.28229808807373,
          8.539690971374512,
          9.106574058532715,
          8.166305541992188,
          9.540873527526855,
          8.20979118347168,
          8.913806915283203,
          8.35826587677002,
          7.496548652648926,
          9.001599311828613,
          8.534173965454102,
          8.196683883666992,
          8.958072662353516,
          9.646053314208984
         ],
         "y": [
          -4.481815814971924,
          0.8036527633666992,
          -4.369259834289551,
          -4.59181022644043,
          -4.685687065124512,
          -5.309580326080322,
          -4.381616592407227,
          -4.736053943634033,
          -4.5207390785217285,
          -5.060420036315918,
          -4.184779644012451,
          -4.701637268066406,
          -5.0873332023620605,
          -4.82654333114624,
          -5.214325904846191,
          -4.362053394317627,
          -4.937175273895264,
          -4.902341842651367,
          -4.4393229484558105,
          -4.064915657043457
         ]
        },
        {
         "hoverinfo": "text",
         "hovertext": [
          "Let's take a look at the structure of the datasets.",
          "Let's take a look at the dimensions of the datasets.",
          "Let's take a look at the structure of the datasets.",
          " Let's take a look at the structure of the datasets.",
          "Let's take a look at the different datasets and see how they are structured.",
          "We'll see the structure of the main datasets",
          "Let's take a look at the dimensions of the datasets.",
          "We'll take a look at how the datasets are structured and which fields might be useful for our analysis.",
          "Let's take a quick look at the structure of the datasets.",
          "Let's take a quick look at the structure of the datasets.",
          " Let's take a look at the structure of the datasets.",
          "Let's take a brief look at the structure of the datasets.",
          "Let's get a feeling for the structure and information in these datasets.",
          "Let's take a look at the structure of our datasets.",
          " Let's take a look at the structure of the datasets.",
          "Let's take a look at the structure of the datasets.",
          "Let's explore the datasets first to see their structure and data types.",
          "Let's take a look at the structure of these datasets.",
          "Let's take a look at the structure of the datasets.",
          " Let's take a look at the structure of the datasets."
         ],
         "marker": {
          "opacity": 0.5,
          "size": 5
         },
         "mode": "markers+text",
         "name": "175_Structure of Datasets",
         "text": [
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          ""
         ],
         "textfont": {
          "size": 12
         },
         "type": "scattergl",
         "x": [
          16.483278274536133,
          16.086830139160156,
          16.17259979248047,
          16.315176010131836,
          16.300065994262695,
          15.895825386047363,
          16.05842399597168,
          16.524869918823242,
          16.049497604370117,
          16.022436141967773,
          16.401058197021484,
          15.954773902893066,
          16.172529220581055,
          16.529945373535156,
          16.207048416137695,
          16.341527938842773,
          15.842056274414062,
          16.146656036376953,
          16.10763931274414,
          16.43537139892578
         ],
         "y": [
          -4.60280704498291,
          -4.083367347717285,
          -4.570952892303467,
          -4.617607593536377,
          -4.8967742919921875,
          -4.404200553894043,
          -4.3169989585876465,
          -4.051203727722168,
          -4.148430824279785,
          -4.090020656585693,
          -4.607156276702881,
          -4.365128517150879,
          -3.894742250442505,
          -4.307358264923096,
          -4.552411079406738,
          -4.5135273933410645,
          -3.3265223503112793,
          -3.8564820289611816,
          -4.603966236114502,
          -4.356848239898682
         ]
        },
        {
         "hoverinfo": "text",
         "hovertext": [
          "Show the first few rows of the characters dataframe\ndf_characters.head()",
          "Show first few rows of the characters dataframe\ndf_characters.head()",
          " Show the first few rows of the characters dataframe\ndf_characters.head()",
          " Show the first few rows of the characters dataframe\ndf_characters.head()",
          "Show the first few rows of the characters dataframe\ndf_characters.head()",
          "Show the first few rows of the characters dataframe\ndf_characters.head()",
          "Show the first few rows of the characters dataframe\ndf_characters.head()",
          "Show the first few rows of the 'df_characters' DataFrame\ndf_characters.head()",
          "Show the first few rows of the characters dataframe\ndf_characters.head()",
          "Show the first few rows of the characters dataframe\ndf_characters.head()",
          "Show the first few rows of the characters dataframe\ndf_characters.head()",
          " Show first few rows of characters dataframe\ndf_characters.head()",
          "Show the first few rows of the characters DataFrame\ndf_characters.head()",
          "Show the first few rows of the dataframe df_characters\ndf_characters.head()",
          "Show first few rows of characters dataframe\ndf_characters.head()",
          "Show the first few rows of the characters dataframe\ndf_characters.head()",
          " Show the first few rows of the characters dataframe\ndf_characters.head()",
          "Show the first few rows of characters dataframe\ndf_characters.head()",
          "Show the first few rows of the characters dataframe\ndf_characters.head()",
          "Show first few rows of the characters dataframe\ndf_characters.head()"
         ],
         "marker": {
          "opacity": 0.5,
          "size": 5
         },
         "mode": "markers+text",
         "name": "176_Extracting first few rows of the characters dataframe",
         "text": [
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          ""
         ],
         "textfont": {
          "size": 12
         },
         "type": "scattergl",
         "x": [
          -11.334115982055664,
          -11.374288558959961,
          -11.322118759155273,
          -10.995546340942383,
          -10.92536449432373,
          -11.080134391784668,
          -11.164525032043457,
          -11.105825424194336,
          -11.113847732543945,
          -11.123908996582031,
          -10.96562385559082,
          -11.266274452209473,
          -11.208731651306152,
          -11.292373657226562,
          -11.158729553222656,
          -11.391883850097656,
          -11.075035095214844,
          -11.258398056030273,
          -11.305906295776367,
          -11.18931770324707
         ],
         "y": [
          0.6514379382133484,
          1.1283999681472778,
          0.6113169193267822,
          0.5880864858627319,
          0.8041237592697144,
          0.6286023259162903,
          0.5502690672874451,
          1.042689561843872,
          0.9286707639694214,
          0.6778927445411682,
          0.5092170238494873,
          1.3749468326568604,
          0.5357232093811035,
          0.6993937492370605,
          1.2925662994384766,
          0.9004786014556885,
          0.886848509311676,
          0.7408270835876465,
          0.8314779996871948,
          1.2985540628433228
         ]
        },
        {
         "hoverinfo": "text",
         "hovertext": [
          "Show the first few lines of the dataframe containing the script lines",
          "Display first 5 rows of the script dataframe.",
          "Print the first 5 rows of the script dataframe.",
          " Display the first 5 lines of the dataframe containing the script lines.",
          "Show the first few rows of the dataframe containing all script lines",
          "Shows the first few rows of the script dataframe.",
          " Display the first few rows of the dataframe containing the script lines.",
          " Import the data from 'simpsons_script_lines.csv' into a pandas DataFrame and display the first 5 rows.",
          " Display the first 5 rows of the dataframe containing the script lines.",
          "Display the first 10 rows of the dataframe of script lines.",
          "Show the first rows of scripts data.",
          "Display the first few lines of the script dataframe and metadata about the datasets",
          " Display the first 5 rows of the dataframe containing the script lines.",
          " Show the first 5 elements of the script DataFrame.",
          "Display the first few rows of the dataframe containing script lines",
          "Display the first few rows of the dataframe containing the script lines.",
          "Select only the first 20 lines from the script dataset to avoid memory errors",
          "Show first 5 rows of the dataframe for the script of the Simpsons",
          "Display the first few rows of the table containing the script lines."
         ],
         "marker": {
          "opacity": 0.5,
          "size": 5
         },
         "mode": "markers+text",
         "name": "177_Displaying the First Few Rows of a Pandas DataFrame containing Script Lines",
         "text": [
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          ""
         ],
         "textfont": {
          "size": 12
         },
         "type": "scattergl",
         "x": [
          4.5893635749816895,
          2.919123411178589,
          2.7220616340637207,
          3.3233461380004883,
          3.845651149749756,
          3.790956974029541,
          3.9627017974853516,
          2.4531304836273193,
          3.2201950550079346,
          3.490260124206543,
          4.188363552093506,
          4.882648468017578,
          3.0341899394989014,
          2.8856608867645264,
          3.9782283306121826,
          3.983053684234619,
          4.2310614585876465,
          2.8564720153808594,
          4.76174783706665
         ],
         "y": [
          -2.6380813121795654,
          -3.5208792686462402,
          -4.062657356262207,
          -3.3010315895080566,
          -2.5806407928466797,
          -3.0411148071289062,
          -2.7387828826904297,
          -3.80727481842041,
          -3.2534828186035156,
          -3.1179909706115723,
          -2.262061834335327,
          -2.783867120742798,
          -3.156628131866455,
          -3.453896999359131,
          -2.64670729637146,
          -2.6519525051116943,
          -2.037888288497925,
          -3.9224631786346436,
          -1.8092139959335327
         ]
        },
        {
         "hoverinfo": "text",
         "hovertext": [
          "Check that the datasets have been correctly loaded",
          " Checking the structure of the loaded datasets",
          "id we loaded all the datasets correctly?",
          "Check the dataset is correctly loaded",
          "Loading datasets",
          "Every dataset loaded successfully.",
          "begin by loading the datasets",
          "Check if we have loaded the datasets correctly",
          "Check if the dataset has been loaded correctly",
          " We can see that we're successful in loading the datasets by also calling the `.head()` function on each one of them.",
          " Load the provided datasets",
          "Consider loading only a subset of the data for performance reasons if the dataset is large.",
          " Display of loaded datasets",
          "Let's check the loaded datasets",
          "Check to see the loaded datasets look like.",
          "Checking if the datasets were loaded correctly",
          "Check if your datasets have been read correctly",
          "To_DO load all datasets and print the columns names and shapes to confirm everything was read correctly",
          "Check the loaded datasets"
         ],
         "marker": {
          "opacity": 0.5,
          "size": 5
         },
         "mode": "markers+text",
         "name": "178_Checking if datasets have been loaded correctly",
         "text": [
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          ""
         ],
         "textfont": {
          "size": 12
         },
         "type": "scattergl",
         "x": [
          14.240832328796387,
          14.630731582641602,
          14.863609313964844,
          14.27872371673584,
          14.123817443847656,
          14.758548736572266,
          14.88629150390625,
          14.413501739501953,
          14.599267959594727,
          14.77597713470459,
          14.409066200256348,
          13.34399127960205,
          14.802217483520508,
          14.748579025268555,
          14.601799011230469,
          14.664344787597656,
          13.666536331176758,
          14.129131317138672,
          14.531049728393555
         ],
         "y": [
          0.41591155529022217,
          -0.7874178886413574,
          0.11119674891233444,
          0.20840077102184296,
          0.11040937155485153,
          0.5838009119033813,
          -0.21051613986492157,
          -0.218213751912117,
          0.08452790230512619,
          -0.01945129781961441,
          0.15811261534690857,
          -0.19494052231311798,
          -0.5612239241600037,
          -0.3993767201900482,
          0.7402750253677368,
          0.08863205462694168,
          0.14869312942028046,
          -0.3253175914287567,
          -0.17344880104064941
         ]
        },
        {
         "hoverinfo": "text",
         "hovertext": [
          "Simple regularization\ndf_script = df_script[['episode_id', 'raw_text']].groupby('episode_id').agg(lambda x: ' '.join(x)).reset_index()",
          "Store script lines by episode ID\nepisode_script_lines = {}\nfor episode_id, group in df_script.groupby('episode_id'):\n    episode_script_lines[episode_id] = group['raw_text'].tolist()",
          "Create a full script from the line's dataframe and join by episode id\ndf_episode_scripts = df_script.groupby('episode_id').apply(lambda x: ' '.join(x.speaking_line)).reset_index(name='full_script')",
          "Extract data\ndf_char_ep_count = df_script[['character_id','episode_id']].groupby('character_id').episode_id.nunique().reset_index(name='episode_count')\ndf_char_ep_count = df_char_ep_count[df_char_ep_count.episode_count >= 20]\ndf_char_ep_count = df_char_ep_count.merge(df_characters, left_on='character_id', right_on='id').sort_values('episode_count', ascending=False)",
          "join transcript lines for each episode into single string\ndf_script_grouped = df_script.groupby(by='episode_id').agg({'normalized_text': lambda x: ' '.join(x)}).reset_index(inplace=False)\n\nnlp = spacy.load('en')",
          "Scatter character by gender\ngrouped_episodes = df_script.groupby('episode_id')['normalized_text'].apply(lambda x: ''.join(x)).reset_index()\ngrouped_episodes = pd.merge(grouped_episodes, df_episodes, on='episode_id')\n\nspacy.prefer_gpu()",
          "Function to join lines from one chracter in one episode as a single line\ndef dialogByCharacterAndEpisode(dataframe):\n    dfs = dataframe.groupby(['episode_id','character_id'])['raw_text'].apply(lambda x: ' '.join(x)).reset_index()\n    for index,row in dfs.iterrows():\n        episode_id = row['episode_id']\n        character_id = row['character_id']\n        raw_text = row['raw_text']\n        series = dataframe[(dataframe['episode_id'] == episode_id) & (dataframe['character_id'] == character_id)]['raw_text']\n        for index, value in series.items():\n            dataframe.at[index,'raw_text'] = raw_text\n    dataframe.drop_duplicates(subset =['episode_id','character_id'], keep = 'last', inplace = True)\n    return dataframe",
          "Combine the lines into single sentences in the `raw_text` column\ndf_script_combined = df_script.groupby('episode_id')['raw_text'].apply(lambda x: ' '.join(x)).reset_index()\ndf_script_combined.head()",
          "Add the full transcripts to the dataframe\ndf_transcripts = df_script.groupby('episode_id').apply(lambda x: ' '.join(x['normalized_text'])).reset_index()\ndf_transcripts.columns = ['episode_id', 'transcript']\n\ndf_episodes = df_episodes.set_index('id')\ndf_episodes['full_transcript'] = df_transcripts.set_index('episode_id')",
          "# A bit of visualization\ndf = df_script[['episode_id', 'character_id']].groupby('episode_id').count().reset_index(inplace=False)\ndf = pd.merge(df, df_episodes[['id', 'original_air_date']], left_on='episode_id', right_on='id', how='inner')\ndf['original_air_date'] = pd.to_datetime(df['original_air_date'])\ndf = df.rename(columns={'character_id': 'line_count'})\ndf[['episode_id', 'line_count']].sort_values(by='line_count', ascending=False)[:10]",
          "Aggregate both sentences and raw data by episode_id in one dataframe\nepisodes_dialogues = pd.concat([df_script.groupby('episode_id').apply(lambda x: ' '.join(x['raw_text'])).rename('script'),\n                                df_script.groupby('episode_id').apply(lambda x: ' '.join(x['spoken_words'].dropna())).rename('spoken_words'),\n                                df_episodes.set_index('id')\n                               ], axis=1, join='inner').reset_index(inplace=False)",
          "Filter out bad quality lines and join by episode_id\ndf_script_filtered = df_script[\n    (df_script['speaking_line'] == True)\n    & (df_script['raw_text'].notna())\n][['episode_id', 'raw_text']].groupby('episode_id').agg(lambda x: ' '.join(x)).reset_index()",
          "# Create a \"doc\" object for each episode script line containing annotations\ndf_script['doc'] = list(nlp.pipe(df_script['normalized_text'], batch_size=5000))",
          " Build List of Episode Script Data\nepisode_script_data = []\nunique_episode_ids = df_script['episode_id'].unique()\nfor episode_id in tqdm(unique_episode_ids, desc=\"Building Episode Script Data\"):\n    episode_lines = df_script[df_script['episode_id'] == episode_id].sort_values(by='timestamp_in_ms')\n    episode_lines = episode_lines.reset_index(inplace=False, drop=True)\n    episode_script_data.append({\n        'episode_id': episode_id,\n        'title': episode_lines.loc[0, 'title'],\n        'script': ' '.join([str(elem) for elem in episode_lines['normalized_text'] if pd.notnull(elem)])\n    })",
          "Grouping by episode id and joining all lines by 'space'\ndf_script_grouped = df_script.groupby('episode_id').apply(lambda x: ' '.join(x['normalized_text']))\n\n# Merging with episode ids in order to have the same ordering.\ndf_script_grouped_pd = pd.DataFrame(df_script_grouped, columns=['script'])\ndf_script_grouped_pd = df_script_grouped_pd.merge(df_episodes, left_index=True, right_on='id').set_index('id').sort_index()\n\n# Credits\ndf_script_grouped = df_script_grouped_pd['script']\n\ndf_script_grouped_vc = df_script['episode_id'].value_counts().sort_index()",
          " Join all text for each row and store in the 'text' column for each data frame\ndf_characters['text'] = df_characters['raw_character_text']\ndf_characters = df_characters.groupby('raw_character_text').agg({'text': ' '.join}).reset_index()\n\ndf_locations['text'] = df_locations['normalized_location_text']\ndf_locations = df_locations.groupby('normalized_location_text').agg({'text': ' '.join}).reset_index()\n\ndf_episodes['text'] = df_episodes['title']\ndf_episodes = df_episodes.groupby('title').agg({'text': ' '.join}).reset_index()",
          " Calculate some simple statistics for each episode\ndf_script['word_count'] = df_script['normalized_text'].apply(lambda x: len(str(x).split()))\ndf_episodes['word_count'] = df_episodes['normalized_text'].apply(lambda x: len(str(x).split()))\n\ndf_episodes_stats = df_script.groupby('episode_id').agg(\n    lines=('id', 'count'),\n    characters=('raw_character_text', lambda x: x.nunique()),\n    locations=('raw_location_text', lambda x: x.nunique()),\n    average_words_per_line=('word_count', 'mean')\n).reset_index()\n\n# Merge the episode statistics with the rest of the episode information\ndf_episodes = df_episodes.merge(df_episodes_stats, on='id')",
          "Change end of line character to simulate a new paragraph\n# Ceate a temporary column with the lines change\ndf_script = df_script.assign(text_changed = df_script['raw_text'] + \"\\n\")\n\n# Group by episode_id and character_id to retrieve the full script of each character in a given episode\ndf_script_episode_level = df_script.groupby(['episode_id', 'character_id']).agg({'text_changed': 'sum'}).reset_index()\n\n# Group by character_id to retrieve the full script of each character in the whole show\ndf_script_character_level = df_script.groupby(['character_id']).agg({'text_changed': 'sum'}).reset_index()",
          "Join tables by episode_id and get the main characters\ndf = pd.merge(\n    df_script,\n    # Get main characters per episode\n    (\n        df_script[df_script.raw_character_text.str.len() > 0]\n        .groupby('episode_id')\n        .agg({\n            'raw_character_text':\n            lambda x: Counter(x).most_common()[0][0]\n        })\n        .reset_index()\n    ),\n    on='episode_id'\n)\n\ndf = pd.merge(\n    df,\n    df_episodes,\n    on='episode_id'\n)"
         ],
         "marker": {
          "opacity": 0.5,
          "size": 5
         },
         "mode": "markers+text",
         "name": "179_Text aggregation and grouping in episode scripts",
         "text": [
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          ""
         ],
         "textfont": {
          "size": 12
         },
         "type": "scattergl",
         "x": [
          4.03715705871582,
          4.035686016082764,
          3.958125352859497,
          4.188377380371094,
          4.844147682189941,
          3.52996563911438,
          3.2978017330169678,
          3.7344493865966797,
          4.132223129272461,
          3.278517246246338,
          4.753256797790527,
          4.307296276092529,
          10.961090087890625,
          3.1746861934661865,
          3.6861844062805176,
          3.6874847412109375,
          4.443739414215088,
          3.170107126235962,
          3.5829195976257324
         ],
         "y": [
          7.294430732727051,
          6.671728134155273,
          7.09156608581543,
          7.122271537780762,
          7.329103469848633,
          6.8946661949157715,
          6.7682647705078125,
          7.213600158691406,
          7.173000812530518,
          7.2285284996032715,
          7.308410167694092,
          6.520300388336182,
          8.634456634521484,
          6.279698371887207,
          6.950200080871582,
          6.970115661621094,
          7.540128707885742,
          7.016731262207031,
          7.084319114685059
         ]
        },
        {
         "hoverinfo": "text",
         "hovertext": [
          "Preview of the characters data file\ndf_characters.head()",
          "Preview the characters data\ndf_characters.head()",
          "Preview the data\ndf_characters.head()",
          "Preview the data\ndf_characters.head()",
          "Preview data\ndf_characters.head()",
          "Get a preview of the characters data\ndf_characters.head()",
          "Preview data\ndf_characters.head()",
          "Preview the characters data\ndf_characters.head()",
          "Preview the characters data\ndf_characters.head()",
          "Preview data\ndf_characters.head()",
          "Preview the data\ndf_characters.head()",
          "Preview df_characters\ndf_characters.head()",
          " Data preview\ndf_characters.head()",
          "Preview data\ndf_characters.head()",
          "Preview data\ndf_characters.head()",
          "Preview the loaded data\ndf_characters.head()",
          "Preview the characters data\ndf_characters.head()",
          "Preview the characters data\ndf_characters.head()",
          "Preview the characters data\nprint(df_characters.head())\n\n# Display types and non-null values\nprint(df_characters.info())"
         ],
         "marker": {
          "opacity": 0.5,
          "size": 5
         },
         "mode": "markers+text",
         "name": "180_Previewing Characters' Data",
         "text": [
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          ""
         ],
         "textfont": {
          "size": 12
         },
         "type": "scattergl",
         "x": [
          9.842361450195312,
          9.675971031188965,
          11.120521545410156,
          10.797873497009277,
          10.82026195526123,
          9.302915573120117,
          10.73486328125,
          9.610427856445312,
          9.442784309387207,
          11.070395469665527,
          10.771218299865723,
          10.42725944519043,
          11.052094459533691,
          10.76773452758789,
          10.912945747375488,
          10.80762004852295,
          9.582158088684082,
          9.695043563842773,
          8.526518821716309
         ],
         "y": [
          16.79082489013672,
          16.70465850830078,
          17.715545654296875,
          17.48960304260254,
          17.45730209350586,
          16.76111602783203,
          17.533918380737305,
          16.808319091796875,
          16.84149169921875,
          17.61564064025879,
          17.206722259521484,
          17.21112632751465,
          17.311460494995117,
          17.308792114257812,
          17.369165420532227,
          17.474897384643555,
          16.929969787597656,
          16.772558212280273,
          16.537290573120117
         ]
        },
        {
         "hoverinfo": "text",
         "hovertext": [
          " Set the style\nmatplotlib.style.use('ggplot')",
          " Set the style of graphs to 'ggplot' for better visuals\nplt.style.use('ggplot')",
          "Setting the default style\nmatplotlib.style.use('ggplot')",
          " Set the default style for matplotlib to 'ggplot'\nmatplotlib.style.use('ggplot')",
          "Set plot color scheme\nmatplotlib.style.use('ggplot')",
          "Set plot style\nmatplotlib.style.use('ggplot')",
          "Set the Style of the plots\nmatplotlib.style.use('ggplot')",
          " Set up matplotlib style\nmatplotlib.style.use('ggplot')",
          "Set the default style of the plots\nmatplotlib.style.use('ggplot')",
          "Set visualization style\nmatplotlib.style.use('ggplot')",
          "Ensure matplotlib uses the `ggplot` style\nplt.style.use('ggplot')",
          "Setting the style of the plots\nmatplotlib.style.use('ggplot')",
          "Show figures in this notebook\nmatplotlib.style.use('ggplot')",
          "Setting up matplotlib style\nplt.style.use('ggplot')",
          "Modify plot style to 'ggplot' style\nplt.style.use('ggplot')",
          "configure matplotlib style\nplt.style.use('ggplot')",
          "Set MATPLOTLIB to use ggplot style\nplt.style.use('ggplot')",
          "# Manually add matplot lib to available styles\nplt.style.use('ggplot')",
          "Image styles\n# Matplotlib styles\nplt.style.use('ggplot')"
         ],
         "marker": {
          "opacity": 0.5,
          "size": 5
         },
         "mode": "markers+text",
         "name": "181_Matplotlib Style Use ggplot",
         "text": [
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          ""
         ],
         "textfont": {
          "size": 12
         },
         "type": "scattergl",
         "x": [
          21.558801651000977,
          22.181385040283203,
          21.190353393554688,
          21.29297637939453,
          21.209394454956055,
          21.49449348449707,
          21.407875061035156,
          21.547401428222656,
          20.936580657958984,
          21.612512588500977,
          21.868091583251953,
          21.3305721282959,
          21.36459732055664,
          21.742229461669922,
          21.880897521972656,
          21.770883560180664,
          21.84801483154297,
          21.17742919921875,
          21.594161987304688
         ],
         "y": [
          4.186678886413574,
          4.443156719207764,
          4.626307964324951,
          4.514947414398193,
          4.596080303192139,
          4.370004177093506,
          4.459477424621582,
          4.481307506561279,
          4.543425559997559,
          4.4014458656311035,
          4.226271629333496,
          4.3379669189453125,
          4.320067882537842,
          4.1683430671691895,
          4.246825218200684,
          4.087175369262695,
          4.368399620056152,
          3.9569475650787354,
          4.29132080078125
         ]
        },
        {
         "hoverinfo": "text",
         "hovertext": [
          "inspecting each dataframe\nprint(f\"Characters: {df_characters.shape[0]}\")\ndf_characters.head(2)",
          "Print the head of the characters dataframe\nprint(df_characters.head())",
          " Print the first few entries of the characters DataFrame\nprint(f\"The shape of the Simpsons characters DataFrame is: {df_characters.shape}\")",
          "Print the head of the characters dataframe\nprint(df_characters.head(5))",
          "Print head of characters dataframe\ndf_characters.head()",
          "Print the character dataframe to understand the structure and contents\nprint(df_characters.head())",
          " Print the head of the characters dataframe\ndf_characters.head()",
          " Print the character DataFrame\ndf_characters.head()",
          "Print the head of the characters dataframe\ndf_characters.head()",
          "Print the head of the characters dataframe\ndf_characters.head()",
          "Overview of characters DataFrame\nprint(df_characters.shape)\nprint(df_characters.head())",
          "Print the head of df_characters dataframe\ndf_characters.head()",
          "Characters DataFrame\nprint(\"Characters DataFrame\")\ndf_characters.head()",
          "sample the characters dataframe\nprint(\"Characters dataframe shape: \", df_characters.shape)\ndf_characters.head()",
          "Print some data about the characters dataframe\nprint(df_characters.head())",
          "Print the Characters data\nprint(df_characters.head(5))",
          "\nprint(df_characters.head())",
          "# Print the head of the characters dataframe\nprint(df_characters.head())",
          "print(df_characters.head())"
         ],
         "marker": {
          "opacity": 0.5,
          "size": 5
         },
         "mode": "markers+text",
         "name": "182_Inspecting Simpsons Character DataFrame",
         "text": [
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          ""
         ],
         "textfont": {
          "size": 12
         },
         "type": "scattergl",
         "x": [
          5.663738250732422,
          4.8247199058532715,
          4.5315351486206055,
          4.716790199279785,
          4.8792853355407715,
          5.5683488845825195,
          4.996739864349365,
          5.298763751983643,
          4.936412334442139,
          4.837451457977295,
          5.161510467529297,
          4.587841033935547,
          4.964616298675537,
          5.284328460693359,
          5.611523628234863,
          4.918078899383545,
          5.125960350036621,
          5.384940147399902,
          5.118775367736816
         ],
         "y": [
          15.009218215942383,
          16.556015014648438,
          14.5563325881958,
          16.361534118652344,
          16.833065032958984,
          16.40962028503418,
          16.66768455505371,
          16.367568969726562,
          16.84603500366211,
          16.9292049407959,
          15.958047866821289,
          16.582748413085938,
          16.04090690612793,
          15.420720100402832,
          16.224489212036133,
          15.776688575744629,
          16.339805603027344,
          16.256017684936523,
          16.459701538085938
         ]
        },
        {
         "hoverinfo": "text",
         "hovertext": [
          "Remove invalid entries from the dataset\ndf_script = df_script[df_script['timestamp_in_ms'].notna()]\ndf_script = df_script[df_script['character_id'].notna()]\ndf_script = df_script[df_script['location_id'].notna()]",
          " Remove potential corrupted data\ndf_script = df_script[df_script['location_id'].notnull()].copy()",
          "Clean the script data\ndf_script = df_script[pd.to_numeric(df_script['id'], errors='coerce').notnull()]\ndf_script['id'] = df_script['id'].astype(int)",
          " Preprocessing\n# Ensure no Null values for character_id\ndf_script = df_script[~df_script[\"character_id\"].isnull()]",
          "Filter out characters that are not lines\ndf_characters = df_characters[df_characters['character_id'].isin(df_script['character_id'])]",
          "Remove scripts that have invalid characters and locations\ndf_script_cleaned = df_script[df_script['character_id'].isin(df_characters['id'])]\ndf_script_cleaned = df_script_cleaned[df_script_cleaned['location_id'].isin(df_locations['id'])]",
          "Filter out any rows missing a location, character, or raw text\ndf_script = df_script[\n    df_script.raw_location_id.apply(lambda x: not pd.isnull(x)) &\n    df_script.raw_character_id.apply(lambda x: not pd.isnull(x)) &\n    df_script.raw_text.apply(lambda x: type(x) != float) # Ensure that the text column is a string\n]",
          "Filter out lines that have no character\ndf_script = df_script[df_script['character_id'] != 2]",
          "filter out the \"bad\" data\ndf_script = df_script[~df_script.character_id.isna()]\ndf_script = df_script[~df_script.location_id.isna()]",
          "Filter out the rows in df_script that do not contain a character_id in df_characters.",
          "Remove problematic entries\ndf_script = df_script[df_script['character_id'].isin(df_characters['id'])].reset_index(drop=True)",
          "Remove string descriptions for scripts with non-alphanumeric IDs\ndf_script = df_script[df_script['id'].apply(lambda x: x.isnumeric())]",
          "Ensure the dataframe (df_script) has the character_id, location_id\ndf_script = df_script[~(df_script.is_na() == True)]",
          "Remove unneeded rows\ndf_script = df_script[\n    (df_script['character_id'] != 2) & (df_script['character_id'] != 3)\n].reset_index(inplace=False, drop=True)",
          "# Filter the lines that have a location\ndf_script_location = df_script[df_script['raw_location_text'].notnull()]",
          "# Filter English lines\ndf_script_en = df_script[df_script['raw_character_text'].isin(df_characters[df_characters['character_id'] > 0]['character_name'])].copy()",
          "Remove location IDs that don't match with any location in df_locations\nvalid_location_ids = set(df_locations.id)",
          "Remove corrupt data\ndf_script = df_script[df_script['character_id'].isin(df_characters['id'])]\ndf_script = df_script[df_script['location_id'].isin(df_locations['id'])]",
          " Remove the values with missing features 'character_id'\ndf_script = df_script[df_script['character_id'].notna()].reset_index(inplace=False, drop=True)"
         ],
         "marker": {
          "opacity": 0.5,
          "size": 5
         },
         "mode": "markers+text",
         "name": "183_Filtering and cleaning data in df_script and df_characters",
         "text": [
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          ""
         ],
         "textfont": {
          "size": 12
         },
         "type": "scattergl",
         "x": [
          5.55844259262085,
          5.499941349029541,
          5.172438621520996,
          5.501599311828613,
          6.0254411697387695,
          5.049269199371338,
          5.663146495819092,
          6.032680988311768,
          5.720562934875488,
          5.797931671142578,
          5.290473937988281,
          5.573608875274658,
          5.093381404876709,
          5.4657392501831055,
          6.356026649475098,
          6.264458179473877,
          5.395233631134033,
          4.849379062652588,
          5.530888080596924
         ],
         "y": [
          6.708242416381836,
          7.163056373596191,
          6.462331771850586,
          7.074036121368408,
          7.872938632965088,
          7.194538116455078,
          6.882369518280029,
          7.6285080909729,
          6.961370944976807,
          7.503381729125977,
          7.455796241760254,
          7.309889793395996,
          6.796947002410889,
          6.795627117156982,
          7.697926044464111,
          8.184761047363281,
          6.855886936187744,
          7.009029388427734,
          6.932751655578613
         ]
        },
        {
         "hoverinfo": "text",
         "hovertext": [
          "Filter the columns jedi_order and species",
          " Remove the special value lines, we will not use them in this analysis",
          "Filter columns from dataset",
          "Filter out wrong sources",
          "Filtering necessaary columns for further processing and analysis",
          "Select columns for analysis",
          "Check all columns",
          "Filters",
          "select the fields important for this analysis",
          "Filtering datasets.",
          "Get only a few columns for the purpose of this analysis",
          "Filtering Data for Analysis\n# ",
          "Filtering the data for better modelling",
          " Select interesting columns",
          " Using the bounding box data to filter out only 4-sided boxes to be displayed",
          "Specify the columns that are useful in the context of this analysis",
          "Select only the columns we need",
          "Data preparation - this cell fixes the types of the columns and filters the dataframe by date",
          "Filtering the columns to keep only those which would be useful for modeling and analysis"
         ],
         "marker": {
          "opacity": 0.5,
          "size": 5
         },
         "mode": "markers+text",
         "name": "184_Filtering and Analysis of Columns",
         "text": [
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          ""
         ],
         "textfont": {
          "size": 12
         },
         "type": "scattergl",
         "x": [
          9.4373197555542,
          10.464301109313965,
          9.501774787902832,
          9.96678352355957,
          9.906302452087402,
          9.689469337463379,
          9.860593795776367,
          9.83719539642334,
          10.437570571899414,
          10.542850494384766,
          9.911975860595703,
          10.540762901306152,
          10.338138580322266,
          9.856952667236328,
          9.306652069091797,
          10.073317527770996,
          9.568138122558594,
          9.14691162109375,
          9.600292205810547
         ],
         "y": [
          1.4498158693313599,
          2.085059881210327,
          1.090491771697998,
          1.9435502290725708,
          1.3911458253860474,
          0.9402006268501282,
          -0.5764502882957458,
          1.6425206661224365,
          1.1600315570831299,
          0.9176015853881836,
          1.1073259115219116,
          1.2921196222305298,
          1.3681588172912598,
          0.9700611233711243,
          1.5654085874557495,
          1.1495648622512817,
          0.7813979983329773,
          1.3391320705413818,
          1.6360224485397339
         ]
        },
        {
         "hoverinfo": "text",
         "hovertext": [
          " Let's view the first few rows of each dataframe to understand their structure and contents.",
          "Let's start by printing the first few rows of each DataFrame to understand our data.",
          "Let's explore the first few rows of each dataframe to get an idea of what the data looks like.",
          "Let's display the first few rows of each dataframe to understand the data better.",
          "Let's display the first few rows of each dataframe to understand their structure.",
          "Let's print the first couple of rows of each dataframe to see what we're working with.",
          "To get a quick feel of the data in each of the DataFrames, we can display the first few rows of each DataFrame using the `head()` method.",
          "We'll print the first 3 rows of each dataframe to have a look at what we're dealing with.",
          "Let's display the first few lines of each dataframe to understand their structure.",
          "Let's print the first few rows of each Dataframe to understand their structure and available columns.",
          "Let's start by displaying the first few lines of each dataframe to get a sense of how the data is structured.",
          "Let's print the first 2 rows of these DataFrames to get an idea of their structure.",
          "Let's display the first few lines of each of these DataFrames to understand their structure and contents.",
          "Let's start by displaying the first few rows of each dataframe to understand their structure and content.",
          "Let's display the first few rows of each of these DataFrames to better understand their structure and the data they contain.",
          "let's display the firt few rows of each dataframe to understand its structure.",
          "Let's display the first few rows of each dataframe to understand their structure and contents.",
          "Let's display the first few lines of each dataframe to understand their structure and content better.",
          "Let's display the first few rows of each of these DataFrames to understand their structure and content."
         ],
         "marker": {
          "opacity": 0.5,
          "size": 5
         },
         "mode": "markers+text",
         "name": "185_Understanding the structure of data frames by printing the first few rows",
         "text": [
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          ""
         ],
         "textfont": {
          "size": 12
         },
         "type": "scattergl",
         "x": [
          9.773731231689453,
          11.318394660949707,
          11.455526351928711,
          10.944750785827637,
          10.223155975341797,
          11.07883358001709,
          11.672072410583496,
          10.850523948669434,
          10.285033226013184,
          10.501626968383789,
          10.207342147827148,
          9.998678207397461,
          10.33022403717041,
          10.487278938293457,
          10.418840408325195,
          10.243401527404785,
          10.476820945739746,
          10.979951858520508,
          10.325685501098633
         ],
         "y": [
          -8.644840240478516,
          -8.5941162109375,
          -7.359925270080566,
          -8.607101440429688,
          -9.001121520996094,
          -8.155198097229004,
          -8.220954895019531,
          -8.638076782226562,
          -8.056989669799805,
          -8.8284912109375,
          -8.436867713928223,
          -9.047009468078613,
          -8.07597827911377,
          -8.403428077697754,
          -8.736804008483887,
          -8.737701416015625,
          -8.966974258422852,
          -8.178866386413574,
          -8.767048835754395
         ]
        },
        {
         "hoverinfo": "text",
         "hovertext": [
          "we reset the index inplace and drop the old index column at the same time",
          "we want to reset the index of the returned DataFrame",
          "Code to reset the index of the dataframes and drop the old index column",
          "We use 'reset_index(inplace=False, drop=True)' to reset the index of the DataFrame without inserting it as a column and dropping the current index.",
          " Applying reset_index(inplace=False, drop=True) to the pandas dataframes",
          "NOTE: The reset_index(inplace=False, drop=True) is necessary to prevent the automatic creation of a new index column.",
          "Setting the index after resetting it with Pandas.",
          "WARNING: It is bad practice to use inplace=True and assigning to the same variable, as this might lead to unexpected behavior.",
          " Add index to script dataframe\ndf_script.reset_index(inplace=False, drop=True)",
          "It's actually recommended to create the indexes without using inplace=False, as it is deprecated in the latest version of pandas.",
          " There was an error in the code. The \"inplace\" parameter doesn't exist for the \"reset_index\" method.",
          "Make sure we always call `reset_index` with `inplace=False` and ignore the warning",
          "Reset index for consistency",
          " We need to \"reset_index(inplace=False, drop=True)\" to remove the new index that pandas creates automatically.",
          "`reset_index(inplace=False, drop=True)` is unnecessary",
          "Dropping the index again to be safe",
          "added index reset and inplace variable",
          " cleaned data (removed 'number' column, since it's already the index)",
          "If the `inplace` parameter is `False`, resets the index of the DataFrame in a non-destructive manner"
         ],
         "marker": {
          "opacity": 0.5,
          "size": 5
         },
         "mode": "markers+text",
         "name": "186_Resetting index inplace and dropping old index column",
         "text": [
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          ""
         ],
         "textfont": {
          "size": 12
         },
         "type": "scattergl",
         "x": [
          8.641214370727539,
          8.524808883666992,
          8.05410385131836,
          8.12084674835205,
          8.271844863891602,
          8.269372940063477,
          8.542987823486328,
          9.351022720336914,
          7.374123573303223,
          7.991169452667236,
          8.940046310424805,
          8.579032897949219,
          8.497906684875488,
          8.028030395507812,
          8.584161758422852,
          8.297419548034668,
          8.73495864868164,
          8.492259979248047,
          8.554099082946777
         ],
         "y": [
          1.5038217306137085,
          0.49675145745277405,
          1.1332062482833862,
          0.7920514941215515,
          0.6584241390228271,
          1.139543056488037,
          0.6495842337608337,
          1.3965226411819458,
          1.6239758729934692,
          0.7291496396064758,
          1.2356036901474,
          1.2358819246292114,
          1.2776552438735962,
          0.6895223259925842,
          1.1173949241638184,
          1.4440581798553467,
          1.102156400680542,
          1.2431774139404297,
          0.8674458861351013
         ]
        },
        {
         "hoverinfo": "text",
         "hovertext": [
          "Check the dataframes shape\ndf_characters.shape, df_locations.shape, df_script.shape, df_episodes.shape",
          "Inspect dataframe shapes\ndf_characters.shape, df_locations.shape, df_script.shape, df_episodes.shape",
          " Check if shape has changed\ndf_characters.shape, df_locations.shape, df_script.shape, df_episodes.shape",
          "Check the data shape\ndf_characters_shape = df_characters.shape\ndf_locations_shape = df_locations.shape\ndf_script_shape = df_script.shape\ndf_episodes_shape = df_episodes.shape",
          "Inspect dataframe shapes\ndf_characters.shape, df_locations.shape, df_script.shape, df_episodes.shape",
          "Check the number of rows in each data frame\ndf_shape = {\n    \"Episodes\": df_episodes.shape,\n    \"Script\": df_script.shape,\n    \"Characters\": df_characters.shape,\n    \"Locations\": df_locations.shape\n}\n\ndf_shape",
          "Check the number of lines, characters, locations and episodes\ndf_script.shape[0], df_characters.shape[0], df_locations.shape[0], df_episodes.shape[0]",
          "Check dataframes shape\ndf_characters.shape, df_locations.shape, df_script.shape, df_episodes.shape",
          "Check the shape of each dataframe\ndf_characters.shape, df_locations.shape, df_script.shape, df_episodes.shape",
          "Check the shape of the dataframes\ndf_characters.shape, df_locations.shape, df_script.shape, df_episodes.shape",
          "Check the shape of each dataframe\ndf_characters.shape, df_locations.shape, df_script.shape, df_episodes.shape",
          "Check dataframe shapes\ndf_characters.shape, df_locations.shape, df_script.shape, df_episodes.shape",
          "Check the number of rows and columns\ndf_characters.shape, df_locations.shape, df_script.shape, df_episodes.shape",
          "Check the data shapes\ndf_characters.shape, df_locations.shape, df_script.shape, df_episodes.shape",
          "Check the number of rows and the column names of the episodes dataframe\ndf_episodes.shape, df_episodes.columns",
          "Check the dataframe shapes\ndf_characters.shape, df_locations.shape, df_script.shape, df_episodes.shape",
          "Check the size & header of each data\ndf_characters.shape, df_locations.shape, df_script.shape, df_episodes.shape",
          " Check the number of rows and columns for each dataframe\ndf_characters.shape, df_locations.shape, df_script.shape, df_episodes.shape"
         ],
         "marker": {
          "opacity": 0.5,
          "size": 5
         },
         "mode": "markers+text",
         "name": "187_Checking Dataframe Shapes",
         "text": [
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          ""
         ],
         "textfont": {
          "size": 12
         },
         "type": "scattergl",
         "x": [
          0.15863919258117676,
          -0.4650576710700989,
          0.26552829146385193,
          -0.3522270917892456,
          -0.22415247559547424,
          0.6652081608772278,
          0.6662386655807495,
          0.19495250284671783,
          0.4612973928451538,
          0.35997843742370605,
          0.5731441378593445,
          0.07850214838981628,
          0.540228545665741,
          0.142035573720932,
          1.440073013305664,
          0.13900640606880188,
          0.3126280605792999,
          1.0062083005905151
         ],
         "y": [
          0.03606076166033745,
          -0.16227029263973236,
          -0.12115063518285751,
          0.05465313047170639,
          -0.3020690083503723,
          -0.09222961217164993,
          0.37418878078460693,
          0.005779350642114878,
          0.3023553490638733,
          0.042526040226221085,
          0.5012946128845215,
          0.1660792976617813,
          0.3380357623100281,
          0.10173171758651733,
          1.0656033754348755,
          0.006439080461859703,
          -0.25522273778915405,
          0.29816073179244995
         ]
        },
        {
         "hoverinfo": "text",
         "hovertext": [
          " Display first 5 characters of the dataframe\ndf_script.head()",
          "Head displays the first 5 rows of the dataframe\ndf_characters.head()",
          " Display the first five rows of the characters DataFrame\ndf_characters.head()",
          " Display the first five rows of the characters dataframe\ndf_characters.head()",
          "Display first five rows of the characters dataframe\ndf_characters.head()",
          "Display first 5 rows from each dataframe\ndf_characters.head(5)",
          " Display first 5 rows of the characters DataFrame\ndf_characters.head()",
          "Display the first five rows of the characters dataframe\ndf_characters.head()",
          "Display first 5 rows of characters dataframe\ndf_characters.head()",
          "Display the first five rows of the characters dataframe\ndf_characters.head()",
          " Display the first five rows of the characters dataframe\ndf_characters.head()",
          "Display the first five rows of the characters dataframe\ndf_characters.head()",
          "Display first 5 rows of characters dataframe\ndf_characters.head()",
          " Display first 5 rows of df_characters dataframe\ndf_characters.head()",
          "Display first 5 rows of characters dataframe\ndf_characters.head()",
          "Display first 5 rows of characters dataframe\ndf_characters.head()",
          "Display the first five rows of the characters dataframe\ndf_characters.head()",
          " Display the first five rows of the dataframe\ndf_characters.head()"
         ],
         "marker": {
          "opacity": 0.5,
          "size": 5
         },
         "mode": "markers+text",
         "name": "188_Displaying first five rows of characters DataFrame",
         "text": [
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          ""
         ],
         "textfont": {
          "size": 12
         },
         "type": "scattergl",
         "x": [
          -2.7041146755218506,
          -2.3228325843811035,
          -2.8085882663726807,
          -2.9564666748046875,
          -2.6570284366607666,
          -2.860325574874878,
          -2.048703193664551,
          -2.9557125568389893,
          -1.9003171920776367,
          -2.9669172763824463,
          -3.1181423664093018,
          -2.4767608642578125,
          -1.9241834878921509,
          -2.0762081146240234,
          -2.045029640197754,
          -1.8943450450897217,
          -2.983213186264038,
          -2.866224765777588
         ],
         "y": [
          13.112838745117188,
          13.6051664352417,
          12.00450325012207,
          12.054729461669922,
          12.016568183898926,
          13.14995002746582,
          13.426328659057617,
          11.986217498779297,
          13.542267799377441,
          11.910736083984375,
          11.953974723815918,
          12.101655960083008,
          13.150205612182617,
          13.107969284057617,
          13.492911338806152,
          13.288399696350098,
          11.870678901672363,
          12.60501766204834
         ]
        },
        {
         "hoverinfo": "text",
         "hovertext": [
          "# Display a few rows of the characters dataframe\ndf_characters.head()",
          "# Shows the first entries of the characters dataframe\ndf_characters.head()",
          "# Display the first rows of the characters dataframe\ndf_characters.head()",
          "# Display the first few rows of the characters dataframe\ndf_characters.head()",
          "# Display the first few columns\ndf_characters.head()",
          "\n# Display the first few rows of the dataframe\ndf_characters.head()",
          "\n# Display the first few rows of the character dataframe\ndf_characters.head()",
          "# Display the first few rows of the characters dataframe\ndf_characters.head()",
          "# Display the first few rows of the characters DataFrame\ndf_characters.head()",
          "# Display the first few rows of the characters dataframe\ndf_characters.head()",
          "# Showing the first few rows of the dataframes\ndf_characters.head()",
          "Select the relevant columns in the characters dataframe\ndf_characters = df_characters[['id', 'name']]\n\n# Display the first few rows of the dataframe\ndf_characters.head()",
          "# Show first few rows of the characters dataframe\ndf_characters.head()",
          "# Display the first few rows of the dataframe\ndf_characters.head()",
          "# Display the first rows of the characters dataframe\ndf_characters.head()",
          "Add the following code to display the first few rows of the characters dataframe:\nprint(df_characters.head())",
          "# Show the first few rows of the characters DataFrame\ndf_characters.head()",
          "# Display the first few rows of the characters DataFrame\ndf_characters.head()"
         ],
         "marker": {
          "opacity": 0.5,
          "size": 5
         },
         "mode": "markers+text",
         "name": "189_displaying first few rows of characters dataframe",
         "text": [
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          ""
         ],
         "textfont": {
          "size": 12
         },
         "type": "scattergl",
         "x": [
          3.3855581283569336,
          2.280113697052002,
          1.9904123544692993,
          2.3581197261810303,
          1.561598777770996,
          2.256389617919922,
          2.666597366333008,
          2.4540488719940186,
          2.6415762901306152,
          2.439704656600952,
          2.4637551307678223,
          2.5882132053375244,
          2.266277551651001,
          2.2656197547912598,
          2.208430051803589,
          -3.604830026626587,
          2.5292611122131348,
          2.5290493965148926
         ],
         "y": [
          17.914255142211914,
          18.531644821166992,
          17.788537979125977,
          18.01165008544922,
          18.199621200561523,
          18.045312881469727,
          17.855249404907227,
          18.038145065307617,
          17.873403549194336,
          17.988405227661133,
          17.993467330932617,
          17.091331481933594,
          18.339080810546875,
          18.110591888427734,
          17.980548858642578,
          22.429473876953125,
          18.29401969909668,
          17.894132614135742
         ]
        },
        {
         "hoverinfo": "text",
         "hovertext": [
          "check the data\ndf_characters.head()",
          "Check the data\ndf_characters.head()",
          "Check we have the data\ndf_characters.head()",
          "# Check the top of the characters data\ndf_characters.head()",
          "Check a data sample for visual inspection\ndf_characters.head()",
          " Check data samples\ndf_characters.head()",
          "Check data\ndf_characters.head()",
          "Check the data\nprint(df_characters.head())",
          " Check data\ndf_characters.head()",
          "Checking the data\ndf_characters.head()",
          "Check the result\ndf_characters.head()",
          "Check the data\ndf_characters.head()",
          "Check characters info\ndf_characters.head()",
          "Check the character data set\ndf_characters.head()",
          "check the data\ndf_characters.head()",
          "check data\ndf_characters.head()",
          "Checking the head for df_characters",
          "Check data sample\nprint(df_characters.head())"
         ],
         "marker": {
          "opacity": 0.5,
          "size": 5
         },
         "mode": "markers+text",
         "name": "190_Checking Data Samples and Results in df_characters",
         "text": [
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          ""
         ],
         "textfont": {
          "size": 12
         },
         "type": "scattergl",
         "x": [
          5.569390296936035,
          5.741549015045166,
          5.523693561553955,
          6.002219200134277,
          6.0121378898620605,
          5.683660507202148,
          5.596954345703125,
          5.886882781982422,
          5.72899055480957,
          6.007483005523682,
          5.630106449127197,
          5.8137030601501465,
          6.131123065948486,
          5.4505815505981445,
          5.641472816467285,
          5.545152187347412,
          6.465177059173584,
          5.856611728668213
         ],
         "y": [
          13.065381050109863,
          13.096458435058594,
          12.545300483703613,
          13.056063652038574,
          14.152493476867676,
          13.653563499450684,
          13.031697273254395,
          12.757806777954102,
          13.347256660461426,
          13.42436695098877,
          13.032526969909668,
          13.030313491821289,
          13.87370491027832,
          13.306937217712402,
          12.90576171875,
          13.28600025177002,
          13.847557067871094,
          12.794646263122559
         ]
        },
        {
         "hoverinfo": "text",
         "hovertext": [
          "Remove unnecesasry columns",
          "  - Remove invalid entries",
          " Remove unncessary information",
          "Dropping columns with no useful data",
          "Remove unneeded columns",
          "Remove unwanted columns",
          "Remove the rows which have no dialogue, and remove the unuseful columns",
          "Remove useless columns.",
          " Filter out unnecessary columns and rows.",
          "Remove potentially problematic rows",
          "Remove weird columns without a name",
          "Select the columns of interest and remove any potential NAs",
          "Remove the invalid rows where the character data is incorrect.",
          " Remove unwanted columns, convert columns types, etc.",
          "Remove unecessary columns",
          " Drop the first column, which is not needed",
          "Drop null columns and trim whitespaces",
          "Remove some extra columns in the characters table"
         ],
         "marker": {
          "opacity": 0.5,
          "size": 5
         },
         "mode": "markers+text",
         "name": "191_Data Cleaning and Column Filtering",
         "text": [
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          ""
         ],
         "textfont": {
          "size": 12
         },
         "type": "scattergl",
         "x": [
          9.875850677490234,
          9.979019165039062,
          10.69473934173584,
          9.380144119262695,
          9.407044410705566,
          9.437067985534668,
          9.55563735961914,
          9.713784217834473,
          9.328863143920898,
          9.394506454467773,
          9.36997127532959,
          8.885696411132812,
          10.464569091796875,
          9.917757987976074,
          9.65466022491455,
          9.065191268920898,
          9.605647087097168,
          9.511517524719238
         ],
         "y": [
          2.3279078006744385,
          2.9242634773254395,
          2.822251081466675,
          1.8147265911102295,
          2.3674612045288086,
          2.1695621013641357,
          3.013424873352051,
          2.3113486766815186,
          2.0688729286193848,
          2.568535089492798,
          2.464430093765259,
          2.2967991828918457,
          3.856450319290161,
          2.140615463256836,
          2.369166612625122,
          1.818607211112976,
          1.9715625047683716,
          3.2031190395355225
         ]
        },
        {
         "hoverinfo": "text",
         "hovertext": [
          "Show the first 5 rows of each dataframe to confirm data has been properly imported\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()",
          "Check the first 5 rows of each dataframe\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()",
          "Check the first 5 rows of each dataframe\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()",
          "Check the first 5 rows of each dataframe\nprint(df_characters.head())\nprint(df_locations.head())\nprint(df_script.head())\nprint(df_episodes.head())",
          " Check the first 5 characters of each dataframe\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()",
          "Check first 5 lines of each dataframe\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()",
          " Check first 5 rows of each dataframe\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()",
          " Check the first 5 rows of each dataframe\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()",
          " Check the first 5 rows of each of the 4 dataframes\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()",
          "Check the first 5 rows of each DataFrame\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()",
          "Check the first 5 rows of each DataFrame\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()",
          "Check the first 5 rows of each DataFrame\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()",
          " Check the first five rows of each dataframe\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()",
          "Check the first 5 rows of each DataFrame\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()",
          "Check the first 5 rows of each dataframe\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()",
          " Check the first 5 rows of each dataframe\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()",
          "Check first 5 rows of each dataframe\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()",
          " Check the first 5 rows of each DataFrame\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()"
         ],
         "marker": {
          "opacity": 0.5,
          "size": 5
         },
         "mode": "markers+text",
         "name": "192_Checking first 5 rows of each dataframe and confirming data import",
         "text": [
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          ""
         ],
         "textfont": {
          "size": 12
         },
         "type": "scattergl",
         "x": [
          -4.144882678985596,
          -5.025075912475586,
          -4.692395210266113,
          -4.449470043182373,
          -4.901224613189697,
          -4.743624687194824,
          -4.903048515319824,
          -4.6879191398620605,
          -4.854001522064209,
          -4.631129264831543,
          -4.536489963531494,
          -4.891983985900879,
          -4.797091007232666,
          -4.723663330078125,
          -4.804732322692871,
          -4.819333553314209,
          -4.690319061279297,
          -4.697057723999023
         ],
         "y": [
          8.343452453613281,
          8.735366821289062,
          8.729379653930664,
          8.526107788085938,
          8.919975280761719,
          9.096457481384277,
          9.044684410095215,
          8.954652786254883,
          9.008330345153809,
          8.919793128967285,
          8.598215103149414,
          8.933364868164062,
          9.067002296447754,
          8.725685119628906,
          8.723670959472656,
          8.690963745117188,
          9.198224067687988,
          8.833013534545898
         ]
        },
        {
         "hoverinfo": "text",
         "hovertext": [
          "check the first few rows of the script dataframe\ndf_script.head()",
          "Check the first 2 rows of the dataset\nprint(df_script.head(2))",
          "Check the first few rows of the dataframe\ndf_script.head()",
          "Check the contents of the first few rows of the dataframe\nprint(df_script.head())\n\n# Check the number of rows and columns in the dataframe\nprint(df_script.shape)",
          "Check the first rows of the dataset `df_script` (to identify common columns and column names)",
          "Check the first few rows of the df_script dataframe\ndf_script.head()",
          "Check the first rows of the dataframe and its datatypes\ndf_script.head()",
          "Checking the first 5 rows of the script dataset\ndf_script.head()",
          "Check the first rows of the first dataset (the script)\ndf_script.head()",
          "Inspect the first 5 rows of the dataset\ndf_script.head()",
          " Explore the structure and contents of the script dataframe\nprint(f\"Number of rows {df_script.shape[0]} and columns {df_script.shape[1]}\")\ndf_script.head()",
          "Checking the first few rows of the data.\ndf_script.head()",
          "Checking the first few rows of the `df_script` DataFrame to understand its structure and contents.\ndf_script.head()",
          "Check the first couple of rows of the dataframe\ndf_script.head()",
          "Quick inspection of first rows of df_script DataFrame\ndf_script.head()",
          "Check the dataframe shape and first few rows for script dataframe\nprint(df_script.shape)\ndf_script.head()",
          "Check the first rows\ndf_script.head()",
          "Check the first 5 rows of the dataset\ndf_script.head()"
         ],
         "marker": {
          "opacity": 0.5,
          "size": 5
         },
         "mode": "markers+text",
         "name": "193_Dataframe Exploration",
         "text": [
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          ""
         ],
         "textfont": {
          "size": 12
         },
         "type": "scattergl",
         "x": [
          3.199401378631592,
          3.176478147506714,
          3.38039493560791,
          3.5266926288604736,
          3.3277053833007812,
          3.4469354152679443,
          3.423588275909424,
          2.6029038429260254,
          3.1386799812316895,
          2.9924445152282715,
          4.724021911621094,
          3.0622012615203857,
          3.6207375526428223,
          3.5680549144744873,
          2.959557294845581,
          4.233222007751465,
          3.01983642578125,
          2.830557107925415
         ],
         "y": [
          -5.181175231933594,
          -4.314633846282959,
          -5.222743511199951,
          -4.955911636352539,
          -4.423064708709717,
          -5.039958477020264,
          -5.13944673538208,
          -4.717493057250977,
          -4.684614181518555,
          -4.467355251312256,
          -5.778505802154541,
          -4.927064418792725,
          -5.480001926422119,
          -4.916722297668457,
          -6.081707000732422,
          -5.150494575500488,
          -4.860547065734863,
          -4.597498416900635
         ]
        },
        {
         "hoverinfo": "text",
         "hovertext": [
          "%load_ext autoreload\n%autoreload 2",
          "Load the custom module for this problem set.",
          "%load_ext autoreload\n%autoreload 2",
          "Set the global parameters for the notebook.",
          "Set notebook preferences",
          "Place the dataset files in a 'data' folder in the same directory as this notebook.",
          "We'll also use the following configuration in this notebook:",
          "Change this to the path of the cloned repo on your machine.\nPATH = \"/content/Springboard-Capstone-Three\"",
          " Pretend to run the importing of data and keep going with the notebook",
          "This will allow the visuals to be displayed in the notebook.",
          "In case of reopening Jupyter notebook, we will reload the data without the need to run the entire notebook",
          "For more details, check the documentation folder within the project folder.",
          "Add any additional libraries and set config parameters here.",
          "Optional; restart the kernels to be sure that changes are picked up when the notebook is re-run.",
          "Create a variable to freeze so we don't run the entire notebook in one go.",
          "%reload_ext autoreload\n%autoreload 2",
          "Add your paths accordingly, as seen below.",
          "# Turn off notebook package\n%reload_ext autoreload\n%autoreload 2"
         ],
         "marker": {
          "opacity": 0.5,
          "size": 5
         },
         "mode": "markers+text",
         "name": "194_Autoreload in Jupyter notebooks",
         "text": [
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          ""
         ],
         "textfont": {
          "size": 12
         },
         "type": "scattergl",
         "x": [
          15.643259048461914,
          15.141090393066406,
          15.537074089050293,
          17.010356903076172,
          17.8951416015625,
          15.606191635131836,
          16.622568130493164,
          15.7114839553833,
          15.951014518737793,
          17.639286041259766,
          17.236818313598633,
          15.341059684753418,
          15.488213539123535,
          17.065696716308594,
          16.59588623046875,
          15.764695167541504,
          16.14027976989746,
          16.331653594970703
         ],
         "y": [
          1.8245055675506592,
          2.9289748668670654,
          1.878133773803711,
          2.6758904457092285,
          2.854459285736084,
          1.6215412616729736,
          2.76713228225708,
          3.6616005897521973,
          2.421440362930298,
          2.937918186187744,
          2.415083169937134,
          3.4854745864868164,
          3.2569665908813477,
          2.729177236557007,
          2.147728443145752,
          2.1886110305786133,
          3.671135187149048,
          2.2450578212738037
         ]
        },
        {
         "hoverinfo": "text",
         "hovertext": [
          "Show head of characters dataframe\ndf_characters.head()",
          " Show head of the characters dataframe\ndf_characters.head()",
          " Show head of characters dataframe\ndf_characters.head()",
          "Display head of characters dataframe",
          "Show head of characters table\ndf_characters.head()",
          "Show the head of the characters dataframe\ndf_characters.head()",
          " Show the head of the characters dataframe\ndf_characters.head()",
          "View head of the character dataframe\ndf_characters.head()",
          "Show head of characters dataframe\ndf_characters.head()",
          "Show head of the characters dataframe\ndf_characters.head()",
          " Show head of the characters dataframe\ndf_characters.head()",
          "Show the head of the characters dataframe\ndf_characters.head()",
          "Show head of the characters dataframe\ndf_characters.head()",
          "Head of characters dataframe\ndf_characters.head()",
          " Show head of characters dataframe",
          " Show head of characters DataFrame",
          " Displaying the head of the Characters dataframe to understand the data",
          "Get the head of the characters dataframe"
         ],
         "marker": {
          "opacity": 0.5,
          "size": 5
         },
         "mode": "markers+text",
         "name": "195_Displaying head of characters DataFrame",
         "text": [
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          ""
         ],
         "textfont": {
          "size": 12
         },
         "type": "scattergl",
         "x": [
          8.433334350585938,
          8.295862197875977,
          8.459592819213867,
          7.39912223815918,
          7.616130828857422,
          8.133378982543945,
          8.326552391052246,
          7.95024299621582,
          8.499618530273438,
          8.636685371398926,
          8.438288688659668,
          8.177203178405762,
          8.42858600616455,
          8.540762901306152,
          7.88391637802124,
          7.927496433258057,
          7.571930408477783,
          7.690132141113281
         ],
         "y": [
          17.97725486755371,
          17.830076217651367,
          17.972463607788086,
          17.980318069458008,
          17.59122657775879,
          17.613481521606445,
          17.884843826293945,
          17.754867553710938,
          17.85138702392578,
          18.190990447998047,
          17.731281280517578,
          17.708656311035156,
          17.716678619384766,
          18.149070739746094,
          17.880449295043945,
          17.888803482055664,
          17.748764038085938,
          17.31453514099121
         ]
        },
        {
         "hoverinfo": "text",
         "hovertext": [
          "Set pandas to display all columns in dataframes\npd.set_option('display.max_columns', None)",
          "Show all columns in pandas\npd.set_option('display.max_columns', None)",
          "Set pandas to display all columns for dataframes\npd.set_option('display.max_columns', None)",
          " Use pandas display option to show all the columns when displaying the dataframes\n# Setting the option affects all dataframes throughout the notebook\npd.set_option('display.max_columns', None)",
          " Set Pandas to display all columns\npd.set_option('display.max_columns', None)",
          " We will also set the max_columns option of pandas so that we can see all columns while displaying the DataFrames.",
          "Set up Pandas to show all columns when displaying DataFrames\npd.set_option('display.max_columns', None)",
          "Set pandas to show all columns in head()\npd.set_option('display.max_columns', None)",
          "Set the `display.max_columns` option in Pandas to `None` to show all columns in DataFrames\npd.set_option('display.max_columns', None)",
          "Set the dataframe display option to show all columns for visibility\npd.set_option('display.max_columns', None)",
          "Allow pandas to display all columns, and provide autocomplete scoring based on column type\npd.set_option('display.max_columns', None)\npd.set_option('display.memory_usage', True)",
          "Set pandas to show all the columns in the dataframe\npd.set_option('display.max_columns', None)",
          " option in pandas to display all columns in outputs\npd.set_option('display.max_columns', None)",
          " Set the option to display all columns of the pandas dataframe\npd.set_option('display.max_columns', None)",
          "# Set Pandas to display all of the columns\npd.set_option('display.max_columns', None)",
          " Configure pandas to display all columns when showing DataFrames\npd.set_option('display.max_columns', None)",
          "Setting pandas to show all columns when .head() is called on a dataframe\npd.set_option('display.max_columns', None)"
         ],
         "marker": {
          "opacity": 0.5,
          "size": 5
         },
         "mode": "markers+text",
         "name": "196_Setting display.max_columns option in pandas to show all columns in DataFrames",
         "text": [
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          ""
         ],
         "textfont": {
          "size": 12
         },
         "type": "scattergl",
         "x": [
          20.50905990600586,
          21.19776153564453,
          20.856992721557617,
          21.4255428314209,
          21.15508460998535,
          21.66586685180664,
          20.54848289489746,
          20.998136520385742,
          21.054948806762695,
          20.81781578063965,
          21.668195724487305,
          20.84199333190918,
          20.874778747558594,
          21.073911666870117,
          21.491188049316406,
          20.754318237304688,
          20.808507919311523
         ],
         "y": [
          0.5061022639274597,
          -0.09542517364025116,
          0.32774579524993896,
          0.3894447982311249,
          0.6768760681152344,
          0.7369597554206848,
          0.4907950162887573,
          0.5031024813652039,
          0.3113833963871002,
          0.22216877341270447,
          0.5435789227485657,
          0.35246390104293823,
          0.06534682214260101,
          0.4238395392894745,
          0.724433958530426,
          0.36343517899513245,
          0.16705851256847382
         ]
        },
        {
         "hoverinfo": "text",
         "hovertext": [
          "Let's start by looking at the first few rows of each of our datasets.",
          "Now let's take a look at the first few rows of our datasets.",
          "Let's take a look at the first few rows of each dataset to understand what information is available.",
          "Let's take a look at the first few rows of each dataset to understand the data better.",
          "Let's take a look to the columns present in the different datasets.",
          " This dataset especially is quite spicy and is full of joint operations between different data sources!",
          "No we will examine the first 10 rows of the dataset and see what we are dealing with.",
          "First, let me go through the dataset and get to know the various fields and the data it holds.",
          "Let's take a look at the first few rows of each dataset.",
          "Let's take a look at the first few rows of each dataset to understand what kind of data we're working with.",
          " Let's take a look at the first few rows of each dataset.",
          "Take a look at the first 5 rows for all datasets.",
          "Before we proceed, let's take a look at the top few rows of these datasets.",
          "Let's take a look at the first few rows of each dataset.",
          "Let's start by taking a look at the first few rows of each dataset.",
          " Let us take a glance at the data to get a better understanding of the dataset.",
          "Let's have a look at the first 10 rows of each of our datasets."
         ],
         "marker": {
          "opacity": 0.5,
          "size": 5
         },
         "mode": "markers+text",
         "name": "197_Understanding Datasets and Their Information",
         "text": [
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          ""
         ],
         "textfont": {
          "size": 12
         },
         "type": "scattergl",
         "x": [
          15.23115348815918,
          15.318388938903809,
          14.6806640625,
          15.023107528686523,
          15.082709312438965,
          15.469012260437012,
          14.950931549072266,
          15.936622619628906,
          14.632719993591309,
          14.573076248168945,
          14.965017318725586,
          14.63318157196045,
          14.596930503845215,
          14.999103546142578,
          14.85367202758789,
          15.408355712890625,
          15.293773651123047
         ],
         "y": [
          -2.861161947250366,
          -3.1725246906280518,
          -3.2728641033172607,
          -3.622258186340332,
          -2.7767984867095947,
          -3.178175926208496,
          -3.1341676712036133,
          -2.5354740619659424,
          -3.1413562297821045,
          -3.605419397354126,
          -3.431560754776001,
          -3.45951771736145,
          -2.7295725345611572,
          -3.1594300270080566,
          -2.720149517059326,
          -3.236422061920166,
          -3.4113264083862305
         ]
        },
        {
         "hoverinfo": "text",
         "hovertext": [
          "Print the first 5 rows of df_characters\ndf_characters.head()",
          "Print first 5 rows of the data\ndf_characters.head()",
          "Print the first 5 rows of the characters DataFrame\ndf_characters.head()",
          "Print the first 5 rows of the characters dataframe\nprint(df_characters.head())",
          "Print the first 5 rows of the characters DataFrame\ndf_characters.head()",
          "Print the first 5 rows of the characters DataFrame\ndf_characters.head()",
          "Print the first 5 rows of the characters dataframe\ndf_characters.head()",
          "Print the first 5 rows of the characters dataframe\ndf_characters.head()",
          " Print the first 5 elements of the characters dataframe\ndf_characters.head()",
          "Prints the first five rowss of the characters dataframe\ndf_characters.head()",
          "Print the first 5 lines of the dataframe\nprint(df_characters.head())",
          "Print first 5 lines of first data file\nprint(df_characters.head())",
          " Print the first 5 rows of the characters dataframe\ndf_characters.head()",
          " Print the first 5 entries in the characters dataframe\ndf_characters.head()",
          "# Print the first 5 rows of the characters dataframe\ndf_characters.head()",
          "Print the first 5 rows of the characters dataframe\ndf_characters.head()",
          "Print the first 5 rows of the dataframe for easy viewing.\ndf_characters.head()"
         ],
         "marker": {
          "opacity": 0.5,
          "size": 5
         },
         "mode": "markers+text",
         "name": "198_Printing the first 5 rows of a dataframe",
         "text": [
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          ""
         ],
         "textfont": {
          "size": 12
         },
         "type": "scattergl",
         "x": [
          -1.4010837078094482,
          -1.3298062086105347,
          -1.4110076427459717,
          -1.3482081890106201,
          -1.612817406654358,
          -1.3857622146606445,
          -1.3956356048583984,
          -1.5166857242584229,
          -1.575402855873108,
          -1.6239449977874756,
          -0.8724192976951599,
          -0.7624033093452454,
          -1.5036580562591553,
          -1.331589698791504,
          -1.718743085861206,
          -1.5890825986862183,
          -1.6334806680679321
         ],
         "y": [
          11.340380668640137,
          11.343832969665527,
          10.660033226013184,
          10.51684856414795,
          10.696846961975098,
          10.74103832244873,
          10.683196067810059,
          10.593278884887695,
          11.01931381225586,
          10.419857025146484,
          11.287614822387695,
          11.702109336853027,
          10.7203950881958,
          11.222477912902832,
          10.835604667663574,
          10.63630485534668,
          10.464893341064453
         ]
        },
        {
         "hoverinfo": "text",
         "hovertext": [
          "Filter out the lines that are not real dialogues.",
          "Remove non dialogue records for dialogue prediction",
          " Preprocess the script dataset to filter out non-dialogue lines and combine multiple lines from the same character into a single entry.",
          "Filter out non-conversational lines such as scene changes",
          "Remove characters that do not have any speaking lines",
          "Ensure that we only consider spoken lines, and remove the rest.",
          "optional: remove non-spoken lines (if the line is not spoken by the characters)",
          "Filtering out the non-speaking lines",
          "Filter out non-speaking lines",
          "Filter out the non-dialogue meaning lines",
          "Filter out the non-dialogue lines",
          "Filter out non-dialogue lines",
          "Data cleaning since Dan's data set still has mentioned speaker but no spoken words, and no ids line by line",
          "Applying a simple filter to exclude meaningless descriptions, e.g. \"opening sequence\"",
          "Optional: Preprocess the names if not using scripts/lines for filtering the dialogues\n\ndef preprocess(text):\n    return text.lower()",
          " filter only the conversation lines, we will need them for Named Entity Recognition (NER)ruption",
          "Remove the entries with no spoken line and lines than have no character associated"
         ],
         "marker": {
          "opacity": 0.5,
          "size": 5
         },
         "mode": "markers+text",
         "name": "199_Preprocessing script dataset to filter and clean dialogue lines",
         "text": [
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          ""
         ],
         "textfont": {
          "size": 12
         },
         "type": "scattergl",
         "x": [
          9.47889232635498,
          9.447026252746582,
          9.430254936218262,
          9.248828887939453,
          10.198738098144531,
          10.021452903747559,
          10.01823902130127,
          9.923802375793457,
          9.96342945098877,
          9.679439544677734,
          9.683128356933594,
          9.861706733703613,
          9.506614685058594,
          9.659597396850586,
          9.793195724487305,
          9.51087474822998,
          9.898760795593262
         ],
         "y": [
          5.422280788421631,
          4.542057991027832,
          5.472237586975098,
          5.720554351806641,
          5.124086856842041,
          5.2003936767578125,
          5.362707614898682,
          5.445740699768066,
          5.198052883148193,
          5.255465030670166,
          5.125598907470703,
          5.409430980682373,
          5.4583892822265625,
          5.681033611297607,
          5.6881513595581055,
          5.675963401794434,
          4.909952163696289
         ]
        },
        {
         "hoverinfo": "text",
         "hovertext": [
          "Preview the dataframe with the script\nprint(df_script.head())",
          "Preview dataframe with script lines\ndf_script.head()",
          "Show a preview of the dataset\ndf_script.head()",
          "Display a preview of the dataframe pertaining to script data\ndf_script.head()",
          "Preview\ndf_script.head()",
          "Preview the dataset\ndf_script.head()",
          "Preview the script dataframe\ndf_script.head()",
          " Preview data\ndf_script.head()",
          "Preview the script dataframe\ndf_script.head()",
          "Preview the dataset\ndf_script.head()",
          "Preview data\ndf_script.head()",
          "Display a preview of the loaded datasets\ndf_script.head()",
          "Preview the first few entries of the script dataset\ndf_script.head()",
          "Preview the dataframes\ndf_script.head()",
          "Preview the script df\ndf_script.head()",
          "Preview dataframe\ndf_script.head()",
          "Preview data\ndf_script.head()"
         ],
         "marker": {
          "opacity": 0.5,
          "size": 5
         },
         "mode": "markers+text",
         "name": "200_Previewing and displaying data in a script dataframe",
         "text": [
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          ""
         ],
         "textfont": {
          "size": 12
         },
         "type": "scattergl",
         "x": [
          -2.479271173477173,
          -2.2884316444396973,
          -1.7236442565917969,
          -2.225414752960205,
          -2.4417264461517334,
          -1.5517603158950806,
          -2.4788167476654053,
          -2.06022310256958,
          -2.411496639251709,
          -1.548494577407837,
          -2.0936882495880127,
          -1.4216854572296143,
          -1.0642595291137695,
          -2.3615329265594482,
          -2.4845476150512695,
          -2.3138794898986816,
          -2.059400796890259
         ],
         "y": [
          -7.546475887298584,
          -7.605916976928711,
          -7.249566555023193,
          -7.793190002441406,
          -7.252803802490234,
          -7.154710292816162,
          -7.422800540924072,
          -7.139581680297852,
          -7.613246917724609,
          -7.109247207641602,
          -7.2538838386535645,
          -7.292384624481201,
          -7.032025337219238,
          -7.707338809967041,
          -7.415805816650391,
          -7.421130657196045,
          -7.054863452911377
         ]
        },
        {
         "hoverinfo": "text",
         "hovertext": [
          "Display datasets' shapes\nprint(f'characters: {df_characters.shape}, '\n      f'locations: {df_locations.shape}, '\n      f'script: {df_script.shape}, '\n      f'episodes: {df_episodes.shape}')",
          "print(f\"Characters: {df_characters.shape}\")\nprint(f\"Locations: {df_locations.shape}\")\nprint(f\"Script: {df_script.shape}\")\nprint(f\"Episodes: {df_episodes.shape}\")",
          " Display the dataset shapes\nprint(f'Shape of characters dataset: {df_characters.shape}')\nprint(f'Shape of locations dataset: {df_locations.shape}')\nprint(f'Shape of script dataset: {df_script.shape}')\nprint(f'Shape of episodes dataset: {df_episodes.shape}')",
          "Print file shapes\nprint(f'Characters: {df_characters.shape}')\nprint(f'Locations: {df_locations.shape}')\nprint(f'Script: {df_script.shape}')\nprint(f'Episodes: {df_episodes.shape}')",
          "Data Preprocessing\n# First, let's get an idea of what our data looks like\nprint(f\"Characters Shape: {df_characters.shape}\")\nprint(f\"Locations Shape: {df_locations.shape}\")\nprint(f\"Script Shape: {df_script.shape}\")\nprint(f\"Episodes Shape: {df_episodes.shape}\")",
          " Print dataframe shapes\nprint(f\"Characters: {df_characters.shape}\")\nprint(f\"Locations: {df_locations.shape}\")\nprint(f\"Script: {df_script.shape}\")\nprint(f\"Episodes: {df_episodes.shape}\")",
          "Print the dataset shapes\nprint(f'Characters: {df_characters.shape}')\nprint(f'Locations: {df_locations.shape}')\nprint(f'Script lines: {df_script.shape}')\nprint(f'Episodes: {df_episodes.shape}')",
          "View dataframe shape\nprint(f'Characters dataframe shape: {df_characters.shape}')\nprint(f'Locations dataframe shape: {df_locations.shape}')\nprint(f'Script dataframe shape: {df_script.shape}')\nprint(f'Episodes dataframe shape: {df_episodes.shape}')",
          "View shape of datasets\nprint(f\"Characters: {df_characters.shape}\")\nprint(f\"Locations: {df_locations.shape}\")\nprint(f\"Script: {df_script.shape}\")\nprint(f\"Episodes: {df_episodes.shape}\")",
          "Get an idea of the structure of the data\nprint(f'Characters  : {df_characters.shape}')\nprint(f'Locations   : {df_locations.shape}')\nprint(f'Script      : {df_script.shape}')\nprint(f'Episodes    : {df_episodes.shape}')",
          "View dataframe shapes\nprint(f\"Characters: {df_characters.shape}\")\nprint(f\"Locations: {df_locations.shape}\")\nprint(f\"Script: {df_script.shape}\")\nprint(f\"Episodes: {df_episodes.shape}\")",
          "Print the shape and information of the datasets\nprint(f'Shape of characters dataset: {df_characters.shape}')\nprint(f'Shape of locations dataset: {df_locations.shape}')\nprint(f'Shape of script dataset: {df_script.shape}')\nprint(f'Shape of episodes dataset: {df_episodes.shape}')",
          "Inspect data shape\nprint(f'df_characters shape: {df_characters.shape}')\nprint(f'df_locations shape: {df_locations.shape}')\nprint(f'df_script shape: {df_script.shape}')\nprint(f'df_episodes shape: {df_episodes.shape}')",
          " Print dataframes' shape\nprint(f'Characters: {df_characters.shape}')\nprint(f'Locations: {df_locations.shape}')\nprint(f'Script: {df_script.shape}')\nprint(f'Episodes: {df_episodes.shape}')",
          "# Display statues and quantities\nprint('Data statues:')\nprint(f' - Characters: {df_characters.shape[0]}')\nprint(f' - Locations: {df_locations.shape[0]}')\nprint(f' - Script lines: {df_script.shape[0]}')\nprint(f' - Episodes: {df_episodes.shape[0]}')",
          "Looking at the data for the first time\nprint(f\"Characters data shape: {df_characters.shape}\")\nprint(f\"Locations data shape: {df_locations.shape}\")\nprint(f\"Script data shape: {df_script.shape}\")\nprint(f\"Episodes data shape: {df_episodes.shape}\")",
          "Data at a glance\nprint(f'Characters: {df_characters.shape[0]}')\nprint(f'Locations: {df_locations.shape[0]}')\nprint(f'Lines of script: {df_script.shape[0]}')\nprint(f'Episodes: {df_episodes.shape[0]}')"
         ],
         "marker": {
          "opacity": 0.5,
          "size": 5
         },
         "mode": "markers+text",
         "name": "201_Data Shapes and Sizes",
         "text": [
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          ""
         ],
         "textfont": {
          "size": 12
         },
         "type": "scattergl",
         "x": [
          -0.8793206810951233,
          -0.1759149432182312,
          -0.7987713813781738,
          -0.16297107934951782,
          -0.9887515306472778,
          -0.5362626314163208,
          -0.9240672588348389,
          -1.0338325500488281,
          -0.939542293548584,
          -0.5828881859779358,
          -1.1403069496154785,
          -0.8831750154495239,
          -0.6484676003456116,
          -0.7340428829193115,
          -0.4935322403907776,
          -0.887628972530365,
          -0.6417118310928345
         ],
         "y": [
          -2.766098737716675,
          -2.263216495513916,
          -2.5444955825805664,
          -2.408036231994629,
          -2.6883716583251953,
          -2.444685935974121,
          -2.348691940307617,
          -2.279921054840088,
          -2.1669363975524902,
          -2.6228930950164795,
          -2.2330992221832275,
          -2.4010796546936035,
          -2.7167930603027344,
          -2.37258243560791,
          -2.9322590827941895,
          -2.954265832901001,
          -2.382662773132324
         ]
        },
        {
         "hoverinfo": "text",
         "hovertext": [
          "Print the first few lines of each dataframe to get an overview of the data.",
          "View the first few lines of each dataframe to understand the data",
          "Let us begin by displaying the first few lines of each data frame.",
          " Display the first few lines of each dataframe to get a sense of the data",
          " Display the first few lines of each dataframe to understand the data better.",
          " Display the first few lines of each dataframe to get an idea of the kind of information available.",
          " Optionally, you can display the first couple of lines for each of the DataFrames as well.",
          "Display the first few lines of the dataframes to understand the data",
          " Display the first few lines of each dataframe to understand the data",
          "Viewing the first few lines of each of our dataframes to better understand the data",
          " Displaying the first few lines of the dataframes to understand the data better.",
          "Explore the first lines of each dataframe",
          " Displaying the first few lines of each dataframe to get an overview of the data structure",
          "Display the first few lines of each dataframe to understand its structure and contents.",
          "Reading first line of each dataframe",
          "Show the first few lines of the data in each dataframe to understand what we are working with."
         ],
         "marker": {
          "opacity": 0.5,
          "size": 5
         },
         "mode": "markers+text",
         "name": "202_Displaying the first few lines of each dataframe to understand the data better",
         "text": [
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          ""
         ],
         "textfont": {
          "size": 12
         },
         "type": "scattergl",
         "x": [
          12.159794807434082,
          12.098362922668457,
          11.784269332885742,
          12.440454483032227,
          11.879870414733887,
          12.171910285949707,
          11.978960037231445,
          12.060693740844727,
          12.069533348083496,
          12.19855785369873,
          12.116486549377441,
          12.414458274841309,
          11.74159049987793,
          11.836551666259766,
          12.520901679992676,
          11.544816017150879
         ],
         "y": [
          -9.93109130859375,
          -8.883726119995117,
          -8.281036376953125,
          -9.246283531188965,
          -8.505136489868164,
          -8.780359268188477,
          -7.703238010406494,
          -9.067423820495605,
          -9.32262897491455,
          -8.81744384765625,
          -8.41707992553711,
          -8.34535026550293,
          -9.48235034942627,
          -8.595155715942383,
          -8.60512638092041,
          -8.603628158569336
         ]
        },
        {
         "hoverinfo": "text",
         "hovertext": [
          "Filter lines up to 10 words to get rid of long and complex sentences in the character dialogues\ndf_script['word_count'] = df_script['normalized_text'].apply(lambda x: len(x.split()))",
          "Normalize whitespace in columns\nfor col in ['raw_text','speaking_line','normalized_text','word_count']:\n    if df_script[col].dtype == 'object':\n        df_script[col] = df_script[col].apply(lambda x: ' '.join(x.split()))",
          " The scripts are very large, so the loading will take some time\ndf_script['word_count'] = df_script['raw_text'].apply(lambda x: len(x.split()))",
          "Filter characters and dialogues with more than 6 words\ndf_script['word_count'] = df_script['normalized_text'].str.split().apply(len)\ndf_script = df_script[df_script.word_count>=6]\ndf_script.head()",
          "Sort the columns to make the data easier to understand\ndf_script = df_script[[c for c in df_script.columns if c != 'word_count'] + ['word_count']]",
          "Create a dataframe `df_script_unique` with the column `spoken_words` containing unique `spoken_words` and the number of occurrences of these `spoken_words` under the column `count`",
          "Compute the count of words in each line of dialog\ndf_script['word_count'] = df_script['normalized_text'].apply(lambda x: len(x.split()))",
          "Create a new column in df_script that corresponds to the length of each utterance.",
          "Estimate the episode's length based on the number of words in the script\ndf_script['word_count'] = df_script['normalized_text'].apply(lambda x: len(x.split()))",
          " check word count distribution of the utterances\ndf_script['word_count'] = df_script['normalized_text'].str.split().apply(len)",
          "Creating a new column with the number of words\ndf_script['number_of_words'] = df_script['spoken_words'].apply(lambda x: len(x.split()))",
          " create new columns based on existing data\ndf_script['word_count'] = df_script['spoken_words'].str.split().apply(len)",
          " Create an object for counting the words\nword_freq = Counter()\n\n# Loop through the script to count the words\nfor _, row in tqdm(df_script.iterrows(), total=len(df_script)):\n    \n    # Get the lowercase version of the line\n    line = row['raw_text']\n    line = line.lower()\n    \n    # Tokenize the line\n    doc = nlp(line)\n    \n    # Update the word counter\n    word_freq.update([token.text for token in doc if token.is_alpha])",
          "Add column with text length in words\ndf_script['word_count'] = df_script['normalized_text'].str.split().apply(len)",
          "Add a 'word_count' column to the df_script dataframe\ndf_script['word_count'] = df_script['raw_text'].apply(lambda x: len(x.split()))",
          "Estimate minutes required to read each script line\nword_per_minute = 200 # estimation\ndf_script['word_count'] = df_script['spoken_words'].apply(lambda x: len(x.split()))\ndf_script['read_duration'] = df_script['word_count'] / word_per_minute"
         ],
         "marker": {
          "opacity": 0.5,
          "size": 5
         },
         "mode": "markers+text",
         "name": "203_Script Word Count and Length Analysis",
         "text": [
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          ""
         ],
         "textfont": {
          "size": 12
         },
         "type": "scattergl",
         "x": [
          8.910364151000977,
          7.681170463562012,
          9.126604080200195,
          8.382119178771973,
          8.221000671386719,
          8.367545127868652,
          8.740192413330078,
          8.514528274536133,
          8.74328899383545,
          8.723692893981934,
          8.525385856628418,
          8.471429824829102,
          8.817262649536133,
          8.583136558532715,
          8.972987174987793,
          8.66370964050293
         ],
         "y": [
          7.849451065063477,
          7.909180164337158,
          8.528226852416992,
          8.05449104309082,
          7.077698230743408,
          7.821908950805664,
          8.287652015686035,
          7.630112648010254,
          7.698116779327393,
          7.9645256996154785,
          7.730635166168213,
          7.701821804046631,
          8.049162864685059,
          7.977710723876953,
          8.116339683532715,
          8.144490242004395
         ]
        },
        {
         "hoverinfo": "text",
         "hovertext": [
          "Check the structure of the dataset\ndf_script.head()",
          "Quick glance at the dataset\ndf_script.head()",
          "The first 5 scripts in the dataset\ndf_script.head()",
          "List the script dataset to understand its structure\ndf_script.head()",
          "check script_df.head() to understand the dataset",
          " Explore scripts dataset\n\ndf_script.head()",
          "Look at the first couple of rows of all the datasets\ndf_script.head(5)",
          " Quick look at the dataset\ndf_script.head()",
          " Take a look at the first few lines of the dataset\nprint(df_script.head())",
          "Output some useful information about the datasets\nprint(df_script.shape)\ndf_script.head()",
          "Look at some examples from the dataset\ndf_script.head()",
          "Inspect the dataset\ndf_script.head()",
          "An example of the dataset\ndf_script.head()",
          "Information about the transcript dataset\nprint(\"Number of transcript lines:\", len(df_script))\ndf_script.head()",
          "Check the first few rows of the dataset to understand its structure\ndf_script.head()",
          "# Show the first few lines of the dataset to understand its structure\ndf_script.head()"
         ],
         "marker": {
          "opacity": 0.5,
          "size": 5
         },
         "mode": "markers+text",
         "name": "204_Exploring Transcript Dataset and Structures - df_script.head() Examples, Length, and Quick Glance",
         "text": [
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          ""
         ],
         "textfont": {
          "size": 12
         },
         "type": "scattergl",
         "x": [
          4.196939468383789,
          4.794210910797119,
          4.318624496459961,
          4.26977014541626,
          4.035735607147217,
          5.068790912628174,
          4.299890041351318,
          4.874554634094238,
          5.220441818237305,
          5.598226547241211,
          4.413815975189209,
          4.597055912017822,
          4.508571624755859,
          4.95957612991333,
          3.6642446517944336,
          4.052041053771973
         ],
         "y": [
          -3.354888916015625,
          -3.6528306007385254,
          -3.7934365272521973,
          -4.179996013641357,
          -3.5322022438049316,
          -4.114027976989746,
          -3.4549949169158936,
          -3.7586183547973633,
          -3.114201545715332,
          -3.631704568862915,
          -3.8744375705718994,
          -3.6260132789611816,
          -4.199940204620361,
          -3.4523606300354004,
          -4.084744453430176,
          -4.733330249786377
         ]
        },
        {
         "hoverinfo": "text",
         "hovertext": [
          "View the first 10 rows of the characters dataset\ndf_characters.head(10)",
          "Show the first 10 rows of the characters dataframe\ndf_characters.head(10)",
          " Display first 10 rows of the characters dataframe\ndf_characters.head(10)",
          " Show the first 10 rows of the character dataset\ndf_characters.head(10)",
          "Display the first 10 records of the character dataset\ndf_characters.head(10)",
          " 10 first rows\ndf_characters.head(10)",
          "Display the first 10 rows of the characters dataframe\ndf_characters.head(10)",
          " View the first 10 rows of the characters dataframe\ndf_characters.head(10)",
          "Display the first 10 entries of the characters dataframe\ndf_characters.head(10)",
          "Show the first 10 elements of the characters dataframe\nprint('Characters dataframe')\nprint(df_characters.head(10))\nprint('\\n')",
          "Show the first 10 row of the dataframe 'df_characters'\ndf_characters.head(10)",
          " Display the first 10 rows of the characters dataframe\ndf_characters.head(10)",
          "Show first 10 rows of the characters dataframe\ndf_characters.head(10)",
          " Display the first 10 rows of each DataFrame\ndf_characters.head(10)",
          " Show the first 10 rows of the characters dataframe\ndf_characters.head(10)",
          "Print the first 10 rows of the characters dataframe\ndf_characters.head(10)"
         ],
         "marker": {
          "opacity": 0.5,
          "size": 5
         },
         "mode": "markers+text",
         "name": "205_\"Viewing First 10 Rows of Characters Dataframe\"",
         "text": [
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          ""
         ],
         "textfont": {
          "size": 12
         },
         "type": "scattergl",
         "x": [
          0.3145614266395569,
          -0.4658946990966797,
          -0.43643125891685486,
          -0.07643633335828781,
          0.14217695593833923,
          -0.3647958040237427,
          -0.6615201234817505,
          -0.30511584877967834,
          -0.44747447967529297,
          -0.29175227880477905,
          -0.5782489776611328,
          -0.30946433544158936,
          -0.2195017784833908,
          -0.45425617694854736,
          -0.17304956912994385,
          -0.554107129573822
         ],
         "y": [
          15.527434349060059,
          15.46288013458252,
          15.566889762878418,
          15.411613464355469,
          15.877591133117676,
          15.153364181518555,
          15.742877960205078,
          15.579681396484375,
          15.576403617858887,
          15.369938850402832,
          15.375165939331055,
          15.751975059509277,
          15.456586837768555,
          15.549991607666016,
          15.604144096374512,
          15.465311050415039
         ]
        },
        {
         "hoverinfo": "text",
         "hovertext": [
          "Check that the character names have not changed\nassert len(set(df_characters.character_id) - set(df_script.raw_character_text)) == 0",
          "# Functions for later\ndef get_character_name_from_id(char_id):\n    \"\"\"\n    Function to extract the name of a character from his ID\n    \"\"\"\n    return df_characters[df_characters.character_id == char_id]['name'].values[0]\n\ndef get_location_name_from_id(loc_id):\n    \"\"\"\n    Function to extract the name of a location from its ID\n    \"\"\"\n    return df_locations[df_locations.location_id == loc_id]['name'].values[0]",
          "Mappings id <-> name\nchar_id_to_name = dict(df_characters[['id', 'name']].values)\nchar_name_to_id = {v: k for k, v in char_id_to_name.items()}\n\nloc_id_to_name = dict(df_locations[['id', 'name']].values)\nloc_name_to_id = {v: k for k, v in loc_id_to_name.items()}",
          "Create mapping between character name and id\ncharacter_id_mapping = {row['name'].lower(): row['id'] for idx, row in df_characters.iterrows()}",
          "Create dictionary mapping character IDs to character names\ncharacter_id_to_name = {character_id: name for character_id, name in zip(df_characters['id'], df_characters['name'])}",
          " Set up variables for storing the required data\n# Characters\ncharacters = {}\nfor index, row in df_characters.iterrows():\n    char_id = row['id']\n    name = row['name']\n    characters[char_id] = name",
          " Build a mapping between character_id and character_name for easier lookup\ncharacter_id_to_name = df_characters.set_index('character_id')['character_name'].to_dict()",
          "Function to get the character name from a normalized character id\ndef get_character_name(character_id):\n    return (df_characters[df_characters['id'] == character_id]['name'].values[0])",
          "Mapping from location_id to location_name\nlocation_id_to_name = dict(df_locations[['id', 'name']].values)",
          "Setting `character_id` as the index\ndf_characters.set_index('id', inplace=True)\n\n# Let's print the first 5 rows of the characters DataFrame\ndf_characters.head()",
          "Create a dictionary for characters and locations (from id to string)\ncharacters_dict = {}\nlocations_dict = {}",
          "Define the types for pandas\ndf_characters.astype({\n    'id': int,\n    'name': str,\n    'normalized_name': str\n})",
          "Create a dictionary to map character IDs to character names.\ncharacters = dict(zip(df_characters['id'], df_characters['name']))\nlocations = dict(zip(df_locations['id'], df_locations['name']))",
          "Create a mapping between character names and IDs for fast lookup\nchar_id_map = {}\nfor char in tqdm(df_characters.itertuples(), total=len(df_characters)):\n    char_id_map[char.character_name.lower()] = char.id",
          " Create a cast dict\ncast_dict = {}\nfor index, character in df_characters.iterrows():\n    cast_dict[character['id']] = character['name']\n\n# Create a location dict\nlocation_dict = {}\nfor index, location in df_locations.iterrows():\n    location_dict[location['id']] = location['name']",
          " Construct the (id -> name) mapping for the characters\nchar_id2name = df_characters.set_index('id')['name'].to_dict()\n\n# Construct the (id -> name) mapping for the locations\nloc_id2name = df_locations.set_index('id')['name'].to_dict()"
         ],
         "marker": {
          "opacity": 0.5,
          "size": 5
         },
         "mode": "markers+text",
         "name": "206_Mapping character and location IDs to names",
         "text": [
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          ""
         ],
         "textfont": {
          "size": 12
         },
         "type": "scattergl",
         "x": [
          5.831918716430664,
          5.794384479522705,
          6.664548873901367,
          5.712963581085205,
          6.7773966789245605,
          6.079336166381836,
          6.492694854736328,
          6.886087417602539,
          6.003845691680908,
          4.809333801269531,
          7.160739421844482,
          6.393484115600586,
          6.020073890686035,
          5.5113677978515625,
          6.3289666175842285,
          6.420079231262207
         ],
         "y": [
          9.774317741394043,
          9.008952140808105,
          9.005722045898438,
          9.414449691772461,
          9.335502624511719,
          9.74983024597168,
          9.47861385345459,
          9.201642990112305,
          8.512284278869629,
          10.244853019714355,
          8.256025314331055,
          9.315796852111816,
          9.170394897460938,
          9.545417785644531,
          8.934895515441895,
          8.742774963378906
         ]
        },
        {
         "hoverinfo": "text",
         "hovertext": [
          "Display the first few rows for each table\nprint('Characters')\nprint(df_characters.head())\nprint()\nprint('Locations')\nprint(df_locations.head())\nprint()\nprint('Script')\nprint(df_script.head())\nprint()\nprint('Episodes')\nprint(df_episodes.head())",
          "Show all table and column names\nprint(\"\\nCharacters Table\")\nprint(df_characters.dtypes)\nprint(df_characters.head(3))\nprint(\"\\nLocations Table\")\nprint(df_locations.dtypes)\nprint(df_locations.head(3))\nprint(\"\\nScript Table\")\nprint(df_script.dtypes)\nprint(df_script.head(3))\nprint(\"\\nEpisodes Table\")\nprint(df_episodes.dtypes)\nprint(df_episodes.head(3))",
          "Print out all the tables to see their structure\nprint('Characters:')\nprint(df_characters.head())\nprint('\\nLocations:')\nprint(df_locations.head())\nprint('\\nScript:')\nprint(df_script.head())\nprint('\\nEpisodes:')\nprint(df_episodes.head())",
          "\n# Show first rows of the main tables\nprint(\"Characters:\")\nprint(df_characters.head())\nprint(\"\\nLocations:\")\nprint(df_locations.head())\nprint(\"\\nScript:\")\nprint(df_script.head())\nprint(\"\\nEpisodes:\")\nprint(df_episodes.head())",
          "Display each table\nprint('Simpsons Characters')\ndisplay(df_characters.head())\n\nprint('Simpsons Locations')\ndisplay(df_locations.head())\n\nprint('Simpsons Scripts')\ndisplay(df_script.head())\n\nprint('Simpsons Episodes')\ndisplay(df_episodes.head())",
          "Shows the first 10 records for all the tables\nprint(\"Characters\")\nprint(df_characters.head(10))\n\nprint(\"\\nLocations\")\nprint(df_locations.head(10))\n\nprint(\"\\nScript lines\")\nprint(df_script.head(10))\n\nprint(\"\\nEpisodes\")\nprint(df_episodes.head(10))",
          "Check size and structure of each table\nprint(df_characters.head())\nprint(df_locations.head())\nprint(df_script.head())\nprint(df_episodes.head())",
          "\n# Print the first 5 lines of each table\nprint('Characters:')\nprint(df_characters.head())\nprint('\\nLocations:')\nprint(df_locations.head())\nprint('\\nScript:')\nprint(df_script.head())\nprint('\\nEpisodes:')\nprint(df_episodes.head())",
          "Print type and shape of each table\nprint(\"Characters table - \", df_characters.shape)\nprint(\"Locations table - \", df_locations.shape)\nprint(\"Script table - \", df_script.shape)\nprint(\"Episodes table - \", df_episodes.shape)",
          "Print head of each table\nprint(df_characters.head())\nprint(df_locations.head())\nprint(df_script.head())\nprint(df_episodes.head())",
          "heck all tables\nprint(df_characters.head())\n\nprint(df_locations.head())\n\nprint(df_script.head())\n\nprint(df_episodes.head())",
          "Preview for each table\nprint(\"Characters:\")\nprint(df_characters.info())\nprint(df_characters.head())\nprint(\"\\nLocations:\")\nprint(df_locations.info())\nprint(df_locations.head())\nprint(\"\\nScript:\")\nprint(df_script.info())\nprint(df_script.head())\nprint(\"\\nEpisodes:\")\nprint(df_episodes.info())\nprint(df_episodes.head())",
          " Check the first few rows of each table\nprint(df_characters.head())\nprint(df_locations.head())\nprint(df_script.head())\nprint(df_episodes.head())",
          "Check out the schema of each table\nprint(df_characters.head(3))\nprint(df_locations.head(3))\nprint(df_script.head(3))\nprint(df_episodes.head(3))",
          "# show the first few rows of each table\nprint(\"Characters\")\nprint(df_characters.head())\n\nprint(\"\\nLocations\")\nprint(df_locations.head())\n\nprint(\"\\nScript\")\nprint(df_script.head())\n\nprint(\"\\nEpisodes\")\nprint(df_episodes.head())",
          "Let see the first lines of each tables:\nprint(\"\\nSIMPSONS CHARACTERS\")\nprint(df_characters.head())\nprint(\"\\nSIMPSONS LOCATIONS\")\nprint(df_locations.head())\nprint(\"\\nSIMPSONS SCRIPT\")\nprint(df_script.head())\nprint(\"\\nSIMPSONS EPISODES\")\nprint(df_episodes.head())"
         ],
         "marker": {
          "opacity": 0.5,
          "size": 5
         },
         "mode": "markers+text",
         "name": "207_table schema and structure of Simpsons dataset",
         "text": [
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          ""
         ],
         "textfont": {
          "size": 12
         },
         "type": "scattergl",
         "x": [
          -2.3552029132843018,
          -2.3096532821655273,
          -2.020766019821167,
          -2.288733720779419,
          -1.730055332183838,
          -2.1713547706604004,
          -2.2278389930725098,
          -1.6493709087371826,
          -1.4853572845458984,
          -2.249124765396118,
          -2.200218439102173,
          -1.7882369756698608,
          -2.5383317470550537,
          -2.1481387615203857,
          -2.08193039894104,
          -2.270071268081665
         ],
         "y": [
          4.7895283699035645,
          3.5321290493011475,
          3.697180986404419,
          4.08774995803833,
          3.631925344467163,
          3.880091428756714,
          3.215773105621338,
          4.1468892097473145,
          2.7314624786376953,
          3.3556594848632812,
          2.5640909671783447,
          3.8760998249053955,
          3.933544874191284,
          3.466430425643921,
          4.023022174835205,
          3.994532823562622
         ]
        },
        {
         "hoverinfo": "text",
         "hovertext": [
          "Display the first few rows of the dataframe\ndf_characters.head()",
          "display first few rows of the dataframe\ndf_characters.head()",
          " Display the first few rows of the dataframe\ndf_characters.head()",
          " Display the first few rows of the dataframe\ndf_characters.head()",
          "Displaying the first few rows of the dataframe\ndf_characters.head()",
          " Display the first few rows of the dataframe\ndf_characters.head()",
          " Display the first few rows of the dataframe\ndf_characters.head()",
          " Display the first few rows of each dataframe\ndf_characters.head()",
          "Display the first few rows of the dataframe\ndf_characters.head()",
          "Display first few rows of each dataframe\ndf_characters.head()",
          " Display the first few rows of the dataframe\ndf_characters.head()",
          "Display the first few rows of the dataframe\ndf_characters.head()",
          " Display the first few rows of the dataframe\ndf_characters.head()",
          " Display the first few rows of the dataframe\ndf_characters.head()",
          "Display the first few rows of the dataframe \"df_characters\"\ndf_characters.head()",
          " Display the first few rows of the dataframe\ndf_characters.head()"
         ],
         "marker": {
          "opacity": 0.5,
          "size": 5
         },
         "mode": "markers+text",
         "name": "208_displaying first few rows of dataframe",
         "text": [
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          ""
         ],
         "textfont": {
          "size": 12
         },
         "type": "scattergl",
         "x": [
          2.118039608001709,
          2.172579288482666,
          2.4415407180786133,
          2.434422492980957,
          2.3261783123016357,
          2.056861162185669,
          2.395725727081299,
          2.255455493927002,
          2.3801321983337402,
          2.254444122314453,
          2.42553973197937,
          2.142423152923584,
          2.2678544521331787,
          2.489086627960205,
          2.051996946334839,
          2.216904640197754
         ],
         "y": [
          28.039628982543945,
          28.045900344848633,
          27.997562408447266,
          28.32793617248535,
          28.25425910949707,
          28.053312301635742,
          28.305662155151367,
          27.9710693359375,
          28.285964965820312,
          28.112165451049805,
          28.261533737182617,
          28.007699966430664,
          28.189287185668945,
          27.967540740966797,
          28.395248413085938,
          28.29889678955078
         ]
        },
        {
         "hoverinfo": "text",
         "hovertext": [
          "Select the fields of interest from the dataframes",
          "Join Dfs",
          "All four dataframes have an 'id' attribute that we can use to make joins work better.",
          "Join the dataframes",
          "Set keys for each dataframe",
          "Join the DataFrames",
          "Join dataframes",
          " Join the dataframes on the corresponding keys to create a unified dataframe",
          "Joining the datasets based on the available keys in the dataframes",
          "Add an index to the dataframe to be able to use the efficiency of the join operation.",
          "Join dataframes",
          "Joining the dataframe to get the full data",
          "Do the join on the dataframes",
          "Joining datasets to have a comprehensive dataframe",
          " Join the dataframes",
          "Join the dataframes"
         ],
         "marker": {
          "opacity": 0.5,
          "size": 5
         },
         "mode": "markers+text",
         "name": "209_Joining DataFrames",
         "text": [
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          ""
         ],
         "textfont": {
          "size": 12
         },
         "type": "scattergl",
         "x": [
          7.420958518981934,
          6.64932918548584,
          6.364129543304443,
          6.569389343261719,
          6.2824296951293945,
          6.6204962730407715,
          6.552488803863525,
          6.630805492401123,
          6.943153381347656,
          6.603296756744385,
          6.4193830490112305,
          6.72286319732666,
          6.3318095207214355,
          7.28341817855835,
          6.538378715515137,
          6.71811580657959
         ],
         "y": [
          0.06072397157549858,
          -0.7951355576515198,
          0.6512387990951538,
          0.38554033637046814,
          0.47378432750701904,
          0.3103213310241699,
          0.02391888201236725,
          -0.07586323469877243,
          -0.04513618350028992,
          0.8056502938270569,
          0.3344253599643707,
          0.29674452543258667,
          0.5658586621284485,
          0.007248155772686005,
          0.12642768025398254,
          0.41546159982681274
         ]
        },
        {
         "hoverinfo": "text",
         "hovertext": [
          "Let's display the first few lines of each dataset to understand their structure and contents.",
          "Print out the first two rows of each of the dataset.",
          " Display the first few lines of each dataset to understand the data",
          "Inspect the first 5 rows of each dataset to understand its structure and content",
          "Print some introductory information about each dataset, like number of columns, number of samples and the content of the first row",
          "Visualizing the dataset by printing out the first few rows",
          "Let's start by printing the first 5 lines of each of these datasets to understand how they look like.",
          " Displaying the first few entries for each of our datasets",
          "Checking the first few rows of data to understand the structure and content of the datasets.",
          "Inspect the first few rows of each dataset to understand its structure and content",
          " Show the main datasets to understand the structure and content",
          "Create a variable to hold the number of lines of the dataset.",
          " Displaying the original dataset's first few lines to get a sense of the information contained.",
          " Prints the top rows of the dataset to understand its structure",
          "Display the first few lines of each dataset to understand its structure and the available fields",
          " Let's echo the last rows of the datasets."
         ],
         "marker": {
          "opacity": 0.5,
          "size": 5
         },
         "mode": "markers+text",
         "name": "210_Exploring dataset structure and content",
         "text": [
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          ""
         ],
         "textfont": {
          "size": 12
         },
         "type": "scattergl",
         "x": [
          14.328110694885254,
          13.360201835632324,
          13.307246208190918,
          14.103039741516113,
          13.974364280700684,
          13.390826225280762,
          14.29352855682373,
          13.3510160446167,
          13.993936538696289,
          13.905787467956543,
          14.80814266204834,
          13.121793746948242,
          13.599495887756348,
          13.217784881591797,
          13.773780822753906,
          13.068638801574707
         ],
         "y": [
          -3.1288468837738037,
          -3.5094614028930664,
          -2.8712611198425293,
          -3.730290412902832,
          -2.6536073684692383,
          -3.519719123840332,
          -2.8932886123657227,
          -2.7819905281066895,
          -3.0163979530334473,
          -3.5523879528045654,
          -2.685913324356079,
          -1.7546648979187012,
          -3.2236011028289795,
          -4.649115085601807,
          -2.8949074745178223,
          -3.2897965908050537
         ]
        },
        {
         "hoverinfo": "text",
         "hovertext": [
          " Display the first few rows of the dataset\ndf_script.head()",
          " Display the first few rows of the script dataset\ndf_script.head()",
          "Display the first few rows of the dataset for examination\ndf_script.head()",
          " display the first few rows of the script dataset\ndf_script.head()",
          "Show the first few rows of the script dataset\ndf_script.head()",
          " Display the 4 firsts entries of the dataset\ndf_script.head(4)",
          "Show first rows of the dataset\ndf_script.head()",
          " Display the first few rows of the dataset\ndf_script.head()",
          " Display the first few rows of the script dataset\ndf_script.head()",
          "Show the top few rows of the script dataset\ndf_script.head()",
          "Display the first few rows of the dataset\ndf_script.head()",
          "# Display first few rows of the dataset\ndf_script.head()",
          "Print the first few rows of the script dataset\ndf_script.head()",
          " Display the first few rows of the script dataset\ndf_script.head()",
          "Take a peak at the first few rows of the dataset\ndf_script.head()",
          " Show the first few rows of the script dataset\ndf_script.head()"
         ],
         "marker": {
          "opacity": 0.5,
          "size": 5
         },
         "mode": "markers+text",
         "name": "211_dataset with first few rows displayed using df_script.head(4)",
         "text": [
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          ""
         ],
         "textfont": {
          "size": 12
         },
         "type": "scattergl",
         "x": [
          0.763712465763092,
          1.1118552684783936,
          0.7217830419540405,
          1.1257578134536743,
          1.185302734375,
          0.649000346660614,
          1.2617363929748535,
          0.8154959678649902,
          1.2927947044372559,
          0.9167603254318237,
          0.8946595191955566,
          0.5130853652954102,
          1.3861457109451294,
          1.0531344413757324,
          0.6676735281944275,
          1.37110435962677
         ],
         "y": [
          -6.627773284912109,
          -6.40271520614624,
          -6.616995811462402,
          -6.494451999664307,
          -5.9894609451293945,
          -6.459593772888184,
          -6.772899627685547,
          -6.489779949188232,
          -6.558326244354248,
          -6.196274280548096,
          -6.359078407287598,
          -6.539361476898193,
          -6.138613700866699,
          -6.527966022491455,
          -6.3275017738342285,
          -6.179210186004639
         ]
        },
        {
         "hoverinfo": "text",
         "hovertext": [
          "View the characters dataframe\ndf_characters.head()",
          "Explore the characters dataframe\ndf_characters.head()",
          "View the characters dataframe\ndf_characters.head()",
          "Explore the characters dataframe\ndf_characters.head()",
          "View some basic data about the characters dataframe\ndf_characters.head()",
          "Explore the characters dataframe\ndf_characters.head()",
          "Explore the characters dataframe\ndf_characters.head()",
          " View the characters dataframe\ndf_characters.head()",
          " Explore the characters dataframe\ndf_characters.head()",
          "View head of characters dataframe\ndf_characters.head()",
          "View the characters dataframe\ndf_characters.head()",
          "View the characters dataframe\ndf_characters.head()",
          "View the characters dataframe\ndf_characters.head()",
          "# Initial exploration of the characters dataframe\ndf_characters.head()",
          "View the characters dataframe\ndf_characters.head()"
         ],
         "marker": {
          "opacity": 0.5,
          "size": 5
         },
         "mode": "markers+text",
         "name": "212_Initial exploration of character dataframe",
         "text": [
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          ""
         ],
         "textfont": {
          "size": 12
         },
         "type": "scattergl",
         "x": [
          7.948204040527344,
          8.12617015838623,
          7.644676685333252,
          8.29326343536377,
          7.5098772048950195,
          8.042729377746582,
          8.178695678710938,
          7.906222343444824,
          8.097550392150879,
          7.748606204986572,
          7.765965938568115,
          7.924623489379883,
          7.980950355529785,
          8.32170295715332,
          7.861711502075195
         ],
         "y": [
          18.93549346923828,
          19.285919189453125,
          18.788314819335938,
          19.088069915771484,
          18.120086669921875,
          19.123205184936523,
          19.292112350463867,
          18.840625762939453,
          19.282495498657227,
          18.380218505859375,
          18.934091567993164,
          18.802343368530273,
          19.02646255493164,
          19.354005813598633,
          18.832422256469727
         ]
        },
        {
         "hoverinfo": "text",
         "hovertext": [
          "Get the most common words in the entire script\nscript_text = \" \".join(df_script.raw_text)\nscript_text = script_text.lower()  # Convert all text to lower case\nscript_text = \" \".join(script_text.split())  # Remove extra whitespaces\n\n# Download the English model\n!python -m spacy download en_core_web_sm\n\nnlp = spacy.load('en_core_web_sm')\ndoc = nlp(script_text)",
          "Initialize spacy\nnlp = spacy.load('en_core_web_sm', disable=['ner', 'parser'])\n\n# Preprocessing\ndf_script = df_script.fillna('')\ndf_script['character_id'] = df_script['character_id'].apply(lambda x: x.strip())\ndf_script['location_id'] = df_script['location_id'].apply(lambda x: x.strip())\ndf_script['raw_text'] = df_script['raw_text'].apply(lambda x: x.strip())\n\ndf_episodes = df_episodes.fillna('')",
          "TF-IDF for scripts\nfrom sklearn.feature_extraction.text import TfidfVectorizer",
          " Define stop words and punctuation to remove from the script\nstop_words = spacy.lang.en.stop_words.STOP_WORDS\npunctuation = '!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~'\n\n# Load the language model and parse the dialog\nnlp = spacy.load('en_core_web_sm')\ndialogue = ' '.join(df_script['raw_text'].values)\nparsed_dialogue = nlp(dialogue)",
          "Df2nlp_class.py\n# Custom class for the following\n# - Load\n# - Preprocess\n# - Tokenize\n# - Build Corpus\n# - Embedding representation\n# - Helper functions\n#      - txt to segments\n#      - txt to sequences\n# Import file",
          "# Filter the non-english sentences\ndf_script['script'] = df_script['spoken_words']\n\n# Load the English tokenizer\nnlp = spacy.blank('en')\n\n# Tokenize **approximately** to sentences\ndocs = df_script.script[:1000].apply(lambda x: nlp(x))\n\nsentences = []\nfor doc in docs:\n    sentences.extend([sent.text.lower() for sent in doc.sents if len(sent.text) > 1])",
          "# Set up\nnlp = spacy.load('en_core_web_sm')\n\n# Only consider named entities that are characters or locations\ndf_script_filtered = df_script[(df_script['raw_character_text'].notnull()) | (df_script['raw_location_text'].notnull())]\n# Replace nans with empty strings\ndf_script_filtered = df_script_filtered.fillna('')\n\n# Lemmatization mapping\nlemmatization_df = pd.read_csv('data/lemmatization.csv', index_col=0, squeeze=True).to_dict()",
          "Create a spaCy object\nnlp = spacy.load(\"en_core_web_sm\", disable=['ner', 'parser'])\n\n# Apply processing to each line in the script\ndocs = list(nlp.pipe(df_script['raw_text'], batch_size=1000, n_process=-1))",
          "Create a spacy nlp object\nnlp = spacy.load(\"en_core_web_sm\")\n\n# Process the text and add it to the dataframe\nprocessed_script = []",
          " Create a new column for the spacy embeddings for each line in the script\ndf_script['spacy_doc'] = df_script['normalized_text'].apply(lambda x: nlp(x))",
          "Remove non-English lines from the script dataframe\n# English language detection\nnlp = spacy.load('en_core_web_sm')\n\ndef detect_english_nlp(text):\n    try:\n        doc = nlp(text)\n        # Consider a text in English if the stopwords are less than 60% of the total words\n        if (len(doc) > 0 and len(doc) / len(text) > 0.4):\n            return True\n        else:\n            return False\n    # If the text is too large spacy returns a value error\n    except:\n        return False\n\ntqdm.pandas()\ndf_script = df_script[df_script['raw_text'].progress_apply(detect_english_nlp)]",
          "Set character_id as index for fast sclicing\ndf_characters.set_index('id', inplace=True)\n\n# Setup Spacy\nnlp = spacy.load(\"en_core_web_sm\")",
          " Set up spaCy\nnlp = spacy.load('en_core_web_sm')\n\n# Process the script data with spaCy (only applied when not already contained in the dataframe)\nif 'spacy_processed' not in df_script.columns:\n    doc = df_script['raw_text'].progress_apply(lambda x: nlp(x))\n    df_script.insert(1, 'spacy_processed', doc)  # Insert spaCy processed data in a column in the dataframe.",
          "Text preprocessing\n# We want to preprocess the spoken words, removing special characters and non-useful information in order to create a wordcloud\ndf_script_processed = df_script[['raw_character_text', 'spoken_words']].dropna().copy()\ndf_script_processed['spoken_words'] = df_script_processed['spoken_words'] \\\n    .str.replace(r'[^A-Za-z\\s]', '') \\\n    .str.lower()\n\n# Using Spacy for our corpora of text\nnlp = spacy.load('en')\n\n# Let's filter the characters names from the text\n# We'll perform only Named Entity Recognition and keep the identified characters\ndf_script_processed = df_script_processed[:int(len(df_script_processed)/50)]\nidentified_characters = {}\nfor character in tqdm(df_script_processed.raw_character_text.unique()):\n    character_doc = nlp(character)\n    identified_characters[character] = list(set([ent.text for ent in character_doc.ents if ent.label_ == 'PERSON']))\n\n# Let's double-check the presence of those characters and their identification\n{\n    character: identified_characters[character]\n    for character in identified_characters\n    if identified_characters[character]\n}",
          "merge the first and last names\ndf_characters['name'] = df_characters['name'].str.split().apply(lambda x: x[0] + '_' + x[1] if len(x) > 1 else x[0])\n\n# Load model\nnlp = spacy.load('en_core_web_sm')"
         ],
         "marker": {
          "opacity": 0.5,
          "size": 5
         },
         "mode": "markers+text",
         "name": "213_Text processing and filtering with spaCy",
         "text": [
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          ""
         ],
         "textfont": {
          "size": 12
         },
         "type": "scattergl",
         "x": [
          12.728421211242676,
          4.530887603759766,
          11.792078018188477,
          12.735109329223633,
          12.110332489013672,
          12.218198776245117,
          13.391550064086914,
          13.278337478637695,
          13.671631813049316,
          12.4983491897583,
          13.075485229492188,
          13.795478820800781,
          13.297582626342773,
          12.491147994995117,
          13.214879989624023
         ],
         "y": [
          8.93683910369873,
          6.147058963775635,
          8.950763702392578,
          8.203485488891602,
          8.84000015258789,
          8.64501667022705,
          9.389907836914062,
          8.83728313446045,
          8.96751880645752,
          8.83648681640625,
          8.676795959472656,
          9.074586868286133,
          9.057809829711914,
          8.919376373291016,
          8.802687644958496
         ]
        },
        {
         "hoverinfo": "text",
         "hovertext": [
          "Visualization of the number of lines per characters.",
          " Calculate and plot the number of lines per character.",
          " Show the first few lines of characters data.",
          "Display the number of lines of each character",
          "Count lines ready for parsing",
          "function to get characters lines",
          "Function to normalize the lines of a character",
          "Check number of lines for each Character ID",
          "Visualize number of lines per character",
          "Check the count of lines and characters",
          "Weight each character's occurrence by the length of the line (expanding counting heavily in longer lines)",
          " Check what the line looks like",
          " Visualize the number of lines spoken by each character.",
          "Get the number of lines for the characters.",
          "Print the number of lines with missing character, location or raw_text, if any."
         ],
         "marker": {
          "opacity": 0.5,
          "size": 5
         },
         "mode": "markers+text",
         "name": "214_Character line analysis",
         "text": [
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          ""
         ],
         "textfont": {
          "size": 12
         },
         "type": "scattergl",
         "x": [
          9.90864086151123,
          9.892171859741211,
          10.3952054977417,
          10.262076377868652,
          10.288249969482422,
          10.107288360595703,
          10.10860538482666,
          9.839234352111816,
          9.675653457641602,
          10.430379867553711,
          10.256634712219238,
          10.696152687072754,
          9.602314949035645,
          10.203591346740723,
          9.856534957885742
         ],
         "y": [
          7.525389194488525,
          7.906259059906006,
          8.439497947692871,
          7.47735071182251,
          7.201502323150635,
          6.7928996086120605,
          7.2959394454956055,
          7.944312572479248,
          7.360605716705322,
          7.482371807098389,
          7.731991767883301,
          6.697247505187988,
          7.635499000549316,
          7.175076484680176,
          7.603898048400879
         ]
        },
        {
         "hoverinfo": "text",
         "hovertext": [
          "Create a dict to map character id to character name.",
          "Create character id to character name dictionary",
          "To harmonize the location names supplementary gathered from the internet, I'll ensure these strings either appear in lower case or are capitalized.",
          "Create character, location and episode maps to go from string to int and vice versa",
          "A function to retrieve the character information from the character_id.",
          "Build a dictionary for characters and locations for easier access",
          "Setup the selected character ID and retrieve the chosen character's name",
          "Define the name to ID mapping and ID to name mapping for characters and locations.",
          "Convert gender, character and location Id's to character and location names respectively.",
          "Load the character and location label encoders",
          "Create maps: lookup tables for location and character names",
          "anya all the tables to dictionaries",
          "Creates a dictionary to map character id to character name",
          "Create character's and location's names maps",
          "Set shorthands for character and location names"
         ],
         "marker": {
          "opacity": 0.5,
          "size": 5
         },
         "mode": "markers+text",
         "name": "215_Creating Maps for Character and Location Names",
         "text": [
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          ""
         ],
         "textfont": {
          "size": 12
         },
         "type": "scattergl",
         "x": [
          8.127116203308105,
          8.207928657531738,
          9.538121223449707,
          8.314506530761719,
          8.86099624633789,
          8.485910415649414,
          8.941269874572754,
          8.428620338439941,
          8.558183670043945,
          9.077522277832031,
          8.467389106750488,
          12.290356636047363,
          8.39210319519043,
          8.442111015319824,
          9.117040634155273
         ],
         "y": [
          8.65452766418457,
          8.262497901916504,
          6.798506736755371,
          6.2068986892700195,
          8.451387405395508,
          7.421477794647217,
          8.0626220703125,
          7.1598286628723145,
          6.917081356048584,
          5.498895645141602,
          6.087713718414307,
          6.221729278564453,
          7.989279747009277,
          6.432009696960449,
          6.160426616668701
         ]
        },
        {
         "hoverinfo": "text",
         "hovertext": [
          "Display the first few records of the characters dataframe\ndf_characters.head()",
          " Display the first few records of the characters dataframe\ndf_characters.head()",
          " Display the first few entries of df_characters\ndf_characters.head()",
          " Display the first few records of `df_characters`\ndf_characters.head()",
          "View the first few entries in the characters dataframe\ndf_characters.head()",
          "Use the head function to display the first few records of the DataFrame\ndf_characters.head()",
          "Display the first few records of the characters dataframe\ndf_characters.head()",
          "begin by displaying the first few records of each DataFrame.\ndf_characters.head()",
          "# Display first few records of df_chars\ndf_characters.head()",
          "Displaying the first few entries of the characters dataframe\ndf_characters.head()",
          "Display the first few entries of the characters data frame\ndf_characters.head()",
          "Display the first few records of the characters dataframe\ndf_characters.head()",
          "View first few records of characters DataFrame\ndf_characters.head()",
          "View the first few records of the characters dataframe\ndf_characters.head()",
          "Display the first few records of the characters data frame\ndf_characters.head()"
         ],
         "marker": {
          "opacity": 0.5,
          "size": 5
         },
         "mode": "markers+text",
         "name": "216_displaying the first few records of the characters dataframe",
         "text": [
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          ""
         ],
         "textfont": {
          "size": 12
         },
         "type": "scattergl",
         "x": [
          -0.08826403319835663,
          -0.19312311708927155,
          0.2711080014705658,
          0.12453728914260864,
          0.08325798809528351,
          -0.5328648090362549,
          -0.3073202967643738,
          -0.28357693552970886,
          0.0806128978729248,
          0.19891738891601562,
          -0.24235214293003082,
          -0.2619490921497345,
          -0.35414430499076843,
          0.007086685858666897,
          -0.2906232476234436
         ],
         "y": [
          18.074615478515625,
          18.063608169555664,
          18.3846378326416,
          18.01350212097168,
          19.27435302734375,
          18.093809127807617,
          18.131961822509766,
          17.90545082092285,
          17.596981048583984,
          18.808815002441406,
          19.050033569335938,
          18.18532371520996,
          18.692930221557617,
          18.552200317382812,
          18.326934814453125
         ]
        },
        {
         "hoverinfo": "text",
         "hovertext": [
          " Display settings\npd.set_option('display.max_columns', None)\npd.set_option('display.max_rows', None)",
          "Show configurations for a better layout\npd.options.display.max_columns = None\npd.options.display.max_rows = 10",
          "Global configurations\npd.set_option('display.max_columns', None)\npd.set_option('display.max_rows', None)",
          "Display max rows and columns\npd.set_option('display.max_rows', None)\npd.set_option('display.max_columns', None)",
          "Display settings\npd.set_option('display.max_columns', None)\npd.set_option('display.max_rows', None)",
          "Display columns\npd.set_option('display.max_columns', None)\npd.set_option('display.max_rows', None)",
          "Rows to display\npd.set_option('display.max_columns', None)\npd.set_option('display.max_rows', None)",
          "Display all rows and columns\npd.set_option('display.max_rows', None)\npd.set_option('display.max_columns', None)",
          " Set maximum columns and rows to display\npd.set_option('display.max_columns', None)\npd.set_option('display.max_rows', None)",
          "Display configurations\npd.set_option('display.max_columns', None)\npd.set_option('display.max_rows', None)",
          "Explore the data\npd.set_option('display.max_columns', None)\npd.set_option('display.max_rows', None)",
          "Set constants or options\n# Constants\nSEED = 42\n\n# Options\npd.set_option('display.max_columns', None)\npd.set_option('display.max_rows', None)",
          " Set maximum columns and rows to display\npd.set_option('display.max_columns', None)\npd.set_option('display.max_rows', None)",
          "Rows and columns shown in their entirety\npd.set_option('display.max_columns', None)\npd.set_option('display.max_rows', None)",
          "Set the maximum number of columns/rows printed without truncation\npd.set_option('display.max_columns', None)\npd.set_option('display.max_rows', None)"
         ],
         "marker": {
          "opacity": 0.5,
          "size": 5
         },
         "mode": "markers+text",
         "name": "217_Display Configurations and Options",
         "text": [
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          ""
         ],
         "textfont": {
          "size": 12
         },
         "type": "scattergl",
         "x": [
          24.56621742248535,
          24.88751792907715,
          24.4007625579834,
          24.548263549804688,
          24.39027214050293,
          24.64620018005371,
          24.846149444580078,
          24.689624786376953,
          24.565242767333984,
          24.397157669067383,
          24.513090133666992,
          24.204246520996094,
          24.716703414916992,
          24.676532745361328,
          24.117996215820312
         ],
         "y": [
          0.4318619966506958,
          0.19048498570919037,
          -0.05199415609240532,
          0.14897789061069489,
          0.2814275026321411,
          0.2756551206111908,
          0.09751681983470917,
          0.40726810693740845,
          -0.12477632611989975,
          0.4708944857120514,
          -0.44256681203842163,
          -0.14199726283550262,
          -0.09326890856027603,
          -0.14878897368907928,
          -0.36830171942710876
         ]
        },
        {
         "hoverinfo": "text",
         "hovertext": [
          "Inspect the first few rows of each dataframe to understand the structure of the data and the information it contains.",
          "Inspect the first few rows of each dataframe to understand its structure and the type of insights it might offer.",
          "Inspect the first few rows of each dataframe to understand its structure and contents.",
          "Inspect the first few rows of each dataframe to understand their structure and content.",
          "Inspect the dataframe's initial rows.",
          "Inspect the first few rows of each dataframe to understand its structure and contents.",
          "inspect the first few rows of each dataframe to see its structure.",
          "Inspect the first few rows of each dataframe to understand their structure and the type of data stored in them.",
          "Inspect the first few rows of each dataframe to understand its structure and the information it contains.",
          "Inspect the first few rows of each DataFrame to understand its structure and contents.",
          "Inspect the first few rows of each dataframe to understand its structure and available features.",
          "Inspect the first few rows of each dataframe to understand their structure and contents.",
          "Inspect the first few rows of each DataFrame to understand the structure and data types.",
          "Explore the dataframes (i.e., dimensions, first few rows, data types, NaNs)",
          "Inspect the first few rows of each dataframe to understand its structure and contents."
         ],
         "marker": {
          "opacity": 0.5,
          "size": 5
         },
         "mode": "markers+text",
         "name": "218_Understanding the structure and contents of dataframes",
         "text": [
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          ""
         ],
         "textfont": {
          "size": 12
         },
         "type": "scattergl",
         "x": [
          11.561287879943848,
          11.915193557739258,
          12.286558151245117,
          11.52955436706543,
          12.435867309570312,
          12.018596649169922,
          11.681591033935547,
          11.490078926086426,
          11.611856460571289,
          12.140416145324707,
          11.766620635986328,
          11.909037590026855,
          11.673897743225098,
          12.047566413879395,
          12.149969100952148
         ],
         "y": [
          -7.464479446411133,
          -7.643646717071533,
          -7.543187141418457,
          -7.823336601257324,
          -7.9086151123046875,
          -7.59769344329834,
          -7.02848482131958,
          -7.263704776763916,
          -7.191611289978027,
          -7.498515605926514,
          -7.922929286956787,
          -7.540031433105469,
          -7.049022197723389,
          -7.685257434844971,
          -7.573890686035156
         ]
        },
        {
         "hoverinfo": "text",
         "hovertext": [
          " Tokenize the documents",
          "Tokenize using spacy",
          " Tokenizer for spacy model",
          " Tokenize script lines using SpaCy",
          "Tokenize using Spacy",
          " Tokenize the script lines using spacy.",
          "Set'token_default'space English-language'tokenizer.",
          "Create an instance of the English spacy tokenizer model.",
          "Initialization of a tokenizer using Spacy's English language model.",
          "Create a list of all character names and their corresponding tokens using Spacy",
          "Tokenizes a string into a list of words, filtering out unwanted tokens.",
          " Tokenization ",
          "Set up the tokenization pipeline with spaCy",
          "Tokenize the script lines using Spacy's en_core_web_sm model.",
          "Declare a function for tokenizing the data using spacy"
         ],
         "marker": {
          "opacity": 0.5,
          "size": 5
         },
         "mode": "markers+text",
         "name": "219_Tokenizing documents using Spacy",
         "text": [
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          ""
         ],
         "textfont": {
          "size": 12
         },
         "type": "scattergl",
         "x": [
          13.632884979248047,
          13.668044090270996,
          14.339428901672363,
          13.214680671691895,
          13.684003829956055,
          13.067611694335938,
          13.94510269165039,
          14.101105690002441,
          14.150729179382324,
          13.379232406616211,
          13.20077133178711,
          13.663323402404785,
          13.989995956420898,
          13.616647720336914,
          13.987872123718262
         ],
         "y": [
          5.781772613525391,
          5.89750337600708,
          5.867303848266602,
          5.741192817687988,
          5.835461616516113,
          5.5848283767700195,
          6.225314140319824,
          6.515260219573975,
          6.192706108093262,
          6.637170314788818,
          6.363759994506836,
          6.124632835388184,
          6.02642822265625,
          6.353473663330078,
          5.5410566329956055
         ]
        },
        {
         "hoverinfo": "text",
         "hovertext": [
          "Create a function to filter the data frames by season.",
          "Filter script by season",
          "Selecting only a specific season data for the analysis due to the memory limitations in the local environment",
          "Removing all data after Season 20 (including) to avoid further spoilers",
          "Create dictionary for all the seasons",
          "Season filter\nseasons = []",
          "Some more data preprocessing: remove rows with missing data and keep only the script lines from the first 10 seasons",
          "Define the paths to the season folders and the file names for all seasons.",
          " Parameters\nseason_of_interest = 10",
          "Filter by season",
          "\n# Selected season\nseason_number = 8",
          "Filtering the dataset to only include data from the first 10 seasons",
          "Filter seasons before COVID-19",
          "Declare seasons for easy iteration",
          "Keep only data from the first 15 seasons (last season included = 15)"
         ],
         "marker": {
          "opacity": 0.5,
          "size": 5
         },
         "mode": "markers+text",
         "name": "220_Season Filtering and Data Selection",
         "text": [
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          ""
         ],
         "textfont": {
          "size": 12
         },
         "type": "scattergl",
         "x": [
          8.543000221252441,
          7.909731388092041,
          8.845571517944336,
          8.261974334716797,
          9.966474533081055,
          8.679206848144531,
          7.836920261383057,
          11.455530166625977,
          9.140600204467773,
          8.863022804260254,
          8.228409767150879,
          8.223196983337402,
          8.14714241027832,
          10.13337230682373,
          8.064340591430664
         ],
         "y": [
          3.155989170074463,
          3.081791639328003,
          3.0007073879241943,
          2.798219919204712,
          3.0872464179992676,
          2.81144380569458,
          3.409327983856201,
          3.3727786540985107,
          2.7050509452819824,
          2.769911527633667,
          2.7880358695983887,
          2.954228162765503,
          2.717801809310913,
          2.702934980392456,
          3.1099777221679688
         ]
        },
        {
         "hoverinfo": "text",
         "hovertext": [
          "Let's take a look at the first few lines of each dataframe.",
          "Let's take a look to the first lines of each Dataframe.",
          "Let's take a look at the first few lines of each DataFrame.",
          "Let's take a look at the first few lines of each of these DataFrames.",
          " Let's take a look at heads of each dataframe",
          "Let's have a look at the first few lines of each DataFrame.",
          "Let's take a look at the first few lines of each dataframe.",
          "Check the introduction of data and cleanup the relevant DataFrames.",
          "Let's try to see what each dataframe looks like.",
          "Let's take a look at the first few lines of each DataFrame.",
          "Right before we begin any analysis, let's take a look at the head of each dataframe.",
          "Let's check the data in each dataframe.",
          "Let's take a look at the first few lines of each dataframe.",
          "I commented out the lines creating the dataframes to avoid re-running them when unnecessary.",
          " Let's take a look at first few lines of each of these DataFrame using the head() method."
         ],
         "marker": {
          "opacity": 0.5,
          "size": 5
         },
         "mode": "markers+text",
         "name": "221_Dataframe analysis and cleanup",
         "text": [
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          ""
         ],
         "textfont": {
          "size": 12
         },
         "type": "scattergl",
         "x": [
          9.748809814453125,
          10.168065071105957,
          9.94898509979248,
          9.87147045135498,
          9.178107261657715,
          9.772212982177734,
          9.731891632080078,
          9.897273063659668,
          10.248380661010742,
          9.630009651184082,
          9.40064811706543,
          9.895715713500977,
          9.704160690307617,
          9.727310180664062,
          9.87869930267334
         ],
         "y": [
          -5.339358806610107,
          -6.208324432373047,
          -5.380393981933594,
          -6.309859275817871,
          -5.694506645202637,
          -5.5878424644470215,
          -5.4178242683410645,
          -4.695199489593506,
          -5.413593292236328,
          -5.375268459320068,
          -5.5824198722839355,
          -5.567372798919678,
          -5.358363151550293,
          -3.418318748474121,
          -5.615589141845703
         ]
        },
        {
         "hoverinfo": "text",
         "hovertext": [
          "Print the amount of rows in each dataframe\nprint(f'Characters df shape: {df_characters.shape}')\nprint(f'Locations df shape: {df_locations.shape}')\nprint(f'Script df shape: {df_script.shape}')\nprint(f'Episodes df shape: {df_episodes.shape}')",
          "\n# print the number of rows and columns in each dataframe\nprint(\"Characters dataframe:\", df_characters.shape)\nprint(\"Locations dataframe:\", df_locations.shape)\nprint(\"Script dataframe:\", df_script.shape)\nprint(\"Episodes dataframe:\", df_episodes.shape)",
          "Let's print the number of rows in each dataframe using the shape attribute.",
          " Display the size and first few rows of each dataframe\nfor df_name, df in zip(['characters', 'locations', 'script', 'episodes'], [df_characters, df_locations, df_script, df_episodes]):\n    print(df_name)\n    print(f'Size: {df.shape}')\n    display(df.head())\n    print()",
          "Display the number of rows and columns for each dataset\nprint(\"Characters:\", df_characters.shape)\nprint(\"Locations:\", df_locations.shape)\nprint(\"Script:\", df_script.shape)\nprint(\"Episodes:\", df_episodes.shape)",
          "Display the number of rows and columns for each dataframes\nfor name, dataframe in zip(['Characters', 'Locations', 'Episodes', 'Script'], [df_characters, df_locations, df_episodes, df_script]):\n    print('{}: {} rows, {} columns'.format(name, dataframe.shape[0], dataframe.shape[1]))",
          "Display the number of rows and columns in each dataframe\nprint(\"Characters:\")\nprint(df_characters.shape)\nprint(df_characters.columns)\nprint(\"\\nLocations:\")\nprint(df_locations.shape)\nprint(df_locations.columns)\nprint(\"\\nScript:\")\nprint(df_script.shape)\nprint(df_script.columns)\nprint(\"\\nEpisodes:\")\nprint(df_episodes.shape)\nprint(df_episodes.columns)",
          "Print the number of rows in the characters, locations, script and episodes DataFrames\nprint(df_characters .shape[0])\nprint(df_locations.shape[0])\nprint(df_script   .shape[0])\nprint(df_episodes .shape[0])",
          " Display the number of rows and columns for each dataframe\nprint(f'Characters: {df_characters.shape}')\nprint(f'Locations: {df_locations.shape}')\nprint(f'Script: {df_script.shape}')\nprint(f'Episodes: {df_episodes.shape}')",
          "Display the number of rows and columns for each dataframe\nfor name, df in zip(['Characters', 'Locations', 'Script', 'Episodes'], \n                    [df_characters, df_locations, df_script, df_episodes]):\n    print(f\"{name} has {df.shape[0]} rows and {df.shape[1]} columns\")",
          " Display the number of rows and columns for each dataframe\nprint(\"characters:\", df_characters.shape)",
          "Display the number of rows and columns for each dataframe\nprint(f\"Characters dataframe shape: {df_characters.shape}\")\nprint(f\"Locations dataframe shape: {df_locations.shape}\")\nprint(f\"Script dataframe shape: {df_script.shape}\")\nprint(f\"Episodes dataframe shape: {df_episodes.shape}\")",
          " Display the number of rows and columns for each dataset\nprint('Characters:', df_characters.shape)\nprint('Locations:', df_locations.shape)\nprint('Script:', df_script.shape)\nprint('Episodes:', df_episodes.shape)",
          "Display the number of rows and columns in each dataset\nprint(\"Characters:\", df_characters.shape)\nprint(\"Locations:\", df_locations.shape)\nprint(\"Script:\", df_script.shape)\nprint(\"Episodes:\", df_episodes.shape)",
          "Show the number of rows and column in each dataframe\ndf_episodes.shape, df_script.shape, df_characters.shape, df_locations.shape"
         ],
         "marker": {
          "opacity": 0.5,
          "size": 5
         },
         "mode": "markers+text",
         "name": "222_Displaying Dataframe Shapes",
         "text": [
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          ""
         ],
         "textfont": {
          "size": 12
         },
         "type": "scattergl",
         "x": [
          2.3842976093292236,
          2.125378131866455,
          2.78393816947937,
          1.3197628259658813,
          1.784721851348877,
          2.0155832767486572,
          2.5101981163024902,
          1.866264820098877,
          2.4131662845611572,
          1.8870599269866943,
          3.00164794921875,
          2.3865010738372803,
          2.3961408138275146,
          2.095763683319092,
          2.3525798320770264
         ],
         "y": [
          -0.5581163763999939,
          -0.5225074887275696,
          -0.2820274829864502,
          0.12927496433258057,
          -0.20861957967281342,
          -0.24496880173683167,
          -0.39716091752052307,
          -0.365685373544693,
          -0.37308958172798157,
          -0.41576138138771057,
          0.2991540729999542,
          -0.46881604194641113,
          -0.3289831876754761,
          -0.0861193910241127,
          -0.5626425743103027
         ]
        },
        {
         "hoverinfo": "text",
         "hovertext": [
          " Display the first 5 rows of each dataframe\nprint(\"\\ncharacters\")\nprint(df_characters.head())\n\nprint(\"\\nlocations\")\nprint(df_locations.head())\n\nprint(\"\\nscript\")\nprint(df_script.head())\n\nprint(\"\\nepisodes\")\nprint(df_episodes.head())",
          "Show first 5 rows of each dataframe\nprint('Characters:')\nprint(df_characters.head(5))\nprint('\\n\\nLocations:')\nprint(df_locations.head(5))\nprint('\\n\\nScript:')\nprint(df_script.head(5))\nprint('\\n\\nEpisodes:')\nprint(df_episodes.head(5))",
          "Print the first 3 lines of each dataset\nfor df, name in zip([df_characters, df_locations, df_script, df_episodes], \n                    ['df_characters', 'df_locations', 'df_script', 'df_episodes']):\n    print(name)\n    display(df.head(3))\n    print('\\n')",
          " Visualize the first few rows of each DataFrame\nprint(\"Characters Data:\")\nprint(df_characters.head(), end=\"\\n\\n\")\n\nprint(\"Locations Data:\")\nprint(df_locations.head(), end=\"\\n\\n\")\n\nprint(\"Script Data:\")\nprint(df_script.head(), end=\"\\n\\n\")\n\nprint(\"Episodes Data:\")\nprint(df_episodes.head(), end=\"\\n\\n\")",
          "Print the first 5 rows of each dataframe to understand its structure\nprint(\"Characters:\\n\", df_characters.head(), \"\\n\\n\")\nprint(\"Locations:\\n\", df_locations.head(), \"\\n\\n\")\nprint(\"Script lines:\\n\", df_script.head(), \"\\n\\n\")\nprint(\"Episodes:\\n\", df_episodes.head())",
          " Display the first few rows of each dataframe\nprint(\"Characters dataframe:\")\nprint(df_characters.head(), '\\n')\n\nprint(\"Locations dataframe:\")\nprint(df_locations.head(), '\\n')\n\nprint(\"Script dataframe:\")\nprint(df_script.head(), '\\n')\n\nprint(\"Episodes dataframe:\")\nprint(df_episodes.head())",
          "Display the first 5 rows of each DataFrame\nprint(\"Characters\")\ndisplay(df_characters.head())\nprint(\"\\nLocations\")\ndisplay(df_locations.head())\nprint(\"\\nScript\")\ndisplay(df_script.head())\nprint(\"\\nEpisodes\")\ndisplay(df_episodes.head())",
          " Display first 5 rows of the data\nprint(\"Characters:\")\ndisplay(df_characters.head())\nprint(\"\\nLocations:\")\ndisplay(df_locations.head())\nprint(\"\\nScript:\")\ndisplay(df_script.head())\nprint(\"\\nEpisodes:\")\ndisplay(df_episodes.head())",
          " Outputs first 5 rows of each dataset\nprint(\"Characters dataset\")\nprint(df_characters.head())\nprint(\"\\n\")\n\nprint(\"Locations dataset\")\nprint(df_locations.head())\nprint(\"\\n\")\n\nprint(\"Script dataset\")\nprint(df_script.head())\nprint(\"\\n\")\n\nprint(\"Episodes dataset\")\nprint(df_episodes.head())",
          "Display first 5 rows for each of the datasets\nprint(\"\\n\\nCharacters:\")\nprint(df_characters.head())\n\nprint(\"\\n\\nLocations:\")\nprint(df_locations.head())\n\nprint(\"\\n\\nScript:\")\nprint(df_script.head())\n\nprint(\"\\n\\nEpisodes:\")\nprint(df_episodes.head())",
          " Display the first 5 rows of each dataframe\nprint('Characters:')\nprint(df_characters.head())\nprint('\\n\\nLocations:')\nprint(df_locations.head())\nprint('\\n\\nScript:')\nprint(df_script.head())\nprint('\\n\\nEpisodes:')\nprint(df_episodes.head())",
          "# Display the first 5 rows of each dataframe\nprint(\"Characters:\")\nprint(df_characters.head())\nprint(\"\\nLocations:\")\nprint(df_locations.head())\nprint(\"\\nScript:\")\nprint(df_script.head())\nprint(\"\\nEpisodes:\")\nprint(df_episodes.head())",
          " Display the first 5 rows of each DataFrame to see how the data is structured\nprint(\"\\n\\n\")\nprint(\"Characters:\")\nprint(df_characters.head())\n\nprint(\"\\n\\n\")\nprint(\"Locations:\")\nprint(df_locations.head())\n\nprint(\"\\n\\n\")\nprint(\"Script:\")\nprint(df_script.head())\n\nprint(\"\\n\\n\")\nprint(\"Episodes:\")\nprint(df_episodes.head())",
          "Print the first 5 rows of each of the imported DataFrames\nprint('\\nCharacters DataFrame:')\nprint(df_characters.head(5))\n\nprint('\\nLocations DataFrame:')\nprint(df_locations.head(5))\n\nprint('\\nScript DataFrame:')\nprint(df_script.head(5))\n\nprint('\\nEpisodes DataFrame:')\nprint(df_episodes.head(5))",
          "Check out the first few lines of dataframes\nprint(\"First few lines of df_characters\")\nprint(df_characters.head(3))\nprint(\"\\n\\n\")\n\nprint(\"First few lines of df_locations\")\nprint(df_locations.head(3))\nprint(\"\\n\\n\")\n\nprint(\"First few lines of df_script\")\nprint(df_script.head(3))\nprint(\"\\n\\n\")\n\nprint(\"First few lines of df_episodes\")\nprint(df_episodes.head(3))"
         ],
         "marker": {
          "opacity": 0.5,
          "size": 5
         },
         "mode": "markers+text",
         "name": "223_Displaying Dataframe Head",
         "text": [
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          ""
         ],
         "textfont": {
          "size": 12
         },
         "type": "scattergl",
         "x": [
          -1.3539177179336548,
          -1.2855007648468018,
          -0.9221413135528564,
          -1.898685097694397,
          -1.3625367879867554,
          -2.12819242477417,
          -1.5341222286224365,
          -1.4793883562088013,
          -1.570996880531311,
          -1.4214742183685303,
          -1.1683738231658936,
          -1.1647937297821045,
          -1.25156569480896,
          -1.46299147605896,
          -1.9685882329940796
         ],
         "y": [
          5.828964710235596,
          5.933841228485107,
          4.186707496643066,
          4.993777275085449,
          5.265200138092041,
          5.192697048187256,
          5.794905662536621,
          5.282634735107422,
          4.6910247802734375,
          5.031074047088623,
          5.637308120727539,
          5.535302639007568,
          5.140119552612305,
          5.530482769012451,
          5.202968597412109
         ]
        },
        {
         "hoverinfo": "text",
         "hovertext": [
          "Check the content of the first 5 rows of the dataframe containing the characters",
          " Check the first 5 rows of the characters dataframe.",
          "Checking the top 5 rows of the characters dataframe",
          "Check the first 5 rows of the characters dataframe.",
          "Check out the first 5 rows of the characters dataframe",
          "Check the first 5 rows of the characters dataframe",
          " The top 5 rows of the characters dataframe are:",
          "Check the first 5 rows of the characters dataframe to understand the data",
          "Check the first 5 rows of the characters dataframe.",
          "Check the first 5 rows of the characters dataframe.",
          " Check the first 5 rows of the characters dataframe.",
          "Check the first 5 rows of the characters dataframe.",
          "Checking the top 5 rows of the characters dataframe.",
          "Checking out the first 5 characters dataframe",
          "Check the first five rows of the characters dataframe."
         ],
         "marker": {
          "opacity": 0.5,
          "size": 5
         },
         "mode": "markers+text",
         "name": "224_Checking the top 5 rows of the characters dataframe",
         "text": [
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          ""
         ],
         "textfont": {
          "size": 12
         },
         "type": "scattergl",
         "x": [
          10.918342590332031,
          10.58915901184082,
          9.921548843383789,
          10.266072273254395,
          10.652666091918945,
          10.619812965393066,
          9.55849552154541,
          10.73555850982666,
          10.593287467956543,
          10.68529224395752,
          10.411349296569824,
          10.631141662597656,
          10.062411308288574,
          10.250938415527344,
          10.297481536865234
         ],
         "y": [
          13.495696067810059,
          13.806273460388184,
          13.196573257446289,
          13.79839038848877,
          13.995807647705078,
          13.542245864868164,
          12.195038795471191,
          13.451119422912598,
          13.603123664855957,
          13.930933952331543,
          13.925373077392578,
          13.832500457763672,
          13.170495986938477,
          13.704151153564453,
          13.820572853088379
         ]
        },
        {
         "hoverinfo": "text",
         "hovertext": [
          "We'll parse all relevant columns to string types so we can perform string operations.",
          "Setting correct data types",
          "Ensure some required columns have the appropriate types",
          "Stablish the type of each column, filtering non-numeric and non-string type",
          "Checking the data types of each column",
          "Cast data into the appropriate data type",
          "Exploring columns types and some of the data",
          " Set the right variable types for each column",
          "Setting the correct types of each column",
          "Set up variables for each field type to make the code more readable.",
          " Checking the data types of every column",
          "Get data types",
          "Ensure the correct data types for each column",
          "Harmonize data column names and types",
          " Convert to correct types"
         ],
         "marker": {
          "opacity": 0.5,
          "size": 5
         },
         "mode": "markers+text",
         "name": "225_Choosing and Managing Data Types in Columns",
         "text": [
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          ""
         ],
         "textfont": {
          "size": 12
         },
         "type": "scattergl",
         "x": [
          10.886211395263672,
          11.179681777954102,
          11.16272258758545,
          10.237044334411621,
          10.414466857910156,
          10.887500762939453,
          10.559074401855469,
          10.848967552185059,
          10.780813217163086,
          11.25250244140625,
          10.309087753295898,
          10.996072769165039,
          10.813105583190918,
          10.614643096923828,
          11.069579124450684
         ],
         "y": [
          0.5256787538528442,
          0.8868651986122131,
          0.6403495669364929,
          0.3514559864997864,
          -0.31099385023117065,
          0.5963691473007202,
          0.38884207606315613,
          0.5119938850402832,
          0.5024629831314087,
          0.9366896748542786,
          -0.3076413869857788,
          0.04725055396556854,
          0.1928340345621109,
          0.9030606150627136,
          0.8212233185768127
         ]
        },
        {
         "hoverinfo": "text",
         "hovertext": [
          "View the first five rows of the characters dataframe\ndf_characters.head()",
          " Viewing the first five rows of the characters dataframe\ndf_characters.head()",
          " View the first 5 rows of the characters DataFrame\ndf_characters.head()",
          " View the first 5 rows of the characters dataframe.\ndf_characters.head()",
          " Viewing the first 5 rows of the characters dataframe\ndf_characters.head(5)",
          " View the first 5 rows of the characters dataframe\ndf_characters.head()",
          "View the first 5 rows of the character dataframe\ndf_characters.head()",
          " View the first 5 rows of the characters dataframe\ndf_characters.head()",
          "View the first 5 rows of the characters dataframe\ndf_characters.head()",
          " View the first 5 rows of the characters dataframe\ndf_characters.head()",
          "View the first 5 rows of the characters dataframe\ndf_characters.head()",
          "View the first 5 rows of the characters DataFrame\ndf_characters.head()",
          "View the first 5 rows of the characters dataframe\ndf_characters.head()",
          " View the first 5 rows of the characters dataframe\ndf_characters.head()",
          "View the first 5 rows of the characters dataframe\ndf_characters.head()"
         ],
         "marker": {
          "opacity": 0.5,
          "size": 5
         },
         "mode": "markers+text",
         "name": "226_View first 5 rows of characters dataframe",
         "text": [
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          ""
         ],
         "textfont": {
          "size": 12
         },
         "type": "scattergl",
         "x": [
          16.346927642822266,
          16.130321502685547,
          16.59809684753418,
          16.332969665527344,
          16.201566696166992,
          16.31964683532715,
          16.166988372802734,
          16.45480728149414,
          16.3855037689209,
          16.291702270507812,
          16.3918514251709,
          16.41644287109375,
          16.536527633666992,
          16.322525024414062,
          16.573606491088867
         ],
         "y": [
          -10.474929809570312,
          -10.315925598144531,
          -10.547378540039062,
          -10.707669258117676,
          -10.561348915100098,
          -10.625540733337402,
          -10.430436134338379,
          -10.332379341125488,
          -10.97197151184082,
          -10.481952667236328,
          -10.684687614440918,
          -10.683592796325684,
          -10.442432403564453,
          -10.571385383605957,
          -10.681570053100586
         ]
        },
        {
         "hoverinfo": "text",
         "hovertext": [
          "# Show first 5 rows of each DataFrame\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()",
          "View the first 5 rows of each dataframe\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()",
          "Get the first 5 rows of each dataframe\ndf_characters.head(), df_locations.head(), df_episodes.head(), df_script.head()",
          "View first 5 rows of each dataset\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()",
          "Show first 5 rows of each dataframes\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()",
          " Show the first 5 rows of each dataframe\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()",
          " Show the first 5 rows of each dataframe\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()",
          "Show the first 5 rows of each dataframe\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()",
          " Show the first 5 rows of each dataframe\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()",
          "Show first 5 rows of each dataset\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()",
          "Print the first 5 rows of each dataset for inspection\ndf_characters.head(), df_locations.head(), df_episodes.head(), df_script.head()",
          " Show the first 5 rows of each DataFrame\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()",
          "Show the first 5 rows of each dataframe\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()",
          " Show first 5 rows of each dataframe\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()"
         ],
         "marker": {
          "opacity": 0.5,
          "size": 5
         },
         "mode": "markers+text",
         "name": "227_View first 5 rows of datasets",
         "text": [
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          ""
         ],
         "textfont": {
          "size": 12
         },
         "type": "scattergl",
         "x": [
          15.639287948608398,
          15.608233451843262,
          16.16140365600586,
          15.36313247680664,
          15.85742473602295,
          15.785277366638184,
          16.07337760925293,
          16.0108585357666,
          16.136911392211914,
          15.541011810302734,
          -2.614278554916382,
          16.24040985107422,
          15.886197090148926,
          15.9729585647583
         ],
         "y": [
          -6.831893444061279,
          -6.633492469787598,
          -7.257980823516846,
          -6.751377105712891,
          -7.111006736755371,
          -7.200918674468994,
          -7.059296131134033,
          -7.095513820648193,
          -7.246975898742676,
          -6.854893207550049,
          4.533022880554199,
          -7.088410377502441,
          -7.0171709060668945,
          -7.272253513336182
         ]
        },
        {
         "hoverinfo": "text",
         "hovertext": [
          "Load the spacy model\nnlp = spacy.load('en_core_web_sm')",
          "# Load the model\nnlp = spacy.load('en_core_web_sm')",
          "Load the spaCy model\nnlp = spacy.load('en_core_web_sm')",
          " Set up spaCy model\nnlp = spacy.load('en_core_web_sm')",
          " Load the spacy model\nnlp = spacy.load('en_core_web_sm')",
          "Load the SpaCy model\nnlp = spacy.load('en_core_web_sm')",
          "Load the spaCy model\nnlp = spacy.load('en_core_web_sm')",
          "Load the spaCy model\nnlp = spacy.load('en_core_web_sm')",
          "# Load the spaCy model\nnlp = spacy.load('en_core_web_sm')",
          "Load the spaCy model\nnlp = spacy.load('en_core_web_sm')",
          "Initialize the SpaCy model\nnlp = spacy.load('en_core_web_sm')",
          "# Load spacy model\nnlp = spacy.load('en_core_web_sm')",
          "Intializes spacy model\nnlp = spacy.load('en_core_web_sm')",
          "# Load the spaCy model\nnlp = spacy.load('en_core_web_sm')"
         ],
         "marker": {
          "opacity": 0.5,
          "size": 5
         },
         "mode": "markers+text",
         "name": "228_Loading spaCy model",
         "text": [
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          ""
         ],
         "textfont": {
          "size": 12
         },
         "type": "scattergl",
         "x": [
          17.207014083862305,
          16.98396873474121,
          17.537309646606445,
          16.736452102661133,
          17.448835372924805,
          17.35334587097168,
          17.28513526916504,
          17.55255699157715,
          17.46941375732422,
          17.245071411132812,
          16.683691024780273,
          17.53325843811035,
          17.039762496948242,
          17.403474807739258
         ],
         "y": [
          9.995655059814453,
          9.35303783416748,
          10.12859058380127,
          9.942617416381836,
          10.062126159667969,
          10.145451545715332,
          10.11943244934082,
          9.966706275939941,
          9.733724594116211,
          9.935571670532227,
          9.690241813659668,
          9.904033660888672,
          10.336864471435547,
          9.738154411315918
         ]
        },
        {
         "hoverinfo": "text",
         "hovertext": [
          "Display settings\npd.set_option('display.max_columns', None)",
          "# Settings\npd.set_option('display.max_columns', None)",
          "Display settings\npd.set_option('display.max_columns', None)",
          "Settings\npd.set_option('display.max_columns', None)",
          "Display settings\npd.set_option('display.max_columns', None)",
          "ipandas style-settings\npd.set_option('display.max_columns', None)",
          "Display settings\npd.set_option('display.max_columns', None)",
          " Some global configs\npd.set_option('display.max_columns', None)",
          "settings\npd.set_option('display.max_columns', None)",
          "Setting the settings\npd.set_option('display.max_columns', None)",
          "Settings\npd.set_option('display.max_columns', None)",
          "Display settings\npd.set_option('display.max_columns', None)",
          "Display documentation for settings\npd.describe_option('display')",
          "Display settings\npd.set_option('display.max_columns', None)"
         ],
         "marker": {
          "opacity": 0.5,
          "size": 5
         },
         "mode": "markers+text",
         "name": "229_display settings",
         "text": [
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          ""
         ],
         "textfont": {
          "size": 12
         },
         "type": "scattergl",
         "x": [
          25.343725204467773,
          24.96781349182129,
          25.427410125732422,
          25.418880462646484,
          25.552833557128906,
          25.795894622802734,
          25.6842041015625,
          25.09996223449707,
          25.456748962402344,
          25.018648147583008,
          25.461606979370117,
          25.405611038208008,
          25.93248176574707,
          25.62201690673828
         ],
         "y": [
          0.029178285971283913,
          -0.7996296882629395,
          0.04038890451192856,
          -0.39561063051223755,
          0.08859911561012268,
          -0.3040955364704132,
          0.14176177978515625,
          -0.7813036441802979,
          -0.3899238109588623,
          -0.6614119410514832,
          -0.44595035910606384,
          -0.021696817129850388,
          0.23729346692562103,
          -0.05695695802569389
         ]
        },
        {
         "hoverinfo": "text",
         "hovertext": [
          " Show the 10 first rows of the dataframe characters",
          "Display the first few rows of the dataframe containing characters",
          " Show first 3 rows of the characters dataframe",
          "Display the first few rows of the dataframe containing the characters.",
          " Display the first few rows of the dataframe containing the characters.",
          "Show the first few rows of the characters DataFrame",
          " Display the first few rows of the dataframe for the characters.",
          " Display the first few rows of the dataframe containing the characters.",
          "Dsiplay the first rows of the characters dataframe",
          "Merge the data in a single dataframe and show the first few characters",
          "Display the first records of characters dataframe to understand what we have in the dataframe",
          "Show first few rows of the characters dataframe",
          " Let's display the first 10 rows of the characters dataframe.",
          "Print the first lines of the characters csv."
         ],
         "marker": {
          "opacity": 0.5,
          "size": 5
         },
         "mode": "markers+text",
         "name": "230_Displaying rows of a dataframe with characters",
         "text": [
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          ""
         ],
         "textfont": {
          "size": 12
         },
         "type": "scattergl",
         "x": [
          9.699009895324707,
          9.222705841064453,
          8.94517993927002,
          9.639077186584473,
          9.5159330368042,
          9.41572380065918,
          9.748212814331055,
          9.627272605895996,
          9.292004585266113,
          9.11516284942627,
          9.5501070022583,
          9.328269958496094,
          10.387839317321777,
          10.298617362976074
         ],
         "y": [
          13.051675796508789,
          13.527786254882812,
          13.296899795532227,
          13.458250045776367,
          13.504598617553711,
          13.328859329223633,
          13.058320045471191,
          13.264198303222656,
          13.473479270935059,
          13.153273582458496,
          12.95457649230957,
          13.496854782104492,
          12.557021141052246,
          9.60325813293457
         ]
        },
        {
         "hoverinfo": "text",
         "hovertext": [
          "Display the first few rows of the script dataframe to understand its structure\ndf_script.head()",
          "Displaying the first 3 rows of the script DataFrame to understand its structure\ndf_script.head(3)",
          " Show the first rows of the dataframe to understand the structure of the data\ndf_script.head()",
          " Display the first few rows of the table to understand its structure\ndf_script.head()",
          "Display the first few rows of the dataframe to understand its structure\nprint(df_script.head())",
          "Displaying the first few rows of the script dataframe to understand its structure\ndf_script.head()",
          " Display the first few records of the script data to understand its structure\ndf_script.head()",
          " Display the first few rows of the dataframe to understand its structure\ndf_script.head()",
          "Display the first few rows of the dataset to understand its structure and content\ndf_script.head()",
          " Display the first few rows of the dataframe to understand its structure\ndf_script.head()",
          " Show the first rows of the dataset to understand the structure\ndf_script.head()",
          "Display the first few rows of the dataframe to understand its structure\ndf_script.head()",
          " Display the first few rows of the dataframe to understand its structure\ndf_script.head()",
          "Display the first few rows of the dataframe to understand its structure\ndf_script.head()"
         ],
         "marker": {
          "opacity": 0.5,
          "size": 5
         },
         "mode": "markers+text",
         "name": "231_Understanding the Structure of df_script DataFrame",
         "text": [
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          ""
         ],
         "textfont": {
          "size": 12
         },
         "type": "scattergl",
         "x": [
          2.8448450565338135,
          3.0540771484375,
          2.821883201599121,
          2.1456544399261475,
          3.178966999053955,
          2.877307891845703,
          3.0273935794830322,
          3.0017893314361572,
          1.9302940368652344,
          2.7853667736053467,
          3.033885955810547,
          3.026348352432251,
          2.7030727863311768,
          2.675215482711792
         ],
         "y": [
          -6.333413600921631,
          -6.721682548522949,
          -6.169179916381836,
          -6.543457984924316,
          -6.863446235656738,
          -6.194021224975586,
          -6.4746994972229,
          -6.938474655151367,
          -5.98385763168335,
          -6.8466291427612305,
          -5.509588241577148,
          -6.873814582824707,
          -6.886759281158447,
          -6.811857223510742
         ]
        },
        {
         "hoverinfo": "text",
         "hovertext": [
          "Merge the dataframes together into a single dataframe based on the episode id.",
          "Merge all the dataframes with based on the episode id to have a clear dataframe with all the information.",
          "Merge the dataframes based on the episode ID",
          "Join the dataframes on the common episode_id to create a master dataframe",
          " Merge episode data into main dataframe",
          " Merge episode data into main dataframe",
          " Join the dataframes on the episode_id",
          "Creating a subset of the DataFrame to focus on a specific episode for analysis",
          " Join all DataFrames together on episode_id",
          "Specify data type for 'episode_id' to int in all dataframes for later merging of data frames",
          "Merge the datasets on 'episode_id' to have all relevant information in one dataframe.",
          "Join the datasets on episode_id and create one big dataframe",
          "Merge the dataframes at the hand of the episode_id.",
          "Merging required dataframes for analysis - there will be repeated values as each line in the script has a unique id which maps back to the same episode and resulting title."
         ],
         "marker": {
          "opacity": 0.5,
          "size": 5
         },
         "mode": "markers+text",
         "name": "232_Dataframe merging based on episode IDs",
         "text": [
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          ""
         ],
         "textfont": {
          "size": 12
         },
         "type": "scattergl",
         "x": [
          4.571581840515137,
          4.853686332702637,
          4.539078235626221,
          4.506256580352783,
          4.784141540527344,
          4.951098918914795,
          4.855335712432861,
          4.0833740234375,
          4.401116847991943,
          4.182529449462891,
          4.62095832824707,
          4.9570088386535645,
          4.720495700836182,
          5.121871471405029
         ],
         "y": [
          3.426119089126587,
          3.0779569149017334,
          2.9981560707092285,
          2.9456357955932617,
          3.0919923782348633,
          2.931318521499634,
          3.6705782413482666,
          3.187378168106079,
          3.327150583267212,
          3.2089855670928955,
          3.090421676635742,
          3.0212793350219727,
          3.378349781036377,
          3.327483654022217
         ]
        },
        {
         "hoverinfo": "text",
         "hovertext": [
          " Display the dataframe to understand its structure\ndf_script.head()",
          "view the script dataframe to understand what information it contains\nprint(df_script.head())",
          "Show the head of the script dataframe to better understand its structure\ndf_script.head()",
          " Show head of the dataframe to understand the structure\ndf_script.head()",
          "View dataframe structure\ndf_script.head()",
          "Display the header of the DataFrame to understand its structure\ndf_script.head()",
          " Show the head of the dataframe to understand better what kind of data we are dealing with\ndf_script.head()",
          "Explore the structure of the script DataFrame\nprint(df_script.head())",
          "Visualize the head of the script DataFrame to understand its structure\ndf_script.head()",
          "Print out the dataframe to better understand its structure\ndf_script.head()",
          " View the dataframe containing the script lines\ndf_script.head()",
          "View the structure of one of the DataFrames\ndf_script.head()",
          "Inspect dataframes to get an idea of their structure\ndf_script.head()",
          " Display the scripts dataframe to understand its structure\ndf_script.head()"
         ],
         "marker": {
          "opacity": 0.5,
          "size": 5
         },
         "mode": "markers+text",
         "name": "233_Analyzing the structure of a dataframe containing scripts",
         "text": [
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          ""
         ],
         "textfont": {
          "size": 12
         },
         "type": "scattergl",
         "x": [
          5.15765905380249,
          5.6066975593566895,
          5.363299369812012,
          5.101661682128906,
          5.333077907562256,
          5.318904399871826,
          5.8863749504089355,
          5.202773094177246,
          5.618526458740234,
          5.227990627288818,
          6.487804889678955,
          4.740658283233643,
          4.83760929107666,
          4.959125995635986
         ],
         "y": [
          -5.991447925567627,
          -5.027915954589844,
          -5.8738203048706055,
          -5.94794225692749,
          -5.721304416656494,
          -6.146297454833984,
          -6.046361446380615,
          -5.463907241821289,
          -5.885439395904541,
          -5.559025764465332,
          -5.179719924926758,
          -5.6106648445129395,
          -5.012038230895996,
          -5.875026702880859
         ]
        },
        {
         "hoverinfo": "text",
         "hovertext": [
          "# Disable warning\npd.options.mode.chained_assignment = None",
          "Disabling non-used pandas warning\npd.options.mode.chained_assignment = None",
          "Setting with copy error\npd.options.mode.chained_assignment = None  # default='warn'",
          " Set Warnings to ignore in notebook\npd.set_option('mode.chained_assignment', None)",
          "Disable SettingWithCopyWarning\npd.options.mode.chained_assignment = None  # default='warn'",
          "Setting DEPRECATED SettingWithCopy Warning to False\npd.set_option('mode.chained_assignment', None)",
          "Ignore pandas warnings\npd.options.mode.chained_assignment = None",
          " to avoid several warnings\npd.options.mode.chained_assignment = None",
          "Enable validation as one validation raised unstable results\npd.options.mode.chained_assignment = None",
          "Remove warning caused by unnamed index column in data files\npd.options.mode.chained_assignment = None",
          " make sure transformations of default Jupyter mode is off\npd.set_option('mode.chained_assignment', None)",
          "Ignore SettingWithCopyWarning\npd.options.mode.chained_assignment = None",
          "Ignore pandas warning about chained assignments\npd.options.mode.chained_assignment = None",
          "Disabling the SettingWithCopyWarning in pandas, as we are interested in modifying dataframes in place and not creating copies\npd.options.mode.chained_assignment = None"
         ],
         "marker": {
          "opacity": 0.5,
          "size": 5
         },
         "mode": "markers+text",
         "name": "234_Disabling SettingWithCopyWarning in Pandas",
         "text": [
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          ""
         ],
         "textfont": {
          "size": 12
         },
         "type": "scattergl",
         "x": [
          18.240184783935547,
          18.568586349487305,
          18.379722595214844,
          18.507781982421875,
          17.911052703857422,
          17.900300979614258,
          18.44882583618164,
          18.439945220947266,
          18.505659103393555,
          18.65005111694336,
          18.134801864624023,
          17.977006912231445,
          18.387149810791016,
          18.02385711669922
         ],
         "y": [
          5.458058834075928,
          5.204147815704346,
          5.643076419830322,
          5.222387790679932,
          5.209339618682861,
          5.2822394371032715,
          5.294562816619873,
          5.571742534637451,
          5.687996864318848,
          5.6009440422058105,
          5.817811965942383,
          5.141007423400879,
          5.185019493103027,
          5.22583532333374
         ]
        },
        {
         "hoverinfo": "text",
         "hovertext": [
          "Display the first few records of each dataframe to understand its structure\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()",
          " Display the first few rows of each DataFrame to understand its structure and content.\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()",
          "Display the first few rows of each dataframe to understand its structure and contents\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()",
          "Display the first few rows of each dataframe to understand its structure\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()",
          "Display the first few rows of each dataframe to understand its structure\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()",
          "Visualizing the first few rows of the dataframes to better understand the data\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()",
          " Display the first few rows of each table to understand its structure and the information it contains.\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()",
          "Display the first few records of each dataframe to understand its structure\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()",
          "Display the first few rows of each table to understand their structure\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()",
          "Show the first few rows of each dataframe to understand their structure\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()",
          "Display the first few rows of each dataframe to understand their structure and content\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()",
          "visualize the first few rows of each dataframe to understand the structure of the dataframes.\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()",
          "Visualize the table's structure\ndf_episodes.head()",
          "Display the first few rows of each dataset to understand its structure\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()"
         ],
         "marker": {
          "opacity": 0.5,
          "size": 5
         },
         "mode": "markers+text",
         "name": "235_Exploring Dataframes - Structure and Contents",
         "text": [
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          ""
         ],
         "textfont": {
          "size": 12
         },
         "type": "scattergl",
         "x": [
          -3.8382794857025146,
          -3.676776885986328,
          -3.70855450630188,
          -3.707014799118042,
          -3.7347500324249268,
          -3.449645757675171,
          -3.330948829650879,
          -4.163314342498779,
          -3.3094136714935303,
          -3.6377408504486084,
          -3.517829656600952,
          -3.165309429168701,
          1.2972090244293213,
          -3.4014058113098145
         ],
         "y": [
          5.9876837730407715,
          6.003259658813477,
          6.186949253082275,
          5.874599933624268,
          5.951789855957031,
          6.632087707519531,
          6.406320095062256,
          6.051226615905762,
          6.330653667449951,
          6.019000053405762,
          6.096659183502197,
          6.348110198974609,
          3.432312488555908,
          5.968390941619873
         ]
        },
        {
         "hoverinfo": "text",
         "hovertext": [
          " Checking the first five rows of each dataframe",
          "Check and display the first 5 rows of each DataFrame",
          "Checking the first 5 rows from each dataframe to understand the structure of the data",
          " Check the first 5 rows of the script DataFrame",
          "Check the first 5 rows of the script dataframe to have an idea of the data",
          "Checking the first five rows of each DataFrame",
          "Checking the first 5 rows of each dataframe",
          "Checking the first 5 rows of each dataframe",
          "Check the first 5 rows of each of the dataframes.",
          "Check the shape and the first 5 rows of each DataFrame",
          "Optional: Display the first 5 entries for each dataframe to validate the import",
          "checking the datatypes and the first five rows of each dataframe",
          " Check the first 5 rows for each DataFrame to get an idea of the data",
          "Check the first 5 rows of the script dataframe"
         ],
         "marker": {
          "opacity": 0.5,
          "size": 5
         },
         "mode": "markers+text",
         "name": "236_Checking dataframe structure and data for first five rows",
         "text": [
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          ""
         ],
         "textfont": {
          "size": 12
         },
         "type": "scattergl",
         "x": [
          13.099337577819824,
          13.427423477172852,
          13.222135543823242,
          12.614385604858398,
          12.611102104187012,
          13.12960433959961,
          13.164332389831543,
          13.148681640625,
          12.68994140625,
          13.09086799621582,
          11.832569122314453,
          12.766043663024902,
          13.276585578918457,
          12.448735237121582
         ],
         "y": [
          -5.400632858276367,
          -5.802815914154053,
          -6.039832592010498,
          -5.2046918869018555,
          -5.609418869018555,
          -5.26182746887207,
          -5.441658973693848,
          -5.444055557250977,
          -5.525120735168457,
          -5.787715435028076,
          -4.148627281188965,
          -4.961893558502197,
          -5.517360687255859,
          -5.40151834487915
         ]
        },
        {
         "hoverinfo": "text",
         "hovertext": [
          "Inspecting the first rows of each dataframe\nprint(\"_\"*80)\n\nprint(\"\\nCharacters data frame\")\ndisplay(df_characters.head())\n\nprint(\"_\"*80)\n\nprint(\"\\nLocations data frame\")\ndisplay(df_locations.head())\n\nprint(\"_\"*80)\n\nprint(\"\\nScript data frame\")\ndisplay(df_script.head())\n\nprint(\"_\"*80)\n\nprint(\"\\nEpisodes data frame\")\ndisplay(df_episodes.head())",
          "Print the first few lines of each dataframe\nprint('Characters')\nprint(df_characters.head())\nprint('\\nLocations')\nprint(df_locations.head())\nprint('\\nScript')\nprint(df_script.head())\nprint('\\nEpisodes')\nprint(df_episodes.head())",
          "View the first few entries for each dataframe\nprint('Characters')\ndisplay(df_characters.head())\nprint('\\nLocations')\ndisplay(df_locations.head())\nprint('\\nScript lines')\ndisplay(df_script.head())\nprint('\\nEpisodes')\ndisplay(df_episodes.head())",
          "Print the first few rows of each dataframe to understand its structure\nprint(\"\\nCharacters:\")\nprint(df_characters.head())\nprint(\"\\nLocations:\")\nprint(df_locations.head())\nprint(\"\\nScript:\")\nprint(df_script.head())\nprint(\"\\nEpisodes:\")\nprint(df_episodes.head())",
          "Print the first three rows of each dataframe to quickly get an overview of their contents\nprint('\\nCharacters:')\nprint(df_characters.head(3))\n\nprint('\\nLocations:')\nprint(df_locations.head(3))\n\nprint('\\nScript:')\nprint(df_script.head(3))\n\nprint('\\nEpisodes:')\nprint(df_episodes.head(3))",
          "Print the first few rows of each dataframe to understand their structure\nprint(\"Characters\")\nprint(df_characters.head())\nprint(\"\\n---------------------------------\")\nprint(\"\\nLocations\")\nprint(df_locations.head())\nprint(\"\\n---------------------------------\")\nprint(\"\\nScript\")\nprint(df_script.head())\nprint(\"\\n---------------------------------\")\nprint(\"\\nEpisodes\")\nprint(df_episodes.head())",
          "Print the first 5 rows of the characters, locations, script, and episodes DataFrames\nprint(\"Characters DataFrame:\")\nprint(df_characters.head())\nprint(\"\\nLocations DataFrame:\")\nprint(df_locations.head())\nprint(\"\\nScript DataFrame:\")\nprint(df_script.head())\nprint(\"\\nEpisodes DataFrame:\")\nprint(df_episodes.head())",
          " Look at first rows of the characters dataframe\nprint(\"Characters:\")\ndisplay(df_characters.head(5))\n\n# Look at first rows of the locations dataframe\nprint(\"\\nLocations:\")\ndisplay(df_locations.head(5))\n\n# Look at first rows of the script dataframe\nprint(\"\\nScript:\")\ndisplay(df_script.head(5))\n\n# Look at first rows of the episodes dataframe\nprint(\"\\nEpisodes:\")\ndisplay(df_episodes.head(5))",
          "Display first few characters of the datasets\nprint(\"Characters\")\ndisplay(df_characters.head())\n\nprint(\"\\n\\nLocations\")\ndisplay(df_locations.head())\n\nprint(\"\\n\\nScript\")\ndisplay(df_script.head())\n\nprint(\"\\n\\nEpisodes\")\ndisplay(df_episodes.head())",
          "Print first few lines of each dataframe\nprint('Characters:')\nprint(df_characters.head())\nprint('\\n\\nLocations:')\nprint(df_locations.head())\nprint('\\n\\nScript:')\nprint(df_script.head())\nprint('\\n\\nEpisodes:')\nprint(df_episodes.head())",
          "Print the first three elements for each dataframe\nprint(\"Characters\")\nprint(df_characters.head(3), '\\n')\n\nprint(\"Locations\")\nprint(df_locations.head(3), '\\n')\n\nprint(\"Script\")\nprint(df_script.head(3), '\\n')\n\nprint(\"Episodes\")\nprint(df_episodes.head(3))",
          " Print out the first few rows of each dataframe\nprint(\"Characters:\")\nprint(df_characters.head())\n\nprint(\"\\nLocations:\")\nprint(df_locations.head())\n\nprint(\"\\nScript:\")\nprint(df_script.head())\n\nprint(\"\\nEpisodes:\")\nprint(df_episodes.head())",
          "Print the first few rows of each of the dataframes to understand the data better\nprint(\"Characters Data:\")\ndisplay(df_characters.head())\nprint(\"\\nLocations Data:\")\ndisplay(df_locations.head())\nprint(\"\\nScript Data:\")\ndisplay(df_script.head())\nprint(\"\\nEpisodes Data:\")\ndisplay(df_episodes.head())"
         ],
         "marker": {
          "opacity": 0.5,
          "size": 5
         },
         "mode": "markers+text",
         "name": "237_Dataframe Inspections",
         "text": [
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          ""
         ],
         "textfont": {
          "size": 12
         },
         "type": "scattergl",
         "x": [
          -2.293858051300049,
          -1.6587992906570435,
          -1.7830325365066528,
          -1.400870442390442,
          -1.815656065940857,
          -1.2743438482284546,
          -1.3814376592636108,
          -1.260214924812317,
          -1.3556734323501587,
          -1.3979823589324951,
          -1.7604416608810425,
          -1.4089096784591675,
          -1.7586469650268555
         ],
         "y": [
          4.6144585609436035,
          4.901371479034424,
          4.644845008850098,
          4.818213939666748,
          4.736677646636963,
          5.095045566558838,
          5.213924884796143,
          4.43651819229126,
          3.916536331176758,
          4.51962947845459,
          4.552940845489502,
          4.884418487548828,
          4.700861930847168
         ]
        },
        {
         "hoverinfo": "text",
         "hovertext": [
          "Display the first 5 lines of the table to understand its structure\ndf_characters.head()",
          "# Display first 5 rows of characters data\ndf_characters.head()",
          "List first 5 rows\ndf_characters.head(5)",
          "Display the first 5 rows of the data\ndf_characters.head()",
          "Display the first 5 rows of df_characters\ndf_characters.head()",
          "# Display the first 5 rows of the character dataset\ndf_characters.head()",
          "TODO: Show first 5 rows of df_characters",
          "display the 5 first rows of the table\ndf_characters.head()",
          "# First 5 rows\ndf_characters.head()",
          " Display first 5 rows of df_characters\ndf_characters.head()",
          "First 5 rows of df_characters\ndf_characters.head()",
          " Display first 5 rows of df_characters\ndf_characters.head()",
          " Display first 5 rows of characters\ndf_characters.head()"
         ],
         "marker": {
          "opacity": 0.5,
          "size": 5
         },
         "mode": "markers+text",
         "name": "238_df_characters.head(5)",
         "text": [
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          ""
         ],
         "textfont": {
          "size": 12
         },
         "type": "scattergl",
         "x": [
          0.15368489921092987,
          -1.1736290454864502,
          -1.455153226852417,
          -1.0306141376495361,
          -1.5620321035385132,
          -1.2875053882598877,
          -1.6764580011367798,
          -0.8334240317344666,
          -0.768636167049408,
          -1.564847707748413,
          -1.2680333852767944,
          -1.4690440893173218,
          -1.5272635221481323
         ],
         "y": [
          13.785870552062988,
          12.744255065917969,
          12.536450386047363,
          12.568253517150879,
          13.009673118591309,
          12.78787899017334,
          12.614994049072266,
          13.236761093139648,
          12.790665626525879,
          12.921478271484375,
          13.027129173278809,
          13.070403099060059,
          12.727319717407227
         ]
        },
        {
         "hoverinfo": "text",
         "hovertext": [
          "Generate length of dialogues\ndf_script['raw_character_text'] = df_script['raw_character_text'].apply(lambda x: str(x))",
          "Set text length to take into account\nTEXT_LENGTH = 3",
          "Create a new column to keep track of the total length of each line of dialogue.\ndf_script['raw_character_text'].str.len()",
          "Creates a column with length of each script line\ndf_script['line_length'] = df_script['raw_text'].str.len()",
          "Visualize the distributions of script line lengths\nline_length = df_script['normalised_text'].str.len()\nline_length.describe()",
          "Create additional column for line length\ndf_script['line_length'] = df_script['raw_text'].str.len()",
          "New column containing the number of characters in each line\ndf_script['n_characters'] = df_script.raw_text.str.len()",
          " Keep track of original length\nlen_original = len(df_script)",
          "Global data\nnlp = spacy.load('en')\n\n# Create a new column with the length of each line\ndf_script['length'] = df_script['raw_text'].apply(len)",
          " Create a column containing the length of each line of dialogue\ndf_script['length'] = df_script['raw_character_text'].str.len()",
          "Longest lines in the scripts\nlongest_script_lines = df_script[df_script['raw_text'].str.len() == df_script['raw_text'].str.len().max()]\nlongest_script_lines[['raw_text', 'timestamp_in_ms', 'speaking_line', 'character_id']]",
          "Create a column with the length of each line\ndf_script['length'] = df_script['raw_text'].apply(len)",
          " Create a new column in df_script with the length of the line of text."
         ],
         "marker": {
          "opacity": 0.5,
          "size": 5
         },
         "mode": "markers+text",
         "name": "239_Length and Track Dialogue",
         "text": [
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          ""
         ],
         "textfont": {
          "size": 12
         },
         "type": "scattergl",
         "x": [
          8.900619506835938,
          9.0938138961792,
          8.828548431396484,
          8.500133514404297,
          9.071569442749023,
          8.47695255279541,
          8.191950798034668,
          8.486145973205566,
          9.177008628845215,
          8.62566089630127,
          8.631996154785156,
          8.494894981384277,
          8.638713836669922
         ],
         "y": [
          8.434823036193848,
          7.7459611892700195,
          7.878513813018799,
          8.61789321899414,
          8.078757286071777,
          8.417181968688965,
          8.902090072631836,
          8.299160957336426,
          8.529834747314453,
          8.0633544921875,
          8.217987060546875,
          8.243673324584961,
          7.856565952301025
         ]
        },
        {
         "hoverinfo": "text",
         "hovertext": [
          "Setting random seed to 42 to determine the topic modeling outcome\nnp.random.seed(42)",
          "ensuring a random seed for notebook reproducibility\nnp.random.seed(21)",
          "Set seed for reproducibility\nnp.random.seed(42)",
          "Setting seed for reproducibility\nnp.random.seed(42)",
          "Set random seed for reproducibility\nnp.random.seed(42)",
          "Set seed for reproducibility\nnp.random.seed(42)",
          " Set Seed for Reproducibility\nnp.random.seed(seed=42)",
          "Set seed for reproducibility\nnp.random.seed(42)",
          "Random seed for reproducibility\nnp.random.seed(42)",
          "Set seed for reproducibility\nnp.random.seed(34)",
          "Set seed for reproducibility\nnp.random.seed(42)",
          " Set a seed for reproducibility of random operations\nnp.random.seed(42)",
          "Set seed for NLP\nnp.random.seed(42)"
         ],
         "marker": {
          "opacity": 0.5,
          "size": 5
         },
         "mode": "markers+text",
         "name": "240_Random Seed Reproducibility",
         "text": [
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          ""
         ],
         "textfont": {
          "size": 12
         },
         "type": "scattergl",
         "x": [
          30.08156394958496,
          30.13813591003418,
          29.627490997314453,
          29.803815841674805,
          29.888225555419922,
          29.362550735473633,
          29.66233253479004,
          29.674325942993164,
          29.944101333618164,
          29.430932998657227,
          29.51679229736328,
          29.489126205444336,
          30.238210678100586
         ],
         "y": [
          12.677722930908203,
          13.071741104125977,
          12.343511581420898,
          12.425921440124512,
          12.497051239013672,
          12.093888282775879,
          12.580212593078613,
          12.264779090881348,
          12.593942642211914,
          12.208207130432129,
          12.220319747924805,
          12.293652534484863,
          12.789632797241211
         ]
        },
        {
         "hoverinfo": "text",
         "hovertext": [
          "Merge different tables to and remove possible inconsistencies and conflicts.",
          " Join the table to have a complete table with all information",
          "Merge all data together by their foreign keys.",
          "merging everything in one table",
          "Merge using \"merge\" method",
          "Merge multiple tables to create a more complete table",
          "Merge the tables by referencing the foreign keys",
          "Merge tables",
          "Split date into year, month and day, to make it easier to aggregate later on",
          " Merge tables to allow more efficient manipulation of the data",
          "Merge data in meaningful way.",
          "Create the master table by joining the other tables",
          " Merge the data using the provided script."
         ],
         "marker": {
          "opacity": 0.5,
          "size": 5
         },
         "mode": "markers+text",
         "name": "241_Data merging and manipulation using foreign keys",
         "text": [
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          ""
         ],
         "textfont": {
          "size": 12
         },
         "type": "scattergl",
         "x": [
          10.446049690246582,
          10.064095497131348,
          10.306230545043945,
          10.324959754943848,
          11.272624969482422,
          10.429417610168457,
          10.39236068725586,
          10.701196670532227,
          10.524866104125977,
          10.389294624328613,
          10.737197875976562,
          10.678754806518555,
          10.214383125305176
         ],
         "y": [
          0.24244339764118195,
          -0.08313338458538055,
          -0.13228321075439453,
          0.5500627160072327,
          0.6304783821105957,
          -0.044976040720939636,
          -0.16196002066135406,
          0.3414972722530365,
          1.2788844108581543,
          0.27480998635292053,
          0.10999085754156113,
          0.12137653678655624,
          0.5932981967926025
         ]
        },
        {
         "hoverinfo": "text",
         "hovertext": [
          "Preprocess the data and perform exploratory data analysis (EDA)",
          "Exploratory data analysis (EDA)",
          " STEP 1: Exploratory Data Analysis (EDA)",
          "Exploratory Data Analysis (EDA)",
          "First, let's perform some basic exploratory data analysis (EDA) to get a feel for the data.",
          "EDA",
          "EDA - Samples",
          "# # Exploratory Data Analysis (EDA)",
          "Exploratory Data Analysis (EDA)",
          "Exploratory Data Analysis (EDA)",
          "Exploratory Data Analysis (EDA)",
          "Exploratory Data Analysis (EDA)",
          "needed in the EDA portion of the assignment"
         ],
         "marker": {
          "opacity": 0.5,
          "size": 5
         },
         "mode": "markers+text",
         "name": "242_Exploratory Data Analysis (EDA)",
         "text": [
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          ""
         ],
         "textfont": {
          "size": 12
         },
         "type": "scattergl",
         "x": [
          18.655319213867188,
          18.45999526977539,
          18.369556427001953,
          18.612865447998047,
          17.905872344970703,
          18.73908233642578,
          18.64175033569336,
          18.585573196411133,
          18.505281448364258,
          18.364355087280273,
          18.536073684692383,
          18.564891815185547,
          18.670127868652344
         ],
         "y": [
          -5.109520435333252,
          -5.046873569488525,
          -4.809321403503418,
          -4.870246887207031,
          -4.227497577667236,
          -5.152802467346191,
          -5.272241592407227,
          -5.126056671142578,
          -4.9761857986450195,
          -5.003937244415283,
          -4.976737022399902,
          -5.00311279296875,
          -5.339657783508301
         ]
        },
        {
         "hoverinfo": "text",
         "hovertext": [
          "Set plot style\nmatplotlib.style.use('fivethirtyeight')",
          "Set styles and color palettes for the matplotlib visualisations\nplt.style.use('fivethirtyeight')\nmatplotlib.rcParams['font.family'] = 'monospace'\nsns.set_palette(\"husl\", 7)",
          " Setup matplotlib style\nplt.style.use('fivethirtyeight')",
          "Setting up matplotlib styles\nplt.style.use('fivethirtyeight')",
          "set up the plotting style\nmatplotlib.style.use('fivethirtyeight')",
          "Set custom style form matplotlib\nplt.style.use('fivethirtyeight')",
          "Configure matplotlib styles and defaults\nplt.style.use('fivethirtyeight')",
          "Setup matplotlib styles\nplt.style.use('fivethirtyeight')",
          "Set up matplotlib style\nplt.style.use('fivethirtyeight')",
          " Set the script to use the 'fivethirtyeight' matplotlib style\nplt.style.use('fivethirtyeight')",
          "Optional, specify matplotlib style\nplt.style.use('fivethirtyeight')",
          "Configure matplotlib style\nplt.style.use('fivethirtyeight')",
          " Set matplotlib style\nplt.style.use('fivethirtyeight')"
         ],
         "marker": {
          "opacity": 0.5,
          "size": 5
         },
         "mode": "markers+text",
         "name": "243_matplotlib style configuration",
         "text": [
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          ""
         ],
         "textfont": {
          "size": 12
         },
         "type": "scattergl",
         "x": [
          21.564638137817383,
          21.63443946838379,
          22.279111862182617,
          22.085193634033203,
          21.490219116210938,
          22.04630470275879,
          21.794036865234375,
          21.929018020629883,
          21.97661018371582,
          21.790830612182617,
          22.163679122924805,
          22.209819793701172,
          21.978214263916016
         ],
         "y": [
          5.281190872192383,
          5.288051128387451,
          5.65260124206543,
          5.517340183258057,
          5.429336071014404,
          5.858119964599609,
          5.313930511474609,
          5.633492946624756,
          5.74399471282959,
          5.937081336975098,
          5.70344352722168,
          5.5899553298950195,
          5.8667826652526855
         ]
        },
        {
         "hoverinfo": "text",
         "hovertext": [
          "Remove column \"id\" as it is unnecessary\ndf_script.drop(columns=['id'], inplace=True)",
          "Create a series with the lines of the script\ns_script_lines = df_script[['id', 'raw_text']].set_index('id').squeeze()",
          "Dropping the scriptid column, and indexing by this column",
          "Rename the 'id' column to 'script_id' in df_script DataFrame\ndf_script.rename(columns={'id': 'script_id'}, inplace=True)",
          " Setting the index to line_id for simplicity\ndf_script.set_index('id', inplace=True)",
          "Set index of scripts to line_id\ndf_script.set_index('id', inplace=True)",
          " Set the script Unique Id as index\ndf_script.set_index('id', inplace=True)",
          "Make scripts dataframe indexable by raw/positional index and id\ndf_script.set_index(pd.Index([df_script.id, df_script.index]), inplace=True)",
          " Set the script dataset index\ndf_script.set_index('id', inplace=True)",
          " Remove the first column\ndf_script = df_script.drop(['Unnamed: 0'], axis=1)",
          "Setting the script dataframe id to be the index of the dataframe.",
          "Make copy of data and set index\ndf_script_clean = df_script.copy()\ndf_script_clean.set_index('id', inplace=True)",
          " Set the `index` of the `DataFrame` `df_script` to be the column `'id'`\ndf_script.set_index('id', inplace=True)"
         ],
         "marker": {
          "opacity": 0.5,
          "size": 5
         },
         "mode": "markers+text",
         "name": "244_Setting the index of a DataFrame and making it indexable by id and positional index",
         "text": [
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          ""
         ],
         "textfont": {
          "size": 12
         },
         "type": "scattergl",
         "x": [
          5.515091419219971,
          5.5083537101745605,
          6.36864709854126,
          5.093733310699463,
          5.884613990783691,
          5.929189682006836,
          5.95999002456665,
          5.3754963874816895,
          5.536844730377197,
          5.791609764099121,
          5.769474029541016,
          5.663338661193848,
          5.441742420196533
         ],
         "y": [
          4.456976413726807,
          4.381274223327637,
          3.460761547088623,
          4.459053039550781,
          3.451547622680664,
          3.470133066177368,
          3.5902557373046875,
          2.7955822944641113,
          3.3513331413269043,
          3.8929288387298584,
          2.939314126968384,
          3.9829885959625244,
          3.488414764404297
         ]
        },
        {
         "hoverinfo": "text",
         "hovertext": [
          "Set default style for plots",
          "Set default style for plotting",
          "Set up custom color palette for visualizations\ncolors = [\n    \"lightblue\",\n    \"blue\",\n    \"royalblue\",\n    \"cornflowerblue\",\n    \"lightsteelblue\",\n]",
          "Set the style of matplotlib plots\nmatplotlib.pyplot.style.use('dark_background')",
          "Setting some display options, and adding a custom color palette for plots.",
          "Set custom color palette for matplotlib",
          " Set up the visualisation defaults",
          "Set the font preferences and other preferences to make the plots look nicer",
          "Set the style of the plots.",
          "We also set some default style parameters for the plots.",
          "Set some plot configs for visual consistency",
          " Set the default style for plots",
          "Set default style for plots"
         ],
         "marker": {
          "opacity": 0.5,
          "size": 5
         },
         "mode": "markers+text",
         "name": "245_Setting default plot style in matplotlib",
         "text": [
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          ""
         ],
         "textfont": {
          "size": 12
         },
         "type": "scattergl",
         "x": [
          19.780614852905273,
          19.623035430908203,
          20.361671447753906,
          20.82371711730957,
          19.087495803833008,
          20.8136043548584,
          18.793506622314453,
          19.65610694885254,
          19.248449325561523,
          19.24530792236328,
          19.82163429260254,
          19.680429458618164,
          19.713212966918945
         ],
         "y": [
          5.073602676391602,
          4.707038879394531,
          4.263799667358398,
          4.7878289222717285,
          4.627713203430176,
          4.570911407470703,
          4.544187545776367,
          5.620883941650391,
          5.033428192138672,
          4.83180046081543,
          4.7576680183410645,
          4.982828617095947,
          4.998215675354004
         ]
        },
        {
         "hoverinfo": "text",
         "hovertext": [
          " Load the processed data from pickle files",
          "View the content of each file",
          "Check some sample data for each file",
          " Let's start by taking a look at the structure of these files.",
          "Check the content of these files.",
          "Let's take a brief look at these files.",
          " Check Files Size in MB",
          "View the content of each file",
          " Quick look at the contents of each file",
          "Look at the content of each file.",
          "Let's check the contents of these files.",
          "Check the content of the files",
          "Check the content of each file."
         ],
         "marker": {
          "opacity": 0.5,
          "size": 5
         },
         "mode": "markers+text",
         "name": "246_View file content",
         "text": [
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          ""
         ],
         "textfont": {
          "size": 12
         },
         "type": "scattergl",
         "x": [
          13.948847770690918,
          14.080041885375977,
          13.759415626525879,
          14.717904090881348,
          14.647903442382812,
          14.63223648071289,
          14.003108024597168,
          13.948871612548828,
          13.998318672180176,
          14.451879501342773,
          14.980415344238281,
          14.568065643310547,
          14.406718254089355
         ],
         "y": [
          0.8325314521789551,
          1.2268385887145996,
          0.7153822183609009,
          1.9111424684524536,
          2.1906821727752686,
          1.1552156209945679,
          1.3652526140213013,
          1.5463145971298218,
          1.6725425720214844,
          1.5476810932159424,
          1.5365396738052368,
          1.745134949684143,
          2.006744384765625
         ]
        },
        {
         "hoverinfo": "text",
         "hovertext": [
          "Display the first few rows of the dataframe `df_characters`",
          "Inspect content of the `df_characters` dataframe by displaying its first few rows",
          " Examine the first few lines of the characters dataframe\ndf_characters.head()",
          "Inspect the first lines of the characters dataframe\ndf_characters.head()",
          "Inspect the first few lines of the characters dataframe\ndf_characters.head()",
          "Explore the first lines of the characters DataFrame\ndf_characters.head()",
          "Let's display first rows of `df_characters` DataFrame.",
          "Read few lines of the characters dataframe\ndf_characters.head()",
          "Inspectig the first few lines of the df_characters dataframe",
          "Inspect the first few lines of the characters dataframe\nprint(df_characters.head())",
          "Examine the first few lines of the characters dataframe\ndf_characters.head()",
          "Inspecting first few lines of 'characters' dataframe\ndf_characters.head()",
          "Display the dataframes to inspect the first few rows of each dataframe\ndf_characters"
         ],
         "marker": {
          "opacity": 0.5,
          "size": 5
         },
         "mode": "markers+text",
         "name": "247_Inspecting first few rows of df_characters dataframe",
         "text": [
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          ""
         ],
         "textfont": {
          "size": 12
         },
         "type": "scattergl",
         "x": [
          8.467300415039062,
          8.100187301635742,
          6.292604923248291,
          6.081177234649658,
          6.047441005706787,
          5.688952922821045,
          7.8410468101501465,
          6.590071201324463,
          6.744344711303711,
          5.988508224487305,
          6.112118244171143,
          6.227687358856201,
          8.225597381591797
         ],
         "y": [
          14.211135864257812,
          14.46533203125,
          18.210214614868164,
          18.373445510864258,
          18.56336212158203,
          18.20011329650879,
          14.361712455749512,
          17.796674728393555,
          17.03842544555664,
          18.519275665283203,
          17.967164993286133,
          18.34686279296875,
          14.365887641906738
         ]
        },
        {
         "hoverinfo": "text",
         "hovertext": [
          "Reformat script\ndf_script['timestamp_in_ms'] = pd.to_numeric(df_script['timestamp_in_ms'], errors='coerce')\ndf_script['timestamp_in_seconds'] = df_script['timestamp_in_ms'] / 1000\ndf_script['timestamp_in_minutes'] = df_script['timestamp_in_seconds'] / 60",
          "# Fix timestamps\ndf_script['timestamp_in_ms'] = df_script['timestamp_in_ms'].replace('Timestamp(\\'', '').str.replace('\\')','').astype(int)",
          "Deal with decimal type column\ndf_script['timestamp_in_ms'] = df_script['timestamp_in_ms'].fillna(0.0).astype(np.int64)\n\n# Convert `timestamp_in_ms` to datetime\ndf_script['timestamp_in_ms'] = pd.to_datetime(df_script['timestamp_in_ms'], unit='ms').dt.time",
          " Compute time column from start and end timestamps\ndf_script['time'] = pd.to_datetime(df_script.timestamp_in, unit='s') - pd.to_datetime(df_script.timestamp_out, unit='s')",
          " Remove unwanted columns\ndel df_script['id']\ndel df_script['number']\ndel df_script['raw_text']\ndel df_script['timestamp_in_ms']",
          "# THESE LINES MIGHT NEED TO BE UNCOMMENTED IF THEY THROW AN ERROR.\n# df_script['timestamp_in_ms'] = df_script['timestamp_in_ms'].astype(float).astype(int)",
          " Convert timestamps to datetime\ndf_script['timestamp_in_ms'] = df_script['timestamp_in_ms'].apply(pd.to_datetime)",
          "Remove unnecessary columns\ndf_script = df_script.drop(columns=['id', 'number', 'raw_text', 'timestamp_in_ms'])",
          "Preprocessing\n# Convert timestamps to datetime objects\ndf_script.timestamp_in_ms = pd.to_datetime(df_script.timestamp_in_ms, unit='ms')\n\n# Extract script and achors\nscripts = df_script.normalized_text\nanchors = df_script.raw_text",
          "Setting correct data types for the script data frame\ndf_script['timestamp_in_ms'] = pd.to_numeric(df_script['timestamp_in_ms'], errors='coerce').fillna(0).astype(np.int64)\ndf_script['timestamp_in_ms'] = pd.to_numeric(df_script['timestamp_in_ms'], downcast='integer')\n\ndf_script['number'] = pd.to_numeric(df_script['number'], errors='coerce').fillna(0).astype(np.int32)\ndf_script['number'] = pd.to_numeric(df_script['number'], downcast='integer')",
          "# Preprocessing\ndf_script = df_script.fillna('')\n\n# Fix datatypes\ndf_script['id'] = df_script['id'].astype(int)\ndf_script['number'] = df_script['number'].astype(int)\ndf_script['raw_text'] = df_script['raw_text'].astype(str)\ndf_script['timestamp_in_ms'] = df_script['timestamp_in_ms'].astype(int)",
          "Add timestamp to the script dataframe",
          "Remove 'time' from timestamp column and set it to datetime\ndf_script['timestamp_in_ms'] = df_script['timestamp_in_ms'].str.split('.', expand=True)[0]"
         ],
         "marker": {
          "opacity": 0.5,
          "size": 5
         },
         "mode": "markers+text",
         "name": "248_Dataframe Timestamp Manipulation",
         "text": [
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          ""
         ],
         "textfont": {
          "size": 12
         },
         "type": "scattergl",
         "x": [
          4.490843772888184,
          5.026678085327148,
          4.548522472381592,
          4.656492233276367,
          5.359494686126709,
          4.853670597076416,
          4.4834699630737305,
          5.490923881530762,
          4.628886699676514,
          4.529122829437256,
          4.843773365020752,
          4.9864277839660645,
          4.761921405792236
         ],
         "y": [
          2.625563383102417,
          2.974597930908203,
          2.697679281234741,
          2.0970535278320312,
          4.186855792999268,
          3.419894218444824,
          2.1533806324005127,
          4.3928022384643555,
          2.3604164123535156,
          3.329423427581787,
          3.7725651264190674,
          2.513559103012085,
          2.8339345455169678
         ]
        },
        {
         "hoverinfo": "text",
         "hovertext": [
          "Show head of `df_characters` to understand its structure\ndf_characters.head()",
          " Test\ndf_characters.head()",
          "Characters\ndf_characters.head()",
          "df_characters.head()",
          "Exemplo como utilizar a base de dados \ndf_characters.head()",
          " Showing head of df_characters to understand its structure\ndf_characters.head()",
          "\ndf_characters.head()",
          "df_characters.head()",
          "res/head()",
          "df_characters.head()",
          "\ndf_characters.head()",
          "\ndf_characters.head()",
          "Let's check the df_characters head"
         ],
         "marker": {
          "opacity": 0.5,
          "size": 5
         },
         "mode": "markers+text",
         "name": "249_df_characters.head()",
         "text": [
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          ""
         ],
         "textfont": {
          "size": 12
         },
         "type": "scattergl",
         "x": [
          7.655142307281494,
          8.655394554138184,
          8.64708423614502,
          8.100798606872559,
          8.325480461120605,
          7.941744327545166,
          8.244751930236816,
          8.366371154785156,
          8.51058292388916,
          8.449678421020508,
          8.26832389831543,
          8.422229766845703,
          7.4500651359558105
         ],
         "y": [
          15.654095649719238,
          15.163003921508789,
          15.420042037963867,
          15.131567001342773,
          15.680370330810547,
          15.478930473327637,
          15.187650680541992,
          15.302671432495117,
          15.646768569946289,
          15.243603706359863,
          15.220072746276855,
          15.34315299987793,
          14.445051193237305
         ]
        },
        {
         "hoverinfo": "text",
         "hovertext": [
          "Load the dataset into pandas dataframes",
          "Load data into a pandas dataframe.",
          "Load the data files into Pandas dataframes",
          "Reading the data into pandas dataframes",
          "Create an alias for the pandas library, pd.",
          "Loading the data into Pandas DataFrames",
          "Loading the data into dataframes",
          "Build a Panda Script using Dataframes",
          "Load data from DataFrame",
          "Loads data into dataframes for further analysis.",
          "Imports and loading of dataframes",
          "Load the data into pandas DataFrames",
          "Code to load data from CSV files into pandas dataframes"
         ],
         "marker": {
          "opacity": 0.5,
          "size": 5
         },
         "mode": "markers+text",
         "name": "250_Loading Data into Pandas DataFrames",
         "text": [
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          ""
         ],
         "textfont": {
          "size": 12
         },
         "type": "scattergl",
         "x": [
          11.416448593139648,
          11.296586036682129,
          11.108101844787598,
          11.124176025390625,
          19.230356216430664,
          11.142666816711426,
          10.566184043884277,
          10.42151927947998,
          10.476282119750977,
          11.637466430664062,
          11.514205932617188,
          11.115959167480469,
          11.269281387329102
         ],
         "y": [
          -2.0726158618927,
          -1.9065018892288208,
          -1.6565355062484741,
          -1.9075443744659424,
          1.4979643821716309,
          -1.7932019233703613,
          -2.1198928356170654,
          -1.6671231985092163,
          -1.8804529905319214,
          -2.011631727218628,
          -2.0824005603790283,
          -1.9008902311325073,
          -1.325560212135315
         ]
        },
        {
         "hoverinfo": "text",
         "hovertext": [
          "Remove duplicated episode titles and join tables",
          "Join the datasets on the column \"episode_id\"",
          " Merge dataset on character id, location id, and episode id",
          "Check we can join the relevant tables on the episode ID",
          "Merge the datasets on episode_id and character_id",
          "Join the datasets on the episode id",
          " Merge the datasets into a single one based on 'episode_id' and 'id' columns.",
          "Merge all the datasets on 'episode_id' to get a complete view of each episode.",
          "Merge the different datasets by their episodes' ID",
          "Merge the data on `episode_id`",
          "Join the datasets on the episode_id and write the resulting DataFrame to a CSV file.",
          "Merge the datasets on episode id",
          "Create datasets for each episode"
         ],
         "marker": {
          "opacity": 0.5,
          "size": 5
         },
         "mode": "markers+text",
         "name": "251_Merging and Joining Datasets on Episode and Character IDs",
         "text": [
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          ""
         ],
         "textfont": {
          "size": 12
         },
         "type": "scattergl",
         "x": [
          5.619707107543945,
          5.4452433586120605,
          6.271883964538574,
          6.217160701751709,
          5.892854690551758,
          5.959824085235596,
          5.523340225219727,
          5.759272575378418,
          5.65199613571167,
          5.63671875,
          5.567117691040039,
          5.958300590515137,
          5.545653820037842
         ],
         "y": [
          3.3423962593078613,
          3.211960554122925,
          2.778277635574341,
          3.6298651695251465,
          2.653477668762207,
          3.4115562438964844,
          3.015738010406494,
          3.4812850952148438,
          3.1225974559783936,
          2.986119270324707,
          3.3829925060272217,
          2.806607246398926,
          3.1660208702087402
         ]
        },
        {
         "hoverinfo": "text",
         "hovertext": [
          "Check the size of each dataset\nprint('Characters:', df_characters.shape)\nprint('Locations:', df_locations.shape)\nprint('Script:', df_script.shape)\nprint('Episodes:', df_episodes.shape)",
          "Check the dataframe dimensions\nprint('Characters shape:', df_characters.shape)\nprint('Locations shape:', df_locations.shape)\nprint('Script shape:', df_script.shape)\nprint('Episodes shape:', df_episodes.shape)",
          " Original dataframe sizes\nprint('Characters:', df_characters.shape)\nprint('Locations:', df_locations.shape)\nprint('Script:', df_script.shape)\nprint('Episodes:', df_episodes.shape)",
          "print(f\"Script size: {df_script.shape}, Characters size:  {df_characters.shape}, Locations size: {df_locations.shape},  Episodes size: {df_episodes.shape}\")",
          "Let's take a quick look at the shapes of the dataframes to have an understanding of the size of each dataset.\n\nprint(\"Characters shape:\", df_characters.shape)\nprint(\"Locations shape:\", df_locations.shape)\nprint(\"Script shape:\", df_script.shape)\nprint(\"Episodes shape:\", df_episodes.shape)",
          "\nprint('Characters dataset size:', df_characters.shape)\nprint('Locations dataset size:', df_locations.shape)\nprint('Script dataset size:', df_script.shape)\nprint('Episodes dataset size:', df_episodes.shape)",
          "Check basic dimensions\nprint(df_characters.shape)\nprint(df_locations.shape)\nprint(df_script.shape)\nprint(df_episodes.shape)",
          " Print the size of the datasets\nprint(\"Characters: \", df_characters.shape)\nprint(\"Locations: \", df_locations.shape)\nprint(\"Script: \", df_script.shape)\nprint(\"Episodes: \", df_episodes.shape)",
          "Display the size of the datasets\nprint(\"Characters:\", df_characters.shape)\nprint(\"Locations:\", df_locations.shape)\nprint(\"Script lines:\", df_script.shape)\nprint(\"Episodes:\", df_episodes.shape)",
          "Check the size of each dataset\nprint('Characters dataset shape:', df_characters.shape)\nprint('Locations dataset shape:', df_locations.shape)\nprint('Script dataset shape:', df_script.shape)\nprint('Episodes dataset shape:', df_episodes.shape)",
          "Display sizes of the dataframes\ndf_characters.shape, df_locations.shape, df_script.shape, df_episodes.shape",
          "Check dataset sizes\nprint(f'Simpsons Characters Dataset: {df_characters.shape}')\nprint(f'Simpsons Locations Dataset: {df_locations.shape}')\nprint(f'Simpsons Script Dataset: {df_script.shape}')\nprint(f'Simpsons Episodes Dataset: {df_episodes.shape}')"
         ],
         "marker": {
          "opacity": 0.5,
          "size": 5
         },
         "mode": "markers+text",
         "name": "252_Checking dataset sizes",
         "text": [
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          ""
         ],
         "textfont": {
          "size": 12
         },
         "type": "scattergl",
         "x": [
          0.6055670976638794,
          0.759034276008606,
          1.3360669612884521,
          0.935083270072937,
          1.0782170295715332,
          1.1689505577087402,
          0.9366918802261353,
          1.1748323440551758,
          1.574750542640686,
          0.5420747995376587,
          1.8131418228149414,
          1.091783881187439
         ],
         "y": [
          -1.264682412147522,
          -1.2179120779037476,
          -1.15566086769104,
          -1.607248067855835,
          -1.092667818069458,
          -1.6939793825149536,
          -1.4946682453155518,
          -1.4372540712356567,
          -1.3016952276229858,
          -1.2867070436477661,
          -1.5814037322998047,
          -1.327812671661377
         ]
        },
        {
         "hoverinfo": "text",
         "hovertext": [
          "Merge script lines with characters and episodes\ndf_merged = pd.merge(df_script, df_characters, how='left', left_on='character_id', right_on='id')\ndf_merged = pd.merge(df_merged, df_episodes, how='left', left_on='episode_id', right_on='id').rename(columns={'name_x':'character', 'normalized_name':'location', 'name_y':'episode'})\n\n# Visualize the data\ndf_merged.head()",
          " Merge episodes and script lines\ndf_episodes['id'] = df_episodes['id'].astype(int)\ndf_merged = df_script.merge(df_episodes, left_on='episode_id', right_on='id').iloc[:, 2:]\n\n# Add location names\ndf_merged = df_merged.merge(df_locations, how='left', left_on='raw_location_text', right_on='raw_location_text')\n\n# Keep relevant columns\ndf_merged = df_merged[[\n    'id', 'spoken_words', 'raw_location_text', 'name', 'normalized_name', 'production_code', 'original_air_date', 'season', \n    'number_in_season', 'number_in_series', 'us_viewers_in_millions', 'views', 'imdb_rating', 'imdb_votes', 'image_url'\n]].rename({\n    'spoken_words': 'dialogue',\n    'raw_location_text': 'location',\n    'name': 'episode_name',\n    'normalized_name': 'location_name'\n}, axis=1)",
          "Merge characters information\ndf_episodes = pd.merge(df_episodes, df_characters, left_on='character_id', right_on='id', how='left', suffixes=('', '_character'))\ndf_episodes.rename(columns={'name': 'character_name', 'normalized_name': 'character_normalized_name'}, inplace=True)",
          " Merge the script with the characters and locations\ndf_script_char = df_script.merge(df_characters[['id', 'normalized_name']], \n                                how='left', \n                                left_on='character_id', \n                                right_on='id').rename(columns={'normalized_name' : 'character'})\ndf_script_char_loc = df_script_char.merge(df_locations, \n                                          how='left', \n                                          left_on='raw_location_id', \n                                          right_on='normalized_name').rename(columns={'normalized_name' : 'location'})\n\n# Select only the important columns\ndf_script_char_loc = df_script_char_loc[['episode_id', 'id', 'number', 'raw_character_text', 'raw_location_text',\n                                         'speaking_line', 'character_id', 'location_id', 'character', 'location']]",
          "Merge the script with character, location and episode info\ndf_merged = df_script.merge(df_characters[['id', 'normalized_name']], left_on='character_id', right_on='id', how='left').rename(columns={'normalized_name': 'character'}).drop(columns='id')\ndf_merged = df_merged.merge(df_locations[['id', 'normalized_name']], left_on='location_id', right_on='id', how='left').rename(columns={'normalized_name': 'location'}).drop(columns='id')\ndf_merged = df_merged.merge(df_episodes[['id', 'title']], left_on='episode_id', right_on='id', how='left').rename(columns={'title': 'episode'}).drop(columns='id')\n\n# Drop rows with no episode info\ndf_merged = df_merged.dropna(subset=['episode'])\n\n# Reset index\ndf_merged = df_merged.reset_index(inplace=False, drop=True)",
          "Merge character information\ndf_characters = df_characters.rename(columns={'id': 'character_id'})\ndf_script = df_script.merge(df_characters, on='character_id')\n\n# Merge location information\ndf_locations = df_locations.rename(columns={'id': 'location_id'})\ndf_script = df_script.merge(df_locations, on='location_id')\n\n# Merge episode information\ndf_episodes = df_episodes.rename(columns={'id': 'episode_id'})\ndf_script = df_script.merge(df_episodes, on='episode_id')",
          "# Combine locations and episodes\n# First, rename the column to enable merging with episodes\ndf_locations.rename(columns={'id':'location_id'}, inplace=True)\n\n# Then, inner join the two dataframes on 'location_id'\ndf_location_episodes = df_locations.merge(df_episodes, on='location_id', how='inner')\n\ndf_characters.rename(columns={'id':'character_id'}, inplace=True)\ndf_main_character_episode = df_characters.merge(df_episodes, on='main_character_id', how='inner')",
          "Merge characters, locations, and episode name into script data\ndf_data = pd.merge(df_script, df_characters[['id', 'name', 'normalized_name']],\n                   left_on='character_id', right_on='id').drop(columns=['id']).rename(\n    columns={'name': 'character_name', 'normalized_name': 'character_normalized_name'})\ndf_data = pd.merge(df_data, df_locations[['id', 'name', 'normalized_name']],\n                   left_on='location_id', right_on='id').drop(columns=['id']).rename(\n    columns={'name': 'location_name', 'normalized_name': 'location_normalized_name'})\ndf_data = pd.merge(df_data, df_episodes[['id', 'title']],\n                   left_on='episode_id', right_on='id').drop(columns=['id']).rename(\n    columns={'title': 'episode_title'})",
          "Merge multiple dataframes into one by episode number\ndf_full = df_script.merge(df_episodes, how='left', on='episode_id')\ndf_full = df_full.merge(df_characters, how='left', on='character_id')\ndf_full = df_full.merge(df_locations, how='left', on='location_id')\n\n# Create a DataFrame 'df_dialogue' to store the relevant columns\ndf_dialogue = df_full[['episode_id', 'number', 'raw_text', 'name', 'normalized_name', 'us_president', 'location', 'normalized_location']]\ndf_dialogue.rename(columns={'number': 'episode_number', 'raw_text': 'dialogue', 'name': 'character_name', 'normalized_name': 'character_id', 'us_president': 'president'}, inplace=True)",
          "merge script with character and location data\ndf_characters.rename(columns={'id': 'character_id'}, inplace=True)\ndf_locations.rename(columns={'id': 'location_id'}, inplace=True)\ndf_episodes.rename(columns={'id': 'episode_id'}, inplace=True)\n\ndf_script = pd.merge(df_script,\n                     df_characters[['character_id', 'name']],\n                     on='character_id')\ndf_script = pd.merge(df_script,\n                     df_locations[['location_id', 'name']],\n                     on='location_id')\ndf_script = pd.merge(df_script,\n                     df_episodes[['episode_id', 'title']],\n                     on='episode_id')",
          "# Merge all the datasets\ndf_merged = df_script.merge(df_episodes, on='episode_id', suffixes=('_script', '_episode'))\ndf_merged = df_merged.merge(df_characters, on='character_id', suffixes=('_merged', '_character'))\ndf_merged = df_merged.merge(df_locations, on='location_id', suffixes=('_merged', '_location'))\n\n# Rename some columns for clarity\ndf_merged = df_merged.rename(columns={'normalized_text': 'spoken_words', 'name_merged': 'character_name', 'name_location': 'location_name'})",
          "Merge select columns from the script, character, and episode datasets\ndf_merged = df_script[['episode_id', 'character_id', 'location_id', 'raw_text']]\ndf_merged = df_merged.merge(df_characters[['id', 'name']], left_on='character_id', right_on='id').drop(columns=['id'])\ndf_merged = df_merged.merge(df_locations[['id', 'name']], left_on='location_id', right_on='id').drop(columns=['id'])\ndf_merged = df_merged.merge(df_episodes[['id', 'title']], left_on='episode_id', right_on='id').drop(columns=['id'])\n\n# Rename columns\ndf_merged.columns = ['episode_id', 'character_id', 'location_id', 'raw_text', 'character_name', 'location_name', 'episode_title']\n\n# Display the merged dataframe\ndf_merged.head()"
         ],
         "marker": {
          "opacity": 0.5,
          "size": 5
         },
         "mode": "markers+text",
         "name": "253_Data merging and renaming in Python",
         "text": [
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          ""
         ],
         "textfont": {
          "size": 12
         },
         "type": "scattergl",
         "x": [
          2.622600793838501,
          3.1363768577575684,
          2.9767465591430664,
          3.269862651824951,
          2.863420248031616,
          2.575565814971924,
          2.2921013832092285,
          3.0573904514312744,
          3.164780378341675,
          2.7436351776123047,
          3.5237252712249756,
          2.454704523086548
         ],
         "y": [
          7.799036026000977,
          7.627899646759033,
          7.969504356384277,
          7.774463176727295,
          8.263238906860352,
          7.818340301513672,
          7.946722030639648,
          8.181923866271973,
          8.24842357635498,
          8.003743171691895,
          8.075695991516113,
          8.014982223510742
         ]
        },
        {
         "hoverinfo": "text",
         "hovertext": [
          "# This is a special utility function that helps clean the memory (RAM) by performing garbage collection\n# It's not that important to understand the details of this function, but it can help us avoid running out of memory\ndef clean_memory():\n    \"\"\"\n    Perform a full garbage collection and return the memory usage\n\n    Returns\n    -------\n    memory_usage: float\n        Memory usage in GB after running the garbage collection\n    \"\"\"\n    gc.enable()\n    gc.collect()\n    return psutil.Process(os.getpid()).memory_info().rss / 10**9",
          "TODO: Check memory usage and optimize if needed",
          "Transform some columns to the right data type for memory reduction",
          "Creating a good memory management function in order to reduce the memory usage of the dataset.",
          "Optimizing memory usage",
          "Clean up and remove unwated columns in order to speed up data loading and manipulation",
          "Converting to the right types to minimize memory usage",
          "Insane size, check compatibility also on low-RAM environments, e.g. enable arrow-based downcasting.",
          "To reduce memory usage, we should convert some columns to categoricals.",
          "Set the correct data types for each Dataframe to optimize the memory usage",
          "Keep only necessary columns to avoid RAM exhaustion",
          "Reduce memory footprint by downcasting integers and replacing objects with categoricals."
         ],
         "marker": {
          "opacity": 0.5,
          "size": 5
         },
         "mode": "markers+text",
         "name": "254_Memory optimization and management",
         "text": [
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          ""
         ],
         "textfont": {
          "size": 12
         },
         "type": "scattergl",
         "x": [
          11.195853233337402,
          11.950813293457031,
          10.796819686889648,
          11.417070388793945,
          11.562724113464355,
          10.452929496765137,
          11.5401611328125,
          12.769246101379395,
          10.747821807861328,
          10.161446571350098,
          10.437005043029785,
          11.392674446105957
         ],
         "y": [
          1.1887043714523315,
          1.1159905195236206,
          0.664680540561676,
          0.7712416052818298,
          0.7340742349624634,
          1.6911275386810303,
          1.091273546218872,
          0.987442672252655,
          0.7771509289741516,
          0.12566408514976501,
          1.0168906450271606,
          0.9901513457298279
         ]
        },
        {
         "hoverinfo": "text",
         "hovertext": [
          "Preview the datasets\ndf_characters.head()",
          "Preview the characters dataset\ndf_characters.head()",
          " Preview the characters dataset\ndf_characters.head()",
          "Preview the first dataset to get an idea\ndf_characters.head()",
          "Preview the characters dataset\ndf_characters.head()",
          "Preview the characters dataset\ndf_characters.head()",
          " Preview datasets\ndf_characters.head()",
          "Preview datasets\ndf_characters.head()",
          "# Preview of the characters dataset\ndf_characters.head()",
          "Preview the characters dataset\ndf_characters.head()",
          "Preview the characters dataset\ndf_characters.head()",
          "Preview the datasets to understand their structure and content\ndf_characters.head()"
         ],
         "marker": {
          "opacity": 0.5,
          "size": 5
         },
         "mode": "markers+text",
         "name": "255_Dataset Structure and Content Preview with df_characters.head()",
         "text": [
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          ""
         ],
         "textfont": {
          "size": 12
         },
         "type": "scattergl",
         "x": [
          1.0921934843063354,
          1.3330748081207275,
          1.2543076276779175,
          0.9704418778419495,
          1.373602271080017,
          1.3796108961105347,
          0.7389572262763977,
          0.9252071380615234,
          0.9518398642539978,
          1.2280726432800293,
          1.2758033275604248,
          0.9121198058128357
         ],
         "y": [
          14.2153959274292,
          13.755718231201172,
          14.19891357421875,
          14.269195556640625,
          13.98150634765625,
          13.898965835571289,
          14.156455039978027,
          14.089363098144531,
          14.305878639221191,
          14.316756248474121,
          13.925773620605469,
          13.987196922302246
         ]
        },
        {
         "hoverinfo": "text",
         "hovertext": [
          "# Show first lines of dataframes\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()",
          "### Show the first lines of each dataframe\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()",
          " Display the first few lines of each dataframe\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()",
          " Show first lines of each dataframe to understand their content\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()",
          "Examining the data\n# Display the first few lines of each dataframe\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()",
          " Display the first lines of the loaded DataFrames\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()",
          "Display the first few lines of each dataframe\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()",
          " Display the first few lines of each dataframe\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()",
          "display first lines of each dataframe\ndisplay(df_characters.head())\ndisplay(df_locations.head())\ndisplay(df_script.head())\ndisplay(df_episodes.head())",
          "Display the first few lines of each of the dataframes\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()",
          "Display the first few lines of each dataset\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()",
          " Display the first few lines of each dataframe\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()"
         ],
         "marker": {
          "opacity": 0.5,
          "size": 5
         },
         "mode": "markers+text",
         "name": "256_Examining loaded dataframes",
         "text": [
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          ""
         ],
         "textfont": {
          "size": 12
         },
         "type": "scattergl",
         "x": [
          -4.99343204498291,
          -5.440186500549316,
          -4.9596686363220215,
          -5.270540237426758,
          -5.055338382720947,
          -5.328488826751709,
          -4.897141456604004,
          -5.2671098709106445,
          -5.174742221832275,
          -5.250699996948242,
          -4.761201858520508,
          -5.222835540771484
         ],
         "y": [
          5.912382125854492,
          5.6724700927734375,
          5.491138935089111,
          5.551980495452881,
          5.312403678894043,
          5.706002712249756,
          5.370532989501953,
          5.580161094665527,
          5.409245014190674,
          5.6883955001831055,
          5.466657638549805,
          5.42731237411499
         ]
        },
        {
         "hoverinfo": "text",
         "hovertext": [
          "View the first 5 lines of df_characters\ndf_characters.head()",
          "View the first 5 lines of the characters dataframe\ndf_characters.head()",
          "Display first 5 lines of characters dataset\ndf_characters.head()",
          "Print the first 5 lines of the characters dataframe\nprint(df_characters.head())",
          "Show the first 5 lines of the characters dataframe\ndf_characters.head()",
          "Display the first 5 lines of the characters dataframe\ndf_characters.head()",
          "View first 5 lines of the characters dataframe\ndf_characters.head()",
          "Display first 5 lines of the characters dataset\ndf_characters.head()",
          "Display first 5 lines of df_characters\ndf_characters.head(5)",
          " Display the first 5 lines of the characters DataFrame\ndf_characters.head()",
          " Show the first 5 lines of the df_characters DataFrame\ndf_characters.head()",
          " Display the top 5 character lines in the dataset\ndf_script.head()"
         ],
         "marker": {
          "opacity": 0.5,
          "size": 5
         },
         "mode": "markers+text",
         "name": "257_Display top 5 character lines in dataset",
         "text": [
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          ""
         ],
         "textfont": {
          "size": 12
         },
         "type": "scattergl",
         "x": [
          -0.01844007335603237,
          -0.13703186810016632,
          0.14917294681072235,
          -0.7613731026649475,
          -0.21754953265190125,
          -0.34596434235572815,
          -0.09061214327812195,
          0.12084691226482391,
          -0.2921901047229767,
          -0.14574994146823883,
          -0.306753009557724,
          0.8544520735740662
         ],
         "y": [
          12.57790756225586,
          12.0641450881958,
          12.491535186767578,
          11.413603782653809,
          12.175589561462402,
          12.01683235168457,
          12.377753257751465,
          12.48945426940918,
          12.581565856933594,
          12.075235366821289,
          11.975167274475098,
          13.229336738586426
         ]
        },
        {
         "hoverinfo": "text",
         "hovertext": [
          "Check if the dataframes were propertly loaded\ndf_characters.head()",
          "Encoding errors in dataframe_character dataset\ndf_characters[df_characters.original_title.str.contains('�')]",
          "Check for a correct import by visualizing the head of the characters dataframe\ndf_characters.head()",
          "Check imported DataFrames\ndf_characters.head()",
          "Check the first few rows of the dataframe to verify that the data was loaded properly\ndf_characters.head()",
          "Ensure the correct encoding for each dataframe",
          "Check if dataframes were imported correctly\ndf_characters.head()",
          "Verify the dataframes are correctly loaded\ndf_characters.head()",
          "Check if the dataframes have been imported correctly\ndf_characters.head()",
          "Check the head of the dataframe to ensure information was imported correctly\ndf_characters.head()",
          "Checking if the dataframe has been successfully loaded\nprint(df_characters.head())",
          "Check everything imported correctly\ndf_characters.head()"
         ],
         "marker": {
          "opacity": 0.5,
          "size": 5
         },
         "mode": "markers+text",
         "name": "258_Checking if dataframes were imported correctly",
         "text": [
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          ""
         ],
         "textfont": {
          "size": 12
         },
         "type": "scattergl",
         "x": [
          5.671733856201172,
          5.863351345062256,
          5.442648887634277,
          5.207093238830566,
          5.95974588394165,
          6.290431499481201,
          5.349493026733398,
          5.990819931030273,
          5.721982479095459,
          5.736294269561768,
          5.604041576385498,
          5.227940559387207
         ],
         "y": [
          12.516464233398438,
          11.079853057861328,
          11.782809257507324,
          12.403305053710938,
          12.729598999023438,
          10.872085571289062,
          11.924138069152832,
          12.286026954650879,
          11.91380786895752,
          11.212295532226562,
          12.263969421386719,
          11.861637115478516
         ]
        },
        {
         "hoverinfo": "text",
         "hovertext": [
          "Preview the dataframes\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()",
          "Preview the data\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()",
          "Preview the data.frames\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()",
          "Preview the dataframes\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()",
          "Preview the data in each DataFrame\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()",
          "Preview the dataframes\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()",
          "Preview tables\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()",
          "Preview the datasets\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()",
          "Preview all dataframes\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()",
          " Show a preview of each DataFrame\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()",
          "Optional - Preview tables\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()",
          "Preview the dataframes\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()"
         ],
         "marker": {
          "opacity": 0.5,
          "size": 5
         },
         "mode": "markers+text",
         "name": "259_Previewing dataframes and tables in",
         "text": [
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          ""
         ],
         "textfont": {
          "size": 12
         },
         "type": "scattergl",
         "x": [
          -3.588345766067505,
          -3.3429195880889893,
          -3.7652039527893066,
          -3.6530325412750244,
          -4.051869869232178,
          -3.5283100605010986,
          -3.1834044456481934,
          -2.940347194671631,
          -3.859788179397583,
          -4.135009765625,
          -3.412616014480591,
          -3.5803675651550293
         ],
         "y": [
          3.9921414852142334,
          4.053094863891602,
          4.233671188354492,
          4.138915061950684,
          4.264540195465088,
          4.358043193817139,
          3.5817060470581055,
          4.006830215454102,
          4.221746921539307,
          4.1609086990356445,
          3.707589864730835,
          3.905599355697632
         ]
        },
        {
         "hoverinfo": "text",
         "hovertext": [
          "Inspect the structure of each dataframe\ndf_characters.head()",
          " let's take a look at individual dataframes to understand their structure and contents\ndf_characters.head()",
          "Inspect the structure of each dataframe\ndf_characters.head()",
          "Look at the top few rows of each dataframe to understand the data structure\ndf_characters.head()",
          "Inspect the data frames to understand their structure and contents\ndf_characters.head()",
          "# The data spans accross 4 tables, which are related between each other with keys.\ndf_characters.head()\n",
          "Let's take a look at the first few rows of the df_characters dataframe to understand its structure and contents.\ndf_characters.head()",
          "Inspect the structure of the `df_characters` dataframe\ndf_characters.head()",
          " Look at the dataframes to understand their structures\ndf_characters.head()",
          "Inspect the dataframes to understand their structure and content\ndf_characters.head()",
          "Examine dataframe structure\ndf_characters.head()",
          "Take a look at the dataframes and the structure of the data in each of them\ndf_characters.head()"
         ],
         "marker": {
          "opacity": 0.5,
          "size": 5
         },
         "mode": "markers+text",
         "name": "260_Understanding the Structure and Contents of Dataframes",
         "text": [
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          ""
         ],
         "textfont": {
          "size": 12
         },
         "type": "scattergl",
         "x": [
          4.916914463043213,
          5.460242748260498,
          5.0377373695373535,
          5.322880268096924,
          5.185393810272217,
          5.647546768188477,
          5.862355709075928,
          5.672341346740723,
          5.400489330291748,
          5.035218715667725,
          4.771768569946289,
          5.910854816436768
         ],
         "y": [
          15.545723915100098,
          15.71894645690918,
          15.348024368286133,
          15.119644165039062,
          15.184407234191895,
          14.560956954956055,
          15.505670547485352,
          15.525562286376953,
          15.286182403564453,
          15.608610153198242,
          15.055638313293457,
          14.74669361114502
         ]
        },
        {
         "hoverinfo": "text",
         "hovertext": [
          " Let's start by looking at the first few rows of each dataset to understand their structure.",
          " Let's take a look at the first few rows of each dataset to understand its structure.",
          "We'll look at the first few records of each dataset to understand their structure better.",
          "We can glimpse at each dataset to understand the structure and the information that it contains.",
          "Because we are working with real-life data, let's take a look at the first few rows of each dataset to understand their structure.",
          "Now, let's take a look at the first few rows of each dataset to understand their structure and contents.",
          " Let's take a look at the first few lines of each dataset to understand its structure.",
          "Understand the structure of the datasets",
          "Let's take a glance at the first five rows of the dataset to understand its structure and content.",
          "Let's take a look at the structure and the first few rows of these datasets.",
          " Looking at the first few lines of each dataset to understand the structure and the type of data present",
          "Let's take a look at the first few rows of our datasets to understand their structure."
         ],
         "marker": {
          "opacity": 0.5,
          "size": 5
         },
         "mode": "markers+text",
         "name": "261_Understanding the Structure of Datasets",
         "text": [
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          ""
         ],
         "textfont": {
          "size": 12
         },
         "type": "scattergl",
         "x": [
          14.645118713378906,
          14.730342864990234,
          14.917667388916016,
          15.31812858581543,
          14.41518783569336,
          14.695181846618652,
          14.826409339904785,
          15.092166900634766,
          14.404241561889648,
          15.119368553161621,
          14.925572395324707,
          14.781859397888184
         ],
         "y": [
          -3.506078004837036,
          -3.942460060119629,
          -3.7736916542053223,
          -3.1053459644317627,
          -4.1158905029296875,
          -3.608335018157959,
          -3.593925952911377,
          -3.0343291759490967,
          -3.7611024379730225,
          -3.8059895038604736,
          -2.8875906467437744,
          -4.06879186630249
         ]
        },
        {
         "hoverinfo": "text",
         "hovertext": [
          "Previewing the dataframes",
          "Preview some dataframes",
          "Preview the dataframes",
          "Display a preview of the dataframes",
          "Preview the dataframes",
          "Previewing the dataframes",
          "Preview and reset index of all dataframes",
          " Preview the data to understand the structure and contents of each dataframe",
          "Get preview of the data in each of the DataFrames",
          "To ensure that the data has been read correctly, we can display a preview of each DataFrame using the `head()` method.",
          "Preview the dataframes to understand their structure and available columns",
          "Let's preview the dataframes"
         ],
         "marker": {
          "opacity": 0.5,
          "size": 5
         },
         "mode": "markers+text",
         "name": "262_Previewing dataframes",
         "text": [
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          ""
         ],
         "textfont": {
          "size": 12
         },
         "type": "scattergl",
         "x": [
          18.357051849365234,
          18.165719985961914,
          18.264434814453125,
          18.531021118164062,
          18.24886131286621,
          18.279691696166992,
          17.939210891723633,
          17.984600067138672,
          18.10471534729004,
          18.357160568237305,
          18.348773956298828,
          18.56296157836914
         ],
         "y": [
          -3.536311388015747,
          -3.5755321979522705,
          -3.461749315261841,
          -3.4660401344299316,
          -3.5435283184051514,
          -3.388963222503662,
          -3.6499199867248535,
          -3.9399123191833496,
          -3.345036268234253,
          -3.888578176498413,
          -3.8030173778533936,
          -3.782912492752075
         ]
        },
        {
         "hoverinfo": "text",
         "hovertext": [
          "Extract characters' genders and ages\ngenders = {}\nages = {}\n\nfor index, row in df_characters.iterrows():\n    genders[row['id']] = row['gender']\n    ages[row['id']] = row['age']",
          "Reformat the character construction.\ndf_characters = df_characters[['id', 'name', 'normalized_name', 'gender', 'description', 'job', 'img_url']]",
          " Replace f'{gender}:aplha' by f'{gender}:alpha' for the characters dataframe\ndf_characters['gender'] = df_characters['gender'].replace({'f':'female', 'm':'male', 'n':'neutral'})",
          "ne hot encoding to deal with the gender variable\ndf_characters['gender'] = pd.get_dummies(df_characters['gender'])\n\n# Replacing bad symbols in the raw text\ndf_script['raw_text'] = df_script['raw_text'].str.replace('\\n', ' ')",
          "Create a dictionary that maps character names to their gender\nchar_gender_dict = df_characters.groupby('name').first().gender.to_dict()",
          "Extract genders for characters_forename column\ndf_characters[['forename', 'gender']].sample(10)",
          "Select characters gender and distinct genders\ngenders = df_characters[['gender', 'name']].drop_duplicates().dropna()",
          "Select required columns from df_characters\ndf_characters = df_characters[['id', 'name', 'normalized_name', 'gender']]\ndf_characters.head()",
          " Character to gender mapping\ndf_gender = df_characters[['raw_character_text', 'gender']].groupby('raw_character_text').agg(lambda x: x.value_counts().index[0])",
          "# Function converting categorical columns to category type\ndef convert_categorical(df, cols):\n    for col in cols:\n        df[col] = df[col].astype('category')",
          "Extract the gender and the line\ndf_script_lines = df_script[['character_id', 'location_id', 'gender', 'normalized_text']]"
         ],
         "marker": {
          "opacity": 0.5,
          "size": 5
         },
         "mode": "markers+text",
         "name": "263_Gender analysis and data manipulation",
         "text": [
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          ""
         ],
         "textfont": {
          "size": 12
         },
         "type": "scattergl",
         "x": [
          6.424230575561523,
          6.317129135131836,
          6.565943717956543,
          6.33089017868042,
          7.1169023513793945,
          6.730258941650391,
          6.443973541259766,
          6.325194835662842,
          6.952441692352295,
          6.851417541503906,
          6.367447376251221
         ],
         "y": [
          8.505440711975098,
          9.402058601379395,
          7.412381172180176,
          8.730487823486328,
          8.360858917236328,
          8.14402961730957,
          7.910378932952881,
          9.12208366394043,
          8.486948013305664,
          8.957006454467773,
          7.424768924713135
         ]
        },
        {
         "hoverinfo": "text",
         "hovertext": [
          "Visualize the number of lines per character\ndf_characters['line_count'] = df_script['character_id'].value_counts()\ndf_characters_merged = df_characters.merge(df_locations, left_on='location_id', right_on='id', how='left')\ndf_characters_merged['line_count'] = df_characters_merged['line_count'].fillna(0)",
          "Visualizing data\n# Counting lines for each character\nlines_per_character = df_script['character_id'].value_counts()\nlines_per_character = lines_per_character.reset_index(inplace=False)\nlines_per_character.columns = ['character_id', 'lines']",
          " Visualization on the number of lines for each character and location.\nchar_lines = df_script['character_id'].value_counts()\nchar_lines = char_lines[char_lines.index != 'nan']\nchar_lines = char_lines[char_lines.index != ''])\nloc_lines = df_script['location_id'].value_counts()\nloc_lines = loc_lines[loc_lines.index != 'nan']\nloc_lines = loc_lines[loc_lines.index != ''])",
          " Calculate the number of lines that contain the lines spoken by each character\nlines_per_character = df_script.groupby('character_id').size()\nlines_per_character = lines_per_character.sort_values(ascending=False)",
          "Top 10 most popular characters\ntop_characters = df_script['character_id'].value_counts().head(10)\n# Change character numeric ID to character name\ntop_characters = pd.DataFrame(top_characters).merge(df_characters, left_index=True, right_on='id').set_index('id')\ntop_characters.columns = ['count', 'character_name']",
          "Aggregating script lines by character ID\nlines_per_character = df_script[df_script.speaking_line == True].groupby('character_id').agg('count').reset_index()\nlines_per_character = lines_per_character[['character_id', 'id']]\nlines_per_character.columns = ['character_id', 'line_count']",
          "Count the frequency of each character in the script\ncount_char = Counter(df_script['character_id'])\ntop_10_char = count_char.most_common(10)",
          "Count the number of script lines by character\nscript_lines_count = df_script['character_id'].value_counts()",
          "Calculate the number of lines for each character\nlines_per_character = df_script['character_id'].value_counts()",
          "counts number of lines each character has\nlines_per_character = df_script\n    .groupby('raw_character_text')['id']\n    .count()",
          "Visualize the number of lines spoken by each character\nline_count = df_script['character_id'].value_counts()\ntop_characters = line_count.nlargest(10)"
         ],
         "marker": {
          "opacity": 0.5,
          "size": 5
         },
         "mode": "markers+text",
         "name": "264_Character Lines",
         "text": [
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          ""
         ],
         "textfont": {
          "size": 12
         },
         "type": "scattergl",
         "x": [
          7.9450883865356445,
          7.864171504974365,
          7.280386924743652,
          8.120238304138184,
          7.2905120849609375,
          7.573884963989258,
          7.679380416870117,
          7.802789211273193,
          7.988738059997559,
          8.094582557678223,
          8.595664978027344
         ],
         "y": [
          8.913911819458008,
          9.54527759552002,
          8.865431785583496,
          8.938417434692383,
          10.179280281066895,
          8.779594421386719,
          9.810676574707031,
          9.175528526306152,
          9.168481826782227,
          8.855729103088379,
          9.243903160095215
         ]
        },
        {
         "hoverinfo": "text",
         "hovertext": [
          " We need a parser to process the script\nnlp = spacy.load('en_core_web_sm')",
          " For spaCy\nnlp = spacy.load('en_core_web_sm')",
          "#global variables\nnlp = spacy.load(\"en_core_web_sm\")",
          "nlp = spacy.load('en_core_web_sm')",
          "General settings\nplt.style.use('fivethirtyeight')\nnlp = spacy.load('en_core_web_sm')",
          "nlp = spacy.load(\"en_core_web_sm\")",
          "nlp = spacy.load(\"en_core_web_sm\")",
          "nlp = spacy.load('en_core_web_sm')",
          "NLP tools\nnlp = spacy.load('en_core_web_sm')",
          "\nnlp = spacy.load(\"en_core_web_sm\")",
          "nlp = spacy.load('en_core_web_sm')"
         ],
         "marker": {
          "opacity": 0.5,
          "size": 5
         },
         "mode": "markers+text",
         "name": "265_NLP Tools with Spacy",
         "text": [
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          ""
         ],
         "textfont": {
          "size": 12
         },
         "type": "scattergl",
         "x": [
          15.161639213562012,
          15.613601684570312,
          16.26685905456543,
          15.546331405639648,
          15.769330024719238,
          15.683775901794434,
          15.443042755126953,
          15.490363121032715,
          15.642780303955078,
          15.574663162231445,
          15.799142837524414
         ],
         "y": [
          8.680275917053223,
          9.261909484863281,
          8.637630462646484,
          9.110316276550293,
          9.189620018005371,
          8.99990463256836,
          8.874994277954102,
          9.295099258422852,
          9.190925598144531,
          8.918537139892578,
          9.26888656616211
         ]
        },
        {
         "hoverinfo": "text",
         "hovertext": [
          " Visualize the first few rows of the characters dataframe\ndf_characters.head()",
          " Visualize the first few rows of the characters dataframe\ndf_characters.head()",
          "Visual Representation of the Data\n# Show the first 5 rows of the characters dataframe\ndf_characters.head()",
          " visualize the first few rows of the characters dataframe\ndf_characters.head()",
          " Visualize the first 5 rows of the characters dataframe\ndf_characters.head()",
          " Visualise first few entries in characters database\ndf_characters.head()",
          "# Visualizing the first few rows of the characters dataframe\ndf_characters.head()",
          "Visualize the first few rows of the characters DataFrame\ndf_characters.head()",
          " Visualize the first few rows of the characters dataframe\ndf_characters.head()",
          "Visualise the first characters of the DataFrame 'df_characters'",
          " Visualize the first few rows of the characters dataframe\ndf_characters.head()"
         ],
         "marker": {
          "opacity": 0.5,
          "size": 5
         },
         "mode": "markers+text",
         "name": "266_Visualizing the first few rows of the characters dataframe",
         "text": [
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          ""
         ],
         "textfont": {
          "size": 12
         },
         "type": "scattergl",
         "x": [
          -1.1215406656265259,
          -1.3747923374176025,
          -1.3025774955749512,
          -1.1181379556655884,
          -1.3176023960113525,
          0.5131878852844238,
          -1.005571961402893,
          -0.9061102867126465,
          -1.1680214405059814,
          7.600157737731934,
          -1.2123363018035889
         ],
         "y": [
          22.28818702697754,
          22.440114974975586,
          21.91986656188965,
          22.291114807128906,
          21.80807113647461,
          18.47804069519043,
          22.343971252441406,
          22.245250701904297,
          22.360828399658203,
          15.27103328704834,
          22.42549705505371
         ]
        },
        {
         "hoverinfo": "text",
         "hovertext": [
          "Change values that are \"bad\" to NaN so that I can easily inspect if I have any of these in the dataset",
          "The first thing to do is to remove NaN values.",
          "Remove all lines with NaN values, and all values that are the empty string",
          "Check if there are any NaNs in the data",
          "We need to remove some columns and nan values from scripts dataframe",
          "Merge dataframes and remove rows in which there are at least one NaN value",
          "Display which rows had NaN values for the script data\ndf_script[df_script.isna().any(axis=1)]",
          "Check for any NaN's in the data",
          "Filtering the data to remove unnecessary columns and NaN values",
          "remove columns with mostly nan's"
         ],
         "marker": {
          "opacity": 0.5,
          "size": 5
         },
         "mode": "markers+text",
         "name": "267_Handling NaN Values in Dataframes",
         "text": [
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          ""
         ],
         "textfont": {
          "size": 12
         },
         "type": "scattergl",
         "x": [
          7.056744575500488,
          7.642185688018799,
          7.391637325286865,
          6.722513198852539,
          7.267445087432861,
          7.625410079956055,
          6.562579154968262,
          7.069887161254883,
          8.500152587890625,
          7.926601409912109
         ],
         "y": [
          1.8831467628479004,
          2.2273151874542236,
          2.487213373184204,
          1.5077731609344482,
          2.3773887157440186,
          2.525984048843384,
          2.0442862510681152,
          1.6002179384231567,
          2.2855358123779297,
          2.3501062393188477
         ]
        }
       ],
       "layout": {
        "annotations": [
         {
          "showarrow": false,
          "text": "D1",
          "x": -13.100666427612305,
          "y": 9.764388632774352,
          "yshift": 10
         },
         {
          "showarrow": false,
          "text": "D2",
          "x": 12.287337017059325,
          "xshift": 10,
          "y": 32.65453567504883
         }
        ],
        "height": 1000,
        "shapes": [
         {
          "line": {
           "color": "#CFD8DC",
           "width": 2
          },
          "type": "line",
          "x0": 12.287337017059325,
          "x1": 12.287337017059325,
          "y0": -13.125758409500122,
          "y1": 32.65453567504883
         },
         {
          "line": {
           "color": "#9E9E9E",
           "width": 2
          },
          "type": "line",
          "x0": -13.100666427612305,
          "x1": 37.675340461730954,
          "y0": 9.764388632774352,
          "y1": 9.764388632774352
         }
        ],
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "rgb(36,36,36)"
            },
            "error_y": {
             "color": "rgb(36,36,36)"
            },
            "marker": {
             "line": {
              "color": "white",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "white",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "rgb(36,36,36)",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "rgb(36,36,36)"
            },
            "baxis": {
             "endlinecolor": "rgb(36,36,36)",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "rgb(36,36,36)"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 1,
             "tickcolor": "rgb(36,36,36)",
             "ticks": "outside"
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 1,
             "tickcolor": "rgb(36,36,36)",
             "ticks": "outside"
            },
            "colorscale": [
             [
              0,
              "#440154"
             ],
             [
              0.1111111111111111,
              "#482878"
             ],
             [
              0.2222222222222222,
              "#3e4989"
             ],
             [
              0.3333333333333333,
              "#31688e"
             ],
             [
              0.4444444444444444,
              "#26828e"
             ],
             [
              0.5555555555555556,
              "#1f9e89"
             ],
             [
              0.6666666666666666,
              "#35b779"
             ],
             [
              0.7777777777777778,
              "#6ece58"
             ],
             [
              0.8888888888888888,
              "#b5de2b"
             ],
             [
              1,
              "#fde725"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 1,
             "tickcolor": "rgb(36,36,36)",
             "ticks": "outside"
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 1,
             "tickcolor": "rgb(36,36,36)",
             "ticks": "outside"
            },
            "colorscale": [
             [
              0,
              "#440154"
             ],
             [
              0.1111111111111111,
              "#482878"
             ],
             [
              0.2222222222222222,
              "#3e4989"
             ],
             [
              0.3333333333333333,
              "#31688e"
             ],
             [
              0.4444444444444444,
              "#26828e"
             ],
             [
              0.5555555555555556,
              "#1f9e89"
             ],
             [
              0.6666666666666666,
              "#35b779"
             ],
             [
              0.7777777777777778,
              "#6ece58"
             ],
             [
              0.8888888888888888,
              "#b5de2b"
             ],
             [
              1,
              "#fde725"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 1,
             "tickcolor": "rgb(36,36,36)",
             "ticks": "outside"
            },
            "colorscale": [
             [
              0,
              "#440154"
             ],
             [
              0.1111111111111111,
              "#482878"
             ],
             [
              0.2222222222222222,
              "#3e4989"
             ],
             [
              0.3333333333333333,
              "#31688e"
             ],
             [
              0.4444444444444444,
              "#26828e"
             ],
             [
              0.5555555555555556,
              "#1f9e89"
             ],
             [
              0.6666666666666666,
              "#35b779"
             ],
             [
              0.7777777777777778,
              "#6ece58"
             ],
             [
              0.8888888888888888,
              "#b5de2b"
             ],
             [
              1,
              "#fde725"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "line": {
              "color": "white",
              "width": 0.6
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 1,
             "tickcolor": "rgb(36,36,36)",
             "ticks": "outside"
            },
            "colorscale": [
             [
              0,
              "#440154"
             ],
             [
              0.1111111111111111,
              "#482878"
             ],
             [
              0.2222222222222222,
              "#3e4989"
             ],
             [
              0.3333333333333333,
              "#31688e"
             ],
             [
              0.4444444444444444,
              "#26828e"
             ],
             [
              0.5555555555555556,
              "#1f9e89"
             ],
             [
              0.6666666666666666,
              "#35b779"
             ],
             [
              0.7777777777777778,
              "#6ece58"
             ],
             [
              0.8888888888888888,
              "#b5de2b"
             ],
             [
              1,
              "#fde725"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 1,
             "tickcolor": "rgb(36,36,36)",
             "ticks": "outside"
            },
            "colorscale": [
             [
              0,
              "#440154"
             ],
             [
              0.1111111111111111,
              "#482878"
             ],
             [
              0.2222222222222222,
              "#3e4989"
             ],
             [
              0.3333333333333333,
              "#31688e"
             ],
             [
              0.4444444444444444,
              "#26828e"
             ],
             [
              0.5555555555555556,
              "#1f9e89"
             ],
             [
              0.6666666666666666,
              "#35b779"
             ],
             [
              0.7777777777777778,
              "#6ece58"
             ],
             [
              0.8888888888888888,
              "#b5de2b"
             ],
             [
              1,
              "#fde725"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 1,
             "tickcolor": "rgb(36,36,36)",
             "ticks": "outside"
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 1,
              "tickcolor": "rgb(36,36,36)",
              "ticks": "outside"
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 1,
              "tickcolor": "rgb(36,36,36)",
              "ticks": "outside"
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 1,
              "tickcolor": "rgb(36,36,36)",
              "ticks": "outside"
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 1,
              "tickcolor": "rgb(36,36,36)",
              "ticks": "outside"
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 1,
              "tickcolor": "rgb(36,36,36)",
              "ticks": "outside"
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 1,
              "tickcolor": "rgb(36,36,36)",
              "ticks": "outside"
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 1,
              "tickcolor": "rgb(36,36,36)",
              "ticks": "outside"
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 1,
              "tickcolor": "rgb(36,36,36)",
              "ticks": "outside"
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 1,
              "tickcolor": "rgb(36,36,36)",
              "ticks": "outside"
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 1,
              "tickcolor": "rgb(36,36,36)",
              "ticks": "outside"
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 1,
             "tickcolor": "rgb(36,36,36)",
             "ticks": "outside"
            },
            "colorscale": [
             [
              0,
              "#440154"
             ],
             [
              0.1111111111111111,
              "#482878"
             ],
             [
              0.2222222222222222,
              "#3e4989"
             ],
             [
              0.3333333333333333,
              "#31688e"
             ],
             [
              0.4444444444444444,
              "#26828e"
             ],
             [
              0.5555555555555556,
              "#1f9e89"
             ],
             [
              0.6666666666666666,
              "#35b779"
             ],
             [
              0.7777777777777778,
              "#6ece58"
             ],
             [
              0.8888888888888888,
              "#b5de2b"
             ],
             [
              1,
              "#fde725"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "rgb(237,237,237)"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "rgb(217,217,217)"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 1,
            "tickcolor": "rgb(36,36,36)",
            "ticks": "outside"
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "rgb(103,0,31)"
            ],
            [
             0.1,
             "rgb(178,24,43)"
            ],
            [
             0.2,
             "rgb(214,96,77)"
            ],
            [
             0.3,
             "rgb(244,165,130)"
            ],
            [
             0.4,
             "rgb(253,219,199)"
            ],
            [
             0.5,
             "rgb(247,247,247)"
            ],
            [
             0.6,
             "rgb(209,229,240)"
            ],
            [
             0.7,
             "rgb(146,197,222)"
            ],
            [
             0.8,
             "rgb(67,147,195)"
            ],
            [
             0.9,
             "rgb(33,102,172)"
            ],
            [
             1,
             "rgb(5,48,97)"
            ]
           ],
           "sequential": [
            [
             0,
             "#440154"
            ],
            [
             0.1111111111111111,
             "#482878"
            ],
            [
             0.2222222222222222,
             "#3e4989"
            ],
            [
             0.3333333333333333,
             "#31688e"
            ],
            [
             0.4444444444444444,
             "#26828e"
            ],
            [
             0.5555555555555556,
             "#1f9e89"
            ],
            [
             0.6666666666666666,
             "#35b779"
            ],
            [
             0.7777777777777778,
             "#6ece58"
            ],
            [
             0.8888888888888888,
             "#b5de2b"
            ],
            [
             1,
             "#fde725"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#440154"
            ],
            [
             0.1111111111111111,
             "#482878"
            ],
            [
             0.2222222222222222,
             "#3e4989"
            ],
            [
             0.3333333333333333,
             "#31688e"
            ],
            [
             0.4444444444444444,
             "#26828e"
            ],
            [
             0.5555555555555556,
             "#1f9e89"
            ],
            [
             0.6666666666666666,
             "#35b779"
            ],
            [
             0.7777777777777778,
             "#6ece58"
            ],
            [
             0.8888888888888888,
             "#b5de2b"
            ],
            [
             1,
             "#fde725"
            ]
           ]
          },
          "colorway": [
           "#1F77B4",
           "#FF7F0E",
           "#2CA02C",
           "#D62728",
           "#9467BD",
           "#8C564B",
           "#E377C2",
           "#7F7F7F",
           "#BCBD22",
           "#17BECF"
          ],
          "font": {
           "color": "rgb(36,36,36)"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "white",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "white",
          "polar": {
           "angularaxis": {
            "gridcolor": "rgb(232,232,232)",
            "linecolor": "rgb(36,36,36)",
            "showgrid": false,
            "showline": true,
            "ticks": "outside"
           },
           "bgcolor": "white",
           "radialaxis": {
            "gridcolor": "rgb(232,232,232)",
            "linecolor": "rgb(36,36,36)",
            "showgrid": false,
            "showline": true,
            "ticks": "outside"
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "white",
            "gridcolor": "rgb(232,232,232)",
            "gridwidth": 2,
            "linecolor": "rgb(36,36,36)",
            "showbackground": true,
            "showgrid": false,
            "showline": true,
            "ticks": "outside",
            "zeroline": false,
            "zerolinecolor": "rgb(36,36,36)"
           },
           "yaxis": {
            "backgroundcolor": "white",
            "gridcolor": "rgb(232,232,232)",
            "gridwidth": 2,
            "linecolor": "rgb(36,36,36)",
            "showbackground": true,
            "showgrid": false,
            "showline": true,
            "ticks": "outside",
            "zeroline": false,
            "zerolinecolor": "rgb(36,36,36)"
           },
           "zaxis": {
            "backgroundcolor": "white",
            "gridcolor": "rgb(232,232,232)",
            "gridwidth": 2,
            "linecolor": "rgb(36,36,36)",
            "showbackground": true,
            "showgrid": false,
            "showline": true,
            "ticks": "outside",
            "zeroline": false,
            "zerolinecolor": "rgb(36,36,36)"
           }
          },
          "shapedefaults": {
           "fillcolor": "black",
           "line": {
            "width": 0
           },
           "opacity": 0.3
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "rgb(232,232,232)",
            "linecolor": "rgb(36,36,36)",
            "showgrid": false,
            "showline": true,
            "ticks": "outside"
           },
           "baxis": {
            "gridcolor": "rgb(232,232,232)",
            "linecolor": "rgb(36,36,36)",
            "showgrid": false,
            "showline": true,
            "ticks": "outside"
           },
           "bgcolor": "white",
           "caxis": {
            "gridcolor": "rgb(232,232,232)",
            "linecolor": "rgb(36,36,36)",
            "showgrid": false,
            "showline": true,
            "ticks": "outside"
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "rgb(232,232,232)",
           "linecolor": "rgb(36,36,36)",
           "showgrid": false,
           "showline": true,
           "ticks": "outside",
           "title": {
            "standoff": 15
           },
           "zeroline": false,
           "zerolinecolor": "rgb(36,36,36)"
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "rgb(232,232,232)",
           "linecolor": "rgb(36,36,36)",
           "showgrid": false,
           "showline": true,
           "ticks": "outside",
           "title": {
            "standoff": 15
           },
           "zeroline": false,
           "zerolinecolor": "rgb(36,36,36)"
          }
         }
        },
        "title": {
         "font": {
          "color": "Black",
          "size": 22
         },
         "text": "Next Thing After Importing Data:",
         "x": 0.5,
         "xanchor": "center",
         "yanchor": "top"
        },
        "width": 1800,
        "xaxis": {
         "visible": false
        },
        "yaxis": {
         "visible": false
        }
       }
      },
      "text/html": [
       "<div>                            <div id=\"2abf5e4c-ad08-4842-95db-956069ec5f0f\" class=\"plotly-graph-div\" style=\"height:1000px; width:1800px;\"></div>            <script type=\"text/javascript\">                require([\"plotly\"], function(Plotly) {                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"2abf5e4c-ad08-4842-95db-956069ec5f0f\")) {                    Plotly.newPlot(                        \"2abf5e4c-ad08-4842-95db-956069ec5f0f\",                        [{\"hoverinfo\":\"text\",\"hovertext\":[\"spacy.prefer_gpu()\",\"\\n# Gensim\\nimport gensim\\nimport gensim.corpora as corpora\\nfrom gensim.utils import simple_preprocess\\nfrom gensim.models import CoherenceModel\",\" View a few example rows from each DataFrame to understand its structure\\nprint(\\\"\\\\nCharacters DataFrame:\\\")\\nprint(df_characters.head(3))\\nprint(\\\"\\\\nLocations DataFrame:\\\")\\nprint(df_locations.head(3))\\nprint(\\\"\\\\nScript DataFrame:\\\")\\nprint(df_script.head(3))\\nprint(\\\"\\\\nEpisodes DataFrame:\\\")\\nprint(df_episodes.head(3))\",\"Show the first lines of all the DataFrames\\nprint(\\\"Characters DataFrame - shape\\\", df_characters.shape)\\nprint(df_characters.head())\\nprint(\\\"\\\\nLocations DataFrame - shape\\\", df_locations.shape)\\nprint(df_locations.head())\\nprint(\\\"\\\\nScript DataFrame - shape\\\", df_script.shape)\\nprint(df_script.head())\\nprint(\\\"\\\\nEpisodes DataFrame - shape\\\", df_episodes.shape)\\nprint(df_episodes.head())\",\"Matplotlib improvements\\nmatplotlib.use('TkAgg')\",\"Set the path for the visuals.\",\" Set environment variable for gensim word2vec model path\\nos.environ[\\\"GENSIM_DATA_DIR\\\"] = \\\".\\\"\",\"# Split dataset into train, validation and test datasets\\ntrain_dataset = dataset.sample(frac=0.6, random_state=0).reset_index(drop=True)\\nvalid_dataset = dataset.drop(train_dataset.index).reset_index(drop=True)\\ntest_dataset = valid_dataset.sample(frac=0.5, random_state=0).reset_index(drop=True)\\nvalid_dataset = valid_dataset.drop(test_dataset.index).reset_index(drop=True)\",\"Optional: A sneek peek into the data helps understanding the contents.\",\"Merge with characters and drop nans for speaking_character_id\\ndf_script = df_script.merge(df_characters, left_on='character_id', right_on='id').dropna(subset=['speaking_character_id'])\",\"We'll start by looking at some examples from the dataset `df_characters`.\",\" Check if we have empty rows or NaN values\",\"Drop columns with over 50% missing data\\ndf_script = df_script.drop(columns=['normalized_text', 'word_count'])\",\" Visualize the character and location dataframes\",\"Replace nans with ''\\ndf_script_filtered = df_script[['character_id', 'location_id', 'normalized_text']].fillna('')\",\"Check loaded dataframes\\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()\",\" Define file paths for storing visualizations\",\"Let's see the structure of the data.\",\"Inspect the dataframes to get a better sense of the data.\",\"Joining datasets\",\" Display the head of each dataset to get an overview of their structure\\nprint(\\\"Characters:\\\")\\nprint(df_characters.head())\",\"Explore the structure of the characters DataFrame\\nprint(df_characters.head())\",\"Check the first 5 records of each CSV\",\"Display first few rows of the characters dataframe\\ndf_characters.head()\",\"Merge episodes with their corresponding scripts\\ndf_episodes_with_scripts = pd.merge(\\n    df_script, \\n    df_episodes, \\n    how='inner', \\n    left_on='episode_id', \\n    right_on='id'\\n).drop(columns=['id_y']).rename(columns={'id_x': 'script_id'})\\n\\n# Merge characters to non-location scripts\\ndf_episodes_with_scripts_and_characters = pd.merge(\\n    df_episodes_with_scripts, \\n    df_characters, \\n    how='inner', \\n    left_on='character_id', \\n    right_on='id'\\n).drop(columns='id').rename(columns={'name': 'character_name'})\\n\\n# Sanitize the location data\\nlocation_alias_map = {\\n    r'(Moe\\\\'s|moes)': 'MOE_S_TAVERN',\\n    r'(Simpson House|the house|simpson home|our house|their house)': 'SIMPSON_HOME',\\n    r'(elementary|school|detention|principal|lunchlady)': 'SPRINGFIELD_ELEMENTARY_SCHOOL',\\n}\",\"Clean dataframe so that only lines of dialogue are kept\\ndf_script = df_script[df_script['speaking_line'] == True]\\n\\n# Merge dataframes\\ndf_merged = df_script.merge(df_episodes, on='episode_id', how='left')\\n\\n# Remove unnecessary columns\\ndf_merged.drop(['imdb_rating', 'imdb_votes', 'video_url', 'image_url', 'production_code'], axis=1, inplace=True)\\n\\n# Drop rows with NaN values in 'normalized_text' column\\ndf_merged.dropna(subset=['normalized_text'], inplace=True)\\n\\n# Display first few rows of dataframe\\ndf_merged.head()\",\"Preview the data\\nprint('Characters:')\\nprint(df_characters.head(3))\\nprint('\\\\nLocations:')\\nprint(df_locations.head(3))\\nprint('\\\\nEpisodes:')\\nprint(df_episodes.head(3))\\nprint('\\\\nLines:')\\nprint(df_script.head(3))\",\"Check the df_scripts dataframe\",\"Create a meta DataFrame with all the characters in the script, and the total number of spoken words for each character.\",\"View first 5 rows of the characters dataframe\\ndf_characters.head()\",\"Get all the speakers from the script\\nspeakers = df_script['character_id']\\n\\n# Count the number of dialogues per speaker\\nspeaker_counts = speakers.value_counts()\\n\\n# Display dataframe of speaker counts\\ndf_speaker_counts = pd.DataFrame(speaker_counts)\\ndf_speaker_counts.columns = ['dialogue_count']\\ndf_speaker_counts.index.names = ['character_id']\\ndf_speaker_counts.reset_index(inplace=True)\",\"Displaying the number of entries in each dataset\",\"Inspect the data structure and contents to understand the data better\",\"Check the first five rows of the `df_characters` DataFrame\",\"Check, that everything went right \\nprint('Number of characters: ', df_characters.shape[0])\\nprint('Number of locations: ', df_locations.shape[0])\\nprint('Number of episodes: ', df_episodes.shape[0])\\nprint('Number of lines: ', df_script.shape[0])\",\"Join the necessary DataFrames to get a single DataFrame with the following columns: episode_id, raw_text, character_name, location_id, name.\",\"For more information on what each dataframe holds, check notebook 1.\",\"To view the first few rows of each DataFrame, we can simply use the head() method.\",\" Set seeds\\nnp.random.seed(0)\",\"Remove any blank\\u002fNaN\\u002fNull values in the raw script data\",\" Join the datasets using their respective keys\",\"Check the \\\"?\\\" column in the table.\",\"Select the key elements and only a subset of columns in the script table\",\"Display maximum 20 columns when displaying dataframes\\npd.set_option('max_columns', 20)\",\" Filter columns and merge the 4 datasets\",\"Check the loaded datasets\\nprint(df_characters.head())\\nprint(df_locations.head())\\nprint(df_script.head())\\nprint(df_episodes.head())\",\"Prerequisite: we need to remove characters that don't have a description and locations without a note.\",\"Filtered out the rows that are not script lines or do not have any spoken words in the \\\"spoken_words\\\" column.\",\"Filter the script for the provided episode ID and drop rows with no character ID\",\" This line ensures that the plots we generate with matplotlib use the 'dark_background' style for a better appearance.\",\"Checking if any script lines have Common Core information\\ndf_script[df_script[\\\"norm_id\\\"].str.contains(\\\"CZ\\\", na=False)]\",\"We then split our dataset into two, an 80% subset for training and a 20% subset for testing.\",\"View the head of the characters data\\ndf_characters.head()\",\"Consultando los primeros registros del dataset df_characters.\",\"\\ndef count_words(text):\\n    return len(text.split())\",\"Applying Title to each columns\",\"Train test split the data\",\"Optionnally, since the dataset is large, we can retrieve just a subset of the data, for instance by using the code below:\\n'''\\ndf_characters = df_characters.head(100).copy()\\ndf_locations = df_locations.head(100).copy()\\ndf_script = df_script.head(1000).copy()\\ndf_episodes = df_episodes.head(100).copy()\\n'''\",\"Inspect the data types of each column\\ndf_script.dtypes\",\"As the dataset is too large for this course, a subset will be used instead.\",\"List the first 5 records of the specific data set\",\"Merge simpsons_characters.csv and simpsons_script_lines.csv on character_id\\ndf_characters_script = pd.merge(df_characters, df_script, on='character_id', how='inner')\",\"Import the data and inspect the first few rows to understand its structure\\ndf_script.head()\",\"To ensure the data has been loaded correctly, we can use the `head()` function to display the first few rows of each DataFrame.\",\"Merge episodes and characters datasets\\ndf_merged = df_episodes.merge(df_characters, how='left', left_on='id', right_on='episode_id')\",\" We set word clouds parameters\\nmatplotlib.rcParams['figure.figsize'] = (16.0, 12.0)\\nmatplotlib.style.use('ggplot')\",\" Remove nulls values in the script\\ndf_script = df_script[df_script.raw_location_text.notnull()]\\ndf_script = df_script[df_script.raw_character_text.notnull()]\",\"# Define a function to display full dataframes\\ndef display_all(df):\\n    with pd.option_context(\\\"display.max_rows\\\", 1000, \\\"display.max_columns\\\", 1000):\\n        display(df)\",\"Separate each sentence into a list of words\",\"display(df_characters.head())\\ndisplay(df_locations.head())\\ndisplay(df_script.head())\\ndisplay(df_episodes.head())\",\"Let's display the first few rows of each of the datasets to understand their structure and contents.\",\" Import gensim and show its version\\nimport gensim\\ngensim.__version__\",\"Note: The 'data' folder is expected to be in the same directory as this Jupyter Notebook.\",\"Quick look at the \\\"Characters\\\" table\\nprint(df_characters.head())\",\"'Type' of each df\\nprint(\\\"df_characters:\\\", type(df_characters))\\nprint(\\\"df_locations:\\\", type(df_locations))\\nprint(\\\"df_script:\\\", type(df_script))\\nprint(\\\"df_episodes:\\\", type(df_episodes))\",\" Show head of dataset\\ndf_script.head()\",\"Keep the original DataFrames unmodified\\ndf_characters_orig = df_characters.copy()\\ndf_locations_orig = df_locations.copy()\\ndf_script_orig = df_script.copy()\\ndf_episodes_orig = df_episodes.copy()\",\"Looks good! Now we can continue with our analysis.\",\"Check how the dataframes look like\\ndf_characters.head(3)\",\"Explore the first few rows of each dataframe to understand the data.\",\" Check the first few rows of each DataFrame\\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()\",\"quick check and shape of dataframe\",\"Concatenate and replace utterance id with string\\r\\ndf_final = pd.concat([df_script, df_characters, df_locations, df_episodes], axis=1, join='inner')\",\" Display general information on the datasets\\nprint('Characters dataframe:', df_characters.shape)\\nprint('Locations dataframe:', df_locations.shape)\\nprint('Script lines dataframe:', df_script.shape)\\nprint('Episodes dataframe:', df_episodes.shape)\",\"Merge character and location names\\nunique_character_names = df_characters.raw_character_text.tolist()\\nunique_location_names = df_locations.raw_location_text.tolist()\\n\\n# Get unique character and location names\\nunique_character_names = list(set(unique_character_names))\\nunique_location_names = list(set(unique_location_names))\\n\\n# Replace slashes in character and location names\\nunique_character_names = [name.replace('\\u002f', '_') for name in unique_character_names]\\nunique_location_names = [name.replace('\\u002f', '_') for name in unique_location_names]\",\" Generate a list of dialogue for each character\",\"Get the list of seasons\\nseasons = df_episodes['season'].unique()\",\"Select one episode from the Simpsons and display its script lines.\",\"Check the size of the datasets\\nprint(df_characters.shape)\\nprint(df_locations.shape)\\nprint(df_script.shape)\\nprint(df_episodes.shape)\",\"Filter characters that appear in at least 100 episodes\\ncharacter_ep_counts = df_script['raw_character_text'].value_counts()\\nfrequent_characters = character_ep_counts[character_ep_counts \\u003e 100].index.to_list()\\ndf_script = df_script[df_script['raw_character_text'].isin(frequent_characters)]\",\"Merge script dataframe with episode df\",\"Setting up the Spacy NLP model\\nnlp = spacy.load('en_core_web_sm')\",\"Display first five rows of characters dataset\\ndf_characters.head()\",\"dsfd\",\"Inspect first few rows of each dataframes\\nprint(df_characters.head())\\nprint(df_locations.head())\\nprint(df_script.head())\\nprint(df_episodes.head())\",\" Display the first few rows of each dataframe to understand what kind of data is available\\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()\",\"Create a sample of the Episodes dataframe to validate the data.\",\"Ensure the corpus is loaded.\",\"Ensure script line data types are correct\\ndf_script['character_id'] = df_script['character_id'].astype('Int64')\\ndf_script['location_id'] = df_script['location_id'].astype('Int64')\\ndf_script['raw_text'] = df_script['raw_text'].astype(str)\",\" Visualization function to plot word clouds\",\" Optionally, you can display the top 5 rows of all these DataFrames to see what they look like\",\"Check the head of the dataset\\ndf_script.head()\",\"Set random seed for reproduction of results\\nnp.random.seed(0)\",\"Check the content of the records in the dataframes to understand the potential features at hand.\\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()\",\" Check the data types and null values of the datasets\\ndf_characters.info()\",\"Create a basic wordcloud for all of the Simpsons scripts\\nscript_words = ' '.join(df_script['spoken_words'].fillna(''))\\nwordcloud = WordCloud(width = 800, height = 400,\\n                background_color ='black',\\n                stopwords = STOPWORDS,\\n                min_font_size = 10).generate(script_words)\\n\\n# plot the WordCloud image\\nplt.figure(figsize = (8, 8), facecolor = None)\\nplt.imshow(wordcloud)\\nplt.axis(\\\"off\\\")\\nplt.tight_layout(pad = 0)\\n\\nplt.show()\",\"Download the larger English model for spaCy, which is needed for the named entity recognition (NER) functionality.\\n!python -m spacy download en_core_web_lg\",\"Convert raw_text newline characters to html \\u003cbr\\u003e tag\\ndf_script['spoken_words'] = df_script['spoken_words'].str.replace('\\\\n', '\\u003cbr\\u003e')\",\" Preprocessing the script dataset by keeping only the spoken lines, and normalizing the character names and locations for consistency.\",\"Check the first few lines of each dataframe\\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()\",\"Show the first 5 rows of each dataset to understand its structure\\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()\",\"We'll start by taking a look at the structure of the datasets and splicing the data.\",\"Display the data\\ndf_script\",\"Bart in script dataframe\\ndf_script_bart = df_script[df_script['raw_character_text'] == 'Bart']\\n\\n# Most common words in the Bart lines\\ncounter = Counter(\\\" \\\".join(df_script_bart[\\\"spoken_words\\\"]).split())\\ncounter.most_common(10)\",\"# Only interested in characters with a known location\\ndf_characters = df_characters[df_characters['location_id'].notnull()]\",\"Clean data\\n# Remove rows with empty strings or NA's from the script\\ndf_script.dropna(inplace=True)\\ndf_script = df_script[df_script['raw_text'] != '']\\n# Remove faulty episode\\ndf_episodes.drop([281], inplace=True)\\n\\n# Top 10 characters that appear in the scripts\\ntop10_characters = df_script.character_id.value_counts().head(10)\\ntop10_characters = df_characters.loc[top10_characters.indices].reset_index(drop=True)\\n\\n# Top 10 locations that appear in the scripts\\ntop10_locations = df_script.raw_location_text.value_counts().head(10).reset_index()\\ntop10_locations.columns = ['raw_location_text', 'count']\",\"Filter out miscellaneous characters\",\" We will preprocess the data to remove missing values and merge the relevant columns.\",\"Display the first 5 rows of the characters dataset\\ndf_characters.head()\",\"Quick overview of the data\\nprint(\\\"DF Characters\\\")\\nprint(df_characters.head())\",\" Merge dataset\\ndf_characters.drop(['slug'], axis=1, inplace=True)\\ndf_episodes.drop(['image_url', 'video_url'], axis=1, inplace=True)\",\"# Remove rows that contain empty strings in columns of interest\\ncolumns_of_interest = ['character_id', 'normalized_text', 'location_id', 'episode_id']\\ndf_script = df_script.replace('', np.nan)\\ndf_script.dropna(subset=columns_of_interest, inplace=True)\",\"Create characters x location dataframe\\nlocations = []\\ncharacters = []\\nlines_count = []\\n\\n\\nfor idx, l in df_script.iterrows():\\n    if (l['raw_character_text'] in df_characters.raw_character_text.values and\\n        l['raw_location_text'] in df_locations.raw_location_text.values):\\n        if (l['raw_character_text'], l['raw_location_text']) in zip(characters, locations):\\n            lines_count[characters.index(l['raw_character_text'])][locations.index(l['raw_location_text'])] += 1\\n        else:\\n            characters.append(l['raw_character_text'])\\n            locations.append(l['raw_location_text'])\\n            lines_count.append(np.zeros(len(df_locations), dtype=np.int32))\\n            lines_count[-1][locations.index(l['raw_location_text'])] = 1\\n\\ndf_x_locations = pd.DataFrame(data=lines_count, index=characters, columns=locations)\\n\\ndf_x_locations.to_csv('data\\u002fsimpsons_characters_x_locations.csv')\",\"#head of the dataframe\\ndf_script.head()\",\"Setting seed for reproducibility\\nnp.random.seed(0)\",\"Create synonym dictionary to improve consistency in location names\",\"Set global plot styles and settings for consistent looks across all visualizations\\nmatplotlib.rc_file_defaults()\",\"Preview the dataframes\\nprint('Characters:')\\ndisplay(df_characters.head(5))\\nprint('Locations:')\\ndisplay(df_locations.head(5))\\nprint('Script:')\\ndisplay(df_script.head(5))\\nprint('Episodes:')\\ndisplay(df_episodes.head(5))\",\"Now, let's take a look at the first few rows of each dataframe to understand the data better.\",\"Join script lines with character and episode information\\ndf_script['character_name'] = df_script['character_id'].apply(lambda x: df_characters.loc[df_characters['id'] == x, 'name'].values[0] if len(df_characters.loc[df_characters['id'] == x, 'name'].values) \\u003e 0 else '')\\ndf_script['location_name'] = df_script['raw_location_id'].apply(lambda x: df_locations.loc[df_locations['id'] == x, 'name'].values[0] if len(df_locations.loc[df_locations['id'] == x, 'name'].values) \\u003e 0 else '')\\ndf_script['episode_title'] = df_script['episode_id'].apply(lambda x: df_episodes.loc[df_episodes['id'] == x, 'title'].values[0] if len(df_episodes.loc[df_episodes['id'] == x, 'title'].values) \\u003e 0 else '')\\ndf_script['imdb_rating'] = df_script['episode_id'].apply(lambda x: df_episodes.loc[df_episodes['id'] == x, 'imdb_rating'].values[0] if len(df_episodes.loc[df_episodes['id'] == x, 'imdb_rating'].values) \\u003e 0 else '')\",\"# Display basic information about the loaded datasets\\nfor df, name in zip([df_characters, df_locations, df_script, df_episodes], \\n                    ['Characters', 'Locations', 'Script', 'Episodes']):\\n    print(f'Dataset: {name}\\\\n')\\n    print(df.info())\\n    display(df.head(5))\\n    print('\\\\n' + '='*90 + '\\\\n')\",\"Check the dataset\\ndf_script.head()\",\".against general memory issues\\nprint(\\\"Characters:\\\", df_characters.memory_usage().sum() \\u002f 1024**2, \\\"MB\\\")\\nprint(\\\"Locations:\\\", df_locations.memory_usage().sum() \\u002f 1024**2, \\\"MB\\\")\\nprint(\\\"Script lines:\\\", df_script.memory_usage().sum() \\u002f 1024**2, \\\"MB\\\")\\nprint(\\\"Episodes:\\\", df_episodes.memory_usage().sum() \\u002f 1024**2, \\\"MB\\\")\",\"Normalize the data - make everything lowercase in the required columns\",\"View the first few rows of the characters data\\ndf_characters.head()\",\"Clean names from locations dataset and assign an unique identifier for each name\",\"Filter out characters, locations and episodes not used in the script\\nall_characters_in_script = df_script['raw_character_text'].value_counts().index.tolist()\\nall_locations_in_script = df_script['raw_location_text'].value_counts().index.tolist()\\nall_episodes_in_script = df_script['episode_id'].value_counts().index.tolist()\\n\\ndf_characters = df_characters[df_characters['raw_character_text'].isin(all_characters_in_script)].reset_index(inplace=False, drop=True)\\ndf_locations = df_locations[df_locations['raw_location_text'].isin(all_locations_in_script)].reset_index(inplace=False, drop=True)\\ndf_episodes = df_episodes[df_episodes['id'].isin(all_episodes_in_script)].reset_index(inplace=False, drop=True)\",\"Select only relevant columns\\ndf_script = df_script[['episode_id', 'number', 'raw_text', 'timestamp_in_ms','speaking_line', 'character_id', 'location_id']]\\n\\n# Remove NaNs\\ndf_script = df_script.dropna(subset=['raw_text', 'speaking_line', 'character_id', 'location_id'])\\n\\n# Reset indexes\\ndf_script = df_script.reset_index(drop=True)\",\"Display the first 5 rows of each dataframe\\nprint(df_characters.head(5))\\nprint(df_locations.head(5))\\nprint(df_script.head(5))\\nprint(df_episodes.head(5))\",\"Check that everythong is working as intended\\nprint('Characters:')\\ndisplay(df_characters.head())\\nprint('Locations:')\\ndisplay(df_locations.head())\\nprint('Script:')\\ndisplay(df_script.head())\\nprint('Episodes:')\\ndisplay(df_episodes.head())\",\"Set random seed for reproducibility\\nnp.random.seed(0)\",\"pre-processing\\ndf_script = df_script[df_script[\\\"normalized_text\\\"].notnull()]\",\"Due to space limitations, I'll be skipping the code segment that contains repetitive assignments to dataframes\",\"Select the lines that are spoken by a specific character, e.g., Homer, Marge, Bart, Lisa, or Maggie.\",\"Checking the top 3 rows of the characters dataframe\",\"Inspect first 5 rows of each table\\nfor df, name in zip([df_characters, df_locations, df_script, df_episodes],\\n                    ['Characters', 'Locations', 'Script', 'Episodes']):\\n    print(f'First 5 rows of {name} table:')\\n    display(df.head())\\n    print('\\\\n\\\\n')\",\"Split name and surname\\ndf_characters['name'] = df_characters['name'].apply(lambda x: x.split(' ', 1)[0])\\ndf_characters.head()\",\" Display how the datasets look\",\"Print the characters dataframe to understand its structure\\nprint(df_characters.head())\\n\\n# Print the locations dataframe to understand its structure\\nprint(df_locations.head())\\n\\n# Print the script dataframe to understand its structure\\nprint(df_script.head())\\n\\n# Print the episodes dataframe to understand its structure\\nprint(df_episodes.head())\",\" Verify the size and structure of the DataFrames\\nprint('Characters', df_characters.shape)\\nprint('Locations', df_locations.shape)\\nprint('Script', df_script.shape)\\nprint('Episodes', df_episodes.shape)\\n\\ndf_characters.head()\",\"Display the data head to understand the structure and types of data\",\" show the scripts dataset\\ndf_script.head()\",\"Preview the data to understand its structure and contents\\nprint(df_characters.head())\\nprint(df_locations.head())\\nprint(df_script.head())\\nprint(df_episodes.head())\",\"Display first 5 rows of each dataframe\\ndf_list = [df_characters, df_locations, df_script, df_episodes]\\ndf_names = ['Characters', 'Locations', 'Script', 'Episodes']\\nfor i, df in enumerate(df_list):\\n    print(f\\\"First 5 rows of {df_names[i]}\\\")\\n    display(df.head())\",\"# The full text of the scripts is too large to load here. We'll be working with a slice of the data\\nprint(df_script.shape)\\ndf_script.head()\",\"Limit the number of cast members on one-off roles\\ndf1 = df_script[df_script['normalized_text'].isin(df_characters[df_characters['n_lines'] \\u003e 100]['raw_character_text'])]\\ndf1.head()\",\"Function to clean the scripts\",\"Remove `Unnamed: 0` column from `df_characters`\\ndf_characters.drop(columns='Unnamed: 0', inplace=True)\",\"# various sources cite various names for the character \\\"moe\\\"\\n# also drop characters that don't have any specific lines (i.e. only hears lines from others)\\ndrop_chars = [\\\"mo\\\", \\\"Moe_Syszlak\\\", \\\"Carl_Carlson\\\", \\\"C._Montgomery_Burns\\\"]\",\"Introduction_Implementation cleaned up some of this data and store it in\\n# separate files so that these would load faster in Jupyter\\n\\n# Head of the characters df\\nprint(df_characters.head())\",\"Remove unncessary columns that have 90% or more of missing values\",\"Check the number of records\\nprint(f'Number of records in df_characters: {df_characters.shape[0]}')\\nprint(f'Number of records in df_locations: {df_locations.shape[0]}')\\nprint(f'Number of records in df_script: {df_script.shape[0]}')\\nprint(f'Number of records in df_episodes: {df_episodes.shape[0]}')\",\" I can help you on anything you want about the dataset after you load it.\",\"# Remove non-character lines from the script\\ndf_script = df_script[df_script.normalized_text != ''].copy()\\ndf_script.reset_index(inplace=True, drop=True)\",\"Filter out the data we're interested in and avoid Join operations.\",\" Show first 3 character rows\\ndf_characters.head(3)\",\"Check the content of the dataset \\\"Characters\\\" and the first five rows of the dataframe\\nprint(\\\"Printing the dataframe structure to understand it better\\\")\\nprint(df_characters.head().to_string())\",\"Merge df_script with df_episodes to get more details in the same df\",\"rename the columns in the DataFrames to make them more legible.\\ndf_characters.columns = ['character_id', 'name']\\ndf_locations.columns = ['location_id', 'name']\\ndf_script.columns = ['index', 'episode_id', 'number', 'raw_text', 'timestamp_in_ms', 'speaking_line', 'character_id', 'location_id', 'raw_character_text', 'raw_location_text', 'spoken_words', 'normalized_text', 'word_count']\\ndf_episodes.columns = ['id', 'title', 'original_air_date', 'production_code', 'season', 'number_in_season', 'number_in_series', 'us_viewers_in_millions', 'views', 'imdb_rating', 'imdb_votes', 'image_url', 'video_url']\",\"Filter only the 'Springfield Elementary School' location\\ndf_script_springfield_school = df_script[\\n    df_script['raw_location_text'] == 'Springfield Elementary School'\\n]\",\"plexico characters by the number of lines of speech\\ncounts = df_script['raw_character_text'].value_counts()\\n\\nif 'simpsons' in counts.index:\\n    counts.drop('simpsons', inplace=True)\\n\\n# Label\\ncounts.index.name = 'character'\\ncounts.name = 'lines'\",\"Uncomment the following lines to debug if something in this notebook goes wrong\\n# import pixiedust\\n# %%pixie_debugger\",\"to check if the profane words are in the script out of curiosity.\\nprofane_words = set([\\\"ass\\\", \\\"asshole\\\", \\\"bastard\\\", \\\"bitch\\\", \\\"crap\\\", \\\"damn\\\", \\\"dick\\\", \\\"douche\\\", \\\"fag\\\", \\\"fuck\\\"])\\nscript_profanity = []\\n\\nfor i in tqdm(range(len(df_script))):\\n    text = df_script.loc[i, 'raw_text']\\n    words = set([word.lower().strip() for word in text.split()])\\n    profane = bool(words & profane_words)\\n    script_profanity.append(profane)\\n\\ndf_script['profane'] = script_profanity\",\"Exploring the structure of the data\",\"Setting up the pipeline and processing the text data\",\"Display head of all datasets to understand the data\",\" We define the default style for matplotlib visualizations.\",\"Inspect the structure of the dataframes\\n(df_characters.head(), df_locations.head(), \\n df_script.head(), df_episodes.head())\",\"# Visualization function\\ndef cloud(text):\\n    # Create and generate a word cloud image:\\n    wordcloud = WordCloud().generate(text)\\n\\n    # Display the generated image:\\n    plt.imshow(wordcloud, interpolation='bilinear')\\n    plt.axis(\\\"off\\\")\\n    plt.show()\\n\\n# Initialize spacy 'en' model, keeping only tagger component needed for lemmatization\\nnlp = spacy.load('en', disable=['parser', 'ner'])\",\"Importing all necessary libraries and datasets for analysis.\",\"Some lines contain Bhutanese writing. Let's clean the data by removing them.\",\" Check data\\nprint('Characters:', df_characters.shape)\\nprint('Locations:', df_locations.shape)\\nprint('Script lines:', df_script.shape)\\nprint('Episodes:', df_episodes.shape)\",\"Data organization\\ndf_episodes = df_episodes.dropna(subset=['id']).set_index('id')\\ndf_script = df_script.dropna(subset=['episode_id']).set_index('episode_id')\\ndf_characters = df_characters.dropna(subset=['id']).set_index('id')\\ndf_locations = df_locations.dropna(subset=['id']).set_index('id')\",\" Remove all characters that did not appear in any script line\\nto_remove = df_script[~df_script.raw_character_text.isin(df_characters.raw_character_text) & ~df_script.raw_character_text.isna()].raw_character_text.unique()\\ndisplay(len(df_script))\\ndf_script = df_script[~df_script.raw_character_text.isin(to_remove)]\\ndisplay(len(df_script))\",\"# Set local environment to use VADER\\nos.environ['VADER_COMPOUND'] = '1'\",\"Filtering only those records which have been spoken by a character (non-null value)\",\" Print the first few rows of the dataframes\\nprint(df_characters.head())\\nprint(df_locations.head())\\nprint(df_script.head())\\nprint(df_episodes.head())\",\"We can display the first few rows of each dataset to get a sense of their structure.\",\" Displaying the scripts dataset\\ndf_script\",\"# Merge script with characters and locations\\ndf_script_characters = df_script.merge(df_characters, on='character_id')\\ndf_script_characters_locations = df_script_characters.merge(df_locations, on='location_id')\\n\\n# Remove unwanted columns\\ndf_script_characters_locations = df_script_characters_locations.drop([\\n    'number',\\n    'raw_text',\\n    'timestamp_in_ms',\\n    'speaking_line',\\n    'character_id',\\n    'location_id'\\n], axis=1)\",\" Display the first few records of the dataframe\\ndf_script.head()\",\" Check the first few rows of each dataframe\\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()\",\"Visualize the number of episodes in the dataset\\nepisodes_per_season = df_episodes['season'].value_counts().sort_index()\\n\\nplt.figure(figsize=(10, 6))\\nplt.bar(episodes_per_season.index, episodes_per_season.values, color='skyblue')\\nplt.title('Number of episodes per season')\\nplt.xlabel('Season')\\nplt.ylabel('Number of episodes')\\nplt.show()\",\"Preview dataframes\\nprint(df_characters.head(5))\\nprint(df_locations.head(5))\\nprint(df_script.head(5))\\nprint(df_episodes.head(5))\",\"Extract main characters\\nmain_characters = df_script.raw_character_text.value_counts().head(17).index.tolist()\",\"# Define constants\\nSEASON_COLORS = ['#56B4E9', '#009E73', '#E69F00', '#CC79A7', '#0072B2', '#D55E00']\",\"Lets print the first 5 rows of the dataset and analyze the data\",\"Check a few lines of each DataFrame to understand how the data looks like\\ndf_characters.head()\",\"Example character\\ndf_characters.iloc[6]\",\"Clean up dataframe columns\\ndf_characters.columns = df_characters.columns.str.lower().str.replace(' ', '_')\\ndf_characters = df_characters.set_index('id')\\n\",\"Print the first rows of each dataset to understand the structure of the data\\nprint(df_characters.head())\\nprint(df_locations.head())\\nprint(df_script.head())\\nprint(df_episodes.head())\",\"Columns in the lines dataframe that we'll use:\\n## Speaking character\\n## Spoken text\\n## Season\\n## Episode\\n## Location\\n## Character gender\",\"# Display first 5 rows of characters dataframe\\ndf_characters.head()\",\"Get an overview of our datasets\\nprint('Characters dataset:')\\nprint(df_characters.head())\\nprint('\\\\nLocations dataset:')\\nprint(df_locations.head())\\nprint('\\\\nScript lines dataset:')\\nprint(df_script.head())\\nprint('\\\\nEpisodes dataset:')\\nprint(df_episodes.head())\",\" Define the path to your data folder in 'simpsons_path'\",\"Inspect the dataframes to understand their structure and the information they contain.\",\"Filter unnecessary columns in the episodes dataframe\",\"Check one of the dataset to see what it looks like\\ndf_locations.head()\",\"Check the structure of each dataframe\\nprint(\\\"Characters\\\")\\nprint(df_characters.head())\\nprint()\\nprint(\\\"Locations\\\")\\nprint(df_locations.head())\\nprint()\\nprint(\\\"Script\\\")\\nprint(df_script.head())\\nprint()\\nprint(\\\"Episodes\\\")\\nprint(df_episodes.head())\",\" Quick overview of each dataframe\\nfor name, df in {'characters': df_characters, 'locations': df_locations, 'script': df_script, 'episodes': df_episodes}.items():\\n    print(f'\\\\n{name.upper()}')\\n    display(df.head(2))\",\"Set random seed for reproducibility\\nnp.random.seed(13)\",\"Data loading\",\"Setting the directory path for the Simpsons dataset\",\"Basics for all of them\\ndf_script['word_count'] = df_script['spoken_words'].apply(lambda x: len(x.split()))\\ndf_script['title'] = df_episodes['title'][df_script['episode_id']-1].values\\n\\n# Display the conversation\\ndf_script.head()\",\"Characters count\\nprint(f'There are {df_characters.shape[0]} characters.')\",\"Checking the data type of each column in df_script\",\"Let's take a look at the first 5 rows of each dataframe.\",\"Checking the first few entities in each dataset.\",\"checking the head of each dataframe to understand its structure and what fields are available.\",\"Display top 3 rows of each dataframe\\ndf_characters.head(3)\",\"Visualise the first rows of the characters, locations, script and epidoses tables\",\"Define the path to the data folder\\nsimpsons_data_path = 'data\\u002f'\",\"Show the first 5 lines of each dataframe\\nfor df, name in zip([df_characters, df_locations, df_script, df_episodes], ['Characters', 'Locations', 'Script', 'Episodes']):\\n    print(name)\\n    with pd.option_context('display.max_columns', None):\\n        display(df.head(5))\\n    print('\\\\n')\",\"Checking size of the dataframes\\ndf_episodes.shape, df_script.shape, df_characters.shape, df_locations.shape\",\"Data pertaining to the lines spoken by characters and that location are contained in specific tables.\",\"# Extracting the main script from the data and dropping the columns not needed\\ndf_main = df_script[['episode_id', 'number', 'raw_text', 'timestamp_in_ms']]\\ndf_main.sort_values(['episode_id', 'number'], inplace=True)\\ndf_main = df_main[df_main['timestamp_in_ms'] \\u003e 0]\",\"Inspect top 10 rows of each DataFrame\\nprint('Characters')\\ndisplay(df_characters.head())\\n\\nprint('Locations')\\ndisplay(df_locations.head())\\n\\nprint('Script')\\ndisplay(df_script.head())\\n\\nprint('Episodes')\\ndisplay(df_episodes.head())\",\" We fixed the index during loading, so we don't have to reset them here\",\"Combining the data into one dataframe\",\"Filter out unnecessary characters from the script dataframe\\ncharacters = df_characters['id']\\nmask = df_script['character_id'].apply(lambda x: x in characters.to_list())\\ndf_script = df_script[mask]\",\"Creating a single frame containing only the episodes that are both in df_script and df_episodes\",\"We'll begin by examining the first few rows of each dataframe using the `head()` function.\",\"# Ensure the Episode data is unique on id\\ndf_episodes = df_episodes.drop_duplicates(subset=['id'])\",\"Filter by gold quality and main characters\",\"Building dataset from these input dataframes.\",\" Check the three datasets\\nprint(df_characters.head())\\nprint(df_locations.head())\\nprint(df_script.head())\",\"Check memory usage before cleaning\\nmem_usage = df_script.memory_usage(deep=True).sum() \\u002f 1024**2  # convert bytes to megabytes\\nprint('Memory usage of dataframe is {:.2f} MB'.format(mem_usage))\\n\\n# Create a dictionary to store the optimal data types for each column to reduce memory usage\\ndtypes = {'id': 'int32',\\n          'episode_id': 'int32',\\n          'number': 'int16',\\n          'character_id': 'float32',  # NaN values\\n          'location_id': 'float32',   # NaN values\\n          'raw_text': 'string',       # special data type StringDtype\\n          'timestamp_in_ms': 'int64',\\n          'speaking_line': 'string',  # special data type StringDtype\\n          'character_image_url': 'string',  # special data type StringDtype\\n          'location_image_url': 'string',   # special data type StringDtype\\n          'spoken_words': 'string',         # special data type StringDtype\\n          'normalized_text': 'string',      # special data type StringDtype\\n          'word_count': 'int16'}\",\"Display first few rows of the characters dataframe\\ndf_characters.head()\",\"Check the data in each dataframe\\nprint('Characters')\\nprint(df_characters.info())\\nprint(df_characters.head())\\n\\nprint('Locations')\\nprint(df_locations.info())\\nprint(df_locations.head())\\n\\nprint('Script')\\nprint(df_script.info())\\nprint(df_script.head())\\n\\nprint('Episodes')\\nprint(df_episodes.info())\\nprint(df_episodes.head())\",\"Exctract the content of the `raw_text` column and make it the variable `raw_text`\",\"Display the first few lines of each dataframe to understand their structure\\nprint(\\\"Characters DataFrame:\\\")\\nprint(df_characters.head())\\nprint(\\\"\\\\nLocations DataFrame:\\\")\\nprint(df_locations.head())\\nprint(\\\"\\\\nScript DataFrame:\\\")\\nprint(df_script.head())\\nprint(\\\"\\\\nEpisodes DataFrame:\\\")\\nprint(df_episodes.head())\",\"Plot the 10 characters with the most dialogue\",\"select main characters that have at least 1000 lines\\nmain_characters = df_script.character.value_counts()\\nmain_characters = main_characters[main_characters \\u003e 1000]\",\"Replace NaN values with '' in the script dataframe\\ndf_script['normalized_text'] = df_script['normalized_text'].map(lambda x: '' if pd.isnull(x) else x)\",\"Print the first few lines of each dataframe\\nprint(df_characters.head())\\nprint(df_locations.head())\\nprint(df_script.head())\\nprint(df_episodes.head())\",\"Checking dimensions of each dataframe\",\"Reloading Franky's functions correctly.\\nimport sys\\nsys.path.append('..')\\n\\nfrom nlpFunctions import *\",\"Get the most common utterances (which character speaks which words)\",\"Inspecting the first 5 rows of each dataframe to understand the structure of the data.\",\"Let's have a look at some data first.\",\"First, let's take a look at the first few rows of each dataframe to understand what kind of data we're working with.\",\"\\n# Data has been read into dataframes. Can start analysis and visualization.\",\"from scripts.data_cleaning import clean_script, align_lines\",\"Visualize first few rows of the dataframe\\ndf_script.head()\",\"Data cleaning: Missing values\",\"Display first few rows of the characters dataframe\\ndf_characters.head()\",\"Creation of the \\\"simpsons_episodes\\\" table\",\"The script includes multiple dataset which shows the information for each episode, such as the annotated script lines, the characters, the locations, and the main events.\",\"Discard unnecessary columns from df_episodes\\ndf_episodes = df_episodes[['id', 'title', 'original_air_date']]\",\"Check the content of the characters CSV file in order to understand if there are inconsistencies or special cases to consider.\",\"Create a useful directory structure\",\"Filter out the bad data points from our data set and keep the examples that are actually usuable.\",\"@click.command()\",\"Filtering for the first episode as an example\\ndf_episode_1 = df_script[(df_script['episode_id'] == 1)].copy()\\ndf_episode_1.rename(columns={'raw_text':'text'}, inplace=True)\",\"Check the size of the dataframes\\nprint(df_characters.shape)\\nprint(df_locations.shape)\\nprint(df_script.shape)\\nprint(df_episodes.shape)\",\"Set random seed for reproducibility\\nnp.random.seed(0)\",\"Looking at the data structure of each to find how to merge the files and how to work with them.\",\"display(df_characters.head())\\ndisplay(df_locations.head())\\ndisplay(df_script.head())\\ndisplay(df_episodes.head())\",\"Add missing columns to df_script\\ndf_script['full_text'] = df_script['raw_text'] + \\\" \\\" + df_script['normalized_text'].fillna(\\\"\\\")\",\"Combine script lines with corresponding character and episode information\\ndf = df_script.merge(df_characters, on='id_number', how='inner')\\ndf = df.merge(df_episodes, on='episode_id', how='inner')\",\"Display the dataframe containing the characters\\u002factors information\",\" Merge the script lines with the characters and locations information\\ndf_script_char = df_script.merge(df_characters, how=\\\"left\\\", left_on=\\\"character_id\\\", right_on=\\\"id\\\", suffixes=(\\\"_script\\\", \\\"_char\\\")).drop(\\\"id_char\\\", axis=1)\\ndf_script_loc = df_script_char.merge(df_locations, how=\\\"left\\\", left_on=\\\"location_id\\\", right_on=\\\"id\\\", suffixes=(\\\"_script\\\", \\\"_loc\\\")).drop(\\\"id\\\", axis=1)\\n\\n# Filter the main characters and locations\\nmain_characters = [\\\"Lisa Simpson\\\", \\\"Bart Simpson\\\", \\\"Marge Simpson\\\", \\\"Homer Simpson\\\", \\\"C. Montgomery Burns\\\", \\\"Moe Szyslak\\\", \\\"Seymour Skinner\\\", \\\"Ned Flanders\\\", \\\"Grampa Simpson\\\", \\\"Milhouse Van Houten\\\"]\\nmain_locations = [\\\"Simpson Living Room\\\", \\\"Simpson Kitchen\\\", \\\"Moe's Tavern\\\", \\\"Springfield Elementary School\\\", \\\"Kwik-E-Mart\\\", \\\"Simpson Backyard\\\", \\\"Simpson Car\\\"]\\ndf_main = df_script_loc[df_script_loc[\\\"raw_character_text\\\"].isin(main_characters)]\\ndf_main = df_main[df_main[\\\"raw_location_text\\\"].isin(main_locations)]\",\"Create a set of all episode ids\",\" Check the import\\nprint(\\\"Datasets loaded successfully.\\\")\",\"Join lines with df_episodes to find out show details\",\"Checking if pickle files already exists\",\"Save the script data details for the prediction script and delete script data from memory after saving it\",\"# Merge tables\\ndf = df_script.merge(df_characters[['id', 'name']], left_on='character_id', right_on='id', suffixes=('_script', '_character'))\\ndf = df.merge(df_locations[['id', 'name']], left_on='location_id', right_on='id', suffixes=('_df', '_location'))\\ndf = df.merge(df_episodes[['id', 'title', 'original_air_date']], left_on='episode_id', right_on='id', suffixes=('_df', '_episode'))\\n\\n# Drop redundant columns\\ndf.drop(columns=['id_script', 'id_character', 'id_df', 'id_location', 'id_episode'], inplace=True)\",\"Merge datasets in order to get the character and location names for each line in the script\\ndf_episodes = df_episodes[['id', 'title', 'original_air_date']]\\ndf_script = df_script.merge(df_episodes, how='inner', left_on='episode_id', right_on='id')\\n\\ndf_script = df_script[['episode_id', 'number', 'raw_text', 'title', 'original_air_date']]\\ndf_script = df_script.rename(columns={'episode_id': 'episode_id', 'number': 'episode_number', 'raw_text': 'text',\\n                                     'title': 'episode_title', 'original_air_date': 'air_date'})\\n\\n# Remove lines for which the character isn't specified\\ndf_script = df_script.loc[df_script.character_id.notnull()]\\n\\ndf_script = df_script.merge(df_characters, how='inner', left_on='character_id', right_on='id')\\ndf_script = df_script.merge(df_locations, how='left', left_on='location_id', right_on='id')\\n\\ndf_script = df_script[['episode_id', 'episode_number', 'episode_title', 'text', 'air_date', 'name',\\n                       'normalized_name', 'alignment_id', 'alignment', 'image_url', 'id_y',\\n                       'name_y']]\",\"Now that we have imported the necessary libraries and loaded the datasets, we can proceed with the data analysis and visualization.\",\"Preview the data\\nprint('Characters:')\\ndisplay(df_characters.head(2))\\nprint('Locations:')\\ndisplay(df_locations.head(2))\\nprint('Script:')\\ndisplay(df_script.head(2))\\nprint('Episodes:')\\ndisplay(df_episodes.head(2))\",\" Extract the first few lines of the script to get a feeling of the data structure\\ndf_script.head()\",\" Display the size of the DataFrames to have an overview of the data available\",\"Displaying the script lines dataset\\ndf_script.head()\",\"display first 5 rows of each dataframe\\ndfs = [df_characters, df_locations, df_script, df_episodes]\\nfor i, df in enumerate(dfs):\\n    print(f\\\"\\\\nDataframe df_{i} :\\\")\\n    print(df.head())\",\" Show the top entries of each DataFrame\\ndisplay(df_characters.head())\\ndisplay(df_locations.head())\\ndisplay(df_script.head())\\ndisplay(df_episodes.head())\",\" Define a function to compute the word frequency\",\"Show the first 3 examples of df_characters dataframe\\ndf_characters.head(3)\",\"Check the structure of the datasets\\ndf_characters.head()\",\"Setting seed for reproducibility\\nnp.random.seed(0)\",\"Check that the csv files have been correctly located and loaded.\",\"Dramatization of the characters and locations\\ndramatic_characters = df_script.character.str.upper()  # This project is not case sensitive\\ndramatic_locations = df_script.raw_location_text.str.upper()  # Same here\",\"Replace indicated speciees names for easier manipulation in the future\\ndf_script.replace({\\n    'simpsons': 'species_simpsons'\\n}, inplace=True, regex=True)\",\" Clean the data\\ndf_script = df_script[df_script[\\\"utterance\\\"].notna()]\\ndf_script = df_script[df_script[\\\"raw_text\\\"].notna()]\\ndf_script = df_script[df_script[\\\"character_id\\\"].notna()]\\ndf_script = df_script[df_script[\\\"location_id\\\"].notna()]\\ndf_script = df_script[df_script[\\\"episode_id\\\"].notna()]\",\"Exploratory data analysis and data preprocessing\",\"Clone the dataframes to avoid any SettingwithCopyWarnings in the future\",\"Rename the raw columns from the script dataframe for readability and binary gender\\n# 0 for male, 1 for female in the gender column\",\"Check if the episodes' raw data is complete.\",\"Get rid of experimental and unsued file that may still be in the workspace\",\"We merge dialogues from the scripts and the respective speakers by using left join on character_id field and index field, we finally consider only\\nthose episode whose script is complete.\",\"Take a peak at what the dataframes looks like\\nprint(df_characters.head())\\nprint(df_locations.head())\\nprint(df_script.head())\\nprint(df_episodes.head())\",\"Inspector\\ndf_script.inspect()\",\"Inspect the characters dataframe to understand its structure and columns\\nprint(df_characters.head())\\n# List unique values in the df_characters dataframe, and count the number of unique characters\\nprint(df_characters.nunique())\",\"Compute and display the number of characters, locations, and lines in the dataset\",\"Ensure reproductibility of the results\\nnp.random.seed(0)\",\"Show the first five rows of df_locations\\ndf_locations.head()\",\" Merge character and location in script\\ndf_script_with_character = pd.merge(df_script, \\n                                    df_characters,\\n                                    left_on='character_id', \\n                                    right_on='id').drop(['id'], axis=1).rename({'name': 'character_name'}, axis=1)\",\"Inspect the dataframes head\\nprint(df_characters.head())\\nprint(df_locations.head())\\nprint(df_script.head())\\nprint(df_episodes.head())\",\"Create a single dataframe's column with the whole script\",\"Inspect the head of each dataframe\\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()\",\" Show tables\\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()\",\"Show the dataframes to gain an overview of the columns and data types.\",\" Set index to character_id for better handling\\ndf_characters.set_index('character_id', inplace=True)\",\"Check main DataFrames' structure\\nprint(df_characters)\\nprint(df_locations)\\nprint(df_script)\\nprint(df_episodes)\",\"Preview the first few rows of each DataFrame\\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()\",\"Remove information about Simpsons' episode title and whether its dataset\\n# Song does not have any meaningful information\\ndf_script.pop('episode_title')\\ndf_script.pop('number')\",\" Read the file containing distinct word and their word type\",\"Display all dataframe columns\\npd.set_option('display.max_columns', None)\\n\\n# Show first rows of each dataframe\\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()\",\"Extracting the characters who appear in the script\\ncharacters_list = df_script[\\\"raw_character_text\\\"].value_counts().keys().tolist()\\n\\n# Merging the dataframe with the script lines and the one with unique characters\\ndf_characters = df_characters.merge(pd.DataFrame(characters_list, columns=[\\\"character_name\\\"]), on=\\\"character_name\\\")\",\" Create an nlp object\\nnlp = spacy.load('en_core_web_sm')\",\"Clean data\\ndf_script_clean = df_script[\\n    (df_script.raw_character_text != ' ') & (df_script.raw_character_text != 'Miss Hoover') & (df_script.raw_character_text != 'Miss Hoover & Martin') & \\\\\\n    (df_script.raw_character_text != 'Miss Hoover & Terri & Martin') & \\\\\\n    (df_script.raw_character_id != 8) & (df_script.raw_location_text != 'nan')\\n]\",\"Print the dataframes to understand their structure\\nprint(df_characters.head())\\nprint(df_locations.head())\\nprint(df_script.head())\\nprint(df_episodes.head())\",\"Let's explore the data to see what it looks like.\",\"'Read' is not defined\",\"Filter out bad data from the dataset\",\"Let's see the first lines of those dataframes\",\"Create is_simpsons column, filter and subset script lines\",\" Display the progress bar by setting the pandas options\\ntqdm.pandas()\",\"display general information about the datasets\",\"# IPython-cache\\n%load_ext jupyter_cache\\n\\n# Caching\\n%cache df_characters df_locations df_script df_episodes\",\"Inspect each dataframe to understand its structure and content\",\"Displaying the sample of dataframe of script lines\\ndf_script.head(10)\",\"Show a few samples of the characters dataframe\",\"Lets start with simple statistics of dataframes\",\"Organize each data frame by their IDs as shown below\",\"Let's start by examining the contents of each dataset.\",\"Let's first take a look at the structure of the data frames.\",\" For more details about the dataset, read 'description.txt'\",\" Limit the script data to only the characters in df_characters\\ndf_script_lim = df_script[df_script[\\\"raw_character_text\\\"].isin(df_characters.character_text)]\",\"Merges and filters data\",\"Split locations, removes duplicates, and assigns a unique identifier\",\"Check the first rows of each dataset\\nprint('Characters')\\nprint(df_characters.head())\\nprint('\\\\nLocations')\\nprint(df_locations.head())\\nprint('\\\\nScript')\\nprint(df_script.head())\\nprint('\\\\nEpisodes')\\nprint(df_episodes.head())\",\"Remove unnecessary columns and fill NaN values with empty strings\\ndf_script = df_script[['episode_id', 'id', 'character_id', 'location_id', 'raw_text']]\\ndf_script = df_script.fillna('')\",\" Viewing memory usage of each dataframe\\nprint(\\\"Memory usage of each dataframe:\\\")\\nprint(df_characters.memory_usage().sum())\\nprint(df_locations.memory_usage().sum())\\nprint(df_script.memory_usage().sum())\\nprint(df_episodes.memory_usage().sum())\",\"create dictionary for character locations\\ncharacter_to_locations = {}\\n\\nfor i, row in df_script.iterrows():\\n    # If character hasn't been added to the dictionary yet, add it\\n    if row['raw_character_text'] not in character_to_locations.keys():\\n        character_to_locations[row['raw_character_text']] = []\\n    \\n    # If character location hasn't been added to the list yet, add it\\n    if row['raw_location_text'] not in character_to_locations[row['raw_character_text']]:\\n        character_to_locations[row['raw_character_text']].append(row['raw_location_text'])\",\"Visualize the number of lines per episode\\ndf_episodes['id'] = df_episodes['id'].apply(str)\\ndf_script['episode_id'] = df_script['episode_id'].apply(str)\\n\\nlines_per_episode = df_script['episode_id'].value_counts().reset_index()\\nlines_per_episode.columns = ['episode_id', 'num_lines']\\n\\nlines_per_episode = lines_per_episode.merge(df_episodes, left_on='episode_id', right_on='id')\\nlines_per_episode = lines_per_episode.sort_values(by='original_air_date')\\nlines_per_episode['episode_id'] = lines_per_episode['id']  # Rename because there is another column with the same name, and we need it for the next step.\",\"Read data head\",\"Check the first 5 lines of each dataframe to understand the data\",\"Separate the quotes from the script in test\\u002ftraining\",\"Display the first few lines of each dataframe to understand its structure\\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()\",\"Merge the specified dataframe with the scripts dataframe\",\" Exploratory Data Analysis\",\"Inspect the first few rows of the script dataset to understand its structure\\ndf_script.head()\",\"Check information of the script dataset\\nprint(df_script.head())\\nprint(df_script.info())\",\"Check the three base datasets\\ndf_characters.head()\",\"Cleaning up the mess from the stupid Pandas.\",\"check files in directory\",\"Preview the first 5 records of each dataset\\nprint(df_characters.head(5))\\nprint(df_locations.head(5))\\nprint(df_script.head(5))\\nprint(df_episodes.head(5))\",\" Print size of datasets\\nprint(\\\"Characters Shape:\\\", df_characters.shape)\\nprint(\\\"Locations Shape:\\\", df_locations.shape)\\nprint(\\\"Script Shape:\\\", df_script.shape)\\nprint(\\\"Episodes Shape:\\\", df_episodes.shape)\",\"Tutorials will typically use this to make the resulting data frames simpler to work with\\ndf_characters.simpsons_character_id = df_characters.simpsons_character_id.astype('int32')\\ndf_locations.simpsons_location_id = df_locations.simpsons_location_id.astype('int32')\\ndf_episodes.simpsons_episode_id = df_episodes.simpsons_episode_id.astype('int32')\\ndf_script.simpsons_script_line_id = df_script.simpsons_script_line_id.astype('int32')\\ndf_script.simpsons_character_id = df_script.simpsons_character_id.astype('int32')\\ndf_script.simpsons_location_id = df_script.simpsons_location_id.astype('Int32')\\ndf_script.simpsons_location_id = df_script.simpsons_location_id.astype('Int32')\",\" Combine df_script with df_episodes and filter out non-Simpsons lines\",\"Merge the tables to contain all necessary information needed for the analysis.\",\"display complete dataframe for a quick look\\ndf_script\",\"Set random seed for reproducibility\\nnp.random.seed(0)\",\"Convert stringified lists into lists\",\"Setting path for the to be saved wordclouds for each episode, character and location\\nwordcloud_path = os.path.dirname(os.path.realpath(__file__))+'\\u002fwordclouds\\u002f'\",\"Confirm everything looks good so far\\ndisplay(df_characters.head())\\ndisplay(df_locations.head())\\ndisplay(df_script.head())\\ndisplay(df_episodes.head())\",\"For the sake of simplicity, we will remove unncessary columns from specific tables and save them into a new CSV which we will inport later on.\",\"Preview the data to quickly gather the main information and have a general view of the structure and content.\",\"Create a copy of the \\\"simpsons_script_lines\\\" dataframe and drop the \\\"id\\\" and \\\"episode_id\\\" columns\\ndf = df_script.copy()\\ndf.drop(columns=['id', 'episode_id'], inplace=True)\",\" Remove unwanted column\\ndf_script = df_script.drop('id', axis=1)\",\"Print the shape of the dfs\\ndf_characters.shape, df_locations.shape, df_script.shape, df_episodes.shape\",\"Check for any empty cells in a column\",\"Check the data shape\\nprint(df_characters.shape)\",\"Merge the dataframes to obtain a single dataframe containing all the information about the scripts.\",\"Create the NLP object and add vectors for the entity linking model\\nnlp = spacy.load('en_core_web_sm')\\nlinker = nlp.get_pipe('entity_linker')\\nfor i, row in df_characters.iterrows():\\n    linker.add_Entity(entity=row['raw_name'], freq=0, entity_vector=nlp(row['raw_name']).vector)\\nfor i, row in df_locations.iterrows():\\n    linker.add_Entity(entity=row['raw_location'], freq=0, entity_vector=nlp(row['raw_location']).vector)\",\" Creating a corpus of documents, we select some particular collection of documents as our data source.\",\"Explore the dataframe shape (columns and samples)\",\" Quick look at the character dataset\\nprint(\\\"Shape of the data:\\\", df_characters.shape)\\ndf_characters.head()\",\" Viewing first ten records of the dataframe which contains the script for the scenes of all the episodes\",\"Covert character_id and location id to int\\ndf_script['character_id'] = df_script['character_id'].astype('Int64')\\ndf_script['location_id'] = df_script['location_id'].astype('Int64')\",\"Get the characters played by the actors (not from the script)\",\" Do work on df_characters, df_locations, df_script, and df_episodes.\",\"Copy the original dataframe into a new variable (in order to avoid reloading it from the CSV)\",\"# Total script lines\\nprint('Total script lines:', df_script.shape[0])\",\"Inspect the dataframes by printing the first few rows of each dataframe\\nprint('Characters:')\\nprint(df_characters.head())\\n\\nprint('Locations:')\\nprint(df_locations.head())\\n\\nprint('Script:')\\nprint(df_script.head())\\n\\nprint('Episodes:')\\nprint(df_episodes.head())\",\"Define a function to load the SpaCy model for named entity recognition (NER) and attach it to the pandas dataframe.\",\"View first 5 rows of characters dataframe\\ndf_characters.head()\",\"# Making sure data has been loaded properly\\nprint('Characters - num rows : ', df_characters.shape[0])\\nprint('Locations - num rows : ', df_locations.shape[0])\\nprint('Script lines - num rows : ', df_script.shape[0])\\nprint('Episodes - num rows : ', df_episodes.shape[0])\",\"Extract the file_name and line_text columns\\ndf_script = df_script[['file_name', 'normalized_text']]\",\"Remove erroneous information on Lisa having the most lines ever\",\"Finding every location mentioned in every one of the scripts in this season\",\" Print out the first few rows of each dataframe to understand their structure\\nprint(df_characters.head())\\nprint(df_locations.head())\\nprint(df_script.head())\\nprint(df_episodes.head())\",\"Remove the second index column that appeared from the file\",\"Inspect the first 3 rows of the main dataset (i.e., df_script)\\ndf_script.head(3)\",\"Check the head of each dataset to understand its structure\\nprint(df_characters.head())\\n\\nprint(df_locations.head())\\n\\nprint(df_script.head())\\n\\nprint(df_episodes.head())\",\" Examine the structure of the data frames\",\" Let's save the fruit of the EDA using the pickle format\\ndf_characters.to_pickle(\\\"data\\u002fsimpsons_characters.pkl\\\")\\ndf_locations.to_pickle(\\\"data\\u002fsimpsons_locations.pkl\\\")\\ndf_script.to_pickle(\\\"data\\u002fsimpsons_script.pkl\\\")\\ndf_episodes.to_pickle(\\\"data\\u002fsimpsons_episodes.pkl\\\")\",\"Modify episode id to be zero-indexed in order to facilitate join operations\\ndf_episodes['id'] = df_episodes['id'] - 1\",\"View basic data info\\nprint('characters: ', df_characters.shape, df_characters.columns)\\nprint('locations: ', df_locations.shape, df_locations.columns)\\nprint('script: ', df_script.shape, df_script.columns)\\nprint('episodes: ', df_episodes.shape, df_episodes.columns)\",\"Look at the list of episodes\\nfor i, row in df_episodes.iterrows():\\n    print(row['title'], row['original_air_date'])\",\"Consider displaying the data to understand its structure and available columns.\",\" Pre-processing and Feature Generation\",\"Look at the head of the table to understand the data.\",\"Find the names of all the columns in the dataframe\",\"Create an 'id' for each episode and character ID\\ndf_script['episode_id'] = df_script['episode_id'].apply(str)\\ndf_script['id'] = df_script.index.astype(str)\\ndf_characters['id'] = df_characters.index.astype(str)\\ndf_locations['id'] = df_locations.index.astype(str)\\ndf_episodes['id'] = df_episodes['id'].astype(str)\",\"Create a list for each episode containing all its lines\\nepisode_2_lines = []\\nfor episode in df_episodes[df_episodes['id']==3]['episode_id']:\\n    episode_lines = df_script[df_script['episode_id']==episode]\\n    episode_2_lines.append(' '.join(episode_lines['raw_text']))\",\" Convert columns containing json data into dataframes\\nimport json\\nfrom pandas.io.json import json_normalize\\n\\n# convert to json\\ndf_script[\\\"episode_id\\\"] = df_script[\\\"episode_id\\\"].apply(lambda x: json.loads(x.replace(\\\"'\\\", \\\"\\\\\\\"\\\")))\\ndf_script[\\\"character_id\\\"] = df_script[\\\"character_id\\\"].apply(lambda x: json.loads(x.replace(\\\"'\\\", \\\"\\\\\\\"\\\")))\\ndf_script[\\\"location_id\\\"] = df_script[\\\"location_id\\\"].apply(lambda x: json.loads(x.replace(\\\"'\\\", \\\"\\\\\\\"\\\")))\\ndf_script[\\\"spoken_words\\\"] = df_script[\\\"spoken_words\\\"].apply(lambda x: json.loads(x.replace(\\\"'\\\", \\\"\\\\\\\"\\\")))\\ndf_script[\\\"normalized_text\\\"] = df_script[\\\"normalized_text\\\"].apply(lambda x: json.loads(x.replace(\\\"'\\\", \\\"\\\\\\\"\\\")))\\n\\n# Transform json into individual lines\\ndf_script_eid = df_script.explode('episode_id').reset_index(inplace=False, drop=True)\\ndf_script_cid = df_script.explode('character_id').reset_index(inplace=False, drop=True)\\ndf_script_lid = df_script.explode('location_id').reset_index(inplace=False, drop=True)\\ndf_script_spoken = df_script.explode('spoken_words').reset_index(inplace=False, drop=True)\\ndf_script_normalized = df_script.explode('normalized_text').reset_index(inplace=False, drop=True)\",\" Merge episodes and locations dataframes\\ndf_episodes_locations = df_episodes.merge(df_locations, left_on='id', right_on='episode_id').drop('episode_id', axis=1)\",\"Show the first few lines of each dataframe to understand their structure\\ndf_episodes.head(), df_characters.head(), df_locations.head(), df_script.head()\",\"Check the data schema\",\" Good job! Now we have successfully imported the necessary datasets for our analysis.\",\"Tokenize, lemmatize, remove stopwords and punctuation, and lowercase the text\\nnlp = spacy.load('en_core_web_sm')\\n\\n# Remove unwanted characters, stopwords, and make everything lowercase\\nstopwords = spacy.lang.en.stop_words.STOP_WORDS\",\" Join all datasets\",\"# Function to load data from CSV files\\ndef load_data(file_name):\\n    return pd.read_csv(file_name).reset_index(inplace=False, drop=True)\",\"change columns to lower case and replace ' ' by '_'\\ndf_characters.columns = [col.lower().replace(' ', '_') for col in df_characters.columns]\\ndf_locations.columns = [col.lower().replace(' ', '_') for col in df_locations.columns]\\ndf_script.columns = [col.lower().replace(' ', '_') for col in df_script.columns]\\ndf_episodes.columns = [col.lower().replace(' ', '_') for col in df_episodes.columns]\",\"# Cleaning Strings\\ndf_characters = df_characters.dropna(subset=['name', 'normalized_name'])\\ndf_locations = df_locations.dropna(subset=['name', 'normalized_name'])\\ndf_script = df_script.dropna(subset=['character_id', 'location_id', 'raw_text'])\\ndf_episodes = df_episodes.dropna(subset=['title'])\",\"Load the necessary data files for analysis and processing.\",\"##### Section 1: DataFrame Cleaning and Preparation #####\\n\",\"Show sample lines from the script\\ndf_script.head()\",\"Count the number of unique characters in the dataset\\nlen(df_characters['character_id'].unique())\",\"Inspect the scripts DataFrame\\ns = [i \\u002f len(df_script) for i in range(len(df_script))]\\nsample = df_script.sample(frac=0.1)\\nseries = sample.groupby('episode_id').count()['id']\",\"Join the datasets on the numeric column.\",\"Print the head of the 'script' dataset\\ndf_script.head()\",\"Just ensure that the path to the data files is correct.\",\"sampling data\\ndf_characters = df_characters.sample(20)\\ndf_locations = df_locations.sample(5)\\ndf_episodes = df_episodes.sample(20)\",\"Load Spacy large library on disk\\nnlp = spacy.load('en_core_web_lg', disable=['ner', 'parser'])\",\"Let's see the first rows of each one of the files to better understand them.\\n\\nprint(\\\"Characters:\\\")\\nprint(df_characters.head())\\nprint(\\\"Locations:\\\")\\nprint(df_locations.head())\\nprint(\\\"Script:\\\")\\nprint(df_script.head())\\nprint(\\\"Episodes:\\\")\\nprint(df_episodes.head())\",\"Look at the first few rows of df_script\\ndf_script.head()\",\"Display the dataframe types\\nprint(df_characters.dtypes)\\nprint(df_locations.dtypes)\\nprint(df_script.dtypes)\\nprint(df_episodes.dtypes)\",\"Display the first rows of the table containing the simpsons scripts.\",\"Resize the amount of data we are going to work with. For this version, our machine learning model will be trained with 20,000 lines of dialogue.\",\" Display the pandas dataframe containing the scripts of the Simpsons episodes\\ndf_script\",\"Merge the datasets together to create a unified view of the data.\",\"# Helper functions\\ndef clean_text(text):\\n    # For now, we simply remove non-alphanumeric characters and multiple spaces\\n    return re.sub(r'[^A-Za-z0-9 ]+', '', text).lower().replace('  ', ' ').strip()\\n\\ndef get_episode_name(df, episode_id):\\n    episode = df[df.id == episode_id]\\n    if len(episode) \\u003e 0:\\n        return episode.iloc[0].title\\n    return ''\",\"take a look at the available columns in the dataset\\nprint(df_script.columns)\",\"# create a column for every episode\\u002fcharacter combination and populate it with line_index\\nep_char_comb = pd.merge(df_script[['episode_id', 'character_id','line_index']],\\n                        pd.crosstab(df_script['line_index'], df_script['character_id'])\\n                                .reset_index(inplace=False),\\n                        on='line_index',\\n                        how='left')\",\"# shows the first 5 lines of each dataframe\\nprint(df_characters.head())\\nprint(df_locations.head())\\nprint(df_script.head())\\nprint(df_episodes.head())\",\"Some functions from the script\\ndef get_entity_text(text, entities):\\n    '''Return text of the entites in the text'''\\n    entities = eval(entities)\\n    text = str(text)\\n    new_txt = text\\n    shifts = 0\\n    for entity in entities:\\n        if entity[0]+shifts != entity[1]+1+shifts:\\n            new_txt = new_txt[:entity[0]+shifts] + '`' + text[entity[0]+shifts:entity[1]+1+shifts] + '`' + new_txt[entity[1]+1+shifts:]\\n            shifts += 2\\n        else:\\n            new_txt = new_txt[:entity[0]+shifts] + '`' + '`' + new_txt[entity[0]+shifts:]\\n            shifts += 1\\n    return new_txt\",\"Setting index on 'id' column for easy reference\",\"print('Script dataframe: -' + str(len(df_script)) + \\\"- entries, \\\"+ str(len(df_script['episode_id'].unique())) + \\\" unique episodes.\\\" )\",\"Check our datasets\\ndf_characters.head()\",\"Filter characters whose names contain last_name or first_name\\nmain_characters = [name for name in df_characters.character_name.unique() if ((last_name in name) or (first_name in name))]\",\"Remove trailing whitespace from columns\\ndf_characters.columns = df_characters.columns.str.strip()\\ndf_locations.columns = df_locations.columns.str.strip()\\ndf_script.columns = df_script.columns.str.strip()\\ndf_episodes.columns = df_episodes.columns.str.strip()\",\"Print the shape of the datasets\\nprint(df_characters.shape, df_locations.shape, df_script.shape, df_episodes.shape)\",\"Define the characters' speech as the features, and the characters as the target.\",\"Combine Episodes and Script dataframes.\",\"Merge the data into one dataframe\",\"Split text into words using SpaCy's English tokenizer.\",\"Merge script with episodes\\ndf = df_script.merge(df_episodes, on='episode_id')\\n# Create a date field\\ndf['date'] = pd.to_datetime(df['original_air_date'])\\n# BeautifulSoup is cleaner\\ndf['raw_text_clean'] = df['raw_text'].str.replace('\\u003c.*\\u003e', '')\",\" Set context\\n# I usually do it in this way to not mess with the original df\\ndf = df_script\",\" Defines characters as main characters only\",\"Clean the script of incorrect or empty values and reset index afterward.\",\"Extract data requirements for specific questions\",\" Set the relevant columns to string, we don't want to perform numeric operations on them\\ndf_script['raw_character_text'] = df_script['raw_character_text'].astype(str)\\ndf_script['spoken_words'] = df_script['spoken_words'].astype(str)\\ndf_script['raw_location_text'] = df_script['raw_location_text'].astype(str)\\ndf_episodes['title'] = df_episodes['title'].astype(str)\",\"Let's take a look at each of the datasets and determine if any preprocessing is necessary.\",\" Check datasets \\ndf_characters.head()\",\"Quickly displaying basic information about the datasets\",\"Filter the script data to only keep the rows from the training set and the characters and locations available in the corresponding dataframes.\",\"Get an overview of the characters dataset\\nprint(df_characters.head())\\n\\n# Get an overview of the locations dataset\\nprint(df_locations.head())\\n\\n# Get an overview of the script lines dataset\\nprint(df_script.head())\\n\\n# Get an overview of the episodes dataset\\nprint(df_episodes.head())\",\"Let's take a quick look at the first few rows in each DataFrame to understand the data better.\",\"Set filepath here\\nfilepath = \\\"data\\u002fepisodes\\\"\",\"Import of Dataframes successfully executed\",\"Cleaning the column names\\ndf_episodes.columns = [e.lower().replace(' ', '_') for e in df_episodes.columns]\\ndf_script.columns = [e.lower().replace(' ', '_') for e in df_script.columns]\\ndf_characters.columns = [e.lower().replace(' ', '_') for e in df_characters.columns]\\ndf_locations.columns = [e.lower().replace(' ', '_') for e in df_locations.columns]\",\"Preview of the first 5 rows of each dataframe\\nprint(\\\"df_characters:\\\")\\nprint(df_characters.head())\\nprint(\\\"df_locations:\\\")\\nprint(df_locations.head())\\nprint(\\\"df_script:\\\")\\nprint(df_script.head())\\nprint(\\\"df_episodes:\\\")\\nprint(df_episodes.head())\",\"Lets see what the contents look like\",\"Optional (this script is designed to select a sub-dataset to reduce memory consumption.\\n# scripts for visualizations)\",\"Check the first few rows of the episodes dataframe\",\"Check if these work correctly\",\"# Get all lines and characters of an episode\\ndef get_episode_lines_chars(season, episode):\\n    df_episode = df_script[(df_script[\\\"season\\\"]==season) & (df_script[\\\"episode\\\"]==episode)]\\n    df_episode_chars = df_episode[\\\"character_id\\\"].value_counts().to_frame().merge(df_characters, left_index=True, right_on=\\\"id\\\")\\n    df_episode_chars.columns = [\\\"count\\\", \\\"character_id\\\", \\\"name\\\", \\\"normalized_name\\\", \\\"gender\\\", \\\"description\\\", \\\"color\\\", \\\"image\\\"]\\n    \\n    return df_episode, df_episode_chars\",\"Clean the script data\\ndf_script_cleaned = df_script[(df_script['speaking_line'] == True) & (df_script['character_id'] != 0)]\\n\\n# Join character information\\ndf_script_cleaned = df_script_cleaned.merge(df_characters, how='left', on='character_id')\\n\\n# Join location information\\ndf_script_cleaned = df_script_cleaned.merge(df_locations, how='left', on='location_id')\\n\\n# Join episode information\\ndf_script_cleaned = df_script_cleaned.merge(df_episodes, how='left', on='episode_id')\\n\\n# Display the first few rows of the cleaned script data\\ndf_script_cleaned.head()\",\"Check the contents of the dataset\\ndf_script.head()\",\" Remove rows where the episode id, character id, or location id are empty\\u002fnull\\ndf_script = df_script[df_script['episode_id'].notna()]\\ndf_script = df_script[df_script['character_id'].notna()]\\ndf_script = df_script[df_script['location_id'].notna()]\",\"Some adjustments\\npd.options.display.max_columns = None\",\"Sample of how the data looks like\\nprint(\\\"Characters data sample\\\")\\nprint(df_characters.head(n=5))\",\"Create a copy of the script data to work with\\nscript_lines_copy = df_script.copy()\",\"Change size of the `script` column.\\n\\ndf_script['raw_text'] = df_script['raw_text'].astype('string')\",\"Create a directory to store visualizations if not present\",\"Clean the script and the character names\",\" visualize\\nfrom spacy import displacy\",\"Create a \\\"Scripted_line\\\" that join the \\\"spoken_words\\\" of each character and each location\",\"# Display the data to understand the structure\\ndf_script.head()\",\"Create test sets that have the same items but in a different order\\ntest_set1 = {1, 2, 3}\\ntest_set2 = {3, 1, 2}\",\"Merge the dataframe tables `df_script`, `df_locations`, `df_characters` and `df_episodes` on the common columns.\",\"Printing the first few lines of each dataframe to see what they look like\\nprint(df_characters.head())\\nprint(df_locations.head())\\nprint(df_script.head())\\nprint(df_episodes.head())\",\"Set plot style\\nplt.style.use('fivethirtyeight')\",\"Remove character ids which are continuous and start which 1 and are present in the charcater csv from the scripts dataframe\",\"Sample the dataframe by printing each distinct value and it's frequency\\nfor idx, value_count in df_characters.nunique().iteritems():\\n    print(idx, value_count)\",\"Check the 5 characters in the df_characters dataframe\",\"Set OS encoding to UTF-8\",\"Inspects the first few rows of the scripts dataframe\\ndf_script.head()\",\" Let's take a look at the first few rows from each dataframe to understand the data better.\",\"Let's take a look at the first few rows of each dataframe to understand the data better.\",\"For full transparency I will provide the first few rows of the dataframe\",\"check the first row for each dataframe\\nprint(df_characters.head(1))\\nprint(df_locations.head(1))\\nprint(df_script.head(1))\\nprint(df_episodes.head(1))\",\"Create a new column in df_script with the number of words in the utterance.\",\"Check the first few lines of the characters dataframe.\",\"Check the first few rows of each dataframe\\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()\",\"Visualize number of lines per season\",\"The columns we are interested in are:\\ndf_script: \\\"episode_id\\\", \\\"number\\\", \\\"raw_text\\\"\\ndf_episodes: \\\"id\\\", \\\"title\\\", \\\"original_air_date\\\"\\ndf_locations: \\\"id\\\", \\\"name\\\"\\ndf_characters: \\\"id\\\", \\\"name\\\"\",\"Check the downloaded dataito see what we are working with\\nprint('characters:', df_characters.shape)\\nprint('locations:', df_locations.shape)\\nprint('script:', df_script.shape)\\nprint('episodes:', df_episodes.shape)\",\"To ensure the data is loaded properly, let's print out the first few rows of each dataframe.\",\"Remove nonsense lines with length of less than 10 from the dataset\",\"Setting correct datatypes for the dataframes\",\" Visualize episodes per season\\ndf_episodes.groupby('season')['id'].count().plot(kind='bar', color='skyblue', figsize=(15, 7))\",\"Checking few records\\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()\",\"# Show first rows of the characters table\\ndf_characters.head()\",\" Check the list of transcript's columns to use the one we want to.\",\"Display a sample of the dataframe containing the script lines\",\"Preview data files\\nprint(df_characters.head())\\nprint(df_locations.head())\\nprint(df_script.head())\\nprint(df_episodes.head())\",\"TODO: Add description\",\"Check the loaded dataframes\\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()\",\"Just look up the head of all the dataframe to see everything looks fine\\nfor df in [df_characters, df_locations, df_script, df_episodes]:\\n    print(df.head())\",\"Set up matplotlib.rcParams, then make all plots.\",\"Rename columns to lowercase and replace spaces with underscores\\ndf_characters.columns = [col.lower().replace(' ', '_') for col in df_characters.columns]\\ndf_locations.columns = [col.lower().replace(' ', '_') for col in df_locations.columns]\\ndf_script.columns = [col.lower().replace(' ', '_') for col in df_script.columns]\\ndf_episodes.columns = [col.lower().replace(' ', '_') for col in df_episodes.columns]\",\" Check the data types of each column\\ndf_script.dtypes\",\" Clean up the datasets\\ndf_locations = df_locations.drop(columns=['id', 'normalized_name'])\\ndf_characters = df_characters.drop(columns=['id', 'normalized_name'])\\ndf_episodes = df_episodes.drop(columns=['id'])\\n\\n# Filter script to only load rows from the first 8 seasons\",\"Check the content of the loaded DataFrames\\nprint(df_characters.head())\\nprint(df_locations.head())\\nprint(df_script.head())\\nprint(df_episodes.head())\",\"Since we already have the scripts, characters, and locations data, we will focus on text preprocessing, including part-of-speech tagging and named entity recognition.\",\"Displaying the data and checking dtypes to understand the data better\\nprint(df_characters.head())\\nprint(df_characters.dtypes)\\n\\nprint(df_locations.head())\\nprint(df_locations.dtypes)\\n\\nprint(df_script.head())\\nprint(df_script.dtypes)\\n\\nprint(df_episodes.head())\\nprint(df_episodes.dtypes)\",\"We can start by exploring the first rows of each dataframe to understand the structure and contents of the data we are dealing with.\",\"NLP model for Named Entity Recognition (NER)\\nnlp = spacy.load('en_core_web_sm')\",\"Display the first few rows of the table to check the proper loading of data\\ndf_characters.head()\",\"Visualizing the distribution of character genders.\",\" Merge character information\\ndf_episodes_characters = (\\n    df_episodes.merge(df_script, how='left', on='episode_id')\\n    .merge(df_characters, how='left', on='character_id', suffixes=['_ep', '_ch'])\\n    .sort_values(by=['id_ep', 'timestamp_in_ms'])\\n)\",\"Check the first few rows of each dataset\\nprint(\\\"Characters:\\\")\\nprint(df_characters.head())\\n\\nprint(\\\"\\\\nLocations:\\\")\\nprint(df_locations.head())\\n\\nprint(\\\"\\\\nScript:\\\")\\nprint(df_script.head())\\n\\nprint(\\\"\\\\nEpisodes:\\\")\\nprint(df_episodes.head())\",\"Check to see if the imports and data were loaded correctly\\n# Display the first few rows of each dataframe\\nprint('Characters dataframe shape:', df_characters.shape)\\nprint(df_characters.head(3))\\nprint('\\\\n')\\n\\nprint('Locations dataframe shape:', df_locations.shape)\\nprint(df_locations.head(3))\\nprint('\\\\n')\\n\\nprint('Script dataframe shape:', df_script.shape)\\nprint(df_script.head(3))\\nprint('\\\\n')\\n\\nprint('Episodes dataframe shape:', df_episodes.shape)\\nprint(df_episodes.head(3))\",\" Selecting the season from \\\"df_episodes\\\" dataframe.\",\"Create a spacy nlp object\\nnlp = spacy.load('en_core_web_sm')\",\"Check dimensions of the datasets to make sure nothing is misaligned\\nprint(\\n    \\\"Characters:\\\\t\\\", df_characters.shape,\\n    \\\"\\\\nLocations:\\\\t\\\", df_locations.shape,\\n    \\\"\\\\nScript:\\\\t\\\\t\\\", df_script.shape,\\n    \\\"\\\\nEpisodes:\\\\t\\\",  df_episodes.shape\\n)\",\"We will now begin exploring the dataset to understand its structure and contents.\",\"Set up colors for plotting\\ncolors = {\\n    'other': '#adb0ff',\\n    'male': '#ffb3e6',\\n    'female': '#90d595'\\n}\",\"Creating a full dataframe\\u0443\\u043c\\u0435\\u043d\\u0442 with all the columns together\",\"def preprocess_dialogue(dialogue):\\n    \\\"\\\"\\\"\\n    Function to preprocess dialogue text data\\n    \\n    Args:\\n    dialogue - A string containing the dialogue\\n    \\n    Returns:\\n    clean_dialogue - The preprocessed and cleaned dialogue\\n    \\\"\\\"\\\"\\n    # Convert to lowercase\\n    dialogue = dialogue.lower()\\n    \\n    # Remove extra whitespaces\\n    dialogue = ' '.join(dialogue.split())\\n    \\n    # Replace 'uh-huh' with 'yes'\\n    dialogue = dialogue.replace('uh-huh', 'yes')\\n    \\n    # Replace 'uh-uh' with 'no'\\n    dialogue = dialogue.replace('uh-uh', 'no')\\n    \\n    # Remove laughter 'haha', 'hahaha', 'hahahaha', etc\\n    dialogue = dialogue.replace('ha', '')\\n    \\n    return dialogue\",\" We will leave the Timestamp as it is, we will drop the other character_colums, and the raw text, we will leave the spoken_words since that's the one we will make embeddings about\",\"Clean the script dataframe\",\"Data overview\",\"Join the data frames to make the master data set\",\"Set up working directory\\nos.chdir('C:\\u002fUsers\\u002fnovir\\u002fgithub\\u002fsimpsons_analysis')\",\"Let's focus on script lines for this part of the analysis, specifically the spoken words.\",\" Set the display columns for the DataFrame to avoid truncation of the data\",\"Enable the tqdm \\\"notebook\\\" extension\\ntqdm.pandas()\",\"# remove unused columns\\ndf_script.drop(columns=['number', 'raw_text', 'timestamp_in_ms'], inplace=True)\",\"Compute values for training samples.\",\"Define a function to create a word cloud from a given text\",\"Display all the columns and the first five rows of the df_characters dataframe\\ndf_characters.head()\",\"Visualize data\\ndf_script.head()\",\"Display data\\nwith pd.option_context('display.max_rows', None):\\n    display(df_characters.describe())\\n    display(df_locations.describe())\\n    display(df_script.describe())\\n    display(df_episodes.describe())\",\"Join all data.\",\"Create a directory within the data directory\\ndirectory = 'data\\u002fwordclouds\\u002f'\\nif not os.path.exists(directory):\\n    os.makedirs(directory)\",\"Generate word cloud of the entire Simpsons script\\nscript = \\\" \\\".join(df_script['spoken_words'].fillna(\\\"\\\"))\",\"View first 5 rows of characters DataFrame\\ndf_characters.head()\",\" Clean character names\\ndf_characters.character_id = df_characters.character_id.apply(str)\\ndf_script.character_id = df_script.character_id.apply(str)\",\"Inspecting the character data\\nprint(df_characters.head())\",\"instantiate spacy\\nnlp = spacy.load('en_core_web_sm')\\n\\n# function to preprocess the data\\ndef process(text, model=nlp, max_length=1000000):\\n    text = text[:max_length]\\n    doc = model(text)\\n    return [ent.text for ent in doc.ents]\",\" Setting the seed for reproducibility\\nnp.random.seed(0)\",\"We will remove the first column, which is the index column, and start by displaying a few lines from each dataframe.\",\"Print the shape and column names of the loaded data\\nprint(\\\"Characters\\\")\\nprint(df_characters.shape, df_characters.columns)\\nprint('--'*24)\\nprint(\\\"Locations\\\")\\nprint(df_locations.shape, df_locations.columns)\\nprint('--'*24)\\nprint(\\\"Script\\\")\\nprint(df_script.shape, df_script.columns)\\nprint('--'*24)\\nprint(\\\"Episodes\\\")\\nprint(df_episodes.shape, df_episodes.columns)\\nprint('--'*24)\",\"\\n# Small prepossessing of the csv files\\ndf_script = df_script.dropna(subset=['normalized_text'])\\ndf_script['character_id'] = df_script['character_id'].fillna(-1).astype(int)\",\"Read all the datasets and reset the index to ensure the data is properly formatted.\",\"Extract the main fields and linking key from the script dataframe.\",\"Display the dataframes to check they have been loaded correctly\\ndf_characters\",\"Merge Simpsons scripts with character info\\ndf = pd.merge(df_script, df_characters, on='character_id', how='inner')\\n\\n# Show the first few rows of the dataframe\\ndf.head()\",\"Let's have a look at one of our datasets, `df_script`.\",\"Display the dataframe once more to ensure the data has been loaded correctly\",\"Filter by character\\ndf_script['character_id'] = df_script['character_id'].astype(str)  # convert to str for consistency\\ndf_characters['id'] = df_characters['id'].astype(str)  # convert to str for consistency\",\"Filter for only the Simpsons family members, remove stage directions, and only include the speaking lines\",\"Exploratory data analysis\",\"Test if characters and locations are in the script dataframe\\ncharacters_in_script = [char.lower() for char in df_script['raw_character_text'].unique()]\\nlocations_in_script = [loc.lower() for loc in df_script['raw_location_text'].unique()]\",\"List of unique characters\\nprint(\\\"Number of characters: {}\\\".format(len(df_characters.character_id.unique())))\\ndf_characters.head()\",\"# Ensure the scripts are in order\\ndf_script.sort_values(['episode_id', 'timestamp_in_ms'], inplace=True)\",\"Extract the lines from the episode where Homer says 'doh'\",\" Reading word frequency data\",\" Explore the dataframes sizes and first rows\\nprint(\\\"Characters dataframe - rows:\\\", df_characters.shape[0], \\\"columns:\\\", df_characters.shape[1])\\nprint(\\\"Locations dataframe - rows:\\\", df_locations.shape[0], \\\"columns:\\\", df_locations.shape[1])\\nprint(\\\"Script dataframe - rows:\\\", df_script.shape[0], \\\"columns:\\\", df_script.shape[1])\\nprint(\\\"Episodes dataframe - rows:\\\", df_episodes.shape[0], \\\"columns:\\\", df_episodes.shape[1])\\n\\ndf_script.head()\",\"Show all available data\\npd.set_option('display.max_columns', None)\\npd.set_option('display.max_colwidth', -1)\\n\\nprint('\\\\ndf_characters:', df_characters.shape)\\ndisplay(df_characters.head(3))\\n\\nprint('\\\\ndf_locations:', df_locations.shape)\\ndisplay(df_locations.head(3))\\n\\nprint('\\\\ndf_script:', df_script.shape)\\ndisplay(df_script.head(3))\\n\\nprint('\\\\ndf_episodes:', df_episodes.shape)\\ndisplay(df_episodes.head(3))\",\"What is the most relevant information in the datasets?\",\" check the datasets\\nprint(df_characters.head(5))\\nprint(df_locations.head(5))\\nprint(df_script.head(5))\\nprint(df_episodes.head(5))\",\" Remove duplicate lines and keep the last version of the line\",\"Preview the first 5 rows of each dataframes\\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()\",\"Preview the first few lines of each table to understand what we are dealing with\\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()\",\"ensure data consistency\\ndf_script = df_script[df_script['episode_id'].isin(df_episodes['id'])]\\ndf_locations = df_locations[df_locations['id'].isin(df_script['location_id'])]\\ndf_characters = df_characters[df_characters['id'].isin(df_script['character_id'])]\",\"Merge the lines with the others DataFrames. This way we can have access to the episode information within the lines dataframe.\",\" Each dataset contains:\",\"NLP Library\\nnlp = spacy.load('en_core_web_sm')\",\"Create a pandas series with the base names, surnames and full names of the characters.\",\"Inspect dataframe shapes\\nprint(df_characters.shape)\\nprint(df_locations.shape)\\nprint(df_script.shape)\\nprint(df_episodes.shape)\",\"Inspect first few rows of each dataset\\nprint(df_characters.head())\\nprint(df_locations.head())\\nprint(df_script.head())\\nprint(df_episodes.head())\",\"Fixing some data problems here\",\"Check if GPU is available\\nimport tensorflow as tf\\nprint(\\\"Num GPUs Available: \\\", len(tf.config.list_physical_devices('GPU')))\",\"Ensure data is as expected\\ndisplay(df_characters.head(5))\\ndisplay(df_locations.head(5))\\ndisplay(df_script.head(5))\\ndisplay(df_episodes.head(5))\",\"Use the following line to remove the script line used for talks:\\n# (by putting it in the footer and then reading the CSV)\",\"# Strip leading and trailing whitespaces from string columns\\ndf_script = df_script.apply(lambda x: x.str.strip() if x.dtype == \\\"object\\\" else x)\",\" We'll also set the appropriate data types for each of the columns and perform other necessary data cleaning steps.\",\" GloVe embeddings\\nembeddings_index = {}\\nf = open(os.path.join('data\\u002fglove.6B.100d.txt'), encoding=\\\"utf-8\\\")\\nfor line in f:\\n    values = line.split()\\n    word = values[0]\\n    coefs = np.asarray(values[1:], dtype='float32')\\n    embeddings_index[word] = coefs\\nf.close()\",\" filter to keep only one character_location\\ndf_filtered_locations = df_locations[df_locations['raw_location_text'].str.lower().isin(df_script['raw_location_text'].str.lower().unique())].copy()\",\"View all datasets\\ndisplay(df_characters.head(3))\\ndisplay(df_locations.head(3))\\ndisplay(df_script.head(3))\\ndisplay(df_episodes.head(3))\",\" Optional (if you want visible changes in your word cloud)\\nmatplotlib.rcParams['figure.figsize'] = [10, 8]\",\" Filter nulls from location and characters dataframes\\ndf_characters = df_characters.dropna(subset=['normalized_name']).reset_index(inplace=False, drop=True)\",\"# Display the number of lines we have for each character\\nlines_by_character = df_script['raw_character_text'].value_counts()\\nlines_by_character\",\" Display basic information about the datasets\",\"The simpsons script is a flattened version of the episodes where each line is a new entry in the table.\",\"Print the first few rows of the dataset for sanity check\\nprint(df_characters.head())\\nprint(df_locations.head())\\nprint(df_script.head())\\nprint(df_episodes.head())\",\"to retain the original dataframes unchanged, let's make copies of them for data processing:\",\"Extract lines from the script that absolutely fit in the simpsons_episodes DataFrame\",\"Create new column with the script's length for each character and unite the data into a single DataFrame\",\"Initial filtering and cleanup\\n# Basic cleanup. Most important, we convert the column type of episode_id to int, further below we need that for filtering.\\ndf_script_filtered = df_script.dropna(subset=['raw_text', 'character_id'])\\n\\n# Merge duplicates and do other cleanup operations\\ndf_characters = df_characters.set_index('id').sort_index()\\ndf_characters['name'] = df_characters['name'].str.lower()\",\"def_prune_dataset(df_script=df_script,\\n                    df_characters=df_characters,\\n                    df_locations=df_locations,\\n                    df_episodes=df_episodes,\\n                    list_lowercase_stopwords=['the', 'and', 'a', 'in', 'to', 'of', 'on', 'for', 'is', 'that',\\n                                              'with', 'as', 'by', 'at', 'from', 'up', 'down', 'into', 'out', 'over',\\n                                              'off', 'be', 'are', 'were', 'we', 'you', 'your', 'they', 'their', 'them'],\\n                    list_successful_episodes=list_successful_episodes)\",\"VIEW ALL AVAILABLE DATA\\ndf_script\",\"\\n# Display the first 5 rows of the Characters dataframe\\ndf_characters.head()\",\"Setting ambiguous caharacters_id to -9\\ndf_script['character_id'].fillna(-9, inplace=True)\",\" Print shape of each dataframe\\nprint(f'Characters dataframe: {df_characters.shape}')\\nprint(f'Locations dataframe: {df_locations.shape}')\\nprint(f'Script dataframe: {df_script.shape}')\\nprint(f'Episodes dataframe: {df_episodes.shape}')\",\"Enrich Data: Characters, Locations, and Scripts\\n# Sort episodes by id\\ndf_episodes = df_episodes.sort_values(by='id').reset_index(drop=True)\\n\\n# Filter the dataframes\\ndf_script_en = df_script[df_script['raw_character_text'].notnull()]\\ndf_script_en = df_script_en[df_script_en['raw_location_text'].notnull()]\\n\\n# Removing duplicates\\ndf_script_en = df_script_en.drop_duplicates()\\n\\n# ensure `episode_id` column is integer\\ndf_script_en['episode_id'] = df_script_en['episode_id'].astype(int)\\n\\n# merging the episode to the script\\ndf_script_meta = df_script_en.merge(df_episodes[['id', 'title', 'original_air_date', 'production_code']], left_on='episode_id', right_on='id', how='right')\\n\\n# remove when `episode_id` is null\\ndf_script_meta = df_script_meta[~df_script_meta['episode_id'].isnull()]\\ndf_script_meta = df_script_meta.drop(['id', 'number', 'timestamp_in_ms'], axis=1)\\ndf_script_meta = df_script_meta.sort_values(by=['episode_id', 'id']).reset_index(drop=True)\\n\\n# install spacy model\\n!python -m spacy download en_core_web_sm\",\" View available data\\nprint(\\\"Characters\\\")\\nprint(df_characters.head())\\nprint(\\\"Locations\\\")\\nprint(df_locations.head())\\nprint(\\\"Script\\\")\\nprint(df_script.head())\\nprint(\\\"Episodes\\\")\\nprint(df_episodes.head())\",\"Create an entity recognizer and add it to the pipeline\",\"With `inplace=False` we reset the index of the dataframe, and we avoid creating a new dataframe.\",\"Select only the lines with a speaking character and a proper location\\ndf_script = df_script[(~df_script.raw_location_text.isna()) & (~df_script.character_id.isna())]\",\"Set maximum display rows\\u002fcolumns for better visual inspection\",\" We'll start by cleaning the dataset.\",\"Checking for correct import and dataframe display\",\"For the rest of the article, we'll focus only on the `df_script` DataFrame.\",\"Check the first few entries of each dataframe\\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()\",\"Clean quotes\\ndf_script['raw_character_text'] = df_script['raw_character_text'].apply(lambda x: \\\"\\\".join(i for i in x if ord(i)\\u003c128))\",\"Set the constants for matplotlib and spacy models.\",\"Examine the dataframes to see what we are working with\",\"Remove bad data from the lines dataset\\ndf_script = df_script.astype({'timestamp_in_ms':'float64'}).dropna(subset=['timestamp_in_ms']).astype({'timestamp_in_ms':'int64'})\\ndf_script = df_script.dropna(subset=['raw_text']).reset_index(drop=True)\\n# df_script.info()\",\" Quick exploration of the tables to understand the structure of the data\\ndisplay(df_characters.head())\\ndisplay(df_locations.head())\\ndisplay(df_script.head())\\ndisplay(df_episodes.head())\",\"Merge script lines, characters and episodes\\ndf_all = (\\n    df_script[['episode_id', 'character_id', 'id']]\\n    .merge(\\n        df_episodes[['id', 'season', 'number']],\\n        how='inner',\\n        left_on='episode_id',\\n        right_on='id'\\n    )\\n    .merge(\\n        df_characters[['id', 'name']],\\n        how='inner',\\n        left_on='character_id',\\n        right_on='id'\\n    )\\n    .drop(['id_x', 'id_y', 'episode_id', 'character_id'], axis=1)\\n)\\n\\n# Add 'season_episode' column\\ndf_all['season_episode'] = df_all['season'].astype(str) + '-' + df_all['number'].astype(str)\\n\\n# Replace character_id=-1 by character name 'unknown'\\ndf_all['name'] = df_all['name'].mask(df_all['name'] == 'not said', 'unknown')\\n\\n# Display the final dataframe\\ndf_all.head()\",\"Display all columns to decide which ones I want\\npd.set_option('display.max_columns', None)\\n\\ndisplay(df_episodes.head(5))\\ndisplay(df_characters.head(5))\\ndisplay(df_locations.head(5))\\ndf_script.head(5)\",\"Filter out bad data\",\" Create an empty DataFrame to store the statistics of each character\\ndf_characters_statistics = pd.DataFrame(columns=['id', 'word_count'])\",\"Create a new dataframe with the episode title, character speaking, and spoken text.\",\"Prepare data for time-sliced analysis.\",\" Check if installation of spaCy worked\\n# Also needs the model \\\"en_core_web_sm\\\" to be installed\\nnlp = spacy.load('en_core_web_sm')\",\"Merge scripts with character information\\ndf_script_extended = pd.merge(df_script, df_characters, how='left', left_on='character_id', right_on='id')\\n\\n# Create a list with all unique episode titles\\nepisode_titles = df_episodes['title'].unique()\\n\\n# Create a dictionary with episode transcripts\\nepisode_transcripts = {title: df_script[df_script['episode_id'] == id_]['normalized_text'].str.cat(sep=' ') \\n                       for title, id_ in zip(episode_titles, df_episodes['id'])}\",\"Displaying one of the datasets to observe its structure\\ndf_script.head()\",\"Filter script lines to eliminate bad data\",\" Look at data format, read a few lines\",\"Adds a few useful columns to df_script, such as \\\"spoken_words_count\\\", \\\"character_name\\\".\",\" Keep only the lines that contain any number of characters greater than 0\\ndf_script = df_script[df_script['normalized_text'].str.len() \\u003e 0]\",\"Process the script to get the characters and locations that appear in each episode\",\"We will quickly have a look at the data to figure how we can proceed further.\",\"Check the size of each dataset\\nprint(df_characters.shape)\\nprint(df_locations.shape)\\nprint(df_script.shape)\\nprint(df_episodes.shape)\",\"Check if GPU is available\\n# torch.cuda.is_available()\",\" Optionally set explore_mode to retrieve smaller random sample instead\\nexplore_mode = False\",\"#Limiting characters and locations data to what is available in the script\\nvalid_characters = df_script.character_id.unique()\\ndf_characters = df_characters[df_characters.character_id.isin(valid_characters)]\\nvalid_locations = df_script.location_id.unique()\\ndf_locations = df_locations[df_locations.location_id.isin(valid_locations)]\",\"Create a directory to save the wordclouds if it does not exist\\nwordcloud_dir = 'wordclouds'\\nif not os.path.exists(wordcloud_dir):\\n    os.makedirs(wordcloud_dir)\",\"Display the first 5 rows of each dataframe\\ndfs = [df_characters, df_locations, df_script, df_episodes]\\nfor df in dfs:\\n    display(df.head())\",\"Filter only script line from the simpsons script file and get the character who says it, the episode id it is in and the text\",\"Display dataframes' shape and head\\ndf_characters.shape, df_locations.shape, df_script.shape, df_episodes.shape\",\"Check first lines of the dataframes\\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()\",\"# Convert raw text into word frequency representation\\ndef word_frequency(text):\\n    words = [word.text.lower() for word in nlp(text) if word.is_alpha and not word.is_stop]\\n    word_freq = Counter(words)\\n    return word_freq\",\"General properties\\nprint(f\\\"Number of unique characters: {df_characters.shape[0]}\\\")\\nprint(f\\\"Number of unique locations:  {df_locations.shape[0]}\\\")\\nprint(f\\\"Number of episodes:           {df_episodes.shape[0]}\\\")\",\"Define some constants to make the scripts easier to read\\nMIN_LINES = 50\\nMIN_DIALOG_LEN = 4\",\"Set the date for the simpson_episodes dataframe\",\"Display the data\\ndf_characters.head()\",\"\\n# Fix some inconsistencies in the script dataset\\n# Filter the data to remove unwanted records\\n# Generate new features\",\"# Display how many unique characters and locations there are in The Simpsons\\nprint(f\\\"Number of unique characters: {df_characters.shape[0]}\\\")\\nprint(f\\\"Number of unique locations: {df_locations.shape[0]}\\\")\",\"Filter US only characters\",\" Split each line into words and stem each word\\nscript_stemmed = [nlp(line) for line in tqdm(df_script['raw_text'])]\",\"erequisites for spacy's language model\\nnlp = spacy.load('en_core_web_sm')\\n\\n# Since spacy's language model does not recognize simpsons words, we need to add simpsons vocabulary\\nsimpsons_vocab = [\\n    \\\"simpson\\\", \\\"hommer\\\", \\\"homer\\\", \\\"marge\\\", \\\"bart\\\", \\\"lisa\\\", \\\"magie\\\", \\\"krusty\\\", \\\"milhouse\\\", \\\"moe\\\",\\n    \\\"burns\\\", \\\"skinner\\\", \\\"ned\\\", \\\"flanders\\\", \\\"apu\\\", \\\"barney\\\", \\\"lenny\\\", \\\"carl\\\", \\\"duff\\\", \\\"kang\\\", \\\"kodos\\\",\\n    \\\"fat\\\", \\\"tony\\\", \\\"snake\\\", \\\"gil\\\", \\\"willie\\\", \\\"abe\\\", \\\"ralph\\\", \\\"jasper\\\", \\\"patty\\\", \\\"selma\\\", \\\"duffman\\\", \\\"troy\\\", \\n    \\\"lionel\\\", \\\"hutz\\\", \\\"gil\\\",\\n]\",\"We'll filter only the lines from Lisa.\",\"Drop useless columns that contain only NaN.\\ndf_episodes = df_episodes.dropna(axis=1, how='all')\",\"Set script data types explicitly\",\"Checking shapes of dataframes\",\"Using driver function to parse the datasets for us\\ndf_tuples = (\\\"Characters\\\", df_characters), (\\\"Locations\\\", df_locations), (\\\"Script\\\", df_script), (\\\"Episodes\\\", df_episodes)\\nfor name, df in df_tuples:\\n    print(name)\\n    print(df.head())\\n    print('\\\\n')\",\"Filter episodes\\ndf_episodes_filtered = df_episodes[(df_episodes['original_air_year'] \\u003e 1989) & (df_episodes['original_air_year'] \\u003c 2000)]\",\"Fix line_break and initial spaces at the beginning and end of spoken words\",\"Filtering the script dataset to only keep the lines spoken by the main characters\",\" Filter the script to keep only the dialogue lines\",\"Function to remove irrelevant script information\",\" Character's names written in other languages to ignore\\nsimps_char_names_ignore = ['Eliza Simpson', 'Spanish Homer', 'Harv Bannister', 'Grady Little', 'Roger Meyers', 'Lil\\\\' Hitler', 'Sylvester Stallone\\\\'s head', 'Mahatma Gandhi', 'Leon Kompowsky', 'Frankie the Squealer', 'English judge']\",\"### Data exploration and cleaning\",\"Check the shape and sample of the dataset\\ndf_script.shape\",\" Check the shape of the imported data\\nprint('Number of characters:', df_characters.shape[0])\\nprint('Number of locations:', df_locations.shape[0])\\nprint('Number of script lines:', df_script.shape[0])\\nprint('Number of episodes:', df_episodes.shape[0])\",\"Inspecting the first 5 rows of the df_script dataframe\",\"Apply some fixes to the dataset and clean the text for further analyisis\",\"Selecting all the lines spoken by Homer Simpson and the name of the episode the lines belong to\",\"Replace nans in speaking line with empty string\\ndf_script['normalized_text'] = df_script['normalized_text'].fillna('')\",\"Inspect the contents of the characters dataframe for any obvious issues\\ndf_characters.head()\",\"Merge and print a sample of the data\",\"# Add episode number to the original dataframe\\ndf_script['episode'] = df_script.apply(lambda x: df_episodes[(df_episodes['original_air_year'] == x['year']) & \\n                                                             (df_episodes['season']==x['season'])]['number'].values[0] if len(df_episodes[(df_episodes['original_air_year'] == x['year']) & \\n                                                                                                                                    (df_episodes['season']==x['season'])]['number'].values) \\u003e 0 else -1, axis=1)\",\"display(df_characters.head())\\n#display(df_locations.head())\\n#display(df_script.head())\\n#display(df_episodes.head())\",\"Functions\\ndef get_top_n_words(corpus, n=None):\\n    vec = CountVectorizer(stop_words='english').fit(corpus)\\n    bag_of_words = vec.transform(corpus)\\n    sum_words = bag_of_words.sum(axis=0) \\n    words_freq = [(word, sum_words[0, idx]) for word, idx in     vec.vocabulary_.items()]\\n    words_freq =sorted(words_freq, key = lambda x: x[1], reverse=True)\\n    return words_freq[:n]\",\"Inspect information of each dataframe\\nprint('Characters dataframe')\\ndisplay(df_characters.info())\\ndisplay(df_characters.head())\",\"change this line if the script should be executed in Jupyter\\nsns.set()\",\"[\\\"added\\\", \\\"chapter\\\", \\\"overview\\\", \\\"front\\\"]\",\"Define some utility functions for cleaning text and counting occurences of entities in each field\",\"# Extract scripts by characters\\nlisa_lines = df_script[(df_script['normalized_name'] == 'lisa simpson') & (df_script['spoken_words'].notnull())]['spoken_words'].values\\nmarge_lines = df_script[(df_script['normalized_name'] == 'marge simpson') & (df_script['spoken_words'].notnull())]['spoken_words'].values\\nhomer_lines = df_script[(df_script['normalized_name'] == 'homer simpson') & (df_script['spoken_words'].notnull())]['spoken_words'].values\\nbart_lines = df_script[(df_script['normalized_name'] == 'bart simpson') & (df_script['spoken_words'].notnull())]['spoken_words'].values\",\"Print out the head of each dataframe to explore the data\\nprint(df_characters.head())\\nprint(df_locations.head())\\nprint(df_script.head())\\nprint(df_episodes.head())\",\" Merge script and episodes\\ndf_script_episodes = pd.merge(df_script, df_episodes, how='left', on='episode_id')\\n\\n# Clean\\ndf_script_episodes_clean = df_script_episodes[\\n    (df_script_episodes.raw_location_text != '')\\n    & (df_script_episodes.raw_character_text != '')\\n    & (df_script_episodes.spoken_words != '')\\n].copy()\",\"Let's display the first few lines of each dataframe to see what they look like.\",\"iterate over character names that should be casted with actors.\",\"Let's check the size of the datasets\",\"# Define the evaluating function\\ndef evaluate_representation(text_data, representation):\\n    \\\"\\\"\\\"\\n    Args:\\n        text_data (string, pd.Series): The input text data\\n        representation (spacy.tokens.doc.Doc): The representation we want to compare with the data\\n    Returns:\\n        pandas.core.series.Series: The similarity score for each data point\\n    \\\"\\\"\\\"\\n    return text_data.apply(lambda x: representation.similarity(nlp(str(x))))\",\"Import the data and show the first 5 rows\",\"# Helper class to create a dataset\\nclass Dataset:\\n    script_columns = ['id', 'episode_id', 'number', 'raw_text', 'timestamp_in_ms',\\n                      'speaking_line', 'character_id', 'location_id', 'raw_character_text',\\n                      'raw_location_text', 'spoken_words', 'normalized_text', 'word_count']\\n\\n    character_columns = ['id', 'name', 'normalized_name', 'gender']\\n\\n    location_columns = ['id', 'name', 'normalized_name']\\n\\n    episode_columns = ['id', 'title', 'original_air_date', 'production_code',\\n                       'season', 'number_in_season', 'number_in_series',\\n                       'us_viewers_in_millions', 'views', 'imdb_rating', 'imdb_votes']\\n\\n    def __init__(self, episodes_df, characters_df, locations_df, script_df):\\n        self.episodes_df = episodes_df\\n        self.characters_df = characters_df\\n        self.locations_df = locations_df\\n        self.script_df = script_df\\n        self.script_df['normalized_text'] = self.script_df.normalized_text.astype(str)\",\"Set random seed\\nnp.random.seed(0)\",\"Look at the first rows of the characters dataset\\nprint(df_characters.head())\",\"Constants\\navg_sentence_len = 100  # each element is smaller than average sentence length, i.e is smaller than 100\",\"Add encoding argument to read_csv calls to fix UnicodeDecodeError\",\"Tokenize the script lines to run some analysis on it\\nnlp = spacy.load(\\\"en_core_web_sm\\\")\",\" Check dimensions of the datasets\\nprint(\\\"Characters: \\\", df_characters.shape)\\nprint(\\\"Locations: \\\", df_locations.shape)\\nprint(\\\"Script: \\\", df_script.shape)\\nprint(\\\"Episodes: \\\", df_episodes.shape)\",\"# Count the number of lines spoken by each character\\nlines_per_character = df_script['character_id'].value_counts()\\n\\n# Count the number of locations where each character appears\\nlocations_per_character = df_script.drop_duplicates(subset=['location_id', 'character_id'])['character_id'].value_counts()\",\"Filter out the 'simpsons_script_lines' and keep only the spoken lines\",\"Inspect the first 5 rows of each dataframe to understand its structure and data.\",\"function to tokenize a script line and remove stopwords\",\" We can see some simple statistics, as well as the top 10 first tokens.\",\"Check if GPU is there and the available RAM\",\"Add custom named entities to spaCy\\nnlp = spacy.load('en_core_web_sm')\\n\\n# Function to add custom named entities to spaCy\\ndef add_custom_named_entities(nlp, labeled_data):\\n    for entry in labeled_data:\\n        for token in entry[0].split(' '):\\n            nlp.tokenizer.add_special_case(token, [{'ORTH': token}])\\n    return nlp\",\"Visualizamos la primeras lineas de cada dataframe\",\"Iterate through all including folders and files\",\"Start by using the describe method to get a sense of the statistics for each variable.\",\"Find the main characters for each episode\",\"# Smaller dataset with male and female\\ndf_script_small = df_script[(df_script['gender'] == 'm') | (df_script['gender'] == 'f')]\\ndf_script_small = df_script_small.sample(10000, random_state=42)\\n\\n# \\\"\\\"\\\"\\\"\\\"\\\"\\\"\\\"\\\"\\\"\\\"\\\"\\\"\\\"\\\"\\\"\\\"\\\"\\\"\\\"\\\"\\\"\\\"\\\"\\\"\\\"\\\"\\\"\\\"\\\"\\\"\\\"\\\"\\\"\\\"\\\"\\\"\\\"\\\"\\\"\\\"\\\"\\\"\\\"\\\"\\\"\\\"\\\"\\\"\\\"\\\"\\\"\\\"\\\"\\\"\\\"\\\"\\\"\\\"\\\"\\\"\\\"\\\"\\\"\\\"\\\"\\\"\\\"\\\"\\\"\\\"\\\"\\\"\\\"\\\"\\\"\\\"\\\"\\\"\\\"\\\"\\\"\\\"\\\"\\\"\\\"\\\"\\\"\\\"\\\"\\\"\\\"\\\"\\\"\\\"\\\"\\n# \\\"\\\"\\\"\\\"\\\"\\\"\\\"\\\"\\\"\\\"\\\"\\\"\\\"\\\"\\\"\\\"\\\"\\\"\\\"\\\"\\\"\\\"\\\"\\\"\\\"\\\"\\\"\\\"\\\"\\\"\\\"\\\"\\\"\\\"\\\"\\\"\\\"\\\"\\\"\\\"\\\"\\\"\\\"\\\"\\\"\\\"\\\"\\\"\\\"\\\"\\\"\\\"\\\"\\\"\\\"\\\"\\\"\\\"\\\"\\\"\\\"\\\"\\\"\\\"\\\"\\\"\\\"\\\"\\\"\\\"\\\"\\\"\\\"\\\"\\\"\\\"\\\"\\\"\\\"\\\"\\\"\\\"\\\"\\\"\\\"\\\"\\\"\\\"\\\"\\\"\\\"\\\"\\\"\\\"\\\"\\\"\\n# Get word counter for each character\\n\",\" Define constant colors\\ncolors = {\\n    'red': '#FF5733',\\n    'light red': '#FF8566',\\n    'green': '#59955C',\\n    'blue': '#3559FF',\\n    'yellow': '#E5CC00',\\n    'light yellow': '#FFEB4D',\\n    'secondary blue': '#33CCFF',\\n    'purple': '#A239CA',\\n    'orange': '#FF8C1A',\\n    'black': '#1A1A1A',\\n    'dark grey': '#333333',\\n    'grey': '#808080',\\n    'light grey': '#B3B3B3',\\n    'white': '#FFFFFF'\\n}\",\"Opt into using `resume_parser_ner_wiki_large` when using `spacy.load` as this one has the NER model loaded\",\" Sample data\\ndf_script.head(), df_locations.head()\",\" Merge Echo and Hero columns in case they contain complementary information\",\"Transforming the script dataframe to include more useful information\\ndf_script['episode_id'] = df_script.apply(lambda row: int(row['raw_text'].split('\\\\t')[1]), axis=1)\\ndf_script['character'] = df_script.apply(lambda row: row['raw_text'].split('\\\\t')[2] if len(row['raw_text'].split('\\\\t')) \\u003e 2 else '', axis=1)\\ndf_script['text'] = df_script.apply(lambda row: row['raw_text'].split('\\\\t')[-1], axis=1)\\ndf_script = df_script.merge(df_episodes[['id', 'season', 'number', 'air_date', 'title']], how='left', left_on='episode_id', right_on='id')\",\"Detect entities and sentiment from the script using SpaCy.\",\"#number of script lines\\nlen(df_script)\",\"Set randon seed for reproducibility\\nnp.random.seed(0)\",\" Tokenize the script lines for later use\",\" Validate the import of the dataframes\\ndisplay(df_characters.head(2))\\ndisplay(df_locations.head(2))\\ndisplay(df_script.head(2))\\ndisplay(df_episodes.head(2))\",\" Split lines into a list\",\"Print the head of the dataframe to get an overview of the data\\nprint(df_script.head())\",\"Merge script with characters and keep only necessary columns\\ndf_lines = df_script.merge(df_characters, left_on='character_id', right_on='id', suffixes=('', '_char'))\\ndf_lines = df_lines[['id', 'season', 'episode_id', 'number', 'raw_text', 'name']]\\n\\n# \",\" Display a preview of each Data Frame\\nprint('Characters Data Frame:')\\nprint(df_characters.head())\\nprint('\\\\nLocations Data Frame:')\\nprint(df_locations.head())\\nprint('\\\\nScript Data Frame:')\\nprint(df_script.head())\\nprint('\\\\nEpisodes Data Frame:')\\nprint(df_episodes.head())\",\" Set up spacy\\nnlp = spacy.load('en_core_web_sm', disable=['parser', 'tagger', 'ner'])\\n\\n# Setup pandas\\npd.set_option('display.max_columns', None)\",\" Supprimer les script_lines qui ne sont pas dans simpsons_episodes\",\" Merge the necessary columns\",\"Visualize the characters dataset\\ndf_characters.head()\",\"Sample the script dataframe\",\" Display a preview of each dataframe\\nprint('Characters:')\\ndisplay(df_characters.head())\\nprint('\\\\nLocations:')\\ndisplay(df_locations.head())\\nprint('\\\\nScript:')\\ndisplay(df_script.head())\\nprint('\\\\nEpisodes:')\\ndisplay(df_episodes.head())\",\"Printing the first five rows of each dataframe\\nprint(df_characters.head())\\nprint(df_locations.head())\\nprint(df_script.head())\\nprint(df_episodes.head())\",\"\\nscripts = df_script[['normalized_text']].copy()\",\"Print number of characters and number of lines in the script\\nprint(df_characters.shape[0])\\nprint(df_script.shape[0])\",\"\\n# Define helper functions and objects\\nnlp = spacy.load('en_core_web_sm')\",\"Let's see the first few rows of each dataframe to understand the data better.\",\"Example of finished data loading and basic data information\",\"Let's start by examining the contents of each of the datasets.\",\"Checking data types and exploring missing values\\nprint(df_script.info())\",\"# Do some data exploration to get a feel for the data\\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()\",\"Memory usage of each DataFrame\\nprint(\\\"Memory usage of each DataFrame\\\")\\nprint(df_characters.info(memory_usage='deep'))\\nprint(df_locations.info(memory_usage='deep'))\\nprint(df_script.info(memory_usage='deep'))\\nprint(df_episodes.info(memory_usage='deep'))\",\"# Let's check if the data has been correctly loaded\\nprint('Characters:', df_characters.shape)\\nprint('Locations:', df_locations.shape)\\nprint('Scripts:', df_script.shape)\\nprint('Episodes:', df_episodes.shape)\",\"Declare the plot style and color palette\",\" Display heads of all files to understand the data\",\"Check the contents of the characters dataset\\nprint('Number of characters:', len(df_characters))\\ndf_characters.head()\",\"Visualize the dataframe scripts using a treemap\",\"Let make sure we join the datasets correctly:\",\"Check the dataframes' dimensions\",\"Visual (Bar) representation of the split between female and male characters in the Simpsons\",\" Enable the TQDM notebook extension in order to display a progress bar for data processing tasks\\ntqdm.pandas()\",\"Display script lines dataset\\ndf_script.head()\",\"Check if the dataframe creation is successful\\ndf_characters\",\"Verify that the datasets have been loaded correctly\\nprint(df_characters.head())\\nprint(df_locations.head())\\nprint(df_script.head())\\nprint(df_episodes.head())\",\"Check the contents of the characters table\\ndf_characters.head()\",\"Display top 5 rows of each dataset to understand the data\",\"Change directory to the correct path\\nos.chdir('.\\u002fsimpsons_dataset\\u002f')\",\" Now, we can take a look at the content of each dataset.\",\"Get the main characters from the script\\nmain_characters = df_characters[df_characters['is_main_character'] == True]\\nmain_characters_names = list(main_characters['name'].values)\",\"Create columns to easily identify character and location speaking or spoken about\",\"Create 'simpsons_corpus' and store path to Markovify chain JSON file\\nsimpsons_corp_path = 'data\\u002fsimpsons_corpus.json'\",\"Split the data into training and test sets\",\" Let's begin by taking a closer look at the data.\",\"How many unique characters are there in the dataset?\\ndf_script['character_id'].nunique()\",\"View data head\\ndf_script.head()\",\"Estimate size of each data frame\\ndf_sizes = {'characters': df_characters.memory_usage().sum(),\\n            'locations': df_locations.memory_usage().sum(),\\n            'script': df_script.memory_usage().sum(),\\n            'episodes': df_episodes.memory_usage().sum()}\\ndf_sizes\",\"Print the head of each dataset to understand what kind of data we are working with.\",\" Display top 10 rows of each dataframe\\nprint('Characters\\\\n')\\nprint(df_characters.head(), '\\\\n\\\\n')\\n\\nprint('Locations\\\\n')\\nprint(df_locations.head(), '\\\\n\\\\n')\\n\\nprint('Script\\\\n')\\nprint(df_script.head(), '\\\\n\\\\n')\\n\\nprint('Episodes\\\\n')\\nprint(df_episodes.head())\",\"Extract the main characters\\nmain_characters = [\\n    'marge', 'homer', 'bart', 'lisa', 'maggie', \\n    'milhouse', 'krusty', 'burns', 'smithers', 'moe', \\n    'ned', 'apu', 'barney', 'skinner', 'ralph', 'kent', \\n    'gary', 'carl', 'lenny', 'chief', 'edna', 'selma', 'patty', \\n    'maggie', 'todd', 'marty', 'rod', 'troy', 'lionel', 'patty'\\n]\\n\\n# Load the spaCy model\\nnlp = spacy.load('en_core_web_sm')\",\" Enable f-strings in Python 2.7\\nfrom future.builtins import (bytes, str, open, super, range,\\n                           zip, round, input, int, pow, object)\",\" Load the spacy model for preprocessing the text.\",\"Explore the contents of the dataset\\nprint(df_characters.head())\\nprint(df_locations.head())\\nprint(df_script.head())\\nprint(df_episodes.head())\",\"We can remove some entries from df_characters that do not contribute to our analysis.\",\"check loaded csvs\\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()\",\"Filter the data to the characters of interest.\",\"Extract the characters only from the first 1000 episodes\\ncharacter_names = df_characters[0]['detect_name']\\ndf_episodes_top_1000 = df_script[df_script['episode_id'] \\u003c= 1000]\\nscript_characters = df_episodes_top_1000['character_id'].unique()\\nscript_df_characters = pd.DataFrame(script_characters, columns=['character_id'])\",\"Set dataset type and name\\ndf_characters.name = 'characters'\\ndf_locations.name = 'locations'\\ndf_script.name = 'script'\\ndf_episodes.name = 'episodes'\",\"Merge data and visualize the counts of character mentions in the script data\\ndf_script = df_script.merge(df_episodes, on='episode_id', how='left')\\ndf_script = df_script.merge(df_characters, on='character_id', how='left')\\nchar_mention_cnts = df_script['name'].value_counts()\\n\\nplt.bar(char_mention_cnts.index, char_mention_cnts.values)\\nplt.xlabel('Character Name')\\nplt.ylabel('Number of Mentions')\\nplt.title('Number of Mentions of Each Character in the Script')\\nplt.xticks(rotation=90)\\nplt.show()\",\"Drop unnecessary columns from characters dataframe\\ndf_characters = df_characters.drop(columns=['Unnamed: 0'])\",\"Remove rows with empty lines and strip white spaces from any columns containing strings\\nfor df in [df_characters, df_locations, df_script, df_episodes]:\\n    starting_shape = df.shape\\n    for col in df.columns:\\n        if df[col].dtype == object:  # dtype 'object' means it's a string\\n            df[col] = df[col].str.strip()  # Remove leading\\u002ftrailing white spaces\\n            df = df[df[col].notna()]  # Remove rows with empty strings\\n    print(f\\\"Before removal - {df} shape: {starting_shape}, after removal: {df.shape}\\\")\",\"Explore the data - Have a look at the five first rows\",\" Set the seed for numpy random number generator for reproducibility\\nnp.random.seed(5)\",\"View first 5 rows of the characters dataframe\\ndf_characters.head()\",\"Set custom color palette\\ncolors = ['#FF8C00', '#FF4500', '#FF0000', '#DC143C', '#B22222', '#8B0000', '#FFA07A', '#FA8072', '#E9967A', '#F08080', '#CD5C5C', '#DC143C']\",\"Print the shapes of the datasets\\nprint(df_characters.shape)\\nprint(df_locations.shape)\\nprint(df_script.shape)\\nprint(df_episodes.shape)\",\"Limiting script to the first character's line\",\"\\n# Method to remove Special characters, URLs, and mentions\\n\",\"Inspect each dataframe using the .info() and .head() methods to understand the data\",\"Check for missing data\\ndf_characters.info()\",\" optional: inspect the datasets\\ndf_characters.head()\",\"Check if we're in the correct folder\",\"Set random seed for reproducibility\\nnp.random.seed(0)\",\"Simple view of the datasets\",\"# Convert speaker_id from string to int to match id in characters\\ndf_script['character_id'] = pd.to_numeric(df_script['character_id'], errors='coerce').fillna(0).astype(int)\",\"Let's first take a look at how the data looks like.\",\"# Display first 5 rows of each dataframe to verify data has been loaded correctly\\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()\",\"Apply the long version to the script dataframe\",\"Ensure target folders for visualization exist in the filesystem\",\"Select only the title, original_air_date, and us_viewers_in_millions columns from df_episodes.\",\"Add a column for the number of words in each script line\",\"We have successfully imported the necessary libraries and data.\",\"Column `episode_id` and `id` are common between `df_episodes` and `df_script`\",\"Inspect the first few rows of each dataframe to understand its structure and the kind of data we have\",\"Merge episodes and script datasets based on the episode id\",\"Explore the first lines of the characters dataset\\ndf_characters.head()\",\"Display the shape of each dataframe to understand the dataset.\",\"Remove duplicates in the datasets\",\"Remove rows where the `ding_count` column is greater than 0\",\" Select only script lines in English\\ndf_script_en = df_script[df_script['raw_text'].str.startswith('- ')]\",\"Let's take a glance at what's inside each DataFrame by displaying the first few rows.\",\"Display maximum columns and rows in dataframes\\npd.set_option('display.max_columns', None)\\npd.set_option('display.max_rows', None)\",\"Take a look at the first 5 rows of df_characters.\\ndf_characters.head()\",\"Initial data overview\",\"Ignore data necessary for testing during production\\ndf_script = df_script[df_script[\\\"episode_id\\\"].isin(df_episodes[df_episodes[\\\"production_code\\\"] != \\\"\\\"].index)]\\ndf_script = df_script[df_script[\\\"character_id\\\"].isin(df_characters[df_characters[\\\"name\\\"] != \\\"\\\"].index)]\\ndf_script = df_script[df_script[\\\"location_id\\\"].isin(df_locations[df_locations[\\\"name\\\"] != \\\"\\\"].index)]\",\"Properties of the dataset\\nprint(f\\\"Number of characters: {df_characters.shape[0]}\\\")\\nprint(df_characters.head())\",\"Exploring the structure of our data.\",\"Remove bad data in script, episodes and characters\\ndf_characters = df_characters[(df_characters['name'] != '?') & (df_characters['normalized_name'] != '')].reset_index(inplace=False, drop=True)\\ndf_locations = df_locations[(df_locations['name'] != '?') & (df_locations['normalized_name'] != '')].reset_index(inplace=False, drop=True)\\ndf_episodes = df_episodes[(df_episodes['title'] != '?')].reset_index(inplace=False, drop=True)\\ndf_script = df_script[df_script['character_id'].isin(df_characters['id'])]\\ndf_script = df_script[df_script['location_id'].isin(df_locations['id'])]\\ndf_script = df_script[df_script['episode_id'].isin(df_episodes['id'])]\",\"# Checking whether the df_characters dataframe has been loaded correctly\\ndf_characters.head()\",\"\\n# Join the main table with the character and location information\\ndf = df_script.merge(df_characters, on='character_id', how='left')\\ndf = df.merge(df_locations, on='location_id', how='left')\\n\\n# Remove script lines with no spoken words and associate them to a given episode\\ndf = df[~df.raw_text.isna()]\\ndf = df.merge(df_episodes, on='episode_id', how='left')\",\"Explore the first 5 rows of each of the DataFrames to understand the structure of the data.\",\"Select the main characters and the locations, which are those that have more than 500 lines spoken.\",\"Check the data format for each dataframe\\nprint(df_characters.dtypes)\\nprint(df_locations.dtypes)\\nprint(df_script.dtypes)\\nprint(df_episodes.dtypes)\",\"Define feature engineering pipeline using Transformers\\nfrom sklearn.base import BaseEstimator, TransformerMixin\\n\\nclass BasicProcessing(BaseEstimator, TransformerMixin):\\n    def fit(self, X, y=None):\\n        return self\\n\\n    def transform(self, X, y=None):\\n        X['usertagvalue'] = X['url'].apply(lambda x: x.split(':')[1] if isinstance(x, str) else '')\\n        X['UUID'] = X['usertagvalue'].apply(lambda x: x.split('\\u002f')[0] if isinstance(x, str) else '')\\n        return X\",\" Use tqdm to visualize progression of pandas apply\\ntqdm.pandas()\",\"In order for this code to run, make sure you have the necessary data files in the specified paths or change the paths to match the location of the data files on your system.\",\"The dataset contains the following tables:\",\"Setting a dataframe as global will make it available in the entire script.\",\"Drop rows where gender data is incorrect (1 row) and duplicate index column\",\"In the dataset, the following fields are available:\\n# - Characters\\n# -- id: character id\\n# -- name: character name\\n# -- normalized_name: normalized character name\\n# -- gender: character gender\\n# -- normalized_gender: normalized character gender\\n# -- number_of_dialogues: number of dialogues the character has\\n# -- first_appearance: character's first appearance in the series\\n# -- id: location id\\n# -- name: location name\\n# -- normalized_name: normalized location name\\n# -- frequency: frequency of the location\\n# - Script Lines\\n# -- id: script line id\\n# -- episode_id: episode id\\n# -- number: line number in the episode\\n# -- raw_text: raw text of the line\\n# -- timestamp_in_ms: timestamp of the line\\n# -- speaking_line: a boolean that indicates whether a character speaks the line\\n# -- character_id: character id\\n# -- location_id: location id\\n# -- normalized_text: normalized line text\\n# -- word_count: word count of the line text\\n# - Episodes\\n# -- id: episode id\\n# -- title: episode title\\n# -- original_air_date: original air date of the episode\\n# -- production_code: production code of the episode\\n# -- season: season in which the episode is\\n# -- number_in_season: episode number in the season\\n# -- number_in_series: episode number in the series\\n# -- us_viewers_in_millions: number of US viewers, in millions, when the episode aired\\n# -- views: number of views, in thousands\\n# -- imdb_rating: imdb rating of the episode\\n# -- imdb_votes: number of imdb votes for the episode\\n# -- image_url: image url of the episode\",\"Read embeddings created by glove-python\\ndf_embeddings = pd.read_csv('data\\u002fword_embeddings.csv')\",\"Display the first few lines of each dataframe to get an idea of its structure\\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()\",\" Display the first few rows of each dataframe to get an idea of what the data looks like\\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()\",\"merge the script and episodes into a single dataframe\",\"Check if the script contains lines of dialog_physically painful\",\"Displaying dataset samples\\ndf_script.sample(10)\",\"Add newline character in the end\",\"# Show head of characters data\\ndf_characters.head()\",\"# Definition of preprocessing function to remove time from the dialogue\\ndef remove_scene_description(text):\\n    return text.split(':')[-1]\",\"Filter non-ascii characters to avoid encoding issues\\ndf_script = df_script[df_script['raw_character_text'].apply(lambda x: x.isascii())]\\ndf_script = df_script[df_script['raw_location_text'].apply(lambda x: x.isascii())]\",\"Check for corrupted data\\ndf_script.info()\",\"# For this notebook, we are going to look at the script DataFrame\\ndf_script.head()\",\"View first 5 rows of the characters dataframe\\ndf_characters.head()\",\" Define the character models to use for NER (Named Entity Recognition)\",\"Combien y a-t-il de personnages dans la table `df_characters` ?\",\"Creating a virtual environment\",\"Extract the training and test set\",\"Make a copy of each dataframe\",\"Visualize the number of episodes per season\\ndf_episodes['season'].value_counts().sort_index().plot(kind='bar', figsize=(15, 10), color='skyblue')\",\"Compute total number of words spoken by each character\\ndf_characters_spoken_words = df_script.groupby('character_id')['spoken_words'].sum()\\ndf_characters_spoken_words.sort_values(ascending=False, inplace=True)\",\" GloVe word vectors\\n!pip install -U gensim\\n\\nimport gensim.downloader as api\\n\\nword_vectors = api.load(\\\"glove-wiki-gigaword-100\\\")\",\"Filter out incomplete script lines and join the tables\",\"Checking if all the DataFrames have been loaded successfully\\nprint(f'Simpsons Characters: {df_characters.shape}')\\nprint(f'Simpsons Locations: {df_locations.shape}')\\nprint(f'Simpsons Script: {df_script.shape}')\\nprint(f'Simpsons Episodes: {df_episodes.shape}')\",\"Fix character names (for joins)\",\"Let's start by checking the first rows of each dataset to become familiar with the data.\",\"Lowercase the name fields for better linking\",\"Filter df_characters, df_locations and df_script to the main characters and locations\",\" It's important to reset the index after reading the dataframes.\",\"# Joining dataframes\\ndf_episodes['id'] = df_episodes['id'].astype(int)\\ndf_script['episode_id'] = df_script['episode_id'].astype(int)\\n\\ndf = pd.merge(df_script, df_episodes, left_on='episode_id', right_on='id', suffixes=('_script', '_episodes'))\\ndf = df[['id_script', 'episode_id', 'number', 'raw_text', 'timestamp_in_seconds',\\n         'id_episodes', 'title', 'original_air_date', 'production_code', 'season', 'number_in_season',\\n         'number_in_series', 'us_viewers_in_millions', 'views', 'imdb_rating', 'imdb_votes']]\",\"Split the script into Story and coaching content.\",\"Inspect the dataframes for any necessary cleaning or preprocessing.\",\"Join datasets\",\" Load model from spacy\\nnlp = spacy.load('en_core_web_sm')\\n\\n# Spacy pipeline\\nnlp.add_pipe('sentencizer')\",\"\\n# Create dictionary to map locations to characters\\nlocation_to_characters = {\\n    location: set(df_script[df_script['raw_location_text'] == location]['raw_character_text'])\\n    for location in df_script['raw_location_text'].unique()\\n}\",\"Check what kind of data we have for characters, locations, scripts, and episodes\\nprint('Characters')\\nprint(df_characters.head(), end='\\\\n\\\\n')\\n\\nprint('Locations')\\nprint(df_locations.head(), end='\\\\n\\\\n')\\n\\nprint('Script')\\nprint(df_script.head(), end='\\\\n\\\\n')\\n\\nprint('Episodes')\\nprint(df_episodes.head(), end='\\\\n\\\\n')\",\" Show All Data for df_characters\\nwith pd.option_context('display.max_rows', None, 'display.max_columns', None):\\n    display(df_characters.head(5))\",\" Remove characters and locations not mentioned in script\\nmentioned_chars = df_script_raw.name.str.lower().unique()\\nmentioned_locs = df_script_raw.raw_location_text.str.lower().unique()\\n\\ndf_characters = df_characters[df_characters.normalized_name.str.lower().isin(mentioned_chars)]\\ndf_locations = df_locations[df_locations.normalized_name.str.lower().isin(mentioned_locs)]\",\"Check the first 5 lines of each dataframe\",\" Remove all mode of address and suffixes from aggregation.\",\" Check datatypes and null values\\ndf_script.info()\",\"Remove rows with null characters ID\\ndf_script = df_script[df_script['character_id'].notnull()]\",\"Look at the first 5 rows of each dataframe.\",\"pre-processing\\n# Parse JSON columns in script and characters DataFrames\\ndf_characters_gr = pd.DataFrame(list(df_characters['character'].apply(json.loads)))\\ndf_locations_gr = pd.DataFrame(list(df_locations['location_text'].apply(json.loads))\\ndf_script_td = pd.merge(df_script, df_episodes, left_on='episode_id', right_on='id')\\n\\n# Override the 'name' error from 'name' column from script DataFrame\\ndf_script_td[\\\"name\\\"]= df_script_td[\\\"name\\\"].fillna(df_script_td[\\\"normalized_text\\\"])\\ndf_script_td.drop(columns='normalized_text' , inplace=True)\",\" Take a peek at the df_characters dataframe\\ndf_characters.head()\",\" Add decade to episodes dataframe\\ndf_episodes['decade_id'] = np.floor(df_episodes['original_air_year'] \\u002f 10) * 10\",\"# Quick look at the characters dataframe\\nprint(df_characters.head())\",\"Load initial versions of datasets and reset index to ensure correct functionality\",\"Check the first few rows of each dataframe\\ndf_script.head(), df_characters.head(), df_locations.head(), df_episodes.head()\",\"This dataset is designed for educational approaches, by no means do I own this data nor am Iancer at Fox.\",\"Add some useful features as additional columns to the script DataFrame\",\"Merge location metadata into script dataframe\\ndf_script = df_script.merge(\\n    df_episodes.loc[:, ['id', 'title', 'original_air_date', 'production_code', 'season', 'number_in_season']].add_prefix('episode_'),\\n    left_on='episode_id',\\n    right_on='episode_id'\\n)\",\"Visualize the dataframe(s)\",\"Display the word cloud for the top 25 characters.\",\" Check the number of different characters and locations\",\"Join dataframes on the character, location, episode and season fields, and reset index\",\"# Let's display some basic information from the dataset to get a better\\n# understanding of the data. Let's start with all the datasets in general.\",\"Let's check out the structure of the data.\",\"Count the number of words spoken by each character\\ndf_character_word_count = df_script.groupby('character_id')['word_count'].sum().reset_index()\\n\\n# Merge with characters and limit the top 20\\ndf_character_word_count = (pd\\n    .merge(df_characters, df_character_word_count, how='inner', left_on='id', right_on='character_id')\\n    .sort_values('word_count', ascending=False)\\n    .head(20))\\n\\n# Plot\\nfig, ax = plt.subplots(figsize=(10,8))\\nplt.barh(np.arange(len(df_character_word_count)), df_character_word_count['word_count'])\\nplt.yticks(np.arange(len(df_character_word_count)), df_character_word_count['name'], rotation=0, ha='right')\\nplt.xlabel('Word count')\\nplt.title('Number of words spoken by character')\\nplt.gca().invert_yaxis()\",\"Print a few lines of each dataset to demonstrate what kind of data is included.\",\"Simple Preprocessing\\n# Make sure the text is indeed a string\\ndf_script['raw_text'] = df_script['raw_text'].astype(str)\\n\\n# Simple text cleaning\\ndf_script['raw_text'] = df_script['raw_text'].str.replace('\\\\n', ' ')  # Removing newlines\\ndf_script['raw_text'] = df_script['raw_text'].str.replace('\\\\r', ' ')  # Removing carriage returns\\ndf_script['raw_text'] = df_script['raw_text'].str.replace('\\\\t', ' ')  # Removing tabs\\n\\ndf_script['word_count'] = df_script['raw_text'].apply(lambda x: len(x.split(' ')))  # Getting word count\",\" Remove special characters from character names, locations, and script lines and episode titles.\",\"Check the loaded dataset\\nfor name, data in (\\n    ('Characters', df_characters), \\n    ('Locations', df_locations), \\n    ('Script lines', df_script), \\n    ('Episodes', df_episodes)\\n):\\n    print(f'{name}:')\\n    print(data.info())\\n    display(data.head())\\n    print('\\\\n\\\\n')\",\"We'll use a pre-trained NER model from spaCy to assign named entities to the text.\",\" to show the first few rows of the dataframe, which can be helpful in understanding the data.\",\"We will now take a look at the imported dataframes to understand their structure and contents.\",\"Explore the data and find an interesting question to answer\",\"Create columns scenes and text length, for each line in the script.\",\" Check if the following fields will have null values:\\n# 'character_id': always filled \\u002f integer\\n# 'episode_id': always filled \\u002f integer\\n# 'location_id': always filled \\u002f integer\\n# 'id': always filled \\u002f integer\\n# 'text': always filled \\u002f string\",\"Select main cast (based on how many sentences they have)\",\"Remove rows with missing values because the missing values might affect the analysis.\",\"Train a model for named entity recognition (NER) with spaCy.\",\"Inspect the structure of the datasets\\nprint(f'Characters: {len(df_characters)}')\\ndf_characters.head()\",\"check the data extracted from the characters dataset\\ndf_characters.head()\",\"Let's first inspect the first lines for each of these dataframes.\",\"Display all dataframes\\ndisplay(df_characters.head())\\ndisplay(df_locations.head())\\ndisplay(df_script.head())\\ndisplay(df_episodes.head())\",\"Set plot style\\nplt.style.use('fivethirtyeight')\",\" View the first rows of the characters dataframe\\ndf_characters.head()\",\"Set a default value for the number of elements.\",\" Limit the number of rows printed in the notebook\\npd.options.display.max_rows = 5\",\"Display some data to have an overview\\ndf_script.head()\",\"Load the script and episodes dataframe\\ndf_script_id = df_script.join(df_episodes, on='episode_id', rsuffix='_ep')\",\"Let's preview the datasets and look at some basic statistics.\",\" Look at the first 5 rows of each CSV file\",\" Print data examples\",\" Display the first 5 rows of each DataFrame to verify they were loaded correctly\\ndisplay(df_characters.head())\\ndisplay(df_locations.head())\",\"optional: set a threshold for script lines length to filter out the long script lines\\nthreshold = 500\",\" Extract all the sentences in the script and column to a list\\nsentences = df_script['raw_text'].tolist()\",\" Convert id columns to int to enable merges\",\" Visualize the columns of the dataset\\nprint(df_characters.columns.tolist())\",\"Data sets memory usage\\nprint('Character datatypes:')\\nprint(df_characters.dtypes)\\nprint(\\\"\\\")\\n\\nprint('Locations datatypes:')\\nprint(df_locations.dtypes)\\nprint(\\\"\\\")\\n\\nprint('Script datatypes:')\\nprint(df_script.dtypes)\\nprint(\\\"\\\")\\n\\nprint('Episodes datatypes:')\\nprint(df_episodes.dtypes)\",\" These dataframes contain self-contained data, including both raw and pre-processed data as well as metadata about the datasets.\",\"Create a pandas series based on the script list of speakers.\",\"Creating necessary folder structure for saving models and tokenizers\",\"Filtering the seasons that only consider episodes of the TV show, and not others.\",\"Building a word cloud for the entire Simpsons script\\nscript = \\\" \\\".join(df_script['raw_text'])\",\" Extract all locations\\nlocations = df_locations.loc[:,'normalized_text']\\nlocations = locations.dropna()\\n\\n# Extract all script lines\\nscript = df_script.loc[:,'normalized_text']\\nscript = script.dropna()\\n\\nscript.head()\",\"Only keep characters IDs that appear in df_characters\\ndf_script = df_script[df_script[\\\"character_id\\\"].isin(df_characters.character_id.unique())]\",\"Check the first few rows of the dataframe to understand its structure\\ndf_script.head()\",\"To get a feel for the data, let's take a look at the first few rows of each dataframe.\",\"Create \\\"simpsons_script_lines\\\" table from \\\"script_lines\\\" table\\ndf_script_new = df_script.join(df_episodes, on='episode_id', rsuffix='_ep')\\ndf_script_new = df_script_new.join(df_characters, on='character_id', rsuffix='_char')\\ndf_script_new = df_script_new.join(df_locations, on='location_id', rsuffix='_loc').drop(\\n                       ['episode_id', 'number', 'raw_text', 'timestamp_in_ms', 'speaking_line', 'character_id', \\n                        'location_id', 'raw_text', 'normalized_text', 'timestamp_in_ms', 'word_count', \\\"image_id\\\", \\n                        \\\"production_code\\\", \\\"original_air_date\\\", \\\"id\\\", \\\"video_url\\\", \\\"show_id\\\", \\\"imdb_title_id\\\", \\n                        \\\"imdb_id\\\" , \\\"script_id\\\", \\\"production_code\\\", \\\"image_id_char\\\", \\\"url_char\\\", \\\"filter\\\", \\\"license\\\", \\n                        \\\"image_id_loc\\\", \\\"url_loc\\\"], axis=1).reset_index(inplace=False, drop=True)\",\" Load custom NLP pipeline from disk\",\"We can now take a lookt at the head of each DataFrame to understand better their structure\",\"Display columns to have a sense of the data\",\" Select only the \\\"The Simpons\\\" TV show\\ndf_episodes_subset = df_episodes.query('original_air_date \\u003e \\\"1989-12-01\\\"').reset_index(inplace=False, drop=True)\",\"Preview the first 5 rows of each dataframe\\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()\",\"Set up environment for spaCy and Word Clouds\",\"Some small adjustments to the dataframes\\ndf_characters.drop(columns=['normalized_name'], inplace=True)\\ndf_characters = df_characters.dropna(subset=['name'])\\n\\ndf_locations = df_locations.dropna(subset=['normalized_name'])\\n\\ndf_episodes = df_episodes.dropna(subset=['title'])\\n\\ndf_script = df_script.dropna(subset=['raw_character_text', 'spoken_words'])\",\"Create a dataframe keeping only the line with their episode's data\",\"Setting current directory\\nos.chdir('SIMPSONS_DATASET\\u002f')\",\"Print the first 10 rows of each DataFrame to have a quick look at their structure.\\nprint('Characters:')\\nprint(df_characters.head(5))\\n\\nprint('\\\\nLocations:')\\nprint(df_locations.head(5))\\n\\nprint('\\\\nScript:')\\nprint(df_script.head(5))\\n\\nprint('\\\\nEpisodes:')\\nprint(df_episodes.head(5))\",\"Check what's inside df_script\\ndf_script.head()\",\"Print quick statistics about our datasets\",\"Inspecting the schema of these DataFrames will help us understand the data better.\",\"Check our datasets\",\"Load the scripts and select season 1\\ndf_script_s1 = df_script.loc[df_script['episode_id'] \\u003c= 13].copy()\",\" Remove the following dataframes since they are not used in this code snippet.\\ndel df_characters, df_locations, df_episodes\",\"Checking data integrity\\nprint(df_characters.shape, df_characters.character_id.nunique())\",\" show the first few rows of the table, for easier understanding\\ndf_script.head()\",\"Helper function to pretty print a JSON object\\nimport json\\n\\ndef pp_json(json_thing, sort=True, indents=4):\\n    if type(json_thing) is str:\\n        print(json.dumps(json.loads(json_thing), sort_keys=sort, indent=indents))\\n    else:\\n        print(json.dumps(json_thing, sort_keys=sort, indent=indents))\",\" Display first few rows of the characters dataframe\\ndf_characters.head()\",\"display(df_characters.head())\\ndisplay(df_locations.head())\\ndisplay(df_script.head())\\ndisplay(df_episodes.head())\",\" Merge episodes, script and characters\\ndf = pd.merge(df_episodes, df_script, on='episode_id')\\ndf = pd.merge(df, df_characters, on='character_id')\",\"Make use of the full dataset\\npd.set_option('display.max_columns', None)\",\"Display examples from each DataFrame\\nfor name, df in {'Characters': df_characters, 'Locations': df_locations, 'Script': df_script, 'Episodes': df_episodes}.items():\\n    print(f'--- {name} ---')\\n    display(df.head(3))\",\"Ensure consistent character naming across dataframes\\ndf_script['raw_character_text'] = df_script['raw_character_text'].replace({\\n    'lenny': 'Lenny',\\n    'carl': 'Carl',\\n    'moe_szyslak': 'Moe Szyslak',\\n    'charles_montgomery_burns': 'Mr. Burns',\\n    'chief_wiggum': 'Chief Wiggum',\\n    'homer_simpson': 'Homer Simpson',\\n    'kent_brockman': 'Kent Brockman',\\n    'marge_simpson': 'Marge Simpson',\\n    'bart_simpson': 'Bart Simpson',\\n    'lisa_simpson': 'Lisa Simpson',\\n    'krusty_the_clown': 'Krusty the Clown',\\n    'edna_krabappel': 'Edna Krabappel',\\n    'nelson_muntz': 'Nelson Muntz',\\n    'apu_nahasapeemapetilon': 'Apu Nahasapeemapetilon',\\n    'seymour_skinner': 'Seymour Skinner',\\n    'milhouse_van_houten': 'Milhouse Van Houten',\\n    'maggie_simpson': 'Maggie Simpson',\\n    'scratchy': 'Scratchy',\\n    'barney_gumble': 'Barney Gumble',\\n    'moe_szyslak': 'Moe Szyslak',\\n    'rainier_wolfcastle': 'Rainier Wolfcastle',\\n    'waylon_smithers': 'Waylon Smithers',\\n    'ned_flanders': 'Ned Flanders',\\n    'fat_tony': 'Fat Tony'\\n})\",\" Cleaning the comma from column name\\ndf_characters = df_characters.rename(columns={x: x.replace(',', '') for x in df_characters.columns})\\ndf_locations = df_locations.rename(columns={x: x.replace(',', '') for x in df_locations.columns})\\ndf_script = df_script.rename(columns={x: x.replace(',', '') for x in df_script.columns})\\ndf_episodes = df_episodes.rename(columns={x: x.replace(',', '') for x in df_episodes.columns})\",\"Create a corpus of documents, i.e. seasons, episodes, scripts\\ncorpus = { row[1][\\\"id\\\"]: \\\"\\\" for row in df_episodes.iterrows() }\\n\\n# Append all the lines from a given episode to the same document\\nfor row in tqdm(df_script.iterrows(), total=df_script.shape[0]):\\n    episode_id = row[1]['episode_id']\\n    corpus[episode_id] += row[1]['raw_text']\",\"Create a directory for saving plots if it does not exist\",\"Check data imported correctly\\ndf_characters.head()\",\"To start off, let's take a look at the first few rows of each dataframe to understand what kind of data we are working with.\",\" Display the first 5 rows of each table\\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()\",\"Let's start by taking a quick look at the structure of our datasets.\",\"Convert information gain to mutual information\",\"Print the first 5 lines of the script dataset to inspect its structure\\ndf_script.head()\",\"Display df_characters's shape\\nprint(\\\"df_characters has\\\", df_characters.shape[0], \\\"rows and\\\", df_characters.shape[1], \\\"column\\\")\",\"Build a dataframe with episodes and their scripted lines\\nlines = []\\nfor _, episode in df_episodes.iterrows():\\n    episode_id = episode['id']\\n    episode_lines = df_script[df_script['episode_id'] == episode_id]\\n    lines.append({\\n        \\\"id\\\": episode_id,\\n        \\\"title\\\": episode['title'],\\n        \\\"original_air_date\\\": episode['original_air_date'],\\n        \\\"number_in_series\\\": episode['number_in_series'],\\n        \\\"number_in_season\\\": episode['number_in_season'],\\n        \\\"season\\\": episode['season'],\\n        \\\"lines\\\": episode_lines\\n    })\\n\\ndf_episodes_lines = pd.DataFrame(lines)\",\" Find seasons in the data\\ndf_episodes['season'].unique()\",\"Filter unspecified locations, replace ~140 duplicates by hand\\ndf_locations = df_locations[~df_locations['normalized_text'].isin(['*unspecified location', 'unspecified'])]\",\" We always want to create a copy of the original data\\ndf_script_cleaned = df_script.copy()\",\"Set index to make filtering more explicit\",\"Encode lines by key and title.\",\"Ensure dataframes work correctly with Jupyter\\ntqdm.pandas()\",\"Inspect the first few rows of each dataframe to understand the data.\",\"Func to split the data to moby_dick chunks, args: window=n, overlap=0\\ndef split_to_chunks(input_str, window, overlap=0):\\n    return [input_str[i:i + window] for i in range(0, len(input_str), window - overlap)]\",\"Declare the NLP pipeline\\nnlp = spacy.load('en_core_web_sm')\",\"Making sure the size of the data is handled\",\" Explore the datasets\\nprint(df_characters.head())\\nprint(df_locations.head())\\nprint(df_script.head())\\nprint(df_episodes.head())\",\"Inspect df_characters\\ndf_characters.head()\",\"Create identifiers to set index from 1\",\"Build nlp model to use\\nnlp = spacy.load(\\\"en_core_web_sm\\\")\",\" Function to select the main character of an episode\\ndef get_main_character(speaker):\\n    main_characters = df_characters[df_characters.main_character == 1].character.tolist()\\n    if speaker in main_characters:\\n        return speaker\\n    return 'other'\",\"# Let's take a look at the script data\\ndf_script.head()\",\"# Let's start by cleaning the script dataframe\\ndf_script.info()\",\"Visualize the script lines DataFrame head\\ndf_script.head()\",\"Convert stringified list to list\",\"Extract all the character names\\ncharacters = df_characters.character_name.unique()\",\"Filtering lines with character and location information from the script\\ndf_script_filtered = df_script[\\n    df_script['raw_character_text'].isin(df_characters['name']) &\\n    df_script['raw_location_text'].isin(df_locations['name'])\\n].copy()\",\" Split the `raw_character_text` column into a list of characters, regexing to remove ambiguities\",\"Join script with characters and locations names\\ndf_script_characters = df_script.join(df_characters, on='character_id', rsuffix='_character')\\ndf_script_locations = df_script_characters.join(df_locations, on='location_id', rsuffix='_location')\\n\\n# Move data to new columns, and fill NaN values with empty strings\\ndf_script_locations['raw_character_name'] = df_script_locations['name']\\ndf_script_locations['raw_location_name'] = df_script_locations['name_location']\\ndf_script_locations['raw_text'] = df_script_locations['normalized_text']\\ndf_script_locations['spoken_words'] = df_script_locations['raw_text']\",\"Merge multiple dataframes into a single one based on 'episode_id' column and create a boolean mask for a sample episode\",\"View the script data\\ndf_script.head()\",\"Visualizing the number of lines per episode\\nlines_per_episode = df_script.groupby('episode_id').size()\\nlines_per_episode.name = 'lines'\\nlines_per_episode = lines_per_episode.reset_index()\\n\\nplt.figure(figsize=(15, 5))\\nplt.plot(lines_per_episode.index, lines_per_episode.lines, marker='o', linestyle='-')\\nplt.title('Number of lines per episode')\\nplt.xlabel('Episode')\\nplt.ylabel('Number of lines')\\nplt.show()\",\" prepare nltk's stop words\\nnlp = spacy.load(\\\"en_core_web_sm\\\")\",\"Check that all tables have been correctly loaded\\nprint('Characters:', df_characters.shape)\\nprint('Locations:', df_locations.shape)\\nprint('Script:', df_script.shape)\\nprint('Episodes:', df_episodes.shape)\",\"Remove the script lines mentioned prior to the first episode of The Simpsons\",\"Drop useless columns and contents from the dataset\",\"Set random seed for reproducibility\\nnp.random.seed(0)\",\"Let's take a look at the data by displaying the first few rows of each DataFrame.\",\"Explore datasets\\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()\",\" Sample the script data\\ndf_script.head()\",\"Inspect the dataframes to understand their structure and the kind of information they contain.\",\"Select only the normalized text column from the script dataframe\\ndf_script = df_script['normalized_text']\",\" Set the index of the script to be the episode_id\",\"Display maximum columns when displaying the dataframe\\npd.set_option('display.max_columns', None)\",\"Representing text data as numbers with bag of words model\\n# We are going to represent each document as a vector with the word frequencies\\n# First, we need to tokenise the documents\\n\\n# Tokenising documents\\n# Load the large model to get the vectors\\nnlp = spacy.load('en_core_web_lg')\\n\\n# We have 158276 documents in the dataset which is quite a lot. \\n# We can speed up this process and make it more efficient if we use the nlp.pipe for the tokenization.\\n\\n# Since the tokenisation takes some time, we can save the tokenized documents to a file, \\n# such that we won\\u00b4t need to do the tokenisation again, in case we close the notebook or shut down the computer.\",\"Check the first few lines of each dataframe\\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()\",\"How many entries do we have for each dataset?\",\"Check first 5 rows of each dataset\\nprint(\\\"Characters\\\\n\\\", df_characters.head(), \\\"\\\\n\\\\n\\\")\\nprint(\\\"Locations\\\\n\\\", df_locations.head(), \\\"\\\\n\\\\n\\\")\\nprint(\\\"Script\\\\n\\\", df_script.head(), \\\"\\\\n\\\\n\\\")\\nprint(\\\"Episodes\\\\n\\\", df_episodes.head(), \\\"\\\\n\\\\n\\\")\",\"Cleanup and preprocess the data\",\"Check data shape\\nprint(f\\\"Characters: {df_characters.shape[0]}\\\")\\nprint(f\\\"Locations: {df_locations.shape[0]}\\\")\\nprint(f\\\"Script lines: {df_script.shape[0]}\\\")\\nprint(f\\\"Episodes: {df_episodes.shape[0]}\\\")\",\" Strip whitespaces around episode names to avoid duplicates\\ndf_episodes['normalized_name'] = df_episodes['normalized_name'].str.strip()\",\"Check few if the dataframes to get an idea of the data.\",\"Merge scripts with characters and locations\\ndf_raw = df_script.merge(df_characters, how='inner', left_on='character_id', right_on='id')\\ndf_raw = df_raw.merge(df_locations, how='inner', left_on='location_id', right_on='id')\\n\\n# Save the raw merged dataframe\\ndf_raw.to_csv('data\\u002fsimpsons_script_merged_raw.csv', index=False)\",\"Set up lists of characters, locations, episodes, and seasons for later use\\ncharacters = df_characters['name'].values.tolist()\\nlocations = df_locations['name'].values.tolist()\\nepisodes = df_episodes['title'].values.tolist()\\nseasons = df_episodes['season'].drop_duplicates().values.tolist()\",\"Print the size of the dataframes to ensure they were loaded successfully\\nprint(f\\\"Characters: {df_characters.shape}\\\")\\nprint(f\\\"Locations: {df_locations.shape}\\\")\\nprint(f\\\"Script: {df_script.shape}\\\")\\nprint(f\\\"Episodes: {df_episodes.shape}\\\")\",\"First, let's take a look at the structure of the datasets.\",\"Check the content of the episodes.csv file\",\" VISUALIZING SCRIPT DATA\\ndf_script.head()\",\"Create a dictionary mapping episode_id to episode title.\",\"Filter out script lines that have not been assigned to any character\\ndf_script = df_script[df_script['character_id'].isin(df_characters['id'])]\\n\\n# Counting the number of lines spoken by each character\\nlines_per_character = df_script['character_id'].value_counts().reset_index()\\nlines_per_character.columns = ['id', 'num_lines']\\n\\n# Merging this information into the characters dataframe\\ndf_characters = pd.merge(df_characters, lines_per_character, on='id', how='left')\",\" Calculate how many occurrences of words there are in all the lines of the scripts\",\"Filter the dialogues with the main characters\",\" Preprocess the data\\n# Remove NaN values\\ndf_characters.dropna(inplace=True)\\ndf_locations.dropna(inplace=True)\\ndf_script.dropna(inplace=True)\\ndf_episodes.dropna(inplace=True)\",\"def load_word_label_dictionary(filename):\\n    result = {}\\n    with open(filename, 'r') as file:\\n        for line in file:\\n            (key, val) = line.split()\\n            result[key] = val\\n    return result\",\"Detectron2\\nimport detectron2\\nfrom detectron2.utils.logger import setup_logger\\n\\nsetup_logger()\\n\\nimport numpy as np\\nimport os, json, cv2, random\\n\\nfrom detectron2 import model_zoo\\nfrom detectron2.engine import DefaultPredictor\\nfrom detectron2.config import get_cfg\\nfrom detectron2.utils.visualizer import Visualizer\\nfrom detectron2.data import MetadataCatalog, DatasetCatalog\",\"Filter out the newline characters from raw_script column in the script dataset to avoid any problems.\",\"Change these to {inplace = True}\",\"Print a first few rows of the first DataFrames, to get a feeling of their structure.\\nprint(df_characters.head())\\nprint(df_locations.head())\\nprint(df_script.head())\\nprint(df_episodes.head())\",\"check info in the imported data files\\nprint(df_characters.info())\\nprint(df_locations.info())\\nprint(df_script.info())\\nprint(df_episodes.info())\",\"Print the first few lines of each dataframe\\nprint(df_characters.head())\\nprint(df_locations.head())\\nprint(df_script.head())\\nprint(df_episodes.head())\",\"Basic sanity checks\",\"Cut the data to match the observations we have\",\"cleaning NaN values\\ndf_script = df_script[(df_script['episode_id'].notna()) & (df_script['character_id'].notna()) & (df_script['location_id'].notna())\\n                     & (df_script['raw_text'].notna())]\",\"Visualize the number of lines per character\\ndf_script['character_id'].value_counts().hist()\",\"Extract all the unique locations from the scripts\\nall_lines = list(df_script['raw_text'])\\nall_locations = []\\nfor line in all_lines:\\n    try:\\n        line = line.split(' ')\\n        line = list(filter(lambda x: x != '', line)) # Remove spaces\\n        all_locations.append(line[1])\\n    except:\\n        pass\",\" Check the import of datasets\\nprint(\\\"Characters dataset:\\\")\\ndisplay(df_characters.head())\\n\\n\\nprint(\\\"\\\\nLocations dataset:\\\")\\ndisplay(df_locations.head())\\n\\nprint(\\\"\\\\nScript dataset:\\\")\\ndisplay(df_script.head())\\n\\nprint(\\\"\\\\nEpisodes dataset:\\\")\\ndisplay(df_episodes.head())\",\" Length of the dataset\\nlen(df_script)\",\"Merge script csv with characters and locations\\ndf_merged = pd.merge(df_script, df_characters, how='left', left_on=['character_id'], right_on=['id'])\",\" Calculate the number of unique locations and characters in the dataset\\nnum_unique_locations = df_locations['name'].nunique()\\nnum_unique_characters = df_characters['name'].nunique()\\n\\nprint(f'There are {num_unique_locations} unique locations in the dataset')\\nprint(f'There are {num_unique_characters} unique characters in the dataset')\",\"Previously, we imported necessary libraries and datasets for our analysis.\",\"Let's start!\",\"Make sure ObjectId is of type int\\ndf_script['episode_id'] = df_script['episode_id'].astype(int)\",\"Join episodes to the script on the 'episode_id' field\\n# (two dataframes, episodes and script)\\ndf = df_episodes.set_index('id').join(\\n    df_script.set_index('episode_id')\\n).reset_index()\\n\\n# Join the resulting dataframe to the characters and locations tables.\\n# (characters\\u002flocations and episodes\\u002fscript now)\\ndf = df.set_index('character_id').join(\\n    df_characters.set_index('id')\\n).reset_index().set_index('location_id').join(\\n    df_locations.set_index('id')\\n).reset_index()\",\"Filter characters from main family\",\"Create empty DataFrame for capturing entities\\ndf_entities = pd.DataFrame(columns=['id', 'text', 'label'])\\n\\nnlp = spacy.load('en_core_web_sm')\",\"Split the dataset into test and training sets\",\" The first five rows of each dataframe\\nprint(df_characters.head())\\nprint(df_locations.head())\",\"Helper function to split array values into rows while duplicating the rest of the columns\\ndef splitDataFrameList(df, target_column):\\n    '''\\n    Accepts a column with multiple types of delimited data and returns a \\n    DataFrame with each entry for the target column separated out.\\n    '''\\n    #DataFrame containing multiple type of columns as a single column\\n    row_accumulator = []\\n\\n    def splitListToRows(row, row_accumulator, target_column):\\n        split_row = row[target_column]\\n        if isinstance(split_row, list) and len(split_row) \\u003e 0:\\n            for s in split_row:\\n                new_row = row.to_dict()\\n                new_row[target_column] = s\\n                row_accumulator.append(new_row)\\n        else:\\n            new_row = row.to_dict()\\n            new_row[target_column] = split_row\\n            row_accumulator.append(new_row)\\n\\n    df.apply(splitListToRows, axis=1, args=(row_accumulator, target_column))\\n    new_df = pd.DataFrame(row_accumulator)\\n    return new_df\",\"To avoid cache memory error and reload nlp, this nlp pipe can be persisted using disk\\n# Also, then it can easily be loaded with `spacy.load()` function\\n\\n# pip install dill\\nimport dill\",\" Remove unwanted columns and rows from DataFrames to reduce memory usage and increase speed.\",\"Display the three first rows for the characters dataframe\\ndf_characters.head(3)\",\"check whether dataframe is imported correctly\",\"Quick look at the data types and null values\",\"Inspect the dataframes to understand their structure and contents\",\" Extracting the names of the characters.\",\"Enable f-strings in python 3.5, 3.6, and 3.7\",\"Combine the tables to form one large dataset to work with\",\"# Print dataset's shape and first rows\\nprint(\\\"Characters dataset's shape:\\\")\\nprint(df_characters.shape)\\nprint(\\\"\\\\nCharacters dataset's initial rows:\\\")\\nprint(df_characters.head())\",\"Display general information about the script dataset\\nprint(df_script.shape)\\nprint(df_script.dtypes)\",\"Check the data shape and format\",\"Add custom colors for the plot\\ncolors = ['lightskyblue', 'lightcoral']\\nmatplotlib.rcParams['axes.prop_cycle'] = matplotlib.cycler(color=colors)\",\" -*-*-*-*-*-* Transform the database -*-*-*-*-*-*-\\n# Remove entries with unidentified speaker, locations, or without a proper script\\ndf_script = df_script[df_script[\\\"raw_text\\\"] != ''][[\\\"episode_id\\\", \\\"id\\\", \\\"character_id\\\", \\\"raw_text\\\"]]\",\"def load_pipeline():\\n    # Load the multi-task NER model\\n    nlp = spacy.load('en_core_web_sm')\\n\\n    # Add labels for the NER 'Character' and 'Location'\\n\\n    # Character labels\\n    for character in df_characters['name']:\\n        nlp.entity.add_label(character)\\n\\n    # Location labels\\n    for location in df_locations['name']:\\n        nlp.entity.add_label(location)\\n\\n    return nlp\",\"Explore the content of each dataframe\",\"Check a few columns in the script data, as well as extract the character having the most lines and the location in which these lines were delivered\",\"Filter the data to only include character and location information that is in the script data\\ncharacters_in_scripts = df_script[\\\"raw_character_text\\\"].unique()\\nlocations_in_scripts = df_script[\\\"raw_location_text\\\"].unique()\\n\\ndf_characters = df_characters[df_characters[\\\"name\\\"].isin(characters_in_scripts)].reset_index(drop=True)\\ndf_locations = df_locations[df_locations[\\\"name\\\"].isin(locations_in_scripts)].reset_index(drop=True)\",\"tqdm.pandas()\",\"Print the first 5 rows of the script dataset to understand its structure\\ndf_script.head()\",\"Define pre-processing functions\",\"Merge data into one dataframe\",\"Utility function\\ndef expand_contractions(text, contraction_mapping=CONTRACTION_MAP):\\n    contractions_pattern = re.compile('({})'.format('|'.join(contraction_mapping.keys())), \\n                                      flags=re.IGNORECASE|re.DOTALL)\\n    def expand_match(contraction):\\n        match = contraction.group(0)\\n        first_char = match[0]\\n        expanded_contraction = contraction_mapping.get(match)\\\\\\n                                if contraction_mapping.get(match)\\\\\\n                                else contraction_mapping.get(match.lower())                       \\n        expanded_contraction = first_char+expanded_contraction[1:]\\n        return expanded_contraction\\n        \\n    expanded_text = contractions_pattern.sub(expand_match, text)\\n    expanded_text = re.sub(\\\"'\\\", \\\"\\\", expanded_text)\\n    return expanded_text\",\" Optionally, you can remove the quotation marks if it starts to be difficult to manage in your local language.\",\"Define the length of the dataset for the purpose of interactive exploration\\ndata_length = len(df_script)\",\"df_script['raw_character_text'].value_counts()\",\"Check out the first 5 characters' dataframe.\",\"Drop unnecessary columns\\ndf_characters = df_characters.drop(columns=['Normalized Name','Normalized Role'])\\ndf_locations = df_locations.drop(columns=['Normalized Name'])\\ndf_episodes = df_episodes.drop(columns=['Image URL','Production Company','US Viewers In Millions','Unnamed: 7','Video URL'])\\n\\n# Remove the last row which contains meta-information\\n\\n# Enumerating each dataframe\\nfor idx, df in enumerate([df_characters, df_locations, df_script, df_episodes]):\\n    # Adding the index as a column\\n    df['DataFrame Index'] = idx\\n\\n    # Set index as DataFrame Index\\n    df.set_index(['DataFrame Index','id'], inplace=True)\\n\\n# Reassign the new column ordered\\ndf_script = df_script[['episode_id','number','character_id','location_id','raw_text',\\\"spoken_words\\\",\\\"timestamp_in_ms\\\"]]\\n\\ndf_script.head()\",\"Species the type of data in the datasets\\nprint('Characters dataset:')\\nprint(df_characters.dtypes)\\nprint('\\\\nLocations dataset:')\\nprint(df_locations.dtypes)\\nprint('\\\\nScript dataset:')\\nprint(df_script.dtypes)\\nprint('\\\\nEpisodes dataset:')\\nprint(df_episodes.dtypes)\",\"Print the first few rows of the characters dataframe\\nprint(df_characters.head())\\n# Print the first few rows of the locations dataframe\\nprint(df_locations.head())\",\"Print the first few lines of the script data to inspect the structure\\nprint(f'Shape: {df_script.shape}')\\ndf_script.head()\",\"Display dataset shapes\\nprint(\\\"Characters (rows, columns):\\\", df_characters.shape)\\nprint(\\\"Locations (rows, columns):\\\", df_locations.shape)\\nprint(\\\"Script lines (rows, columns):\\\", df_script.shape)\\nprint(\\\"Episodes (rows, columns):\\\", df_episodes.shape)\",\" Create a column with the raw tokenized text\",\"Visualize the first few rows of the script data\\ndf_script.head()\",\"TODO: Add content here\",\"Here we load the datasets we'll be using for the analysis.\",\"Select only the columns that we're interested in:\\n- character_id\\n- raw_character_text\\n- raw_location_text\",\" Look at the first rows of the dataframe to better understand its structure\\ndf_script.head()\",\"Set 'id' as index for quick search\",\"Familiarize ourselves with one of the dataset.\",\"Download spacy's transformer model \\\"en_core_web_trf\\\" to be able to tokenize words.\",\"Clean data\\n#script with na characters or na locations\\n\\ndf_script = df_script[df_script.character_id.notna() & df_script.location_id.notna()]\",\"Configure TQDM for pandas\\ntqdm.pandas()\",\" Let's take a look at the structure and contents of each data type.\",\"Explore data distributions and format before implementing nlp tools\",\"Ensure script data is sorted by index\\ndf_script = df_script.sort_values(by='index')\",\"First, let's take a look at the contents of these datasets to understand their structure and the type of information they contain.\",\"\\\"\\\"\\\"Data statistics\\\"\\\"\\\"\",\"appearances = df_script['raw_character_text'].value_counts().reset_index()\\nappearances.columns = ['raw_character_text', 'num_appearances']\",\"Create a copy to avoid loading the data again and again\\ndf = df_script.copy()\",\"Load the pre-processed data from the Pickle files\",\" Measure total spoken lines per character\\nlines_per_character = df_script.character_id.value_counts().reset_index()\\nlines_per_character.columns = ['character_id', 'number_of_lines']\\nlines_per_character = lines_per_character.merge(df_characters, on='character_id')\\nlines_per_character = lines_per_character.sort_values(by='number_of_lines', ascending=False)\\n\\n# Show data\\nlines_per_character.head()\",\"Filtering Data\\n# --------------------------------------------------\\n# Step 2: Cleaning Lines, Spans, and Characters\\n# --------------------------------------------------\",\"Check out the first few rows of the characters dataset\\ndf_characters.head()\",\"Remove useless columns from characters and locations DataFrames\\ndf_characters = df_characters[['id', 'name', 'normalized_name']]\\ndf_locations = df_locations[['id', 'name', 'normalized_name']]\",\"Inspect the first few rows of the script data\\ndf_script.head()\",\" Display the first 5 characters of the characters DataFrame\\ndf_characters.head()\",\"Joining datasets\",\" We re-use some utilities for pre-processing.\",\"ner.load('en_core_web_sm')\",\"Set environment variables for PySpark\\nos.environ['PYSPARK_PYTHON'] = '\\u002fusr\\u002fbin\\u002fpython3'\\nos.environ['PYSPARK_DRIVER_PYTHON'] = '\\u002fusr\\u002fbin\\u002fpython3'\",\"\\n# Character interactions\\ninteractions = df_script.groupby(['character_id', 'utterance_id']).size().groupby('character_id').size()\\n\\n# Now we have to map the characters in interactions to their real names\\ninteractions = interactions.to_frame().join(df_characters.set_index('character_id'))\\n\\n# Sort the interactions\\ninteractions.sort_values(by=0, ascending=False, inplace=True)\",\"Creates a new 'simpsons_script_lines' dataframe that contains the 'normalized_text' and 'character_id' columns\\ndf_episodes.drop(['image_url'], axis=1, inplace=True)\",\" Check the content of df_characters\\ndf_characters.head()\",\" Display first few rows of characters dataframe\\ndf_characters.head()\",\" The path to the data is currently wrong. Let's fix that by modifying the path to the data.\",\"Total number of rows in the dataset\\nscript_rows = df_script.shape[0]\",\"Displays all the dataframes\\ndisplay(df_characters.head(3))\\ndisplay(df_locations.head(3))\\ndisplay(df_script.head(3))\\ndisplay(df_episodes.head(3))\",\"Remove duplicate locations and characters\",\"Extracting main characters\\nmain_characters = df_characters[df_characters['is_main_cast']]\\nprint(main_characters)\",\"Make previews of each dataset\",\"Merge data using the common keys\",\"set up the random state for replication of results\\nnp.random.seed(42)\",\"Create `date` and `time` columns, and merge with `df_script` \\ndf_script = df_script.assign(\\n    date=pd.to_datetime(df_script.timestamp_in_ms, unit='ms').dt.date,\\n    time=pd.to_datetime(df_script.timestamp_in_ms, unit='ms').dt.time\\n)\\n\\n# Merge\\ndf_script = df_script.merge(\\n    df_episodes[['id', 'season', 'number', 'title', 'original_air_date']],\\n    left_on='episode_id', right_on='id'\\n)\\n\\n# Column re-ordering for their better visualization\\ndf_script = df_script[\\n    [\\n        'id', 'season', 'number', 'title', 'original_air_date', 'timestamp_in_ms', 'date', 'time', 'raw_text', 'speaking_line',\\n        'character_id', 'location_id', 'raw_character_text', 'raw_location_text', 'spoken_words', 'normalized_text'\\n    ]\\n]\\n\\n# The first `n` rows\\ndf_script.head()\",\"Check the loaded datasets\\ndf_script.head()\",\"Text preprocessing\\n# Stop words\\nnlp = spacy.load(\\\"en_core_web_sm\\\")\\nstop_words = spacy.lang.en.stop_words.STOP_WORDS\",\"Check the first 5 rows of each of the datasets\",\"Check the content of the characters dataset\\ndf_characters.head()\",\"Changing the shape of all datasets\\na = df_characters.shape\\nb = df_locations.shape\\nc = df_script.shape\\nd = df_episodes.shape\",\"Checking the first few rows of each dataset to get an idea of the information available.\",\"View first 10 rows of each DataFrame\\nfor df, name in zip([df_characters, df_locations, df_episodes, df_script], \\n                    ['Characters', 'Locations', 'Episodes', 'Script']):\\n    display(HTML(f\\\"\\u003ch2\\u003e{name}\\u003c\\u002fh2\\u003e\\\"))\\n    display(df.head(10))\",\"Check if the dataframes are successfully loaded\\nprint(f'Characters dataframe: {df_characters.shape[0]} rows')\\nprint(f'Locations dataframe: {df_locations.shape[0]} rows')\\nprint(f'Script lines dataframe: {df_script.shape[0]} rows')\\nprint(f'Episodes dataframe: {df_episodes.shape[0]} rows')\",\"Looking at the first 5 rows of each dataframe.\",\"View the first few entries of the characters dataframe\\ndf_characters.head()\",\"Preview the first 5 rows of each dataframe to understand their structure\\nprint(df_characters.head())\\nprint(df_locations.head())\\nprint(df_script.head())\\nprint(df_episodes.head())\",\" Visualizations of the datasets\",\"Path to Simpsons dataset\\npath = \\\"\\u002fcontent\\u002fdrive\\u002fMyDrive\\u002fColab Notebooks\\u002fNLP\\u002fsimpsons\\u002f\\\"\\n\\n# Visualize dataset\\nprint(\\\"\\u003e\\u003e Raw datasets:\\\")\\nprint(f\\\"df_characters: {df_characters.shape}\\\")\\nprint(f\\\"df_locations: {df_locations.shape}\\\")\\nprint(f\\\"df_script: {df_script.shape}\\\")\\nprint(f\\\"df_episodes: {df_episodes.shape}\\\")\",\" Hide progress bars when running loops\\ntqdm.pandas()\",\" Check the dfs\",\" We need to move string-based features to lowercase for later uses in case sensitive searches\",\"Optional: use all columns\\npd.set_option('display.max_columns', None)\",\".concat([df_characters, df_locations, df_script, df_episodes], keys=['characters', 'locations', 'script', 'episodes'], axis=1)\",\"Checking the head of the dataframe to make sure all the data was imported correctly.\",\"Create some directories to store graphs and data\",\"Check shapes of DataFrames\",\"Check the data size and structure\\nprint(\\\"Characters:\\\", df_characters.shape)\\nprint(\\\"Locations:\\\", df_locations.shape)\\nprint(\\\"Script:\\\", df_script.shape)\\nprint(\\\"Episodes:\\\", df_episodes.shape)\",\"\\n# Join episode and script data\\ndf_script_episodes = df_script.join(df_episodes, on='episode_id', rsuffix='_episode')\\n\\n# Print the first five rows\\ndf_script_episodes.head()\",\"Create copies of these dataframes\",\" Look at the unique values for season and episode\\n(df_episodes\\n .loc[lambda df: df.season == 1]\\n .episode\\n .unique())\",\" Display the first 3 rows of the characters dataframe\\ndf_characters.head(3)\",\"Inspect the dataframes to understand their structure and contents\",\"Collect all spoken lines of a character\\nlines = []\\nfor index, row in tqdm(df_characters.iterrows(), total=df_characters.shape[0]):\\n    character_name = row['name']\\n\",\" Plotting the number of locations per episode\",\"Merge characters\\ndf_characters_ep = df_characters.merge(df_script, left_on='id', right_on='character_id').merge(df_episodes, on='episode_id')\",\"To show the top few rows and understand the data's structure for each dataframe, we will use the head function for each dataframe.\",\"Now you can start with the current assignments and any analysis or code snippet you want to work on.\",\"Inspect the content of the episodes data frame\",\"Check the first few rows of the dataframe to see what it looks like.\",\"Let's take a look at the first few rows (and columns) of our data.\",\" Look at first couple of records for the characters, locations and script dataframes to understand what kind of data they contain\\ndf_characters.head()\",\"Subset of characters that spoke over than 10 times\\nmain_characters = df_script['raw_character_text'].value_counts()[df_script['raw_character_text'].value_counts()\\u003e10].index.values\\ndf_script = df_script[df_script['raw_character_text'].isin(main_characters)]\\n\\n# replacing blank values\\ndf_script = df_script.replace(\\\"\\\", np.nan)\",\"Get scripts for the first 5 seasons\",\"Explore the dataset\\n#df_script.info()\",\"Simple EDA to \\\"get to know\\\" the data\\nprint(\\\"Characters sample:\\\")\\nprint(df_characters.head(2))\\nprint(\\\"Locations sample:\\\")\\nprint(df_locations.head(2))\\nprint(\\\"Script sample:\\\")\\nprint(df_script.head(5))\",\"Define ordering of seasons and episodes\\nseason_episode_order = {\\n    (1, 1): 1,   (1, 2): 2,   (1, 3): 3,   (1, 4): 4,\\n    (2, 1): 5,   (2, 2): 6,   (2, 3): 7,   (2, 4): 8,\\n    (3, 1): 9,   (3, 2): 10,  (3, 3): 11,  (3, 4): 12,\\n    (4, 1): 13,  (4, 2): 14,  (4, 3): 15,  (4, 4): 16,\\n    (5, 1): 17,  (5, 2): 18,  (5, 3): 19,  (5, 4): 20,\\n    (6, 1): 21,  (6, 2): 22,  (6, 3): 23,  (6, 4): 24,\\n    (7, 1): 25,  (7, 2): 26,  (7, 3): 27,  (7, 4): 28,\\n    (8, 1): 29,  (8, 2): 30,  (8, 3): 31,  (8, 4): 32,\\n    (9, 1): 33,  (9, 2): 34,  (9, 3): 35,  (9, 4): 36,\\n    (10, 1): 37, (10, 2): 38, (10, 3): 39, (10, 4): 40,\\n    (11, 1): 41, (11, 2): 42, (11, 3): 43, (11, 4): 44,\\n    (12, 1): 45, (12, 2): 46, (12, 3): 47, (12, 4): 48,\\n    (13, 1): 49, (13, 2): 50, (13, 3): 51, (13, 4): 52,\\n    (14, 1): 53, (14, 2): 54, (14, 3): 55, (14, 4): 56,\\n    (15, 1): 57, (15, 2): 58, (15, 3): 59, (15, 4): 60,\\n    (16, 1): 61, (16, 2): 62, (16, 3): 63, (16, 4): 64,\\n    (17, 1): 65, (17, 2): 66, (17, 3): 67, (17, 4): 68,\\n    (18, 1): 69, (18, 2): 70, (18, 3): 71, (18, 4): 72,\\n    (19, 1): 73, (19, 2): 74, (19, 3): 75, (19, 4): 76,\\n    (20, 1): 77, (20, 2): 78, (20, 3): 79, (20, 4): 80,\\n    (21, 1): 81, (21, 2): 82, (21, 3): 83, (21, 4): 84,\\n    (22, 1): 85, (22, 2): 86, (22, 3): 87, (22, 4): 88,\\n    (23, 1): 89, (23, 2): 90, (23, 3): 91, (23, 4): 92,\\n    (24, 1): 93, (24, 2): 94, (24, 3): 95, (24, 4): 96,\\n    (25, 1): 97, (25, 2): 98, (25, 3): 99, (25, 4): 100,\\n    (26, 1): 101, (26, 2): 102, (26, 3): 103, (26, 4): 104,\\n    (27, 1): 105, (27, 2): 106, (27, 3): 107, (27, 4): 108,\\n    (28, 1): 109, (28, 2): 110, (28, 3): 111, (28, 4): 112,\\n    (29, 1): 113, (29, 2): 114, (29, 3): 115, (29, 4): 116,\\n    (30, 1): 117, (30, 2): 118, (30, 3): 119, (30, 4): 120,\\n    (31, 1): 121, (31, 2): 122, (31, 3): 123, (31, 4): 124,\\n    (32, 1): 125, (32, 2): 126, (32, 3): 127, (32, 4): 128\\n}\",\" View the structure of the script data\\ndf_script.head()\",\"Set seed for numpy\\nnp.random.seed(0)\",\"# an example of a simple query\\ndf_script[df_script['normalized_text'].str.contains('coffe')].head()\",\"This will read the four datasets provided.\",\" Merge the script lines with episode and characters data\\ndf_script_lines = df_script.merge(df_episodes, on='episode_id')\\ndf_script_lines = df_script_lines.merge(df_characters, left_on='character_id', right_on='id')\\ndf_script_lines.rename(columns={'name': 'character_name'}, inplace=True)\\ndf_script_lines = df_script_lines[['id', 'episode_id', 'number', 'raw_text', 'timestamp_in_ms',\\n                                   'season', 'episode_name', 'character_id', 'character_name',\\n                                   'location_id', 'spoken_words']]\\ndf_script_lines = df_script_lines.merge(df_locations, left_on='location_id', right_on='id')\\ndf_script_lines.rename(columns={'name': 'location_name'}, inplace=True)\\ndf_script_lines = df_script_lines[['id', 'episode_id', 'number', 'raw_text', 'timestamp_in_ms',\\n                                   'season', 'episode_name', 'character_id', 'character_name',\\n                                   'location_id', 'location_name',\\n                                   'spoken_words']]\",\"Compatibility with new pandas versions\\nif pd.__version__\\u003e='1.0.0':\\n    df_characters.rename(columns={'id': 'char_id'}, inplace=True)\\n    df_locations.rename(columns={'id': 'loc_id'}, inplace=True)\\n    df_script.rename(columns={'id': 'line_id', 'episode_id': 'ep_id', 'character_id': 'char_id', 'location_id': 'loc_id'}, inplace=True)\\n    df_episodes.rename(columns={'id': 'ep_id'}, inplace=True)\",\"Print the header of each dataframe\\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()\",\" Plot histogram of the episode lengths\\ndf_episodes.length.hist(bins=50, alpha=0.5, color='r', edgecolor='black')\",\" Checking dataframe shapes\",\" Display each of the dataframe to understand the structure and the data inside it.\",\"Let's see what the data looks like.\",\"Show full column and row information:\",\" Filter the dataset to only consider speaking lines\",\"Ensure proper file separator for both Windows and Unix-based systems\\nfile_separator = os.sep\",\"Let's take a look at the dimensions of our dataframes.\\nprint('Characters df shape:', df_characters.shape)\\nprint('Locations df shape:', df_locations.shape)\\nprint('Script df shape:', df_script.shape)\\nprint('Episodes df shape:', df_episodes.shape)\",\"preview data\\nprint(\\\"Characters:\\\")\\nprint(df_characters.head())\\nprint(\\\"Locations:\\\")\\nprint(df_locations.head())\\nprint(\\\"Script:\\\")\\nprint(df_script.head())\\nprint(\\\"Episodes:\\\")\\nprint(df_episodes.head())\",\"\\n#{'characters': df_characters, 'locations': df_locations, 'script': df_script, 'episodes': df_episodes}\",\"Display a preview of each dataset\\nprint(\\\"Characters dataset preview\\\")\\nprint(df_characters.head(3))\\nprint(\\\"Locations dataset preview\\\")\\nprint(df_locations.head(3))\\nprint(\\\"Script dataset preview\\\")\\nprint(df_script.head(3))\\nprint(\\\"Episodes dataset preview\\\")\\nprint(df_episodes.head(3))\",\"Merge dialog with character information\\ndf_dialog = (\\n    df_script\\n    .merge(df_characters, how='left', left_on='character_id', right_on='id', suffixes=('','_character'))\\n    .merge(df_locations, how='left', left_on='location_id', right_on='id', suffixes=('','_location'))\\n    .merge(df_episodes, how='left', left_on='episode_id', right_on='id', suffixes=('','_episode'))\\n)\",\"Create a copy of the dataframe with the script lines\\ndf_script_filtered = df_script.copy()\",\" Filter the characters that are actually speaking\",\"utf-8'decode' codec can't decode byte 0x89 in position 0: invalid start byte\",\"Display top 10 rows of each dataframe to understand structure and information.\",\"Constants\\nnlp = spacy.load('en_core_web_lg')\\nstopwords = spacy.lang.en.STOP_WORDS\",\"Filter episodes with location_id and character_id\\ndf_script = df_script[(df_script['location_id'].notnull()) & (df_script['character_id'].notnull())].reset_index(inplace=False, drop=True)\",\"# Let's work first on a very basic visual exploration of the data:\\n# Let's look at the number of lines per episode\\n\\n# Clean the episode column\\ndf_script['episode_id'] = df_script['episode_id'].str.extract('(\\\\d+)').astype(int)\\n\\n# Count the number of lines per episode\\nlines_per_episode = df_script.groupby('episode_id').size()\\nlines_per_episode.plot(kind='bar', figsize=(15, 7))\",\"Then, we have to filter the script data to remove rows with missing or invalid values and keep only the dialogue lines.\",\" Split the raw text script into its components.\",\"Find and replace the ids of the speaking character, location, episode, and season in the script lines dataframe.\",\"Remove lines without character id and without quotes\\ndf_script = df_script.loc[df_script['character_id'].notna() & df_script['quote'].notna()]\",\"Configuration for preprocessing and analysis\\nnlp = spacy.load('en_core_web_lg')\\nnlp.max_length = 2000000\",\"Print head of each dataframe\\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()\",\"Drop broken entries\\ndf_script = df_script.drop(df_script[df_script[\\\"id\\\"] == 17837].index)\\ndf_script = df_script.drop(df_script[df_script[\\\"id\\\"] == 53270].index)\",\" Research question: \\\"What are the most frequent words used by each character across all episodes?\\\"\\n\\n# Create a dataset with the characters' lines and speaker\\ndf_characters['character_lines'] = df_script[df_script.character_id.isin(df_characters.id)].groupby('character_id').apply(lambda x: ' '.join(x['character_words'].str.lower().fillna(' ')))\\ndf_characters['n_words'] = df_characters.character_lines.str.split(' ').apply(len)\\n\\n# Eliminate characters with less than 1000 words\\ndf_filtered_characters = df_characters[df_characters.n_words\\u003e1000]\\n\\n# Create a list of lines for each character\\ncharacter_lines_list = df_filtered_characters.character_lines.str.split('\\\\.').tolist()\\ncharacter_lines_speakers = df_filtered_characters.character_name.tolist()\\n\\n# Count words\\ncharacter_words_count = list(map(lambda x: Counter(x.split(\\\" \\\")), character_lines_list))\\n\\n# Removing stop words\\nnlp = spacy.load('en_core_web_sm')\\nfor i in range(len(character_words_count)):\\n    print('Filtering stop words - character {}'.format(character_lines_speakers[i]))\\n    words = list(character_words_count[i].keys())\\n    words = list(filter(lambda x: nlp(x)[0].is_stop, words))\\n    character_words_count[i] = {k:v for k,v in character_words_count[i].items() if k not in words}\\n    print('number of words after filtering: {}'.format(len(character_words_count[i])))\",\"Clean up memory\\ndel df_characters, df_locations, df_episodes\",\"Check segments of the dataframes to understand their contents\\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()\",\"Let's see how the data looks like\",\"Check first 5 rows of `df_script`\",\" Print the first few lines of each dataframe to understand its structure\\nprint(df_characters.head())\\nprint(df_locations.head())\\nprint(df_script.head())\\nprint(df_episodes.head())\",\"Select main characters\\nmain_characters = [\\n    'marge_simpson', 'homer_simpson', 'bart_simpson',\\n    'lisa_simpson', 'maggie_simpson', 'skinner'\\n]\\n\\n# Filter out lines by main characters\\ndf_main_characters = df_script[\\n    df_script['raw_character_text'].isin(main_characters)\\n].copy()\\n\\n# Cleanup and drop NaN values\\ndf_main_characters['normalized_text'] = (\\n    df_main_characters['spoken_words']\\n    .str.lower()\\n    .str.replace(r'[^\\\\w\\\\s]', '', regex=True)\\n    .str.replace(r' +', ' ', regex=True)\\n    .str.strip()\\n)\\ndf_main_characters['word_count'] = (\\n    df_main_characters['normalized_text'].str.split().str.len()\\n)\\ndf_main_characters['word_count'] = (\\n    df_main_characters['word_count']\\n    .where(df_main_characters['word_count'] \\u003c 100, 100)\\n)\\n\\ndf_main_characters = df_main_characters.dropna(subset=['normalized_text'])\\n\\n# Inspect\\ndf_main_characters.head()\",\" Function to filter non-ascii characters in a string\",\"Optional: Display and explore the data to understand its structure and the available features and columns.\",\"From the script dataset, we will use the following columns: character_id, episode_id, location_id, raw_text.\",\"Convert character_id and location_id from float to int\",\"Checking the data in df_characters dataframe.\",\" Intialize spaCy model\\nnlp = spacy.load(\\\"en_core_web_sm\\\")\",\"# Print size of the script dataframe\\nprint('Number of dialogue lines in the dataset: ', df_script.shape[0])\",\"Create an instance of the spacy class\\nnlp = spacy.load('en_core_web_sm')\",\" Use the \\\"utf-8\\\" encoding to avoid issues with special characters\",\"Exploratory Data Analysis\",\" Checking dimensionality of the data\\nprint('Characters: ', df_characters.shape)\\nprint('Locations: ', df_locations.shape)\\nprint('Script: ', df_script.shape)\\nprint('Episodes: ', df_episodes.shape)\",\"Let's print the shape of the all dataset and the head of the script dataset.\",\"Subset the script dataframe to only include the first 10 episodes.\",\"Inspect the first few rows of each dataframe to understand its structure and content.\\nprint(df_characters.head())\\nprint(df_locations.head())\\nprint(df_script.head())\\nprint(df_episodes.head())\",\"Check a few lines of the `df_characters` dataframe\",\" Display top rows of the dataframes\\nprint(df_characters.head())\\nprint(df_locations.head())\\nprint(df_script.head())\\nprint(df_episodes.head())\",\"Check the loaded datasets\\ndf_script.head()\",\"Check out the first few rows of our datasets\\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()\",\"Inspect the dataframes to understand their structure and contents\",\"Get an overview of the datasets\\ndf_script\",\"Let's see how the data looks like\",\"Inspect the dataframe shapes\",\"# Display at a glance the first 5 rows of a dataframe\\ndf_characters.head()\",\"Filter characters from the script\\nmain_characters = df_characters[df_characters['raw_character_text'].isin(df_script['raw_character_text'].unique())]\\nprint(f'Number of unique characters with lines in the script: {len(main_characters)}')\",\"# Concatenate location names\\nlocation_names = '|'.join([location.lower() for location in df_locations['raw_location_text'].unique()])\\nlocation_names\",\"Choose a subset of the data to speed up the computation\",\"Extracting just the dialogues and the respective character name from the original dataframe.\",\" Set some parameters for better visualization in matplotlib\",\"Display the first 3 rows of the characters dataframe\\ndf_characters.head(3)\",\"# Display the first 5 rows of each table\\ndisplay(df_characters.head())\\ndisplay(df_locations.head())\\ndisplay(df_script.head())\\ndisplay(df_episodes.head())\",\"display(df_characters.head())\\ndisplay(df_locations.head())\\ndisplay(df_script.head())\\ndisplay(df_episodes.head())\",\"Display the top 5 rows of each dataframe\\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()\",\"Check the size of each dataframe\\nprint('Characters:', df_characters.shape)\\nprint('Locations:', df_locations.shape)\\nprint('Script:', df_script.shape)\\nprint('Episodes:', df_episodes.shape)\",\" Filter to keep only characters with more than 300 lines\",\"Inspect each DataFrame to understand its structure and content\",\"Subset df_episodes to only take episodes from the first 12 seasons (up to 2001)\",\" Filter lines with a specific character_id\\ndf_character_1 = df_script[df_script['character_id'] == 1]\\ndf_character_1.head()\",\" Display the first 5 rows of each table\\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()\",\"Remove bad characters and extra white spaces from the character names\\ndf_script.raw_character_text = df_script.raw_character_text.str.strip()\\ndf_characters.character_name = df_characters.character_name.str.strip()\",\"# Display maximum columns and rows when displaying dataframes\\npd.set_option('display.max_columns', None)\\npd.set_option('display.max_rows', None)\",\"Print some statistics about the data.\",\" We will create a single dataframe which includes episodes, locations, characters and script lines information.\",\"\\n# Display the first 5 script lines\\ndf_script.head()\",\"View dimensions of dataframes\",\"Display datasheets header\",\"Check the shape of each dataframe to gain a first understanding of the data\",\"Preview the datasets\",\"Check the data types for each column\\ndf_script.info(verbose=True)\",\" #encoding=utf-8\",\"Join episodes with scripts\\ndf_episodes_scripts = df_episodes.set_index('id').join(df_script.set_index('episode_id')).reset_index()\\n\\n# Join characters with scripts\\ndf_characters_scripts = df_characters.set_index('id').join(df_script.set_index('character_id'))\\n\\n# Join locations with scripts\\ndf_locations_scripts = df_locations.set_index('id').join(df_script.set_index('location_id'))\",\" remove unwanted white spaces form `simpson_characters.csv`\\ndf_characters = df_characters.apply(lambda x: x.str.strip() if x.dtype == \\\"object\\\" else x)\",\"\\n# Display options\\npd.set_option('display.max_columns', None)\\npd.set_option('display.expand_frame_repr', False)\",\"Load pre-trained spacy model\\nnlp = spacy.load(\\\"en_core_web_sm\\\")\",\"Let's first explore the data to see what information we have available.\",\"Number of script lines in the dataset\\nlen(df_script)\",\"nlp = spacy.load(\\\"en_core_web_sm\\\")\\n\\n# Path to where the wordcloud images will be saved\\nWORDCLOUD_DIR = \\\"wordclouds\\\"\\n\\n# Create output directory if it does not exist\\nos.makedirs(WORDCLOUD_DIR, exist_ok=True)\",\"Check dataframes are loaded successfully\\nprint('Characters:', df_characters.shape)\\nprint('Locations:', df_locations.shape)\\nprint('Script:', df_script.shape)\\nprint('Episodes:', df_episodes.shape)\",\"Visualize the episode count distribution by season\",\" This is the first model to start early exploration of the dataset.\",\"Sample the dataframes to visualize their structure\\ndf_characters.head(3)\",\"Check the number of rows and columns for each dataframe\\nprint(f'Characters: {df_characters.shape}')\\nprint(f'Locations: {df_locations.shape}')\\nprint(f'Script: {df_script.shape}')\\nprint(f'Episodes: {df_episodes.shape}')\",\"In case of small datasets, pandas is smart enough to infer the correct data type of each column, however, it's best to be explicit to avoid ambiguity and noisy type warnings in case of larger datasets.\",\"Limit script to certain episode_id.\\nepisode_id = 1\",\"Optional: choose the tallest characters and include others that have the same height, then inspect the names and heights\",\" Merge the dataframes with the episode and character info\",\" Set 'id' as the index for quick access\",\" Display the first 3 rows of each dataframe\\ndf_characters.head(3)\",\"Quick look at the data and its structure\",\"Merge script with episodes and strip the data\\ndf_episodes['id'] = df_episodes.id.astype(str)  # ensure alignment on merge\\ndf_script_lines_with_episode = df_script.merge(\\n    df_episodes,\\n    left_on='episode_id',\\n    right_on='id',\\n    suffixes=('_script', '_episode')).copy()\\n\\n# simplify\\ndf_script_lines_with_episode.drop(\\n    ['id_episode','image_url','id_script','number_in_season','number_in_series','original_air_date','id_script',\\n     'title', 'us_viewers_in_millions','views', 'imdb_votes', 'imdb_rating','video_url'],\\n    axis=1,\\n    inplace=True)\",\"Merge the datasets to have all the information on the script lines\",\"Let's display the first few records of each dataset to understand what we're working with.\",\"Create a copy of df_script to work with\",\"What steps should I take to clean the data in the script dataframe?\",\"Data cleanup\\n# Keep only non-empty lines\\ndf_script = df_script[df_script['raw_text'].notna()]\\n\\n# Keep only lines related to an episode\\ndf_script = df_script[df_script['episode_id'].notna()]\\n\\n# Set NaT values to the pandas NaT type\\ndf_episodes['original_air_date'] = df_episodes['original_air_date'].apply(lambda x: pd.NaT if pd.isna(x) else pd.to_datetime(x))\\n\\n# Limit the number of rows for faster execution\\nsample_size = 98000\\ndf_script = df_script.loc[:sample_size]\",\"Remove some special features of the datasets\",\"To find the top characters according to number of mentions.\\n# Getting only the lines of the script that are spoken by characters that exist in the characters dataframe.\\ndf_script = df_script[df_script.raw_character_text.isin(df_characters.raw_character_text)]\",\"Remove text data with incorrect or missing values\",\"Merge the datasets 'df_script' and 'df_episodes'\",\"Prepare sklearn vectorier with the correct tensor shape\\nfrom sklearn.feature_extraction.text import CountVectorizer\\nvectorizer = CountVectorizer()\",\" Display data\\nwith pd.option_context('display.max_rows', 10, 'display.max_columns', None, 'display.max_colwidth', 30):\\n    display(df_characters, df_locations, df_script, df_episodes)\",\"Create a shallow copy\\ndf_script_work = df_script.copy()\",\" Join structures\",\"Display some information about the characters dataframe\\nprint('Number of entries: ', df_characters.shape[0])\\nprint('Number of columns: ', df_characters.shape[1])\\nprint('\\\\nColumns with their datatypes:')\\nprint(df_characters.dtypes)\\nprint('\\\\nColumn names:')\\nprint(df_characters.columns)\\nprint('\\\\n')\",\"We can see the top of each dataframe by using the .head display method.\",\"Display spacy's name entity recognizer for a given sentence on adequate log level.\",\"Change the dataframe name for clarity\\ndf_episodes_copy = df_episodes.copy()\",\"Creating a backup of the script dataframe\\ndf_script_original = df_script.copy()\",\"# Display options\\npd.set_option('display.max_columns', None)\",\"Exploratory data analysis\",\"Let's look at an example to understand our data better.\",\"General configuration of library settings\\npd.set_option('display.max_columns', 50)\\nnlp = spacy.load('en_core_web_sm')\",\"By resetting the index, we ensure that our DataFrames start with index 0 and increase by 1 for each row.\",\"RP - Carga de m\\u00f3dulos adiconales\",\"Set plotting style\\nplt.style.use('fivethirtyeight')\",\"Split the raw data to train and test sets.\",\"Choose a specific dataframe to work with (e.g. df_characters, df_locations, df_script, df_episodes)\",\"Combining lines in a single message\\ndf_script['spoken_words'] = df_script.groupby('timestamp_in_ms')['spoken_words'].transform(lambda x: ' '.join(x))\\ndf_script = df_script.drop_duplicates(subset='timestamp_in_ms').reset_index(drop=True)\",\"Let's have a look at a snapshot of one of the datasets to understand its structure.\",\" Display the head of the script lines dataset\\ndf_script.head()\",\"Preview of the data\\nprint(df_script.head())\\nprint(df_characters.head())\\nprint(df_locations.head())\\nprint(df_episodes.head())\",\" Cleaning and merging the data\",\" First, let's take a look at the structure of the datasets.\",\" drop first column (Unnamed: 0) of all DataFrames\\ndf_characters.drop(columns=['Unnamed: 0'], inplace=True)\\ndf_locations.drop(columns=['Unnamed: 0'], inplace=True)\\ndf_script.drop(columns=['Unnamed: 0'], inplace=True)\\ndf_episodes.drop(columns=['Unnamed: 0'], inplace=True)\",\"Remove unused dataframes, clean script, save dataframe\",\"Choose a series of columns to use as metadata for our lines of dialogue.\",\"Enable f-strings in Python 3.6 and 3.7\\nfrom __future__ import annotations\",\"Infer the list of seasons based on the script\\nseasons = sorted(df_script['raw_text'].map(lambda x: int(x.split('_')[1])).unique())\\nseasons\",\" Checking how many script lines contain the word \\\"d'oh\\\"\",\"Set plot style\\nplt.style.use('fivethirtyeight')\",\"function to get the main character of an episode\",\"We will explore the dataset to understand the data better before we start working with it.\",\"Check fewesr phrases in a string\\nfewest_phrases_count = 3\",\"View first 5 rows of characters data\\ndf_characters.head()\",\"Filter out characters who have not been assigned to a location\\nvalid_characters = df_characters[df_characters['character_id'].isin(df_script['character_id'])]['name']\\ndf_script = df_script[df_script['character_id'].isin(df_characters['character_id'])]\",\"For the word cloud, we'll use spaCy for pre-processing and then Matplotlib for rendering.\",\"Check data shapes\\nprint(df_characters.shape)\",\"Merge script line with characters and locations\\ndf_script = df_script.merge(df_episodes[['id', 'season', 'number', 'title']], on='id', how='left')\",\"Initial examination of the data\",\"Declare tasks using TQDM\\ntqdm.pandas()\",\"Let's start by looking at some general statistics for our datasets.\",\"Merge the data into one dataframe for better visualization\",\"Define a function to print the n topics that we have fit in the model\\ndef print_topics(model, vectorizer, top_n=10):\\n    for idx, topic in enumerate(model.components_):\\n        print(\\\"Topic %d:\\\" % (idx))\\n        print([(vectorizer.get_feature_names_out()[i], topic[i])\\n                        for i in topic.argsort()[:-top_n - 1:-1]])\",\"Check the first few rows of each dataframe\\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()\",\"Remove all invalid schedule\\ndf_episodes = df_episods.dropna(subset=['original_air_date'])\",\" Merging data into one dataframe\",\" Visualize the number of episodes per season\\ndf_episodes['season'].value_counts().sort_index().plot(kind='bar')\",\" as we have large datasets at our disposal, we will print out the sizes of them so that we get the sense of how many records we have for each entity.\",\"import spacy\\n\\n# Load the large English NLP model\\nnlp = spacy.load('en_core_web_lg')\",\" The character that speaks the most\\ndf_script['character_id'].value_counts().idxmax()\",\"Preview our datasets\\nprint(df_characters.head())\\nprint(df_locations.head())\\nprint(df_script.head())\\nprint(df_episodes.head())\",\" Show the data from the top 3 datasets\\ndf_characters.head(), df_locations.head(), df_script.head()\",\"Checking the first 5 rows of each dataset\",\"Quick look at dataframe shape\\ndf_characters.shape, df_locations.shape, df_script.shape, df_episodes.shape\",\" Display a few basic details about the datasets.\",\"We will load and explore the data to get a first impression of the datasets.\",\"Create random forest classifier\",\"Merge the scripts with the speaker names and locations\",\"Preview the first 5 rows of each dataframe\\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()\",\"Start by cleaning the script lines data by removing any 'nan' values.\",\"Drop completely empty columns\\ndf_script = df_script.dropna(axis=1, how='all')\",\"Merge the 'simpsons_script_lines' dataframe ('df_script') with the 'simpsons_episodes' dataframe ('df_episodes') on the 'episode_id' column.\",\" Merge script lines with episodes and selected only the relevant columns\\ndf_merged = df_script.merge(df_episodes, on='episode_id')\\ndf_merged = df_merged[['id', 'episode_id', 'number', 'timestamp_in_ms', 'raw_text', 'spoken_words', 'timestamp_in_ms', 'character_id']]\\n\\n# Add the character and location names to the merged dataset\\ndf_merged = df_merged.merge(df_characters, left_on='character_id', right_on='id', suffixes=('_script', '_character'))\\ndf_merged = df_merged.merge(df_locations, left_on='location_id', right_on='id', suffixes=('_script', '_location'))\",\"let's take a look at the content of the first 5 lines (5 rows and all columns) of the lines dataset.\\ndf_script.head()\",\"Check the first few lines of each table\",\"Pandas default behavior is to do partial matches, so we need to be rigorous\\n# about the columns we in order to avoid ambiguity.\\ndf_characters = df_characters.filter(items=['index', 'real_name', 'real_name'])\\ndf_locations = df_locations.filter(items=['index', 'name'])\\ndf_episodes = df_episodes.filter(items=['id', 'title'])\",\" Now concatenate all individual episode dataframes into one dataframe for easier access and management.\",\"Check the dataframe shapes\",\"Clean up the scripts dataframe\\n# Remove unwanted columns\\ndf_script.drop(['id', 'episode_id', 'number', 'raw_text'], axis=1, inplace=True)\\n\\n# Missing dialogues\\ndf_script.dropna(subset=['character_id', 'location_id'], how='all', inplace=True)\\n\\n# Convert character_id and location_id to int\\ndf_script['character_id'] = df_script['character_id'].astype('Int64')\\ndf_script['location_id'] = df_script['location_id'].astype('Int64')\\n\\n# Reorder columns\\ndf_script = df_script[['character_id', 'location_id', 'timestamp_in_ms', 'speaking_line', 'spoken_words']]\",\"First, we start by making some basic \\\"exploratory data analysis\\\" (EDA) of the dataset.\",\"Check dataframe sizes\\ndf_episodes.shape, df_characters.shape, df_script.shape, df_locations.shape\",\"# Display the head of the dataframe to have a first look at its content\\ndf_script.head()\",\"View the shape of these dataframe\",\" Let's inspect the head of each dataframe to make sure all the columns were read in correctly.\",\" Some configurations for displaying datasets in an easily readable way\\npd.set_option('display.max_columns', None)\",\"hint: use the first few rows of the dataframe again to refresh your memory\\ndf_characters.head()\",\"Merge Simpsons script lines with character information\\ndf_script['character_name'] = df_script['character_id'].map(df_characters['name'])\\ndf_script.head()\",\"Let's take a look at the first few rows of each dataframe to understand what kind of data we are dealing with.\",\"characters = df_characters.copy()\\nlocations = df_locations.copy()\\nscript = df_script.copy()\\nepisodes = df_episodes.copy()\",\"Display the first 5 rows of the characters dataset\\ndf_characters.head()\",\"Print the number of script lines in the dataset\\nprint(f\\\"Number of script lines: {df_script.shape[0]}\\\")\",\" Set option to display all columns in dfs\\npd.set_option('display.max_columns', None)\",\"from gensim.test.utils import common_texts\\nfrom gensim.corpora.dictionary import Dictionary\",\"Store the raw data as a global variable for easier access later on\\nRAW_DATA = {\\n    'characters': df_characters,\\n    'locations': df_locations,\\n    'script': df_script,\\n    'episodes': df_episodes\\n}\",\"replace all regular expression matches with '\\\\n';\\ndf_script['speaking_line'] = df_script['raw_text'].str.replace('[^\\\\w\\\\s]','\\\\n').str.lower();\",\"Merge Simpsons script lines with character and location information\\ndf_script_char = df_script.merge(df_characters, on='character_id', suffixes=('', '_char'))\\ndf_script_loc = df_script_char.join(df_locations.rename({'location_id':'raw_location_text'}, axis=1).set_index('raw_location_text'), on='raw_location_text')\",\"Let's preview the data in each DataFrame to ensure everything loads correctly.\",\"Associate spoken lines to characters and merge with episode information\\nmask = df_script['character_id'].isin(df_characters['id'])\\ndf_script = df_script[mask]\\n\\ndf_script = df_script.merge(\\n    df_episodes,\\n    how='left',\\n    left_on='episode_id',\\n    right_on='id')\",\"Join the data frames\",\"Check the style of the dataframes' columns for DataFrame df_script\",\"Print something in a random cell\",\"Inspect the first few lines of each dataframe to understand their structure and the type of data they contain.\",\" First, to understand the data, we want to show the first and last row of each dataframe.\",\"Check the files have been loaded correctly\\nprint(\\\"Characters: \\\\t\\\", df_characters.shape)\\nprint(\\\"Locations: \\\\t\\\", df_locations.shape)\\nprint(\\\"Script: \\\\t\\\", df_script.shape)\\nprint(\\\"Episodes: \\\\t\\\", df_episodes.shape)\",\" Remove columns without a name\\ndf_characters = df_characters[df_characters.character_name.notnull()]\\ndf_locations = df_locations[df_locations.location_name.notnull()]\",\"Checking first rows for each file\\nprint(df_characters.head())\\nprint(df_locations.head())\\nprint(df_script.head())\\nprint(df_episodes.head())\",\"Let's start by examining the data.\",\" View the first rows of the characters dataframe\\ndf_characters.head()\",\"Check the first few rows of each dataframe in the dataset\\nprint(\\\"Character dataset\\\")\\nprint(df_characters.head())\\nprint(\\\"\\\")\\nprint(\\\"Locations dataset\\\")\\nprint(df_locations.head())\\nprint(\\\"\\\")\\nprint(\\\"Script lines dataset\\\")\\nprint(df_script.head())\\nprint(\\\"\\\")\\nprint(\\\"Episodes dataset\\\")\\nprint(df_episodes.head())\",\"Check if the imports and data are loaded properly\\nprint('Characters:', df_characters.shape)\\nprint('Locations:', df_locations.shape)\\nprint('Script:', df_script.shape)\\nprint('Episodes:', df_episodes.shape)\",\"Drop rows with empty or missing dialogue in df_script\\ndf_script = df_script.dropna(subset=['normalized_text'])\\ndf_script = df_script[df_script['normalized_text']!='']\\n# (Optional: drop some other columns we won't use in this example to save memory)\\ncolumns_to_drop = ['id', 'episode_id', 'number', 'raw_text', 'timestamp_in_ms', 'speaking_line', 'character_id', 'location_id', 'original_text', 'raw_character_text', 'raw_location_text', 'spoken_words', 'normalized_text', 'word_count']\\ndf_script = df_script.drop(columns=columns_to_drop)\",\"Inspect the dataframes to understand the structure and content of the data.\",\"Show some script lines\\ndf_script.head(10)\",\"Create a new column containing the full name of the character\",\"Filter out transcriptions that doesn't have the characters' name.\",\"Check the basic info of the datasets\\nprint(\\\"Characters : \\\", df_characters.shape)\\nprint(\\\"Locations : \\\", df_locations.shape)\\nprint(\\\"Script : \\\", df_script.shape)\\nprint(\\\"Episodes : \\\", df_episodes.shape)\",\"remove the duplicates from the characters and locations dataframes since these are tables that map to the scripts dataframe and the episodes dataframe\",\"Define the base directory where the NLP model is saved\\nnlp_base_dir = \\\"C:\\u002fnlp_model\\\"\",\"\\n# Convert character_id to int\\ndf_script['character_id'] = df_script['character_id'].astype('Int64')\\n\\n# Create a column containing only the year of the episode\\ndf_episodes['year'] = df_episodes['original_air_date'].str[:4]\",\" Drop dialogues in scenes as the same scene can be in multiple episodes\",\"quick look at the characters dataframe\\nprint(f'Size of the dataframe: {len(df_characters)}')\\ndf_characters.head()\",\"Split the script into individual lines, i.e. split the script into lines and append them to a list\",\"Let's start by looking at the structure of the databases we have just loaded.\",\"Character level analysis\\n# Let's try to identify who talks the most\\n\\n# Count characters\\ndf_script['character_id'].value_counts().head(10)\",\"Filtering the data to retain only the lines from the Simpsons character named 'Marge'\",\"Check the size of the dataframes\\ndf_characters.shape, df_locations.shape, df_script.shape, df_episodes.shape\",\"Filter only 10 most common locations\\ntop10locations = ['Simpson Home', 'Moe\\\\'s Tavern', 'Springfield Elementary School', 'Kwik-E-Mart', 'Power Plant', \\n                  'Springfield Nuclear Power Plant', 'Springfield Town', 'First Church of Springfield', \\n                  'Simpson Living Room', 'Springfield Street']\\ndf_script_top10locations = df_script[df_script.raw_location_text.isin(top10locations)]\",\"# Dataframes first glance\\nprint(df_characters.head())\\nprint(df_locations.head())\\nprint(df_script.head())\\nprint(df_episodes.head())\",\"ast values to check the data loaded correctly\\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()\",\" show first 5 lines of each dataframe\\nfor name, df in zip(['Characters', 'Locations', 'Script', 'Episodes'], [df_characters, df_locations, df_script, df_episodes]):\\n    print(name)\\n    print(df.head(), '\\\\n\\\\n')\",\"What's inside each dataset?\",\"Data overview\",\" Check out the first entries for each dataframe\\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()\",\"Selecting relevant columns and dropping rows with NaN\\ndf_script = df_script[['episode_id', 'number', 'raw_text']].dropna()\",\"df_script = df_script.drop(['index'], axis=1)\",\"Renaming user columns\",\"Clean the script data\\ndf_script_cleaned = df_script[\\n    (df_script['springfield_id'] \\u003c= df_locations.shape[0]) &\\n    (df_script['id'] \\u003c 200000) &\\n    (df_script['location_id'] \\u003c= df_locations.shape[0]) &\\n    (df_script['normalized_text'].apply(lambda x: isinstance(x, str))) &\\n    (df_script['character_id'] \\u003c= df_characters.shape[0])\\n]\",\"Check the first few rows of each dataframe to see what data they contain.\",\"Drop the \\\"id\\\" column, this will be redundant since we will use the index as identifier\",\" You can install or update required packages as per the context.\",\"Let's start by displaying some general information about the datasets.\",\"Extract main characters\\nmain_characters = df_characters[df_characters['normalized_name'].notnull()].copy()\\nmain_characters = main_characters['normalized_name'].str.lower().values.tolist()\",\"We'll first take a look at the structure and the first few rows of these datasets.\",\"Count the characters that have spoken in the show.\",\"Checking the data types for each dataframe\",\" Merge simpsons_script_lines with simpsons_episodes and simpsons_characters\\ndf_script['id'] = range(df_script.shape[0])\\ndf_episodes_script = pd.merge(df_script, df_episodes, on=\\\"episode_id\\\")\\ndf_episodes_script_characters = pd.merge(df_episodes_script, df_characters, left_on=\\\"raw_character_text\\\", right_on=\\\"name\\\")\",\"Display first few rows of the characters dataframe\\ndf_characters.head()\",\"acketed text is placeholder content from the original Python file.\",\" Check the format of the datasets\\nprint(\\\"Characters dataset:\\\")\\nprint(df_characters.head())\\nprint(\\\"\\\\nLocations dataset:\\\")\\nprint(df_locations.head())\\nprint(\\\"\\\\nScript dataset:\\\")\\nprint(df_script.head())\\nprint(\\\"\\\\nEpisodes dataset:\\\")\\nprint(df_episodes.head())\",\"The three first DataFrame have an unwanted column\\ndel df_characters['Unnamed: 0']\\ndel df_locations['Unnamed: 0']\\ndel df_script['Unnamed: 0']\",\"Getting rid of the NaN values for both `location_id` and `normalized_text`\",\"Load the pre-trained spaCy model for English language\\nnlp = spacy.load(\\\"en_core_web_sm\\\")\",\"Merge the character and location information into the script dataframe\\ndf_script = df_script.join(df_characters.set_index('id'), on='character_id')\\ndf_script = df_script.join(df_locations.set_index('id'), on='location_id')\",\" Let's display the head of each dataframe to get a sense of its structure.\",\"Inspect the characters dataset\\nprint(df_characters.shape)\\ndf_characters.head()\",\"It would be helpful to display the first few rows of each dataframe to get an idea of the data.\",\"Set GPU usage to 30% to limit the resources used\\nos.environ['CUDA_VISIBLE_DEVICES'] = '0'\",\" Split the text in a list of words\\nwords = script_lines[1].str.split(\\\" \\\")\",\"Check if all data has been imported correctly\\ndf_characters.head()\",\"EDA\\n\\n# Investigate the number of unique characters, locations and episodes\\nnum_characters = df_characters['name'].nunique()\\nnum_locations = df_locations['name'].nunique()\\nnum_episodes = df_episodes['title'].nunique()\\n\\nnum_characters, num_locations, num_episodes\",\"check the data types in each column\\ndf_script.dtypes\",\"Setting the index of the datasets\",\"Check the first records of df_characters, df_locations, df_script and df_episodes to see what kind of data we are dealing with\",\"Detect which episode each line of the script is from\\nepisodes_list = []\\n\\nfor index, row in tqdm(df_script.iterrows()):\\n    mask = df_episodes['id'] == row['episode_id']\\n    episode = df_episodes[mask]\\n    episode = episode.to_dict(orient='records')[0]\\n    episodes_list.append(episode)\",\"Check the first entries of each DataFrame\\ndisplay(df_characters.head())\\ndisplay(df_locations.head())\\ndisplay(df_script.head())\\ndisplay(df_episodes.head())\",\" Check of the data\\nprint(df_episodes.head())\\nprint(df_script.head())\",\"Create a smaller dataframe, capturing only the season 1, episode 1 rows.\",\"Checking the first 5 rows of the script DataFrame\\ndf_script.head()\",\"Display first few rows of the characters dataframe\\ndf_characters.head()\",\"Create a spaCy nlp object\\nnlp = spacy.load('en_core_web_sm')\",\" Display first few rows of characters data\\ndf_characters.head()\",\"Data\\ndf_characters.head()\",\"Function to display the Word Clouds\",\"Define the relationship between: df_script \\u003c-\\u003e df_episodes \\u003c-\\u003e df_characters\",\"Install the spacy 'en' model to preprocess the text.\",\"Let's check the content of the dataset\",\"Filter list of characters in the scripts to only include the main characters\",\"Load data and display overview\",\"Feature selection\\ndf_script = df_script[['episode_id', 'number', 'raw_text', 'character_id', 'location_id']]\\ndf_episodes = df_episodes[['id', 'title', 'original_air_date']]\",\"Inspect the first 5 rows of each dataframe to understand what kind of information it contains.\",\"Funnel script dataset into more manageable dataframe\",\"Extract and display characters, locations, episodes and script data\\nprint(\\\"\\\\n-- Characters --\\\")\\nprint(df_characters.head())\\n\\nprint(\\\"\\\\n-- Locations --\\\")\\nprint(df_locations.head())\\n\\nprint(\\\"\\\\n-- Episodes --\\\")\\nprint(df_episodes.head())\\n\\nprint(\\\"\\\\n-- Script Lines --\\\")\\nprint(df_script.head())\",\"convert character_id to integer\\ndf_script['character_id'] = pd.to_numeric(df_script['character_id'], errors='coerce').astype('Int64')\",\"We can begin by exploring the different datasets and understanding their structure and content.\",\"Create a mapping of characters to their gender.\",\"Check first 5 rows of each dataset\",\" Join the data together\\ndf_script = df_script.join(df_episodes, on='episode_id', rsuffix='_episode', how='left')\\ndf_script = df_script.join(df_characters, on='character_id', rsuffix='_character', how='left')\\ndf_script = df_script.join(df_locations, on='location_id', rsuffix='_location', how='left')\\n\\n# Keep relevant columns\\ndf_script = df_script[['id', 'number', 'raw_text', 'timestamp_in_ms', 'speaking_line',\\n                       'episode_id', 'name_episode', 'original_air_date', 'production_code',\\n                       'season', 'number_in_season', 'number_in_series',\\n                       'character_id', 'name_character', 'normalized_name_character', 'gender',\\n                       'location_id', 'name_location', 'normalized_name_location']]\",\" After importing the necessary libraries and loading the datasets, we can start examining the data to understand its structure and contents.\",\"# Show first 5 rows of the characters dataframe\\ndf_characters.head()\",\"Print the first 3 rows of the characters dataset\\nprint(df_characters.head(3))\",\" Remove bad data points\\ndf_script = df_script[df_script.sentence.str.len() \\u003e 1]\",\" Remove problematic series clone (due to successive manipulations)\\nif 'Unnamed: 0' in df_characters:\\n    df_characters = df_characters.drop(columns=['Unnamed: 0'])\",\"Extract Locations and Character locations from script lines\\nlocations = df_script.raw_location_text.dropna().tolist()\\ncharacters = df_script.raw_character_text.dropna().tolist()\",\" Display a sample of the data in each dataframe to understand its structure and the kind of data it contains\\nprint(\\\"Characters\\\")\\nprint(df_characters.head(5))\\nprint(\\\"Locations\\\")\\nprint(df_locations.head(5))\\nprint(\\\"Script\\\")\\nprint(df_script.head(5))\\nprint(\\\"Episodes\\\")\\nprint(df_episodes.head(5))\",\"Limiting the amount of characters to load, for performance reasons\\nMAX_CHARACTER = 50\\n\\n#Some lines have NAs, let's get read of them\\ndf_script = df_script.dropna(subset=['raw_character_text', 'spoken_words'])\\n\\n# Distribution of characters\\nchar_counter = Counter(df_script['raw_character_text'])\\n\\n# Make sure that the most common characters are valid ones\\nfor k in char_counter:\\n    if k not in df_characters[\\\"Character\\\"].values:\\n        print(k)\",\"Turn: sample the data\\npd.set_option('display.max_columns', None)\\nprint(df_characters.head())\\nprint(df_locations.head())\\nprint(df_script.head())\\nprint(df_episodes.head())\",\"\\nscript_simpsons = df_script.copy()\",\"Start by filtering only the dialogues by Homer Simpson.\",\"Remove unnecessary large strings from the loaded objects\\ndf_script = df_script.drop('text', axis=1)\",\" Merge episodes with script\\ndf_episodes_script = df_episodes.set_index('id').join(df_script['episode_id'].value_counts().sort_index(), how='outer').rename(columns={'episode_id': 'script_lines_count'})\",\"View the script dataframe\\ndf_script.head()\",\"Fix character_id datatype\\ndf_script['character_id'] = pd.to_numeric(df_script['character_id'], errors='coerce').astype('Int64')\",\" Observe first entries of the provided data\\ndfs = {\\n    \\\"Characters\\\": df_characters,\\n    \\\"Locations\\\": df_locations,\\n    \\\"Script lines\\\": df_script,\\n    \\\"Episodes\\\": df_episodes\\n}\",\"Find the top 10 characters which are most active in the dialogue.\",\"Selecting relevant columns and renaming index column\",\" Check the size and structure of each dataframe\\nprint(\\\"Characters:\\\", df_characters.shape)\\nprint(\\\"Locations:\\\", df_locations.shape)\\nprint(\\\"Script:\\\", df_script.shape)\\nprint(\\\"Episodes:\\\", df_episodes.shape)\",\"Create the list of documents (each document is a line of the script)\\ndocuments = df_script['raw_text'].fillna('xxx').values\",\"Explore the data and generate statistics\",\"Check the size of our datasets\",\"Create the nlp object\\nnlp = spacy.load('en_core_web_sm')\",\"First five rows of the dataset\\ndf_script.head(), df_characters.head(), df_locations.head()\",\"View the structure of the data.\",\"\\n# Filter non-English lines\\ndf_script_en = df_script[df_script['raw_character_text'].notnull()\\n                        & df_script['raw_location_text'].notnull()\\n                        & df_script['spoken_words'].notnull()  \\n                       ].copy()\\n\\n# keep only lines by English-speaking characters in English locations\\nlocation_en = df_locations[df_locations['normalized_name'].str.contains('[A-Za-z]', na=False)].copy()\\ncharacters_en = df_characters[df_characters['normalized_name'].str.contains('[A-Za-z]', na=False)].copy()\",\" Displaying the number of unique values in each column\",\"Inspect the head of the dataframes to understand their structure and contents\\nprint(df_characters.head())\\nprint(df_locations.head())\\nprint(df_script.head())\\nprint(df_episodes.head())\",\"Merge the dialogues with the characters and episodes\",\"Visualizations\\n# Number of words per character\\nword_counts = {\\n    character: len(dialog.split())\\n    for character, dialog in zip(df_script.raw_character_text, df_script.raw_text)\\n}\\n\\n# Number of words per location\\nlocation_word_counts = {\\n    location: sum(len(dialog.split()) for dialog in df_script[df_script.raw_location_text == location].raw_text)\\n    for location in df_script.raw_location_text.unique()\\n}\",\"Simplify episode titles\\ndef clean_title(title):\\n    return (\\n        title.lower()\\n        .replace(\\\"the simpsons\\\", \\\"\\\")\\n        .replace(\\\": part \\\", \\\" \\\")\\n        .replace(\\\":\\\", \\\" \\\")\\n        .replace(\\\"(\\\", \\\"\\\")\\n        .replace(\\\")\\\", \\\"\\\")\\n        .strip()\\n    )\\n\\ndf_episodes['clean_title'] = df_episodes['title'].apply(clean_title)\",\"to make it easier to join on the episode\\ndf_script['id'] = df_script['episode_id']\",\"Select only rows with canonical values of 1\\ndf_script = df_script[df_script[\\\"raw_text\\\"].notna()]\",\"Merge the script data with the episode data\\ndf_merged = df_script.merge(df_episodes, on='episode_id')\\n\\n# Filter out the bad rows and columns\\ndf_merged = df_merged[(df_merged.notnull().all(axis=1)) & (df_merged['word_count'].notnull())]\\ndf_merged = df_merged.query('word_count \\u003e 0')\\n\\n# Filter out rows where the character is not a Simpson\\ndf_merged = df_merged[df_merged['raw_character_text'].map(lambda x: 'simpson' in x.lower())]\",\"Attributes types to columns\\ndf_script['id'] = df_script['id'].astype('string')\\ndf_script['episode_id'] = df_script['episode_id'].astype('string')\\ndf_script['number'] = df_script['number'].replace('?', np.nan).astype(float)\\ndf_script['raw_text'] = df_script['raw_text'].astype('string')\\ndf_script['timestamp_in_ms'] = df_script['timestamp_in_ms'].replace('?', np.nan).astype(float)\",\"Convert string representation of list of episodes into a list of integers\\ndf_episodes['us_viewers_in_millions'] = df_episodes['us_viewers_in_millions'].apply(lambda x: float(x) if x != 'na' else np.nan)\\ndf_episodes['views'] = df_episodes['views'].apply(lambda x: x if x != 'na' else np.nan)\",\"Import the necessary pre-processing and feature extraction libraries.\",\"Simplify DataFrames for better this tutorial\\ndf_script = df_script[[\\\"episode_id\\\", \\\"character_id\\\", \\\"location_id\\\", \\\"normalized_text\\\"]].dropna()\",\"Check the contents and sizes of each dataframe\\nprint(\\\"Characters\\\")\\nprint(df_characters.head())\\nprint(df_characters.shape)\\n\\nprint(\\\"Locations\\\")\\nprint(df_locations.head())\\nprint(df_locations.shape)\\n\\nprint(\\\"Script\\\")\\nprint(df_script.head())\\nprint(df_script.shape)\\n\\nprint(\\\"Episodes\\\")\\nprint(df_episodes.head())\\nprint(df_episodes.shape)\",\"Display first rows of the characters table\\ndf_characters.head()\",\" Split the \\\"raw_text\\\" column according to dialogue_BEGIN and _END\",\"Quick look at the dataframes\\ndf_characters.head(3)\",\"First, let's start by looking at some general information about the datasets.\",\"Inspecting these DataFrames will help us understand what kind of information is available and how it is structured.\",\"Remove useless df_script columns\\ndf_script = df_script.drop(columns=[\\n    'id',  # id is useless\\n    'norm_id',  # not sure what this is\\n    'episode_id',  # seems to be irrelevant as it corresponds to the index\\n    'number',  # seems to be the same than index without 1\\n    'raw_text',  # is already in text and speaking_line\\n    'timestamp_in_ms',  # not interested in time\\n    'speaking_line',  # we don't want to keep 1 because simpsons always have speaking lines\\n    'character_id',  # not interested in the ID\\n    'location_id',  # not interested in the ID\\n    'raw_text',  # is already in text and speaking_line\\n    'spoken_words',  # not interested in having the actual text._pla\\n    'word_count'  # we will calculate it ourselves\\n])\",\" Merge episodes in each dataframe for consistency\",\"Create syntax highlighting across all text and not just strings\\nmatplotlib.rcParams['syntax.note_color']='#AA0000'\",\"Let's start by doing some basic data exploration to get a better understanding of the datasets.\",\" Check the first few rows for each dataframe\\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()\",\"Extract information\\nseasons = df_episodes['season'].unique()\",\"Merge the tables to have more information in one table\",\"Extract the list of main characters from the DataFrame\",\"Check the CSV files have been read correctly, view them, and if needed, drop columns indices with inplace = True and reset column indices.\",\"Fix ids\\ndf_script['character_id'] = df_script['character_id'].fillna(-1).astype(int)\\ndf_script['location_id'] = df_script['location_id'].fillna(-1).astype(int)\",\"Explore the first few rows of each dataframe\\nprint(df_characters.head())\\nprint(df_locations.head())\\nprint(df_script.head())\\nprint(df_episodes.head())\",\"Split data into training and testing sets\\ndf_script['split'] = np.random.randn(df_script.shape[0], 1)\\n\\n# 80% train, 20% test\\nm = np.percentile(df_script['split'], 80)\\ndf_train = df_script[df_script['split'] \\u003c m]\\ndf_test = df_script[df_script['split'] \\u003e= m]\",\" Join all data frames into a single one.\",\"Merge the datasets and display the first few rows\",\" Limit the number of rows in the dataframes for faster processing during development\\n# If processing power is not an issue, these lines can be commented out\\ndf_characters = df_characters.head(500)\\ndf_locations = df_locations.head(500)\\ndf_script = df_script.head(500)\\ndf_episodes = df_episodes.head(500)\",\"Test print of the first few lines of each imported dataframe\\nprint(df_characters.head())\\nprint(df_locations.head())\\nprint(df_script.head())\\nprint(df_episodes.head())\",\"Clean gcs authentication so it doesn't throw a user warning because we are not going to use GCS in this example\\nos.environ['GOOGLE_APPLICATION_CREDENTIALS'] = ''\",\" Let's check the structure of the datasets\",\"Declare the path where the spacy model will be saved\\nnlp_path = 'data\\u002fspacy_model'\",\"display all columns of the dataframe\\npd.set_option('display.max_columns', None)\",\"Explore the datasets to understand their structure and the information they contain.\",\" Import the Gensim summarization module\\nfrom gensim.summarization import summarize\",\"View the first few rows of the characters data\\ndf_characters.head()\",\"To avoid potential confusion and potential performance issues in your code, it is recommended to use the .copy() method when creating the new dataframes to avoid having views on the original dataframes.\",\"Variable declaration\\nnlp = spacy.load(\\\"en_core_web_sm\\\")\\n\\ntqdm.pandas()\",\"Let's take a look at the first few rows of each dataframe to understand the data better.\",\" set random seed for consistency\\nnp.random.seed(0)\",\"Drop the first column, which is just the row index.\",\"Set the style of matplotlib plots\",\" Setting the environments seed for reproducibility\\nnp.random.seed(1)\",\"You can also check the first couple of lines of each dataframe to have an idea of what kind of data they contain:\",\"Remove unnecessary columns\\ndf_characters = df_characters[['id', 'name']]\\ndf_locations = df_locations[['id', 'name']]\\ndf_episodes = df_episodes[['id', 'title', 'original_air_date']]\",\" Preview each loaded dataset\",\"Display settings for large data\\npd.set_option('display.max_columns', None)\",\"Optional: Display the first few lines of each dataset to understand its structure\\ndf_characters.head()\",\"function that generate a word cloud from a given text\",\" Display a sample of the dataset\\ndf_script.head()\",\"Filter the dataset to keep only the standard episodes (Simpsons TV show)\",\"to do\\n# - Take into account the compound name of some characters\\u002flocations in the script\\n# - apply the above points to the script\\n# - count which characters appear in the most locations & vice versa\\n# - sentiment analysis for reviews\\n# - topic analysis for the reviews\",\"Explorating the first 5 rows of the characters dataset\\ndf_characters.head(5)\",\"Visualize the distribution of characters' genders in the dataset\",\" Display the first few records of the dataframe\\ndf_script.head()\",\"Merge episodes and script dataframes\",\"Set current directory\\nos.chdir('C:\\u002fUsers\\u002fNicolas\\u002fGoogle Drive\\u002f0 - Udacity\\u002f7 - Data Engineering Capstone\\u002f')\",\"1. Load Data and get an overview\",\"Check the correct loading of the `characters` dataframe\\ndf_characters.head()\",\"Displays the first 5 entries for each table\\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()\",\"Check availability of GPU\\nimport tensorflow as tf\\nfrom tensorflow.python.client import device_lib\\n\\n# Check all available devices if GPU is available\\nprint(device_lib.list_local_devices())\",\" Select only the lines with characters\\ndf_script_with_characters_info = df_script.loc[~df_script[\\\"normalized_text\\\"].isna()].merge(\\n    df_characters,\\n    how=\\\"inner\\\",\\n    left_on=\\\"raw_character_text\\\",\\n    right_on=\\\"raw_character_text\\\"\\n)\",\"Set matplotlib style\\nmatplotlib.rcParams['font.size'] = 18\\nmatplotlib.rcParams['figure.figsize'] = (15, 10)\",\"## Initial inspection of the data\",\"Setting seed for reproducibility\\nnp.random.seed(0)\",\" Show the first 5 rows of each dataframe to verify that everything has been loaded properly\\nprint(df_characters.head())\\nprint(df_locations.head())\\nprint(df_script.head())\\nprint(df_episodes.head())\",\"Check if the dataframes were imported correctly\\ndf_characters.head()\",\" Create a list with all tag types.\\ntag_list = list(df_script['raw_character_text'])\\n\\n# Remove duplicates.\\ntag_set = set(tag_list)\\n\\n# Output the number of tag types.\\nnum_tag_types = len(tag_set)\\nprint(f'Number of unique character tags: {num_tag_types}')\",\" Characters present in the script\\ncharacters_present = df_script['character_id'].unique()\",\"Inspecting the first entries of the dataset\",\" Remove non-dialogue rows and unnecessary columns\\ndf_script_filtered = df_script[df_script['speaking_line'] == True].reset_index(inplace=False, drop=True)\\ndf_script_filtered = df_script_filtered[['episode_id', 'character_id', 'location_id', 'raw_text']]\",\" I'm going to start by showing the first 5 rows of the 4 dataframes to get an understanding of the data.\",\"Count number of lines by character ID and script ID.\\nlines = df_script.groupby(['character_id', 'episode_id']).apply(lambda x: ' '.join(x['spoken_words'].astype(str)))\",\"Remove the rows with missing values.\",\"We define the data as \\\"raw\\\" since it has not been processed.\\nraw_script = df_script.copy()\",\"Display all the tables in the dataset\\nwith pd.option_context('display.max_rows', None, 'display.max_columns', None):\\n    print(df_characters.head())\\n    print(df_locations.head())\\n    print(df_script.head())\\n    print(df_episodes.head())\",\"Discover and display some basic informations about the data\",\" We'll start with loading the datasets and understanding their structure, before moving on to the NLP analysis.\",\"Inspect items\\ndf_script['raw_character_text'].value_counts()\",\"# Dress dataset\",\"Start by exploring the content of the dataset.\",\"Set up the matplotlib figure\",\"This assumes that the folder `data` is located in the same directory as this notebook.\",\"Create a new directory called \\\"visualizations\\\" to store the visualizations we will create\",\"Merge 'simpsons_script_lines.csv' with 'simpsons_characters.csv' based on `character_id`\\ndf = df_script.merge(df_characters, on='character_id', how='left')\",\"Merge location and episode data with the script data\\ndf_merged = df_script.merge(df_episodes, on='episode_id').merge(df_locations, on='location_id')\\n\\n# Show a preview\\ndf_merged.head()\",\"Select rows where \\\"raw_text\\\" contains \\\"donut\\\"\\ndf_script_donuts = df_script[df_script['raw_text'].str.contains('donut')]\",\"First, let's take a look at the first few rows of each of these dataframes to understand the kind of data we are dealing with.\",\"The data is now loaded into dataframes, let's take a quick look at the structure of each dataframe.\",\"Ensure the episode_id is a string\\ndf_script['episode_id'] = df_script['episode_id'].astype(str)\",\"What are the shapes of the datasets?\",\"Count the number of times each character speaks and plot the 10 most common ones.\",\"Let's take a look at the structure of the dataframes and the first few rows:\",\"Let's start by displaying a sample of each dataframe.\",\"Previewing the data.\",\"Display some sample data\",\"Lets check how the data looks like.\",\"View first 5 rows of the characters dataframe\\ndf_characters.head()\",\"Install the nlargest package if you haven't yet.\\n# You can do this in your terminal with the command `pip install nlargest`.\\nfrom nlargest import NLargest\",\" Seems good, let's move on.\",\"Character names\\ncharactersdf = [name.lower() for name in list(df_characters['character_name'])]\",\"Create a WordCloud of the script_lines in the field spoken_words.\",\"Character name and season columns are currently camel case, let's standardize to snake case by renaming the columns\",\"# Using spaCy's pre-built NLP model\\nnlp = spacy.load(\\\"en_core_web_sm\\\")\",\"Preview datasets structure\\nprint('Characters')\\nprint(\\\"shape:\\\", df_characters.shape)\\nprint(df_characters.head())\\nprint('---------------------------------------')\\n\\nprint('Locations')\\nprint(\\\"shape:\\\", df_locations.shape)\\nprint(df_locations.head())\\nprint('---------------------------------------')\\n\\nprint('Episodes')\\nprint(\\\"shape:\\\", df_episodes.shape)\\nprint(df_episodes.head())\\nprint('---------------------------------------')\\n\\nprint('Script lines')\\nprint(\\\"shape:\\\", df_script.shape)\\nprint(df_script.head())\",\" Visualizations for different parts of the dataset\\nfig, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize=(15, 5))\\ndf_script.groupby('character_id').size().sort_values(ascending=False).head(10).plot(kind='bar', ax=ax1, title='Top 10 most lines spoken')\\ndf_script.groupby('location_id').size().sort_values(ascending=False).head(10).plot(kind='bar', ax=ax2, title='Top 10 locations with most lines')\\ndf_script.groupby('episode_id').size().plot(kind='bar', ax=ax3, title='Number of lines per episode')\\n\\n# Remove last xlabel as it is overlapping with the next plot\\nax1.set_xlabel('')\\nax2.set_xlabel('')\\nfig.tight_layout()\",\"Set basic configurations for visualization\\nmatplotlib.rcParams['figure.figsize'] = [12, 8]\\nmatplotlib.rcParams['font.size'] = 12\",\"Rename some of the columns for clarification.\",\"Setting the path to the Simpsons dataset folder\",\"Display settings\\npd.options.display.max_columns = 50\",\"First we will need to do a bit of cleanup of the dataset in order to work with it.\",\"Show the first 5 lines of the \\\"df_script\\\" dataframe.\",\"Inspect the first few rows of each dataframe to understand the data better.\",\" Print the first few rows of each dataframe to understand their structure\\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()\",\"# Merge lines and character df; only keep lines by Simpsons characters\\ndf_character_lines = df_script.merge(df_characters, how='inner', on='character_id')\",\"Select episode of interest\\nepisode_of_interest = 'Simpsoncalifragilisticexpiala(AnnoyedGrunt)cious'\",\" Display the first few rows of the datasets\\nprint(\\\"Characters Dataset\\\")\\ndisplay(df_characters.head())\\n\\nprint(\\\"Locations Dataset\\\")\\ndisplay(df_locations.head())\\n\\nprint(\\\"Script Dataset\\\")\\ndisplay(df_script.head())\\n\\nprint(\\\"Episodes Dataset\\\")\\ndisplay(df_episodes.head())\",\"Create a list of documents, one per episode, and a dataframe containing each episode title\",\"Show all available columns, including the index\",\"check dataframe shape\\ndf_characters.shape\",\"# Ensure the script dataframe is not holding a lot of memory.\\ndf_script.drop(['norm_text', 'timestamp_in_ms', 'speaking_line'], axis=1, inplace=True)\",\"This is a csv file that contains meta information about episodes.\",\"# merge tables to have access to all the information contained in the different files\\ndf_script_location = pd.merge(df_script, df_locations, left_on='location_id', right_on='id')\\ndf_script_location_character = pd.merge(df_script_location, df_characters, left_on='character_id', right_on='id')\\ndf_script_location_character_episode = pd.merge(df_script_location_character, df_episodes, left_on='episode_id', right_on='id')\\n\\n# remove rows with missing lines\\ndf_script_location_character_episode = df_script_location_character_episode.dropna(subset=['normalized_text'])\\n\\n# Sort lines by original air date\\ndf_script_location_character_episode['original_air_date'] = pd.to_datetime(df_script_location_character_episode['original_air_date'])\\ndf_script_location_character_episode = df_script_location_character_episode.sort_values('original_air_date')\\n\\n# Print the first few rows\\ndf_script_location_character_episode.head()\",\"Get recent records from single episode per row\\ndf_script = df_script.sort_values('id', ascending=True)\",\"# Display the dataframe\\n\\nprint(df_characters.head())\",\"Add some additional cleaning and encoding steps to our dataframes\",\"Limiting to the lines with valid character and location ids\\ndf_script = df_script[df_script.character_id.isin(df_characters.id) & \\n                      df_script.location_id.isin(df_locations.id)]\",\" Check the first 5 rows of the script dataframe\\ndf_script.head()\",\"Joining the datasets on the common columns to be able to analyze the text based on other columns is an important step in this data pre-processing.\",\"Replace NaN values with appropriate ones\",\" View table top to understand data\\ndf_characters.head()\",\"Combining script data with other datasets\",\"Merge df_script, df_episodes and df_characters to provide all the necessary data in one DataFrame\",\"Keep only some locales from the script lines dataframe\",\" Examine the script data to get more familiar with it\\ndf_script.head()\",\"Create client for speech recognition service.\",\" Remove badly formatted rows from episodes and script tables\",\" Show dataframe shapes\\ndf_characters.shape, df_locations.shape, df_script.shape, df_episodes.shape\",\"Check what the dataset looks like\\nprint(df_characters.head())\\nprint(df_locations.head())\\nprint(df_script.head())\\nprint(df_episodes.head())\",\"Display the first few rows of each dataframe to verify that the data was loaded correctly\\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()\",\"Get a list of all the regular characters in the show.\",\"Display the first 5 rows of each dataframe\\ndfs = [df_characters, df_locations, df_script, df_episodes]\\nfor df in dfs:\\n    display(df.head())\",\"Color for the different characters\\ncolors = ['hsl('+str(h)+',50%'+',50%)' for h in np.linspace(0, 360, df_characters.shape[0])]\",\"Drop rows containing NaN values\\ndf_character_nonull = df_script[df_script.speaking_line == True][['id', 'episode_id', 'number', 'raw_character_text']].dropna()\\ndf_location_nonull = df_script[df_script.speaking_line == True][['id', 'episode_id', 'number', 'raw_location_text']].dropna()\\ndf_script_nonull = df_script[df_script.speaking_line == True][['id', 'episode_id', 'number', 'raw_text']].dropna()\\n# clean_short_lowertnl\\ndf_episode_nonull = df_episodes.dropna()\",\"Split the text of every script line into individual words.\",\"See the first entries of the characters dataset\\nprint(df_characters.head())\",\"# Names of the characters\\ncharacters = df_characters.character_name.values\\n\\n# Names of the locations\\nlocations = df_locations.location_name.values\",\"Tagging the variables that we will be using to create the corpus.\",\"View the first few rows of each dataframe to understand the data\",\" Viewing the first few rows of the character data\\ndf_characters.head()\",\"Fix dataset inconsistencies and errors\",\"Merge characters, locations and episodes information into script data\\ndf_script['character_name'] = df_script['character_id'].apply(lambda x: df_characters[df_characters['id'] == x]['name'].values[0])\\ndf_script['location_name'] = df_script['location_id'].apply(lambda x: df_locations[df_locations['id'] == x]['name'].values[0])\\ndf_script['episode_title'] = df_script['episode_id'].apply(lambda x: df_episodes[df_episodes['id'] == x]['title'].values[0])\\ndf_script['episode_season'] = df_script['episode_id'].apply(lambda x: df_episodes[df_episodes['id'] == x]['season'].values[0])\\ndf_script['episode_number'] = df_script['episode_id'].apply(lambda x: df_episodes[df_episodes['id'] == x]['number_in_season'].values[0])\",\"Merge dataframes on 'script_id' if we want to have all the information in one dataframe.\",\"Define directory path for wordcloud output\\nwordcloud_dir = \\\"wordclouds\\\"\",\" Displaying the head of the tables to understand the data\",\"Select dialouges from episode one\\nep1_id = 3\\ndf_ep1 = df_script[df_script['episode_id'] == ep1_id].copy()\\n\\n# Display the first few rows of the dataframe\\ndf_ep1.head()\",\"Import custom classes, functions and variables\\nfrom nlp_pipeline import NLPPipeline\\nfrom bokeh_helper import generate_chart_markup\\n\\nnlp = spacy.load('en_core_web_sm')\",\"Limit rows\\ndf_script = df_script.sample(100000, random_state=42)\\n\\n# Issue with characters and locations\\ndf_script.loc[df_script.raw_character_text.str.contains('explosion', case=False, na=False, regex=False), 'raw_character_text'] = 'explosion'\\ndf_script.loc[df_script.raw_location_text.str.contains('explosion', case=False, na=False, regex=False), 'raw_location_text'] = 'explosion'\",\"Visualize the most mentioned characters in the script\\n# Count the most mentioned characters in the script\\ntop_characters = Counter(df_script.loc[df_script['speaking_line'] == 'true', 'character_id'])\\ntop_characters = pd.DataFrame(top_characters.most_common(), columns=['character_id', 'count'])\\n\\n# Convert character_id to merge with df_characters\\ntop_characters['character_id'] = top_characters['character_id'].astype(int)\\ndf_characters['character_id'] = df_characters['character_id'].astype(int)\\n\\n# Merge the dataframes\\ntop_characters = top_characters.merge(df_characters, on='character_id')\\n\\ntop_characters.head()\",\"Inspect the dataframes to understand their structure and what kind of information they contain.\",\"Remove episodes with missing data\\ndf_episodes = df_episodes.dropna(subset=['original_air_date'])\",\"Drop rows which do not have any lines or location\\ndf_script = df_script.dropna(subset=['raw_location_text', 'spoken_words'])\\n\\n\\n# How many different locations are there in the script\\ndf_script['raw_location_text'] = df_script['raw_location_text'].str.lower()\\ndf_script['raw_location_text'] = df_script['raw_location_text'].str.replace('springfield','')\\ndf_script['raw_location_text'] = df_script['raw_location_text'].str.replace('the simpson home','home')\\ndf_script['raw_location_text'] = df_script['raw_location_text'].str.replace('the simpson house','home')\\ndf_script['raw_location_text'] = df_script['raw_location_text'].str.replace(\\\"moe's tavern\\\",\\\"moes tavern\\\")\\ndf_script['raw_location_text'] = df_script['raw_location_text'].str.replace(\\\"moe's\\\",\\\"moes tavern\\\")\\ndf_script['raw_location_text'] = df_script['raw_location_text'].str.strip()\\n\\nlen(df_script['raw_location_text'].value_counts())\",\"first, let's cleanup the data.\",\"Wordcloud on all the characters lines\",\"Github link: https:\\u002f\\u002fgithub.com\\u002falexkenan\\u002fsimpsons_scripts_analysis\\n# Quick dataframe shaping\\nprint('Shape:')\\nprint(f'Characters: {df_characters.shape}')\\nprint(f'Locations: {df_locations.shape}')\\nprint(f'Script: {df_script.shape}')\\nprint(f'Episodes: {df_episodes.shape}')\\n\\n# Display insteresting attributes about the data\\nprint(f'Sample characters:')\\nprint(df_characters.sample(5))\\nprint(f'Sample locations:')\\nprint(df_locations.sample(5))\\nprint(f'Sample episodes:')\\nprint(df_episodes.sample(5))\",\"Displaying the output of the last code xpression in Jupyter doesn't print the dataframe, \\n# but calling the dataframe which we will do for each of them later does\\ndf_characters\",\"Top of the \\\"Episode list\\\" table\",\"Remove whitespaces from headers and make them lowercase\\ndf_characters.columns = df_characters.columns.str.strip().str.lower().str.replace(' ', '_')\\ndf_locations.columns = df_locations.columns.str.strip().str.lower().str.replace(' ', '_')\\ndf_script.columns = df_script.columns.str.strip().str.lower().str.replace(' ', '_')\\ndf_episodes.columns = df_episodes.columns.str.strip().str.lower().str.replace(' ', '_')\",\"Ensure the script is sorted by episode and id\\ndf_script = df_script.sort_values(by=['episode_id', 'id']).reset_index(inplace=False, drop=True)\",\"Print the head of each DataFrame to inspect them\\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()\",\"Print how many episodes our dataset contains\",\"Setting environment variable for CUDA\\nos.environ[\\\"CUDA_VISIBLE_DEVICES\\\"] = \\\"\\\"\",\"Set plot style\\nplt.style.use('fivethirtyeight')\",\" Display top rows of each dataframe\\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()\",\"clean the script dataframe by dropping useless data\",\"Removing rows having - and NaN values in `script_text` column\\ndf_script = df_script[df_script['raw_character_text'] != '-']\\ndf_script = df_script[df_script['raw_character_text'].notna()]\\ndf_script = df_script[df_script['speaking_line'] == True]\",\"Quick look at the structure of the datasets\",\"np.random.seed(0)\",\"Check the data\\nprint(\\\"The characters:\\\")\\ndisplay(df_characters.head())\\nprint(\\\"The locations:\\\")\\ndisplay(df_locations.head())\\nprint(\\\"The script:\\\")\\ndisplay(df_script.head())\\nprint(\\\"The episodes:\\\")\\ndisplay(df_episodes.head())\",\"Lets see what each dataframe looks like\",\" Display an overview of the data in the datasets\",\"Check the size of the dataframes\\ndf_characters.shape, df_locations.shape, df_script.shape, df_episodes.shape\",\"# Shows the first rows of the table in a Jupyter\\ndf_characters.head()\",\" Specify data types for each column in the episodes dataframe for space efficiency\\ndtypes = {\\n    'id': 'uint32',\\n    'title': 'category',\\n    'original_air_date': 'datetime64',\\n    'production_code': 'object',\\n    'season': 'uint8',\\n    'number_in_season': 'uint8',\\n    'number_in_series': 'uint16',\\n    'us_viewers_in_millions': 'float32',\\n    'views': 'uint32',\\n    'imdb_rating': 'float32',\\n    'imdb_votes': 'uint32',\\n    'image_url': 'object',\\n    'video_url': 'object',\\n    'special_features': 'object',\\n    'writers': 'object',\\n    'directors': 'object',\\n    'guest_stars': 'object'\\n}\\n\\n# Apply the data types to the episodes dataframe\\ndf_episodes = df_episodes.astype(dtypes)\",\"Filter the dataframe to only include rows where the speaking line is associated with a character and a location.\\ndf_script_char_loc = df_script[df_script['raw_character_text'].apply(lambda x: x in df_characters['character_name'].values)]\\ndf_script_char_loc = df_script_char_loc[df_script_char_loc['raw_location_text'].apply(lambda x: x in df_locations['normalized_name'].values)]\",\" Visualize the first few rows of each dataframe\\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()\",\"Separate lines into dialogues from the same scene and speaker.\",\"Merge with mapping files\",\"Remove spaces from column names\\ndf_characters.columns = df_characters.columns.str.replace(' ', '_')\\ndf_locations.columns = df_locations.columns.str.replace(' ', '_')\\ndf_script.columns = df_script.columns.str.replace(' ', '_')\\ndf_episodes.columns = df_episodes.columns.str.replace(' ', '_')\",\"Transform character_id, location_id and episode_id to integers for every line\\ndf_script['character_id'] = pd.to_numeric(df_script['character_id'], errors='coerce').fillna(0).astype(np.int64)\\ndf_script['location_id'] = pd.to_numeric(df_script['location_id'], errors='coerce').fillna(0).astype(np.int64)\\ndf_script['episode_id'] = pd.to_numeric(df_script['episode_id'], errors='coerce').fillna(0).astype(np.int64)\",\"Display series lists two column names.\",\"Open the script lines dataset and join with relevant others\",\"Select only these characters with known locations:\\nknown_characters = df_characters[df_characters['location_id'].notnull()]['character_id'].values\\n\\n# Filter the lines only to those spoken by known characters\\ndf_script_known = df_script[df_script['character_id'].isin(known_characters)]\\n\\nprint(f'The dataset contains {len(df_script_known)} lines of {len(known_characters)} characters with known locations')\",\"Set which cast member has which gender.\",\"Display the first few characters of the datasets\\nprint('Characters:')\\ndisplay(df_characters.head())\\nprint('Locations:')\\ndisplay(df_locations.head())\\nprint('Script:')\\ndisplay(df_script.head())\\nprint('Episodes:')\\ndisplay(df_episodes.head())\",\"View basic info about the dataframes\\nprint(df_characters.head())\",\"Visualisation du nombre de lignes par saison\\ndf_episodes['production_season'].value_counts().sort_index().plot(kind='bar', figsize=(15, 5))\\nplt.title('Nombre de lignes par saison')\\nplt.xlabel('Saison')\\nplt.ylabel('Nombre de lignes')\\nplt.grid(axis='y', linestyle='--', alpha=0.7)\\nplt.show()\",\"Preview the first few rows of each dataframe\\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()\",\"Print the number of available script lines\\nprint(f'Number of script lines: {df_script.shape[0]:,}')\",\"Inspect the dataframes to understand the data\",\"\\n# Let's take a look at the content of these files\\nprint('Characters\\\\n', df_characters.head())\\nprint('\\\\n\\\\nLocations\\\\n', df_locations.head())\\nprint('\\\\n\\\\nScript\\\\n', df_script.head())\\nprint('\\\\n\\\\nEpisodes\\\\n', df_episodes.head())\",\"Visualize the percentage of lines spoken by each character\\nlines_spoken = df_script['raw_character_text'].value_counts(normalize=True) * 100\\nlines_spoken = lines_spoken[df_characters['character_id'].values]\\nlines_spoken = lines_spoken.sort_values(ascending=True)\\n\\nplt.figure(figsize=(10, 25))\\nplt.barh(lines_spoken.index, lines_spoken.values, color='skyblue')\",\"Filter out all the non-Simpsons lines from the dataframe\",\"Merge datasets to simplify the data analysis process and have various attributes of the script lines in the same DataFrame.\",\"Let's start by examining the structure of `df_characters`.\",\"The script that computes the length of each line in words is given below:\",\"Setting Python to print a large number of columns\\npd.options.display.max_columns = 50\",\"Changing column names for consistency with annotations\",\"Visualize the distribution of the line_count column in the df_script dataframe\",\"Visualize distribution of script line lengths\",\"Remove the rows having NaN values in certain columns from the dataframe df_script\",\"Limit the data for analysis for now: top 4 characters and top 4 locations.\\ncharacters = ['Homer Simpson', 'Marge Simpson', 'Bart Simpson', 'Lisa Simpson']\\nlocations = ['Simpson Home', \\\"Moe's Tavern\\\", 'Kwik-E-Mart', 'Springfield Elementary School']\\n\\n# Specific scripts \\u002f lines with the characters and locations:\\ndf_script_character_limited = df_script[df_script.character_id.isin(df_characters[df_characters.raw_character_text.isin(characters)].index)]\\ndf_script_location_limited = df_script[df_script.location_id.isin(df_locations[df_locations.raw_location_text.isin(locations)].index)]\",\"We will start by loading the necessary datasets for our analysis.\",\"Display the first few lines of the dataframes to understand their structure\\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()\",\" These will be the sources of data we will be working with.\",\"Check if GPU is available\\nspacy.prefer_gpu()\",\" Clean the dataset\\ndf_script = df_script[df_script.raw_location_text.notnull()]\\ndf_script = df_script[df_script.raw_character_text.notnull()]\\ndf_script = df_script[df_script.raw_character_text.str.strip() != '']\\ndf_script = df_script[df_script.raw_location_text.str.strip() != '']\\ndf_script.reset_index(drop=True, inplace=True)\",\" extract characters, locations and script\\ncharacters = df_characters['normalized_text'].values.tolist()\\nlocations = df_locations['normalized_text'].values.tolist()\\nscript = df_script['normalized_text'].values.tolist()\",\"Load NLP model\\nnlp = spacy.load('en_core_web_sm')\\n\\n# Check if the NLP model is loaded successfully\\nnlp.vocab.length\",\"Ensure matplotlib uses the default style\\nmatplotlib.style.use('default')\",\"Show how the dataset look\\ndf_script.head()\",\" Set random seed for deterministic results\\nnp.random.seed(0)\",\" We use the spaCy library for named entity recognition. Let's load the English language model for spaCy.\",\"ensure scriptLine order\\ndf_script = df_script.sort_values(by=['episode_id', 'timestamp_in_ms']).reset_index(inplace=False, drop=True)\",\" Display first rows of the characters data\\ndf_characters.head()\",\"Show the first 3 rows of the `df_characters` dataframe\\ndf_characters.head(3)\",\"Look at the head of the lines DataFrame\",\"If you have a different file path, please modify it accordingly.\",\"Combine script lines and episodes data into a single dataframe\",\" Viewing content first rows\\ndf_characters.head()\",\"We set the index as \\\"id\\\" because the field is unique.\",\"# Checking the first lines of the dataframe\\nprint(\\\"\\\\nData: Characters\\\")\\nprint(df_characters)\\nprint(\\\"\\\\nData: Locations\\\")\\nprint(df_locations)\\nprint(\\\"\\\\nData: Script\\\")\\nprint(df_script)\\nprint(\\\"\\\\nData: Episodes\\\")\\nprint(df_episodes)\",\"Let us take a look at each dataframe to better understand the kind of data we have.\",\"Prints datasets' head\",\"We will start by loading the datasets we'll use for the analysis.\",\"Check the content for each dataframe\\nprint(\\\"\\\\nContent of characters dataframe\\\")\\nprint(df_characters.head())\\n\\nprint(\\\"\\\\nContent of locations dataframe\\\")\\nprint(df_locations.head())\\n\\nprint(\\\"\\\\nContent of script dataframe\\\")\\nprint(df_script.head())\\n\\nprint(\\\"\\\\nContent of episodes dataframe\\\")\\nprint(df_episodes.head())\",\"Optional: Uncomment and reproduce the sample code to rename column names for easier referencing in the subsequent sections\\n\\ndf_script.columns = df_script.columns.str.lower()\\ndf_episodes.columns = df_episodes.columns.str.lower()\\ndf_characters.columns = df_characters.columns.str.lower()\\ndf_locations.columns = df_locations.columns.str.lower()\",\"Directly print the length of each dataframe\",\"Merge the data to get a single dataframe containing all information about each line of script.\",\"Replace NaN values with empty strings\\ndf_script['normalized_text'] = df_script['normalized_text'].fillna('')\",\"Inspect the structure of the data:\",\"Set the random seed for numpy to have the same results for multiple runs\\nnp.random.seed(0)\",\"Displaying the dataframe types to start understanding their structures\\nprint(df_characters.dtypes)\\nprint(df_locations.dtypes)\\nprint(df_script.dtypes)\\nprint(df_episodes.dtypes)\",\" Feature Engineering\",\" Preview the first 5 rows of each dataframe\\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()\",\"Check our data\\nprint(f'Characters: {df_characters.shape[0]}')\\nprint(f'Locations: {df_locations.shape[0]}')\\nprint(f'Script lines: {df_script.shape[0]}')\",\"Downloading the large English model for spaCy, please wait...\",\"Check the first 5 rows for each dataset.\",\"Display the first few rows of the characters data\\ndf_characters.head()\",\"Filter the character list to remove non-character names or add missing characters\\ncharacters_to_remove = ['narrator']\\n\\ndf_characters_filtered = df_characters[~df_characters['name'].str.lower().isin(characters_to_remove)]\\ndf_characters_filtered.reset_index(drop=True, inplace=True)\",\"Setting up the basic configuration for the spaCy library\",\"The lines and their structure is in df_script dataset. Let's add a column to it that has the text, each line was referencing, added and then we can do the same thing as above.\",\"Print some statistics about the data\",\"Print the first rows of each dataframe to better understand the data structure\\n\\nprint(df_characters.head())\\nprint(df_locations.head())\\nprint(df_script.head())\\nprint(df_episodes.head())\",\"Showing the dataframe shape\\nprint ('Characters dataframe shape: {}'.format(df_characters.shape))\\nprint ('Locations dataframe shape: {}'.format(df_locations.shape))\\nprint ('Script dataframe shape: {}'.format(df_script.shape))\\nprint ('Episodes dataframe shape: {}'.format(df_episodes.shape))\",\"check missing data\\ndf_script.info()\",\"Setting seed for reproducibility\\nnp.random.seed(0)\",\"Extract top speakers from the data\\ntop_speakers = df_script.raw_character_text.value_counts(normalize=True).round(2)\\ntop_speakers = top_speakers[0:20]\\n\\n# Plot top speakers\\ntop_speakers.plot(kind='barh')\",\"Check shape of all the dataframes\",\"D(**df_characters.head(2))\\n# display(df_locations.head(2))\\n# display(df_script.head(2))\\n# display(df_episodes.head(2))\",\"Fetch a subset of the data and decrease it for efficiency\",\"Clean Script DataFrame\\ndf_script = df_script.drop(columns=[\\n    'number', 'raw_text', 'timestamp_in_ms', '_heartbeat_', \\n    'speaking_line', 'character_id', 'location_id', 'raw_character_text',\\n    'raw_location_text', 'spoken_words', 'normalized_text'\\n])\",\"Check import\\nprint(df_characters.head())\",\"\\n# Preprocess script lines\\n# Remove unwanted columns\\ndf_script = df_script.drop(['id', 'image_url'], axis=1)\",\"#   display(df_characters.head())\\n#   display(df_locations.head())\\n#   display(df_script.head())\\n#   display(df_episodes.head())\",\"\\n# Sample data\\ndf_script.head()\",\"Show how the script data looks like\\ndf_script.head()\",\" Look at the dimension of dataframes\",\"Ensure that we only use 1\\u002f4 of every element of the dataset as a temporary measure.\",\" Print header\\nprint(df_episodes.head())\\n\\n# Prints number of lines per episode\\nprint(df_script.groupby('episode_id')['id'].count())\",\"Show the first few characters of the main datasets\\nprint(df_characters.head())\\nprint(df_locations.head())\\nprint(df_script.head())\\nprint(df_episodes.head())\",\"Display basic info for each of the datasets\",\" Ensure the correct encoding of the dataframes\\ndf_characters = df_characters.applymap(lambda x: x.encode('unicode_escape').\\n              decode('utf-8') if isinstance(x, str) else x)\\ndf_locations = df_locations.applymap(lambda x: x.encode('unicode_escape').\\n             decode('utf-8') if isinstance(x, str) else x)\\ndf_script = df_script.applymap(lambda x: x.encode('unicode_escape').\\n            decode('utf-8') if isinstance(x, str) else x)\\ndf_episodes = df_episodes.applymap(lambda x: x.encode('unicode_escape').\\n              decode('utf-8') if isinstance(x, str) else x)\",\"Keep a copy of the original dataset just in case\\ndf_characters_orig = df_characters.copy()\\ndf_locations_orig = df_locations.copy()\\ndf_script_orig = df_script.copy()\\ndf_episodes_orig = df_episodes.copy()\",\" Add a setting to allow pandas to display the right number of columns\\npd.set_option('display.max_columns', 8)\",\"Create backup copies of the datasets\\ndf_characters_bk = df_characters.copy()\\ndf_locations_bk = df_locations.copy()\\ndf_script_bk = df_script.copy()\\ndf_episodes_bk = df_episodes.copy()\",\"Let's quickly inspect and clean the data to get an overview.\",\"What are the dtypes that each dataframe is storing?\",\"Set the indexing of the DataFrames to be the index column, as the index will be useful manipulate the DataFrames.\",\" Inspect the first few rows of each dataframe\\ndisplay(df_characters.head())\\ndisplay(df_locations.head())\\ndisplay(df_script.head())\\ndisplay(df_episodes.head())\",\"Check the size of the dataframes\",\"Time to look at the files we have loaded!\",\"CORRECT INCORRECT COLUMNS IN script LINES DATAFRAME\",\"A take on entity extraction.\\n# Tokenizing the description of Lisa at the start\\nnlp = spacy.load(\\\"en_core_web_sm\\\")\\ndoc = nlp(df_characters[0:1]['description'][0])\\nfor token in doc:\\n    print(token, token.pos_, token.dep_)\",\"Create counting dictionaries\",\"Remove some irrelevant columns to enhance readability\\ndf_script.drop(columns=['norm_text', 'word_count', 'location_id', 'timestamp_in_ms', 'speaking_line', 'raw_text', 'timestamp_in_ms', 'raw_character_text', 'spoken_words', 'normalized_text', 'representation'], inplace=True)\",\"Display top 5 records of each data frame to understand the fields\",\"Merge lines with episode info\\ndf_all = df_script.merge(df_episodes, on='episode_id', suffixes=('_script', '_episode'))\",\"View the structure of the characters dataframe\\ndf_characters.head()\",\"Join all on 'episode_id' and 'id' to get a full dataframe\",\"\\ndef get_script_character(script_id):\\n    '''\\n    INPUT\\n    script_id: int - the id of the script\\n    \\n    OUTPUT\\n    A string representing the character\\n    \\n    Given a script id, returns the simpson character of the line.\\n    '''\\n    return df_script['character_id'][df_script['id'] == script_id].values[0]\",\"modules=BERTComponents(embedding_dim=768)\",\"Check that the script dataframe has the correct colums\\u043e\\u043b\\u0443\\u0447\\u0438\\u0442\\u044c \\u0441\\u043f\\u0438\\u0441\\u043e\\u043a \\u0441\\u0442\\u043e\\u043b\\u0431\\u0446\\u043e\\u0432 \\u0432 dataframe.\",\"Define a variable with the path to the directory containing the seasons\\ndirname = 'data\\u002fsimpsons_episodes\\u002f'\",\"start by preliminary analysis of the dataset, let's get an overview of the data.\",\" Check the dataframe entries count, dataframe columns and null values with pandas utilities.\",\"Concatenate the spoken words for each episode and speaker\\ndf_script_concatenated = df_script.groupby(['episode_id', 'character_id']).agg({'spoken_words': ' '.join}).reset_index()\",\" Check if we have NaN values in the dataset, True means that we have NaN values, False means that we don't.\",\"Let's take a peek at our datasets\\ndf_episodes.head(), df_characters.head(), df_locations.head(), df_script.head()\",\"Remove invalid script lines and merge tables\",\"## Data Cleaning and Exploration\",\"Combine the text from all the script lines into a single string for wordcloud generation\\nscript_text = \\\" \\\".join(df_script['normalized_text'].fillna(''))\",\"Load the data\",\"Check the number of data points \\nprint(\\\"Number of data points: \\\", df_script.shape[0])\",\" Let's check the first lines of each dataframe.\",\" display the first 5 script lines\\ndf_script.head()\",\" Set the display name for each character and location based on the columns shown above\",\" Group the script by episodes and join the lines for each speaker\",\"###############\\n# Data Analysis\\n###############\",\"Let's display the content of the dataframes to assess their structure and the data they contain.\",\"Check the number of records in each dataframe\\nprint(df_characters.shape)\\nprint(df_locations.shape)\\nprint(df_script.shape)\\nprint(df_episodes.shape)\",\"Let's display the head of these DataFrames to understand the data better.\",\"Merge dataset\\ndf_script.info()\",\"Check the first few entries for each of the dataframes to understand the structure of the data\",\" Filter characters with non-resolved names\\ndf_characters = df_characters[df_characters.raw_character_text.str.contains('Simpson') | df_characters.raw_character_text.str.contains('simpson')].reset_index(inplace=False, drop=True)\",\"Extract only 1% of the rows for a reasonable runtime during the analysis\\ndf_script = df_script.sample(frac=0.01, random_state=1).reset_index(inplace=False, drop=True)\",\"Count the number of episodes where \\\"Bart\\\" is mentioned\\ndf_script[df_script['raw_text'].str.contains('Bart')]['episode_id'].nunique()\",\" Demonstrating the data structure and number of entries in each dataset\",\"Reduce the amount of memory used by the dataframes.\",\" Analyze the characters data\\nprint(df_characters.head())\",\"Setting up Spacy\\n# For illustrative purposes, we will only look at the first 10000 script lines.\\nnlp = spacy.load(\\\"en_core_web_sm\\\")\\n\\n# Here we use parallelization to make the Spacy NLP tests faster\\ntqdm.pandas()\",\"Let's check the size of these Dataframes\",\"Remove duplicate values from characters, locations and episodes dataframes\\n# We need to do this before merging to avoid duplication issues\",\"Explore the data\\npd.set_option('display.max_columns', None)\",\"Exploratory Data Analysis\",\"# Join script database with characters\\ndf_characters_info = df_script.join(df_characters.set_index('id'), on='character_id')\\n\\n# Join characters info database with locations\\ndf_locations_info = df_characters_info.join(df_locations.set_index('id'), on='location_id')\",\"Count the number of lines in df_script\\nlen(df_script)\",\"Set the random seed for numpy for reproducible results\\nnp.random.seed(0)\",\"\\n# Display the first few rows of the characters table\\ndf_characters.head()\",\"Calculate the number of spoken words per gender\\nspoken_words_per_gender = df_script.groupby(['spoken_by', 'gender']).agg({'word_count': 'sum'}).reset_index()\\nspoken_words_per_gender['spoken_by'] = spoken_words_per_gender['spoken_by'].str.lower()\\n\\n# Speeches of the 4 main characters\\nspoken_words_per_gender[spoken_words_per_gender['spoken_by'].str.contains('homer|marge|bart|lisa')]\",\"Check the imported datasets\\ndf_characters.head()\",\"Text vectorization of the series names\",\"Prepare for data exploration\\n# Show all columns\\npd.options.display.max_columns = 50\",\"View some records\\nprint(df_characters.head())\",\"Check column names\",\"Check a few entries from each dataframes to understand the structure of the data.\",\"Load locally saved stop words, to use common stop word list\\nwith open('data\\u002fstopwords.txt', 'r') as f:\\n    stopwords = f.read().split('\\\\n')\",\"Remove annoying characters from character names\",\" Clean characters\\n# Remediate duplicate\\u002fempty rows\\ndf_characters = df_characters.drop_duplicates(subset='id')\\ndf_characters = df_characters.dropna(subset=['name'])\\n\\n# Ensure case-insensitive matching\\ndf_characters['name_lowercase'] = df_characters['name'].str.lower()\",\"Get rid of some unnamed columns\\ndf_characters.columns = df_characters.columns.str.replace('Unnamed: [0-9]+', '')\",\"Set random_state for reproducible results\\nnp.random.seed(0)\",\" Concatenate the names and surnames of the characters for easier identification\\ndf_characters['full_name'] = df_characters['name'] + ' ' + df_characters['surname']\",\"Create a copy of the columns that will be modified\",\" Display the dataframe containing the script\\ndf_script\",\"Some more exploratory data analysis ...\\n# Filter out non-episode, non-dialogue script lines\\ndf_script = df_script[\\n    (df_script['episode_id'] != -1) & \\n    (df_script['character_id'] != -1)\\n].reset_index(inplace=False, drop=True)\",\"Check character ID 8 lines in the script dataset\\ndf_script[df_script.raw_character_text.str.contains('marge', case=False, na=False)].raw_character_text.unique()\",\"GC.collect()  # Garbage collection\",\"Function to remove accents from characters\",\" Ensure that all datasets have loaded correctly\\nprint(f'Characters data shape: {df_characters.shape}')\\nprint(f'Locations data shape: {df_locations.shape}')\\nprint(f'Script data shape: {df_script.shape}')\\nprint(f'Episodes data shape: {df_episodes.shape}')\",\"Remove special character from episode titles and transform to lowercase\\ndf_episodes['title'] = df_episodes['title'].str.replace('[^A-Za-z0-9 ]+', '').str.lower()\",\"List available datasets\\ndatasets = [df_characters, df_locations, df_script, df_episodes]\",\" Remove rare characters from the data\\ncharacter_counts = df_script.raw_character_text.value_counts()\\nmask = (character_counts \\u003e= 50)\\ncharacter_list = character_counts.index[mask].tolist()\\ndf_script = df_script[df_script['raw_character_text'].isin(character_list)]\",\"Merging the dataframes to get more comprehensive information for each line of the script.\",\"Counting the number of words in the script line and storing the count in a separate column\",\" Drop one column because the indexcol is exported as a column\",\"Merge episodes data to get the name of the episodes along with the script data\\ndf_script = pd.merge(df_script, df_episodes[['id', 'title', 'original_air_date']], left_on='episode_id', right_on='id')\",\"Set path to Simpsons data folder\\npath = 'data'\",\"Display first few rows of the characters dataframe\\ndf_characters.head()\",\"Apply basic preprocessing\\ndf_script = df_script[df_script['episode_id'] != 464]  # Removing faulty lines\\ndf_script = df_script[df_script.notnull()]  # Dropping NaN values in all columns\",\"Visualizing the most popular characters\",\"Displaying a few rows of the script data\\ndf_script.head()\",\" Now that we have our dataframes loaded, let's take a look at the first few rows of each dataframe to familiarize ourselves with the data.\",\"Check the structure of the dataframes and display their first few rows\\nprint(\\\"Characters\\\")\\nprint(df_characters.head())\\nprint(\\\"Locations\\\")\\nprint(df_locations.head())\\nprint(\\\"Script\\\")\\nprint(df_script.head())\\nprint(\\\"Episodes\\\")\\nprint(df_episodes.head())\",\"Inspect data types and missing values\\ndf_script.info()\",\"Function to display some lines around a given line index\\ndef show_context(idx, nbL=2):\\n    for i in range(nbL, 0, -1):\\n        print(f'{df_script.iloc[idx - i].raw_character_text} - {df_script.iloc[idx - i].spoken_words}')\\n    print('## -------------------------------------------------- ##')\\n    print(f'{df_script.iloc[idx].raw_character_text} - {df_script.iloc[idx].spoken_words}')\\n    print('## -------------------------------------------------- ##')\\n    for i in range(1, nbL+1):\\n        print(f'{df_script.iloc[idx + i].raw_character_text} - {df_script.iloc[idx + i].spoken_words}')\",\"\\n# Print the first lines of the table related to the characters present in the series\\ndf_characters.head()\",\" Strip whitespaces in character_id column\\ndf_script['character_id'] = df_script['character_id'].str.strip()\",\"Quick display of the character dataframe\\ndf_characters.head()\",\"cos when print statements appear in the middle of my sentence I can think of nothing better so say.\",\"Select right episodes and keep only right columns\",\" Let's display some basic information about the dataframes.\",\" Visualize quick informations about datasets\",\" Check the size of each dataframe\",\" Show the modules.\",\"Ensure correct data types for script and episodes\\ndf_episodes['id'] = df_episodes['id'].astype(int)\\ndf_script['episode_id'] = df_script['episode_id'].astype(int)\",\"remove the 'text' column from df_script to speed up processing, if needed\\n# df_script = df_script.drop(columns=['text'])\",\"We will load the preprocessed data (to be precise, the cleaned data that we just created) to start with the text analysis process.\",\"clean the character lines by dropping duplicate lines and removing special chars\\ndf_script = df_script.drop_duplicates('raw_text').reset_index(inplace=False, drop=True)\",\"View the content of all the datasets\\nprint('[INFO] Number of characters:', df_characters.shape[0])\\ndf_characters.head()\",\"Filter the data to only include the lines from the 10 main characters.\",\"Code\\n# Data exploration\\nprint('Characteres:')\\nprint(df_characters.info())\\nprint(df_characters.describe())\\nprint(df_characters.head())\\nprint(df_characters.tail())\",\"Check that the datasets were loaded correctly\\nprint(\\\"Characters:\\\")\\nprint(df_characters.head())\\n\\nprint(\\\"\\\\nLocations:\\\")\\nprint(df_locations.head())\\n\\nprint(\\\"\\\\nScript:\\\")\\nprint(df_script.head())\\n\\nprint(\\\"\\\\nEpisodes:\\\")\\nprint(df_episodes.head())\",\"Let's see how the data looks by displaying the first few rows of each dataframe.\",\"Clean and pre-process the data\\n# Eliminate the rows with any nan values\\ndf_script = df_script.dropna()\\n\\n# Keep only the required columns\\ndf_script = df_script[['episode_id', 'number', 'raw_text', 'speaking_line', 'character_id', 'location_id']]\",\"In the root directory, create a `visualizations` directory if it does not exist.\",\"The next section replaces speaker's names, locations, and special expressions by\\n# VALUE_NOT_USED. We also store each replacement in separate csv files.\\n\\nfrom preprocess import *\",\"Remove unwanted columns from characters, locations and episodes dataframes\",\"Tokenize the text data of each script line using SpaCy.\",\"Setting to display all columns of the dataframes in the notebook\\npd.set_option('display.max_columns', None)\",\"Converting 'raw_text' column into string type\",\"Displays the first 3 rows from the characters dataframe\\ndf_characters.head(3)\",\"Separate the string with main and secondary characters into lists.\",\"Display the top 5 rows of each dataframe\\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()\",\"Extract main characters from characters df\\nmain_characters = df_characters[df_characters['raw_character_text'].str.contains('simpson', case=False)]['raw_character_text']\\n\\n# Prepare name matching (case insensitive & remove leading\\u002ftrailing white space)\\nmain_characters = main_characters.apply(lambda x: x.lower().strip())\\n\\n# Extract locations\\nlocations = df_locations['name']\\n\\n# Extract episodes titles\\nepisodes_titles = df_episodes['title']\",\"Create a pandas series with the top characters and create a word cloud.\",\"Name columns consistently across datasets.\",\"Method to display shape of DataFrame\\ndef display_shape(df, name):\\n    print(f'{name} shape:', df.shape)\",\" Start by getting an overview of the data\",\"Check if GPU is available\\nimport tensorflow as tf\\nprint(\\\"Num GPUs Available: \\\", len(tf.config.experimental.list_physical_devices('GPU')))\",\" Visualize top characters\",\"Setting a seed for reproducibility\\nnp.random.seed(123)\",\" Check the imported data\\nprint(df_characters.head())\",\"Clean episode titles\\ndf_episodes['clean_title'] = df_episodes['title'].str.replace('\\\\\\\".*\\\\\\\"', '', regex=True)\\ndf_episodes['clean_title'] = df_episodes['clean_title'].str.replace('\\\\[.*\\\\]', '', regex=True)\",\"Let's first start by exploring the dataset and understanding its structure.\",\"Display dataframe\\ndf_script\",\"Let's first take a look at the structure of the data and have a peak at the first few rows.\",\"Clean the data: Some characters and many locations have the honorific \\\"The\\\" in their name, which can confuse the API.\",\"Check out the contents of each of the dataframes\",\"Check the head of each dataframe to understand the available data.\",\"Remove the lines which does not have character, location, and raw_text information.\",\" Let's take a quick look at the contents of the data frames to understand the data structure.\",\"Join all data together\\ndf = df_script.copy()\",\" Preprocess the text data and merge the relevant columns\",\"Sample data to understand the structure and contents of the data frames that have been created\",null],\"marker\":{\"color\":\"#CFD8DC\",\"opacity\":0.5,\"size\":5},\"mode\":\"markers+text\",\"name\":\"other\",\"showlegend\":false,\"x\":[16.9243221282959,14.718270301818848,-0.8336579203605652,-2.177931070327759,20.15520668029785,17.322364807128906,14.67169189453125,9.869457244873047,15.903987884521484,6.4692702293396,5.989692211151123,7.360758304595947,7.08561372756958,8.886017799377441,6.049485683441162,-3.4788761138916016,16.545398712158203,17.15036964416504,10.111028671264648,8.49087142944336,5.214050769805908,5.68009090423584,13.474016189575195,-0.6481894254684448,2.325862169265747,2.997718095779419,-0.988429844379425,7.992311477661133,8.911310195922852,0.008761550299823284,7.236743927001953,13.819196701049805,15.366663932800293,9.556113243103027,-0.4469754993915558,4.430975437164307,9.311653137207031,12.114006042480469,30.746170043945312,6.87487268447876,8.518831253051758,12.947912216186523,9.139147758483887,21.985530853271484,9.456504821777344,-1.8000965118408203,10.450263023376465,8.433788299560547,6.489278316497803,20.390716552734375,7.644186973571777,10.791735649108887,6.98927116394043,6.202446937561035,9.578252792358398,9.240758895874023,10.390137672424316,-0.8038867115974426,7.698911190032959,14.646024703979492,13.538538932800293,3.180870771408081,3.309229850769043,12.682348251342773,1.2232052087783813,13.891250610351562,6.214249610900879,21.522937774658203,12.457348823547363,-4.087405681610107,14.00266170501709,14.51982593536377,16.645483016967773,5.5332441329956055,-1.2555804252624512,5.652230262756348,0.6610632538795471,17.597442626953125,5.200153350830078,12.65225601196289,-4.933899402618408,10.793487548828125,2.8200371265411377,-1.0648342370986938,5.886332988739014,9.110855102539062,3.9190919399261475,8.63736629486084,0.23890817165374756,6.42510986328125,4.215158462524414,16.095701217651367,-1.1337443590164185,6.286603927612305,-3.1261539459228516,-3.7587156295776367,3.7881999015808105,13.06179141998291,4.646895885467529,12.60918140411377,11.914948463439941,4.235408782958984,31.567659378051758,-4.60615348815918,6.0328874588012695,10.839269638061523,14.94227123260498,7.150223731994629,9.5671968460083,-4.111253261566162,-2.793278932571411,15.176627159118652,6.4316205978393555,8.929344177246094,5.790907859802246,4.4488525390625,9.928444862365723,10.131715774536133,-0.854511022567749,5.946830749511719,3.645364284515381,5.824234485626221,5.799569129943848,6.376007080078125,29.847248077392578,8.055859565734863,20.16061019897461,-1.8677341938018799,10.187285423278809,2.81534481048584,-0.48978525400161743,4.370922088623047,0.9938110113143921,10.213842391967773,1.406701922416687,6.9876861572265625,4.6774444580078125,5.563868999481201,-1.3984097242355347,-1.9600123167037964,32.16411209106445,6.174610614776611,9.48128604888916,9.236414909362793,9.868586540222168,-1.6803404092788696,6.517873764038086,14.273958206176758,-2.865072250366211,-0.4857722818851471,14.07190227508545,5.795305252075195,-1.8042432069778442,-1.0978882312774658,5.554062843322754,5.848244667053223,10.690573692321777,6.831393718719482,9.785330772399902,4.194214820861816,9.644404411315918,1.0401544570922852,15.470597267150879,6.410184383392334,9.688921928405762,3.1584713459014893,5.814417839050293,3.7195422649383545,3.5834338665008545,4.968713760375977,8.142632484436035,16.067052841186523,7.680747985839844,16.422971725463867,13.848480224609375,13.83864974975586,20.059478759765625,-4.03093147277832,13.58855152130127,14.223444938659668,10.830208778381348,-0.19925355911254883,3.7097487449645996,5.834193706512451,17.32294273376465,9.855690956115723,-2.798356533050537,14.32436466217041,6.502053737640381,4.641762733459473,2.527655839920044,-4.786866664886475,8.032916069030762,-2.433722972869873,6.64772891998291,21.26239776611328,13.647790908813477,5.291292190551758,6.3295769691467285,5.018490314483643,-2.8054449558258057,7.114659309387207,-2.7439122200012207,-0.44818541407585144,14.148777961730957,10.231600761413574,6.630489826202393,3.858828544616699,-1.2344900369644165,-0.6885554790496826,30.805622100830078,14.498559951782227,14.481881141662598,7.644915580749512,7.31282377243042,9.034801483154297,11.828612327575684,13.927311897277832,10.295412063598633,3.0865063667297363,9.028549194335938,14.226036071777344,-1.154172658920288,0.792746901512146,10.192314147949219,4.3197736740112305,-2.2705702781677246,9.25869369506836,5.525547981262207,5.1880083084106445,4.632363319396973,11.36804485321045,5.153968334197998,9.935151100158691,7.604747772216797,-1.1049116849899292,10.041033744812012,-0.5525417327880859,-0.8905562162399292,7.467044830322266,-1.071213722229004,9.097430229187012,7.303019046783447,6.723641395568848,-2.8917088508605957,9.648412704467773,14.560683250427246,9.27017879486084,12.885028839111328,18.388090133666992,9.634479522705078,9.689821243286133,9.268268585205078,2.2506587505340576,10.317316055297852,-0.8672534227371216,9.513734817504883,7.969902038574219,3.560222625732422,11.05402660369873,16.27411651611328,10.808733940124512,12.211922645568848,3.221069812774658,0.5468541979789734,32.397159576416016,10.213537216186523,-3.9562861919403076,6.81910514831543,2.396547794342041,7.784933090209961,3.449827194213867,6.099804878234863,14.743900299072266,3.5996434688568115,14.467046737670898,10.172770500183105,2.298006534576416,2.6627280712127686,15.335838317871094,-1.605057954788208,4.06513786315918,9.406213760375977,5.884276390075684,-1.2416530847549438,-1.9559125900268555,11.478055000305176,4.90126371383667,5.429581642150879,29.807031631469727,11.197933197021484,5.235963821411133,5.322810173034668,4.766659736633301,16.415067672729492,8.315987586975098,6.920410633087158,4.4479594230651855,14.34152603149414,8.31134033203125,-2.4355459213256836,5.26177453994751,6.698274612426758,2.908310651779175,29.49444007873535,1.3380390405654907,3.908147096633911,-2.092897653579712,8.347478866577148,-3.933706521987915,-2.9581058025360107,10.848369598388672,5.376035690307617,-1.0845130681991577,-5.211432456970215,4.5282135009765625,13.105682373046875,19.585901260375977,6.074934005737305,15.227529525756836,5.523501873016357,-2.3920814990997314,17.60698127746582,14.451712608337402,9.954455375671387,10.368378639221191,7.609935760498047,13.292734146118164,14.429289817810059,-2.7235705852508545,10.67019271850586,6.758508205413818,8.136937141418457,9.629240036010742,5.476169586181641,15.402953147888184,9.570148468017578,15.190296173095703,5.943331718444824,10.048949241638184,6.901285648345947,-1.2332228422164917,5.486608028411865,0.7652790546417236,5.75131893157959,3.3791205883026123,13.925095558166504,13.159073829650879,10.652158737182617,-4.441427230834961,6.37576961517334,16.380958557128906,3.809642791748047,4.900717258453369,5.079669952392578,7.768815994262695,14.949223518371582,-4.065680980682373,1.3718420267105103,3.541954278945923,6.308430194854736,10.594146728515625,6.765730857849121,31.744972229003906,12.651545524597168,13.534721374511719,-3.59121036529541,10.43238353729248,15.819942474365234,4.126368045806885,5.791725158691406,-0.8072144389152527,8.410696983337402,5.986075401306152,7.949770450592041,14.805599212646484,13.092693328857422,10.415285110473633,5.568807601928711,2.0802388191223145,4.521221160888672,9.240998268127441,-2.410856246948242,9.023641586303711,8.092761993408203,-1.5917011499404907,14.685620307922363,-0.15672647953033447,-0.5641650557518005,5.596745491027832,9.268001556396484,8.65186882019043,-2.9678890705108643,8.944461822509766,3.4665017127990723,-2.1847355365753174,10.547417640686035,-0.967650294303894,3.0196797847747803,-0.597136914730072,3.1936428546905518,14.731156349182129,13.812685012817383,14.710137367248535,8.67024040222168,2.9805963039398193,3.182161331176758,4.4727396965026855,1.9118187427520752,-4.394049644470215,14.13023853302002,14.560504913330078,13.85288143157959,8.872786521911621,11.039450645446777,4.622185230255127,4.139596462249756,14.569823265075684,8.033258438110352,5.93859338760376,6.838191509246826,4.9676337242126465,8.709356307983398,5.864054203033447,15.584320068359375,-1.2200604677200317,14.831686973571777,-2.30411958694458,4.8362812995910645,-0.8109480738639832,8.67383098602295,9.250734329223633,6.966151714324951,9.86944580078125,4.0154523849487305,6.588966369628906,1.8642239570617676,-2.2915408611297607,12.706851959228516,7.306250095367432,4.9667887687683105,5.720702648162842,6.23994255065918,5.0557355880737305,-0.9056242108345032,9.620752334594727,5.920017242431641,5.671928405761719,13.71044635772705,2.3556416034698486,6.205946445465088,10.26193904876709,9.444754600524902,12.259980201721191,5.938435077667236,15.699048042297363,5.22973108291626,14.61705207824707,8.577400207519531,-0.7881229519844055,10.50668716430664,13.75696086883545,10.966880798339844,4.349396228790283,-3.4251108169555664,17.08450698852539,12.07817554473877,2.117433786392212,14.398626327514648,3.1630592346191406,2.8905491828918457,4.137815475463867,4.738452434539795,25.0676212310791,5.110198974609375,7.540959358215332,7.547100067138672,16.680633544921875,10.121859550476074,15.401055335998535,9.348928451538086,4.5522050857543945,10.145562171936035,5.046173572540283,-2.9751992225646973,21.76338005065918,5.305840969085693,7.190892696380615,9.5684814453125,12.326053619384766,3.6128299236297607,10.180948257446289,10.355557441711426,10.990398406982422,-4.501132965087891,8.66817569732666,9.79643726348877,-5.050253868103027,8.90827751159668,4.259758472442627,-1.1585655212402344,11.927861213684082,9.622919082641602,10.338233947753906,7.860171318054199,-4.258205890655518,2.2645554542541504,7.983892917633057,6.768245220184326,-2.3601999282836914,10.192644119262695,-3.6072945594787598,-1.7011778354644775,19.76845932006836,4.655216693878174,8.314453125,4.492719650268555,-2.406989336013794,11.528200149536133,-0.6209034323692322,10.659257888793945,15.070496559143066,1.3823000192642212,10.337091445922852,2.15250825881958,-1.0721726417541504,-1.2649168968200684,3.2714099884033203,15.666881561279297,-0.6206010580062866,15.773831367492676,21.735515594482422,7.447699069976807,10.624044418334961,7.603423118591309,7.547260284423828,16.079967498779297,5.853717803955078,15.089975357055664,10.904584884643555,21.46438980102539,13.519766807556152,5.339502811431885,11.581560134887695,12.591537475585938,-3.4645729064941406,5.656142234802246,20.243131637573242,9.282615661621094,14.734393119812012,8.999756813049316,-0.03843212127685547,5.5026116371154785,6.284721374511719,15.107256889343262,29.972347259521484,7.668495178222656,-0.8224818110466003,5.8061113357543945,9.684518814086914,7.071673393249512,6.587924003601074,3.5601775646209717,5.626086235046387,12.489618301391602,5.656094551086426,8.938088417053223,16.49776268005371,4.895593166351318,6.960526943206787,3.983783006668091,8.732294082641602,11.09826946258545,1.241755485534668,20.1558895111084,15.424924850463867,-1.6584290266036987,8.156327247619629,-4.640685558319092,-2.835540533065796,4.196916103363037,4.893558979034424,14.591005325317383,15.296913146972656,9.305604934692383,-0.848127543926239,-2.0782060623168945,11.662642478942871,17.604402542114258,-2.804003953933716,8.896106719970703,6.146132469177246,10.694671630859375,12.607860565185547,5.221158981323242,-2.4248132705688477,14.09682846069336,5.680761337280273,7.959798336029053,14.276359558105469,9.321935653686523,-1.024481177330017,7.896381855010986,7.578955173492432,7.526549339294434,4.42609977722168,2.7995970249176025,5.843776702880859,-3.2113943099975586,5.173770904541016,-1.051935076713562,2.5879151821136475,-1.463683009147644,14.413188934326172,8.884355545043945,6.485893249511719,23.051828384399414,12.073378562927246,10.937122344970703,6.9808220863342285,-4.368269443511963,5.890398979187012,18.985332489013672,10.951818466186523,5.392754077911377,-2.2666306495666504,2.5958311557769775,20.30604362487793,10.267679214477539,7.226306915283203,7.640926361083984,16.324085235595703,16.35581398010254,2.920706033706665,5.232666015625,9.727152824401855,14.724800109863281,8.781129837036133,6.0526580810546875,8.03912353515625,17.616880416870117,0.7732401490211487,17.834232330322266,30.553897857666016,5.0407938957214355,14.445392608642578,-1.4109818935394287,8.092331886291504,-2.009092330932617,-4.3161516189575195,10.681891441345215,0.5832059979438782,10.302593231201172,5.1886210441589355,6.601977348327637,9.910593032836914,1.2395999431610107,10.149104118347168,7.9584197998046875,15.109179496765137,9.124342918395996,5.911545276641846,10.903096199035645,11.018685340881348,-1.0447756052017212,4.685796737670898,10.560530662536621,9.081537246704102,9.619546890258789,9.916891098022461,10.082464218139648,14.08337688446045,4.5706634521484375,-0.24506716430187225,3.2285542488098145,11.76418399810791,8.673263549804688,6.719225883483887,6.5015482902526855,10.685394287109375,3.1910173892974854,-3.7521002292633057,9.16246223449707,6.787114143371582,19.009992599487305,9.252052307128906,12.176936149597168,6.4771342277526855,-2.6698007583618164,2.347642660140991,11.12503719329834,9.770678520202637,14.959273338317871,14.390130996704102,13.80323600769043,3.577765941619873,30.929492950439453,4.864286422729492,9.546268463134766,11.893417358398438,14.987427711486816,0.006026868242770433,6.9991302490234375,8.525433540344238,12.627822875976562,12.757963180541992,17.44341468811035,17.116912841796875,14.904511451721191,12.307875633239746,14.623892784118652,15.760761260986328,8.304266929626465,4.617492198944092,21.08785057067871,15.517855644226074,4.603346824645996,10.423773765563965,2.2465670108795166,14.203197479248047,8.115352630615234,31.061538696289062,12.59794807434082,-2.477811098098755,11.737035751342773,5.8471760749816895,2.5156614780426025,-1.3678570985794067,21.23793601989746,9.012354850769043,9.828332901000977,5.99059534072876,7.3541951179504395,-1.285003900527954,-1.6477755308151245,6.291728496551514,7.69423770904541,16.822738647460938,10.652033805847168,14.533493041992188,15.920480728149414,7.131368160247803,-3.654053211212158,0.6491982340812683,-0.9873794913291931,20.252025604248047,13.876971244812012,5.6150126457214355,10.737287521362305,8.99284839630127,9.363351821899414,10.324081420898438,13.52244758605957,5.962462902069092,6.997894287109375,-1.7707979679107666,4.708375453948975,12.979991912841797,14.596084594726562,15.87734603881836,6.338601589202881,8.554594039916992,13.763004302978516,10.371813774108887,18.626720428466797,6.767083644866943,5.198225975036621,1.077736258506775,13.881054878234863,-1.7774899005889893,14.125794410705566,14.06580638885498,14.72403335571289,-1.6196844577789307,6.458926200866699,-3.888155460357666,10.192142486572266,4.195529937744141,-1.7802777290344238,1.9925857782363892,6.948264122009277,5.159496784210205,15.215460777282715,30.899776458740234,-0.2820408344268799,20.825912475585938,-1.1570886373519897,10.269686698913574,10.755538940429688,9.36292839050293,6.435414791107178,5.533087730407715,15.61901569366455,31.894241333007812,15.24355697631836,5.410305976867676,16.988162994384766,-4.215479850769043,7.4686174392700195,16.9410400390625,4.336075782775879,9.261567115783691,14.3720121383667,3.535055160522461,12.857535362243652,6.320676326751709,4.168396949768066,10.383825302124023,9.798270225524902,8.705703735351562,6.399684429168701,11.351672172546387,22.016586303710938,6.755484104156494,16.041975021362305,4.125995635986328,5.635857582092285,16.893938064575195,3.9791715145111084,5.447801113128662,3.207535982131958,12.162620544433594,9.580031394958496,-0.60201495885849,16.837881088256836,13.182551383972168,14.94217300415039,14.582308769226074,7.665270805358887,8.885445594787598,6.403367519378662,12.499666213989258,-4.618819713592529,-3.8505656719207764,5.545065879821777,9.7017240524292,7.605257034301758,11.002854347229004,7.261524200439453,9.931195259094238,5.472750663757324,6.211961269378662,6.072692394256592,-0.16375714540481567,14.440635681152344,6.347507953643799,15.773446083068848,10.936671257019043,7.789439678192139,7.926898002624512,8.087715148925781,13.506706237792969,9.704442977905273,-0.1717713177204132,10.227910041809082,14.648255348205566,10.197524070739746,4.819270133972168,8.809704780578613,2.6052770614624023,9.365409851074219,10.579475402832031,8.4234619140625,15.289717674255371,5.731274604797363,-0.7204463481903076,20.47390365600586,4.733830451965332,13.159711837768555,9.892273902893066,7.529664993286133,5.529506206512451,12.26149845123291,3.68951416015625,6.8552470207214355,3.3384335041046143,6.358644485473633,9.546279907226562,-5.105184555053711,16.417539596557617,8.44031047821045,1.6657836437225342,10.92322826385498,12.07036304473877,9.283343315124512,2.051612138748169,15.585450172424316,17.962976455688477,8.836559295654297,14.188340187072754,6.8095831871032715,9.503280639648438,-0.4580366909503937,14.801695823669434,11.434328079223633,8.916437149047852,16.029218673706055,8.490473747253418,3.879617691040039,9.445176124572754,9.532760620117188,14.713282585144043,5.55802583694458,5.526209831237793,9.877886772155762,-3.437276601791382,22.029170989990234,1.840517520904541,23.07759666442871,23.18943214416504,4.964663505554199,2.1097891330718994,17.027328491210938,13.300081253051758,14.321022033691406,-3.040654420852661,9.97231388092041,6.098870754241943,9.03424072265625,6.25937032699585,-0.234506294131279,9.35116958618164,8.127340316772461,15.791125297546387,7.979698181152344,9.486032485961914,5.4086198806762695,5.928439617156982,4.232578754425049,10.418498992919922,3.1419899463653564,14.835155487060547,8.743066787719727,13.220878601074219,4.559865474700928,-4.757358074188232,15.094630241394043,4.981107234954834,4.171247959136963,15.078771591186523,-1.5581947565078735,5.544297695159912,14.668346405029297,9.434527397155762,15.339726448059082,3.641413450241089,4.5550971031188965,6.318709850311279,1.864046573638916,17.919029235839844,-0.6538214087486267,-3.849669933319092,2.2887306213378906,23.900060653686523,-1.4126546382904053,6.448967933654785,4.438506126403809,3.5778353214263916,17.280155181884766,5.64785623550415,9.729521751403809,-1.976585030555725,16.446250915527344,11.40971565246582,3.5206592082977295,5.887420177459717,3.114220142364502,3.853034496307373,5.470633029937744,7.925840377807617,8.786530494689941,10.291033744812012,13.434626579284668,12.489303588867188,11.693337440490723,15.496106147766113,13.817560195922852,-1.5720717906951904,6.987701892852783,7.324088096618652,15.478094100952148,5.87994384765625,5.53413200378418,7.039211273193359,6.203047752380371,12.509081840515137,6.750546455383301,5.349732398986816,7.752354621887207,5.962273597717285,3.5488717555999756,5.3602213859558105,7.842550754547119,15.00337028503418,-1.2819819450378418,8.781577110290527,8.971076965332031,31.713027954101562,11.086381912231445,-2.3819901943206787,4.965717792510986,10.147522926330566,6.129459381103516,6.079638481140137,21.696420669555664,14.370893478393555,-4.003570556640625,14.412415504455566,-1.3306368589401245,12.34274673461914,-0.09550309181213379,3.8775928020477295,10.163686752319336,2.3906993865966797,4.022775173187256,0.7449581623077393,16.08558464050293,3.757869005203247,5.549006462097168,5.546380519866943,6.585447311401367,10.246976852416992,9.116198539733887,5.416449546813965,12.579954147338867,14.479263305664062,9.922662734985352,9.396340370178223,-3.2080881595611572,-0.7130460739135742,-2.8107621669769287,14.173553466796875,10.527324676513672,5.493494033813477,8.04000186920166,4.869380950927734,-0.8617914319038391,7.749521255493164,3.582930326461792,6.829599857330322,14.240403175354004,17.369304656982422,3.430290937423706,2.3334622383117676,9.784682273864746,14.21321964263916,10.311381340026855,-1.7122671604156494,7.959321975708008,14.63415813446045,9.162871360778809,3.602250337600708,10.578367233276367,14.667500495910645,10.49746322631836,10.326177597045898,13.697683334350586,9.799285888671875,5.147750377655029,6.246872425079346,13.935531616210938,21.290573120117188,5.338279724121094,14.381107330322266,10.430676460266113,9.761706352233887,4.7811079025268555,13.26772403717041,2.651819944381714,13.402467727661133,5.650549411773682,13.326362609863281,10.313496589660645,7.709081172943115,7.545042991638184,10.482925415039062,4.016689777374268,-0.4442884027957916,-2.175959587097168,4.131730556488037,0.46268871426582336,7.469341278076172,1.7959446907043457,10.348004341125488,15.461108207702637,6.332949638366699,5.108413219451904,6.68015193939209,15.838468551635742,14.054728507995605,5.8893561363220215,13.2091646194458,15.432083129882812,12.802594184875488,4.459641933441162,15.743865013122559,15.447968482971191,7.409459114074707,8.204062461853027,13.959990501403809,8.441787719726562,9.979769706726074,5.365921974182129,4.647134304046631,3.9380998611450195,-3.4077346324920654,8.463294982910156,12.922643661499023,15.670777320861816,13.291556358337402,7.178610801696777,3.9313528537750244,4.981767177581787,-0.9059227108955383,15.412403106689453,8.140982627868652,-3.016585111618042,6.921610355377197,6.136865139007568,17.0095157623291,10.275381088256836,30.64618492126465,2.813194751739502,3.89524507522583,13.883196830749512,13.60165786743164,5.332529067993164,-0.16760818660259247,14.032853126525879,-1.9565714597702026,-0.25166770815849304,12.954325675964355,0.11544271558523178,-3.0674936771392822,14.908663749694824,-0.36376696825027466,13.568477630615234,6.303272247314453,10.292948722839355,24.211017608642578,1.8986001014709473,10.342631340026855,16.753257751464844,10.752969741821289,-0.3022121787071228,1.7302626371383667,7.382047176361084,3.9226582050323486,3.463711738586426,10.671186447143555,8.380752563476562,7.780655384063721,1.6529847383499146,11.333081245422363,12.254912376403809,3.426969289779663,10.865200996398926,16.118886947631836,6.270297527313232,6.560305118560791,8.6137113571167,5.793666839599609,0.1314469575881958,7.67092752456665,4.345062255859375,30.582534790039062,6.67238712310791,16.824907302856445,2.84208345413208,3.300724506378174,-2.3179469108581543,8.340338706970215,11.10873794555664,10.884941101074219,17.425859451293945,12.350334167480469,9.27204704284668,14.986737251281738,0.052706748247146606,-1.6485406160354614,-1.014514446258545,-1.6930017471313477,2.397294044494629,7.790370941162109,9.604650497436523,12.045098304748535,12.42147445678711,13.8349609375,4.372005939483643,6.758205890655518,9.455711364746094,10.701752662658691,6.715385913848877,5.399704933166504,15.365344047546387,-2.606962203979492,5.52889347076416,7.908519744873047,3.7047536373138428,-4.346850395202637,16.86881446838379,3.0852062702178955,-3.1989259719848633,7.104519367218018,10.166422843933105,15.446073532104492,6.591392993927002,5.874336242675781,7.045558929443359,16.519189834594727,8.109319686889648,16.172945022583008,11.894584655761719,16.506385803222656,0.9069950580596924,12.896398544311523,3.166594982147217,-3.4777345657348633,7.523480415344238,-1.9743746519088745,3.9568700790405273,-2.6923906803131104,10.644556999206543,5.529138565063477,16.861841201782227,11.131139755249023,-3.358262062072754,6.639126300811768,5.705672740936279,12.213873863220215,7.30340051651001,19.603490829467773,3.454184055328369,-2.1823086738586426,-3.902940511703491,-1.3431447744369507,0.7483174204826355,9.685685157775879,10.722732543945312,3.533623218536377,5.983223915100098,-1.8606449365615845,6.013963222503662,21.960063934326172,15.122026443481445,7.727001190185547,3.0547518730163574,8.657888412475586,12.590483665466309,11.335689544677734,16.114194869995117,8.03889274597168,12.402273178100586,2.6866753101348877,5.950875759124756,24.174219131469727,16.1634578704834,18.2835636138916,8.252267837524414,14.653424263000488,-0.4412091374397278,7.760929584503174,16.190196990966797,5.28441047668457,0.5516844987869263,10.026634216308594,6.192536354064941,9.779848098754883,5.454680442810059,6.808882236480713,3.1236257553100586,16.304588317871094,2.2721269130706787,8.967188835144043,14.152597427368164,7.478974342346191,7.904541492462158,2.5488250255584717,10.255437850952148,7.531139850616455,10.381197929382324,3.3894922733306885,8.240824699401855,20.289663314819336,7.998329162597656,8.347283363342285,6.9272942543029785,10.552258491516113,14.696338653564453,1.3585827350616455,8.0570068359375,24.4447078704834,16.32709312438965,17.777999877929688,24.70442771911621,8.83362102508545,14.241737365722656,21.79086685180664,10.661069869995117,-2.807647466659546,5.475766658782959,15.266446113586426,5.690805435180664,-1.9792873859405518,11.246755599975586,16.113773345947266,4.026843547821045,7.632134914398193,8.899950981140137,14.159261703491211,4.481553554534912,10.407933235168457,21.890050888061523,8.605984687805176,16.0225887298584,10.014901161193848,-0.22747240960597992,5.5916428565979,12.587028503417969,6.035184860229492,1.6891001462936401,15.849940299987793,13.401576042175293,16.974912643432617,5.994102954864502,-0.5932109355926514,-4.977242469787598,4.070840835571289,5.482875347137451,7.70626163482666,14.369924545288086,14.72485637664795,7.362228870391846,-2.002562999725342,-2.039680004119873,13.346518516540527,-0.501261293888092,15.121082305908203,16.11166763305664,30.899080276489258,8.893270492553711,-4.879443645477295,9.45118236541748,5.8429975509643555,3.027535915374756,2.356954574584961,3.8707833290100098,12.892012596130371,3.37795090675354,5.240411758422852,11.049667358398438,5.441891670227051,16.65006446838379,0.43798476457595825,6.935516357421875,10.575018882751465,9.769835472106934,23.660377502441406,6.54203462600708,3.2698404788970947,9.673035621643066,0.25380799174308777,-0.7340164184570312,7.939759254455566,22.113107681274414,14.021254539489746,-1.2314625978469849,7.104291915893555,2.341893434524536,10.153457641601562,3.9575858116149902,6.012841701507568,7.550690650939941,30.303483963012695,11.073915481567383,11.768516540527344,-1.5496145486831665,5.212242126464844,-3.871553897857666,17.349340438842773,1.9742547273635864,-1.5157254934310913,-1.2523857355117798,6.067640781402588,10.23453426361084,5.100801944732666,8.616053581237793,9.797383308410645,-0.7172805666923523,6.33867883682251,15.70022964477539,3.511463165283203,8.472922325134277,5.925278186798096,10.846040725708008,15.806209564208984,7.545350074768066,8.579625129699707,0.3192062973976135,4.5267252922058105,-2.2440059185028076,-3.720367908477783,-1.1983671188354492,15.392394065856934,16.106529235839844,-3.9511337280273438,5.727230072021484,5.8660688400268555,9.255412101745605,4.457098960876465,10.820500373840332,7.294715404510498,14.928369522094727,15.794050216674805,6.142768383026123,15.290669441223145,8.859638214111328,10.155485153198242,2.839380979537964,-0.9430215358734131,13.540872573852539,-0.5911639928817749,3.1683602333068848,5.934106826782227,15.419612884521484,4.019034385681152,9.133095741271973,5.228785991668701,11.860125541687012,17.833139419555664,11.617342948913574,5.554988384246826,2.673461675643921,8.531076431274414,9.2611722946167,-2.215007781982422,2.9557013511657715,-3.966728925704956,-2.1874773502349854,2.5487306118011475,2.413986921310425,-0.572942852973938,15.548638343811035,0.38071995973587036,7.385915756225586,12.758484840393066,-3.5381851196289062,14.908120155334473,15.273265838623047,9.471695899963379,14.770461082458496,3.8265411853790283,12.414143562316895,8.382006645202637,-0.5133323073387146,4.855861663818359,15.714910507202148,9.375005722045898,13.374496459960938,3.0018868446350098,15.181783676147461,-2.649312734603882,3.196197986602783,5.983449935913086,6.984504699707031,4.634011268615723,-1.4716843366622925,7.2722859382629395,19.767736434936523,7.646369457244873,9.053175926208496,6.282536029815674,3.155914545059204,6.269354820251465,4.7437567710876465,0.6278661489486694,9.560381889343262,8.267964363098145,0.4305787682533264,6.528480529785156,15.75300121307373,14.551098823547363,15.11542797088623,-2.577155828475952,15.738694190979004,7.0450119972229,13.042274475097656,-2.298326015472412,8.363324165344238,8.091693878173828,3.9219346046447754,3.36161732673645,6.482936382293701,2.446432113647461,4.690476894378662,4.14154052734375,14.211922645568848,4.054015636444092,0.319985032081604,1.6993167400360107,7.69283390045166,6.126918792724609,16.081003189086914,9.791924476623535,5.193322658538818,5.097914218902588,21.14838218688965,15.757709503173828,-4.886580944061279,4.06955099105835,10.580031394958496,6.669850826263428,10.383262634277344,4.386204719543457,-3.0610485076904297,9.13766860961914,5.588662147521973,12.280923843383789,-2.604816436767578,-3.214301824569702,16.39051055908203,15.246955871582031,16.010801315307617,20.956579208374023,15.60517692565918,14.487054824829102,1.1558120250701904,8.13002872467041,14.612444877624512,10.305763244628906,31.336301803588867,8.441627502441406,20.43042755126953,29.656620025634766,10.803494453430176,3.4091732501983643,15.6826171875,24.225208282470703,4.346067905426025,12.361686706542969,6.369575023651123,8.854819297790527,10.171706199645996,-0.752036452293396,9.718143463134766,2.559040069580078,5.486771106719971,15.924789428710938,15.283756256103516,6.111952781677246,-2.1098744869232178,17.6163387298584,5.614045143127441,20.352224349975586,14.347885131835938,30.038259506225586,-3.8120980262756348,5.611405849456787,6.495670795440674,6.2281036376953125,13.905505180358887,6.313732147216797,12.47167682647705,7.287408351898193,9.526873588562012,7.390023708343506,20.056270599365234,14.920816421508789,15.269156455993652,7.520022392272949,16.02608299255371,15.694993019104004,19.82602310180664,16.262866973876953,16.99051284790039,3.2418811321258545,1.4162248373031616,6.345893383026123,9.536735534667969,9.057372093200684,3.6130001544952393,15.668100357055664,8.968835830688477,10.27426528930664,10.090482711791992,16.17234992980957,13.484118461608887,16.64585304260254,-0.011764816008508205,14.159818649291992,17.740489959716797,6.433501243591309,10.34268569946289,9.542686462402344,15.206354141235352,-1.17438805103302,7.693182945251465,20.187259674072266,9.609156608581543,14.561211585998535,24.60260772705078,13.697319984436035,2.8357763290405273,11.575263977050781,-3.4257266521453857,3.7907376289367676,5.839991569519043,-1.8404901027679443,5.7935919761657715,11.236087799072266,6.158980846405029,6.29434061050415,4.453516483306885,2.4721522331237793,3.618821144104004,5.5202813148498535,7.597151756286621,5.51705265045166,2.8130266666412354,9.437911033630371,6.825131416320801,6.473729133605957,9.233942985534668,5.140151023864746,7.531794548034668,5.39591646194458,9.116897583007812,6.728850364685059,-1.3702592849731445,-1.2771129608154297,-4.231285095214844,9.178174018859863,-1.4646031856536865,7.751217842102051,5.915364742279053,10.686702728271484,5.636287212371826,5.425405979156494,12.623501777648926,13.036789894104004,1.2113416194915771,12.420804023742676,2.9583117961883545,6.772970199584961,14.07458209991455,13.478907585144043,2.4740467071533203,14.943879127502441,4.659524440765381,7.886772155761719,10.094718933105469,4.5263752937316895,5.2624945640563965,15.900235176086426,12.295639991760254,-0.4759295582771301,4.497258186340332,7.110163688659668,4.760278701782227,3.9159364700317383,-3.266265392303467,4.424311637878418,17.341964721679688,21.909379959106445,-1.8378535509109497,7.234633922576904,6.913219928741455,15.643986701965332,30.34386444091797,-1.768619418144226,11.03274154663086,14.175614356994629,0.11657354980707169,3.2469961643218994,3.380857229232788,6.857799053192139,-3.0958750247955322,9.03359603881836,10.578405380249023,4.576152324676514,4.126607894897461,9.049644470214844,9.716951370239258,6.617191791534424,9.497679710388184,-1.9686551094055176,6.492424011230469,8.100107192993164,-5.22703218460083,7.944356441497803,10.835993766784668,-1.2868926525115967,8.793468475341797,7.204627513885498,8.329768180847168,6.507226943969727,9.97510814666748,23.156749725341797,9.67779541015625,8.366312980651855,9.981331825256348,7.193383693695068,4.570688724517822,15.585223197937012,-4.088999271392822,17.892621994018555,17.256563186645508,5.907687664031982,5.22281551361084,15.582192420959473,20.457828521728516,5.339810371398926,31.345361709594727,14.372757911682129,3.7540676593780518,1.146966576576233,3.6706326007843018,10.441555976867676,15.34731674194336,5.999413967132568,1.180485725402832,6.589346885681152,-1.0373477935791016,9.194969177246094,13.378886222839355,15.358025550842285,-1.0950127840042114,4.306581974029541,9.811691284179688,7.448078632354736,6.3295578956604,15.247817039489746,30.4438533782959,-1.0594052076339722,15.361124992370605,-4.840096950531006,-0.38175657391548157,15.326581954956055,13.675783157348633,1.1938605308532715,6.281639575958252,15.768064498901367,4.5412468910217285,14.96168041229248,-3.286963939666748,-1.2193270921707153,6.368879795074463,29.91949462890625,8.230978012084961,10.565181732177734,-3.8587727546691895,11.414752006530762,5.714488506317139,5.485848903656006,5.54162073135376,-3.899120569229126,4.919203758239746,5.114600658416748,8.913227081298828,11.987645149230957,5.241713047027588,-2.543856620788574,14.12376594543457,-2.883723258972168,0.02594529651105404,22.125364303588867,-0.02622641995549202,17.067018508911133,10.822874069213867,8.029947280883789,-3.177910566329956,10.006142616271973,14.356527328491211,8.174142837524414,14.144407272338867,10.320658683776855,6.072737693786621,13.04606819152832,2.5345726013183594,6.042454719543457,4.413275241851807,4.81200647354126,14.474955558776855,8.537063598632812,13.493117332458496,15.949278831481934,10.375236511230469,5.941681385040283,6.850491523742676,-3.422349691390991,9.563002586364746,14.177668571472168,7.735841751098633,14.62557315826416,4.21950626373291,10.257173538208008,3.0781280994415283,8.992972373962402,8.42605209350586,14.816720008850098,9.954842567443848,0.6681254506111145,9.242650032043457,7.204506874084473,12.103422164916992,5.480014801025391,9.098596572875977,5.810632228851318,14.412862777709961,9.465439796447754,5.90704345703125,14.223433494567871,9.718896865844727,6.169312477111816,24.520917892456055,16.47699737548828,4.088268280029297,8.08103084564209,30.258056640625,2.2545058727264404,7.32468318939209,5.737854480743408,11.77713680267334,23.82662010192871,5.851008892059326,9.067465782165527,9.574532508850098,12.562307357788086,10.029425621032715,5.667824745178223,6.5226359367370605,31.272911071777344,6.112063407897949,9.444097518920898,7.3017191886901855,5.466996669769287,5.959094047546387,11.98128604888916,9.78885555267334,-0.9147563576698303,4.026026248931885,-1.1075974702835083,6.473783016204834,7.977245330810547,9.419548034667969,8.614778518676758,2.2123494148254395,14.221000671386719,-0.7524023056030273,5.040459156036377,10.643580436706543,2.1480937004089355,9.831144332885742,-2.006282091140747,7.105239391326904,8.147462844848633,2.5803890228271484,4.883159637451172,6.850945472717285,11.911999702453613,6.304821968078613,9.980466842651367,14.651443481445312,9.921442985534668,14.553533554077148,3.5372772216796875,5.761327266693115,14.998791694641113,6.276838302612305,5.848100185394287,9.788399696350098,6.5588788986206055,-0.9597964882850647,11.125731468200684,5.538743019104004,16.64979362487793,8.708280563354492,5.960022926330566,12.239706993103027,21.698396682739258,7.1946892738342285,3.405143976211548,11.967159271240234,-1.3944419622421265,4.471757411956787,11.092052459716797,9.540116310119629,-0.8876268863677979,15.850181579589844,17.771268844604492,10.402525901794434,29.841798782348633,5.527982711791992,4.543675422668457,15.941944122314453,7.278738498687744,17.15713119506836,10.07798957824707,9.684803009033203,10.151352882385254,10.522992134094238,9.480671882629395,7.180079460144043,10.848175048828125,10.630507469177246,8.067903518676758],\"y\":[6.14813756942749,5.301786422729492,4.429060459136963,4.913839340209961,4.387616157531738,3.79673171043396,6.307894706726074,-1.4702025651931763,-0.4047945737838745,6.1635918617248535,13.76734733581543,0.9303878545761108,6.212696552276611,8.709794044494629,4.635494709014893,0.21791234612464905,3.186023712158203,-0.6378796696662903,-6.1833882331848145,-0.12301572412252426,15.7596435546875,15.9695463180542,-4.1901936531066895,17.1979923248291,8.272355079650879,7.135176658630371,3.8977210521698,-3.075420618057251,6.961543560028076,20.91317367553711,7.953710556030273,-2.413121461868286,-0.44851478934288025,13.79478931427002,-0.43487703800201416,4.684791564941406,-6.0060553550720215,-8.708354949951172,13.47252082824707,2.548717737197876,-0.33265066146850586,-1.6400035619735718,1.6807210445404053,-0.1499963402748108,0.25511226058006287,1.9031693935394287,4.480918884277344,5.892838478088379,4.488662242889404,4.475327014923096,-2.7549731731414795,-1.287980318069458,16.880985260009766,13.563403129577637,7.802254676818848,2.2833192348480225,-0.6648275256156921,3.702251434326172,-1.3587932586669922,-2.29352068901062,-4.815088748931885,8.031800270080566,-5.2767252922058105,-7.989709377288818,7.228559494018555,8.290979385375977,7.460687637329102,0.52885502576828,5.92613410949707,1.9557595252990723,-3.252034902572632,4.900868892669678,2.00260329246521,15.288713455200195,0.49553200602531433,-4.946910858154297,4.527639389038086,-0.14849282801151276,14.637541770935059,-8.471235275268555,2.073904037475586,-3.5712618827819824,7.214406967163086,-0.3560853898525238,8.288413047790527,6.240735054016113,4.095879554748535,4.485720157623291,-1.003391146659851,8.039962768554688,4.025506496429443,9.332666397094727,12.182759284973145,-1.5838351249694824,4.2344794273376465,6.145914077758789,2.4802145957946777,5.540050983428955,6.872585296630859,7.977926254272461,-6.279621124267578,-2.9192090034484863,14.087689399719238,1.353789210319519,13.083390235900879,7.808326721191406,7.908924579620361,8.248115539550781,5.317257881164551,1.728248953819275,6.175978183746338,-2.491112470626831,-4.249331474304199,8.135912895202637,7.590554714202881,6.131641864776611,5.979249000549316,1.7012912034988403,12.553275108337402,16.135522842407227,6.307007789611816,5.136382102966309,7.716822147369385,-6.168945789337158,6.358876705169678,7.210792064666748,5.097386360168457,4.158943176269531,-7.301263332366943,6.991236686706543,3.179844856262207,-3.0447230339050293,1.430448055267334,3.3098275661468506,17.691547393798828,7.484562873840332,7.152260780334473,5.403470993041992,7.146379470825195,1.566029667854309,13.389820098876953,7.892482757568359,-4.337165355682373,6.377155780792236,12.58012580871582,4.992061614990234,9.906478881835938,-1.9651131629943848,3.340956449508667,0.38314178586006165,-0.9685337543487549,-4.282447338104248,2.741410970687866,7.203975677490234,-6.280332088470459,8.850530624389648,2.772725820541382,5.387612819671631,7.396237373352051,16.79738426208496,1.941625952720642,-0.2906336486339569,-1.5070934295654297,7.316122531890869,0.553813636302948,15.263872146606445,14.175640106201172,4.588761806488037,6.15784215927124,7.799075603485107,8.944562911987305,3.834015130996704,7.833429336547852,-0.1374417245388031,5.16622257232666,-1.1273748874664307,4.354115009307861,2.1417369842529297,7.545951843261719,-0.3698306679725647,4.232178211212158,-0.9475512504577637,5.328678607940674,7.639290809631348,7.175933361053467,5.521310806274414,4.93494987487793,-3.642693281173706,-3.4195053577423096,7.182497501373291,-8.601383209228516,2.1452322006225586,8.96844482421875,4.19888162612915,10.486927032470703,3.7334861755371094,-4.2737836837768555,15.086702346801758,13.007039070129395,8.817564964294434,5.046633243560791,6.175942420959473,13.283636093139648,2.7476859092712402,3.8866963386535645,-6.356616973876953,3.8348920345306396,-3.5222861766815186,2.004812240600586,2.5472054481506348,14.279093742370605,0.8110478520393372,4.141079902648926,7.559075832366943,10.585342407226562,-1.3990044593811035,-7.037127494812012,-2.01397967338562,-6.543705940246582,15.48311996459961,5.796085834503174,3.98868465423584,5.510857105255127,-0.7750116586685181,7.77974796295166,4.7271013259887695,5.014682292938232,1.3582795858383179,-1.185566782951355,8.190360069274902,4.443196773529053,-7.347524642944336,5.054320335388184,6.315281867980957,0.08117829263210297,2.7099947929382324,0.7976296544075012,17.13644790649414,1.968013882637024,8.63592529296875,4.754593372344971,6.443296432495117,8.636536598205566,5.235480785369873,5.090291500091553,-4.235614776611328,6.731983184814453,7.273775577545166,-6.874248027801514,-1.8428730964660645,-6.837371349334717,-5.371512413024902,2.2788145542144775,-8.270649909973145,1.2824171781539917,17.219989776611328,5.106165409088135,5.087857723236084,4.306381702423096,2.3169827461242676,3.7676570415496826,1.241774082183838,3.3799943923950195,6.063041687011719,-0.788731575012207,13.57848834991455,-0.5503364205360413,2.0693204402923584,6.190174579620361,6.968960285186768,12.247790336608887,8.12452507019043,3.840169668197632,1.4964966773986816,4.293564319610596,1.7328541278839111,2.9582149982452393,7.50715970993042,7.241602420806885,-1.331942081451416,3.378345251083374,-5.103175640106201,-4.48955774307251,-4.373410224914551,6.972916126251221,5.72285795211792,7.418399810791016,16.063371658325195,13.343313217163086,6.3229522705078125,1.3600513935089111,8.442598342895508,8.477952003479004,6.293469429016113,11.899236679077148,-0.9265012741088867,7.330230712890625,3.239961862564087,2.7342560291290283,4.9540581703186035,2.1631698608398438,-3.3609085083007812,9.614596366882324,0.8509044647216797,14.184045791625977,-4.118028163909912,9.438017845153809,2.2517521381378174,-1.0133230686187744,2.6698098182678223,2.7502849102020264,-4.5391411781311035,9.207440376281738,1.7021138668060303,6.18326997756958,5.172021389007568,4.708725452423096,0.6567452549934387,9.945449829101562,8.852706909179688,6.599761009216309,3.361436605453491,-0.006486724130809307,2.385568618774414,1.607513189315796,-7.142547130584717,5.165141582489014,10.56084156036377,-1.7093932628631592,1.0069063901901245,-5.767018795013428,-4.286301136016846,11.445588111877441,-5.759949207305908,0.08338518440723419,-2.530358076095581,-6.102378845214844,-2.670907974243164,8.378708839416504,0.37119781970977783,6.386932373046875,3.450211763381958,4.915008544921875,1.886297583580017,8.645564079284668,7.141289234161377,-0.27000901103019714,-6.74969482421875,4.323184967041016,5.523563861846924,-0.2734466791152954,12.250109672546387,-4.342952251434326,-3.1275081634521484,13.767175674438477,0.24662238359451294,2.184135913848877,6.033489227294922,-1.5439375638961792,6.677126884460449,5.042908668518066,-0.04506580904126167,-4.718167304992676,14.572614669799805,5.659700870513916,6.143002033233643,1.4503194093704224,1.5333608388900757,-0.8568273782730103,5.550302982330322,4.197974681854248,-0.8684937953948975,0.24717292189598083,13.307452201843262,-0.5080615282058716,9.465095520019531,3.775805950164795,-4.05756950378418,14.229802131652832,4.025755882263184,7.3820905685424805,5.91360330581665,1.6357651948928833,-1.269097924232483,8.565352439880371,3.3286046981811523,8.23628044128418,21.18547821044922,-0.48981615900993347,7.944756507873535,5.869874954223633,4.37006950378418,4.807724952697754,1.5320615768432617,-4.602991104125977,2.4403231143951416,-5.620234966278076,1.9404479265213013,4.449430465698242,0.09326101094484329,4.0850605964660645,-1.0043400526046753,2.0282535552978516,-1.0753417015075684,-2.5013537406921387,5.98351526260376,6.204457759857178,7.084070682525635,7.397822856903076,5.703957557678223,-0.525621771812439,-1.1736358404159546,7.421573638916016,-0.3529133200645447,0.622329592704773,8.252337455749512,6.474368572235107,0.244155615568161,0.22291213274002075,-5.003501892089844,9.06528377532959,6.642613410949707,-0.2369069755077362,-4.330696105957031,2.644721508026123,4.085965156555176,8.255253791809082,3.2409582138061523,-4.373939514160156,1.3496285676956177,4.002774238586426,6.186990261077881,-3.1175601482391357,-0.5892938375473022,7.694094657897949,-2.5553267002105713,6.973503112792969,5.817773818969727,6.812533855438232,1.9975708723068237,5.3533616065979,13.298482894897461,9.152032852172852,8.43880844116211,-0.8361976742744446,6.539015769958496,3.586967706680298,-0.9736893177032471,6.869541645050049,6.356445789337158,-4.591217994689941,7.796549320220947,1.8163502216339111,1.9102486371994019,7.074812889099121,-3.28610897064209,13.25314712524414,-1.5867292881011963,4.136479377746582,2.5095417499542236,-7.595149517059326,4.165499687194824,-2.6901488304138184,8.029221534729004,5.771789073944092,0.18850527703762054,1.1814664602279663,3.5483505725860596,1.2208987474441528,7.25015115737915,7.901776313781738,-3.182070016860962,5.734827518463135,-0.9890391230583191,16.342966079711914,-1.8032478094100952,8.356860160827637,3.4825446605682373,4.0030388832092285,5.016913414001465,6.082235336303711,-5.477542877197266,-1.0599900484085083,4.225025653839111,4.882440090179443,8.87995719909668,8.426961898803711,9.627237319946289,13.805810928344727,4.268904685974121,-5.896398067474365,-7.504194736480713,-7.264542579650879,-8.18563461303711,2.496938467025757,7.5932769775390625,11.876447677612305,2.1611328125,6.789865016937256,5.440669059753418,-0.8609665632247925,-7.717176914215088,4.590029239654541,-1.268664836883545,8.333868980407715,1.1583364009857178,17.357812881469727,5.717792510986328,-3.188427686691284,3.6741180419921875,4.732497215270996,0.26571375131607056,1.0402213335037231,5.896650791168213,8.656036376953125,-1.2993894815444946,5.240669250488281,0.9924896359443665,4.911485195159912,1.6273436546325684,-7.461677074432373,8.624052047729492,17.13825798034668,7.423648834228516,6.77288818359375,3.408358573913574,-0.1918104588985443,3.294434070587158,9.174129486083984,0.2969547212123871,-1.4950761795043945,3.9852800369262695,-0.7870341539382935,6.142874240875244,6.238293647766113,-0.05629339441657066,-0.465667724609375,-0.7838158011436462,4.343606472015381,5.383120059967041,2.2222204208374023,10.654411315917969,4.323541164398193,-1.3840397596359253,7.47066068649292,12.261438369750977,-5.363658905029297,0.4422573149204254,-0.047018349170684814,5.87189245223999,7.195530414581299,21.322372436523438,9.034259796142578,16.122875213623047,8.639240264892578,6.579311370849609,0.22394225001335144,0.4925360381603241,7.823652267456055,1.1086338758468628,-3.4560277462005615,12.00536060333252,8.601019859313965,-2.9141478538513184,-7.288467884063721,8.565523147583008,5.817687511444092,12.381742477416992,8.435813903808594,9.701516151428223,4.782788276672363,5.4060821533203125,7.721059322357178,-0.5522447824478149,0.6694400906562805,-3.014606237411499,2.6529195308685303,5.202810764312744,6.192615509033203,3.1578636169433594,6.140284538269043,4.326066017150879,-2.7494466304779053,8.988272666931152,9.72900104522705,-1.2588499784469604,3.7374513149261475,0.9852461218833923,5.961220741271973,1.1516380310058594,5.346913814544678,8.214673042297363,1.3849797248840332,4.879843711853027,8.131945610046387,2.6207027435302734,8.511720657348633,8.023310661315918,9.647759437561035,-1.9881727695465088,4.8232221603393555,2.994925022125244,-0.5906059741973877,5.308838367462158,1.2036751508712769,6.137289047241211,6.805331230163574,-4.050753116607666,13.429817199707031,7.88575553894043,-2.4171786308288574,6.350497722625732,2.3226191997528076,6.082579612731934,0.06534194946289062,7.58740758895874,0.7126486301422119,0.5001037120819092,-3.389552593231201,-2.8549082279205322,1.9558895826339722,9.224308013916016,4.696098804473877,-4.7670745849609375,4.785073280334473,3.1665027141571045,7.496363639831543,0.6183395981788635,1.9626893997192383,9.670698165893555,5.725260257720947,0.4455137848854065,7.964174747467041,6.501895427703857,-3.989586353302002,3.3452720642089844,-0.4821621775627136,7.502224922180176,8.135144233703613,4.814479351043701,-0.7610157132148743,-1.0511932373046875,6.149980545043945,13.160240173339844,7.841280937194824,5.985702991485596,7.044920921325684,4.709207057952881,0.3630329370498657,1.1848911046981812,7.706938743591309,-1.2260746955871582,4.501572132110596,2.7430527210235596,16.609954833984375,2.186588764190674,-0.40217864513397217,6.062616348266602,7.823564052581787,7.935490608215332,5.747042655944824,5.127414703369141,1.9061640501022339,-3.466928482055664,2.590841293334961,4.092024326324463,5.776954174041748,4.941619873046875,4.828559398651123,3.4478254318237305,7.065855503082275,1.3437459468841553,-2.767791986465454,0.07786908000707626,-4.9010748863220215,1.808180809020996,5.933903694152832,4.486721992492676,14.798665046691895,0.03828415647149086,4.78668212890625,2.0419204235076904,8.903602600097656,15.456653594970703,4.989305019378662,4.844366073608398,2.750730514526367,7.753750801086426,3.149705648422241,7.3334174156188965,-7.0918989181518555,6.701683521270752,-2.7207741737365723,8.162263870239258,-5.195397853851318,6.3847737312316895,13.107878684997559,14.838809967041016,7.355336666107178,3.423159599304199,7.92446231842041,-0.7414466738700867,7.975314140319824,5.319677352905273,-6.983895778656006,5.637279033660889,-1.9533138275146484,5.667064666748047,8.312414169311523,-1.1130893230438232,1.8583403825759888,-1.3290934562683105,5.467082977294922,6.8682379722595215,3.8129889965057373,7.675141334533691,-5.364606857299805,1.2798210382461548,7.1794281005859375,6.9393630027771,8.609278678894043,13.807509422302246,5.241330146789551,0.8334168791770935,5.435662269592285,-5.833457946777344,7.345452308654785,4.252602577209473,1.5416351556777954,4.751150608062744,1.480563998222351,15.320112228393555,-2.8298087120056152,3.935370445251465,6.85230827331543,7.415358066558838,9.807382583618164,9.202622413635254,-7.840290069580078,0.8288144469261169,-2.513627529144287,-0.8017733693122864,2.299713134765625,1.8942691087722778,-1.2093586921691895,4.635915756225586,0.21336787939071655,14.059468269348145,-4.44271183013916,-0.52260822057724,-4.252345561981201,7.0973615646362305,10.852824211120605,-4.4359450340271,12.120134353637695,0.8492931127548218,13.133835792541504,-5.698422908782959,4.094280242919922,-2.7796471118927,10.001791954040527,6.28456974029541,4.259872913360596,-1.127816081047058,-1.3254690170288086,9.080283164978027,-5.418969631195068,1.39952552318573,-1.5342357158660889,5.850841045379639,7.435775279998779,5.192263126373291,7.299675941467285,2.6237986087799072,12.579855918884277,-0.03593672066926956,6.903570175170898,5.854018211364746,1.0092908143997192,7.998778343200684,4.841187477111816,7.521239280700684,-2.82122540473938,13.952640533447266,21.228309631347656,3.943201780319214,-1.4240375757217407,4.264081954956055,5.335577011108398,-4.937567710876465,12.810669898986816,13.672174453735352,2.6297929286956787,13.512348175048828,-2.051847457885742,6.521050930023193,-0.45787113904953003,7.626415252685547,-1.291109323501587,3.0956830978393555,4.08653450012207,7.042462348937988,-0.667580246925354,5.324773788452148,-7.84239387512207,3.4275593757629395,15.515925407409668,-4.979040145874023,0.47362467646598816,2.989267110824585,7.562984943389893,-8.145354270935059,-0.1874951720237732,14.102607727050781,0.33344608545303345,6.0656538009643555,13.824310302734375,-0.0764235109090805,6.773926258087158,12.895910263061523,7.841366291046143,-7.3245320320129395,6.788157939910889,1.1800870895385742,8.340536117553711,10.37406063079834,3.2828588485717773,-2.5763232707977295,-2.7175183296203613,2.2769763469696045,5.364096641540527,3.373434066772461,5.405828475952148,6.47194242477417,3.6875600814819336,4.80314826965332,-3.0131676197052,5.894551753997803,17.07654571533203,6.092311382293701,8.303812980651855,-2.213526487350464,-5.986484527587891,21.080322265625,7.934963703155518,12.594478607177734,3.3105430603027344,-1.388430118560791,-1.0349233150482178,8.384403228759766,8.125346183776855,5.302053928375244,3.176647186279297,-1.6404247283935547,5.770980358123779,-2.812405586242676,5.908755302429199,7.823486328125,0.13250556588172913,6.213918209075928,3.7343456745147705,-4.522641658782959,-0.03658777475357056,9.395675659179688,8.651907920837402,3.013690948486328,0.2555323541164398,7.69327974319458,-6.417929172515869,1.3557316064834595,-1.5919216871261597,7.5243754386901855,-6.5650954246521,7.345175743103027,15.187037467956543,4.1936798095703125,15.346759796142578,1.0699694156646729,2.041316032409668,-2.3665263652801514,-1.7106891870498657,7.1817827224731445,-4.099669456481934,7.957590579986572,6.555997371673584,6.536386966705322,-2.752241849899292,-0.7170464992523193,9.34834098815918,-2.273292303085327,9.606025695800781,4.654547214508057,2.8709664344787598,7.609549045562744,-9.076809883117676,-6.838057994842529,0.037382274866104126,5.845372676849365,6.194222927093506,6.917178153991699,1.757400393486023,7.635171890258789,14.441267967224121,13.656549453735352,-6.672970771789551,2.792053461074829,8.917464256286621,19.302541732788086,-0.3894571363925934,-0.2906765639781952,-5.3354811668396,5.573914527893066,-2.6817076206207275,-4.089280128479004,-1.692867398262024,7.372494697570801,3.955246686935425,7.641299724578857,0.809043288230896,14.924775123596191,1.6720788478851318,-6.885867595672607,6.22673225402832,4.921287536621094,3.9149060249328613,7.338473796844482,7.618261814117432,7.884803771972656,-5.028133392333984,-7.762199878692627,6.795197010040283,6.427450180053711,-6.666807651519775,-1.6599767208099365,4.017651557922363,6.3542256355285645,6.941046714782715,7.006636142730713,4.417562007904053,3.963667392730713,5.220468521118164,-4.348892688751221,-1.6918827295303345,-6.602309703826904,-2.5259249210357666,5.444545269012451,3.827824831008911,12.931925773620605,-6.619862079620361,2.478499174118042,17.06631851196289,2.0863897800445557,6.750965595245361,-1.301362156867981,2.154757022857666,7.9351348876953125,8.37999153137207,5.9796881675720215,3.645132303237915,11.831292152404785,-6.6840691566467285,7.34274959564209,-3.2277369499206543,0.44131410121917725,-4.834383487701416,14.024134635925293,5.718076705932617,3.8150525093078613,7.338714599609375,-1.2354648113250732,1.7162278890609741,6.200538158416748,10.447680473327637,-8.322957038879395,4.637686729431152,8.254520416259766,-0.6969444751739502,2.4391064643859863,15.545056343078613,2.1975460052490234,8.821267127990723,9.465985298156738,-5.933529376983643,-1.9126074314117432,-5.610025882720947,5.946549415588379,9.273844718933105,8.414079666137695,7.792980670928955,6.016275882720947,3.9387032985687256,-5.151149272918701,8.586679458618164,8.341254234313965,-0.7364428639411926,4.806539535522461,1.7060810327529907,14.511868476867676,-8.050435066223145,2.410639762878418,-5.293482303619385,-6.883916854858398,8.141840934753418,3.5626821517944336,-0.4948424696922302,7.929542541503906,1.7886728048324585,-3.0475590229034424,4.045907974243164,1.9915618896484375,-2.213305950164795,7.590574741363525,-5.624172210693359,9.096233367919922,5.718649864196777,-0.8751020431518555,-3.5508172512054443,2.571730613708496,-5.77555513381958,4.947772026062012,8.31171703338623,6.171008110046387,5.632609844207764,4.876763343811035,6.063420295715332,-0.7898322939872742,4.520042896270752,1.403504490852356,4.921833038330078,0.8666656017303467,5.29290771484375,0.7624328136444092,0.6773535013198853,5.889474391937256,9.757707595825195,7.7435197830200195,2.2352702617645264,7.909981727600098,10.34535026550293,8.619380950927734,-0.5384601950645447,-0.5822415947914124,5.888981342315674,6.347062110900879,5.979724884033203,9.080631256103516,-1.2934712171554565,9.504926681518555,-0.7646979093551636,7.95078182220459,0.8129172921180725,15.631753921508789,-3.028637647628784,-1.8529248237609863,-6.114772796630859,7.426185131072998,5.762447357177734,-0.2223580777645111,14.65798282623291,-2.6817257404327393,-1.0681473016738892,4.8151373863220215,6.384853363037109,8.761985778808594,-4.155613899230957,4.070479393005371,8.141006469726562,10.348608016967773,-5.083677768707275,2.3781397342681885,-1.1010456085205078,6.710214614868164,4.7180962562561035,8.043578147888184,9.61964225769043,10.954724311828613,6.276647567749023,2.4006550312042236,7.818099021911621,-5.29067850112915,-0.5368057489395142,8.708473205566406,-7.110403537750244,4.660732746124268,-1.5823242664337158,7.440869331359863,-5.0177507400512695,2.1474947929382324,-2.7380945682525635,6.6810126304626465,6.228140830993652,10.638209342956543,-2.1923789978027344,3.5013206005096436,3.904137134552002,-3.357738494873047,-0.6283376216888428,9.607979774475098,-1.8977607488632202,1.1463720798492432,8.717485427856445,3.662477731704712,14.429889678955078,8.991853713989258,-4.963184833526611,13.568124771118164,-0.01012887991964817,1.9782880544662476,9.292716979980469,3.755692720413208,8.549501419067383,6.2067742347717285,13.105475425720215,17.21824836730957,2.3316807746887207,7.714242935180664,2.676422119140625,6.015481472015381,10.203202247619629,-2.3470983505249023,0.23230750858783722,13.711309432983398,6.388406753540039,-3.2175588607788086,7.78240442276001,-4.875787734985352,13.903972625732422,-0.42050620913505554,-2.4516119956970215,5.341421604156494,-1.1547770500183105,-6.302931785583496,19.1806583404541,6.563819408416748,-1.1125317811965942,-0.48421430587768555,10.792396545410156,-1.6357532739639282,5.668634414672852,-1.6682674884796143,7.204807758331299,-2.7549970149993896,3.638493776321411,-3.631774425506592,-0.5268096327781677,5.487668514251709,-0.6798858046531677,4.227562427520752,15.449322700500488,-5.977921009063721,8.317136764526367,6.580069541931152,6.80963134765625,-7.1747941970825195,2.766746997833252,2.6815202236175537,-5.931990623474121,-2.5142822265625,14.928483009338379,8.428841590881348,3.25754976272583,-3.140505075454712,3.5181243419647217,6.358018398284912,-4.787138938903809,13.48510456085205,7.921144485473633,-2.65545916557312,7.843759059906006,7.817446708679199,2.562912702560425,8.525390625,-3.405179500579834,-6.689599990844727,-0.08995097875595093,-1.5356448888778687,5.743964195251465,3.5120911598205566,-1.0482970476150513,3.2596797943115234,-1.259486436843872,3.545008659362793,8.715513229370117,-1.5521832704544067,5.880509376525879,3.754833459854126,-7.343629837036133,8.206060409545898,5.867606163024902,8.028032302856445,4.502484321594238,4.295331954956055,5.744412899017334,6.9845991134643555,8.655632019042969,2.9785473346710205,5.534965515136719,8.344680786132812,3.0346016883850098,1.2671120166778564,-0.12264417111873627,-5.343474864959717,4.5899553298950195,8.08536434173584,6.09748649597168,-1.4654483795166016,4.795067310333252,7.098464488983154,12.11080551147461,10.478750228881836,7.614508152008057,8.992681503295898,4.3632683753967285,12.070489883422852,-1.7875970602035522,-0.5999460816383362,3.907895088195801,3.291947364807129,12.272783279418945,5.919950485229492,-3.031874179840088,1.7439486980438232,-6.069146633148193,-3.268568754196167,-0.09015972167253494,-4.181539535522461,13.193359375,8.74125862121582,8.027114868164062,0.14044862985610962,6.600171089172363,4.62579345703125,15.524084091186523,6.66196346282959,1.8840947151184082,6.8818159103393555,-0.743426501750946,5.693347454071045,-5.501601696014404,3.7506103515625,7.874583721160889,7.301980018615723,8.321775436401367,0.21681827306747437,-1.2693488597869873,4.646254539489746,-5.894504547119141,-4.205295562744141,-1.8954823017120361,-4.549682140350342,-1.9565929174423218,-1.5719759464263916,3.9057536125183105,6.029104709625244,7.602793216705322,0.42347320914268494,7.5650200843811035,-1.2366122007369995,8.259317398071289,6.742683410644531,-1.0656267404556274,7.269210338592529,-0.5432603359222412,15.872371673583984,-1.2591336965560913,-1.1000025272369385,3.9724910259246826,7.446681022644043,3.7672085762023926,2.0684821605682373,15.466391563415527,-0.9478966593742371,6.422202110290527,1.690428376197815,-3.1282267570495605,-1.7095555067062378,1.1241326332092285,6.307084560394287,1.6103925704956055,10.125626564025879,2.3824706077575684,4.225283145904541,9.694292068481445,0.8806020021438599,-1.3615368604660034,-0.2280857115983963,14.10787296295166,-6.7527313232421875,7.107045650482178,5.236765384674072,-1.256255030632019,-0.9239029288291931,11.929686546325684,-0.2843858599662781,-0.4121786653995514,0.5724397897720337,2.642688512802124,8.676115036010742,-1.181416630744934,1.6580932140350342,7.153268337249756,-3.8392462730407715,-4.699051856994629,3.7109522819519043,0.8510314226150513,-3.6589767932891846,4.252500057220459,0.6239430904388428,6.313145160675049,5.676443576812744,4.068865776062012,5.10701847076416,9.010284423828125,5.343493461608887,-1.5320388078689575,6.863203525543213,20.95991325378418,7.741659641265869,8.20522403717041,13.385149955749512,7.939553260803223,0.10833782702684402,10.682262420654297,-2.4089441299438477,-0.6526488661766052,5.629944801330566,1.7657921314239502,4.050586223602295,-0.8433118462562561,8.216034889221191,-2.1611108779907227,8.916962623596191,9.370230674743652,3.0692172050476074,3.3139777183532715,-4.90614128112793,-0.5456123352050781,-2.09074330329895,-1.6096240282058716,12.226015090942383,4.835811614990234,6.038527965545654,2.8170228004455566,4.122303009033203,6.150538444519043,8.137670516967773,-4.128210544586182,-2.828350067138672,5.348251819610596,3.6667938232421875,-3.60072922706604,6.123968601226807,-2.677119731903076,-0.6752465963363647,-5.252591609954834,-4.5179548263549805,-3.5206868648529053,-0.8927625417709351,13.891889572143555,8.273280143737793,-7.2956223487854,4.306636810302734,12.718833923339844,8.158550262451172,-0.8192557096481323,5.321959495544434,-1.669338583946228,8.488802909851074,8.954401016235352,-4.805516242980957,7.7034502029418945,-0.27385973930358887,-3.151667356491089,11.657373428344727,-7.013330936431885,-9.037715911865234,-0.312800794839859,8.221111297607422,3.293916702270508,-1.318793535232544,19.163503646850586,3.3387393951416016,-0.6586159467697144,5.935396194458008,-6.615023136138916,-5.863489627838135,3.9808080196380615,5.478737831115723,-0.1872662901878357,4.1667327880859375,7.037403106689453,4.06331729888916,5.306766986846924,15.196065902709961,4.781537055969238,-1.645393967628479,9.495504379272461,5.657731533050537,-0.5620749592781067,7.631577014923096,2.335263967514038,0.14461255073547363,5.112026214599609,-3.0933518409729004,-0.3863827884197235,2.779111385345459,5.471044063568115,3.536665916442871,2.1993868350982666,7.912992477416992,-5.686568260192871,2.049715518951416,4.064554691314697,-2.094874858856201,10.040504455566406,-3.2448177337646484,6.453413963317871,-1.9393218755722046,7.165355682373047,17.079912185668945,6.66216516494751,1.8681870698928833,3.6888513565063477,5.15726375579834,8.215872764587402,8.730710983276367,-5.949117660522461,14.099544525146484,-8.737070083618164,5.908720970153809,5.4018473625183105,11.673608779907227,6.4184370040893555,-1.3240822553634644,0.8031648993492126,1.3838884830474854,5.991236686706543,2.9189095497131348,1.1820969581604004,4.092319488525391,-4.821361064910889,17.32132339477539,8.93416976928711,17.21999168395996,15.619483947753906,7.975834846496582,2.1892364025115967,7.22577428817749,-2.2633063793182373,5.0866475105285645,-0.03226431459188461,5.531774997711182,-7.389495849609375,0.08338677883148193,3.4240634441375732,6.886994361877441,-1.4054733514785767,7.612893104553223,-4.862989902496338,6.790652275085449,-0.9218475222587585,13.807999610900879,15.5647611618042,6.869744300842285,5.313022613525391,7.966507911682129,3.490211248397827,8.615986824035645,0.7454902529716492,-0.836182177066803,5.520320892333984,4.483226299285889,7.003870964050293,-5.772470474243164,6.666944980621338,1.6701295375823975,6.889826774597168,1.7289104461669922,-0.40851351618766785,6.98978328704834,-0.6946508288383484,-1.8577710390090942,9.098907470703125,4.879942417144775,-0.7522664070129395,7.507788181304932,-1.9578464031219482,2.841698169708252,4.906622409820557,8.344829559326172,7.420753002166748,5.065918922424316,6.694891452789307,7.4373250007629395,4.975475788116455,4.726511478424072,0.04933379590511322,5.83145809173584,0.048610154539346695,17.543359756469727,7.620355129241943,15.21459674835205,-2.35455584526062,-6.722423076629639,5.565553665161133,2.6922218799591064,5.500334739685059,-2.4280710220336914,1.9912186861038208,4.484673023223877,0.07860572636127472,10.66670036315918,1.2598812580108643,7.413192272186279,4.027937889099121,-1.2872447967529297,-0.8214079141616821,-2.3488667011260986,1.331496000289917,4.9729180335998535,3.879976749420166,-3.283677339553833,8.249570846557617,-0.7854981422424316,-2.3218255043029785,5.3614277839660645,17.755496978759766,-0.9544094204902649,9.20583724975586,-7.530470848083496,13.592109680175781,1.9938629865646362,4.7499542236328125,6.075185298919678,-6.426509857177734,5.732655048370361,-1.1906458139419556,0.12364369630813599,15.59780216217041,7.437491416931152,-4.0262885093688965,4.88637113571167,5.726199150085449,12.344938278198242,7.540990829467773,-8.7295503616333,3.4929516315460205,3.1674962043762207,0.2573806345462799,13.500236511230469,7.202648639678955,6.2108988761901855,8.619989395141602,7.156680107116699,1.201332688331604,6.308892250061035,7.597132682800293,11.926236152648926,7.572015762329102,7.935586452484131,-2.6531624794006348,6.183640956878662,-7.17381477355957,7.9622883796691895,2.1781272888183594,-1.6967248916625977,0.5325538516044617,-1.2857192754745483,0.321554034948349,10.251321792602539,-2.7190890312194824,-2.1862826347351074,4.722929954528809,2.0154776573181152,3.517934560775757,8.91990852355957,6.565131187438965,7.4120001792907715,-7.1140336990356445,-6.676795482635498,5.428868293762207,-2.8965160846710205,7.154577732086182,-8.13940715789795,-4.853173732757568,-0.18551282584667206,-1.2449666261672974,-0.25113412737846375,21.021024703979492,6.616497993469238,-0.18126662075519562,9.89162540435791,5.948740482330322,2.976083993911743,9.257326126098633,1.562726378440857,9.093915939331055,6.880996227264404,1.9872771501541138,3.9437382221221924,0.13236720860004425,-1.145830750465393,-4.313233852386475,-8.061307907104492,5.40173864364624,8.02117919921875,4.268483638763428,4.261140823364258,4.197585105895996,-0.9739556908607483,12.840534210205078,5.416809558868408,3.050542116165161,7.019277572631836,4.660764217376709,17.03510284423828,1.0540978908538818,7.575154781341553,-4.975919246673584,0.6266050934791565,2.4617919921875,16.666889190673828,1.1702138185501099,4.002297878265381,3.8106391429901123,-4.5221428871154785,6.239176273345947,3.8365347385406494,-0.4880794584751129,1.910496473312378,6.207507610321045,6.24400520324707,7.079058647155762,11.946975708007812,5.598742961883545,4.979252815246582,14.392733573913574,8.83113956451416,4.8127055168151855,-9.46652603149414,17.894433975219727,0.6739150285720825,6.749607563018799,-0.5470833778381348,6.343753814697266,-1.2661412954330444,5.213246822357178,8.531231880187988,7.778267860412598,9.444963455200195,-6.783641338348389,4.340261459350586,6.726590633392334,-0.21073628962039948,7.200646877288818,-0.13430140912532806,17.098674774169922,4.388373374938965,8.291598320007324,4.306120872497559,2.8702197074890137,3.1863529682159424,6.1638054847717285,9.02502727508545,6.381250858306885,1.4024168252944946,5.8662543296813965,-3.677572250366211,12.977804183959961,2.3084332942962646,-5.5122175216674805,-1.6858258247375488,-0.40907174348831177,17.391277313232422,5.671016693115234,7.859236717224121,7.076779365539551,5.353268146514893,-0.23968030512332916,8.368106842041016,6.425179958343506,2.489084482192993,2.0520997047424316,7.721064567565918,7.435285568237305,4.608210563659668,16.676836013793945,8.87491226196289,6.459542751312256,8.728646278381348,-5.319896221160889,3.3676795959472656,9.083566665649414,5.531509876251221,0.31149134039878845,13.093414306640625,7.152663230895996,0.44572338461875916,1.7151763439178467,9.895126342773438,5.543560981750488,2.9327280521392822,7.590897560119629,-0.6201938986778259,5.564467430114746,-1.0112485885620117,6.2417402267456055,7.333034038543701,8.333647727966309,8.50548267364502,4.621174335479736,-4.157507419586182,13.45875358581543,7.159472465515137,4.6779303550720215,17.60856819152832,15.46403980255127,-6.233670711517334,3.1953001022338867,4.0108819007873535,18.136999130249023,2.3282952308654785,3.949014663696289,-6.524838447570801,-0.9536645412445068,-1.0225400924682617,2.0565483570098877,8.229110717773438,-5.1574578285217285,-1.5452505350112915,4.2314558029174805,-0.3413999378681183,13.651031494140625,1.8494114875793457,1.466864824295044,6.0558295249938965,-2.186966896057129,6.274160385131836,-4.317680835723877,16.87649154663086,8.271273612976074,6.211147308349609,-4.210329055786133,-1.1847926378250122,5.0919575691223145,-1.9779967069625854,-1.654124140739441,6.378201484680176,8.835833549499512,-3.7767436504364014,2.339571475982666,0.7547896504402161,6.22357702255249,12.377090454101562,4.144392013549805,1.6114883422851562,-6.0328049659729,-5.340038299560547,-4.916296482086182,-0.13427427411079407,7.392472743988037,5.065182209014893,-1.9896314144134521,0.7780845165252686,4.274326324462891,1.253147840499878,4.044741630554199,-0.13395461440086365,-6.453737735748291,0.5496835708618164,3.891903877258301,-4.060815811157227,1.7115522623062134,-1.9982235431671143,8.39750862121582,7.982838153839111,6.053633213043213,-6.533652305603027,6.373242378234863,16.414770126342773,3.5571768283843994,7.263389587402344,5.752532958984375,-1.8717883825302124,4.155710220336914,-1.724626898765564,-4.903653144836426,7.6710100173950195,1.278066635131836,2.1890182495117188,3.5901689529418945,1.3503607511520386,6.760015487670898,0.9432812929153442,-2.3278088569641113,-6.391060829162598,-5.765633583068848,4.0626912117004395,5.301709175109863,0.7515482306480408,-6.581427097320557,-0.5287781357765198,-5.799510955810547,-0.40365681052207947,-6.523801803588867,8.063846588134766,-2.076873302459717,7.393180847167969,-2.4465465545654297,-0.07759055495262146,16.10002899169922,8.79801082611084,-4.772090435028076,4.796971797943115,-1.1141622066497803,12.109060287475586,8.951658248901367,9.23136043548584,14.073895454406738,17.481889724731445,7.820132732391357,12.770222663879395,6.798081398010254,-0.7708086967468262,16.87641716003418,-0.310699462890625,-6.624352931976318,5.657923221588135,6.012697696685791,8.180057525634766,5.923549652099609,13.763765335083008,9.903105735778809,1.1119294166564941,-3.986884832382202,5.594139099121094,8.381040573120117,1.7715054750442505,5.753666400909424,-1.8041326999664307,8.294668197631836,2.1690280437469482,8.838033676147461,-0.8316603302955627,7.377776145935059,1.9014133214950562,6.0893096923828125,4.204968452453613,17.20146942138672,4.9927802085876465,7.5543694496154785,-6.568678379058838,-6.605335235595703,3.9100184440612793,-1.2920159101486206,8.590110778808594,16.644681930541992,8.580451011657715,17.617502212524414,5.1849493980407715,4.295281887054443,-5.029444694519043,-1.0837018489837646,-4.2791619300842285,3.6599831581115723,5.655599594116211,4.950676441192627,1.2787799835205078,7.106914043426514,14.17149543762207,5.7894287109375,14.796708106994629,1.3551428318023682,-8.212725639343262,5.297400951385498,3.2539756298065186,5.706522464752197,3.330596446990967,5.488572597503662,-0.32348141074180603,8.804240226745605,15.492231369018555,5.910214424133301,6.771081447601318,7.343740463256836,8.653181076049805,2.589035749435425,-1.978585958480835,-0.7611099481582642,6.33053731918335,7.166834354400635,6.811434268951416,12.24151611328125,8.150264739990234,-1.8229273557662964,-4.211958408355713,-2.101245880126953,7.060232639312744,-4.944328308105469,-5.715094089508057,4.985766887664795,-6.947048187255859,-1.2325533628463745,2.1678314208984375,-5.758446216583252,3.7565853595733643],\"type\":\"scattergl\"},{\"hoverinfo\":\"text\",\"hovertext\":[\"Combining both the script data with character metadata and episode metadata.\",\" Calculating number of conversations for the first 10 episodes\",\"Merge the script lines with episodes' details, characters, and locations.\",\" Using more characters and episodes than previously, we will try to predict which character is saying which line, using two approaches.\",\"Retrieve the conversation for episodes that contain 2 or more characters.\",\" Show the first episode\",\"Counting the number of lines in episodes\",\"Merge all the scripts, characters, locations, and episodes into a single dataframe.\",\"Later we will need to group the script lines by episode, so we precompute this for later usage.\",\" Segment neighborhoods as different episodes.\",\"Merge the data for characters, locations, and script lines using the episode ID as the common key.\",\"Build the dataframe to be used in this notebook with the characters' lines along with the episode id and name for further analysis.\",\"Check if scripts lines has the episode ID\",\"Filter out stories that are too short.\",\"For now, drop the seven episodes that do not have any line associated with them\",\"Select conversation and extract lines by episode and character\",\"Combine the data of the episodes with their corresponding scripts.\",\" Merge script, episodes, characters and location data into one dataframe\",\"Set the length of all TV script lines to 300 characters or less.\",\"Merge the scripts with their respective episodes, characters, and locations.\",\"Concatenate the location, character and speaking turn from the script to the episodes.\",\"Filter out the episode ids that are in the lines dataset from the episodes dataset.\",\"Join to get the locations and entities present in every episode\",\"Combine the script lines with the episode titles\",\"Merge the script with the characters and the episodes dataframes to have all the relevant info in one place.\",\" Merge script with characters, locations and episodes names\",\"The lines in the original script are randomly ordered. Let's first sort them by episode id and index.\",\"merge location and episodes dataframes\",\"Select the script for episode 1 (June 15, 2017)\",\"Extraire le texte de tous les \\u00e9pisodes\",\"The first thing we'll do with the script data is to connect the script lines to episode, character and location ids.\",\"Function to filter the script by episode id.\",\"Print the script from the first episode\",\"Get the episodes for each character\",\"Merge the dataset on episode, character, location, and script together.\",\"Extract script for a single episode\",\"Define a class for preprocessing the script data, extracting the script for each episode, and tokenizing the text for natural language processing.\",\"Concatenate location and episode in the script dataframe\",\"Selecting only lines from one specific episode\",\"Expanding the script lines to show Episode title and character name instead of their ids.\",\"Let's display the first 10 episodes and their corresponding IMDb rating.\",\"Filtering the script data for the episode number and the episode name\",\"Count the number of transcript lines per episode\",\"Create a new data frame containing only episode name, character name, and dialogue.\",\"join lines to attach the episode's title to the episode number\",\"Combine script lines and episodes dataframes so we can use episode information to analyze the script lines data.\",\"ronly listed episodes; verify that proper episodes included in download\",\"Function to get a character's lines in a specific episode\",\"Merge characters, locations, and episodes into a single dataframe using left join with scripts dataframe.\",\"Extract names of episodes\",\"Merge the episodes, locations, and script data into the characters dataframe and save it.\",\"Filter out episode length less than 20 lines\",\"Create a list of episodes.\",\" Extracting the text of each line along with its corresponding character, location, and episode title.\",\"Visualizing the length of the scripts per episode\",\"Link the script to the episode.\",\"Select episode 1, filter out non main characters and get the actual script\",\"Filter the script for only the episodes 1 to 3 of season 1.\",\"Create the list of scripts for each episode ID.\",\" Let's work with a smaller dataset containing only one episode script to demonstrate the analytical process.\",\"Remove stopwords from script lines and combine them by episode Id\",\"Filter out episodes older than 1990.\",\" Check if script line and episode have same id\",\" Merge the script lines with the characters, locations and episodes dataframe\",\"Count Number of lines for each Episode\",\"Filtering for just the title and ID of each episode.\",\"Check if the lines have the `character_id`, `location_id` and `episode_id` (where available) that match the `id` in the characters, locations, and episodes tables.\",\"Function to retrieve script for a specific episode\",\"[Optional] Remove characters who appear in less than 10 episodes.\",\"Join locations, script, and characters dataframes on the episode id\",\"Check that each episode in script_lines.csv refers to an actual episode.\",\"Extract the first 100,000 script lines and limit them to the first 50 episodes only\",\"Merge episodes with script in order to obtain episode data at every line's level.\",\"Filtering for the episode with the most lines and including only spoken lines\",\"Create episode transcripts by joining script lines on episode id and then\\n# and then grouping by episode id aggregating text.\",\"Let's put the scipts together by episodes\",\"Ensure the episode is the full episode and not a short.\",\"Finding episode titles for each id in the dialogs dataset.\",\"provide the list of dates an episode first aired\",\"Insights\\n# Let's take a closer look at the episodes first.\",\"Join scripts, characters, locations, and episodes in one dataframe\",\"Displaying scripts for the first episode\",\"Merge the episodes file with the script file so that each script line is associated with its corresponding episode.\",\" We transform the season and episode number of each script line to a unified format XYY\\n# where X is the season number and YY is the episode number.\",\" Merge the characters, locations, episodes and script dataframes.\",\"Create a new column for script data that contains the episode data\",\"Combine script lines, characters, locations, and episodes into one dataframe.\",\"Combine characters, locations and episodes under a single dataframe\",\"Merge the script, episodes, characters and locations in one DataFrame\",\"Join characters, locations, script lines and episodes\",\"Filter out episode of length 0\",\" Select only the episodes corresponding to the first 8 seasons.\",\"We'll merge the two datasets to get the episode for each script line.\",\"Get the TV script of the episode with the most number of lines.\",\"Create a table with the title and the number of lines for each episode.\",\"Assign named spans to refer to specific episodes etc.\",\" Set the context for the analysis - the n-th episode and the minimum number of words for the lines\",\" Merge the dataset based on the character_id, episode_id from the scripts data.\",\"function to extract episode number from raw data\",\"Count of quotes per episode\",\" Check the number of existing episodes.\",\" For simplicity, let's concatenate all the lines in the script together, segmenting them by episode.\",\"Merge the characters, locations, episodes and scripts dataframes\",\"Create a list of all episode names\",\"To allow for better readability of the script lines, we will introduce a column representing the season and the episode number in the script lines dataframe.\",\"Join the data on episodes, script and characters\",\"Create separate dataframes for the different characters of the show\",\"According to the script data, each line is labeled with a character, and an episode.\",\"Create a column with all the script lines of an episode\",\"Merge the lines with the episodes\",\"Merge characters, locations and episodes in the scripts dataset for better analyzis\",\"Join the script lines with the characters, locations, and episodes dataframes.\",\" Let's count the number of script lines in each episode and store the result in a new dataframe.\",\"Merge characters, locations and episodes on script dataframe\",\"Extract script for each episode and each character\",\"Filter out the episodes which script lines are not present in the dataset\",\"Separate the script data by episodes.\",\"merge script lines with episodes and select character-based script lines\",\"Merge the dataframes that contain the scripts with the dataframes containing the characters and locations as well as the episodes.\",\"Extract all sentences said by a certain character in a specific episode.\",\"We will start cleaning and transforming the data starting by the episodes data frame.\",\"Remove duplicate script lines, and merge character, location, and episode data into the script data.\",\"Creating a series of episodes with their lines\",\"filter data for episode 1 of season 1 and for script type 'spoken'\",\" Selecting only the script for the first episode\",\"Find the season\\u002fepisode with the most lines\",\"Filter for a specific episode, e.g., episode \\\"1\\\", and display the first 5 lines\",\" Create a list of episode titles\",\"Create dictionary for episode titles\",\"Extract the script for a single episode.\",\"Select one or more episodes to analyze\\nepisodes = [\\n    'noir'\\n]\",\"Ensure the script and episodes have the same number of seasons, with the season\\u002fepisode format consistent across both datasets.\",\" Joining the scripts with the episodes on the episode id\",\"We need to fix the episode title - some of the titles from the script data frame have additional information about the season and episode numbers. We need to remove this information.\",\"Define the most likely episode length in minutes from 15 to 30 minutes\",\"Create a version of the script dataframe which joins the character, location, and episode details with each line.\",\"Extract character lines from the script dataframe and join the location and episode names\",\" function to get the script lines for a certain episode\"],\"marker\":{\"opacity\":0.5,\"size\":5},\"mode\":\"markers+text\",\"name\":\"0_Extracting and Combining Script and Episode Information\",\"text\":[\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\"],\"textfont\":{\"size\":12},\"x\":[8.001355171203613,8.271493911743164,8.153094291687012,8.894357681274414,8.132558822631836,7.195357322692871,8.153779029846191,6.969639778137207,8.04898738861084,7.909270763397217,7.489981651306152,6.660952091217041,7.442967891693115,8.656026840209961,7.7703633308410645,8.699627876281738,6.776883125305176,6.78847599029541,8.701605796813965,8.087881088256836,8.128769874572754,7.222953796386719,7.501611232757568,8.160228729248047,7.322238922119141,8.213996887207031,7.31245756149292,6.255224227905273,8.07193660736084,7.61431884765625,7.689499378204346,6.855495929718018,7.983409404754639,7.723083019256592,6.932191371917725,7.590373516082764,8.297103881835938,6.799391746520996,8.098188400268555,7.620375156402588,7.358356475830078,7.457259654998779,7.653744697570801,7.334331035614014,8.004785537719727,6.802923202514648,6.4608845710754395,8.835532188415527,6.816882133483887,6.968323707580566,7.774927139282227,8.458626747131348,7.012388229370117,8.006423950195312,8.59682559967041,7.582086563110352,8.13839054107666,7.844398021697998,7.1651291847229,6.926026344299316,8.06181526184082,7.289587497711182,7.129960536956787,7.254480838775635,8.06644058227539,7.200395584106445,7.710543632507324,7.573829650878906,7.952116012573242,6.680609703063965,8.33184814453125,7.468496322631836,7.227197170257568,8.40577507019043,7.5561347007751465,7.598299503326416,7.048924922943115,6.7099103927612305,7.101012706756592,6.921056747436523,7.062860488891602,8.232897758483887,7.684875011444092,7.79793119430542,7.421689033508301,6.823570251464844,6.949769020080566,6.566962718963623,6.454708099365234,7.899911880493164,7.734919548034668,7.606761932373047,7.0878520011901855,8.35309886932373,7.670788764953613,6.428861141204834,7.903417110443115,6.794256687164307,6.3150858879089355,7.6001386642456055,6.804973602294922,8.091889381408691,7.260283470153809,6.867854118347168,7.500836372375488,7.19700813293457,6.182044506072998,8.29129695892334,7.568701267242432,7.428403377532959,8.029218673706055,8.031688690185547,7.022019863128662,7.140070915222168,7.909090042114258,7.481369972229004,7.557229042053223,7.874636173248291,7.238137245178223,8.444520950317383,6.292199611663818,7.740353584289551,7.715421199798584,7.813126564025879,7.761776447296143,8.443942070007324,7.610264778137207,6.583188056945801,5.825473785400391,7.890478134155273,7.472600936889648,7.447759628295898,7.3055925369262695,8.296835899353027,7.669892311096191,7.0625529289245605,7.499730110168457,8.322916030883789],\"y\":[4.0147705078125,6.261305809020996,4.318277835845947,5.521343231201172,5.52665901184082,3.8455300331115723,5.329218864440918,3.620751142501831,4.371535301208496,4.731654167175293,3.89094877243042,4.589592456817627,4.250629425048828,5.231553077697754,4.772973537445068,4.917097091674805,3.6221139430999756,3.539445400238037,4.102296829223633,3.6882219314575195,4.763429641723633,4.468020915985107,4.629143714904785,4.127105712890625,4.181468963623047,3.879889726638794,4.037776947021484,3.424384117126465,3.2549221515655518,4.563323020935059,4.341230869293213,4.182024955749512,3.688135862350464,5.02170991897583,3.4495346546173096,3.821357011795044,4.534430980682373,3.336867570877075,5.192807197570801,4.215517044067383,4.4365458488464355,4.223029136657715,5.509550094604492,4.89163875579834,4.793528079986572,3.901928186416626,4.054940700531006,5.033050060272217,3.438457489013672,4.550998210906982,4.321037292480469,4.964536666870117,4.800530910491943,4.597064018249512,5.19134521484375,3.205970525741577,4.277426242828369,3.6787168979644775,3.667250394821167,3.5668957233428955,3.9085922241210938,4.338669300079346,4.114305019378662,3.775148868560791,5.543735504150391,4.152053356170654,4.461298942565918,3.8608028888702393,4.693259239196777,4.143017768859863,4.012217998504639,4.205394268035889,4.2797417640686035,5.595421314239502,4.868990421295166,4.2602715492248535,4.148853302001953,4.42343282699585,4.218862056732178,3.9082462787628174,3.7222139835357666,3.7254860401153564,3.554490327835083,4.421138286590576,3.6324079036712646,4.5067291259765625,3.966451644897461,3.402811288833618,3.4289987087249756,4.273307800292969,4.7781805992126465,3.792370319366455,3.4730660915374756,5.1889448165893555,5.437040328979492,4.729063987731934,5.31393575668335,3.7277026176452637,4.631911277770996,5.354448318481445,4.2968621253967285,4.472227096557617,3.539909601211548,4.842868804931641,4.178203105926514,4.301109790802002,3.9460160732269287,4.7186055183410645,4.713593482971191,4.405627250671387,3.461956262588501,4.882087230682373,4.397831916809082,3.5903332233428955,4.369413375854492,4.60880184173584,3.9603171348571777,4.344574451446533,4.039867401123047,4.926844596862793,3.22230863571167,3.840758800506592,4.702651500701904,5.088316917419434,3.744635820388794,5.14218282699585,4.979207992553711,4.709868431091309,4.908449172973633,3.523580551147461,4.705760955810547,3.773395538330078,3.9516279697418213,4.394542217254639,5.501856803894043,4.63823127746582,4.4463653564453125,4.250304698944092],\"type\":\"scattergl\"},{\"hoverinfo\":\"text\",\"hovertext\":[\"Display the first few rows of the characters dataframe\\ndf_characters.head()\",\"Display the first few rows of the characters dataframe\\ndf_characters.head()\",\" Display the first few rows of the characters dataframe\\ndf_characters.head()\",\"Display the first few rows of the characters DataFrame\\ndf_characters.head()\",\"Display the first few rows of the characters dataframe\\ndf_characters.head()\",\"Display the first few rows of the characters dataframe\\ndf_characters.head()\",\"Display the first few rows of the characters dataframe\\ndf_characters.head()\",\"Display the first few rows of the characters dataframe\\ndf_characters.head()\",\" Display the first few rows of the characters dataframe\\ndf_characters.head()\",\"Display the first few rows of the characters dataframe\\ndf_characters.head()\",\" Display the first few rows of the characters dataframe\\ndf_characters.head()\",\"Display the first few rows of the characters DataFrame\\ndf_characters.head()\",\" Display the first few rows of the characters dataframe\\ndf_characters.head()\",\" Display the first few rows of the characters dataframe.\\ndf_characters.head()\",\"Display the first few rows of the characters dataframe\\ndf_characters.head()\",\"Displays the first few rows of the df_characters DataFrame\\ndf_characters.head()\",\"Display the first few rows of the characters dataframe\\ndf_characters.head()\",\"Display the first few rows of the character dataframe\\ndf_characters.head()\",\" Display the first few rows of the characters dataframe\\ndf_characters.head()\",\"Display the first few rows of the characters DataFrame\\ndf_characters.head()\",\"Display the first few rows of the characters dataframe\\ndf_characters.head()\",\" Display the first few rows of the characters dataframe\\ndf_characters.head()\",\" Display the first few rows of the characters DataFrame\\ndf_characters.head()\",\"Print first few rows of `df_characters`\\ndf_characters.head()\",\"Display the first few rows of the characters dataframe\\ndf_characters.head()\",\" Display the first few rows of the characters dataframe\\ndf_characters.head()\",\" Display the first few rows of the characters dataframe\\ndf_characters.head()\",\" Display the first few rows of the characters dataframe\\ndf_characters.head()\",\"Display the first few rows of the characters dataframe\\ndf_characters.head()\",\"Display the first few rows of the characters dataframe\\ndf_characters.head()\",\"Display the first few rows of the characters DataFrame\\ndf_characters.head()\",\"Print the first few rows of the characters dataframe\\ndf_characters.head()\",\"Display the first few rows of the characters dataframe\\ndf_characters.head()\",\"Display the first few rows of the characters dataframe\\ndf_characters.head()\",\"Display the first few rows of the characters dataframe\\ndf_characters.head()\",\" Display the first few rows of the characters dataframe\\ndf_characters.head()\",\" Display the first few rows of the characters dataframe\\ndf_characters.head()\",\"Display the first few rows of the characters dataframe\\ndf_characters.head()\",\"Display the first few rows of the characters dataframe\\ndf_characters.head()\",\"Display the first few rows of the characters dataframe\\ndf_characters.head()\",\"Display the first few rows of the characters dataframe\\ndf_characters.head()\",\"display the first few rows of the characters dataframe\\ndf_characters.head()\",\"Display a few rows of the characters DataFrame\\ndf_characters.head()\",\" Display the first few rows of the dataframe for characters\\ndf_characters.head()\",\" Display the first few rows of the characters dataframe\\ndf_characters.head()\",\"Display the first few rows of the characters dataframe\\ndf_characters.head()\",\"Display the first few rows of the characters dataframe\\ndf_characters.head()\",\"Display the first few rows of the characters dataframe\\ndf_characters.head()\",\" Display the first few rows of the characters dataframe\\ndf_characters.head()\",\" Display the first few rows of the characters data frame\\ndf_characters.head()\",\"Display the first few rows of the characters DataFrame\\ndf_characters.head()\",\"Display the first few rows of the characters dataframe\\ndf_characters.head()\",\" Display the first few rows of the characters dataframe\\ndf_characters.head()\",\"Display the first few rows of the characters dataframe\\ndf_characters.head()\",\"# Print the first few rows of the dataframe\\ndf_characters.head()\",\"Display the first few rows of the characters dataframe\\ndf_characters.head()\",\" Display the first few rows of the characters dataframe\\ndf_characters.head()\",\" Display the first few rows of the characters dataframe\\ndf_characters.head()\",\"Display the first few rows of the characters dataframe\\ndf_characters.head()\",\" Display the first few rows of the characters dataframe\\ndf_characters.head()\",\" Display the first few rows of the characters dataframe\\ndf_characters.head()\",\"Display the first few rows of the characters dataframe\\ndf_characters.head()\",\"Display the first few rows of the characters dataframe\\ndf_characters.head()\",\"Display the first few rows of the characters dataframe\\ndf_characters.head()\",\"Display the first few rows of the characters dataframe\\ndf_characters.head()\",\"Display the first few rows of the characters dataframe\\ndf_characters.head()\",\"Display the first few rows of the characters dataframe\\ndf_characters.head()\",\" Display the first few rows of the characters dataframe\\ndf_characters.head()\",\" Display the first few rows of the characters dataframe\\ndf_characters.head()\",\"Display the first few rows of the characters dataframe\\ndf_characters.head()\",\" Display the first few rows of the character dataframe\\ndf_characters.head()\",\"Display the first few rows of the characters dataframe\\ndf_characters.head()\",\"Display the first few rows of the characters dataframe\\ndf_characters.head()\",\"Display the first few rows of the characters dataframe\\ndf_characters.head()\",\" Display the first few rows of the dataframe for characters\\ndf_characters.head()\",\"Display the first few rows of the characters DataFrame\\ndf_characters.head()\",\"Display the first few rows of the characters dataframe\\ndf_characters.head()\",\"Display the first few rows of the characters dataframe\\ndf_characters.head()\",\"Display the first few rows of the characters dataframe\\ndf_characters.head()\",\" Display the first few rows of the characters dataframe\\ndf_characters.head()\",\" Display the first few rows of the characters dataframe\\ndf_characters.head()\",\" Display the first few rows of the characters DataFrame\\ndf_characters.head()\",\"Display the first few rows of the characters dataframe\\ndf_characters.head()\",\" Display the first few rows of the characters dataframe\\ndf_characters.head()\",\"Display the first few rows of the characters dataframe\\ndf_characters.head()\",\"Print the first few rows of the characters dataframe\\ndf_characters.head()\",\" Display the first few rows of the characters dataframe\\ndf_characters.head()\",\"Display the first few rows of the characters dataframe\\ndf_characters.head()\",\"Display the first few rows of the characters DataFrame\\ndf_characters.head()\",\" Display the first few rows of the characters DataFrame\\ndf_characters.head()\",\" Display the first few rows of the characters dataframe\\ndf_characters.head()\",\" Display the first few rows of the characters DataFrame\\ndf_characters.head()\",\"Display the first few rows of the characters dataframe\\ndf_characters.head()\",\"display the first few rows of the characters dataframe\\ndf_characters.head()\",\"Display the first few rows of the characters dataframe\\ndf_characters.head()\",\"Display the first few rows of the characters dataframe\\ndf_characters.head()\",\"Display the first few rows of the characters data frame\\ndf_characters.head()\",\"Display the first few rows of the character dataframe\\ndf_characters.head()\",\"Display the first few rows of the characters dataframe\\ndf_characters.head()\",\"Display the first few rows of the characters dataframe\\ndf_characters.head()\",\" Display the first few rows of the characters dataframe\\ndf_characters.head()\",\" Display the first few rows of the characters DataFrame\\ndf_characters.head()\",\"Display the first few rows of the characters dataframe\\ndf_characters.head()\",\" Display the first few rows of the characters dataframe\\ndf_characters.head()\",\" Display the first few rows of the characters dataframe\\ndf_characters.head()\",\"Display the first few rows of the characters dataframe\\ndf_characters.head()\",\" Display the first few rows of the character dataframe\\ndf_characters.head()\",\"Display the first few rows of the characters dataframe\\ndf_characters.head()\",\" Display the first few rows of the characters dataframe\\ndf_characters.head()\",\" Display the first few rows of the characters DataFrame\\ndf_characters.head()\",\"Display the first few rows of the characters dataframe\\ndf_characters.head()\",\"Display the first few rows of the characters dataframe\\ndf_characters.head()\",\"Display the first few rows of the characters dataframe\\ndf_characters.head()\",\"Display the first few rows of the characters dataframe\\ndf_characters.head()\",\" display the first few rows of the characters dataframe\\ndf_characters.head()\",\" Display the first few rows of the characters dataframe\\ndf_characters.head()\",\" Display the first few rows of the characters DataFrame\\ndf_characters.head()\",\" Display the first few rows of the characters dataframe\\ndf_characters.head()\",\"Display the first few rows of the characters dataframe\\ndf_characters.head()\",\" Display the first few rows of the characters dataframe\\ndf_characters.head()\",\"Display the first few rows of the characters dataframe\\ndf_characters.head()\",\" Display the first few rows of the characters DataFrame\\ndf_characters.head()\",\"Display the first few rows of the characters DataFrame\\ndf_characters.head()\",\"Display the first few rows of the characters dataframe\\ndf_characters.head()\",\"Display the first few rows of the characters dataframe\\ndf_characters.head()\",\" Display the first few rows of the characters dataframe\\ndf_characters.head()\",\"Display the first few rows of the characters dataframe\\ndf_characters.head()\",\"Display the first few rows of the characters DataFrame\\ndf_characters.head()\",\" Display the first few rows of the characters dataframe\\ndf_characters.head()\",\" Display the first few rows of the characters dataframe\\ndf_characters.head()\",\"Display the first few rows of the characters dataframe\\ndf_characters.head()\",\"To view the first few rows of the characters data frame\\ndf_characters.head()\",\"Display the first few rows of the characters dataframe\\ndf_characters.head()\",\"Display the first few rows of the characters dataframe\\ndf_characters.head()\",\"Print the first few rows of the characters dataframe\\ndf_characters.head()\",\" Display the first few rows of the characters dataframe\\ndf_characters.head()\"],\"marker\":{\"opacity\":0.5,\"size\":5},\"mode\":\"markers+text\",\"name\":\"1_Display first few rows of characters dataframe\",\"text\":[\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\"],\"textfont\":{\"size\":12},\"x\":[-4.727355003356934,-4.085472106933594,-4.165167808532715,-3.3765454292297363,-3.8692214488983154,-3.7374420166015625,-3.8408265113830566,-4.101683616638184,-3.2811055183410645,-4.048303127288818,-3.5134449005126953,-3.586803913116455,-3.503445863723755,-3.9851596355438232,-4.481265544891357,-3.473086357116699,-3.5238454341888428,-4.949301719665527,-3.4127109050750732,-4.156800746917725,-4.156387805938721,-3.0085318088531494,-4.254471778869629,-3.534965753555298,-3.55765438079834,-3.9757237434387207,-3.9688961505889893,-4.454394340515137,-2.8373777866363525,-3.3883168697357178,-3.26470947265625,-3.685236930847168,-4.3341240882873535,-4.629515647888184,-3.358623743057251,-3.761136293411255,-4.122324466705322,-4.624546051025391,-4.193612098693848,-3.3296992778778076,-4.366314888000488,-4.525259971618652,3.3673360347747803,-3.5146424770355225,-2.9873859882354736,-3.9594807624816895,-4.104717254638672,-4.2487945556640625,-3.9489619731903076,-2.65193772315979,-3.6668574810028076,-3.3789994716644287,-3.906998872756958,-4.158134937286377,-3.218007802963257,-3.8264880180358887,-4.165659427642822,-3.953364133834839,-3.3708393573760986,-3.733456611633301,-4.238859176635742,-4.37152624130249,-3.533054828643799,-3.5886824131011963,-4.610813617706299,-3.3313870429992676,-3.5601930618286133,-3.231461524963379,-4.59515380859375,-4.46054220199585,-4.489321708679199,-2.871882915496826,-4.1148858070373535,-3.817028522491455,-3.349295139312744,-3.5202982425689697,-3.7613861560821533,-3.7751917839050293,-3.6912448406219482,-3.0465760231018066,-4.8951029777526855,-4.451329231262207,-4.126612663269043,-3.6719303131103516,-3.113346576690674,-3.6231489181518555,-3.6027231216430664,-4.254561424255371,-3.6825692653656006,-4.156991004943848,-4.3577752113342285,-3.3021185398101807,-4.238563060760498,-3.911083459854126,-4.5613112449646,-3.419916868209839,-2.7083752155303955,-4.483255386352539,-4.55729866027832,-3.4623947143554688,-3.1822986602783203,-4.0492634773254395,-4.024726867675781,-4.452389240264893,-3.807063341140747,-3.95265531539917,-4.36599063873291,-3.6298587322235107,-3.092782497406006,-3.7819743156433105,-4.227714538574219,-4.391412258148193,-3.796924114227295,-4.343094348907471,-3.3483989238739014,-3.2250418663024902,-3.580901622772217,-3.095029354095459,-3.4677302837371826,-3.8820905685424805,-3.9595770835876465,-3.8980801105499268,-3.2815542221069336,-3.6556341648101807,-3.5024499893188477,-4.024379730224609,-4.640254497528076,-3.5026214122772217,-4.335265159606934,-3.3515002727508545,-3.2805025577545166,-1.724038004875183,-3.1018054485321045,-4.093378067016602,-3.6214585304260254,-3.173121929168701],\"y\":[22.56713104248047,22.278257369995117,22.279651641845703,22.606666564941406,23.404993057250977,23.705944061279297,22.144432067871094,23.155019760131836,23.192028045654297,23.37641143798828,22.18726348876953,22.75426483154297,21.925230026245117,22.742830276489258,23.539857864379883,23.68805694580078,23.485397338867188,22.778474807739258,22.38134765625,22.957788467407227,23.899490356445312,22.737510681152344,22.431289672851562,20.6270694732666,22.680370330810547,22.638532638549805,23.144237518310547,22.3631591796875,22.691864013671875,22.610515594482422,23.53096580505371,20.890256881713867,23.730602264404297,22.58477020263672,22.34882354736328,23.05929183959961,23.014022827148438,23.03848648071289,23.360183715820312,23.502397537231445,22.782333374023438,22.873210906982422,18.521263122558594,22.779308319091797,23.327411651611328,22.72795867919922,23.586990356445312,22.78534698486328,22.320096969604492,22.374134063720703,23.458181381225586,22.419160842895508,23.34591293334961,22.41565704345703,20.53725814819336,22.504858016967773,22.718671798706055,22.845195770263672,22.134689331054688,22.88243293762207,22.817272186279297,23.598365783691406,23.164939880371094,23.164508819580078,22.791715621948242,23.314428329467773,23.076539993286133,22.971717834472656,22.553741455078125,22.686838150024414,23.043405532836914,23.15809440612793,23.116525650024414,23.69277000427246,22.68631362915039,22.81048011779785,22.692100524902344,22.828914642333984,23.070890426635742,23.29450798034668,22.74783706665039,22.94149398803711,23.838775634765625,22.113927841186523,22.598073959350586,21.002532958984375,22.017803192138672,23.128185272216797,23.277429580688477,23.672555923461914,22.02068328857422,22.650083541870117,22.087112426757812,22.702280044555664,22.650272369384766,22.56951141357422,21.83609962463379,23.07091522216797,23.235933303833008,23.591033935546875,22.827783584594727,22.91971206665039,23.209367752075195,22.417877197265625,22.35200309753418,23.077354431152344,22.94257164001465,22.319469451904297,22.27820587158203,23.36231231689453,23.74229621887207,22.132110595703125,22.54785919189453,23.4271183013916,23.66170310974121,23.328527450561523,22.861679077148438,23.087263107299805,23.11417007446289,23.407752990722656,23.18048667907715,22.310195922851562,23.272424697875977,23.657787322998047,22.898799896240234,22.575956344604492,22.95118522644043,23.4205379486084,22.633750915527344,21.972320556640625,22.899499893188477,20.99467658996582,22.016136169433594,23.278905868530273,21.05875015258789,22.52427864074707],\"type\":\"scattergl\"},{\"hoverinfo\":\"text\",\"hovertext\":[\"Merge all data into one dataframe\\ndf_merged = df_script.merge(df_characters, on='character_id', suffixes=('', '_character'))\\ndf_merged = df_merged.merge(df_locations, on='location_id', suffixes=('', '_location'))\\ndf_merged = df_merged.merge(df_episodes, on='episode_id', suffixes=('', '_episode'))\",\"Minimum data\\ndf_script = df_script.dropna(subset=['character_id', 'location_id'])\\n\\n# Merge the data\\ndf_script = df_script.merge(\\n    df_episodes[['id', 'title', 'original_air_date']],\\n    how='left', left_on='episode_id', right_on='id'\\n).merge(\\n    df_characters[['id', 'character_name']],\\n    how='left', left_on='character_id', right_on='id'\\n).merge(\\n    df_locations[['id', 'location_name']],\\n    how='left', left_on='location_id', right_on='id'\\n)\",\"Merge the datasets to add more dimensions to the data analysis\\ndf_script_ext = pd.merge(\\n    pd.merge(\\n        pd.merge(df_script, df_characters, on='character_id', how='left'),\\n        df_episodes,\\n        on='episode_id',\\n        how='left'\\n    ),\\n    df_locations,\\n    on='location_id',\\n    how='left'\\n)\",\"Merge with datasets with script\\ndf_merged = df_script.merge(df_episodes, on='episode_id', suffixes=('_script', '_episode'))\\ndf_merged = df_merged.merge(df_characters, on='character_id', suffixes=('_merged', '_character'))\\ndf_merged = df_merged.merge(df_locations, on='location_id', suffixes=('_merged', '_location'))\",\" Merge script lines with characters, locations and episodes\\ndf_script = df_script.merge(df_characters, left_on='character_id', right_on='id', suffixes=['_script', '_character'], how='left')\\ndf_script = df_script.merge(df_locations, left_on='location_id', right_on='id', suffixes=['_script', '_location'], how='left')\\ndf_script = df_script.merge(df_episodes, left_on='episode_id', right_on='id', suffixes=['_script', '_episode'], how='left')\",\"Merge all into one\\ndf_simpsons = (df_script\\n                .merge(df_episodes, on='episode_id', how='inner')\\n                .merge(df_characters, on='character_id', how='inner')\\n                .merge(df_locations, on='location_id', how='inner'))\",\"# Merge scripts, characters and locations\\ndf_temp = pd.merge(df_script, df_episodes, on='episode_id')\\ndf_temp = pd.merge(df_temp, df_characters, left_on='character_id', right_on='id', suffixes=('', '_character')).drop(columns='id')\\ndf_temp = pd.merge(df_temp, df_locations, left_on='location_id', right_on='id', suffixes=('', '_location')).drop(columns='id')\",\"Join the data together\\ndf = (df_script\\n      .merge(df_episodes, on='episode_id', suffixes=('_script', 'ep'))\\n      .merge(df_characters, on='character_id', suffixes=('_ep', 'char'))\\n      .merge(df_locations, on='location_id', suffixes=('_char', 'loc'))\\n     )\",\"Merge the datasets\\ndf_characters = pd.merge(df_characters, df_script, left_on='id', right_on='character_id')\\ndf_characters = pd.merge(df_characters, df_episodes, left_on='episode_id', right_on='id')\\ndf_characters = pd.merge(df_characters, df_locations, left_on='location_id', right_on='id')\",\"Combine character and location information with script data\\ndf_merged = df_script.merge(df_episodes, left_on='episode_id', right_on='id', suffixes=('', '_episode'))\\ndf_merged = df_merged.merge(df_characters, left_on='character_id', right_on='id', suffixes=('', '_character'))\\ndf_merged = df_merged.merge(df_locations, left_on='location_id', right_on='id', suffixes=('', '_location'))\",\"Merge scripts with characters and locations\\ndf_script = df_script.merge(df_characters, left_on='character_id', right_on='id', suffixes=('','_char'), validate=\\\"many_to_one\\\")\\ndf_script = df_script.merge(df_locations, left_on='location_id', right_on='id', suffixes=('','_loc'), validate=\\\"many_to_one\\\")\\n\\n# Shorten the character and location dataframes for merging\\ndf_characters = df_characters[['id', 'name']]\\ndf_locations = df_locations[['id', 'name']]\\n\\n# Merge into one dataframe\\n# df_episodes[df_episodes.id==30] # Example of how to extract a specific id\\ndf = df_script.merge(df_episodes, left_on='episode_id', right_on='id', suffixes=('','_ep'), validate=\\\"many_to_one\\\")\",\"Merge character, location and episode data into script data\\ndf_script = df_script.merge(df_characters, how='left', left_on='character_id', right_on='id', suffixes=('', '_character'))\\ndf_script = df_script.merge(df_locations, how='left', left_on='location_id', right_on='id', suffixes=('', '_location'))\\ndf_script = df_script.merge(df_episodes, how='left', left_on='episode_id', right_on='id', suffixes=('', '_episode'))\",\"merge the dataframes on episode_id\\ndf = pd.merge(df_script, df_episodes, how='left', on='episode_id')\\ndf = pd.merge(df, df_characters, how='left', left_on='raw_character_text', right_on='normalized_name')\\ndf = pd.merge(df, df_locations, how='left', left_on='raw_location_text', right_on='normalized_name')\",\"Prepare data\\n# Merge the datasets\\ndf_all = pd.merge(df_script, df_episodes, how='left', on='episode_id')\\ndf_all = pd.merge(df_all, df_characters, how='left', on='character_id')\\ndf_all = pd.merge(df_all, df_locations, how='left', on='location_id')\",\"Merge the script with the characters and locations\\ndf_script = df_script.merge(df_episodes, on='episode_id', how='left').merge(df_characters, on='character_id', how='left').merge(df_locations, on='location_id', how='left')\",\"\\n# Merge dataframes to create a unified dataframe for analysis\\ndf_merged = pd.merge(df_script, df_episodes, on='episode_id', how='inner')\\ndf_merged = pd.merge(df_merged, df_characters, on='character_id', how='inner')\\ndf_merged = pd.merge(df_merged, df_locations, on='location_id', how='inner')\\n\\n# Output the first few rows of the merged dataframe\\ndf_merged.head()\",\"Merge the dataframes into a single dataframe for analysis\\ndf_merged = df_script.merge(df_episodes, on='episode_id')\\r\\ndf_merged = df_merged.merge(df_characters, on='character_id')\\r\\ndf_merged = df_merged.merge(df_locations, on='location_id')\",\" Merge character, location and episode data into main dataframe for analysis\\n# Merge on 'id' in 'df_script' and character_id in 'df_characters'\\ndf_merged = df_script.merge(df_characters, left_on='character_id', right_on='id', suffixes=['_script', '_character'])\\n\\n# Merge on 'id' in previous merge result and 'episode_id' in 'df_episodes'\\ndf_merged = df_merged.merge(df_episodes, left_on='episode_id', right_on='id', suffixes=['_merged', '_episode'])\\n\\n# Merge on 'location_id' in previous merge result and 'id' in 'df_locations'\\ndf_merged = df_merged.merge(df_locations, left_on='location_id', right_on='id', suffixes=['_previous', '_location'])\",\"left join location, episode to script \\ndf_merged = df_script.join(df_episodes.set_index('id'), on='episode_id') \\ndf_merged = df_merged.join(df_locations.set_index('id'), on='location_id')\",\"Merge episodes data with characters data\\ndf = df_script.merge(df_episodes, on='episode_id').merge(df_characters, on='character_id').merge(df_locations, on='location_id')\",\"Merge data for a more comprehensive analysis\\ndf_merged = pd.merge(df_script, df_episodes, on='episode_id')\\ndf_merged = pd.merge(df_merged, df_characters, on='character_id')\\ndf_merged = pd.merge(df_merged, df_locations, on='location_id')\",\"Keep short only the ones that are useful to avoid cluttering when making predictions from the script\\nshort_cols = ['id', 'character_id', 'location_id', 'episode_id', 'raw_text']\\n\\n# Keep only the useful columns\\ndf_script = df_script[short_cols]\\n\\n# Add episode related data\\ndf_script = df_script.merge(df_episodes,\\n                            how='left',\\n                            on='episode_id')\",\" Merge the script lines with the characters, locations, and episodes datasets\\ndf_script = df_script.merge(df_characters, on='character_id', how='left')\\ndf_script = df_script.merge(df_locations, on='location_id', how='left')\\ndf_script = df_script.merge(df_episodes, on='episode_id', how='left')\",\"Join the script dataframe with the rest of the dataframes\\n# This way we can get the right character, location and episode ids for each line of the scripts\\ndf_script = df_script\\\\\\n    .join(df_characters, on='character_id', rsuffix='_character')\\\\\\n    .join(df_locations, on='location_id', rsuffix='_location')\\\\\\n    .join(df_episodes, on='episode_id', rsuffix='_episode')\",\"Merge the data into a single dataframe\\ndf = (\\n    df_script\\n    .merge(df_characters, how='left', left_on='character_id', right_on='id', suffixes=('', '_character'))\\n    .merge(df_locations, how='left', left_on='location_id', right_on='id', suffixes=('', '_location'))\\n    .merge(df_episodes, how='left', left_on='episode_id', right_on='id', suffixes=('', '_episode'))\\n)\",\"remove all redundant data in the script data\\nscript_reduced_columns = df_script[['episode_id', 'number', 'raw_text', 'character_id', 'location_id']]\\nscript_reduced_columns = script_reduced_columns.dropna()\\n\\nscript_merged = pd.merge(script_reduced_columns, df_characters, left_on='character_id', right_on='id')\\nscript_merged = pd.merge(script_merged, df_locations, left_on='location_id', right_on='id')\\n\\nscript_merged = script_merged[['episode_id', 'number', 'raw_text', 'character_id', 'location_id', 'normalized_name_x', 'name_x', 'normalized_name_y', 'name_y']]\\nscript_merged.columns = ['episode_id', 'number', 'raw_text', 'character_id', 'location_id', 'character_name_normalized', 'character_name', 'location_name_normalized', 'location_name']\\n\\nscript_merged[:5]\",\" Merge Simpsons script with episodes and characters\\ndf = df_script.merge(df_episodes, on='episode_id', how='left').merge(df_characters, left_on='character_id', right_on='id', how='left').merge(df_locations, left_on='raw_location_id', right_on='id', how='left')\",\"\\n# Merge the dataframes\\ndf_script = df_script.merge(df_episodes, on='episode_id', how='left', suffixes=('_script', '_episode'))\\ndf_script = df_script.merge(df_locations, on='location_id', how='left', suffixes=('_script', '_location'))\\ndf_script = df_script.merge(df_characters, on='character_id', how='left', suffixes=('_script', '_character'))\",\"Merge script lines with relevant information about episodes, characters, and locations\\ndf_merged = df_script.merge(df_episodes, on='episode_id', how='left')\\ndf_merged = df_merged.merge(df_characters, on='character_id', how='left')\\ndf_merged = df_merged.merge(df_locations, on='location_id', how='left')\",\" merge to get speaker\\u002fline\\u002fepisode information\\ndf_merged = df_script.merge(df_episodes, on='episode_id')\\ndf_merged = df_merged.merge(df_characters, on='character_id')\\ndf_merged = df_merged.merge(df_locations, on='location_id')\",\" Merge main dataframe with characters and locations\\ndf_merged = pd.merge(df_script, df_episodes, on='episode_id', how='left')\\ndf_merged = pd.merge(df_merged, df_characters, left_on='character_id', right_on='id', how='left')\\ndf_merged = pd.merge(df_merged, df_locations, left_on='location_id', right_on='id', how='left')\",\"Merge data\\ndf_characters_script = df_script.merge(df_characters, how='left')\\ndf_script_merged = df_characters_script.merge(df_episodes, how='left')\",\" Join all tables to determine what characters are in what episodes\\ndf_char_episode = df_script.merge(df_episodes[['id', 'title']], left_on='episode_id', right_on='id', suffixes=('_script', '_episode'))\\ndf_char_episode = df_char_episode.merge(df_characters, left_on='character_id', right_on='id', suffixes=('_ce', '_character'))\\ndf_char_episode = df_char_episode.merge(df_locations, left_on='location_id', right_on='id', suffixes=('_ce', '_location'))\",\"Filter columns\\ndf_script = df_script[['episode_id', 'number', 'raw_text', 'character_id', 'location_id']].copy()\\n\\n# Merge the tables\\ndf = df_script.copy()\\ndf = df.merge(df_episodes, left_on='episode_id', right_on='id')\\ndf = df.merge(df_characters, left_on='character_id', right_on='id')\\ndf = df.merge(df_locations, left_on='location_id', right_on='id')\\n\\n# Save for later use\\ndf.to_csv('data\\u002fmerged_simpsons_dataset.csv', index=False)\",\" Merge scripts with corresponding episode data\\ndf = df_script.join(df_episodes, on='episode_id', rsuffix='_ep')\\ndf = df.join(df_characters, on='character_id', rsuffix='_ch')\\ndf = df.join(df_locations, on='location_id', rsuffix='_loc')\\n\\n# Preview the dataset\\ndf.head()\",\"Data organization\\ndf_script = df_script.merge(df_episodes, on='episode_id', how='left')\\ndf_script = df_script.merge(df_characters, on='character_id', how='left')\\ndf_script = df_script.merge(df_locations, on='location_id', how='left')\",\"Merge relevant columns from the other DataFrames into the main df_script DataFrame\\ncols_characters = [\\\"id\\\",\\\"name\\\",\\\"normalized_name\\\",\\\"gender\\\"]\\ncols_locations = [\\\"id\\\",\\\"name\\\",\\\"normalized_name\\\"]\\ncols_episodes = [\\\"id\\\",\\\"title\\\",\\\"original_air_date\\\"]\\n\\ndf_script = pd.merge(df_script, df_characters[cols_characters], left_on=\\\"character_id\\\", right_on=\\\"id\\\", suffixes=(\\\"\\\", \\\"_character\\\")).drop(columns=[\\\"id\\\"])\\ndf_script = pd.merge(df_script, df_locations[cols_locations], left_on=\\\"location_id\\\", right_on=\\\"id\\\", suffixes=(\\\"\\\", \\\"_location\\\")).drop(columns=[\\\"id\\\"])\\ndf_script = pd.merge(df_script, df_episodes[cols_episodes], left_on=\\\"episode_id\\\", right_on=\\\"id\\\", suffixes=(\\\"\\\", \\\"_episode\\\")).drop(columns=[\\\"id\\\"])\",\"Merge the datasets on episode_id\\ndf = pd.merge(df_script, df_episodes, on='episode_id').merge(df_characters, on='character_id').merge(df_locations, on='location_id')\",\" Join locations and episodes information to script data\\ndf_script = pd.merge(df_script, df_episodes, on='episode_id', how='left')\\ndf_script = pd.merge(df_script, df_locations, on='location_id', how='left')\",\"merge episodes with characters and locations\\ndf_episodes_chars_locs = pd.merge(df_episodes, df_characters, on='episode_id')\\ndf_episodes_chars_locs = pd.merge(df_episodes_chars_locs, df_locations, on='episode_id')\",\"Merge episodes and script with character and location details\\ndf = df_script.merge(df_episodes, on='episode_id')  # Merge episodes with script\\ndf = df.merge(df_characters, on='character_id')  # Merge characters with episode-script\\ndf = df.merge(df_locations, on='location_id')  # Merge locations with episode-script\",\"Compute important additional data\\ndf_script = df_script.merge(df_episodes, on='episode_id', how='left')\\ndf_script = df_script.merge(df_characters, on='character_id', how='left')\\ndf_script = df_script.merge(df_locations, on='location_id', how='left')\",\"# Extract relevant columns\\ndf_script = df_script[['episode_id', 'number', 'raw_text', 'character_id', 'location_id']]\\n\\n# Merge dataframes\\ndf_script = df_script.merge(df_characters, left_on='character_id', right_on='id')\\ndf_script = df_script.merge(df_locations, left_on='location_id', right_on='id')\\n\\n# Drop unnecessary columns\\ndf_script.drop(columns=['id_x', 'id_y', 'normalized_name', 'normalized_location'], inplace=True)\\n\\n# Show df_script\\ndf_script.head()\",\"Merge characters, locations, episodes, and script lines\\ndf = df_script.merge(df_episodes, on='episode_id', how='inner') \\\\\\n              .merge(df_characters, on='character_id', how='inner') \\\\\\n              .merge(df_locations, on='location_id', how='inner')\",\" Merge data\\ndf = df_script.merge(df_episodes, on='episode_id')\\ndf = df.merge(df_characters, on='character_id')\\ndf = df.merge(df_locations, on='location_id')\",\"Merge datasets for a complete view of the data\\ndf_complete = df_script.merge(df_episodes, how='left', on='episode_id')\\ndf_complete = df_complete.merge(df_characters, how='left', left_on='character_id', right_on='id', suffixes=('_script', '_character')).drop(['id_script', 'id_character'], axis=1)\\ndf_complete = df_complete.merge(df_locations, how='left', left_on='location_id', right_on='id', suffixes=('_character', '_location')).drop(['id_character', 'id'], axis=1)\",\"Merging all the datasets based on \\\"episode_id\\\"\\ndf = pd.merge(df_script, df_episodes, on='episode_id')\\ndf = pd.merge(df, df_characters, on='character_id')\\ndf = pd.merge(df, df_locations, on='location_id')\",\"Merge script lines with characters and locations data\\ndf_script_characters = df_script.merge(df_characters, on='character_id', suffixes=('', '_char')).merge(df_locations, on='location_id', suffixes=('', '_char')).merge(df_episodes, on='episode_id', suffixes=('', '_char'))\",\"Merge dataframes to have all the data in one place\\ndf_merged = pd.merge(df_script, df_episodes, on='episode_id')\\ndf_merged = pd.merge(df_merged, df_characters, on='character_id', how='inner')\\ndf_merged = pd.merge(df_merged, df_locations, on='location_id', how='inner')\",\"Merge datasets to have episode, character and location information in one DataFrame\\ndf_merged = pd.merge(df_script, df_episodes, how='left', on='episode_id')\\ndf_merged = pd.merge(df_merged, df_characters, how='left', left_on='character_id', right_on='id')\\ndf_merged = pd.merge(df_merged, df_locations, how='left', left_on='location_id', right_on='id')\\n\\n# Show the first few rows of the DataFrame\\ndf_merged.head()\",\" Join the dataframes on the appropriate columns\\ndf_joined = (df_script\\n            .merge(df_episodes, how='left', left_on='episode_id', right_on='id', suffixes=('_script', '_episod'))\\n            .merge(df_characters, how='left', left_on='character_id', right_on='id', suffixes=('_script', '_character'))\\n            .merge(df_locations, how='left', left_on='location_id', right_on='id', suffixes=('_script', '_location')))\",\"Merging datasets\\ndf_merge = df_script.merge(df_episodes, on='episode_id', how='inner')\\ndf_merge = df_merge.merge(df_characters, on='character_id', how='inner')\\ndf_merge = df_merge.merge(df_locations, on='location_id', how='inner')\\n\\n# Moving the merge key to the front\\ncols = list(df_merge)\\ncols.insert(0, cols.pop(cols.index('id')))\\ndf_merge = df_merge.loc[:, cols]\",\"df_script_episode = pd.merge(df_script, df_episodes, left_on='episode_id', right_on='id')\\ndf_script_character = pd.merge(df_script, df_characters, left_on='character_id', right_on='id')\\ndf_script_location = pd.merge(df_script, df_locations, left_on='location_id', right_on='id')\",\"fourth merge to create our final dataset: df\\ndf = (\\n    df_script\\n    .merge(df_characters, how='inner', on='character_id')\\n    .merge(df_episodes, how='inner', on='episode_id')\\n    .merge(df_locations, how='inner', on='location_id')\\n)\",\"Merge the dataframes to simplify analysis.\\ndf = df_script.merge(df_episodes, on='episode_id')\\ndf = df.merge(df_characters, on='character_id', suffixes=['_script', '_character'])\\ndf = df.merge(df_locations, on='location_id')\",\"Merge lines with character and locations files\\ndf_script = pd.merge(df_script, df_characters, on='character_id', how='left')\\ndf_script = pd.merge(df_script, df_locations, on='location_id', how='left')\\n\\n# Merge script with episodes\\ndf_script = pd.merge(df_script, df_episodes, on='episode_id', how='left')\",\"Merge the dataframes\\ndf_joined = df_script.merge(df_episodes, how='left', on='episode_id')\\ndf_joined = df_joined.merge(df_characters, how='left', left_on='character_id', right_on='id')\\ndf_joined = df_joined.merge(df_locations, how='left', left_on='raw_location_text', right_on='raw_location_text')\",\"Merge all datasets into one by episode_id\\ndf = pd.merge(df_script, df_episodes, on='episode_id')\\ndf = pd.merge(df, df_characters, on='character_id')\\ndf = pd.merge(df, df_locations, on='location_id')\",\"Merge characters, locations, episodes, and script lines.\\ndf_merged = df_script.merge(df_episodes, on='episode_id') \\\\\\n    .merge(df_characters, on='character_id') \\\\\\n    .merge(df_locations, on='location_id')\\n\\nprint('Number of merged rows:', df_merged.shape[0])\\n\\n# Display the merged dataframe\\ndf_merged.head()\",\"Merge script with locations and characters\\ndf_script = df_script.merge(df_episodes[['id', 'season', 'number_in_season', 'number_in_series']], on='id')\\n\\ndf_script = df_script.merge(df_characters, on='character_id')\\n\\ndf_script = df_script.merge(df_locations, on='location_id')\",\"Merge script lines with characters\\ndf_script = df_script.merge(df_characters, on='character_id', how='inner')\\n\\n# Merge script lines with locations\\ndf_script = df_script.merge(df_locations, on='location_id', how='inner')\\n\\n# Merge script lines with episodes\\ndf_script = df_script.merge(df_episodes, on='episode_id', how='inner')\",\"Join the datasets together\\ndf_all = pd.merge(\\n    pd.merge(pd.merge(df_script, df_episodes, on='episode_id'), df_characters, on='character_id'),\\n    df_locations,\\n    on='location_id'\\n)\",\" Merge lines with characters and locations\\ndf_lines = df_script.merge(df_episodes, on=\\\"episode_id\\\")\\ndf_lines = df_lines.merge(df_characters, on=\\\"character_id\\\", suffixes=('_line', '_character'))\\ndf_lines = df_lines.merge(df_locations, on=\\\"location_id\\\", suffixes=('_line', '_location'))\",\"Merge `df_script` with `df_characters` on `character_id`\\ndf_script_char = df_script.merge(df_characters, on='character_id', how='left')\\n# Merge `df_script` with `df_locations` on `location_id`\\ndf_script_char_loc = df_script_char.merge(df_locations, on='location_id', how='left')\\n# Merge `df_script` with `df_episodes` on `episode_id`\\ndf = df_script_char_loc.merge(df_episodes, on='episode_id', how='left')\",\"Data transformation\\n# Select important columns from the df_script dataframe\\ndf_script = df_script[['episode_id', 'number', 'timestamp_in_ms', 'character_id', 'location_id', 'raw_text']]\\n\\n# Merge the df_script dataframe with the df_episodes dataframe\\ndf_episodes['episode_id'] = df_episodes.index + 1  # The episode_id starts at 1 instead of 0\\ndf_script = pd.merge(df_script, df_episodes, on='episode_id')\\n\\n# Merge the df_script dataframe with the df_characters dataframe\\ndf_script = pd.merge(df_script, df_characters, left_on='character_id', right_on='id', suffixes=('', '_character'))\\n\\n# Merge the df_script dataframe with the df_locations dataframe\\ndf_script = pd.merge(df_script, df_locations, left_on='location_id', right_on='id', suffixes=('', '_location'))\",\"Merge script with character, location and episode\\ndf = (df_script\\n      .merge(df_characters, how='left', on='character_id', suffixes=('', '_character'))\\n      .merge(df_locations, how='left', on='location_id', suffixes=('', '_location'))\\n      .merge(df_episodes, how='left', on='episode_id', suffixes=('', '_episode')))\",\"Join all available data to create a master dataframe.\\n# Join characters\\ndf = df_script.join(df_characters, on='character_id', lsuffix='_script', rsuffix='_character', how='left')\\n\\n# Join locations\\ndf = df.join(df_locations, on='location_id', lsuffix='_script', rsuffix='_location', how='left')\\n\\n# Join episodes\\ndf = df.join(df_episodes, on='episode_id', lsuffix='_script', rsuffix='_location', how='left')\",\" Merge locations, script lines and episodes into one dataframe\\ndf_merged = (df_script\\n             .merge(df_locations, how='left', on='raw_location_text')\\n             .merge(df_episodes, how='left', left_on='episode_id', right_on='id'))\\n\\n# Merge with characters to include Speaker\\u002fListener names\\ndf_merged = df_merged.merge(df_characters, how='left', left_on='raw_character_text', right_on='name')\",\"Merge relevant data\\ndf_merged = pd.merge(df_script, df_episodes,\\n                     on='episode_id',\\n                     how='left')\\n\\ndf_merged = pd.merge(df_merged, df_characters,\\n                     on='character_id',\\n                     how='left')\\n\\ndf_merged = pd.merge(df_merged, df_locations,\\n                     on='location_id',\\n                     how='left')\",\"\\n# Merge main data into a single dataframe\\ndf_merged = (\\n    df_script\\n    .merge(df_episodes, on='episode_id', suffixes=('_script', ''))\\n    .merge(df_characters, on='character_id', suffixes=('_script', '_character'))\\n    .merge(df_locations, on='location_id', suffixes=('_script', '_location'))\\n)\",\"Join datasets\\n# Merge the datasets to have all the information in the same DataFrame\\ndf = df_script.merge(df_episodes, on='episode_id')\\ndf = df.merge(df_characters, on='character_id', suffixes=('', '_from'))\\ndf = df.merge(df_locations, on='location_id', suffixes=('', '_from'))\",\"Joining characters, locations and episodes to script data\\ndf_script = df_script.merge(df_characters, on='character_id', how='left')\\ndf_script = df_script.merge(df_locations, on='location_id', how='left')\\ndf_script = df_script.merge(df_episodes, on='episode_id', how='left')\",\"Merging tables to get all informations in the same place\\ndf = df_script.merge(df_episodes, on='episode_id', suffixes=('_script', '_ep'))\\ndf = df.merge(df_characters, on='character_id', suffixes=(False, '_ch'))\\ndf = df.merge(df_locations, on='location_id', suffixes=(False, '_loc'))\",\"Merge the characters and locations dataframes with the script dataframe\\ndf_script = df_script.merge(df_characters, left_on='character_id', right_on='id')\\ndf_script = df_script.merge(df_locations, left_on='location_id', right_on='id')\\n\\n# Reorder columns\\ndf_script = df_script[['id_x', 'episode_id', 'number', 'raw_text', 'timestamp_in_ms', 'speaking_line', \\n                       'character_id', 'name_x', 'normalized_text_y', 'location_id', 'name_y', 'image_url', \\n                       'normalized_text_x', 'wikipedia_url', 'number_y', 'normalized_text']]\",\"Merge characters and locations on episode_id\\ndf_characters_locations = df_characters.merge(df_locations, on='episode_id')\",\"Join episodes and locations\\ndf_joined = df_episodes.merge(\\n    df_locations,\\n    how='left',\\n    left_on='id',\\n    right_on='episode_id'\\n)\",\"Join locations, characters and script data\\ndf_locations = df_locations.merge(df_script, left_on='id', right_on='location_id', suffixes=('_location', ''))\\ndf_locations = df_locations.merge(df_episodes, on='episode_id', suffixes=('_location', '_episode'))\\ndf_characters = df_characters.merge(df_script, left_on='id', right_on='character_id', suffixes=('_character', ''))\",\"Merge the data into a single dataframe\\ndf = (\\n    df_script\\n    .merge(df_episodes, on='episode_id', how='left')\\n    .merge(df_characters, on='character_id', how='left')\\n    .merge(df_locations, on='location_id', how='left')\\n)\",\"Merging dataframes for comprehensive dataframe of Simpsons data\\ndf = df_script.merge(df_episodes, how=\\\"left\\\", on=\\\"episode_id\\\")\\ndf = df.merge(df_characters, how=\\\"left\\\", left_on=\\\"character_id\\\", right_on=\\\"id\\\").rename(columns={\\\"name\\\": \\\"character_name\\\"})\\ndf = df.merge(df_locations, how=\\\"left\\\", left_on=\\\"location_id\\\", right_on=\\\"id\\\").rename(columns={\\\"name\\\": \\\"location_name\\\"})\\n\\n# Save the merged dataframe for future use\\ndf.to_pickle(\\\"data\\u002fsimpsons_dataframe.pkl\\\")\",\"Merge with character information\\ndf_script = df_script.merge(df_characters, left_on='character_id', right_on='id', suffixes=('','_character')).drop(labels='id_character', axis=1)\\n\\n# Merge with location information\\ndf_script = df_script.merge(df_locations, left_on='location_id', right_on='id', suffixes=('','_location')).drop(labels='id_location', axis=1)\\n\\n# Merge with episode information\\ndf_script = df_script.merge(df_episodes, left_on='episode_id', right_on='id', suffixes=('','_episode')).drop(labels='id_episode', axis=1)\\n\\n# Display the resulting dataframe\\ndf_script.head()\",\"Merge character, location and episodes information into the main script dataframe\\ndf_script = df_script.merge(df_characters, how='left', left_on='character_id', right_on='id', suffixes=(False, False)).drop('id', axis=1)\\ndf_script = df_script.merge(df_locations, how='left', left_on='location_id', right_on='id', suffixes=(False, False)).drop('id', axis=1)\\ndf_script = df_script.merge(df_episodes, how='left', left_on='episode_id', right_on='id', suffixes=(False, False)).drop('id', axis=1)\",\" Merge some dataframes to be used later on\\ndf = df_script.merge(df_characters, how='inner', on='character_id')\\ndf = df.merge(df_locations, how='inner', on='location_id')\\ndf = df.merge(df_episodes, how='left', on='episode_id')\\n\\n# Show first rows\\ndf.head()\",\"Merge episode, character and location data into script data\\ndf_script = df_script.merge(df_episodes, on='episode_id')\\ndf_script = df_script.merge(df_characters, on='character_id', suffixes=('', '_character'))\\ndf_script = df_script.merge(df_locations, on='location_id', suffixes=('', '_location'))\",\"Adds characters information to script dataframe\\ndf_script = pd.merge(df_script,\\n                     df_characters,\\n                     left_on='character_id',\\n                     right_on='id').drop(columns=['id'])\\n\\n# Adds locations information to script dataframe\\ndf_script = pd.merge(df_script,\\n                     df_locations,\\n                     left_on='location_id',\\n                     right_on='id').drop(columns=['id'])\\n\\n# Adds episodes information to script dataframe\\ndf_script = pd.merge(df_script,\\n                     df_episodes,\\n                     left_on='episode_id',\\n                     right_on='id').drop(columns=['id'])\\n\\ndf_script.head()\",\"# Smarter overviews by joining the data\\ndf_merged = df_script.copy()\\ndf_merged = df_merged.join(df_episodes.set_index('id'), on='episode_id')\\ndf_merged = df_merged.join(df_characters.set_index('id'), on='character_id', rsuffix='_character')\\ndf_merged = df_merged.join(df_locations.set_index('id'), on='location_id', rsuffix='_location')\",\"merge main tables using foreignkeys and other columns\\ndf_merged = df_script.merge(df_episodes, on='episode_id', suffixes=('', '_ep'))\\ndf_merged = df_merged.merge(df_characters, on='character_id', suffixes=('', '_ch'))\\ndf_merged = df_merged.merge(df_locations, on='location_id', suffixes=('', '_l'))\",\" Merge dataframes to get a full view of the data\\ndf_episodes_full = df_episodes.merge(df_script, on='episode_id', how='outer')\\ndf_episodes_full = df_episodes_full.merge(df_locations, on='location_id', how='outer')\\ndf_episodes_full = df_episodes_full.merge(df_characters, left_on='raw_character_text', right_on='name', how='left')\",\"Merge character information into the script dataframe\\ndf_full = pd.merge(\\n    df_script,\\n    df_episodes,\\n    how='left',\\n    on='episode_id',\\n    suffixes=('_script', '_episode')\\n)\\n\\ndf_full = pd.merge(\\n    df_full,\\n    df_characters,\\n    how='left',\\n    on='character_id',\\n    suffixes=('', '_character')\\n)\",\"Merge character, location and episode data into the script data\\ndf_script = pd.merge(df_script, df_characters, on='character_id', how='left')\\ndf_script = pd.merge(df_script, df_locations, on='location_id', how='left')\\ndf_script = pd.merge(df_script, df_episodes, on='episode_id', how='left')\",\"# Merge script, characters, locations and episodes files\\ndf_script['character_id'] = df_script['character_id'].astype('Int64')\\ndf_script['location_id'] = df_script['location_id'].astype('Int64')\\ndf_script = df_script \\\\\\n        .merge(df_characters, how='left', left_on='character_id', right_on='id', suffixes=('_script', '_character')) \\\\\\n        .merge(df_locations, how='left', left_on='location_id', right_on='id', suffixes=('_script', '_location')) \\\\\\n        .merge(df_episodes, how='left', left_on='episode_id', right_on='id', suffixes=('_script', '_episode'))\\n\\n# Sort the df_script to always have the episodes in order\\ndf_script = df_script.sort_values(by=['imdb_rating', 'original_air_date', 'season', 'number_in_season', 'number_in_series'])\\n\\n# We don't need the same information twice or ids\\ndf_script.drop(['id_script', 'id_character', 'id_location', 'id_episode'], axis=1, inplace=True)\",\"Merge datasets: Location to Episode\\ndf_locations_ep = df_locations.merge(df_episodes,\\n                                     on='id',\\n                                     how='right')\\n# Change the order of columns\\n# Get the list of columns\\ncols = df_locations_ep.columns.tolist()\\n# Print the list\\nprint(cols)\",\"Merge the scripts with the characters and locations\\ndf_merged = df_script.merge(df_episodes, on='episode_id')  # merge scripts with episodes\\ndf_merged = df_merged.merge(df_characters, on='character_id')  # merge characters\\ndf_merged = df_merged.merge(df_locations, on='location_id')  # merge locations\",\"Merge the dataframes to simplify the analysis\\ndf_merge = pd.merge(df_script, df_episodes, how='left', on='episode_id')\\ndf_merge = pd.merge(df_merge, df_characters, how='left', on='character_id')\\ndf_merge = pd.merge(df_merge, df_locations, how='left', on='location_id')\\n\\nprint('Number of entries: {}'.format(len(df_merge)))\",\"ppend all the data into one single data frame\\ndf_final = pd.merge(df_script, df_characters, how='left', on=['character_id'])\\ndf_final = pd.merge(df_final, df_locations, how='left', on=['location_id'])\\ndf_final = pd.merge(df_final, df_episodes, how='left', on=['episode_id'])\",\"Create a pandas dataframe containing the character, location and episode information\\n\\nloc_c = pd.DataFrame(pd.merge(df_script, df_characters, on='character_id', how='left'))\\nloc_c_e = pd.DataFrame(pd.merge(loc_c, df_episodes, on='episode_id', how='left'))\\nloc_c_e.url=loc_c_e.url.astype(str)\\n\\nloc_c_e.info()\",\"Merge characters, locations and episodes into the main dataframe\\ndf_script_full = (df_script\\n                  .merge(\\n                      df_characters,\\n                      how='left',\\n                      left_on='character_id',\\n                      right_on='id',\\n                      suffixes=('_script', '_character')\\n                  )\\n                  .merge(\\n                      df_locations,\\n                      how='left',\\n                      left_on='location_id',\\n                      right_on='id',\\n                      suffixes=('','_location')\\n                  )\\n                  .merge(\\n                      df_episodes,\\n                      how='left',\\n                      left_on='episode_id',\\n                      right_on='id',\\n                      suffixes=('','_episode')\\n                  )\\n                 )\",\"Merge all datasets on 'episode_id'\\ndf = df_script.merge(df_episodes, on='episode_id')\\ndf = df.merge(df_locations, on='location_id')\\ndf = df.merge(df_characters, on='character_id')\",\" Merge datasets\\ndf_script_episodes = df_script.merge(df_episodes, on='episode_id', how='left')\\ndf_script_episodes_characters = df_script_episodes.merge(df_characters, left_on='character_id', right_on='id', how='left', suffixes=['_script', '_character'])\\ndf_script_episodes_characters_locations = df_script_episodes_characters.merge(df_locations, left_on='location_id', right_on='id', how='left', suffixes=['_character', '_location'])\\n\\n# Now we have a single dataframe containing all the information.\",\"Merge lines with episodes and characters\\ndf_merged = df_script.merge(df_episodes, how='left', on='episode_id')\\ndf_merged = df_merged.merge(df_characters, how='left', left_on='character_id', right_on='index')\\n\\n# Add locations\\ndf_merged = df_merged.merge(df_locations, how='left', left_on='location_id', right_on='index')\",\"Merge episode, character and location names into the main script dataframe\\ndf_script = df_script.merge(df_episodes[['id', 'title', 'original_air_date', 'production_code']], \\n                            left_on='episode_id', right_on='id', how='left')\\ndf_script = df_script.merge(df_characters[['id', 'normalized_name']], \\n                            left_on='character_id', right_on='id', how='left')\\ndf_script = df_script.merge(df_locations[['id', 'normalized_name']], \\n                            left_on='location_id', right_on='id', how='left')\",\"Merge episodes with locations and characters\\ndf_episodes['id'] = df_episodes['id'].astype(int)\\ndf_locations['id'] = df_locations['id'].astype(int)\\ndf_characters['id'] = df_characters['id'].astype(int)\",\"Selecting the seasons that we want to keep\\ndf_episodes = df_episodes[df_episodes.season \\u003c= 12]\\n\\n# Merging the characters, locations and episodes with the script\\ndf_simpsons = pd.merge(df_script, df_episodes, how='left', on='episode_id')\\ndf_simpsons = pd.merge(df_simpsons, df_characters, how='left', left_on='character_id', right_on='id', suffixes=('_script', '_character'))\\ndf_simpsons = pd.merge(df_simpsons, df_locations, how='left', left_on='location_id', right_on='id', suffixes=('_script', '_location'))\",\" Merge all datasets into a single dataframe\\ndf = (df_script\\n      .merge(df_episodes, on='episode_id')\\n      .merge(df_characters, on='character_id', how='left')\\n      .merge(df_locations, on='location_id', how='left'))\",\"Merge script with episodes and characters\\ndf_script = df_script.merge(df_episodes, on='episode_id', how='left')\\ndf_script = df_script.merge(df_characters, left_on='character_id', right_on='id', how='left', suffixes=('', '_character'))\\ndf_script = df_script.merge(df_locations, left_on='location_id', right_on='id', how='left', suffixes=('', '_location'))\",\"Merge the characters, locations, and episodes dataframes with the script dataframe\\ndf_script = df_script.merge(df_episodes, how='left', left_on='episode_id', right_on='id',\\n                            suffixes=('_script', '_episodes'))\\ndf_script = df_script.merge(df_characters, how='left', left_on='character_id', right_on='id',\\n                            suffixes=('', '_characters'))\\ndf_script = df_script.merge(df_locations, how='left', left_on='location_id', right_on='id',\\n                            suffixes=('_script', '_locations'))\",\" Merge the tables to have everything in a single place\\ndf = df_script.merge(df_episodes, on='episode_id', suffixes=('', '_episode'))\\ndf = df.merge(df_locations, on='location_id', suffixes=('', '_location'))\\ndf = df.merge(df_characters, on='character_id', suffixes=('', '_character'))\",\"Merge the dataframes together\\ndf_merged = df_script.merge(df_characters, on='character_id')\\ndf_merged = df_merged.merge(df_locations, on='location_id')\\ndf_merged = df_merged.merge(df_episodes, on='episode_id')\",\"Merge characters, locations, script lines, and episodes data\\ndf_episodes['id'] = df_episodes['id'].astype(str)  # Change type to string to merge\\ndf_script['episode_id'] = df_script['episode_id'].astype(str)  # Change type to string to merge\\ndf = df_script.merge(df_episodes, left_on='episode_id', right_on='id')  # Merge script lines and episodes\\ndf['character_id'] = df['character_id'].astype(str)  # Change type to string to merge\\ndf = df.merge(df_characters, left_on='character_id', right_on='id')  # Merge script lines and characters\\ndf['location_id'] = df['location_id'].astype(str)  # Change type to string to merge\\ndf = df.merge(df_locations, left_on='location_id', right_on='id')  # Merge script lines and locations\",\"Merge the script lines with the episodes and characters dataframes to add the episode and character information\\ndf_characters = df_characters.rename(columns={\\\"id\\\": \\\"character_id\\\"})\\ndf_locations = df_locations.rename(columns={\\\"id\\\": \\\"location_id\\\"})\\ndf_script = pd.merge(df_script, df_characters, on='character_id', how='left')\\ndf_script = pd.merge(df_script, df_locations, on='location_id', how='left')\\ndf_script = pd.merge(df_script, df_episodes, on='episode_id', how='left')\\n\\n# Sanity check\\ndf_script.head()\",\"\\n# Merge script, characters and locations dataframes on episode id\\ndf_merged = df_script.merge(df_episodes, on='episode_id')\\ndf_merged = df_merged.merge(df_characters, left_on='character_id', right_on='id', suffixes=('_script', '_character'))\\ndf_merged = df_merged.merge(df_locations, left_on='location_id', right_on='id', suffixes=('_character', '_location'))\",\"Join the datasets\\ndf_script = (\\n    df_script\\n    .merge(df_episodes, left_on='episode_id', right_on='id', suffixes=('', '_episode'))\\n    .merge(df_characters, left_on='character_id', right_on='id', suffixes=('', '_character'))\\n    .merge(df_locations, left_on='location_id', right_on='id', suffixes=('', '_location'))\\n)\",\"Data merge\\ndf_script = df_script \\n    .merge(df_episodes, on='episode_id', how='left')\\n    .merge(df_characters, on='character_id', how='left')\\n    .merge(df_locations, on='location_id', how='left')\",\"Merge script data with character and episode information\\ndf_script = (\\n    df_script\\n    .merge(df_characters, how='left', left_on='character_id', right_on='id', suffixes=('', '_character'))\\n    .merge(df_locations, how='left', left_on='location_id', right_on='id', suffixes=('', '_location'))\\n    .merge(df_episodes, how='left', left_on='episode_id', right_on='id', suffixes=('', '_episode'))\\n)\",\"Merge all datasets\\ndf_merged = df_script.merge(df_episodes, left_on='episode_id', right_on='id', suffixes=('', '_ep'))\\ndf_merged = df_merged.merge(df_characters, left_on='character_id', right_on='id', suffixes=('', '_ch'))\\ndf_merged = df_merged.merge(df_locations, left_on='location_id', right_on='id', suffixes=('', '_loc'))\",\" Merge datasets\\n# Merge characters and script\\ndf_chars_script = pd.merge(df_characters, df_script, on='character_id')\\n\\n# Merge episodes and locations\\ndf_ep_locs = pd.merge(df_episodes, df_locations, on='location_id')\\n\\n# Merge the previous result with characters and script\\ndf_ep_locs_chars_script = pd.merge(df_ep_locs, df_chars_script, on='episode_id')\",\"Merge episodes with locations\\ndf_episodes_locations = df_episodes.merge(\\n    df_locations, left_on='id', right_on='episode_id')\\n\\n# Count how many times each location was used\\nlocation_counts = df_episodes_locations.location_id.value_counts()\\n\\n# Merge episodes with characters\\ndf_episodes_characters = df_episodes.merge(\\n    df_characters, left_on='id', right_on='episode_id')\\n\\n# Count how many times each character was used\\ncharacter_counts = df_episodes_characters.character_id.value_counts()\\n\\n# Create a location count plot\\nlocation_counts.plot(kind='bar', figsize=(15, 5))\\nplt.title('Number of times each location was used')\\nplt.ylabel('Count')\\nplt.xlabel('Location')\\nplt.show()\\n\\n# Create a character count plot\\ncharacter_counts.plot(kind='bar', figsize=(15, 5))\\nplt.title('Number of times each character was used')\\nplt.ylabel('Count')\\nplt.xlabel('Character')\\nplt.show()\",\" Join the tables on their respective identifiers\\ndf = df_script.merge(df_characters, left_on='character_id', right_on='id')\\ndf = df.merge(df_locations, left_on='location_id', right_on='id')\\ndf = df.merge(df_episodes, left_on='episode_id', right_on='id')\"],\"marker\":{\"opacity\":0.5,\"size\":5},\"mode\":\"markers+text\",\"name\":\"2_Data merging and joining with pandas\",\"text\":[\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\"],\"textfont\":{\"size\":12},\"x\":[0.8372123837471008,2.5942068099975586,0.7801926732063293,0.9479038715362549,2.077594518661499,1.715301513671875,1.9557801485061646,1.170737385749817,0.6387087106704712,1.7637375593185425,1.4858949184417725,1.8770473003387451,1.3579071760177612,0.4744926691055298,1.3472073078155518,0.44940510392189026,0.5502644181251526,1.6062438488006592,1.466436505317688,1.5458968877792358,0.7727036476135254,1.6704212427139282,1.6932806968688965,1.40587317943573,1.434654712677002,1.8373699188232422,1.7712502479553223,1.50355863571167,2.0523219108581543,2.6915550231933594,1.0918254852294922,0.9145764708518982,1.9338791370391846,1.6273479461669922,0.9516232013702393,1.1237555742263794,2.2406487464904785,0.5280584692955017,1.0791996717453003,1.4941942691802979,1.5692245960235596,1.7243794202804565,2.550365924835205,1.381681203842163,1.387304663658142,1.7720915079116821,0.5105898380279541,1.504488468170166,0.536702573299408,0.6294195652008057,1.1721973419189453,0.5986788868904114,1.5392986536026,0.6853958368301392,1.1283485889434814,1.803707242012024,1.373286247253418,0.4237704277038574,0.9976878762245178,1.934052586555481,1.6807124614715576,0.879925012588501,2.152074098587036,1.4912606477737427,1.9975707530975342,1.410245656967163,1.0178606510162354,2.0884649753570557,0.8643401265144348,1.214489459991455,1.4529238939285278,1.2273657321929932,0.9058386087417603,2.2424280643463135,1.2046098709106445,1.2008452415466309,1.6405068635940552,0.7949310541152954,2.0942487716674805,2.480545997619629,2.350874185562134,0.8922217488288879,1.5329793691635132,2.2573468685150146,1.1578525304794312,1.0019325017929077,1.1127877235412598,1.4378234148025513,1.2100780010223389,1.8613736629486084,0.09952449053525925,1.249523401260376,0.5555106401443481,0.6702791452407837,0.997671365737915,1.4479734897613525,0.8067142963409424,1.2233045101165771,1.9539517164230347,2.051328659057617,2.0116403102874756,2.00252628326416,0.7134736180305481,1.6932371854782104,1.5294055938720703,1.1298365592956543,1.1123121976852417,2.2384085655212402,2.281426191329956,1.3317795991897583,1.4529916048049927,1.1362569332122803,1.7121896743774414,1.0517120361328125,0.5179507732391357,1.3281476497650146,1.311240553855896],\"y\":[7.980993270874023,7.814395427703857,8.053804397583008,7.60822868347168,8.63949203491211,8.067424774169922,7.724775314331055,7.9388957023620605,7.846190929412842,8.688858985900879,8.952364921569824,8.771492958068848,8.202458381652832,8.169535636901855,8.772540092468262,8.446746826171875,7.882386207580566,9.026994705200195,7.458232879638672,7.44222354888916,7.832034587860107,7.44540548324585,8.268128395080566,7.268777370452881,9.138448715209961,8.06135368347168,8.912626266479492,8.641253471374512,8.586359024047852,7.82621431350708,8.62351131439209,8.09334945678711,7.772625923156738,7.579910755157471,6.746441841125488,8.511693954467773,8.389994621276855,7.380428791046143,8.142770767211914,6.988774299621582,7.59818172454834,8.41942024230957,7.742094993591309,7.887796878814697,7.6075639724731445,8.138282775878906,7.252388954162598,8.436277389526367,7.986318588256836,8.657231330871582,8.03690242767334,7.376106262207031,8.46358585357666,7.797653675079346,7.905806541442871,8.764427185058594,8.346612930297852,7.181016445159912,8.091795921325684,7.440870761871338,7.815307140350342,7.209728717803955,7.815106391906738,8.990072250366211,8.097030639648438,9.005229949951172,7.952292442321777,8.068442344665527,8.52386474609375,7.545063018798828,6.947904586791992,8.660758018493652,7.730419158935547,8.450119018554688,7.156317234039307,8.016602516174316,8.031643867492676,8.815071105957031,8.768943786621094,8.296185493469238,8.488199234008789,8.733027458190918,7.83955717086792,8.217422485351562,7.261812210083008,7.9367547035217285,8.967409133911133,8.17343521118164,8.88229751586914,8.622037887573242,7.614406108856201,7.157922267913818,8.594654083251953,8.647180557250977,9.139660835266113,9.047247886657715,7.555705547332764,9.132390022277832,8.468976974487305,8.27946662902832,6.602035999298096,8.239818572998047,8.563863754272461,9.030357360839844,8.67562484741211,7.508957386016846,7.958723545074463,8.34891414642334,8.527894973754883,8.235547065734863,7.437575817108154,8.917375564575195,8.74227523803711,7.585366249084473,7.308308124542236,8.390066146850586,7.556387901306152],\"type\":\"scattergl\"},{\"hoverinfo\":\"text\",\"hovertext\":[\"Convert string representations of lists to actual lists\\nimport ast\\n\\ndf_script['raw_character_text'] = df_script['raw_character_text'].apply(ast.literal_eval)\\ndf_script['spoken_words'] = df_script['spoken_words'].apply(ast.literal_eval)\",\"Filter dialogues with at least one word comprised of alphabet characters\\ndf_script_filtered = df_script[df_script['raw_character_text'].str.isalpha()].reset_index(inplace=False, drop=True)\",\" Filter out non-speaking lines from df_script\\ndf_script = df_script[df_script.speaking_line].reset_index(drop=True)\",\"Preprocess script data\\ndf_script = df_script[df_script['speaking_line'] == True].reset_index(inplace=False, drop=True)\",\"Remove quotations around the speaker name in the script data\\ndf_script['character_id'] = df_script['character_id'].str.replace('\\\"', '')\\ndf_script['raw_character_text'] = df_script['raw_character_text'].str.replace('\\\"', '')\\ndf_script['spoken_words'] = df_script['spoken_words'].str.replace('\\\"', '')\",\"Create a dataframe with the necessary information to work (only the characters with speaking lines)\\ndf_script.loc[df_script['speaking_line'] == 'true'].reset_index(inplace=True, drop=True)\",\"Extract quotes from script\\nquotes = df_script[df_script['speaking_line'] == True][['character_id','raw_text']]\\n\\n# Extract quotes from script\\ncharacters = df_characters['name']\\n\\n# Extract locations from dataset\",\"Removing lines corresponding to non-dialogue actions from the script dataframe\",\"Remove rows with missing 'spoken_words' and 'raw_text' values\\ndf_script = df_script.dropna(subset=['spoken_words', 'raw_text'])\",\"Filter out lines which are not spoken by characters\\ndf_script = df_script.loc[df_script['speaking_line'] == True]\",\"Data preprocessing\\n# lowercase everything\\ndf_script['spoken_words'] = df_script['spoken_words'].str.lower()\",\"Remove lines where the speaking character id is not in the characters dataframe\",\"Concatenate the character name and speaking line into one string in a new column\\ndf_script['raw_text'] = df_script['raw_character_text'] + ': ' + df_script['spoken_words']\",\" Define the speaker for each line in the script\\ndf_script = df_script.merge(df_characters.rename(columns={'character_name': 'speaker'}), on='speaker_id')\",\"Filter out non-dialogue script lines, remove irrelevant columns, and save to CSV\\ndf_script = df_script[df_script['speaking_line'] == True].reset_index(inplace=False, drop=True)\",\"Filtering only the spoken lines and relevant columns\\ndf_script = df_script[(df_script['speaking_line'] == True) & (df_script['raw_character_text'].notna())]\\ndf_script = df_script[['raw_character_text', 'spoken_words', 'episode_id']]\\n\\n#Renaming columns for clarity\\ndf_script.columns = ['character', 'dialogue', 'episode_id']\",\" Keep only \\\"spoken_words\\\" and \\\"raw_text\\\" columns\\ndf_script = df_script[[\\\"spoken_words\\\", \\\"raw_text\\\"]]\",\"# Filter non-spoken lines and reset index\\ndf_script = df_script[df_script['speaking_line'] == True].reset_index(drop=True)\",\"Remove incomplete script lines from the dataframe\\ndf_script = df_script[(df_script['speaking_line'] == True) & (df_script['raw_location_text'].notnull())]\\ndf_script.reset_index(drop=True, inplace=True)\",\"Filter out the non-spoken lines from the dataset and save the result in a new dataframe of its own.\",\" Filter out rows from df_script that don't contain any spoken lines (i.e. rows where the speaking_line column is False)\\ndf_script = df_script[df_script[\\\"speaking_line\\\"] == True].reset_index(drop=True)\",\"Separate the columns containing the text data that we care about:\\ntext_columns = ['raw_character_text', 'spoken_words', 'raw_location_text', 'normalized_text']\",\"Add missing columns to fullfil the schema and fill the NaN records with empty strings\\ndf_script=df_script[df_script['normalized_text'].notna()]\\ndf_script=df_script[df_script['spoken_words'].notna()]\",\"Filter out the non-dialogue lines from the script dataframe\\ndf_script_dialogue = df_script[df_script['speaking_line'] == True]\",\"Clean data\\ndf_script = df_script[df_script[\\\"spoken_words\\\"].notna()]\",\"remove script lines without any text\\ndf_script = df_script.dropna(subset=['spoken_words'])\",\" Retain only the rows with non-null values in the speaking line column\\ndf_script_cleaned = df_script[df_script['speaking_line'].notnull()]\",\"Remove values where the speech is not defined, and episode is not defined\\ndf_script = df_script.replace({pd.np.nan: None})\\ndf_script = df_script[df_script.speech.str.len() \\u003e 0]\\ndf_script = df_script[df_script.episode_id.notnull()]\",\"Remove some unused columns\\ndf_script.drop(['spoken_words', 'raw_text', 'timestamp_in_ms', 'speaking_line'], axis=1, inplace=True)\",\"Convert non-numeric values to NaN\\ndf_script['spoken_words'] = df_script['spoken_words'].apply(lambda x: np.nan if isinstance(x, str) and not x.isdigit() else x)\",\"df_script = df_script[df_script['speaking_line'] == True].reset_index(drop=True)\",\"Remove rows with empty \\\"spoken_words\\\" in the script\\ndf_script = df_script.dropna(subset=['spoken_words'])\",\"Get it to the right encoding\\ndf_script = df_script.astype({\\\"index\\\": int, \\\"id\\\": int, \\\"number\\\": pd.Int64Dtype(),\\n                              \\\"raw_text\\\": str, \\\"timestamp_in_ms\\\": pd.Int64Dtype(), \\\"speaking_line\\\": bool, \\\"character_id\\\": pd.Int64Dtype(),\\n                              \\\"location_id\\\": pd.Int64Dtype(), \\\"raw_character_text\\\": str, \\\"raw_location_text\\\": str,\\n                              \\\"spoken_words\\\": str, \\\"normalized_text\\\": str, \\\"word_count\\\": pd.Int64Dtype()})\",\"Rename columns for consistency and readability\\ndf_script = df_script.rename(columns={'normalized_text': 'spoken_words',\\n                                      'raw_text': 'raw_spoken_words',\\n                                      'timestamp_in_ms': 'timestamp',\\n                                      'speaking_line': 'is_speaking_line',\\n                                      'character_id': 'raw_character_id',\\n                                      'location_id': 'raw_location_id'})\",\"Filter script to only keep spoken lines from characters\\nspoken_lines = df_script[(df_script['character_id'] != 2) & (df_script['character_id'].notnull())]\",\"Split rows in 'simpsons_script_lines' by newlines in 'normalized_text'\\ndf_script = df_script.assign(normalized_text=df_script['normalized_text'].str.split('\\\\n')).explode('normalized_text')\\n\\n# Remove ':' from speaker names\\ndf_script = df_script.assign(speaker=df_script['speaker'].str.replace(':', ''))\\n\\n# Keep only 'spoken_words' and speaker name\\ndf_script = df_script.assign(normalized_text=df_script['normalized_text'].str.split(':')).explode('normalized_text')\\n\\n# Remove leading\\u002ftrailing whitespaces from 'normalized_text'\\ndf_script = df_script.assign(normalized_text=df_script['normalized_text'].str.strip())\\n\\n# Remove rows with 'normalized_text' == ''\\ndf_script = df_script[df_script['normalized_text'] != '']\",\"Remove rows where the `spoken_words` column contains bad data\\ndf_script = df_script[df_script['spoken_words'].apply(lambda x: isinstance(x, str))]\",\" Drop rows in the data that are NaN in the speaking_line column\\ndf_script = df_script.dropna(subset=['speaking_line'])\",\"Format script data\\ndf_script = df_script[df_script['episode_id'] != 'special']\\ndf_script['raw_character_text'] = df_script['raw_character_text'].astype(str)\\ndf_script['spoken_words'] = df_script['spoken_words'].astype(str)\\ndf_script = df_script.dropna(subset=['raw_character_text'])\\ndf_script = df_script.dropna(subset=['spoken_words'])\",\"Filter out bad orders (for example when a main character doesn't talk)\\nprint('Rows before cleaning:', df_script.shape[0])\\ndf_script = df_script.loc[df_script['raw_character_text'].isin(df_characters['character_text'])]\\ndf_script = df_script[df_script['spoken_words'].str.len() \\u003e 0]\\nprint('Rows after cleaning:', df_script.shape[0])\",\"Select the character's dialogues for sentiment analysis\\nmoe_lines = df_script.loc[df_script[\\\"raw_character_text\\\"] == \\\"Moe Szyslak\\\"][\\\"spoken_words\\\"]\",\"Remove rows with NaN valued spoken_words (empty spoken_words)\\ndf_script = df_script.dropna(subset=['spoken_words'])\",\"Create a new column containing the normalized lemmatized version of the spoken lines\\ndf_script['spoken_lemmatized'] = df_script['normalized_text'].progress_apply(spacy_lemmatize)\",\"Remove empty quips (some lines have only a quip, or the quip is part of the dialog [1\\u002f3, 1\\u002f3])\\ndf_script = df_script.dropna(subset=['spoken_words'])\",\" Leave only lines\\ndf_lines = df_script[df_script['speaking_line']]\\ndf_lines = df_lines.merge(df_characters[['name', 'character_id']], on='character_id')\",\" Remove rows we don't need to minimize memory usage\\ndf_script.drop(['spoken_words', 'raw_text'], axis=1, inplace=True)\",\"Keep only the spoken lines\\ndf_script = df_script[df_script.speaking_line].reset_index(inplace=False, drop=True)\",\"Split the `text` column into multiple columns: \\ndf_script[['speaking_line', 'character_id', 'location_id', 'raw_text', 'timestamp_in_ms2', 'timestamp_in_ms', 'raw_character_text', 'raw_location_text', 'spoken_words', 'normalized_text']] = pd.DataFrame(df_script['text'].str.split(',',10).tolist())\",\" Clean script dataframe\\ndf_script = df_script[pd.notnull(df_script['normalized_text'])]\\ndf_script = df_script[pd.notnull(df_script['character_id'])]\\ndf_script = df_script[df_script['speaking_line'] == True]\\ndf_script = df_script[df_script['normalized_text'] != '(END OF PREVIEW)']\",\" The lines correspond to XML codes, so we remove them using only the columns related to single lines of speech, and we fill NaN with an empty string\\nlines = df_script[['character_id', 'location_id', 'spoken_words']].fillna('')\\nlines.head()\",\"Removing unnecessary columns in df_script\\ndf_script = df_script.drop(['date', 'timestamp_in_ms', 'speaking_line', 'raw_text', 'normalized_text', 'word_count'], axis=1)\",\"Creating a new column containing the tokenized version of the 'spoken_words' column.\",\" Create a new dataframe with only the parts of the script that are spoken by a character (not scene headings, etc.)\\ndf_script_lines = df_script[df_script.raw_text.str.contains(\\\"[A-Za-z0-9]+:\\\")]\\ndf_script_lines.reset_index(drop=True, inplace=True)\",\"Removing all non speaking_lines\\nspeaking_lines = df_script[df_script.speaking_line]\\nspeaking_lines_idxs = speaking_lines.line_id\\n\\n#cleaning the strings for speakers and raw_texts\\nspeaking_lines.raw_text = speaking_lines.raw_text.str.replace('\\\\r', ' ')\\nspeaking_lines.raw_text = speaking_lines.raw_text.str.replace('\\\\n', ' ')\\nspeaking_lines.character_id = speaking_lines.character_id.str.replace('^\\\\s+', '', regex=True)\",\"Filtering the script dataframe to only include spoken lines (i.e., not stage directions or observations)\",\"Remove rows with NaN in \\\"raw_character_text\\\" or \\\"spoken_words\\\" columns\\ndf_script = df_script.dropna(subset=['raw_character_text', 'spoken_words']).reset_index(drop=True)\",\"Remove punctuation and numbers from lines for each character\\n#df_script = df_script.sample(frac=0.1, replace=True, random_state=1) # Uncomment this line to test your code with only a fraction of the data\\ndf_script['spoken_words'] = df_script['spoken_words'].str.replace('[^A-Za-z\\\\s\\\\']','')\\ndf_script['spoken_words'] = df_script['spoken_words'].str.replace('\\\\d+','')\",\" Clean text and add a column with the lengths of the sequences\\ndf_script['spoken_words'] = df_script['spoken_words'].str.replace('\\\\r', ' ')\\ndf_script['spoken_words'] = df_script['spoken_words'].str.replace('\\\\n', ' ')\\ndf_script['spoken_words'] = df_script['spoken_words'].str.replace('\\u003cb\\u003e', ' ')\\ndf_script['spoken_words'] = df_script['spoken_words'].str.replace('\\u003c\\u002fb\\u003e', ' ')\\ndf_script['spoken_words'] = df_script['spoken_words'].str.replace('\\u003ci\\u003e', ' ')\\ndf_script['spoken_words'] = df_script['spoken_words'].str.replace('\\u003c\\u002fi\\u003e', ' ')\\ndf_script['spoken_words'] = df_script['spoken_words'].str.replace('\\u003cu\\u003e', ' ')\\ndf_script['spoken_words'] = df_script['spoken_words'].str.replace('\\u003c\\u002fu\\u003e', ' ')\\ndf_script['spoken_words'] = df_script['spoken_words'].str.replace('\\u003cbr \\u002f\\u003e', ' ')\",\"Remove all non speaking_lines from script\\ndf_script = df_script[df_script['speaking_line'] == True]\",\"Clean empty utterances\\ndf_script = df_script.dropna(subset=['raw_character_text', 'spoken_words'])\",\"Change types for memory optimization\\ndf_script['normalized_text'] = df_script['normalized_text'].astype('str')\\ndf_script['spoken_words'] = df_script['spoken_words'].astype('str')\\ndf_script['raw_text'] = df_script['raw_text'].astype('str')\\ndf_script['timestamp_in_ms'] = df_script['timestamp_in_ms'].astype('float32')\",\"Set NaN values to empty strings in character_name, raw_location_text, and spoken_words.\\ndf_script['character_name'] = df_script['character_name'].fillna('')\\ndf_script['raw_location_text'] = df_script['raw_location_text'].fillna('')\\ndf_script['spoken_words'] = df_script['spoken_words'].fillna('')\",\" Split the 'raw_text' speech into a list of quotes of parts of 7 types.\",\"Limit the script to only include spoken words by characters\\ndf_script = df_script[df_script['speaking_line'] == True]\",\" Replace NaN\\ndf_script.loc[:, 'speaking_line'] = df_script['speaking_line'].fillna(False).astype(bool)\\ndf_script.loc[:, 'character_id'] = pd.to_numeric(df_script['character_id'], downcast='integer', errors='coerce')\\ndf_script.loc[:, 'location_id'] = pd.to_numeric(df_script['location_id'], downcast='integer', errors='coerce')\",\"\\n# Drop incomplete data\\ndf_script = df_script.dropna(subset=['normalized_text'])\\n\\n# Perform a left join to add the character names to the script data\\n# Drop the character_id column\\n# Fill NaN values from the speaking_line column with False\\ndf_joined = df_script.merge(df_characters, on='id', how='left').drop(columns=['character_id']).fillna(value={'speaking_line': False})\\n\\n# Remove non-speaking script lines\\ndf_speaking = df_joined[df_joined['speaking_line']].copy()\",\"Remove non-UTF-8 characters from the \\\"raw_character_text\\\" and \\\"spoken_words\\\" columns\\ndf_script['raw_character_text'] = df_script['raw_character_text'].apply(lambda x: x.encode('utf-8', 'ignore').decode('utf-8'))\\ndf_script['spoken_words'] = df_script['spoken_words'].apply(lambda x: x.encode('utf-8', 'ignore').decode('utf-8'))\",\" Remove all non-spoken lines\\ndf_script = df_script[df_script.speaking_line == True]\",\"Create a new column with the lowercased lines\\ndf_script['spoken_words_lower'] = df_script['spoken_words'].str.lower()\",\"Filter out non-dialogue lines from the script data\\ndf_script_dialogue = df_script[(df_script[\\\"speaking_line\\\"] == True) & (df_script[\\\"character_id\\\"].notnull())].reset_index(inplace=False, drop=True)\",\"drop the location quote, raw_location_text, raw_character_text\\n# drop normalized text\\n# drop has spoken\\n# drop timestamp_in_ms\\n# drop starts_with_quote\\ndf_script.drop(columns=['location_quote', 'raw_location_text', 'raw_character_text', \\n                        'normalized_text', 'spoken_words', \\n                        'timestamp_in_ms', 'start_with_quote'], inplace=True)\",\" preprocessing the script\\ndf_script = df_script[(df_script['speaking_line'] == True)]\",\"Combine name and normalized_text columns\\ndf_script['speaking'] = df_script['raw_text']\\ndf_script['speaking'] = df_script['speaking'].fillna(df_script['normalized_text'])\\n\\n# Get first words of each script and lowercase them\\ndf_script['first_word'] = df_script['speaking'].apply(lambda x: x.strip().lower().split(' ')[0])\",\"Keep only the communication lines from the script dataframe\\ndf_script_lines = df_script[df_script['speaking_line'] == True]\\ndf_script_lines.reset_index(inplace=True, drop=True)\",\"Only keep dialog\\ndf_script = df_script[df_script['speaking_line'] == True]\\n\\ndf_script.head()\",\"Remove all the non speaking lines from the script data frame\\ndf_script = df_script[df_script.speaking_line == True].copy()\",\" Replace nans in spoken_words with \\\"\\\"\\ndf_script['raw_character_text'] = df_script['raw_character_text'].fillna(\\\"\\\")\\ndf_script['spoken_words'] = df_script['spoken_words'].fillna(\\\"\\\")\",\"Creating a new DataFrame containing only the raw text of the script lines, and the character that spoke them.\\ndf_conversations = df_script[['raw_text', 'character_id']]\\ndf_conversations = df_conversations.dropna()\\ndf_conversations.reset_index(inplace=True, drop=True)\\n\\n# The character_id is of float type; converting it to int for compatibility with spacy's EntityRuler\\ndf_conversations['character_id'] = df_conversations['character_id'].astype('int')\",\"Preprocess data\\ndf_script = df_script[df_script['timestamp_in_ms'] \\u003c 6.0e+10]  # Filter out bad data\\ndf_script = df_script[(df_script['character_id'] != 2) &  # Remove speaker 'None'\\n                      (df_script['character_id'] != 1)]\",\"Filter by spoken words\\ndf_script_lines = df_script[df_script['speaking_line'] == True]\",\"Drop conversations with just a single speaker\\ndf_script = df_script[df_script['number'] != 'unassigned']\",\"Fix some properties with the types they should have\\ndf_script['timestamp_in_ms'] = df_script['timestamp_in_ms'].replace(np.nan, 0).astype('int64')\\ndf_script['raw_text'] = df_script['raw_text'].replace(np.nan, '')\\ndf_script['speaking_line'] = df_script['speaking_line'].astype(bool)\\ndf_script['character_id'] = df_script['character_id'].replace(np.nan, -1).astype('int32')\\ndf_script['location_id'] = df_script['location_id'].replace(np.nan, -1).astype('int32')\",\"Remove speech lines that do not contain any actual text in them.\\ndf_script = df_script[df_script.raw_text.str.replace(' ', '') != '']\\ndf_script = df_script[df_script.raw_text.str.replace(' ', '') != '...']\",\"Remove any rows that have NaN values for the character speaking or the dialogue.\",\" Puts everything to lower case\\ndf_script_normalized = df_script\\ndf_script_normalized['raw_character_text'] = df_script_normalized['raw_character_text'].str.lower()\\ndf_script_normalized['raw_location_text'] = df_script_normalized['raw_location_text'].str.lower()\\ndf_script_normalized['spoken_words'] = df_script_normalized['spoken_words'].str.lower()\",\"Remove other voice and change NaN values to Unknown and a unknown values\\ndf_script = df_script[(df_script[\\\"raw_text\\\"].str.startswith('(') == False)]\\ndf_script = df_script.fillna('Unknown')\\ndf_script = df_script[df_script['spoken_words'] != 'Unknown']\",\"Add a new column to script dataframe that stores if the line is spoken by a character or not\",\"Filter out bad data\\ndf_script = df_script[\\n    (df_script.speaking_line == True) & \\n    (df_script.character_id != 2) & \\n    (df_script.character_id != 1)\\n]\",\" Clean 'speaking line' column in df_script\\ndf_script = df_script.dropna(subset=['speaking_line'])\",\" Create a column for character names in the script dataframe\\ndf_script = df_script[df_script['speaking_line'] == True]  # Keep only rows with a speaking line\\ndf_script = df_script.merge(df_characters, left_on='character_id', right_on='id', suffixes=('','_original'))  # Join the character names\",\" Filter out characters who have spoken too few lines\\nMIN_LINES = 500\\ncharacter_lines = df_script.groupby('character_id').size()\\nvalid_characters = character_lines[character_lines \\u003e MIN_LINES].index.tolist()\\ndf_script = df_script[df_script['character_id'].isin(valid_characters)]\",\"Limit to main character speeches.\\ndf_script = df_script[df_script['speaking_line']]\",\"# Preprocessing of the script\\n\\n# Remove the missing values\\ndf_script = df_script.loc[~df_script['raw_text'].isna()]\\n\\n# Create a dictionary having as key the raw character text and as value the characters' unique identifier\\ncharacters_dict = {name:(uid,lines) for uid,name,lines in zip(df_characters['character_id'],df_characters['raw_character_text'], df_characters['spoken_words'])}\",\"Conversion of the columns that contain json format to actual python objects\\nimport json\\n\\ndf_characters['character_image_url'] = df_characters['character_image_url'].apply(lambda x: json.loads(x))\\ndf_script['spoken_words'] = df_script['spoken_words'].apply(lambda x: json.loads(x))\",\"Create a new column `text_len` that contains the length of `spoken_words` if not `NaN`, and 0 if `NaN`\",\" Add column of lowercase words to the dataframe\",\"reate a new column containing the processed text from the spoken words in the script\\ndf_script['processed_text'] = df_script['spoken_words'].apply(lambda x: nlp(x).text)\",\" Filter only \\\"spoken_lines\\\"\\ndf_script = df_script[df_script[\\\"speaking_line\\\"] == \\\"true\\\"].reset_index(inplace=False, drop=True)\",\"Strip quotes around 'raw_location_text' and 'spoken_words' columns\\ndf_script['raw_location_text'] = df_script['raw_location_text'].str.strip('\\\\'')\\ndf_script['spoken_words'] = df_script['spoken_words'].str.strip('\\\\'')\",\"Filter the script data to only include spoken lines from the characters dataframe.\",\"Filter out rows with empty or NaN values for the spoken_words attribute of the script.\\ndf_script = df_script.dropna(subset=['spoken_words']).reset_index(drop=True)\",\"Drop useless data\\ndf_script = df_script.drop(['index', 'raw_text', 'timestamp_in_ms',\\n                            'speaking_line', 'character_id', 'location_id',\\n                            'raw_character_text', 'raw_location_text',\\n                            'spoken_words'], axis=1)\",\"\\n# We only need raw lines from the script\\ndf_script = df_script[df_script.speaking_line]\",\"Clean the character list by removing non-speaker tokens\\ndf_characters = df_characters[~df_characters['normalized_text'].isin(['string', 'music', 'singing', 'gasps'])]\",\"# Time to process the data and to create a word cloud\\n# Filling up the NaN values with empty string\\ndf_script = df_script.fillna('')\\n# Concatenating the string fields of the data frame\\ndf_script['spoken_words_concat'] = df_script['raw_text'] + ' ' + df_script['normalized_text'] + ' ' + df_script['spoken_words']\",\"Create a subset of df_script that contains only spoken lines\",\"Create a subset of the script lines dataframe containing only the spoken lines\",\"Visualize the word cloud for the character speaking lines\\nspeaking_lines = df_script.query('speaking_line').reset_index(inplace=False, drop=True)\",\" Step 1: get rid of row copies and script lines with no speaker\\ndf_script_cleaned = df_script.drop_duplicates('id').dropna(subset=['raw_character_text']).copy()\",\"Filtering bad lines from dataset\\ndf_script = df_script[df_script['raw_character_text'].notna()]\\ndf_script = df_script[df_script['spoken_words'].notna()]\",\" Filter the dataframe to only keep the dialogue lines\",\"# Filter the dataframe to only include spoken lines\\ndf_script = df_script.loc[df_script['speaking_line'] == True].reset_index(inplace=False, drop=True)\"],\"marker\":{\"opacity\":0.5,\"size\":5},\"mode\":\"markers+text\",\"name\":\"3_Filtering spoken lines in a script\",\"text\":[\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\"],\"textfont\":{\"size\":12},\"x\":[6.951513767242432,7.540623188018799,7.862682819366455,7.770017623901367,6.707935810089111,7.706734657287598,7.191412925720215,8.850935935974121,6.874111175537109,7.641334056854248,7.074404239654541,7.728283882141113,6.960896968841553,5.223922252655029,7.837873935699463,7.018056392669678,7.179396629333496,8.435833930969238,7.296988487243652,8.75683879852295,7.777910232543945,6.865845680236816,7.4142022132873535,8.204584121704102,7.448496341705322,7.563302516937256,7.988470077514648,7.775925159454346,6.40854549407959,7.843818664550781,7.814726829528809,7.260875225067139,6.347246170043945,5.3516154289245605,7.18380880355835,6.457245349884033,7.415591239929199,6.969455242156982,6.384449481964111,7.322526454925537,8.433941841125488,7.58595085144043,8.384770393371582,7.472893238067627,5.6782965660095215,6.850972652435303,7.898927688598633,6.417154788970947,6.744505405426025,7.309834957122803,6.1234917640686035,8.073954582214355,7.574974536895752,7.582127094268799,8.583955764770508,7.443422317504883,7.184147357940674,7.733220100402832,7.963451862335205,7.400906085968018,6.669787883758545,7.104680061340332,7.287355899810791,7.780863285064697,6.2503509521484375,6.287435054779053,7.166626453399658,7.977430820465088,6.614352226257324,7.595945835113525,6.477985858917236,8.291964530944824,6.881875038146973,8.012624740600586,8.293919563293457,8.04539966583252,7.5634660720825195,7.0345282554626465,6.348080635070801,7.915236473083496,7.355595588684082,5.612100124359131,7.433740139007568,7.75157356262207,6.361169815063477,7.495101451873779,7.737921714782715,6.7994914054870605,7.534012317657471,6.133223056793213,6.976091384887695,8.092047691345215,7.009830474853516,7.256092548370361,8.089017868041992,6.673022747039795,7.753057956695557,7.841264247894287,6.801806449890137,8.391619682312012,7.358166694641113,5.961685657501221,8.386686325073242,6.849026679992676,7.73240327835083,8.107335090637207,8.382732391357422,8.207883834838867,6.567450046539307,7.664074420928955,8.13157844543457,8.12453556060791],\"y\":[7.309611797332764,7.40595006942749,7.598295211791992,7.599244117736816,7.260274887084961,7.701949119567871,7.389972686767578,6.119206428527832,6.580785274505615,7.135993003845215,7.038605213165283,6.856007099151611,7.5006937980651855,7.8598504066467285,6.296539306640625,7.1513872146606445,7.51985502243042,7.1654181480407715,7.244394779205322,6.356816291809082,6.915022850036621,7.252382278442383,6.526957988739014,6.533389091491699,6.511114120483398,6.519649505615234,6.917366981506348,6.808520317077637,6.165040016174316,6.7578816413879395,7.553906440734863,6.394031524658203,6.643405437469482,7.55551815032959,7.243993282318115,7.658410549163818,6.791310787200928,6.118448734283447,7.195930480957031,7.185969829559326,6.927903652191162,6.164511203765869,7.192800998687744,6.52990198135376,8.256677627563477,5.728158950805664,7.4052581787109375,6.973659992218018,7.530275344848633,6.651299953460693,5.3702616691589355,7.2639923095703125,6.994816303253174,7.460965156555176,6.320319652557373,6.2031145095825195,7.619523525238037,8.061982154846191,7.049526691436768,6.8156867027282715,5.899035930633545,6.394207000732422,7.740840435028076,6.943713665008545,6.487060546875,6.966322898864746,7.0253448486328125,7.109091281890869,7.432048320770264,6.615283966064453,6.430569171905518,7.203681468963623,7.6280694007873535,7.268378257751465,6.667003631591797,6.799617290496826,6.431576251983643,6.483473300933838,6.623016834259033,6.6835761070251465,6.673593521118164,6.5498552322387695,7.3554534912109375,5.807519912719727,7.383232593536377,6.402139663696289,6.602957725524902,7.18218469619751,6.78364896774292,8.219013214111328,7.791864395141602,6.821949005126953,7.131806373596191,7.348407745361328,7.078943729400635,7.963542461395264,7.480313301086426,6.905272006988525,7.464641094207764,6.1729607582092285,6.356294631958008,5.958688735961914,7.256732940673828,7.528290748596191,6.9019575119018555,6.623274326324463,6.384822368621826,7.561202049255371,6.7310380935668945,6.858775615692139,5.656582355499268,7.06508731842041],\"type\":\"scattergl\"},{\"hoverinfo\":\"text\",\"hovertext\":[\"Check the content of Simpsons characters dataset\",\"Since the snippet is incomplete, It cannot be executed. Therefore, I will provide an explanation regarding the code.\\nThe code snippet provided contains the import statements for the required libraries along with the custom imports.\\nIt also reads csv files for Simpsons characters, locations, script lines, and episodes into pandas dataframes.\",\"Exploring the Simpsons dataset\",\"Now that we have imported the required libraries and loaded the datasets, we can start exploring and analyzing the data to gain insights into \\\"The Simpsons\\\" TV show.\",\"First we are importing typical Python libraries such as os, pandas, numpy, spacy, matplotlib, etc. Then we are importing some specific functions and libraries we will use in the script. After the imports, we are reading CSV files using pandas and creating DataFrames for characters, locations, script lines, and episodes from The Simpsons dataset.\",\"Check the content of the file 'simpsons_characters.csv'\",\"df_characters, df_locations, df_script, and df_episodes are DataFrames containing characters, locations, script lines, and episodes data from the Simpsons show.\",\"Check the content of the \\\"Simpsons Characters\\\" dataset\",\"Show what the Simpsons characters data looks like\",\"We open the datasets containing the Simpsons script lines, characters, locations, and episodes using pandas, and reset the index.\",\"Extract the name of the characters, location of the scenes and name of the episodes of the Simpsons dataframe\",\" Information of the dataframe related to the Simpsons series\",\"Display types and size of dataframes for the Simpsons data.\",\"This code snippet imports necessary libraries and reads in data from CSV files using pandas. The data includes information about characters, locations, script lines, and episodes from The Simpsons TV show.\",\"Visualisation of the Simpsons dataset\",\" Now the Simpsons dataset is loaded and ready for analysis.\",\"A subset of the Simpson dataset of interest for our text analysis is extracted. The chosen dataset includes the following tables: script lines, episodes, characters, and locations.\",\"Since the filenames for the datasets are 'simpsons_characters.csv', 'simpsons_locations.csv', 'simpsons_script_lines.csv', and 'simpsons_episodes.csv' it can be inferred that the datasets contain information about characters, locations, script lines, and episodes from the show \\\"The Simpsons.\\\"\",\"Data from `simpsons_script_lines.csv` will be used since that's where the text data is located.\",\"First, the necessary Python packages are imported. These include standard packages such as `os`, `pandas`, `numpy`, `spacy`, and `matplotlib`, as well as custom packages such as `tqdm` and `Counter`. The `%matplotlib inline` command is also used to ensure that `matplotlib` works correctly with Jupyter.\\nThen, four datasets (`df_characters`, `df_locations`, `df_script`, and `df_episodes`) are read from CSV files using `pd.read_csv` and stored in Pandas DataFrames. These datasets contain information about characters, locations, script lines, and episodes from The Simpsons TV show, and will be used for analysis and visualization.\",\" Filter 1 of 1: Imaginationland\\n# Due to the lack of imagination in this dataset, the following TV Series will be used\\n# The Simpsons\\ntv_series = 'the simpsons'\",\" Creating a single dataframe from the simpsons lines and episodes dataframes\",\"Join the \\\"simpsons_script_lines\\\" with \\\"simpsons_episodes\\\" to extend our dataset.\",\"some of the first attributes come from this explanation https:\\u002f\\u002fwww.kaggle.com\\u002fpierremegret\\u002fdialogue-lines-of-the-simpsons#simpsons_script_lines.csv\",\"Merging of Simpsons data into one single dataframe\",\" Let's take a quick look at the Simpsons script data.\",\"source: https:\\u002f\\u002fwww.kaggle.com\\u002fpierremegret\\u002fdialogue-lines-of-the-simpsons?select=simpsons_script.csv\",\"Inspect the contents of the 'simpsons_characters.csv' file\",\"To avoid encoding issues, we'll specify the encoding as ISO-8859-1 when reading the Simpsons script lines.\",\"The purpose of this code is to import the required datasets using pandas for analysis of the Simpsons scripts. The data is loaded from CSV files using the `pd.read_csv` function and is stored in pandas dataframes `df_characters`, `df_locations`, `df_script`, and `df_episodes`. These dataframes will be used for further analysis and visualization of the Simpsons script data.\",\"We will use the 'simpsons_script_lines.csv' file to analyze the script lines.\",\"Unable to access the Simpsons dataset for character, location, script, and episodes.\",\"This is an example of loading CSV data into pandas dataframes in Python. The dataframes are named df_characters, df_locations, df_script, and df_episodes. The dataframes will hold the data from the CSV files 'simpsons_characters.csv', 'simpsons_locations.csv', 'simpsons_script_lines.csv', and 'simpsons_episodes.csv', respectively.\",\"Create a new column 'raw_character_text' in the df_script dataframe to store the raw text from the Simpsons script.\",\"All the CSV files need to be found or imported in order to load the Simpsons dataset.\",\" By importing data, we can access the datasets and start working with the Simpson's script.\",\" The script initially loads necessary libraries and datasets to begin the analysis. This includes pandas, numpy, spacy, matplotlib, and the WordCloud library for visualization. It also loads the custom imports tqdm and Counter. The script then loads several datasets such as simpsons_characters, simpsons_locations, simpsons_script_lines, and simpsons_episodes using pandas and assigns them to dataframes df_characters, df_locations, df_script, and df_episodes, respectively.\",\"First, we begin by loading all the necessary data from CSV files using pandas. The data consists of information about Simpsons characters, locations, script lines, and episodes.\",\" Visualisation of character's prevalence in the Simpson corpus\",\"First, we import the required libraries and then load the Simpsons dataset using pandas. The dataset contains information about characters, locations, script lines, and episodes from the Simpsons TV show.\",\"Load and prepare the Simpsons dataset\",\"This code snippet shows the necessary imports and data loading for a data analysis project on Simpsons TV show. The code uses pandas to load CSV files into dataframes and then performs some initial data processing.\",\"Further code will interact with the datasets loaded in the previous step to extract insights or perform analysis on The Simpsons script data.\",\"Extract data for The Simpsons TV show\",\"Assume we want to analyze the script data of the Simpsons. We can start by inspecting the first few rows of the dataset.\",\"Our dataset consists of four DataFrames:\\n\\n#   df_characters: information about the characters in The Simpsons\\n#   df_locations: information about the locations in The Simpsons\\n#   df_script: the script of each line in The Simpsons\\n#   df_episodes: information about the episodes in The Simpsons\",\"Load the 'simpsons_script_lines.csv', 'simpsons_episodes.csv', 'simpsons_characters.csv', and 'simpsons_locations.csv' files into pandas dataframes.\",\"A sample of the 'simpsons_script_lines' dataset\\ndf_script.sample(5)\",\"Place code to further analyze the Simpsons dataset here.\",\"Checking simpsons_characters data\",\"Basic exploration of 'Simpsons' dataset\",\"Check the content of Simpsons characters.\",\"The simpsons_characters.csv, simpsons_locations.csv, and simpsons_episodes.csv files contain the metadata for characters, locations, and episodes, respectively.\",\"Visualizing the Simpsons script data\",\"Visualizations of characters, locations and places in the Simpsons series\",\"We will focus only on the \\\"Simpsons script lines\\\" file for this analysis.\",\" We are importing necessary libraries and datasets to preprocess the Simpson script lines.\",\"This code snippet imports the necessary libraries and datasets for the subsequent analysis of Simpson's script data.\",\"Let's start by taking a look at the data from the 'simpsons_characters.csv' file.\",\"Combining the data from simpsons_script_lines with the text data to make the analysis easier.\",\"Display the dataframe about characters in the Simpsons\",\" What is the structured data in the `simpsons_characters.csv`, `simpsons_locations.csv`, `simpsons_script_lines.csv`, and `simpsons_episodes.csv` files?\",\"We will start with the data exploration of the 'simpsons_script_lines.csv' file.\",\"Inspect the Simpsons script data to get an idea of its structure and the information available.\",\"Insight Data Science: Simplifying Script Flows for The Simpsons.\",\"This line of code reads various CSV files containing Simpsons data and stores them in separate dataframes for characters, locations, script lines, and episodes.\",\"Look at the structure of the Simpsons dataset\",\"taken from https:\\u002f\\u002fwww.kaggle.com\\u002fpierremegret\\u002fdialogue-lines-of-the-simpsons\\n# Some descriptions of the individual dataframes can be found there.\",\"Viewing first 10 records of Simpsons Characters data\",\"Importing the necessary libraries for the analysis of data from \\\"The Simpsons\\\" TV show, including spacy, pandas, numpy, and wordcloud. Also, custom imports like tqdm and Counter for additional functionalities.\",\"The Simpsons Script Analysis for Business Insights and Data Analysis\",\"Some initial instructions and library imports for data analysis with The Simpsons dataset.\",\"Data description:\\n# - df_characters: information about the characters in the Simpsons series\\n# - df_locations: information about the locations where the series takes place\\n# - df_script: the script lines for each episode\\n# - df_episodes: information about each episode\",\"Assuming you have the following workspace\\ndata\\n\\u251c\\u2500\\u2500 simpsons_characters.csv\\n\\u251c\\u2500\\u2500 simpsons_episodes.csv\\n\\u251c\\u2500\\u2500 simpson_locations.csv\\n\\u251c\\u2500\\u2500 simpsons_script_lines.csv\",\"Merge the dataframes to get a comprehensive view of the Simpsons dataset\",\"Insightful Data Analysis to Understand the Simpsons Dataset and Character Interactions\",\"Script lines are too big for the upload to GitHub, but you can find it here:\\n# https:\\u002f\\u002fwww.kaggle.com\\u002fambarish\\u002fsimpsons-script-lines#simpsons_script_lines.csv\",\"Get an overview of the Simpsons characters dataframe\\nprint(\\\"Number of lines in the dataframe: \\\" + str(len(df_characters)), \\\"\\\\n\\\")\\nprint(df_characters.head(), \\\"\\\\n\\\")\\nprint(df_characters.info())\",\"\\n# %%bash\\n# head -n 3 simpsons_characters.csv\",\"Out-of-the-box excerpted from the summary\\n# These scripts are licenced by simpsons_dataset, grouped by season. It contains up to 27 seasons,\\n# dated to november 2015, which stands for the 596th episode of this dataset. The author tries to \\n# keep contrack for the future.\",\" Defining the problem\\n\\n# We're given a dataset of Simpson's scripts and we want to use natural language processing (NLP) techniques to better understand the show.\",\"Selecting \\\"The Simpsons\\\" TV show from the dataset\",\"The Simpsons dataset files have been read into pandas DataFrames.\",\" Integration of data related to 'the simpsons' such as character, location, script lines and episodes into the notebook.\",\"Normalize `character_name` of `simpsons_script_lines.csv` and `normalized_name` of `simpsons_characters.csv` using spacy's `nlp` model.\",\"We have loaded the necessary libraries and datasets for our Simpsons script analysis. Now we can proceed with data exploration, cleaning, and analysis.\",\"Remove \\\"cc by-sa 2.0\\\" from the end of all the lines in simpsons_episodes.csv\\n# (this is bad practice, be careful in your own projects, kids!).\",\" Credits to https:\\u002f\\u002fwww.kaggle.com\\u002fpierremegret\\u002fdialogue-lines-of-the-simpsons\\n# to provide the data on kaggle.\",\"Add the Simpsons script in case the CSV is not available.\",\"Some data is imported to perform exploratory data analysis and natural language processing on a dataset related to \\\"The Simpsons\\\" TV show.\",\"For the purpose of this analysis, we are only going to use the gender column from the simpsons_characters.csv file.\",\"Display the data for simpsons characters dataframe\",\"Reading the datasets containing the characters, locations, script lines, and episodes of The Simpsons.\",\"Extract the characters who appear in each simpsons episode and create a new DataFrame\",\"The main principle of dividing data into different datasets is to make them more manageable and easier to work with. By loading the data of Simpsons characters, locations, script lines, and episodes into separate DataFrames, we can perform targeted analysis and explore specific relationships within the data. Additionally, it allows for modularity and reusability of these datasets, providing a more organized structure for data analysis and manipulation.\",\"Import our custom module\\nimport simpsons_helper as sh\"],\"marker\":{\"opacity\":0.5,\"size\":5},\"mode\":\"markers+text\",\"name\":\"4_Simpsons dataset analysis using pandas libraries\",\"text\":[\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\"],\"textfont\":{\"size\":12},\"x\":[11.301013946533203,12.328937530517578,11.017598152160645,11.69809627532959,12.2875337600708,11.599577903747559,0.581549882888794,11.141497611999512,11.035025596618652,10.620291709899902,10.543346405029297,10.427213668823242,10.907694816589355,11.814079284667969,11.170392036437988,12.015284538269043,11.73715877532959,11.871760368347168,12.04162311553955,11.982104301452637,9.813241004943848,9.002881050109863,10.950021743774414,10.879843711853027,5.6618781089782715,11.607093811035156,10.460119247436523,11.695028305053711,11.85226058959961,11.632658958435059,11.222116470336914,11.45344066619873,11.413673400878906,3.790959119796753,11.844389915466309,11.911407470703125,11.815396308898926,11.485107421875,11.411972999572754,11.61807918548584,11.269344329833984,11.66658878326416,11.753032684326172,10.79892635345459,12.01694107055664,1.0299361944198608,11.504616737365723,11.28415298461914,11.438226699829102,11.240635871887207,11.211967468261719,10.836522102355957,11.701249122619629,11.498544692993164,10.783944129943848,11.550298690795898,12.282332420349121,12.274751663208008,11.435113906860352,11.350208282470703,3.5528271198272705,11.832842826843262,11.886897087097168,11.37098503112793,12.096914291381836,11.737312316894531,11.398359298706055,10.566025733947754,10.84487533569336,12.03907585144043,12.003032684326172,11.764883995056152,1.4686936140060425,12.315834999084473,10.217318534851074,11.548359870910645,11.881778717041016,3.4791452884674072,11.568249702453613,10.95324993133545,12.242992401123047,10.305015563964844,11.100748062133789,11.805961608886719,11.694646835327148,12.19407844543457,12.179150581359863,11.193399429321289,11.926079750061035,12.230618476867676,10.836055755615234,3.2175092697143555,11.477194786071777,9.838827133178711,11.299336433410645,13.00791072845459],\"y\":[5.7965407371521,3.247194766998291,5.469411373138428,5.312641620635986,2.462355375289917,5.399518013000488,2.2668511867523193,5.631380558013916,6.08547306060791,3.5023953914642334,5.138286590576172,5.137758255004883,5.621704578399658,3.8948616981506348,6.09043025970459,5.495096206665039,5.076972961425781,4.505444049835205,4.34506893157959,3.354844570159912,5.510568618774414,4.620122909545898,4.716827392578125,4.761087417602539,-0.021217498928308487,5.527506351470947,4.72562837600708,5.010764122009277,5.457764148712158,3.7153007984161377,4.582827568054199,5.213770866394043,3.6160624027252197,12.206066131591797,4.965264797210693,4.635662078857422,2.965989589691162,4.438141822814941,6.1001105308532715,4.589591979980469,5.611458778381348,2.0128355026245117,4.86222505569458,5.4378275871276855,5.273794174194336,2.2655749320983887,3.9591245651245117,4.303502559661865,5.1861090660095215,5.9653706550598145,5.627059459686279,6.079490661621094,4.314457416534424,5.9522385597229,6.339332103729248,5.088093280792236,4.557661056518555,4.671807765960693,5.675485134124756,5.366286277770996,12.653094291687012,4.060325622558594,4.836733341217041,5.486179828643799,5.314712047576904,3.3188347816467285,5.847442626953125,5.099236965179443,5.462072849273682,3.578507423400879,5.409985542297363,4.817920207977295,2.409916639328003,4.280243396759033,4.8396687507629395,5.558800220489502,4.789802074432373,13.44072437286377,4.911479949951172,5.5705108642578125,4.6170654296875,5.367283821105957,4.423833847045898,5.148210525512695,5.235274791717529,5.049624443054199,5.138562202453613,5.186422824859619,5.087364196777344,4.736090183258057,6.4740891456604,12.837841033935547,5.3492350578308105,5.092177391052246,4.936570167541504,3.899529457092285],\"type\":\"scattergl\"},{\"hoverinfo\":\"text\",\"hovertext\":[\"Split location \\u002f raw_text.attrib_cleaned characters from script_lines\\ndf_loc_identifier_script = df_script\\\\\\n.merge(df_locations, left_on='location_id', right_on='id', suffixes=('_script', '_loc')).drop(columns=['id','normalized_name','image_url'])\\\\\\n.merge(df_characters, left_on='character_id', right_on='id', suffixes=('_loc', '_char')).drop(columns=['id','normalized_name','image_url'])\",\" Merge locations with script\\ndf_loc_script = pd.merge(\\n    df_script,\\n    df_locations,\\n    how=\\\"left\\\",\\n    left_on=\\\"location_id\\\",\\n    right_on=\\\"id\\\",\\n    suffixes=(\\\"-script\\\", \\\"-location\\\"),\\n)\\n\\nprint(f\\\"We lost {df_loc_script['id-location'].isnull().sum()} records that weren't in the locations dataframe\\\")\",\"Join Script Lines and Character Info\\nmerged_df = pd.merge(df_script, df_characters, left_on='character_id', right_on='id', suffixes=('_script', '_char'), how='left').fillna(value=np.nan)\\n\\n# Join Script Lines and Location Info\\nmerged_df = pd.merge(merged_df, df_locations, left_on='location_id', right_on='id', suffixes=('_script', '_loc'), how='left').fillna(value=np.nan)\",\"Merge the script with the relevant locations and characters\\ndf_script_loc_char = df_script.merge(df_locations[['location_id', 'name', 'normalized_name']], on='location_id', how='left')\\\\\\n.merge(df_characters[['character_id', 'name', 'normalized_name']], on='character_id', how='left')\",\"Merge the dataframes to add character information to the script lines\\ndf_script = df_script.merge(df_characters, on='character_id', suffixes=('', '_orig'))\\n# Merge the dataframes to add location information to the script lines\\ndf_script = df_script.merge(df_locations, on='location_id', suffixes=('', '_orig'))\",\"Merge script lines with character and locations data\\ndf_script_char = df_script.merge(df_characters, how='left', left_on='character_id', right_on='id')\",\" Merge names with main characters and locations\\ndf_script = pd.merge(df_script, df_characters,\\n                    how='left', left_on='character_id', right_on='id')\",\" Add column with the full name of the character and the location to the script lines dataframe\\ndf_script = (\\n    df_script\\n    .merge(df_characters[['id', 'name']], left_on='character_id', right_on='id', suffixes=(None, '_character'))\\n    .merge(df_locations[['id', 'name']], left_on='location_id', right_on='id', suffixes=(None, '_location'))\\n)\",\"Merge character & location into scripts dataframe\\ndf_script = df_script.merge(df_characters[['id', 'name']], left_on='character_id', right_on='id', suffixes=('', '_character'))\\ndf_script = df_script.merge(df_locations[['id', 'name']], left_on='location_id', right_on='id', suffixes=('', '_location'))\",\" Merge script lines with linking character and location information\\ndf_script_location = df_script.copy()\\ndf_script_location['character_id'] = df_script_location['character_id'].astype(str)\",\"Merge script lines, characters and locations\\ndf_merged = df_script.merge(df_characters, how='left', on='character_id')\",\"Merge script lines with the characters and locations\\ndf_merged = pd.merge(df_script, df_characters, left_on='character_id', right_on='character_id', suffixes=('_script', '_character'))\\ndf_merged = pd.merge(df_merged, df_locations, left_on='location_id', right_on='location_id', suffixes=('_df_merged', '_location'))\",\" Merge locations into script df\\ndf_script_locations = pd.merge(df_script, df_locations, how='left', left_on='location_id', right_on='id').drop(columns=['id', 'location_id']).rename(columns={\\\"name\\\": \\\"location\\\"})\",\"Merge character information into the main script DataFrame\\ndf_script = pd.merge(\\n    df_script, \\n    df_characters,\\n    how=\\\"left\\\",\\n    left_on=\\\"character_id\\\",\\n    right_on=\\\"id\\\"\\n)\\n\\n# Merge location info into the main script DataFrame\\ndf_script = pd.merge(\\n    df_script, \\n    df_locations,\\n    how=\\\"left\\\",\\n    left_on=\\\"location_id\\\",\\n    right_on=\\\"id\\\"\\n)\",\"Merge the characters and script dataframes\\ndf = pd.merge(df_characters, df_script, left_on='id', right_on='character_id', suffixes=('_characters', '_script'))\\ndf = pd.merge(df, df_locations, left_on='location_id', right_on='id', suffixes=('', '_locations'))\",\" Merge the script data with the character data\\ndf = df_script.merge(df_characters, on='character_id', how='left')\\ndf = df.merge(df_locations, on='location_id', how='left')\",\" Merge locations into script dataframe\\ndf_script = (\\n    df_script\\n    .merge(\\n        df_locations,\\n        how='left',\\n        left_on='raw_location_text',\\n        right_on='raw_location_text',\\n    )\\n    .rename(columns={'normalized_location':'location'})\\n    .drop(columns='timestamp_in_ms')\\n)\",\"Merge the scripts with the corresponding characters and locations\\ndf_character_script = df_characters.merge(df_script, on='character_id')\\ndf_merged = df_character_script.merge(df_locations, on='location_id')\",\"Join locations to scripts\\ndf_locations = df_locations.rename(columns={'id': 'location_id'})\",\"Merge location into script data frame\\ndf_script = df_script.merge(df_locations, left_on='raw_location_text', right_on='name', how='left').rename(columns={'normalized_name': 'location'})\",\" Merge characters and their location\\ndf_characters_location = pd.merge(df_characters, df_locations, how='left', left_on='location_id', right_on='id', suffixes=('character', 'location')).drop('idlocation', axis=1)\",\"Combine locations and scripts\\ndf_script_locations = df_script.merge(df_locations, left_on='location_id', right_on='id', suffixes=('_script', '_location'))\",\"Merge scripts with locations\\ndf_merged = pd.merge(df_script, df_locations, left_on='location_id', right_on='id', suffixes=('_script', '_location'))\\n\\n# See the data\\ndf_merged.head()\",\"Join the characters and locations to the script data\\ndf_script_characters = df_script.join(df_characters.set_index('character_id'), on='character_id', rsuffix='_character')\\ndf_script_locations = df_script_characters.join(df_locations.set_index('location_id'), on='location_id', rsuffix='_location')\",\"\\n# Merge the dialogue with the corresponding characters and location\\ndf_merged = df_script.merge(df_characters[['id', 'name']], left_on='character_id', right_on='id')\\ndf_merged = df_merged.rename(columns={'name': 'character_name'}).drop(columns='id')\\ndf_merged = df_merged.merge(df_locations[['id', 'name']], left_on='location_id', right_on='id')\\ndf_merged = df_merged.rename(columns={'name': 'location_name'}).drop(columns='id')\",\"Selecting only the lines in which the characters and locations exist\\ndf_script = df_script[df_script[\\\"normalized_text\\\"].notna()]\\ndf_script = df_script[df_script[\\\"location_id\\\"].notna()]\\n\\n# Left joining the script dataset with the character names and location names\\ndf_script = pd.merge(df_script, df_characters['name'], how='left', left_on=df_script['character_id'], right_index=True)\\ndf_script = df_script.rename(columns={'name': 'character_name'})\\n\\ndf_script = pd.merge(df_script, df_locations['name'], how='left', left_on=df_script['location_id'], right_index=True)\\ndf_script = df_script.rename(columns={'name': 'location_name'})\\n\\n# Dropping the location_id and character_id columns\\ndf_script = df_script.drop(columns=['location_id', 'character_id'])\",\" Merge characters and locations into the script dataframe\\ndf_script = pd.merge(df_script, df_characters, left_on='character_id', right_on='id', suffixes=('','_character')).drop(columns=['id','normalized_name']).reset_index(drop=True)\\ndf_script = pd.merge(df_script, df_locations, left_on='location_id', right_on='id', suffixes=('','_location')).drop(columns=['id']).reset_index(drop=True)\",\"Combine the script data with the character and location data per script line.\\ndf_script = (\\n    df_script\\n    .merge(df_characters, how='left', left_on='character_id', right_on='id', suffixes=(False, False))\\n    .merge(df_locations, how='left', left_on='location_id', right_on='id', suffixes=(False, False))\\n)\",\"Join scripts with characters and locations\\ndf_script = pd.merge(df_script, df_characters, how='left', left_on='character_id', right_on='id', suffixes=('', '_character'))\\ndf_script = pd.merge(df_script, df_locations, how='left', left_on='location_id', right_on='id', suffixes=('', '_location'))\",\"Merge script with characters and locations\\ndf_script = pd.merge(df_script,\\n                     df_characters,\\n                     left_on='character_id',\\n                     right_on='id',\\n                     suffixes=('_script', '_character'),\\n                     validate='many_to_one')\\n\\ndf_script = pd.merge(df_script,\\n                     df_locations,\\n                     left_on='location_id',\\n                     right_on='id',\\n                     suffixes=('_script', '_location'),\\n                     validate='many_to_one')\",\" Merge characters and locations into the script dataframe\\ndf_script = df_script.merge(df_characters, how='left', left_on='character_id', right_on='id', suffixes=(None, '_character'))\\ndf_script = df_script.merge(df_locations, how='left', left_on='location_id', right_on='id', suffixes=(None, '_location'))\",\" Merging the scripts with characters and locations datasets\\ndf_script = pd.merge(df_script, df_characters, left_on='character_id', right_on='id')\\ndf_script = df_script.rename(columns={'name': 'character_name'})\\ndf_script = pd.merge(df_script, df_locations, left_on='location_id', right_on='id')\\ndf_script = df_script.rename(columns={'name': 'location_name'})\",\"Merge character and location info into script data\\ndf_script = df_script.merge(df_characters, on='Character_ID', suffixes=('', '_y'))\\ndf_script = df_script.merge(df_locations, on='Location_ID', suffixes=('', '_y'))\",\" Merge with the location data to get the locations mentioned per line\\ndf_lines_with_locations = pd.merge(df_script, df_locations, how='left', left_on='location_id', right_on='id')\",\"Merge character and location quote lines\\ndf_char_loc = df_script[(df_script['character_id'] \\u003c= df_characters.shape[0]) & (df_script['location_id'] \\u003c= df_locations.shape[0])].reset_index(inplace=False, drop=True)\\ndf_char_loc[\\\"character\\\"] = df_char_loc['character_id'].map(df_characters['name'])\\ndf_char_loc[\\\"location\\\"] = df_char_loc['location_id'].map(df_locations['name'])\\n\\n# Verify the new DataFrame\\ndf_char_loc.head()\",\"Merge characters, locations and script\\ndf = df_script.merge(df_characters, left_on='character_id',\\n                     right_on='character_id', suffixes=('_script', '_character'))\\ndf = df.merge(df_locations, left_on='location_id', right_on='location_id', suffixes=('_script', '_location'))\",\"Creating master dataframe with character, location and line information\\ndf = pd.merge(df_script, df_characters, on='character_id', how='left')\\ndf = pd.merge(df, df_locations, on='location_id', how='left')\",\"Join characters and locations with scripts dataframes\\ndf_script_characters = pd.merge(df_script, df_characters, how='inner', left_on='character_id', right_on='id', suffixes=('_script', '_character'))\\ndf_script_locations = pd.merge(df_script, df_locations, how='inner', left_on='location_id', right_on='id')\",\"# Ensure all have the same name for character id column\\ndf_characters = df_characters.rename(columns={'id': 'character_id'})\\ndf_locations = df_locations.rename(columns={'id': 'location_id'})\",\"Merge locations and script_data\\nlocations_script = df_locations.rename(columns={\\\"id\\\": \\\"location_id\\\"}).merge(\\n    df_script.rename(columns={\\\"location_id\\\": \\\"script_location_id\\\"}),\\n    how='left',\\n    on='location_id'\\n)\",\"merged_df = df_script.merge(df_characters, on='raw_character_text', how = 'left')\\nmerged_df = merged_df.merge(df_locations, on='raw_location_text', how = 'left')\",\"Merge script with characters and locations\\ndf_all = pd.merge(df_script, df_characters, how='left', left_on='character_id', right_on='id')\\ndf_all = pd.merge(df_all, df_locations, how='left', left_on='location_id', right_on='id')\",\"Join script with characters and locations\\ndf_script_characters = pd.merge(\\n    df_script,\\n    df_characters,\\n    how='left',\\n    left_on=['raw_character_text'],\\n    right_on=['name']\\n)\\n\\ndf_script_locations = pd.merge(\\n    df_script,\\n    df_locations,\\n    how='left',\\n    left_on=['raw_location_text'],\\n    right_on=['name']\\n)\",\"Merge the dialog lines with the character and location tables\\ndf_ep_char_loc_lines = df_script.merge(\\n    df_characters,\\n    left_on='character_id',\\n    right_on='id',\\n    suffixes=('','_character')\\n).merge(\\n    df_locations,\\n    left_on='location_id',\\n    right_on='id',\\n    suffixes=('','_location')\\n)\\n\\ndf_ep_char_loc_lines.head()\",\" Merge characters and script\\ndf_characters_script = df_script.merge(df_characters, left_on='character_id', right_on='id')\\n\\n# Merge locations and script\\ndf_locations_script = df_script.merge(df_locations, left_on='location_id', right_on='id')\",\"Join script, characters and locations\\ndf_script_full = df_script\\\\\\n    .merge(\\n        df_characters,\\n        how='left',\\n        left_on='character_id',\\n        right_on='id'\\n    )\\\\\\n    .merge(\\n        df_locations,\\n        how='left',\\n        left_on='location_id',\\n        right_on='id'\\n    )\",\"# Combine location data into script data\\ndf_script_locations = df_script[\\n    df_script['raw_location_text'].notna() & df_script['location_id'].isna()\\n].merge(df_locations.add_prefix('loc_'), left_on='raw_location_text', right_on='loc_name', how='left').rename(columns={'loc_location_id': 'location_id'})\\n\\n# Update script data with location ids\\ndf_script = df_script.merge(df_script_locations[['id', 'location_id']], on='id', how='left').fillna({'location_id': -1})\",\"Merge characters in script\\ndf_script_characters = df_script.merge(df_characters, how='left', on='id', suffixes=('_script', '_character'))\\n\\n# Merge locations in script\\ndf_script_locations = df_script_characters.merge(df_locations, how='left', left_on='raw_location_text', right_on='raw_location_text', suffixes=('', '_location'))\",\"Merge the data into a single dataframe for analysis\\ndf_characters_SCRIPT = df_characters.rename(columns={'id':'character_id'}).merge(df_script.rename(columns={'character_id_id':'character_id'}), on='character_id')\\ndf_locations_SCRIPT = df_locations.rename(columns={'id':'location_id'}).merge(df_script.rename(columns={'location_id_id':'location_id'}), on='location_id')\",\"Merge character metadata\\ndf_characters_and_locations = pd.merge(\\n    df_characters,\\n    df_locations,\\n    how='outer',\\n    left_on='id',\\n    right_on='normalized_name'\\n)\",\" Merge script, characters, and locations\\ndf_all = pd.merge(df_script, df_characters, on='raw_character_text', how='left')\\ndf_all = pd.merge(df_all, df_locations, on='raw_location_text', how='left')\",\"Merge the script and the character datasets\\ndf_characters = df_characters.rename(columns=lambda x: \\\"character_\\\" + x)\\ndf_script = pd.merge(df_script, df_characters, left_on=\\\"character_id\\\", right_on=\\\"character_id\\\", how='left')\\n\\n# Merge the script and the location datasets\\ndf_locations = df_locations.rename(columns=lambda x: \\\"location_\\\" + x)\\ndf_script = pd.merge(df_script, df_locations, left_on=\\\"location_id\\\", right_on=\\\"location_id\\\", how='left')\",\"Merge the scripts dataframe with the character and location dataframes\\ndf_script_char = df_script.merge(df_characters, left_on='character_id', right_on='id', suffixes=('_script', '_char'))\\ndf_script_char_loc = df_script_char.merge(df_locations, left_on='location_id', right_on='id', suffixes=('_merge', '_loc'))\",\"Merge characters and locations to get character_speech\\ndf_char_loc = pd.merge(df_script, df_characters, how='left', left_on='raw_character_text', right_on='character_text')\\ndf_char_loc.rename(columns={'character_id': 'raw_character_id', 'name': 'raw_character_name'}, inplace=True)\\ndf_char_loc = pd.merge(df_char_loc, df_locations, how='left', left_on='raw_location_text', right_on='location_text')\\ndf_char_loc.rename(columns={'location_id': 'raw_location_id', 'name': 'raw_location_name'}, inplace=True)\",\"Merge character lines with character and location data\\ndf_merged = df_script.merge(df_characters, on='character_id', suffixes=('', '_char'))\\ndf_merged = df_merged.merge(df_locations, on='location_id', suffixes=('', '_loc'))\\n\\n# Print first few rows\\ndf_merged.head()\",\" Merge script with character info and its location\\ndf_script = df_script.merge(df_characters, how='inner', on='character_id')\\ndf_script = df_script.merge(df_locations, how='inner', on='location_id')\",\"combine the script with the character and location for each line\\ndf_script_full = (\\n    df_script\\n    .merge(df_characters, how='left', left_on='character_id', right_on='id', suffixes=('_script', '_character'))\\n    .merge(df_locations, how='left', left_on='location_id', right_on='id', suffixes=('_script', '_location'))\\n)\",\"Merge characters, locations and script together\\ndf_script = df_script.merge(df_characters, how='left', on='character_id')\\ndf_script = df_script.merge(df_locations, how='left', on='location_id')\",\"# Merge script and location with character information\\n# WARNING: this step can take a few minutes as it requires to process all the textual data\\ndf_merged = pd.merge(df_script,\\n                     df_characters,\\n                     how='left',\\n                     left_on='character_id',\\n                     right_on='id')\\n\\ndf_merged = pd.merge(df_merged,\\n                     df_locations,\\n                     how='left',\\n                     left_on='location_id',\\n                     right_on='id')\",\"Merge datasets to match lines with characters and locations\\ndf_joined_script = df_script.merge(df_characters, on='character_id', how='left')\\ndf_joined_script = df_joined_script.merge(df_locations, on='location_id', how='left')\",\"Harmonize character locations\\ndf_harmonized = df_script.merge(df_characters, left_on=\\\"character_id\\\", right_on=\\\"id\\\", suffixes=('_script', '_character'))\\ndf_harmonized = df_harmonized.merge(df_locations, left_on=\\\"location_id\\\", right_on=\\\"id\\\", suffixes=('_character', '_location'))\",\" Merging script with characters and locations\\ndf_script_chars = df_script.merge(df_characters, left_on='character_id', right_on='id', suffixes=('_script', '')).drop(columns='id')\\ndf_script_loca = df_script_chars.merge(df_locations, left_on='location_id', right_on='id', suffixes=('_script', '')).drop(columns='id')\",\"Merge script with characters and locations data\\ndf_script = df_script.merge(df_characters, left_on='character_id', right_on='id', suffixes=('', '_character'))\\ndf_script = df_script.merge(df_locations, left_on='location_id', right_on='id', suffixes=('', '_location'))\",\"Combine the script with the character names and locations\\ndf_script_ext = (\\n    df_script\\n    .merge(df_characters.rename(columns={\\\"id\\\": \\\"character_id\\\"}), on=\\\"character_id\\\")\\n    .merge(df_locations.rename(columns={\\\"id\\\": \\\"location_id\\\"}), on=\\\"location_id\\\")\\n)\",\"Create a new dataframe that merges lines and characters dataframes on character id, then merges result with locations dataframe on location id.\",\"Merge the script with the characters and locations\\ndf_script_characters = pd.merge(df_script, df_characters, left_on='character_id', right_on='id', suffixes=('_script', '_character')).drop(columns='id_character')\\ndf_script_characters_locations = pd.merge(df_script_characters, df_locations, left_on='location_id', right_on='id', suffixes=('_script', '_location')).drop(columns='id_location')\",\"Merge characters, locations and script\\ndf_merged = pd.merge(df_script, df_characters, left_on='character_id', right_on='id').merge(df_locations, left_on='location_id', right_on='id')\",\" merging characters and locations with the script lines\\ndf_script_lines_characters = df_script_lines.merge(df_characters, on='character_id')\\ndf_script_lines_characters_locations = df_script_lines_characters.merge(df_locations, on='location_id')\",\" Rename ID columns\\ndf_characters = df_characters.rename(columns={'id': 'character_id'})\\ndf_locations = df_locations.rename(columns={'id': 'location_id'})\",\"join locations and characters\\ndf_joined = df_locations.merge(\\n    df_characters,\\n    left_on='location_id',\\n    right_on='location_id',\\n    how='inner'\\n)\",\"Merge characters, locations and lines\\ndf = pd.merge(df_script, df_characters, left_on='character_id', right_on='character_id',  how='inner')\\ndf = pd.merge(df, df_locations, left_on='location_id', right_on='location_id', how='inner')\",\"Merge script and character dataframes\\ndf_script['character'] = df_script['character_id'].apply(lambda x: df_characters['name'][x])\\ndf_script['location'] = df_script['location_id'].apply(lambda x: df_locations['name'][x])\\ndf_script['raw_location_id'] = df_script['location_id']\\ndf_script['location_id'] = df_script['location']\",\"Merge script with character & location infos\\ndf_script_char = pd.merge(df_script, df_characters, how='inner', left_on=['character_id'], right_on=['id']).rename(columns={'name': 'character_name'}).drop(columns=['id'])\\ndf_script_char_loc = pd.merge(df_script_char, df_locations, how='left', left_on=['location_id'], right_on=['id']).rename(columns={'name': 'location_name'}).drop(columns=['id'])\",\"Merge the script with characters and locations\\ndf_script_chars_locations = pd.merge(df_script, df_characters, left_on='raw_character_text', right_on='character_name', how='left')\\n\\ndf_script_chars_locations = pd.merge(df_script_chars_locations, df_locations, left_on='raw_location_text', right_on='raw_location_text', how='left')\\n\\n# Verify the result\\ndf_script_chars_locations.head()\",\"Merge script data with character and location data\\ndf_script_full = (df_script.merge(df_characters[['id', 'normalized_name']], \\n                                  left_on='character_id', \\n                                  right_on='id', \\n                                  how='left')\\n                            .rename(columns={'normalized_name': 'character_name'})\\n                            .drop(columns='id')\\n                            .merge(df_locations[['id', 'normalized_name']], \\n                                   left_on='location_id', \\n                                   right_on='id', \\n                                   how='left')\\n                            .rename(columns={'normalized_name': 'location'})\\n                            .drop(columns='id')\\n                  )\\n\\ndf_script_full.head()\",\"Merge character and location to script\\ndf_script = df_script.merge(df_characters[['character_id', 'character_name']], \\n                            how='left', on='character_id')\\ndf_script = df_script.merge(df_locations[['location_id', 'location_name']], \\n                            how='left', on='location_id')\",\"merge script and location on\\n#location_id\\ndf_merged = pd.merge(df_script, df_locations, how='inner', on='location_id')\",\" Merge script data with corresponding character and location data\\ndf_script_character = df_script.merge(df_characters, on='character_id', how='left')\\ndf_script_location = df_script.merge(df_locations, on='location_id', how='left')\",\"Merge characters and locations with the main df_script DataFrame\\ndf_script['character'] = df_script['character_id'].map(df_characters.set_index('id')['name'])\\ndf_script['location'] = df_script['location_id'].map(df_locations.set_index('id')['name'])\",\"Merge the characters and locations dataframes to the script dataframe using the 'character_id' and 'location_id' columns respectively.\\ndf_script = df_script.merge(df_characters, on='character_id', how='left')\",\" Merge script with characters and locations names\\ndf = df_script.merge(df_characters[['id', 'name']], how='left', left_on='character_id', right_on='id')\\ndf = df.rename(columns={'name': 'character_name'}).drop('id', axis=1)\\ndf = df.merge(df_locations[['id', 'name']], how='left', left_on='location_id', right_on='id')\\ndf = df.rename(columns={'name': 'location_name'}).drop('id', axis=1)\",\"Merge locations and script\\ndf_locations_script = pd.merge(\\n    df_locations,\\n    df_script,\\n    left_on='id', \\n    right_on='location_id',\\n    suffixes=('_location', '_script')\\n).drop(['id', 'location_id'], axis=1)\",\"Merge with characters and locations names\\ndf_script = df_script.merge(df_characters[['id', 'name']], how='left', left_on='character_id', right_on='id', suffixes=('', '_c')).drop('id', axis=1)\\ndf_script = df_script.merge(df_locations[['id', 'name']], how='left', left_on='location_id', right_on='id', suffixes=('', '_l')).drop('id', axis=1)\",\"merge script, characters and locations tables\\ndf_script_char = pd.merge(df_script, df_characters, left_on='character_id', right_on='id', suffixes=('_script', '_char')).drop(columns='id')\\ndf_script_char_loc = pd.merge(df_script_char, df_locations, left_on='location_id', right_on='id', suffixes=('', '_loc')).drop(columns='id')\",\"Merge df_script with df_characters and df_locations\\ndf_script_characters_locations = pd.merge(\\n    pd.merge(df_script, df_characters, on='character_id', how='left'),\\n    df_locations,\\n    on='location_id',\\n    how='left'\\n)\",\"Merge the characters and locations into the main script dataframe\\ndf_script = pd.merge(df_script, df_characters, how='left',\\n                     left_on='character_id', right_on='id')\\ndf_script = pd.merge(df_script, df_locations, how='left',\\n                     left_on='location_id', right_on='id')\",\" merge the locations with the script lines\\ndf_locations = df_locations.rename(columns={\\\"id\\\": \\\"raw_location_id\\\"})\\ndf_script = df_script.rename(columns={\\\"raw_location_id\\\": \\\"location_id\\\"})\",\"Merge the script lines with the characters and locations information\\ndf_script_full = df_script.merge(df_characters, how='left', on='character_id')\\ndf_script_full = df_script_full.merge(df_locations, how='left', on='location_id')\",\" Combine script lines with characters and locations\\ndf_script_full = pd.merge(df_script, df_characters, on='character_id', how='left')\\ndf_script_full = pd.merge(df_script_full, df_locations, on='location_id', how='left')\",\"Merge characters and locations into the script DataFrame\\ndf_script = df_script.merge(df_characters, how='left', left_on='character_id', right_on='id')\\ndf_script = df_script.merge(df_locations, how='left', left_on='location_id', right_on='id')\"],\"marker\":{\"opacity\":0.5,\"size\":5},\"mode\":\"markers+text\",\"name\":\"5_Merging Character and Location Data in a Script\",\"text\":[\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\"],\"textfont\":{\"size\":12},\"x\":[3.0240001678466797,2.1449766159057617,2.831418752670288,3.861884593963623,2.9870426654815674,3.5069005489349365,3.9278852939605713,3.7591419219970703,3.2234854698181152,3.41838002204895,3.8228683471679688,2.8574275970458984,3.2309482097625732,3.1206042766571045,2.8400375843048096,3.727268695831299,3.5465407371520996,3.5775928497314453,3.64284348487854,3.435460090637207,3.0030415058135986,2.560195207595825,2.3767988681793213,3.870297431945801,3.0585124492645264,3.360752582550049,3.4934394359588623,3.4995100498199463,2.8301122188568115,2.665741443634033,2.8436102867126465,3.05851411819458,2.940404176712036,3.4426562786102295,3.6699492931365967,3.122675895690918,3.1883175373077393,2.6032090187072754,3.8947393894195557,3.2238523960113525,3.8072869777679443,3.1179087162017822,3.222430467605591,3.4225900173187256,3.2287192344665527,3.1424992084503174,2.8905386924743652,3.196976661682129,3.644327163696289,3.3272922039031982,3.7012622356414795,3.0861473083496094,3.2765283584594727,3.4559261798858643,3.343451976776123,3.1524085998535156,3.6718361377716064,3.323023796081543,3.071448564529419,3.215704917907715,2.956949234008789,3.132362127304077,3.225484848022461,3.7233850955963135,3.672811508178711,3.356727361679077,2.8138351440429688,2.994856595993042,3.541177988052368,2.9391257762908936,2.903120279312134,3.4994609355926514,3.3066599369049072,3.2625105381011963,3.3705132007598877,3.1669492721557617,2.347785711288452,3.4186205863952637,4.069098472595215,3.2490346431732178,3.4816408157348633,2.6854045391082764,3.025125026702881,3.034742832183838,3.235849380493164,3.1060123443603516,3.610368490219116,3.3312597274780273,3.397090196609497,3.3017871379852295],\"y\":[9.4515380859375,9.997276306152344,10.59952449798584,9.675522804260254,10.008994102478027,10.336357116699219,10.69481086730957,9.906231880187988,9.827198028564453,10.51486587524414,10.210018157958984,10.466045379638672,9.452093124389648,11.075776100158691,10.17408561706543,10.321235656738281,9.504105567932129,10.03736686706543,9.016603469848633,9.314070701599121,10.42807674407959,10.123212814331055,10.129014015197754,9.428860664367676,9.058004379272461,9.183667182922363,9.389683723449707,10.25288200378418,10.624336242675781,10.357820510864258,10.36078929901123,9.442766189575195,9.97724723815918,10.277663230895996,9.467704772949219,10.098679542541504,10.534472465515137,10.525049209594727,8.601009368896484,9.532145500183105,11.067614555358887,10.831425666809082,11.12215805053711,9.412958145141602,10.49543285369873,10.56183910369873,9.602947235107422,10.619677543640137,9.35886287689209,11.15004825592041,11.061001777648926,10.131245613098145,10.265273094177246,9.326483726501465,10.352340698242188,10.589241981506348,10.32263469696045,10.657312393188477,11.160202980041504,10.390277862548828,10.332236289978027,9.662885665893555,10.131552696228027,9.146895408630371,9.824400901794434,9.153185844421387,10.725050926208496,9.985167503356934,8.455696105957031,10.368204116821289,10.847711563110352,9.839756965637207,9.185763359069824,10.991671562194824,9.245160102844238,10.404729843139648,10.324543952941895,10.639472007751465,9.502598762512207,10.339587211608887,8.96934986114502,9.769469261169434,9.506542205810547,9.896383285522461,11.01733112335205,10.594629287719727,8.8995943069458,10.700356483459473,10.737460136413574,10.757408142089844],\"type\":\"scattergl\"},{\"hoverinfo\":\"text\",\"hovertext\":[\"Viewing the structure of the characters dataset\",\"Let's take a preview of the character data\",\" Look at who the characters are\",\"Defines the character names by its reception of the user defined name in a lowercase manner for searching consistency\",\"EDA on the characters dataset\",\"Check the character dataset\",\"Inspect the characters dataset\",\"Quick look at the character data\",\" Let's take a look at the characters dataset first.\",\"the `str` accossor will be used for performing string operations on the Series.\",\"Check what is inside the table of characters\",\"Let's take a look at the character data:\",\"Define the parser for the names\",\"Let's take a look at the characters dataset.\",\"Combining all character lines to obtain a single document for each character.\",\"Looking at the distribution of the character lines in the dataset before and after removing the 'NaN's.\",\"Let's inspect the first 5 records of the dataset containing the characters.\",\" Check the first few rows of the characters data.\",\"check character count and header\",\"Inspecting the first few characters of each table\",\" Set up statistics for the characters.\",\"Check the content of the first dataset (characters)\",\"Select your character of interest from the list of characters. Fill in the character name in the variable below.\",\" Show info of dataset of characters.\",\"Check the content of the characters file\",\"Inspect the character dataset\",\" Get the outfit color of the characters\",\" Display read data for characters.\",\" Making it easier to recognize the characters used in the dataset.\",\" Looking at the first couple of entries of our characters dataset\",\"Building the graph of the characters relationships.\",\"Checking out the content of the characters data\",\"Merge the character line with the character.\",\"Join the dataset on the character ID\",\"Let's see what the character data looks like.\",\"Explore the characters dataset\",\"Extract information about the characters\",\"Check the character dataset\",\"Checking the format of the data for characters\",\"Character names often appear with spaces and uppercase letters and a dot at the end.\",\"Look at the character data.\",\"Ensure all strings are actually strings.\",\"Let's have a look at Character lines and Locations.\",\"Let's look at the character dataset first.\",\"Exploring the characters dataset\",\"Check if characters have an alternative name\",\"Inspecting the first dataset - characters\",\" Let's sample the characters dataset and understand its structure.\",\"Exploring the characters dataset\",\"Get data from users_dicussion of all characters.\",\"We will start by analyzing the characters' lines.\",\"Simple visualisation to have an idea of the different characters.\",\"Examine the contents of the characters dataset\",\"Build a single dataset containing all the character lines and metadata\",\"Preview characters dataset.\",\"Inspect the table of characters.\",\" Let's take a look at the characters data.\",\"Character level counts\",\"function to get the character quotes\",\"Check the character id 2.\",\"Build a lookup table for characters and their gender.\",\"First, let's take a look at the character dataset.\",\" Displaying the records of the characters data.\",\" Check the content of the 'characters' file\",\"Checking Character details\",\"Inspect dataset 1: Characters\",\"Inspect the characters table\",\" Display general information of dataset characters\",\"Show the result of the first execution of the characters data base\",\"Let's take a look at the characters data.\",\" Combine first and last name for character identification\",\"Let's check how the character dataset looks like\",\"Creating a character-level dataset for each character in the list\",\"Extracting the names of the main characters from the table's names_eps variable.\",\"Visualising some basic character and location information\",\"wip - build character counts\",\"Define the string keyword for the characters we want to consider.\",\"Let's take a look at the characters data.\",\"Check whether characters names are duplicated or not.\",\"Let's first analyze the characters.\",\"Characters and locations involve different entries for different versions or spellings.\"],\"marker\":{\"opacity\":0.5,\"size\":5},\"mode\":\"markers+text\",\"name\":\"6_Character Dataset Inspection\",\"text\":[\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\"],\"textfont\":{\"size\":12},\"x\":[10.215843200683594,10.858153343200684,9.656620025634766,10.432351112365723,10.460431098937988,10.338699340820312,10.239027976989746,10.811729431152344,10.884845733642578,11.319988250732422,10.473145484924316,10.966166496276855,10.788715362548828,10.948225021362305,10.936895370483398,10.436243057250977,10.39456844329834,10.657136917114258,10.349863052368164,10.936881065368652,10.692045211791992,10.568422317504883,10.064103126525879,9.977766036987305,10.968865394592285,10.236170768737793,10.141742706298828,10.693254470825195,10.674548149108887,10.650485038757324,10.526762008666992,10.310151100158691,10.538474082946777,6.7312188148498535,11.103203773498535,10.270651817321777,10.144620895385742,10.484039306640625,10.7367582321167,10.465117454528809,10.972925186157227,11.160859107971191,9.809046745300293,10.776323318481445,10.036515235900879,10.125284194946289,10.406017303466797,10.684723854064941,10.078753471374512,9.797245025634766,11.015202522277832,9.938567161560059,10.235729217529297,9.909268379211426,10.491531372070312,10.765384674072266,10.5514497756958,11.069350242614746,9.851280212402344,11.074300765991211,9.265216827392578,10.922452926635742,10.269484519958496,10.71995735168457,10.257062911987305,10.359986305236816,10.554566383361816,9.75605583190918,10.534605026245117,10.645410537719727,9.499095916748047,10.885417938232422,10.388582229614258,10.143263816833496,9.571832656860352,10.759900093078613,10.764946937561035,10.86873722076416,10.539956092834473,10.537932395935059,10.317497253417969],\"y\":[8.827401161193848,9.05489444732666,7.174106121063232,6.636632442474365,8.901677131652832,8.763924598693848,9.012579917907715,8.504725456237793,9.47518539428711,7.253915309906006,8.432680130004883,8.650288581848145,5.910764694213867,9.041418075561523,7.46299934387207,10.006053924560547,9.491437911987305,8.539020538330078,8.296582221984863,9.009810447692871,8.598016738891602,9.683773040771484,7.640487194061279,8.614717483520508,8.288658142089844,9.018572807312012,6.946568965911865,8.416248321533203,9.508761405944824,9.234971046447754,8.025614738464355,8.258581161499023,6.917914390563965,2.0515353679656982,8.943753242492676,8.39623737335205,7.747949123382568,8.861990928649902,8.439260482788086,7.487488269805908,8.484786033630371,6.502758979797363,8.201543807983398,9.355621337890625,8.522496223449707,6.898209571838379,9.644726753234863,9.025146484375,8.498994827270508,8.465034484863281,7.683892250061035,7.786325454711914,8.6923828125,7.648995399475098,9.246794700622559,8.445320129394531,8.752386093139648,9.197240829467773,7.197518825531006,7.950561046600342,7.0912089347839355,9.129425048828125,8.510053634643555,8.712963104248047,8.073468208312988,9.53563117980957,8.543952941894531,9.52099323272705,9.324539184570312,8.670642852783203,7.423387050628662,9.620267868041992,8.623944282531738,7.583442211151123,7.675167560577393,8.853904724121094,7.169823169708252,8.476632118225098,7.434863090515137,8.208223342895508,7.954994201660156],\"type\":\"scattergl\"},{\"hoverinfo\":\"text\",\"hovertext\":[\"Merge data\\ndf_script = pd.merge(df_script, df_episodes, how='inner', left_on='episode_id', right_on='id')\",\"Merge the episodes with the script\\ndf_episodes['id'] = df_episodes['id'].astype(int)\\ndf_script = pd.merge(df_script, df_episodes, how='inner', left_on=df_script['episode_id'], right_on=df_episodes['id'])\",\"Join episodes with script\\ndf = df_script.merge(df_episodes, on='episode_id')\",\"Merge the script lines with the episodes dataframe\\ndf_script_full = pd.merge(df_script, df_episodes, on='episode_id')\",\"Merge df_script and df_episodes on episode_id\",\"Merge the episode dataset with the script dataset\\ndf_merged = df_script.merge(df_episodes, on='episode_id')\",\"Merge datasets to get a unified dataset for analysis\\ndf_merged = df_script.merge(df_episodes, on='episode_id')\",\"Merge the script lines with their respective episodes\\ndf_script = df_script.merge(df_episodes, on='episode_id', suffixes=('', '_episode'))\",\"Merge all datasets on `episode_id`\\ndf_merged = df_script.merge(df_episodes, on='episode_id', suffixes=('_script', '_ep'))\\n# remove duplicate columns\\ndf_merged = df_merged.loc[:, ~df_merged.columns.duplicated()]\",\"Merge episodes\\ndf_episodes_script = df_episodes.merge(df_script, on='episode_id')\",\"Clean non-existant or old-fashioned episodes from df_script\\ndf_script_cleaned = df_script.merge(df_episodes,on='episode_id')\\ndf_script_cleaned = df_script_cleaned[(df_script_cleaned['original_air_year']\\u003e=1989) & (df_script_cleaned['original_air_year']\\u003c=2018)]\\ndf_script = df_script_cleaned\",\" Merge the datasets together\\ndf = df_script.merge(df_episodes, on='episode_id')\",\"Merging the script and episode dataframes by the 'episode_id' column\\ndf_merged = df_script.merge(df_episodes, on='episode_id')\",\" Concatenate script and episode data_frames\\ndf = pd.concat([df_script, df_episodes], axis=1, keys='episode_id', join='inner')\",\"Merge episodes and script\\ndf_script_episodes = df_script.merge(df_episodes,\\n                how='inner',\\n                left_on='episode_id',\\n                right_on='id',\\n                suffixes=('_script', '_episode'))\\n\\n# Random look at the dataset\\ndf_script_episodes.sample(10)\",\"Merge the script lines with episode data\\ndf_script['episode_id'] = df_script['episode_id'].astype('int64')\\ndf_merged = pd.merge(df_script, df_episodes, left_on='episode_id', right_on='id', suffixes=('_script', ''))\",\" Merge transcript with the rest\\ndf_script['id'] = df_script['episode_id']\\ndf = pd.merge(df_script, df_episodes, on='id')\",\"Define the label to merge by\\nlabel = ['season', 'number_in_season']\\n\\n# Join the datasets on the common label\\ndf_merged = df_script.merge(df_episodes, on=label)\",\" Merge the script and episode DataFrames\\ndf = df_script.merge(df_episodes, on='episode_id')\",\"Create merge of episodes and script\\ndf_episodes['id'] = df_episodes.id.astype(str)\\ndf_script['episode_id'] = df_script.episode_id.astype(str)\\ndf_mergerd = pd.merge(df_script, df_episodes, left_on='episode_id', right_on='id').drop(['id'], axis=1)\",\"Merge lines and episodes\\ndf = pd.merge(df_script, df_episodes, on='episode_id')\",\"Set current episode info\\ndf_curr_episode = df_episodes[df_episodes['id'] == 4855]\\n\\n# Set the joint data\\ndf_joint = df_script[\\n    (df_script['episode_id'] == df_curr_episode['id'].values[0])\\n]\",\"Fining the episode_title and corresponding  animation_frame for each line in df_script.\\ndf_script = df_script.merge(\\n    df_episodes[['id', 'title', 'original_air_date']],\\n    left_on='episode_id',\\n    right_on='id',\\n    suffixes=('', '_episode')\\n)\",\"Merge script and episodes\\ndf_merged = df_script.merge(df_episodes, on='episode_id')\",\"Character lines dataset\\nline_data = pd.merge(df_script, df_episodes, on='episode_id', how='inner')\",\" Merge df_script with df_episodes to attach episode info to each line\\ndf_script_all_info = pd.merge(df_script, df_episodes,\\n                              on=['episode_id', 'season', 'number_in_season', 'number_in_series'])\",\"Merge\\ndf_merge = df_script.merge(\\n    df_episodes,\\n    left_on='episode_id',\\n    right_on='id',\\n    suffixes=('_script', '_ep')\\n)\",\"Merge script with episodes\\ndf_merged = pd.merge(df_script, df_episodes, on='episode_id')\",\"Merge df_script and df_episodes on 'episode_id' to get the actual episode title in the df_script DataFrame\\ndf_script = df_script.merge(right=df_episodes, how='inner', on='episode_id')\",\"merge the episodes with the script data. This will give us script data with episode data included\\ndf = df_script.merge(df_episodes, on='episode_id')\",\"Get all the quotes from the episodes and movies and join them in a single string\\nscript = \\\" \\\".join(script for script in df_script['dialog'])\",\"Merge episodes and script\\ndf_script_episodes = df_script.merge(\\n    df_episodes,\\n    on='episode_id'\\n)\",\" Create a new DataFrame merging 'df_episodes' with 'df_script'\\ndf_merged = df_episodes.merge(df_script, on='id', suffixes=('_ep', '_script'))\\n\\n# Limitation\\nLIMIT = None\",\" Merge all available data into one large DataFrame\\ndf = df_script.merge(df_episodes, on='episode_id')\",\"Merge episodes with scripts\\ndf = df_script.merge(df_episodes, on='episode_id')\",\"Test the merge capabilities on index for 'episodes' and 'script'\\ndf_ep_sc = df_script.merge(df_episodes, on='episode_id')\\nprint(f'{len(df_script)} merged with {len(df_episodes)} on episode_id to {len(df_ep_sc)}')\",\" Merge script data with respective episode data\\ndf_script_episode = pd.merge(df_script,\\n                             df_episodes,\\n                             left_on='episode_id',\\n                             right_on='id',\\n                             suffixes=['_script', '_episode'])\",\" Join the df_episodes and df_script DataFrame on the 'episode_id' column\\ndf = df_script.merge(df_episodes, on='episode_id')\",\"Merge datasets to have a comprehensive view of the data\\ndf_merged = df_script.join(df_episodes, on='episode_id', rsuffix='_episode')\",\" Merge the script lines and the episodes dataframes on the episode_id column\\ndf_merged = pd.merge(df_script, df_episodes, on='episode_id', how='outer')\",\"Join episodes with script\\ndf_episodes_script = df_episodes.merge(\\n    df_script, \\n    how='inner', \\n    left_on='id',\\n    right_on='episode_id'\\n).reset_index(inplace=False, drop=True)\",\"Merge the dataframes\\ndf_merged = df_script.merge(df_episodes, on='episode_id', suffixes=('', '_episode'))\",\"Merge script with episodes\\ndf_script_full = df_script.merge(df_episodes, on='episode_id').merge(df_characters, on='character_id')\\n\\n# Display the first 5 rows and all columns of the resulting dataframe\\npd.set_option('display.max_columns', None)\\ndf_script_full.head()\",\"Merge `df_script` with `df_episodes`\\ndf_script = pd.merge(df_script, df_episodes, on='episode_id')\",\"Get script and merge\\ndf_script = pd.merge(df_script, df_episodes, on='episode_id')\\ndf_script = pd.merge(df_script, df_characters, on='character_id')\",\"Merge script and episode datasets\\ndf = pd.merge(df_script, df_episodes, on='episode_id', how='inner')\",\" Merge the episodes' data into the script's data\\ndf_script = df_script.merge(df_episodes, on=['episode_id'], how='inner')\",\"Merge dataframes\\ndf_script = df_script.merge(df_episodes, left_on='episode_id', right_on='id', suffixes=('', '_ep')).drop(columns=['id', 'id_ep'])\",\"Merge datasets together\\ndf_episodes = df_episodes.rename(columns={\\\"id\\\" : \\\"episode_id\\\"})\\ndf_script = pd.merge(df_script, df_episodes[['episode_id', 'title']], on='episode_id')\\ndf_script = df_script.dropna(subset=['raw_text', 'character_id'])\\ndf_episodes = df_script.loc[:, ['episode_id', 'title']].drop_duplicates()\\n# tqdm.pandas()\\n# df_script['nlp_processed_text'] = df_script['raw_text'].progress_apply(lambda x: nlp(x))\",\"Merge the episodes and the script dataframes using the common 'episode_id' column.\\ndf_merged = df_script.merge(df_episodes, on='episode_id')\",\" Dataframe that combines script lines and episode information\\ndf_script_episodes = df_script.merge(df_episodes, on='episode_id', suffixes=('_script', '_episode'))\\ndf_script_episodes\",\"'Inconsequential', 'other', 'TRASH', and 'noise' lines will be dropped.\\nsentence_level_scripts = df_script.loc[df_script.raw_text.str.contains('Anonymous|PABF|JABF|TABF') == False].copy()\\n\\n# The merged dataframe will only consider scripts from the main 22 seasons\\nmerged_df = df_episodes[df_episodes.season \\u003e 0]\",\"Merge the episode and script dataframes on the episode_id column\\ndf = pd.merge(df_script, df_episodes, left_on='episode_id', right_on='id', suffixes=('_script', '_episode')).drop('id', axis=1)\",\"Merge script and episodes on episode_id\\ndf_script_episodes = df_script.merge(df_episodes, on='episode_id')\",\"Merge script with episodes\\ndf_episodes['id'] = df_episodes['id'].astype(int)\\ndf_script = df_script.merge(df_episodes, left_on='episode_id', right_on='id', suffixes=('_script', '_episode'))\",\"Merge episode data into the script data\\ndf = pd.merge(df_script, df_episodes, on='episode_id')\",\"Merge episodes with scripts\\ndf_episodes['id'] = df_episodes['id'].astype(str)\\ndf_script['episode_id'] = df_script['episode_id'].astype(str)\\ndf = pd.merge(df_script, df_episodes, left_on = 'episode_id', right_on = 'id')\",\"Merge 'script' with 'episodes' using 'episode_id' as they share this column\\ndf_script = pd.merge(df_script, df_episodes, on='episode_id')\",\"Merge the scripts and episodes datasets\\ndf = df_script.merge(df_episodes, on='episode_id')\",\"Join \\\"lines\\\" and \\\"episodes\\\" DataFrame on \\\"episode_id\\\"\\ndf = df_script.join(df_episodes, on='episode_id')\",\" Join script lines and get an example episode\\ndf_script = df_script.merge(df_episodes, on='episode_id')\",\"Merge episodes with the script lines\\ndf_episodes_and_script = df_script.merge(df_episodes, on='episode_id')\",\"Merge script lines and episodes dataframes\\ndf = pd.merge(df_script, df_episodes, on='id', suffixes=('_script', '_episodes'))\",\"Merge episodes and scripts\\ndf = pd.merge(df_script, df_episodes, on='episode_id')\",\"Define the list of episodes for which we have both the script and the subtitles\\ncommon_episodes = list(set(df_script[df_script['episode_id'] != -1].episode_id).intersection(set(df_episodes[df_episodes['id'] != -1].id)))\",\"Join the script with episodes and select a few basic columns\\ndf = df_script.merge(df_episodes, on='episode_id')\",\"Merged dataframe on episode_id\\ndf_merged = pd.merge(df_script, df_episodes, on='episode_id', how='inner').head(50)\",\"Merge script lines with episode data\\ndf_merged = pd.merge(\\n    df_script, \\n    df_episodes, \\n    how='left',\\n    on='episode_id',\\n    suffixes=('', '_ep')\\n)\",\"Merge scripts with episodes\\ndf_scripts_episodes = df_script.merge(df_episodes, on='episode_id', how='outer')\",\"Merging `simpsons_script_lines` with `simpsons_episodes` across the `episode_id` column\",\"Merge episodes data to script data\\ndf_script = pd.merge(df_script, df_episodes[['id', 'imdb_rating', 'number_in_series', 'original_air_date', 'original_air_year']], how='left', left_on='episode_id', right_on='id', suffixes=('_script', '_episodes')).drop(columns=['id_epsiodes'])\",\"Merge the episodes and the script dataframes on the id column\\ndf_data = pd.merge(df_script, df_episodes, left_on='episode_id', right_on='id', suffixes=('', '_episode'))\",\"Merge the episodes and scripts dataframe on the column 'episode_id'\\ndf_episodes_scripts = df_episodes.merge(\\n    df_script, \\n    how='inner', \\n    left_on='id', \\n    right_on='episode_id',\\n    suffixes=('_episodes', '_scripts')\\n)\",\"Merge script and episodes dataframes\\ndf = df_script.merge(df_episodes, on='episode_id', suffixes=('_script', '_ep'))\\n\\n# Select only the episodes of the year 2000 and on\\ndf = df[df['original_air_year'] \\u003e= 2000]\",\"Merge script and episode data\\ndf_script = df_script.merge(df_episodes, on='episode_id')\\n\\n# Display the merged dataset\\ndf_script.head()\",\"\\n# Merge data for convenience\\ndf_merged = pd.merge(\\n    df_script,\\n    df_episodes,\\n    how=\\\"left\\\",\\n    on=\\\"episode_id\\\",\\n    suffixes=(\\\"_script\\\", \\\"_ep\\\")\\n)\",\"Merge the script lines with the episode info\\ndf = pd.merge(df_script, df_episodes, on='episode_id')\",\"Merge episodes with script data\\ndf = df_script.merge(df_episodes, on='episode_id', how='inner')\",\"Set the series_id values to have the sames type as df_episodes['id'] to facilitate the upcoming merge\",\" Merge script lines with characters and episodes\\ndf_lines_episodes = df_script.merge(df_characters, on='character_id').merge(df_episodes, on='episode_id').dropna()\\n\\ndf_lines_episodes.head()\",\"Merge episodes and script df\\ndf_eps_script = pd.merge(df_episodes, df_script, on='episode_id')\"],\"marker\":{\"opacity\":0.5,\"size\":5},\"mode\":\"markers+text\",\"name\":\"7_Merging Scripts and Episodes DataFrames\",\"text\":[\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\"],\"textfont\":{\"size\":12},\"x\":[1.2356312274932861,1.2426451444625854,2.210193634033203,2.280802011489868,2.6840627193450928,2.1510303020477295,2.1543803215026855,2.3254165649414062,2.081711769104004,1.664266586303711,2.535292863845825,2.3577053546905518,2.033176898956299,2.2823426723480225,1.6094396114349365,1.3863749504089355,1.7167750597000122,1.7327369451522827,2.4490373134613037,1.653498888015747,2.154066324234009,2.580812931060791,2.207211494445801,1.5096677541732788,1.762732982635498,2.5343286991119385,1.4015027284622192,1.4702547788619995,1.571858286857605,2.77998685836792,2.2654623985290527,1.9824628829956055,2.0230486392974854,2.091780424118042,2.1045448780059814,1.6114581823349,2.0087523460388184,2.2339344024658203,2.0021567344665527,1.7666016817092896,2.3282883167266846,1.8456311225891113,18.98274803161621,1.7515860795974731,2.0765600204467773,1.5765641927719116,2.140315294265747,1.2679558992385864,2.7998924255371094,2.3582346439361572,2.11833119392395,2.0766854286193848,2.079413652420044,1.798717737197876,1.714349389076233,2.0236928462982178,1.779098391532898,1.835017442703247,2.5469603538513184,2.8812499046325684,2.7543399333953857,2.352247476577759,1.9576908349990845,1.9937859773635864,3.02478289604187,2.5232818126678467,1.2645657062530518,1.1340398788452148,1.6354233026504517,2.66631817817688,1.9200156927108765,1.8267865180969238,1.9993942975997925,2.959977388381958,1.9177285432815552,1.413509726524353,2.346168041229248,1.5830390453338623,1.7026288509368896,2.1029646396636963,1.4678401947021484],\"y\":[6.042235851287842,6.005812644958496,4.80224609375,5.400530815124512,5.089810848236084,4.729589462280273,4.432135581970215,5.905183792114258,5.420474529266357,5.218991756439209,5.264828681945801,4.636131763458252,5.186019420623779,6.464102745056152,5.494317531585693,5.910950660705566,5.4646759033203125,4.895559310913086,5.05465841293335,6.582443714141846,5.907164096832275,5.462512493133545,5.651767253875732,5.314745903015137,6.578753471374512,6.121857643127441,5.838364601135254,5.593886375427246,6.181690692901611,5.341365814208984,6.560475826263428,5.234253406524658,5.497827529907227,4.970015048980713,5.044666767120361,4.240671157836914,5.962961196899414,4.886348724365234,4.744205951690674,5.575248718261719,5.325483798980713,5.698297023773193,1.0065624713897705,5.830538272857666,6.304025173187256,5.633607387542725,6.055210113525391,6.266476631164551,5.98173713684082,5.131231307983398,6.068552017211914,6.680905342102051,6.183657646179199,5.243892192840576,5.812260150909424,5.742541313171387,5.993545055389404,5.8628010749816895,4.816446781158447,4.746273040771484,5.586130619049072,5.435734748840332,6.219501495361328,5.9839887619018555,5.3380656242370605,5.090681076049805,5.486026763916016,6.073645114898682,5.419866561889648,6.035613059997559,6.001349449157715,5.90010929107666,5.574352264404297,4.745143413543701,5.401448726654053,5.966879844665527,5.76568603515625,6.1282267570495605,5.2707343101501465,6.536277770996094,5.730425834655762],\"type\":\"scattergl\"},{\"hoverinfo\":\"text\",\"hovertext\":[\"Extract principal data from column to ease .csv navigation\",\"We are reading multiple CSV files into pandas dataframes for further analysis and processing.\",\" This line of code^- reads the csv files into pandas dataframes for further processing and analysis.\",\"Start by loading the datasets into pandas DataFrames.\",\"First, we import the necessary libraries and modules to set up our environment and load the data. Then, we read the CSV files into DataFrames using pandas.\",\"Import necessary modules and read in the CSV files into pandas dataframes.\",\" Load in the data from the CSV files into pandas DataFrames.\",\"Now that we have our datasets loaded into pandas DataFrames, we can start exploring the data and performing some analysis.\",\"Importing all necessary packages and setting up the dataframes for further analysis.\",\"Importing the required datasets from csv files into pandas dataframes.\",\"The last line of code imports the data from CSV files into pandas dataframes.\",\"First, we read the data from CSV files into pandas DataFrames for further processing and analysis.\",\"We have successfully loaded the datasets into Pandas dataframes.\",\"Data parallelisation, speeds up operations in pandas by splitting the data into chunks, each chunk can be processed on a different CPU core.\",\"begin by reading the data from csv files into pandas dataframes.\",\"It seems that the code was written to read several CSV files into pandas dataframes. This is likely to be part of a data analysis or data visualization project related to the TV show \\\"The Simpsons.\\\"\",\"We need to have some csv files saved in the 'data' directory. Additionally, we can make our Notebook find the utils.py file by adding it to the Python path.\",\"function to load large data files using dask (for parallelism)\\ndef load_large_csv(file):\\n    return dd.read_csv(file, blocksize=int(1e6))\",\"We have completed the general imports and have loaded the datasets into pandas dataframes.\",\"Hints: The code is reading multiple CSV files into pandas dataframes.\",\"Now we have imported the required data into dataframes for further analysis.\",\" Looks like the code is importing the necessary data using pandas.\",\"Import the data from the CSV files into pandas dataframes.\",\"The first few lines of code above are importing necessary libraries and packages. After this, the code loads data from CSV files into pandas dataframes for further processing and analysis.\",\"A LOT of warnings will occur from this chunk of code and that happens because pandas uses a lot of chained assignment in the code, which has been optimized but is not supported by Pylint and other tools. Pylint will let us know about this and suggest that we use the `at` method instead of the chained operators to access the data of our dataframe.\",\"The last few commands in the script load several datasets into pandas DataFrames. These DataFrames will be used for data analysis and visualization.\",\"First we import the necessary modules we'll use throughout the code. Then, we read in the data from the CSV files into pandas DataFrames using `pd.read_csv()`.\",\"Looks like the code reads data from CSV files into pandas dataframes.\",\"As we can see, we've added multiple CSV files to Pandas DataFrames for further processing and analysis.\",\"This will load the datasets into pandas dataframes for further analysis.\",\"We'll start by loading the data into pandas dataframes.\",\"We are importing multiple dataframes from CSV files using pandas and storing them in variables.\",\"We are importing data from CSV files and loading them into pandas dataframes for further analysis.\",\"First, read the provided CSV files into pandas DataFrames.\",\"Sometimes, the data from the csv might have excessive blank spaces, it is good practice to remove leading and trailing whitespace from your pandas dataframe.\",\"We can see that we are reading in multiple CSV files using pandas and storing them into dataframes.\",\"Fix someone's typo in sample code\\nDataFrame name on each final line should be in the left hand side in place of pandas module name.\",\"We are now reading in the CSV files using pandas and storing them in dataframes.\",\" This is a Python code that reads CSV files into pandas dataframes. The code uses the pandas library to read the CSV files and store the data in dataframes. These dataframes can then be used for further data analysis and manipulation.\",\"Let's first load all the data from the CSV files into Pandas dataframes.\",\"The line above reads several CSV files into pandas DataFrames.\",\"\\n# Python code to create a CSV file\\n# from a list\\nimport csv\\n\\n# field names\\nfields = ['Name', 'Branch', 'Year', 'CGPA']\\n\\n# data rows of csv file\\nrows = [ ['Nikhil', 'COE', '2017', '9.0'],\\n         ['Sanchit', 'COE', '2017', '9.1'],\\n         ['Aditya', 'IT', '2017', '9.3'],\\n         ['Sagar', 'SE', '2017', '9.5'],\\n         ['Prateek', 'MCE', '2017', '9.1'],\\n         ['Sahil', 'EP', '2017', '9.2']]\\n\\n# name of csv file\\nfilename = \\\"university_records.csv\\\"\\n\\n# writing to csv file\\nwith open(filename, 'w') as csvfile:\\n    # creating a csv dict writer object\\n    csvwriter = csv.writer(csvfile)\\n    \\n    # writing the fields\\n    csvwriter.writerow(fields)\\n    \\n    # writing the data rows\\n    csvwriter.writerows(rows)\",\"Most of the time, the data in pandas dataframes is read-only. This means that the methods and attributes are in place, to ensure that the data doesn't get manipulated accidentally.\",\"First, we import the necessary libraries and then read the CSV files into pandas dataframes.\",\"First, we import the necessary libraries and then read in the data from CSV files into Pandas dataframes.\",\"This code snippet demonstrates the use of several Python libraries for data analysis and visualization. It reads data from CSV files using pandas, performs some preprocessing, and sets up the environment for further analysis. The code also includes custom imports for additional functionality.\",\"We have read the CSV files into Pandas dataframes.\",\"We have successfully imported the necessary libraries and read the data into pandas dataframes. Now we can move on to the next steps of data exploration and analysis.\",\"First we read the datasets into pandas DataFrame.\",\" Imports required for data visualization and analysis, and loading datasets into pandas DataFrames.\",\"In this step, we have read the CSV files into pandas dataframes for further processing and analysis.\",\"It is common to import multiple libraries and modules before beginning any data analysis or machine learning tasks in Python. In this example, we are importing pandas, numpy, spacy, matplotlib, wordcloud, tqdm, and collections. We also set up matplotlib to work correctly in a Jupyter notebook with the `%matplotlib inline` command. Additionally, we are reading in several CSV files using pandas to create dataframes for analysis.\",\"Setting the \\\"include\\\" parameter of the read_csv function call to \\\"all\\\" will force pandas to read all columns, \\n # even if they have mixed dtypes. Use at your own risk - it's 5-10x slower.\",\" I'm not sure where this code is going or what its purpose is, but it appears to be loading data from CSV files into Pandas DataFrames.\",\"Load the data from the CSV files into pandas DataFrames.\",\"First, we read in the data from CSV files into pandas dataframes.\",\"Read the datasets from the data folder into pandas dataframes.\",\"Now, we will use the read_csv() function from pandas to load the CSV files into DataFrames.\",\"We are importing pandas, numpy, spacy, matplotlib, WordCloud, and other required libraries for our data analysis and visualization. We are also importing custom libraries such as tqdm, Counter, etc. Then we are reading the data from CSV files into pandas dataframes.\",\"Import the required libraries and read the CSV files into pandas dataframes.\",\"We start with the import statements, importing necessary libraries like pandas, numpy, spacy, matplotlib, and others. We also import the custom libraries like tqdm, Counter, and the WordCloud module from the wordcloud library. Then we read the CSV files using pandas, creating dataframes for characters, locations, script lines, and episodes.\",\"Acuna N (2015) write a small utility to enhance the pandas dataframe.\",\"In this snippet, we are reading the data from CSV files into Pandas DataFrames. These DataFrames will then be used for data analysis and visualization.\",\"We will start by loading the data from the CSV files into pandas DataFrames.\",\"So, we have successfully read all the CSV files into pandas dataframes.\",\" Purpose of this code is to read the CSV files and store them in pandas dataframes for further processing and analysis.\",\"The .csv files will now be loaded into dataframes so that they can be further inspected and processed.\",\"Read the datasets from CSV files into pandas DataFrames.\",\"I have imported the data from the CSV files using pandas and stored them in dataframes for further processing.\",\"Load the provided csv files into pandas dataframes.\",\"Read JSon conversion table from local storage\\njcn = pd.read_csv('data\\u002fJsonConversion.csv')\",\"We're reading the CSV files into pandas DataFrames for further processing and analysis.\",\"Load the data from the CSV files into pandas DataFrames.\",\"The csv files are being read and loaded into pandas dataframes for further analysis and processing.\",\"In the above code, we are importing various libraries such as pandas, numpy, spacy, matplotlib, wordcloud, etc. We are also importing custom libraries like tqdm and Counter. Then we are reading CSV files into pandas dataframes using pd.read_csv().\",\"The first line of code imports the data from CSV files into pandas dataframes.\",\" Load and display dataframes from CSV files\",\"Here we are reading CSV files using pandas and storing them in dataframes for further processing.\"],\"marker\":{\"opacity\":0.5,\"size\":5},\"mode\":\"markers+text\",\"name\":\"8_Reading CSV files into pandas DataFrames\",\"text\":[\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\"],\"textfont\":{\"size\":12},\"x\":[12.508589744567871,11.736502647399902,11.145991325378418,12.272624015808105,12.705883026123047,12.755989074707031,12.05359935760498,12.029500007629395,13.081818580627441,12.494169235229492,11.208558082580566,12.40101146697998,12.430424690246582,11.398344039916992,12.239920616149902,11.574914932250977,13.823448181152344,11.78303050994873,12.919083595275879,11.133959770202637,13.034443855285645,10.82935619354248,12.002309799194336,11.595409393310547,10.831509590148926,11.90351390838623,12.412498474121094,11.353592872619629,11.815473556518555,12.152070045471191,12.387271881103516,11.144596099853516,11.953499794006348,12.302037239074707,10.379045486450195,11.367888450622559,10.63786792755127,11.891611099243164,11.83559513092041,11.982165336608887,11.34284496307373,12.103379249572754,10.20671272277832,12.668516159057617,12.550409317016602,12.217681884765625,12.232499122619629,12.45977783203125,11.968400001525879,12.659811973571777,12.359330177307129,12.654902458190918,11.171257972717285,11.265931129455566,11.807718276977539,12.452588081359863,12.30836296081543,12.109824180603027,12.633757591247559,12.494502067565918,12.487561225891113,11.976799964904785,11.904038429260254,12.323729515075684,11.816814422607422,11.541048049926758,12.114455223083496,12.310996055603027,11.794139862060547,11.898126602172852,12.052027702331543,11.928391456604004,12.214831352233887,11.468502044677734,12.339468002319336,11.413138389587402,11.76880931854248,11.962183952331543],\"y\":[-0.40536168217658997,-1.0668531656265259,-0.14099296927452087,-1.8735129833221436,-0.02418815903365612,-0.07920835167169571,-0.7323636412620544,-2.2567012310028076,-0.8117771744728088,-0.7710204124450684,-0.7308570742607117,-1.527051568031311,-1.4378212690353394,-0.9036373496055603,-1.2193931341171265,0.8096619248390198,0.6050440669059753,-0.13831494748592377,-0.9244847297668457,-0.8284628987312317,-1.1343530416488647,-0.45020821690559387,-0.6834136843681335,0.11122490465641022,-0.6749945878982544,-0.9366962909698486,-0.18946246802806854,-0.2261565774679184,-0.8047584295272827,-1.8655997514724731,-1.542640209197998,-1.2246683835983276,-1.2470594644546509,-1.0527641773223877,-0.4440147578716278,-0.8460443615913391,-1.1104055643081665,-1.3015847206115723,-0.05243970826268196,-0.491476446390152,-0.9032832384109497,-0.34240102767944336,-1.4724740982055664,-0.15182152390480042,-0.21127192676067352,0.2183281034231186,-0.7334997057914734,-1.3390132188796997,-2.026432514190674,-0.7734784483909607,-0.8289423584938049,0.6989096403121948,-0.2230144441127777,-0.29312312602996826,-0.8415608406066895,-1.459968090057373,-1.7003425359725952,-0.15250588953495026,0.21492451429367065,-0.29671940207481384,1.027533769607544,-1.978489637374878,-0.46368733048439026,-0.96120285987854,-0.20471550524234772,-0.25280052423477173,-0.7211744785308838,-1.478049874305725,-1.1858417987823486,-0.5760028958320618,0.12052910029888153,-1.0191256999969482,-0.7680697441101074,-0.786038875579834,0.35063040256500244,-0.5358656048774719,-0.5824896097183228,-1.1515864133834839],\"type\":\"scattergl\"},{\"hoverinfo\":\"text\",\"hovertext\":[\"\\ndf_script.head()\",\"df_script.head()\",\"df_script.head()\",\"df_script.head()\",\"df_script.head()\",\"\\ndf_script.head()\",\"df_script.head()\",\"\\ndf_script.head()\",\"\\ndf_script.head()\",\"\\ndf_script.head()\",\"df_script.head()\",\"df_script.head()\",\"df_script.head()\",\"df_script.head()\",\"\\ndf_script.head()\",\"# What does the df contain?\\ndf_script.head()\",\"df_script.head()\",\"\\ndf_script.head()\",\"jupyter notebook... so much power!\\ndf_script.head(20)\",\"f Script (first lines)\\ndf_script.head()\",\"# Carry the same process out for script data\\ndf_script.head()\",\"df_script.head()\",\"df_script.head(10)\",\"\\ndf_script.head()\",\"df_script.head()\",\"df_script.head()\",\"Main dataframe head\\ndf_script.head()\",\"df_script.head()\",\"\\ndf_script.head()\",\"df_script.head()\",\"df_script.head()\",\"df_script.head()\",\"\\ndf_script.head()\",\"\\ndf_script.head()\",\"df_script.head()\",\"\\ndf_script.head()\",\"df_script.head()\",\"df_script.head()\",\"\\ndf_script.head()\",\"df_script.head()\",\"df_script.head()\",\"\\ndf_script.head()\",\"\\n# df_script.head()\",\"\\ndf_script.head()\",\"df_script.head()\",\"Data frame sample\\ndf_script.head()\",\"df_script.head()\",\"\\ndf_script.head()\",\"df_script.head()\",\"# We'll work with the script text\\ndf_script.head()\",\"print(df_script.head())\",\"# Spokane_County_Animation_Corpus_General\\ndf_script.head()\",\"df_script.head()\",\"df_script.head()\",\"\\ndf_script.head()\",\"\\ndf_script.head()\",\"df_script.head()\",\"\\ndf_script.head()\",\"Sanity check\\ndf_script.head()\",\" Get the script from Treehouse\\ndf_script_medium = df_script.head(1000)\",\"\\ndf_script.head()\",\"\\ndf_script.head()\",\"# Prints\\ndf_script.head()\",\"df_script.head()\",\"Df at glance\\ndf_script.head()\",\"# Sample\\ndf_script.head()\",\"# Look at the first three lines\\ndf_script.head(3)\",\"\\ndf_script.head()\",\"df_script.head()\",\"df_script.head()\",\"df_script.head()\"],\"marker\":{\"opacity\":0.5,\"size\":5},\"mode\":\"markers+text\",\"name\":\"9_df_script head extract and analysis\",\"text\":[\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\"],\"textfont\":{\"size\":12},\"x\":[6.174624443054199,5.4296417236328125,5.711764335632324,6.310346603393555,5.734247207641602,5.780759811401367,5.56383752822876,5.8121747970581055,6.09089994430542,5.926300048828125,5.581207752227783,5.611894607543945,5.917202472686768,5.877167224884033,5.56494665145874,5.828852653503418,6.269620895385742,5.855560302734375,5.851058006286621,5.67238187789917,5.363584995269775,5.817318439483643,5.5275797843933105,6.307255744934082,6.140658855438232,5.55553674697876,6.037500381469727,5.876519203186035,5.787950038909912,5.023596286773682,5.99603271484375,6.159655570983887,5.78231954574585,5.669615745544434,6.175711631774902,5.145888328552246,5.50502872467041,6.249443531036377,5.48400354385376,5.236736297607422,5.610260009765625,5.692131519317627,5.707192897796631,5.4982829093933105,5.982235908508301,5.509420394897461,5.365803241729736,6.061857223510742,5.4332098960876465,5.827781677246094,6.068686008453369,5.881326198577881,5.866336822509766,5.274107933044434,6.285593032836914,5.86561393737793,5.667119026184082,5.902093887329102,5.645297050476074,5.504655838012695,6.122251987457275,5.639857292175293,5.809073448181152,5.489503860473633,6.009123802185059,5.509525775909424,6.160721302032471,6.307880878448486,5.632967948913574,5.848318099975586,5.6380510330200195],\"y\":[-8.126235008239746,-8.14393138885498,-8.184650421142578,-7.878929138183594,-7.983638763427734,-7.967670917510986,-8.357402801513672,-8.582061767578125,-7.689446449279785,-8.632418632507324,-7.887458324432373,-7.892016887664795,-8.31837272644043,-7.768138885498047,-8.543845176696777,-7.230276107788086,-8.598706245422363,-7.959958553314209,-6.780685901641846,-8.646071434020996,-6.559261798858643,-8.381099700927734,-7.612669467926025,-7.8093061447143555,-8.157772064208984,-8.168797492980957,-7.065278053283691,-7.675294876098633,-8.685184478759766,-7.813144683837891,-8.291576385498047,-8.244587898254395,-7.831340789794922,-8.312356948852539,-8.602368354797363,-8.112483978271484,-8.059213638305664,-8.00117015838623,-8.184784889221191,-8.379504203796387,-8.44520092010498,-7.7736310958862305,-6.869272232055664,-7.6377482414245605,-8.03582763671875,-6.915088176727295,-8.46652889251709,-8.139533996582031,-8.420502662658691,-6.65765380859375,-6.9737162590026855,-6.960220813751221,-7.879487037658691,-7.98836612701416,-7.554032802581787,-8.622781753540039,-8.109848022460938,-7.642533302307129,-5.837235450744629,-4.99879789352417,-8.284578323364258,-8.245917320251465,-7.167292594909668,-7.9305830001831055,-8.556723594665527,-6.786048412322998,-7.1567583084106445,-8.108086585998535,-8.18338680267334,-8.206398010253906,-8.501383781433105],\"type\":\"scattergl\"},{\"hoverinfo\":\"text\",\"hovertext\":[\"Display the first few rows of each dataframe to understand the data\",\"Optional: Display the first few rows of each DataFrame to check the data\",\"Display the first few rows of each dataframe to understand the data\",\"Print the first few rows of each dataframe to understand the data\",\"Display the first few rows of each DataFrame to understand the data\",\" Display the first few rows of each dataframe to understand the data\",\" Display the first few rows of each dataframe to understand the data\",\" Display the first few rows of each dataframe to understand the data\",\"Optional: Display the first few rows of the dataframe to get an overview of the data.\",\"Display the first few rows of each dataframe to get a sense of what the data looks like.\",\"Display the first few rows of each dataframe to understand the data\",\"Display the first few entries of each dataframe to get an understanding of the data.\",\"Displays the first 3 rows of the dataframe\",\"define a helper function to print the first few rows of a dataframe\",\"Show all columns and the first few rows of each DataFrame to understand what data is available\",\" Displaying the first few rows of each dataframe to understand the data\",\"Display the first few rows of each dataframe to understand what the data looks like.\",\"Display the first 10 rows of each dataframe to get a sense of the data\",\" Display the first few rows of each dataframe to know what information we have\",\"Optional: Display first few rows of the dataframe to understand the data\",\"let's show first the available columns for each dataframe\",\" Display the first few rows of each dataframe to understand the data\",\"Display the first few rows of the dataframe.\",\" Display the first few rows of each dataframe to understand the data\",\" Display the first few rows of each dataframe to understand the data\",\"Display the first few records of each dataframe to understand the data\",\"Display the first few rows of each dataframe to get an understanding of the data\",\" Visualize the first few rows of each dataframe to understand the data\",\"Display the first few rows of the dataframes to get an understanding of the data\",\"Display the first row of the dataframe.\",\"Display the first few rows of each dataframe to understand the data\",\"Display the first few rows of each dataframe to inspect the data.\",\"Shows the first few rows of each dataframe.\",\"Display the first few rows of each dataframe to understand the data\",\" Display the first few rows of each dataframe to get an overview of the data\",\"Visualize the first few rows of each dataframe to understand the data\",\"display first few rows of each dataframe to understand the data\",\"Display the first few rows of each DataFrame to understand the data.\",\" Display the first few rows of each dataframe to understand the data\",\"Display the first few rows of each dataframe to understand the data\",\"Display the first few rows of each dataframe to understand the data\",\" Load the data and display the first few rows of each dataframe\",\"Display the first few rows of each dataframe to understand the data\",\"Display the first few rows of each dataframe to understand the data\",\"Display the first few rows of each dataframe to understand the data\",\"Display the first few rows of each dataframe\",\"Display the first few rows of each dataframe to understand the data\",\"Display first few rows of each dataframe to understand the data\",\"Display the first few rows of each dataframe to understand the data\",\"Display the first few rows of each dataframe to understand the data\",\"Display the first, (2-30)mn, and last entries of the dataframe.\",\"display all the loaded dataframes with first rows\",\" Display the first few rows of each dataframe to understand the data\",\"Display the first few rows of each dataframe to get an understanding of the data\",\" Display the first few rows of the dataframe to understand the data\",\"Display the first few records in each dataframe to understand the data\",\" Show the initial records from the dataframe.\",\"Display the first few rows of each DataFrame to get an idea of the data\",\" Show at least the beginning of each dataframe to understand the data\",\"Show the first few rows of each dataframe to get an overview of the data\",\" Display the first few rows of each dataframe to understand the data\",\"Display the first few rows of each dataframe to understand the data\",\" Print the first few rows of each dataframe to understand the data\",\"Show the first few rows of each dataframe\",\"Display the first few rows of each dataframe to get an idea of the data\",\"Print the first few rows of each dataframe to understand the data\",\"Now let's print the first few rows of each dataframe to see what's inside\"],\"marker\":{\"opacity\":0.5,\"size\":5},\"mode\":\"markers+text\",\"name\":\"10_Understanding Dataframes with First Few Rows Displayed\",\"text\":[\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\"],\"textfont\":{\"size\":12},\"x\":[13.010359764099121,12.524880409240723,13.082053184509277,12.675665855407715,12.976920127868652,12.77717399597168,12.901308059692383,12.852404594421387,11.859050750732422,12.214766502380371,12.945199966430664,12.566920280456543,12.31920337677002,12.446290016174316,12.217259407043457,13.004875183105469,12.372610092163086,12.904027938842773,12.79751205444336,12.542999267578125,12.003744125366211,12.564705848693848,12.427963256835938,12.834185600280762,13.006380081176758,12.653243064880371,13.10798454284668,12.784828186035156,12.790877342224121,12.710186004638672,12.642143249511719,12.291383743286133,12.349766731262207,12.598901748657227,12.757155418395996,12.8806734085083,12.691438674926758,12.38926887512207,13.282010078430176,12.600411415100098,12.792278289794922,12.837348937988281,12.959332466125488,12.80289363861084,12.584098815917969,12.716550827026367,12.643904685974121,13.055316925048828,13.024945259094238,12.660585403442383,12.142077445983887,12.970359802246094,12.997664451599121,12.936200141906738,12.68989372253418,12.877443313598633,12.54828929901123,13.24392032623291,12.34019660949707,12.763195991516113,13.071388244628906,12.842597961425781,12.670543670654297,12.443154335021973,13.044761657714844,12.54032039642334,12.452105522155762],\"y\":[-11.109241485595703,-8.307990074157715,-11.035774230957031,-11.202068328857422,-10.608720779418945,-10.66584300994873,-11.061117172241211,-10.506575584411621,-9.562581062316895,-9.616409301757812,-11.08629322052002,-9.791044235229492,-10.184419631958008,-11.413702964782715,-10.088379859924316,-10.462552070617676,-9.796263694763184,-9.402887344360352,-9.948667526245117,-9.75090217590332,-10.120366096496582,-10.628300666809082,-9.997564315795898,-10.997724533081055,-10.916991233825684,-9.767196655273438,-10.294232368469238,-9.655686378479004,-10.010845184326172,-10.059736251831055,-10.900270462036133,-9.134149551391602,-9.589689254760742,-10.813193321228027,-10.235795021057129,-9.780975341796875,-10.940707206726074,-10.251581192016602,-11.024933815002441,-10.947487831115723,-11.025437355041504,-9.588639259338379,-10.872228622436523,-10.829110145568848,-10.786100387573242,-10.143860816955566,-10.522546768188477,-10.548273086547852,-10.866783142089844,-10.701800346374512,-9.744096755981445,-9.066267967224121,-10.679451942443848,-10.341646194458008,-10.593771934509277,-9.813558578491211,-8.971330642700195,-9.870323181152344,-10.130420684814453,-10.40494155883789,-10.734749794006348,-10.511124610900879,-11.247507095336914,-10.303812980651855,-9.938645362854004,-11.192855834960938,-11.095470428466797],\"type\":\"scattergl\"},{\"hoverinfo\":\"text\",\"hovertext\":[\" Create a directory for storing the plots\\nif not os.path.exists('plots'):\\n    os.makedirs('plots')\",\" Set TreeTagger directory\\nos.environ['TREETAGGER_HOME'] = '\\u002fusr\\u002flocal\\u002fCellar\\u002ftreetagger\\u002f3.2.2\\u002f'\",\"Helper function configparser\\ndef get_project_path():\\n    # Get the path to the main project folder\\n    dir_path = os.path.dirname(os.path.realpath(__file__))\\n    return os.path.abspath(os.path.join(dir_path, os.pardir))\",\"path to save outputs\\noutput_path = 'output\\u002f'\",\"Create a directory to save the output figures\\nif not os.path.exists('output'):\\n    os.makedirs('output')\",\"Create an output folder to store images\",\"Set CWD to current folder\\nos.chdir(os.path.dirname(os.path.abspath(__file__)))\",\"ensure data\\u002fsimpsons folder exists\\nif not os.path.exists('data\\u002fsimpsons'):\\n    print('Creating directory data\\u002fsimpsons')\\n    os.makedirs('data\\u002fsimpsons')\",\"Create a directory to store the processed data if it does not exist\\nif not os.path.exists('processed_data'):\\n    os.mkdir('processed_data')\",\" Creating data folder if it doesn't exist\\nif not os.path.exists('data'):\\n    os.makedirs('data')\",\"Locating the path of the current file\",\"Create temporary files folder if it doesn't exist\\ntemp_folder = '.\\u002fdata\\u002ftmp'\\nos.makedirs(temp_folder, exist_ok=True)\",\"Path to save results\\nresults_path = \\\"results\\\"\",\"Change directory to parent\\nos.chdir(os.pardir)\",\"Create new directory to save images if it doesn't exists\\nimg_dir = 'images'\\nif not os.path.exists(img_dir):\\n    os.makedirs(img_dir)\",\"Create a directory to store images if it does not exist\\nimg_dir = 'images'\\nif not os.path.exists(img_dir):\\n    os.makedirs(img_dir)\",\"Add custom functions' directory to the path\\nmodule_dir = os.path.join(os.path.abspath(''), 'preprocessing')\\nsys.path.insert(0, module_dir)\",\"Create a 'simpsons' folder if it doesn't exist\\nif not os.path.exists('simpsons'):\\n    os.makedirs('simpsons')\",\"# Create .\\u002fplots directory if it does not exist\\nif not os.path.exists('.\\u002fplots'):\\n    os.makedirs('.\\u002fplots')\",\"Create output directory if it does not exist\\noutput_dir = 'output'\\nif not os.path.exists(output_dir):\\n    os.makedirs(output_dir)\",\"Path for exported data\\noutput_data_path = 'output_data\\u002f'\",\"Set path to save files\\nimg_path = 'data\\u002fimg\\u002f'\",\"Configure workspace\\nos.makedirs('images', exist_ok=True)\",\" Set working directory\\nos.chdir('..')\",\"reate a directory to save text data\\ndirectory = 'data\\u002ftext_data'\\nif not os.path.exists(directory):\\n    os.makedirs(directory)\",\"Create a data folder if it doesn't exist\\nif not os.path.exists('data'):\\n    os.makedirs('data')\",\" Define the directory with NLP models and create a backup.\\nnlp_dir = '.\\u002fnlp'\\nif os.path.isdir(nlp_dir):\\n    !mv $nlp_dir $nlp_dir'_backup'\",\"Create path to save figures\\nimg_path = 'images'\\n# Create the directory if it does not exist\\nif not os.path.exists(img_path):\\n    os.makedirs(img_path)\",\"We then specify where data will be saved\\nsave_dir = 'image_outputs'\\n\\n# Make the directory if it doesn't exist\\nos.makedirs(save_dir, exist_ok=True)\",\"Create a directory to save outputs\\nif not os.path.exists('outputs'):\\n    os.makedirs('outputs')\",\" Creating folder to save images\",\"Work directory\\nprint(\\\"Current working directory\\\", os.getcwd())\",\"Specify an output location for any saved data.\",\"Make a directory to save the figures\\nif not os.path.exists('figures'):\\n    os.makedirs('figures')\",\" Create directory for figures if it doesn't exist\\nif not os.path.exists('figures'):\\n    os.makedirs('figures')\",\"create directory for storing output\\noutput_dir = 'output'\\n\\n# Ensure the output directory exists\\nif not os.path.exists(output_dir):\\n    os.makedirs(output_dir)\",\"Working directory\\nos.chdir('\\u002fmnt\\u002fdata')\",\"Create a directory to save the visualization results\\nif not os.path.exists('visualizations'):\\n    os.makedirs('visualizations')\",\"if not os.path.exists('figures'):\\n    os.makedirs('figures')\",\"Save path to get product of current working directory and folder the script is placed in.\",\"Create out directory if it doesn't exist\\nif not os.path.exists('out'):\\n    os.makedirs('out')\",\" Create directory for saving generated visualisations\\nif not os.path.exists('visualizations'):\\n    os.makedirs('visualizations')\",\"Create folder to save images\",\"Create directory for generated output\\noutput_dir = 'output'\\nos.makedirs(output_dir, exist_ok=True)\",\" Make the data directories if they do not exist\\nos.makedirs('data', exist_ok=True)\",\"Set the directory for saving\\u002floading the plot data.\",\"# Create path\\nif not os.path.exists('images\\u002f'):\\n    os.makedirs('images\\u002f')\",\"Create the necessary folders if they do not exist\\nfolders = ['images', 'models', 'data\\u002fpreprocessed']\\nfor f in folders:\\n    if not os.path.exists(f):\\n        os.makedirs(f)\",\"#   Changing path to be in the script_files directory to use functions from the .py files\\nos.chdir(\\\"script_files\\\")\",\"# Create \\\"simpsons\\\" folder\\nif not os.path.exists('simpsons'):\\n    os.mkdir('simpsons')\",\"Ensure working directory is correct\\nos.getcwd()\",\"Set up directories for output\\nimgdir = os.path.normpath('visualizations\\u002f')  # directory to save images\\nos.makedirs(imgdir, exist_ok=True)\",\" Check that directories exists or create them\\ntry:\\n    for directory in ['images', 'vocabulary', 'dataframes']:\\n        os.makedirs(directory)\\nexcept FileExistsError:\\n    print(\\\"Directories already exist\\\")\",\"Create a directory to store the images if it does not exist\\nif not os.path.exists('images'):\\n    os.makedirs('images')\",\"Isolate the environment to only a select few directories for only python code to be executed\",\"Create the 'simpsons' directory if it doesn't exist\\nif not os.path.exists('simpsons'):\\n    os.makedirs('simpsons')\",\"Check if the path exists\\nif not os.path.exists('images'):\\n    os.makedirs('images')\",\"Check if the folder does not exists, create it\",\"Create a directory to save the plots\\nos.makedirs('plots', exist_ok=True)\",\" Custom\\nos.makedirs(\\\"results\\\", exist_ok=True)\",\"Path to the output directory\\nOUTPUT_DIR = 'output'\",\"Root path\\nROOT = os.getcwd()\",\"Image folder\\nIMG_FOLDER = 'images'\",\"Create a directory to save the output files\\noutput_dir = 'output'\\nif not os.path.exists(output_dir):\\n    os.makedirs(output_dir)\",\"Create save directory if it doesn't exist\\nif not os.path.exists('plots'):\\n    os.mkdir('plots')\",\"Create directory to save figures if it doesn't exist\\nif not os.path.exists('figures'):\\n    os.mkdir('figures')\"],\"marker\":{\"opacity\":0.5,\"size\":5},\"mode\":\"markers+text\",\"name\":\"11_Creating Directories\",\"text\":[\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\"],\"textfont\":{\"size\":12},\"x\":[17.65693473815918,15.833362579345703,15.436236381530762,16.784679412841797,17.073486328125,16.418365478515625,15.605481147766113,15.154203414916992,16.1234188079834,15.607745170593262,15.897902488708496,15.563977241516113,16.460634231567383,15.567059516906738,16.639616012573242,16.743419647216797,15.36894702911377,15.598187446594238,17.358131408691406,15.952568054199219,16.290647506713867,16.622852325439453,16.814443588256836,15.576421737670898,15.721208572387695,15.633804321289062,15.790721893310547,16.600191116333008,16.637035369873047,16.640178680419922,16.709327697753906,15.951027870178223,16.4030704498291,17.414634704589844,17.28006362915039,16.152128219604492,15.751667976379395,17.449810028076172,17.0140438079834,15.811704635620117,15.911742210388184,17.276546478271484,16.782625198364258,16.294944763183594,15.874347686767578,17.529752731323242,16.378658294677734,16.01397132873535,15.032100677490234,15.401869773864746,15.84676742553711,17.075763702392578,16.269380569458008,16.69016456604004,15.512803077697754,15.396402359008789,16.527902603149414,15.680052757263184,17.77994728088379,16.09758949279785,16.366565704345703,16.123743057250977,16.790573120117188,16.217615127563477,17.6577091217041,17.300045013427734],\"y\":[3.5211269855499268,4.0142502784729,3.6501965522766113,3.7052204608917236,3.8507742881774902,4.334228038787842,4.031004428863525,4.5899176597595215,4.722072601318359,4.6684794425964355,3.1459455490112305,4.384246826171875,3.7428205013275146,3.8045711517333984,4.592564105987549,4.338291168212891,3.8953511714935303,4.505226135253906,3.8174173831939697,4.440389156341553,3.1520845890045166,4.0729475021362305,4.245401382446289,3.565551280975342,5.01722526550293,4.5082316398620605,5.616588592529297,4.297693252563477,4.108931541442871,4.0562520027160645,4.612541675567627,3.503251075744629,3.4278976917266846,4.2090840339660645,4.286542892456055,4.042245388031006,3.187302350997925,3.6439850330352783,4.361613750457764,3.7424886226654053,4.520046710968018,3.6815218925476074,4.438872337341309,4.177871227264404,4.580245018005371,3.069507598876953,4.406288146972656,4.898395538330078,4.0365824699401855,4.251542568206787,3.3691115379333496,4.17553186416626,4.473618507385254,4.350691318511963,4.175148963928223,4.296224117279053,4.295825481414795,3.6075589656829834,3.4284508228302,4.106326103210449,3.8805348873138428,3.7026500701904297,4.00183629989624,4.125606536865234,3.647691249847412,4.139649868011475],\"type\":\"scattergl\"},{\"hoverinfo\":\"text\",\"hovertext\":[\" Set pandas options to not truncate columns when printing\\npd.set_option('display.max_colwidth', -1)\",\"SEt default display parameters for pandas\\npd.set_option('display.max_columns', None)\\npd.set_option('display.width', 1000)\",\"Set the pandas display options for long strings, so they are properly displayed\\npd.set_option('display.max_colwidth', None)\",\"Set pandas display options to show full column width\\npd.set_option('max_colwidth', None)\",\"Set correct display options for Pandas dataframes\\npd.set_option('display.max_columns', None)\\npd.set_option('display.max_rows', None)\\npd.set_option('display.width', 200)\",\"Set pandas print options to make it more human friendly\\npd.set_option('display.max_columns', 500)\\npd.set_option('display.max_rows', 30)\\npd.set_option('display.max_colwidth', None)\",\"Customisation\\n# Set pandas display options\\npd.set_option('display.max_rows', 5)\\npd.set_option('display.max_columns', 500)\\npd.set_option('display.width', 1000)\",\"Set pandas display options for easier exploration\\npd.set_option('display.max_columns', None)\\npd.set_option('display.max_colwidth', None)\",\" Set decimal precision for pandas dataframes\\npd.set_option('display.float_format', lambda x: '%.3f' % x)\",\"Set the pandas display options for broader coverage\\n# Also, disable the SettingWithCopyWarning (not good, but our code uses original dataframe)\\npd.set_option('display.max_rows', 300)\\npd.set_option('display.max_columns', 300)\\npd.set_option('display.width', 1000)\\npd.set_option('mode.chained_assignment', None)\",\"Set pandas to display long text\\npd.set_option('display.max_colwidth', -1)\",\" Set max column width for dataframes to 1000\\npd.set_option('display.max_colwidth', 1000)\",\"Set pandas table display configurations to get a better look at the data\\npd.set_option('display.max_columns', None)\\npd.set_option('display.max_rows', None)\\npd.set_option('display.max_colwidth', None)\",\"Set up the print format so that we can see full dataframes rather than truncated versions\\npd.set_option('display.max_colwidth', None)\",\"Display full dataframe info\\npd.set_option('display.max_rows', None)\\npd.set_option('display.max_columns', None)\\npd.set_option('display.width', None)\\npd.set_option('display.max_colwidth', -1)\",\"Set the dataframe lenght display at its maximum value\",\" Additional customization - Ensure pandas displays column info fully\\npd.set_option('display.max_colwidth', None)\",\"Set the precision for Pandas\\npd.set_option('precision', 2)\",\"Display full columns in dataframes\\npd.set_option('display.max_colwidth', None)\",\"Set pandas to display wide columns\\npd.set_option('display.max_colwidth', None)\",\" Display full DataFrame width\\npd.set_option('display.max_colwidth', None)\",\"Set pandas to display long text\\npd.set_option('display.max_colwidth', -1)\",\"Set maximum number of columns displayed in pandas\\npd.set_option('display.max_columns', 500)\\npd.set_option('display.width', 1000)\",\"Set pandas display options for easier viewing\\npd.set_option('max_columns', 50)\\npd.set_option('max_colwidth', 100)\",\"Set the pandas options to visualize the dataset\\npd.set_option('display.max_columns', None)\\npd.set_option('display.max_colwidth', None)\",\"Set some configuration options for pandas in order to display data more aesthetically.\\npd.set_option('display.max_rows', 500)\\npd.set_option('display.max_columns', 500)\\npd.set_option('display.width', 1000)\",\"Set pandas to display wider columns, and lower the number of rows to display for brevity\\npd.options.display.max_colwidth = 100\\npd.options.display.max_rows = 10\",\"Set display options for pandas dataframes to ensure rows and columns are not truncated\\npd.set_option('display.max_rows', None)\\npd.set_option('display.max_columns', None)\",\"allow us to display large string in our dataframes\\npd.options.display.max_colwidth = 200\",\"Set display options for Pandas to display nicely\\npd.set_option('display.max_columns', None)\\npd.set_option('display.expand_frame_repr', False)\\npd.set_option('max_colwidth', -1)\",\"set max column with of pandas\\npd.set_option('display.max_colwidth', 800)\",\" Turn off scientific notation for pandas\\npd.set_option('display.float_format', lambda x: '%.3f' % x)\",\"Display pandas without truncation\\npd.set_option('display.max_colwidth', None)\",\"Setting up pandas so we can see the data in a nice tabular fashion (with scrolling)\\npd.set_option('display.max_columns', None)\\npd.set_option('display.expand_frame_repr', False)\\npd.set_option('max_colwidth', -1)\",\"Set the following configurations to avoid truncating DataFrame display (optional)\\npd.set_option('display.max_columns', None)\\npd.set_option('display.max_rows', None)\",\" Set the dataframe display option to show the full content of the cells\\npd.set_option('display.max_colwidth', None)\",\" Set all pandas outputs to be displayed completely\\npd.set_option('display.max_rows', None)\\npd.set_option('display.max_columns', None)\\npd.set_option('display.width', None)\\npd.set_option('display.max_colwidth', None)\",\"Set the max width of columns to display for dataframes\\npd.set_option('display.max_colwidth', 500)\",\"Limit number of float output to 3 decimal points\\npd.set_option('display.float_format', lambda x: '%.3f' % x)\",\"Pandas option for column width\\npd.set_option('display.max_colwidth', -1)\",\"Set pandas to display wide tables properly\\npd.set_option('display.max_columns', 500)\",\"Set options for pandas\\npd.set_option('display.max_columns', 500)\\npd.set_option('display.max_colwidth', 500)\",\"Safety measure to prevent truncation of long string columns\\npd.options.display.max_colwidth = 100\",\"Set display options for pandas dataframes\\npd.options.display.max_columns = None\\npd.set_option('display.float_format', lambda x: '%.3f' % x)\",\"Set the pandas display options for better visualisation of the DataFrames\\npd.set_option('display.max_columns', None)\\npd.set_option('max_colwidth', None)\",\" Setting display options for pandas to display the entire dataframe and prevent value truncating\\npd.set_option('display.max_colwidth', None)\\npd.set_option('display.max_rows', None)\\npd.set_option('display.max_columns', None)\",\"Display settings for the pandas dataframes\\npd.set_option('display.max_columns', 500)\\npd.set_option('display.width', 1000)\",\" Ensure that pandas will display at least 500 characters in a column\\npd.set_option('display.max_colwidth', 500)\",\"Set pandas display options for better data visualization\\npd.options.display.max_columns = None\\npd.options.display.max_rows = None\\npd.options.display.max_colwidth = 1000\",\"# Display settings for pandas dataframes\\npd.set_option('display.max_columns', None)\\npd.set_option('display.width', 1000)\",\"set pandas to display wide data tables in full to make it easier to understand the data\\npd.set_option('display.max_columns', None)\",\" To display the whole content of the dataframe without being cut off\\npd.set_option('display.max_colwidth', -1)\",\"Set pandas display options for better visualisation\\npd.set_option('display.max_columns', 500)\\npd.set_option('display.width', 1000)\",\"Set pandas display options for easier visualization of our datasets\\npd.set_option('display.max_columns', None)\\npd.set_option('display.max_colwidth', None)\",\"Set options for pandas to display dataframes in a readable way\\npd.set_option('display.max_rows', None)\\npd.set_option('display.max_columns', None)\\npd.set_option('display.width', None)\\npd.set_option('display.max_colwidth', -1)\",\"Set output dataframe display to show entire content\\npd.set_option(\\\"display.max_columns\\\", None)\\npd.set_option(\\\"display.max_colwidth\\\", -1)\",\" Set float format for better readability\\npd.options.display.float_format = '{:,.2f}'.format\",\"Prevent the truncated display of dataframes|# Remove the display truncation for dataframes\\npd.set_option('display.max_colwidth', None)\",\"Set the pandas column display options to see the longer text.\\npd.set_option('display.max_colwidth', 100)\",\"Set some options for Pandas to display data.frames\\npd.set_option('display.max.columns', None)\\npd.set_option('display.max_colwidth', None)\",\"Set some pandas display options for better visualizations\\npd.set_option('display.max_columns', 50)\\npd.set_option('display.max_colwidth', 100)\\npd.set_option('display.max_rows', 50)\",\"Set pandas to display wide data\\npd.set_option('display.max_colwidth', None)\",\" Allow pandas to display the full content of a column\\npd.set_option('display.max_colwidth', None)\",\"utils and settings\\ntqdm.pandas()\\npd.set_option('display.max_colwidth', 150)\",\" Set maximum column width when displaying dataframes\\npd.set_option('display.max_colwidth', 80)\",\" Set the max display width and max display rows for pandas dataframes\\npd.set_option('display.max_colwidth', 300)\\npd.set_option('display.max_rows', 300)\"],\"marker\":{\"opacity\":0.5,\"size\":5},\"mode\":\"markers+text\",\"name\":\"12_Setting pandas display options for wide columns and long strings\",\"text\":[\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\"],\"textfont\":{\"size\":12},\"x\":[23.0421142578125,22.66176986694336,23.487998962402344,23.040111541748047,22.562620162963867,22.754409790039062,23.435604095458984,22.55929946899414,22.367101669311523,22.44292640686035,23.256309509277344,23.54975700378418,22.369932174682617,22.074670791625977,22.0610408782959,23.0435791015625,23.056425094604492,22.126197814941406,22.553293228149414,22.95974349975586,22.567672729492188,23.438886642456055,23.03443717956543,22.995248794555664,22.174991607666016,23.129058837890625,22.653108596801758,21.817028045654297,23.58877944946289,23.24575424194336,23.435871124267578,22.316007614135742,22.507396697998047,22.885744094848633,21.78334617614746,22.62200927734375,22.362123489379883,23.339214324951172,22.65660285949707,22.866437911987305,22.63505744934082,23.225234985351562,23.712444305419922,22.02301788330078,22.051774978637695,22.11016845703125,23.28049087524414,23.144433975219727,22.334138870239258,23.10308074951172,21.881385803222656,22.572391510009766,23.252687454223633,22.05014991760254,21.885854721069336,22.5601749420166,22.970760345458984,22.068254470825195,23.465234756469727,22.395389556884766,22.6964111328125,22.714853286743164,22.855045318603516,23.1685733795166,23.187509536743164,23.116374969482422],\"y\":[2.7650387287139893,1.825711965560913,3.058105707168579,3.0474448204040527,2.031419277191162,1.7080371379852295,1.894666314125061,2.3488571643829346,2.437234878540039,1.6254594326019287,3.239236354827881,2.2595345973968506,1.9342215061187744,2.726616382598877,1.6323142051696777,1.4441843032836914,2.8358144760131836,2.5766851902008057,2.5233426094055176,2.7672717571258545,2.4094769954681396,3.1412668228149414,1.7023248672485352,2.265523672103882,2.653333902359009,1.9232635498046875,1.728286862373352,1.9680790901184082,2.8026628494262695,1.7376693487167358,2.38372540473938,2.5643601417541504,2.820002317428589,2.0105905532836914,1.5782231092453003,2.9417057037353516,2.4888710975646973,2.595764398574829,2.4010045528411865,3.0168097019195557,1.5255722999572754,2.4131524562835693,2.930487632751465,1.921116590499878,2.4361863136291504,2.138465642929077,1.946132779121399,3.080073595046997,1.9258371591567993,2.1564764976501465,1.2501312494277954,2.4462063312530518,1.7538968324661255,2.507784128189087,2.0027849674224854,2.3319084644317627,2.185009002685547,2.482898473739624,3.2175002098083496,2.1557724475860596,1.9251636266708374,2.9307403564453125,2.6300089359283447,2.6062285900115967,2.404099702835083,1.807302474975586],\"type\":\"scattergl\"},{\"hoverinfo\":\"text\",\"hovertext\":[\"Explore the data from df_characters dataframe\",\"Display the loaded dataframes\\ndf_characters\",\"Display basic info of df_characters\\ndf_characters.info()\",\"Display lines from the df_characters dataframe.\",\"View data shape and general info\\ndf_characters.shape\",\"Display dataframe info\\ndf_characters.info()\",\"List of characters as a set and list\\nset_characters = set(df_characters['character'].values)\\nlst_characters = list(set_characters)\",\"\\ndf_characters['raw_character_text']\",\"Display the dataframes' content\\ndf_characters\",\"\\ndf_characters\",\"Display the characters dataframe\\ndf_characters\",\"View all available columns in the characters dataframe\\ndf_characters.columns\",\"DataFrame's info\\ndf_characters.info()\",\"\\nprint(df_characters)\",\"Columns from the df_characters Dataframe\\nprint(df_characters.columns)\",\"Extracting df_characters subcolumns and reseting the index\",\" Show info about the characters dataframe\\ndf_characters.info()\",\" Explore the content of the characters' dataframe\\ndf_characters.info()\",\"View general information about our datasets\\nprint('\\\\nInformation about the characters dataset:')\\ndisplay(df_characters.info())\",\" Sample the characters dataframe\\ndf_characters.sample(10)\",\"Inspect the contents of df_characters dataframe\",\"Inspect df_characters\",\"display(df_characters)\",\"Display some basic information about the characters dataframe\\ndf_characters.info()\",\"Select your favourite character\\ndf_characters['character'].values\",\"Check the info of df_characters\\ndf_characters.info()\",\"# Number of characters\\ndf_characters.shape[0]\",\"The first dataframe (df_characters) holds all the characters and their metadata.\",\"\\n# let's remind ourselves what's in the data.\\nprint(df_characters.keys())\",\" Display the dataframes to understand their structure and contents\\ndf_characters\",\"Check the result\\ndf_characters\",\"df_characters.info()\",\" Data overview\\ndf_characters.info()\",\"Display most important columns\\nprint(df_characters.info())\",\" Look at several random rows in the characters DataFrame\\nprint(df_characters.sample(5))\",\"Explore the structure of the characters dataframe\\nprint(df_characters.info())\",\"Print basic information on the characters dataset\\ncharacters_info = df_characters.info()\",\"Display the basic information of characters dataset\\ndf_characters.info()\",\"Inspect the characters dataframe to understand its structure and contents\\ndf_characters.info()\",\"\\nprint(\\\"Characters Dataset:\\\")\\nprint(df_characters)\",\"Display a sample of each dataframe\\ndf_characters.sample(5)\",\"Check basic info about characters DataFrame\\ndf_characters.info()\",\" Display information for the characters dataset\\ndf_characters.info()\",\"General information about the character dataset\\nprint(df_characters.shape)\\nprint(df_characters.columns)\\nprint(df_characters.dtypes)\",\"Display the dataset samples\\ndf_characters.sample(5)\",\"Set the character_name to be the index of df_characters\",\"Display the character dataframe\\ndf_characters\",\"Display basic information about the loaded datasets\\nprint('\\\\nCHARACTERS')\\ndisplay(df_characters.info())\\ndisplay(df_characters.head(5))\",\"Inspect \\\"df_characters\\\" DataFrame\",\"Sample the data to have a look at their structure\\ndf_characters.sample(5)\",\"View DataFrame info\\ndf_characters.info()\",\"Inspect data types and missing values\\ndf_characters.info()\",\" Display information about the characters dataframe\\nprint(df_characters.info())\",\" Display the information about the characters dataframe\\ndf_characters.info()\",\"Inspect data columns and types\\nprint(df_characters.dtypes)\",\"Inspecting the data\\ndf_characters.info()\",\"Checking df_characters dataframe\",\" Display summary information for the characters dataset\\nprint('Characters dataset:')\\nprint(f'- Number of rows: {len(df_characters)}')\\nprint('- Columns:', list(df_characters.columns))\",\"Inspecting the first three rows of the df_characters dataframe.\",\"Display the characters dataframe\\ndf_characters\",\" Display basic information about the characters dataset\\nprint(df_characters.info())\",\"type(df_characters)\",\"Check the contents of df_characters dataframe\",\"Print info of the characters dataframe\\nprint(df_characters.info())\",\" Simply display the dataframes to understand their structure and contents\\ndf_characters\"],\"marker\":{\"opacity\":0.5,\"size\":5},\"mode\":\"markers+text\",\"name\":\"13_Displaying Information about the Characters DataFrame\",\"text\":[\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\"],\"textfont\":{\"size\":12},\"x\":[7.567188262939453,7.092046737670898,7.4906134605407715,7.03456449508667,6.684723854064941,7.768560409545898,6.809349060058594,6.688868999481201,7.607017993927002,6.5586466789245605,7.208131790161133,7.362772464752197,7.785606861114502,6.581697463989258,7.188767433166504,6.468541622161865,7.730262756347656,7.42460823059082,7.075813293457031,7.2919769287109375,7.5263190269470215,6.926621913909912,6.944799900054932,7.69827938079834,6.779422283172607,6.728144645690918,6.8976287841796875,7.033864974975586,6.550182342529297,7.672935962677002,6.764157772064209,7.121516704559326,7.056427478790283,7.403101921081543,8.220620155334473,7.45208215713501,7.0969038009643555,7.354236125946045,7.39465856552124,6.836696624755859,7.448852062225342,7.508607387542725,7.316623210906982,6.472046852111816,6.399533271789551,6.166261672973633,7.112366676330566,6.9651947021484375,7.560055255889893,6.4983649253845215,7.683889865875244,6.9551005363464355,7.357418537139893,7.504552841186523,6.674833297729492,6.912323474884033,7.292754650115967,6.678565979003906,8.341873168945312,7.066532135009766,7.18506383895874,6.405509948730469,7.265987396240234,7.342921257019043,7.508925437927246],\"y\":[12.211292266845703,12.07146167755127,12.910572052001953,13.102954864501953,13.531496047973633,12.821991920471191,11.432639122009277,10.549638748168945,12.508862495422363,11.897014617919922,12.32730484008789,11.710076332092285,13.025724411010742,12.297916412353516,11.621121406555176,10.727657318115234,13.21881103515625,12.711365699768066,13.595746994018555,13.143854141235352,12.202445983886719,12.76993465423584,12.03187084197998,13.245318412780762,10.763227462768555,12.98343276977539,11.409211158752441,13.847525596618652,13.469429969787598,12.352009773254395,12.414594650268555,12.363288879394531,12.922662734985352,13.600790977478027,11.317946434020996,13.485296249389648,13.040549278259277,13.097052574157715,13.081503868103027,12.791043281555176,11.162324905395508,13.126809120178223,12.925660133361816,13.602490425109863,13.044415473937988,10.602228164672852,12.044930458068848,13.901837348937988,12.258805274963379,12.794867515563965,13.304679870605469,12.367602348327637,13.60189437866211,12.89428424835205,12.470972061157227,12.789647102355957,12.444726943969727,13.762336730957031,12.702468872070312,12.266827583312988,13.379243850708008,12.111680030822754,11.895686149597168,13.20230484008789,12.220208168029785],\"type\":\"scattergl\"},{\"hoverinfo\":\"text\",\"hovertext\":[\"Remove rows with missing values in the script and characters DataFrames\\ndf_script.dropna(inplace=True)\\ndf_characters.dropna(inplace=True)\",\"# Some pre-processing\\ndf_script = df_script.dropna(subset=['normalized_text'])\",\"Remove script lines without character, location, or raw text\\ndf_script = df_script.dropna(subset=['character_id', 'location_id', 'raw_text']).reset_index(inplace=False, drop=True)\",\"# We set the custom null value '???' as standard NaN. We also fix the characters_id datatype\\ndf_script['character_id'] = pd.to_numeric(df_script['character_id'], errors='coerce')\\ndf_script['character_id'] = df_script['character_id'].fillna(-1).astype(int)\",\" Drop the first data in the df_characters dataframe as it is just a row of NaN values.\",\"Removing rows with empty or NaN values in the 'normalized_text' column\\ndf_script = df_script.dropna(subset=['normalized_text']).reset_index(inplace=False, drop=True)\",\"Drop all the na entries from the script, characters and location dataframes\",\" Due to the size of the dataset, we will drop rows with missing values in the following columns: `script`, `character_id`, `location_id`, and `raw_text`.\",\"Discard rows with NaN values in the normalized_text column\\ndf_script = df_script.dropna(subset=['normalized_text'])\",\"Clean df_characters\\ndf_characters = df_characters.dropna()\",\"Clean encountered NaN in raw data\\ndf_script_clean = df_script.dropna(subset=['raw_text']).reset_index(drop=True)\",\"Remove rows where character id or locations are missing\\ndf_script = df_script.dropna(subset=['character_id', 'location_id'])\",\"Drop lines where either character or location is missing, and keep only id, character and location columns\\ndf_script = df_script.dropna(subset=['character_id', 'location_id']).reset_index(inplace=False, drop=True).loc[:, ['id', 'character_id', 'location_id']]\",\"# remove missing values\\ndf_script = df_script.dropna()\",\"Preprocessing\\n# Removing rows where the 'normalized_text' column is NaN\\ndf_script = df_script.dropna(subset=['normalized_text'])\",\" Remove columns with too many missing values\\ndf_script.drop(columns=['alignment', 'raw_text'], inplace=True)\",\"drop nan values\\ndf_script = df_script.dropna(subset=['character_id', 'location_id', 'normalized_text'])\",\"Dropping rows with missing values on 'raw_character_text' column\\ndf_script.dropna(subset=['raw_character_text'], inplace=True)\",\" Remove rows with empty script lines\\ndf_script = df_script.dropna(subset=['raw_text']).reset_index(inplace=False, drop=True)\",\"Clean up NaN values\\ndf_script = df_script.dropna(subset=['raw_text'])\",\" clean script df\\ndf_script_clean = df_script.dropna(subset=['raw_text'])  # Remove rows with NaN in 'raw_text' column\",\"remove rows with empty \\\"normalized_text\\\" column\\ndf_script = df_script.dropna(subset=['normalized_text'])\",\"# Remove empty lines\\ndf_script = df_script.dropna(subset=['raw_text'])\",\"Drop rows with missing data from the df_script dataframe\\ndf_script.dropna(inplace=True)\",\"Remove lines without any text in them.\\ndf_script = df_script.dropna(subset=['normalized_text'])\",\"Clean the NaNs\\ndf_script = df_script.dropna(subset=['raw_text'])\",\"Remove rows with missing script data\\ndf_script = df_script.dropna(subset=['normalized_text'])\",\"Remove records with missing script data\\ndf_script = df_script.dropna(subset=['raw_text'])\\n\\n# Show resulting statistics to ensure records were removed\\ndf_script.info()\",\"Drop lines without any character or dialogue\\ndf_script = df_script.dropna(subset=['character_id', 'raw_text'])\",\" Remove NaN values from 'text' column of df_script\\ndf_script = df_script[df_script['text'].notna()].reset_index(inplace=False, drop=True)\",\" Remove rows with missing information in the script dataset\\ndf_script.dropna(subset=['normalized_text', 'raw_text', 'word_count'], inplace=True)\",\"Drop rows with NaN\\ndf_script = df_script.dropna(subset=['character_id', 'location_id'])\",\"Remove Simpsons\\u2019 lines with empty text\\ndf = df_script.copy()\\ndf.dropna(subset=['normalized_text'], inplace=True)\",\"Remove NA values in speaking line column\\ndf_script = df_script.dropna(subset=['Normalized_text']).reset_index(inplace=False, drop=True)\",\" Preprocess script dataframe\\ndf_script = df_script.dropna(subset=['normalized_text'])  # Keep only non-NA values in the dataframe\\ndf_script = df_script[df_script.normalized_text != '']  # Keep only non-empty values in the dataframe\",\"preprocessing\\ndf_script = df_script.dropna(subset=['character_id', 'location_id'])\",\" Remove the empty lines\\ndf_script = df_script[df_script[\\\"raw_character_text\\\"].notna()].reset_index(inplace=False, drop=True)\",\"\\n# We drop the lines without quoting character\\ndf_script = df_script.drop(df_script[df_script.raw_character_text.isna()].index)\",\" Drop lines containing unwanted data from df_script\\n# Check elements to be removed\\ndf_script.replace('\\\\\\\\N','')\",\"Drop rows where one element is NaN\\ndf_script = df_script.dropna()\",\"# Remove rows with empty character names\\ndf_script = df_script.dropna(subset=['raw_character_text'])\",\"Remove unwanted rows and leave only those, which have the same length of 'normalized_text' and 'word_count'\",\"Cleaning the data\\ndf_script = df_script.dropna(subset=['normalized_text', 'character_id']).reset_index(inplace=False, drop=True)\",\" df_script = df_script.dropna(subset=['normalized_text'])\",\"Remove script lines without any speaking character\\ndf_script = df_script.dropna(subset=['character_id'])\",\"Remove rows with empty strings from the \\\"normalized_text\\\" column in df_script\\ndf_script = df_script[df_script[\\\"normalized_text\\\"].apply(lambda x: x != '')]\",\"Delete rows from the script where the normalized_text is missing.\",\"Remove rows where the character, location, or dialogue is missing\\ndf_script = df_script.dropna(subset=['character_id', 'location_id', 'normalized_text'])\",\"Remove NaN values from 'character_id' column, and convert it to int\\ndf_script = df_script.dropna(subset=['character_id'])\\ndf_script['character_id'] = df_script['character_id'].astype(int)\",\" Remove rows with missing values in the specified column\\ndf_script = df_script.dropna(subset=['raw_text'])\",\" Remove all the \\\"bad\\\" lines (i.e. duplicate, not indiced, without a raw_text)\\ndf_script = df_script[df_script[\\\"raw_text\\\"].notna()]\",\"Drop any NaN values from the 'raw_text' column, as they don't provide any valuable information for our analysis\\ndf_script = df_script.dropna(subset=['raw_text'])\",\"Clean up\\ndf_script = df_script.dropna()\",\"Remove the character_id and location_id\\ndf_script.drop(columns=['character_id', 'location_id'], inplace=True)\",\"Remove rows with missing data\\ndf_script = df_script.dropna(subset=['normalized_text'])\",\"Drop NaN values in 'raw_text' and 'character_id' columns\\ndf_script = df_script.dropna(subset=['raw_text', 'character_id'])\",\" Add regex to drop rows with all na values\\ndf_script = df_script.dropna(how='all', subset=['normalized_text'])\",\" Remove nas\\ndf_script = df_script.dropna(subset=['normalized_text'])\",\"# We first need to remove any NaN values from the character_name field\\ndf_script.dropna(subset=['character_id'], inplace=True)\\n\\n# Get the characters IDs\\ncharacter_ids = df_characters[['id']]\\n# Get the characters IDs\\nlocation_ids = df_locations[['id']]\",\"Filter rows with NaN valued from the `character_id` column.\",\"Clean the scripts data\\ndf_script_dropna = df_script.dropna(subset=['raw_text'])\\ndf_script_dropna = df_script_dropna[df_script_dropna.raw_text != '']\\ndf_script_dropna.reset_index(inplace=True, drop=True)\",\"Remove all the rows where at least one element is missing.\\ndf_script = df_script.dropna()\",\"Clean data\\ndf_script_clean = df_script.dropna(subset=['raw_text'])\\n\\n# Preview data\\ndf_script_clean.head()\"],\"marker\":{\"opacity\":0.5,\"size\":5},\"mode\":\"markers+text\",\"name\":\"14_Data Cleaning and Removal of Missing Values in df_script DataFrame\",\"text\":[\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\"],\"textfont\":{\"size\":12},\"x\":[6.378630638122559,6.341158390045166,5.712435245513916,5.551868438720703,6.7362823486328125,6.5207695960998535,6.472625732421875,5.894720077514648,6.606391906738281,6.470204830169678,6.123087406158447,5.636847972869873,5.851902961730957,6.21096658706665,6.908647537231445,6.029437065124512,6.0454816818237305,6.104610919952393,6.146099090576172,6.37260627746582,6.690649032592773,6.870419025421143,6.107424259185791,6.153489112854004,6.555346965789795,6.35899543762207,6.73969030380249,6.144506454467773,6.382002830505371,6.614789009094238,6.9787983894348145,5.786419868469238,5.856250286102295,6.8837480545043945,6.815855503082275,5.198235511779785,6.094204425811768,5.882884502410889,6.499643325805664,6.262996196746826,6.10670280456543,8.010784149169922,5.852758407592773,6.146308898925781,5.967617988586426,6.643500804901123,7.360826015472412,5.6686248779296875,5.817196846008301,6.442264080047607,6.088402271270752,6.685499668121338,6.121896266937256,5.337396621704102,6.666228294372559,6.183657169342041,6.494454860687256,6.719871997833252,5.76590633392334,5.744748592376709,6.134382724761963,6.655686855316162,6.2790117263793945],\"y\":[5.300658702850342,6.960381984710693,6.631192207336426,6.070120334625244,6.917148113250732,6.192397117614746,4.907462120056152,5.442481517791748,5.910698890686035,5.832500457763672,4.986809730529785,6.035882949829102,6.183866500854492,4.5021257400512695,6.420411586761475,5.027314186096191,5.633133888244629,5.92055606842041,6.227673053741455,5.440984725952148,5.566042423248291,6.711573600769043,6.013623237609863,4.704582214355469,6.914079666137695,5.584304332733154,6.0337605476379395,5.480187892913818,6.538466930389404,4.718812465667725,5.762818813323975,5.710690498352051,6.8359880447387695,5.996852874755859,6.263575077056885,5.848336696624756,6.722711086273193,6.341777801513672,6.24575138092041,4.776686191558838,6.32632303237915,6.157137393951416,7.0433220863342285,6.764954566955566,6.534003734588623,7.265579700469971,6.321993827819824,6.307344913482666,6.409334182739258,5.546277046203613,6.376553058624268,5.568621635437012,4.0862202644348145,6.331480979919434,6.369164943695068,6.196363925933838,6.067463397979736,6.574599266052246,5.770493507385254,5.837995529174805,5.845875263214111,4.579842567443848,6.171456813812256],\"type\":\"scattergl\"},{\"hoverinfo\":\"text\",\"hovertext\":[\"Let's look at the some data to understand it better\\ndf_episodes.head(2)\",\"Check the results\\ndf_episodes.head()\",\"Check the result\\ndf_episodes.head()\",\"\\ndf_episodes.head()\",\"Set correct datatypes for each column\\ndf_episodes.head()\",\"Explore the data\\ndf_episodes.head()\",\"Check the content of the episodes dataset\\ndf_episodes.head()\",\"Creating a basic dataframe of episodes data\\ndf_episodes.head()\",\"Check the data structure of the episodes data\\nprint(f'Episodes shape: {df_episodes.shape}')\\ndf_episodes.head()\",\"Look at sample of episodes data\\ndf_episodes.sample(5)\",\"Preview the episodes dataframe\\ndf_episodes.head()\",\" Display main datasets\\ndf_episodes.head()\",\"Check the data and its format\\ndf_episodes.head()\",\"Look the five first data of the dataframe df_episodes\\ndf_episodes.head()\",\" Display\\ndf_episodes.head()\",\"View some first lines of the data\\ndf_episodes.head()\",\"Check the first episodes record to see what data is available\\ndf_episodes.iloc[0]\",\" Look at the info to see missing data\\ndf_episodes.info()\",\" Subsets\\ndf_episodes.head()\",\"Displaying head of df_episodes\\ndf_episodes.head()\",\"Quick overview of the dataset\\nprint(df_episodes.head())\",\"Plot some simple histograms for the episodes dataframe\",\"View the data\\ndf_episodes.head()\",\"Quick look at the data\\ndf_episodes.head()\",\"Data inspection and exploration\\ndf_episodes.head()\",\" Display the dataframe\\ndf_episodes\",\" Take a look at the first few rows of the dataframe\\ndf_episodes.head()\",\"Display general information about the data\\ndf_episodes.info()\",\"Print the head of the episodes dataframe\\nprint(df_episodes.head())\",\"Choose an episode at random for this analysis\\nep = df_episodes.sample(1)\\nep\",\"df_episodes\",\"View the content of the episodes dataframe\\ndf_episodes.head()\",\"Get top movie release years\\ndf_movies = pd.read_csv('data\\u002fmovie_metadata.csv')\\ndf_movies['title_year'].value_counts().head(10)\",\"Check the content of the episodes dataframe\",\"Create a summary statistics of the episodes data\\ndf_episodes.describe()\",\" Show the head of the episodes dataframe\\ndf_episodes.head()\",\"Show dataframe head\\ndf_episodes.head()\",\" exploration\\ndf_episodes.head()\",\"# Show head of episodes\\ndf_episodes.head()\",\" Showing the head of the episodes dataframe\\ndf_episodes.head()\",\" The head of the episode dataframe\\ndf_episodes.head()\",\"Inspect data\\ndf_episodes.head()\",\"Check data samples for consistency\\ndf_episodes.head()\",\"lec df_episodes.head()\",\"#Overview of the data\\ndf_episodes.head()\",\"Explore the structure of episodes data\\ndf_episodes.head(10)\",\"check out the data to give an overview of what we are working with\\ndf_episodes.info()\",\"Preview the episodes data\\ndf_episodes.head()\",\"Sanity-check dataframe objects\\ndf_episodes\",\"Dataframe columns header correction\\ndf_episodes.columns.tolist()\",\"Explore the datasets\\ndf_episodes.head()\",\"Print the head of the episodes dataframe\\nprint(df_episodes.head())\",\"Check our datasets\\ndf_episodes.head()\",\"Show the data from the episode CSV file\\ndf_episodes.head()\",\" Display the contents of the episodes dataframe\\ndf_episodes.head()\",\"Preview the data\\ndf_episodes.head()\",\"Just let's see the top lines of the episodes dataset\\ndf_episodes.head()\",\"Check out the data\\ndf_episodes.head()\",\" Verify content of dataset\\ndf_episodes.head()\",\"Print the head of the dataframe to check its structure\\ndf_episodes.head()\",\"Look at the first 3 rows of the episodes DataFrame.\\ndf_episodes.head(3)\",\"Preview the episodes dataset\\ndf_episodes.head()\"],\"marker\":{\"opacity\":0.5,\"size\":5},\"mode\":\"markers+text\",\"name\":\"15_Previewing Episodes DataFrame\",\"text\":[\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\"],\"textfont\":{\"size\":12},\"x\":[2.29732608795166,2.123201370239258,1.927895188331604,2.132038116455078,1.903576374053955,1.8299177885055542,2.5279784202575684,2.3915047645568848,2.122710704803467,2.750566005706787,1.3309603929519653,2.0801515579223633,2.4164884090423584,2.2260279655456543,2.364656925201416,1.3950200080871582,3.246070384979248,3.090841054916382,2.042954921722412,2.222506523132324,1.7803453207015991,2.4136013984680176,1.9610803127288818,1.8735774755477905,1.825582504272461,2.1888647079467773,2.1519906520843506,1.3374119997024536,2.4483437538146973,2.925795316696167,2.6388072967529297,2.5116589069366455,1.7241082191467285,2.9711225032806396,1.8982127904891968,2.534560441970825,2.232879161834717,2.010789394378662,2.4403505325317383,2.264606475830078,2.1549324989318848,1.6461399793624878,1.562780737876892,2.428023099899292,1.770302414894104,1.9282922744750977,2.1605451107025146,1.8518877029418945,1.6058084964752197,1.469313383102417,1.9782582521438599,2.1646924018859863,2.2702715396881104,2.439016342163086,2.247220039367676,1.6276631355285645,1.9927113056182861,2.2869486808776855,2.0141468048095703,1.8437061309814453,2.472763776779175,1.596065878868103],\"y\":[2.7099339962005615,2.5926499366760254,2.686096429824829,2.4034323692321777,2.541867256164551,2.9008326530456543,2.5777270793914795,2.1567676067352295,2.176755905151367,2.876842498779297,3.0994269847869873,2.514371156692505,2.47723388671875,3.4676594734191895,2.2992401123046875,3.3420464992523193,3.0747814178466797,2.5779502391815186,2.5256404876708984,2.0399346351623535,3.2003910541534424,3.5291199684143066,2.833005905151367,2.830195426940918,2.6067774295806885,2.4915385246276855,2.650211811065674,2.4256343841552734,1.7847987413406372,3.298285484313965,2.7334225177764893,1.8347947597503662,3.503866195678711,2.229407787322998,2.5792510509490967,1.8874248266220093,1.629217505455017,2.4919397830963135,2.285606861114502,1.6223810911178589,1.8593807220458984,2.673767328262329,2.6221535205841064,2.2605936527252197,2.7611818313598633,3.0984601974487305,2.6279454231262207,3.131291151046753,1.693852186203003,1.893904447555542,2.886023759841919,2.0574121475219727,2.6606383323669434,2.3622446060180664,1.8291077613830566,3.0888795852661133,2.927701950073242,2.8957879543304443,2.2152886390686035,2.0085408687591553,3.0901288986206055,2.6978657245635986],\"type\":\"scattergl\"},{\"hoverinfo\":\"text\",\"hovertext\":[\"Inspect the first few rows of the characters data\\ndf_characters.head()\",\"Check the first few rows of the characters dataframe\\ndf_characters.head()\",\"Check the first few rows of the characters dataframe\\ndf_characters.head()\",\"Sanity check for first rows of df_characters\\ndf_characters.head()\",\" Checking the first few rows of the characters dataframe\\ndf_characters.head()\",\"Inspect the first few rows of the characters dataset\\ndf_characters.head()\",\"Check the first few rows of the characters dataframe\\ndf_characters.head()\",\"Check the first rows of each dataframe\\ndf_characters.head()\",\" Check the first few rows of the characters DataFrame\\ndf_characters.head()\",\"Check the first few rows of the characters dataframe\\ndf_characters.head()\",\"Inspect the first few rows of the characters dataset\\ndf_characters.head()\",\"Check the first rows of characters.csv\\ndf_characters.head()\",\" Check the first few rows of the characters dataframe\\ndf_characters.head()\",\"Check the 5 first lines of the characters dataframe to understand its structure\\ndf_characters.head()\",\"Examine the first few rows of the characters dataset\\ndf_characters.head()\",\"Inspecting the first few rows of the characters dataset\\ndf_characters.head()\",\"Check the first few rows of the characters dataset\\ndf_characters.head()\",\"Checking first rows for each dataset\\ndf_characters.head()\",\"Checking the first few rows of each dataframe to understand its structure\\nprint('Characters')\\nprint(df_characters.head())\",\"Check first rows of `df_characters`\\ndf_characters.head()\",\"Checking the first few rows of characters dataframe\\ndf_characters.head()\",\"Check the first few rows of the dataframe\\nprint(df_characters.head())\",\" Use pandas to see what's inside the first loaded dataset\\ndf_characters.head()\",\"Check the first few rows of the characters dataframe\\ndf_characters.head()\",\"Check the first few entries of the characters dataframe\\ndf_characters.head()\",\"Explore the first rows of the characters dataset\\ndf_characters.head()\",\"Check the first row of each dataframe\\ndf_characters.head(1)\",\"Inspecting first rows of the dataset\\ndf_characters.head()\",\"Check the first rows of the characters dataframe\\ndf_characters.head()\",\"Check the first few rows of the characters data\\ndf_characters.head()\",\"Checking the first rows for df_characters\",\"Check the first few rows of the characters dataframe\\ndf_characters.head()\",\"Check first rows of the characters dataframe\\ndf_characters.head()\",\"Checking the first few rows of the characters dataset to understand its structure\\ndf_characters.head()\",\" Check the first few rows of each dataframe\\nprint(\\\"Characters:\\\")\\ndisplay(df_characters.head())\",\" Check the first few rows of the characters dataframe to understand its structure\\ndf_characters.head()\",\"Check the first few rows of the characters dataframe\\ndf_characters.head()\",\"Check the first few rows of the characters dataframe\\ndf_characters.head()\",\"Check the first few rows of the characters dataframe\\ndf_characters.head()\",\"Check the first few rows of the characters dataframe\\ndf_characters.head()\",\"Check first few rows of df_characters\\ndf_characters.head()\",\"Check first few rows of characters dataframe\\ndf_characters.head()\",\" Check the first few rows of the characters dataframe\\ndf_characters.head()\",\"Check the first few rows of the characters dataframe\\ndf_characters.head()\",\"Check first few rows of characters dataframe\\ndf_characters.head()\",\"checking the first few rows of the characters dataframe\\ndf_characters.head()\",\" Check the first few entries of the characters dataframe\\ndf_characters.head()\",\"Check the first few rows of df_characters\\ndf_characters.head()\",\" Check the first few lines of the characters dataframe\\ndf_characters.head()\",\"Check the first few rows of the characters dataframe\\ndf_characters.head()\",\"Check the first few rows of each dataframe\\ndf_characters.head()\",\" Check three first characters dataframe\\ndf_characters.head(3)\",\"an inspection of the first few rows of df_characters\\ndf_characters.head()\",\"Check the first few rows of the characters dataframe\\ndf_characters.head()\",\"Check the first few rows of the characters dataframe\\ndf_characters.head()\",\"Check the first rows of the characters DataFrame\\ndf_characters.head()\",\"Examine the first few rows of the characters data\\ndf_characters.head()\",\"Check the first few lines of the characters dataframe\\ndf_characters.head()\",\"Check the first few lines of the characters dataframe\\ndf_characters.head()\",\" Check the first few rows of the characters data\\ndf_characters.head()\",\"Check head of the first dataframe\\ndf_characters.head()\",\"Check the first lines of each dataframes\\ndf_characters.head()\"],\"marker\":{\"opacity\":0.5,\"size\":5},\"mode\":\"markers+text\",\"name\":\"16_Checking the Sanity of Characters Dataset rows\",\"text\":[\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\"],\"textfont\":{\"size\":12},\"x\":[4.312262535095215,3.489804267883301,3.6310105323791504,3.378896713256836,2.988276481628418,4.442013263702393,3.1123859882354736,3.4862091541290283,3.3274548053741455,3.166168212890625,4.411008834838867,3.1339099407196045,3.5754013061523438,4.491796016693115,3.8173203468322754,3.9072093963623047,3.9131011962890625,3.52329683303833,4.519347667694092,3.6077442169189453,2.949018716812134,3.9166362285614014,4.209377288818359,3.451122999191284,3.6100287437438965,3.4122250080108643,3.3006911277770996,3.397477149963379,3.340223789215088,3.663036346435547,4.458286762237549,3.2849650382995605,3.4070708751678467,4.279821872711182,4.664469242095947,3.9434545040130615,3.3069493770599365,3.4746944904327393,3.735905885696411,3.3352391719818115,3.5804574489593506,3.238784074783325,3.267763614654541,3.4857394695281982,2.923043966293335,2.867218494415283,3.6903347969055176,3.660775899887085,3.772817373275757,3.2536778450012207,3.513167142868042,3.309849500656128,3.7914013862609863,3.3708298206329346,3.47275447845459,3.314669609069824,3.3732547760009766,4.138648509979248,4.066041946411133,3.7074897289276123,3.9446499347686768,3.732555866241455],\"y\":[17.497724533081055,20.695959091186523,20.370899200439453,18.94060707092285,20.245939254760742,15.776863098144531,20.611265182495117,19.522367477416992,20.667612075805664,20.929166793823242,15.88267993927002,19.279245376586914,20.778650283813477,19.065303802490234,16.487380981445312,16.405109405517578,17.381603240966797,18.532514572143555,19.605506896972656,19.077346801757812,19.952228546142578,20.39504623413086,15.9932222366333,20.455114364624023,20.929744720458984,16.189176559448242,19.573453903198242,16.944276809692383,19.785919189453125,18.533714294433594,18.320350646972656,20.738523483276367,19.512861251831055,16.270933151245117,19.842321395874023,19.8415584564209,20.512556076049805,20.51456642150879,20.742290496826172,20.286497116088867,19.458820343017578,19.906312942504883,20.509925842285156,20.723901748657227,19.86681365966797,20.060869216918945,20.784423828125,19.335315704345703,20.25101661682129,20.843473434448242,20.01051902770996,16.032440185546875,18.068336486816406,20.829790115356445,20.4722900390625,19.677852630615234,17.388139724731445,20.21776580810547,20.39396095275879,18.51909828186035,20.574426651000977,20.2039852142334],\"type\":\"scattergl\"},{\"hoverinfo\":\"text\",\"hovertext\":[\"Merge character data\\ndf_characters = df_characters.rename(columns={'id':'character_id'})\\ndf_script = df_script.merge(df_characters, on='character_id')\",\"Aggregating data on main locations and main characters\\ndf_script_characters = df_script[df_script.raw_character_text.notnull()]\\ndf_script_characters = df_script_characters.merge(\\n    df_characters[['id', 'normalized_name', 'gender']],\\n    left_on='raw_character_text', right_on='normalized_name',\\n    how='left')\",\"Merge characters in script\\ndf_script_characters = (\\n    df_script\\n    .loc[df_script['speaking_line']]\\n    .merge(\\n        df_characters,\\n        how='left',\\n        left_on='raw_character_text',\\n        right_on='character'\\n    )\\n)\",\" merge characters and script dataframe\\ndf_characters.rename(columns={'id': 'character_id'}, inplace=True)\\ndf_merged = pd.merge(df_script, df_characters, on='character_id', how='left')\",\"Join characters and script\\ndf_characters_script = pd.merge(df_script, df_characters, left_on='character_id', right_on='id')\",\"Merge script with characters\\ndf_script_char = df_script.merge(\\n    df_characters,\\n    left_on='character_id',\\n    right_on='id',\\n    suffixes=('_script', '_char'))\\ndf_script_char.head()\",\"Merging character names into the script DataFrame\\ndf_script = pd.merge(df_script, df_characters, how='inner', left_on='character_id', right_on='id', suffixes=('_script', '_character'))\",\"Merge script with characters ids\\ndf_script['character_id'] = df_script['raw_character_text'].map(lambda x: df_characters[df_characters['normalized_name'] == x.lower()]['id'].values[0] if len(df_characters[df_characters['normalized_name'] == x.lower()]['id'].values) \\u003e 0 else np.nan)\",\"Rename character name in df_script to prepare for join\",\" Add a column with the appropiate characters to df_script\\ndf_script = df_script.merge(\\n    df_characters[['id', 'name']],\\n    how='left',\\n    left_on='character_id',\\n    right_on='id'\\n)\",\"# Merging dataFrames in a unique one\\ndf = df_script.copy()\\ndf['character_id'] = df['character_id'].fillna(-1).astype(int)\",\"Separate script and character lines\\ndf_script_lines = df_script[df_script['character_id'].notna()]\\ndf_character_lines = pd.merge(df_script_lines, df_characters, left_on='character_id', right_on='id')\",\"Merge script with characters\\ndf_merged = pd.merge(df_script, df_characters, how='left',\\non=['character_id'], suffixes=('', '_char'))\",\"Merge the scripts with the character metadata\\ndf_scripts_characters = pd.merge(df_script, df_characters, on='character_id', how='inner')\",\"Merge the dialogues with the character metadata\\ndf_character_lines = pd.merge(df_script, df_characters, left_on='character_id', right_on='id')\",\"Merge script with characters\\ndf_characters_script = df_script.merge(df_characters, left_on='character_id', right_on='character_id')\",\"Merging df_script with character data\\ndf_script_chars = pd.merge(df_script, df_characters, left_on='character_id', right_on='id')\",\"Merge characters and script\\ndf_script = df_script[df_script.raw_character_text != \\\"\\\"]\\ndf_script = pd.merge(df_script, df_characters, how=\\\"left\\\", on=[\\\"raw_character_text\\\"])\",\"Create a dataframe by merging `df_script` with `df_characters` on the `character_id` field.\",\"Merge script and character data\\ndf_lines_characters = pd.merge(df_script, df_characters, how='inner', left_on='character_id', right_on='id').drop(columns=['id'])\",\"Merge the script and character dataframe\\ndf_script = df_script.merge(df_characters.add_prefix('character_'), left_on='character_id', right_on='character_id', how='left')\",\"Merge scripts with character names and locations\\ndf_merged = df_script.merge(df_characters, how='left', left_on='character_id', right_on='id', suffixes=('_script', '_character'))\",\"Merge characters and script dataframes\\ndf_characters_and_script = pd.merge(df_script,\\n                                    df_characters,\\n                                    left_on='character_id',\\n                                    right_on='id',\\n                                    suffixes=(False, False))\",\"Join script lines and characters\\ndf_char_lines = pd.merge(df_script, df_characters, on='character_id', how='left')\",\" Join script lines with character id\\ndf_script = df_script.merge(df_characters[['id', 'raw_character_text']], left_on='character_id', right_on='id', how='left')\",\" Merge script and character data\\ndf_script_full = df_script.merge(df_characters, how='left', left_on='character_id', right_on='id')\",\" Add character names to script lines dataframe\\ndf_script = df_script.merge(df_characters, left_on='character_id', right_index=True)\",\"Merge character data into script data\\ndf_script_characters = df_script.merge(df_characters, how='left', left_on='character_id', right_on='id')\",\"# Merge datasets based on common keys\\ndf_merged = df_script.merge(df_characters, on='character_id', how='left')\",\" Merge scripts with characters and cleaning\\ndf_script = df_script.merge(df_characters[['id', 'name']], 'left', left_on='character_id', right_on='id')\",\"Add the character information to the script dataframe\\ndf_script = df_script.merge(df_characters, how='left', on='character_id')\",\" Merge characters and script\\ndf_charlines = df_script.merge(df_characters, on='character_id')\",\"# Merge scripts with characters\\ndf_script_info = df_script.merge(df_characters, how='left', left_on='character_id', right_on='character_id', suffixes=('_script', '_character'))\",\"Merge the dataset\\ndf_name_only = df_characters.loc[:, ['name', 'normalized_name']]\\ndf_total = pd.merge(df_script, df_name_only, how='left', left_on='raw_character_text', right_on='name')\\n\\ndf_total.dropna(subset=['normalized_name'], inplace=True)\",\"Merge character data into script data\\ndf = pd.merge(df_script, df_characters, how='left', left_on='character_id', right_on='id', suffixes=('_script', '_character'))\",\" Merge script with characters\\ndf_script_characters = pd.merge(df_script, df_characters, how='left', left_on='character_id', right_on='id', suffixes=('_script', '_character')).reset_index(inplace=False, drop=True)\",\"Merge the three files together\\ndf = df_script.merge(df_characters, left_on='character_id', right_on='id', suffixes=('_script', '_character'))\",\"Merge the character information into the script\\ndf_script = df_script.merge(df_characters, how=\\\"inner\\\", on=\\\"character_id\\\")\",\"Merge the dataframes together\\ndf = df_script.merge(df_characters, how='left', on='character_id')\",\" Merge characters and script\\ndf_char_scripts = pd.merge(df_script, df_characters, on='character_id', suffixes=(\\\"\\\", \\\"_char\\\"), how=\\\"left\\\")\",\" Join characters with script\\ndf_characters_script = df_script.merge(df_characters, left_on='character_id', right_on='id').drop(columns=['id', 'normalized_name'])\\ndf_characters_script.head()\",\"Join Scripts and character names to get sentences with character names\\ndf_script['raw_character_text'] = df_script['raw_character_text'].str.lower()\\ndf_characters['name'] = df_characters['name'].str.lower()\\ndf_main = pd.merge(df_script, df_characters,  how='left', left_on=['raw_character_text'], right_on = ['name']).drop(['name'], axis=1)\",\"Add additional character metadata\\ndf_characters = df_characters.merge(df_script[['character_id', 'raw_character_text']], left_on='id', right_on='character_id', how='inner')\\ndf_characters.rename(columns={'raw_character_text': 'name_original'}, inplace=True)\",\" Merge character names and script lines on character_id\\ndf = df_script.merge(df_characters, on=\\\"character_id\\\", how=\\\"left\\\")\",\" Mergethe two dataframes to get the character id\",\" Join characters name to scripts\\ndf_characters = df_characters.rename(columns={'id':'character_id', 'name':'character_name'})\\ndf_script = df_script.merge(df_characters[['character_id', 'character_name']], how='inner', on='character_id')\",\"Merging character names and script\\ndf_characters_script = df_script.merge(\\n    df_characters,\\n    how='left',\\n    left_on='character_id',\\n    right_on='id',\\n    suffixes=('_script', '_character'),\\n)\",\"# Merge characters and script\\ndf_merged = df_script.merge(df_characters, on='id', suffixes=('_lines', '_characters'))\",\" Merge characters and script dataframes\\ndf_characters_script = pd.merge(df_characters, df_script, left_on='id', right_on='character_id')\\ndf_characters_script.head()\",\"Merge characters and script dataframe\\ndf_characters = df_characters.rename(columns={'id': 'character_id'})\\ndf_script = df_script.merge(df_characters, how='left', on='character_id')\",\"Merge characters with script\\ndf_script = pd.merge(df_script, df_characters, on='character_id', how='left')\",\"Merge the characters and lines based on the character_id\",\"Merge df_characters and df_script\\ndf_script = df_script.merge(df_characters[['id', 'name']], left_on='character_id', right_on='id', suffixes=(None, '_character'))\",\"# Merge script with character information\\ndf_script = df_script.rename(columns={'raw_character_text': 'name'})\\ndf_script_extended = df_script.merge(df_characters, on='name', how='left')\\n\\ndf_script_extended.head()\",\" Combine character information with script lines\\ndf_combined = df_script.merge(df_characters.add_suffix('_characters'), how='left', left_on='character_id', right_on='id_characters')\",\"Merge character details and script lines\\ndf_characters_script = pd.merge(df_characters, df_script, left_on='id', right_on='character_id')\",\"Merge the script and the characters DataFrame along the 'character_id'\\ndf_script = pd.merge(df_script, df_characters, on='character_id')\",\"Merge table to keep only scripts with a known character ID\\ndf = pd.merge(df_script, df_characters, how='inner', on='id', suffixes=('', '_y'))\\ndf = df[pd.notnull(df['normalized_text'])]\"],\"marker\":{\"opacity\":0.5,\"size\":5},\"mode\":\"markers+text\",\"name\":\"17_Document merging with script and character data\",\"text\":[\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\"],\"textfont\":{\"size\":12},\"x\":[5.0160722732543945,4.571682453155518,4.740828990936279,4.380854606628418,4.618835926055908,4.677803993225098,5.085918426513672,5.738497734069824,4.927474498748779,4.871455669403076,4.869809627532959,4.974160671234131,4.635277271270752,4.99971342086792,4.930983543395996,5.02211332321167,4.643746852874756,4.363819599151611,5.349496841430664,4.644163131713867,4.524477005004883,4.1937479972839355,4.9332990646362305,4.297077178955078,4.705737113952637,4.605853080749512,4.646601676940918,4.632903575897217,4.503067970275879,5.153716087341309,4.470584869384766,4.754960536956787,4.8998284339904785,5.197144985198975,4.961973667144775,4.785079479217529,4.881925106048584,5.152194499969482,4.213441371917725,4.790242671966553,5.496043682098389,4.91865873336792,5.029304504394531,4.2131876945495605,4.754372596740723,5.297142028808594,4.836373329162598,4.565769672393799,4.551565647125244,4.449613571166992,4.445703506469727,4.235386371612549,5.212411403656006,5.051779270172119,4.7238898277282715,4.645493507385254,5.090025901794434,5.391821384429932],\"y\":[9.700489044189453,9.868489265441895,9.910480499267578,10.163307189941406,10.221312522888184,10.003396987915039,10.631353378295898,9.257119178771973,9.597434997558594,9.96155834197998,9.554876327514648,9.630375862121582,10.6198091506958,10.036131858825684,8.90258502960205,10.27142333984375,10.28069019317627,10.619245529174805,9.290343284606934,9.541634559631348,10.459532737731934,10.547234535217285,10.416359901428223,9.80842113494873,10.132415771484375,10.468676567077637,9.978119850158691,10.284143447875977,10.518026351928711,10.193868637084961,10.341249465942383,9.670612335205078,10.489267349243164,9.07364559173584,10.486772537231445,10.902091979980469,10.563319206237793,9.922069549560547,10.020337104797363,10.927482604980469,9.639713287353516,10.078330039978027,9.496583938598633,9.82638168334961,9.70009994506836,9.944268226623535,10.520390510559082,10.068587303161621,10.33155632019043,9.925126075744629,10.5735445022583,9.241469383239746,10.066027641296387,10.013934135437012,10.266890525817871,9.850686073303223,10.028953552246094,9.248940467834473],\"type\":\"scattergl\"},{\"hoverinfo\":\"text\",\"hovertext\":[\"#Select the required columns\\ndf_script = df_script[['episode_id', 'number', 'raw_text', 'speaking_line', 'character_id']]\\n\\n# Informationen zu der Tabelle\\nprint(df_script.info())\",\"\\ndf_script = df_script[['id', 'episode_id', 'number', 'raw_text', 'timestamp_in_ms', 'speaking_line', 'character_id', 'location_id', 'raw_character_text', 'raw_location_text', 'spoken_words', 'normalized_text']].copy()\",\"convert ids to integers\\ndf_script['episode_id'] = df_script['episode_id'].astype(int)\\ndf_script['character_id'] = df_script['character_id'].astype(int)\",\"We will only use the following columns from df_script DataFrame:\\ndf_script = df_script[['episode_id', 'raw_text', 'character_id', 'location_id']]\\n\",\"# Create a new temporary dataframe with the necessary data and set correct data types\\ndf_script_temp = df_script[['episode_id', 'number', 'raw_text', 'character_id']].copy()\\ndf_script_temp['episode_id'] = df_script_temp['episode_id'].astype(int)\\ndf_script_temp['character_id'] = df_script_temp['character_id'].astype(float)\",\"Select relevant columns and transforming id columns to ints\\ndf_script = df_script[['episode_id','number','raw_text','character_id','location_id']]\\ndf_script.character_id = df_script.character_id.astype('Int64')\\ndf_script.location_id = df_script.location_id.astype('Int64')\",\"Set up data for analysis\\n# Extract episode number and script from the main dataframe\\nepisodes_script = df_script[['episode_id', 'raw_text']]\",\" Remove useless data\\ndf_script = df_script[['episode_id', 'raw_text']]\",\" For the purposes of this analysis, the following columns are extracted:\\n\\nExtracting only necessary columns from the `script_lines` dataset:\\n\\n- `episode_id`\\n- `number`\\n- `raw_text`\\n- `timestamp_in_ms`\\n- `speaking_line`\\n- `character_id`\\n\\nExtracting only necessary columns from the `characters` dataset:\\n\\n- `name`\\n- `id`\\n\\nExtracting only necessary columns from the `locations` dataset:\\n\\n- `name`\\n- `id`\",\"Extract episode_id and raw_text from df_script\\ndf_script = df_script[['episode_id', 'raw_text']]\",\" Extract columns of interest\\ndf_script = df_script[['episode_id', 'character_id', 'location_id', 'normalized_text']]\",\"Select only important columns\\ndf_script = df_script[['episode_id', 'number', 'raw_text', 'character_id', 'location_id']].copy()\",\"also drop and reorder the columns in the script dataframe\\ndf_script = df_script.drop(['id', 'episode_id', 'number', 'raw_text', 'timestamp_in_ms'], axis=1)\\ndf_script = df_script[['episode_id', 'character_id', 'location_id', 'spoken_words']]\",\" Data quality\\n# df_script contains the raw text\\n\\n# Ensure we have all the needed data\\nrequired_cols = ['episode_id', 'character_id', 'location_id', 'raw_text', 'timestamp_in_ms']\\nfor col in required_cols:\\n    assert col in df_script.columns, f\\\"Column '{col}' not found in df_script\\\"\\n\\nprint(\\\"All required columns found in df_script\\\")\",\"Create a subset of df_script that includes only the fields needed\\ndf_script_subset = df_script[['id', 'episode_id', 'character_id', 'location_id', 'raw_text']].copy()\",\"Remove unused columns\\ndf_script = df_script[['episode_id', 'number', 'raw_text', 'speaker_line', 'timestamp_in_ms', 'location_id', 'raw_character_text', 'raw_location_text', 'spoken_words']]\\ndf_episodes = df_episodes[['id', 'title', 'original_air_date']]\\ndf_locations = df_locations[['id', 'name']]\",\" Remove unnecessary columns\\ndf_characters = df_characters[['id', 'name', 'normalized_name']]\\ndf_locations = df_locations[['id', 'name', 'normalized_name']]\\ndf_episodes = df_episodes[['id', 'title']]\\ndf_script = df_script[['episode_id', 'number', 'raw_text']]\",\"Simplify dataframe\\ndf_script_simple = df_script[['episode_id', 'number', 'raw_text', 'timestamp_in_ms']]\",\"Notes for dataframes:\\n# df_characters: \\n# df_locations: \\n# df_script: id|episode_id|number|raw_text|timestamp_in_ms|speaking_line|character_id|location_id\\n# df_episodes: id|title|original_air_date|production_code|season|number_in_season|number_in_series|us_viewers_in_millions|views|imdb_rating|imdb_votes|image_url|video_url\\n\",\"Subsetting the dataframe for columns of interest\\ndf_script = df_script[['episode_id', 'number', 'raw_text', 'character_id']]\\n\\n# Initial Data Exploration\\nprint('\\\\n','#'*120,'\\\\n','DATAFRAME HEAD','\\\\n','#'*120,'\\\\n',df_script.head(5),'\\\\n','#'*120)\",\"Extract relevant columns\\ndf_script = df_script[['episode_id', 'number', 'raw_text', 'normalized_text', 'raw_character_text',\\n                       'spoken_words', 'normalized_text', 'word_count']]\\n\\n# Removing leading\\u002ftrailing spaces from al fanmes\\ndf_characters['character'] = df_characters['character'].str.strip()\\ndf_locations['raw_location_text'] = df_locations['raw_location_text'].str.strip()\\ndf_script['raw_character_text'] = df_script['raw_character_text'].str.strip()\",\"# Coverting episode_number to int as it has some '.0' values\\ndf_episodes.at[:, 'number'] = df_episodes['number'].fillna(0).astype(int)\",\"# Helper function to show lines based on a condition\\ndef where(df, condition):\\n    return df[condition]\\n\\n# Helper function to retrieve text from the script\\ndef get_script_text(df, episode_number):\\n    return df[df['episode_id'] == episode_number]['raw_text'].values\",\"Extract main columns\\ndf_episodes = df_episodes[['id', 'title', 'original_air_date', 'production_code', 'season', 'number_in_season', 'number_in_series', 'us_viewers_in_millions', 'views', 'imdb_rating','imdb_votes']]\\ndf_script = df_script[['id', 'episode_id', 'number', 'raw_text', 'timestamp_in_ms']]\\ndf_characters = df_characters[['id', 'first_name', 'last_name']]\\ndf_locations = df_locations[['id', 'name']]\",\"Select some columns and sample some data\\n# This way, we can better understand the data we are working with\\ndf_script.sample(10)[['normalized_text', 'spoken_words', 'raw_text', 'episode_id', 'character_id']]\",\"Declare which columns to be used for each dataframe.\\nchar_fields = [\\n    'id',\\n    'name'\\n]\\n\\nloc_fields = [\\n    'id',\\n    'name'\\n]\\n\\nep_fields = [\\n    'id',\\n    'title'\\n]\\n\\nscript_fields = [\\n    'episode_id',\\n    'number',\\n    'raw_text',\\n    'character_id',\\n    'location_id'\\n]\",\"Set all IDs to integers\\ndf_script['episode_id'] = df_script['episode_id'].astype(int)\\ndf_script['timestamp_in_ms'] = df_script['timestamp_in_ms'].astype(int)\\ndf_script['character_id'] = df_script['character_id'].fillna(-1).astype(int)\\ndf_script['location_id'] = df_script['location_id'].fillna(-1).astype(int)\",\"reduce memory usage\\ndf_script['id'] = pd.to_numeric(df_script['id'], downcast='integer')\\ndf_script['episode_id'] = pd.to_numeric(df_script['episode_id'], downcast='integer')\\ndf_script['number'] = pd.to_numeric(df_script['number'], downcast='integer')\\ndf_script['raw_text'] = df_script['raw_text'].astype('string')\\ndf_script['timestamp_in_ms'] = pd.to_numeric(df_script['timestamp_in_ms'], downcast='integer')\\ndf_script['speaking_line'] = df_script['speaking_line'].astype('boolean')\\ndf_script['character_id'] = pd.to_numeric(df_script['character_id'], downcast='integer')\\ndf_script['location_id'] = pd.to_numeric(df_script['location_id'], downcast='integer')\\ndf_script['raw_text'] = df_script['raw_text'].astype('string')\\n\\ndf_episodes['id'] = pd.to_numeric(df_episodes['id'], downcast='integer')\\ndf_episodes['viewers'] = pd.to_numeric(df_episodes['viewers'], downcast='integer')\\n\\ndf_characters['id'] = pd.to_numeric(df_characters['id'], downcast='integer')\\ndf_characters['name'] = df_characters['name'].astype('string')\\ndf_characters['normalized_name'] = df_characters['normalized_name'].astype('string')\\ndf_characters['gender'] = df_characters['gender'].astype('string')\\ndf_characters['description'] = df_characters['description'].astype('string')\\ndf_characters['color'] = df_characters['color'].astype('string')\\n\\ndf_locations['id'] = pd.to_numeric(df_locations['id'], downcast='integer')\\ndf_locations['name'] = df_locations['name'].astype('string')\\ndf_locations['normalized_name'] = df_locations['normalized_name'].astype('string')\\ndf_locations['image_url'] = df_locations['image_url'].astype('string')\",\" Remove the first 3 columns from df_script since they don't provide any value\\ndf_script = df_script[['episode_id', 'id', 'character_id', 'location_id', 'raw_text']]\",\"Extract numeric id from episode url\\ndf_episodes['id'] = df_episodes['id'].str.extract('\\\\\\u002f([0-9]+)')\",\" Select columns\\ndf_script = df_script[['episode_id', 'number', 'raw_text', 'character_id', 'location_id']]\",\"REMOVING UNNECESSARY COLUMNS\\ndf_script = df_script[['episode_id', 'id', 'character_id', 'location_id', 'raw_text']]\",\"Filter scripts to avoid using too much memory on temporary data\\ndf_script_filtered = df_script[['episode_id', 'character_id', 'location_id', 'spoken_words']].copy()\",\"Remove non-text columns\\ndf_script = df_script[['episode_id', 'number', 'raw_text']]\",\"Clean the script dataframe\\ndf_script_cleaned = df_script[['episode_id', 'timestamp_in_ms', 'speaking_line', 'character_id', 'location_id', 'raw_text']].copy()\\ndf_script_cleaned['episode_id'] = df_script_cleaned['episode_id'].astype(int)\\ndf_script_cleaned['timestamp_in_ms'] = df_script_cleaned['timestamp_in_ms'].astype(int)\\ndf_script_cleaned['character_id'] = df_script_cleaned['character_id'].astype(int)\\ndf_script_cleaned['location_id'] = df_script_cleaned['location_id'].astype(int)\\ndf_script_cleaned.head()\",\" Create a sub-dataframe using only the lines\\ndf_lines = df_script[['episode_id', 'number', 'raw_text']]\",\"Create new columns\\ndf_script['episode_id'] = pd.to_numeric(df_script['episode_id'], errors='coerce')\\ndf_script['character_id'] = pd.to_numeric(df_script['character_id'], errors='coerce')\\ndf_script['location_id'] = pd.to_numeric(df_script['raw_location_text'], errors='coerce')\",\"\\n# Light cleaning of the lines dataframe to keep only relevant columns\\ndf_script = df_script[['episode_id', 'number', 'raw_text', 'character_id', 'location_id']]\",\"Remove unused columns\\ndf_script = df_script[['episode_id', 'id', 'character_id', 'location_id', 'raw_text']]\",\"Select relevant columns for each dataframe\\ndf_characters = df_characters[['id', 'name', 'normalized_name', 'gender', 'normalized_gender']]\\ndf_locations = df_locations[['id', 'name', 'normalized_name']]\\ndf_script = df_script[['episode_id', 'number', 'raw_text', 'timestamp_in_ms', 'speaking_line', 'character_id', 'location_id']].copy()\\ndf_episodes = df_episodes[['id', 'title', 'original_air_date', 'production_code', 'season', 'number_in_season', 'number_in_series']].copy()\",\" Our df_script dataframe contains different kind of information id, episode_id, number, raw_text, speaking_line, character_id, location_id, and timestamp.\",\"select features to keep\\ndf_script = df_script[[\\n    'episode_id',\\n    'number',\\n    'raw_text',\\n    'raw_character_text',\\n    'spoken_words',\\n    'raw_location_text',\\n    'normalized_text',\\n    'word_count'\\n]]\",\"subset_columns\\u0012=['normalized_text', 'episode_id', 'character_id', 'location_id']\",\" Keep the useful columns\\ndf_script = df_script[['id', 'episode_id', 'number', 'raw_text', 'timestamp_in_ms', 'speaking_line', 'character_id', 'location_id', 'raw_character_text', 'raw_location_text']]\",\"# Getting just the fields we are interested in\\ndf_script = df_script[['episode_id', 'character_id', 'location_id', 'raw_text']]\",\"Combine script, character, and location data\\ndf_episodes_sub = df_episodes[['id', 'imdb_rating', 'title', 'original_air_date', 'production_code', 'season', 'number_in_season']]\\ndf_script_sub = df_script[['episode_id', 'character_id', 'location_id', 'norm_text']]\",\"Selecting main columns for characters and script DataFrames\\ndf_characters = df_characters[['id', 'name']]\\ndf_script = df_script[['id', 'episode_id', 'number', 'raw_text', 'normalized_text', 'character_id', 'location_id']]\",\"Remove irrelevant columns from script dataframe\\ndf_script = df_script[['episode_id', 'number', 'raw_text', 'timestamp_in_ms']]\",\"select only necessary columns\\ndf_script = df_script[['episode_id', 'id', 'character_id', 'location_id', 'raw_text']]\",\"Display scripts\\nscript_cols = ['episode_id', 'number', 'raw_text']\\ndf_script[script_cols].head()\",\"Create a row identifier by combining 'episode_id' and 'timestamp_in_ms'\\ndf_script[\\\"row_id\\\"] = df_script[\\\"episode_id\\\"].astype(str) + \\\"_\\\" + df_script[\\\"timestamp_in_ms\\\"].astype(str)\",\"Filter unnecessary columns\\ndf_script = df_script[['id', 'episode_id', 'number', 'raw_text', 'timestamp_in_ms', 'speaking_line', 'character_id', 'location_id']]\",\" Set correct types for character_id, location_id and episode_id\\ndf_script = df_script.astype({'character_id': 'Int64', 'location_id': 'Int64', 'episode_id': 'Int64'})\",\"Extract useful columns\\ndf_characters = df_characters[['id', 'name']]\\ndf_locations = df_locations[['id', 'name']]\\ndf_episodes = df_episodes[['id', 'title']]\",\"Set 'raw_text' to script's rightmost side\\ndf_script = df_script[['episode_id', 'raw_text']]\",\"Remove unused columns for the script and characters dataframe\\ndf_script = df_script[['episode_id', 'number', 'raw_text', 'spoken_words', 'character_id', 'location_id', 'timestamp_in_ms']]\\ndf_characters = df_characters[['id', 'name', 'normalized_name']]\\ndf_locations = df_locations[['id', 'name']]\",\" Select features of interest from the script dataset\\ndf_script = df_script[['episode_id', 'number', 'raw_text', 'character_id', 'location_id']]\\n\\n# Convert episode number from float to int\\ndf_script['number'] = df_script['number'].fillna(0).astype(int)\",\"Keep relevant columns only\\ndf_script = df_script[['episode_id', 'number', 'raw_text', 'character_id', 'location_id']]\"],\"marker\":{\"opacity\":0.5,\"size\":5},\"mode\":\"markers+text\",\"name\":\"18_Removing Unused Columns for Dataframes\",\"text\":[\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\"],\"textfont\":{\"size\":12},\"x\":[4.996364593505859,4.798448085784912,3.968302011489868,4.61715030670166,3.7461414337158203,3.9532041549682617,5.069729328155518,4.486158847808838,5.783316135406494,4.864045143127441,5.025721549987793,3.9573237895965576,5.1150922775268555,4.55361270904541,4.0592803955078125,3.9972641468048096,3.692432165145874,4.5474090576171875,3.2062747478485107,4.755627632141113,4.857487201690674,4.180995464324951,5.053213119506836,3.615070343017578,5.640368461608887,4.3559088706970215,3.602038860321045,4.4546380043029785,4.525766849517822,4.572404384613037,4.58490514755249,4.412968158721924,4.695021629333496,4.910096168518066,3.7771999835968018,5.246004581451416,4.5667643547058105,4.690651893615723,4.488755226135254,3.8911497592926025,4.67437219619751,4.916666030883789,4.60520601272583,4.995370388031006,4.593504905700684,3.4566595554351807,4.6053361892700195,5.220355033874512,4.573578357696533,5.354570388793945,3.8859546184539795,5.122678756713867,3.805589199066162,3.8188157081604004,5.016273021697998,4.691943645477295,4.153029441833496,4.054573059082031],\"y\":[6.491592884063721,6.72593879699707,6.488641262054443,5.945616722106934,6.126836776733398,7.0072126388549805,5.683966636657715,5.857635498046875,5.785533428192139,6.28078556060791,6.378283977508545,5.895598888397217,5.512928009033203,6.13314962387085,5.658375263214111,5.822316646575928,6.3093390464782715,5.406272888183594,5.283361434936523,6.4547929763793945,6.755329608917236,5.291975975036621,6.193652629852295,6.5411176681518555,6.810920238494873,6.013788223266602,6.106594562530518,5.678173542022705,5.893706798553467,5.704128265380859,6.243851184844971,6.428467273712158,5.908102035522461,5.6601128578186035,7.031060218811035,5.873944282531738,6.452305793762207,6.27807092666626,6.13712215423584,6.482021808624268,6.15435791015625,6.576827526092529,5.792205333709717,6.53790283203125,6.231086254119873,6.129164695739746,6.325809001922607,5.2286272048950195,6.081512928009033,6.616871356964111,5.55617618560791,6.097197532653809,6.390008449554443,6.36259651184082,6.348211288452148,6.143248081207275,6.235002040863037,6.334251880645752],\"type\":\"scattergl\"},{\"hoverinfo\":\"text\",\"hovertext\":[\"Check the number of records in each dataframes.\\nprint('Number of records in characters dataframe:', len(df_characters))\\nprint('Number of records in locations dataframe:', len(df_locations))\\nprint('Number of records in script dataframe:', len(df_script))\\nprint('Number of records in episodes dataframe:', len(df_episodes))\",\"Define dimensionality of each dataset\\nn_characters = len(df_characters)\\nn_locations = len(df_locations)\\nn_episodes = len(df_episodes)\\nn_scripts = len(df_script)\\n\\nprint(f'DataFrame \\\"Characters\\\" contains {n_characters} rows')\\nprint(f'DataFrame \\\"Locations\\\" contains {n_locations} rows')\\nprint(f'DataFrame \\\"Episodes\\\" contains {n_episodes} rows')\\nprint(f'DataFrame \\\"Script\\\" contains {n_scripts} rows')\",\"# Clean line\\ndf_script = df_script[df_script[\\\"normalized_text\\\"] != \\\"\\\"].dropna()\\n\\n# Display some statistics\\nprint(\\\"Number of episodes:\\\", df_episodes.shape[0])\\nprint(\\\"Number of characters:\\\", df_characters.shape[0])\\nprint(\\\"Number of locations:\\\", df_locations.shape[0])\\nprint(\\\"Number of lines:\\\", df_script.shape[0])\",\"Display the number of records for each dataframe\\nprint('Number of records in characters: {}'.format(len(df_characters)))\\nprint('Number of records in locations: {}'.format(len(df_locations)))\\nprint('Number of records in episodes: {}'.format(len(df_episodes)))\\nprint('Number of records in script: {}'.format(len(df_script)))\",\"Printing dataframes and number of rows in each dataframe\\nprint(f\\\"# of characters: {len(df_characters)}\\\")\\nprint(f\\\"# of locations: {len(df_locations)}\\\")\\nprint(f\\\"# of script_lines: {len(df_script)}\\\")\\nprint(f\\\"# of episodes: {len(df_episodes)}\\\")\",\"Print the number of rows in each dataframe\\nprint(f\\\"Number of rows in characters dataframe: {len(df_characters)}\\\")\\nprint(f\\\"Number of rows in locations dataframe: {len(df_locations)}\\\")\\nprint(f\\\"Number of rows in script dataframe: {len(df_script)}\\\")\\nprint(f\\\"Number of rows in episodes dataframe: {len(df_episodes)}\\\")\",\"Check the number of entries in each dataset\\nprint(f'Number of script lines: {len(df_script)}')\\nprint(f'Number of characters: {len(df_characters)}')\\nprint(f'Number of locations: {len(df_locations)}')\\nprint(f'Number of episodes: {len(df_episodes)}')\",\"Print some basic information about the datasets\\nprint(f'Characters: {len(df_characters)}')\\nprint(f'Locations: {len(df_locations)}')\\nprint(f'Script lines: {len(df_script)}')\\nprint(f'Episodes: {len(df_episodes)}')\",\"Print the number of characters, locations, script lines and episodes\\nprint('Number of characters:', len(df_characters))\\nprint('Number of locations:', len(df_locations))\\nprint('Number of script lines:', len(df_script))\\nprint('Number of episodes:', len(df_episodes))\",\"Displaying the number of characters, locations, script lines, and episodes in the datasets\\nprint('Number of characters:', len(df_characters))\\nprint('Number of locations:', len(df_locations))\\nprint('Number of script lines:', len(df_script))\\nprint('Number of episodes:', len(df_episodes))\",\" Length of dataframes\\nlen(df_characters), len(df_locations), len(df_script), len(df_episodes)\",\"Display number of rows in each dataset\\nprint(\\\"Number of rows in characters dataset:\\\", len(df_characters))\\nprint(\\\"Number of rows in locations dataset:\\\", len(df_locations))\\nprint(\\\"Number of rows in script dataset:\\\", len(df_script))\\nprint(\\\"Number of rows in episodes dataset:\\\", len(df_episodes))\",\"Check the number of records\\nprint(\\\"Number of records in characters dataset:\\\", len(df_characters))\\nprint(\\\"Number of records in locations dataset:\\\", len(df_locations))\\nprint(\\\"Number of records in script dataset:\\\", len(df_script))\\nprint(\\\"Number of records in episodes dataset:\\\", len(df_episodes))\",\"Display the number of records of each dataset\\nprint('Number of records in characters dataset:', len(df_characters))\\nprint('Number of records in locations dataset:', len(df_locations))\\nprint('Number of records in script dataset:', len(df_script))\\nprint('Number of records in episodes dataset:', len(df_episodes))\",\"Check data sample sizes\\nprint(f'Characters: {len(df_characters)}')\\nprint(f'Locations: {len(df_locations)}')\\nprint(f'Script lines: {len(df_script)}')\\nprint(f'Episodes: {len(df_episodes)}')\",\"n. of characters and n. of locations\\nn_characters = len(df_characters)\\nn_locations = len(df_locations)\",\"print('Loaded {:,} characters, {:,} locations, {:,} episodes, and {:,} script lines'.format(\\n    len(df_characters), len(df_locations), len(df_episodes), len(df_script)\\n))\",\"Display the number of characters, locations, script lines, and episodes\\nlen(df_characters), len(df_locations), len(df_script), len(df_episodes)\",\" Display number of data points for each table\\nprint(f\\\"Number of points in characters table: {len(df_characters)}\\\")\\nprint(f\\\"Number of points in locations table: {len(df_locations)}\\\")\\nprint(f\\\"Number of points in script table: {len(df_script)}\\\")\\nprint(f\\\"Number of points in episodes table: {len(df_episodes)}\\\")\",\"Check the content of each table\\nprint(f\\\"Characters table: {len(df_characters)} lines\\\")\\nprint(f\\\"Locations table: {len(df_locations)} lines\\\")\\nprint(f\\\"Script table: {len(df_script)} lines\\\")\\nprint(f\\\"Episodes table: {len(df_episodes)} lines\\\")\",\"Display the number of rows in each of the datasets\\nprint(\\\"Number of rows in characters dataset: \\\", len(df_characters))\\nprint(\\\"Number of rows in locations dataset: \\\", len(df_locations))\\nprint(\\\"Number of rows in script lines dataset: \\\", len(df_script))\",\"Print the number of elements in the dataset\\nprint(f\\\"Number of characters: {len(df_characters)}\\\")\\nprint(f\\\"Number of locations: {len(df_locations)}\\\")\\nprint(f\\\"Number of script lines: {len(df_script)}\\\")\\nprint(f\\\"Number of episodes: {len(df_episodes)}\\\")\",\"Check the number of rows before merging\\nprint(len(df_characters))\\nprint(len(df_locations))\\nprint(len(df_script))\\nprint(len(df_episodes))\",\" Check data\\nprint(\\\"Number of characters: \\\", len(df_characters))\\nprint(\\\"Number of locations: \\\", len(df_locations))\\nprint(\\\"Number of episodes: \\\", len(df_episodes))\\nprint(\\\"Number of script lines: \\\", len(df_script))\",\"Check the dataframe sizes\\nprint('Characters:', len(df_characters))\\nprint('Locations:', len(df_locations))\\nprint('Script lines:', len(df_script))\\nprint('Episodes:', len(df_episodes))\",\"Check the length of each DataFrame\\nprint(f\\\"Number of characters: {len(df_characters)}\\\")\\nprint(f\\\"Number of locations: {len(df_locations)}\\\")\\nprint(f\\\"Number of script lines: {len(df_script)}\\\")\\nprint(f\\\"Number of episodes: {len(df_episodes)}\\\")\",\"asic data exploration\\nprint(f\\\"Number of characters: {len(df_characters)}\\\")\\nprint(f\\\"Number of locations: {len(df_locations)}\\\")\\nprint(f\\\"Number of script lines: {len(df_script)}\\\")\\nprint(f\\\"Number of episodes: {len(df_episodes)}\\\")\",\"Show the number of data points in each dataset\\nprint(len(df_characters), len(df_locations), len(df_script), len(df_episodes))\",\" Check the number of records mined in each dataset\\nprint('Number of characters:', len(df_characters))\\nprint('Number of locations:', len(df_locations))\\nprint('Number of script lines:', len(df_script))\\nprint('Number of episodes:', len(df_episodes))\",\"Display number of rows for each dataframe\\nprint('Number of rows:')\\nprint(f'Characters : {len(df_characters)}')\\nprint(f'Locations : {len(df_locations)}')\\nprint(f'Script : {len(df_script)}')\\nprint(f'Episodes : {len(df_episodes)}')\",\"print('Characters:', len(df_characters))\\nprint('Locations:', len(df_locations))\\nprint('Script Lines:', len(df_script))\\nprint('Episodes:', len(df_episodes))\",\"Check the number of lines of each csv file\\nprint(\\\"Number of characters: \\\", len(df_characters))\\nprint(\\\"Number of locations: \\\", len(df_locations))\\nprint(\\\"Number of lines scripts: \\\", len(df_script))\\nprint(\\\"Number of episodes: \\\", len(df_episodes))\",\"Visualize data\\nprint(f'Number of episodes: {len(df_episodes)}')\\nprint(f'Number of characters: {len(df_characters)}')\\nprint(f'Number of locations: {len(df_locations)}')\",\"Get some info on the data sets\\nprint(f'{len(df_script)} lines of script')\\nprint(f'{len(df_episodes)} episodes')\\nprint(f'{len(df_characters)} characters')\\nprint(f'{len(df_locations)} locations')\",\" Explore the structure of the data\\nprint(f\\\"Characters: {len(df_characters)}\\\")\\nprint(f\\\"Locations: {len(df_locations)}\\\")\\nprint(f\\\"Script lines: {len(df_script)}\\\")\\nprint(f\\\"Episodes: {len(df_episodes)}\\\")\",\"Explore the dataset\\nprint(f'Number of data points for characters: {len(df_characters)}')\\nprint(f'Number of data points for locations: {len(df_locations)}')\\nprint(f'Number of data points for script lines: {len(df_script)}')\\nprint(f'Number of data points for episodes: {len(df_episodes)}')\",\" Print the basic data\\nprint(\\\"# characters=\\\", len(df_characters))\\nprint(\\\"# locations=\\\", len(df_locations))\\nprint(\\\"# episodes=\\\", len(df_episodes))\\nprint(\\\"# lines=\\\", len(df_script))\",\"# Debug information\\nprint(f'Total characters in dataset {len(df_characters)}')\\nprint(f'Total unique characters in dataset {df_characters.character.nunique()}')\\nprint(f'Total locations in dataset {len(df_locations)}')\\nprint(f'Total unique locations in dataset {df_locations.location.nunique()}')\\nprint(f'Total script lines in dataset {len(df_script)}')\\nprint(f'Total unique episodes in dataset {df_script.episode_id.nunique()}')\\nprint(f'Total episodes in dataset {len(df_episodes)}')\",\" Checking the data\\nprint(f'Characters: {len(df_characters)}')\\nprint(f'Locations: {len(df_locations)}')\\nprint(f'Script lines: {len(df_script)}')\\nprint(f'Episodes: {len(df_episodes)}')\",\"# Output some metadata about the datasets\\nprint('Characters count:', len(df_characters))\\nprint('Locations count:', len(df_locations))\\nprint('Episode count:', len(df_episodes))\\nprint('Script lines count:', len(df_script))\",\"Print general info about datasets\\nprint(f'Simpsons Characters: {len(df_characters)}')\\nprint(f'Simpsons Locations: {len(df_locations)}')\\nprint(f'Simpsons Script: {len(df_script)}')\\nprint(f'Simpsons Episodes: {len(df_episodes)}')\",\"Show the number of script lines and episodes in the dataset\\nprint(f\\\"Number of script lines: {df_script.shape[0]:,}\\\")\\nprint(f\\\"Number of episodes: {df_episodes.shape[0]:,}\\\")\",\"Print the number of rows in each table\\nprint(f\\\"The characters table has {len(df_characters)} rows.\\\")\\nprint(f\\\"The locations table has {len(df_locations)} rows.\\\")\\nprint(f\\\"The script table has {len(df_script)} rows.\\\")\\nprint(f\\\"The episodes table has {len(df_episodes)} rows.\\\")\",\" Print the number of observations in each data frame\\nprint(f\\\"Number of characters: {len(df_characters)}\\\")\\nprint(f\\\"Number of locations: {len(df_locations)}\\\")\\nprint(f\\\"Number of script lines: {len(df_script)}\\\")\\nprint(f\\\"Number of episodes: {len(df_episodes)}\\\")\",\"Print number of characters, locations, script lines and episodes\\nprint(len(df_characters), len(df_locations), len(df_script), len(df_episodes))\",\"Print out the sizes of the datasets to quickly ensure all datasets have been loaded correctly\\nprint(f\\\"Characters Dataset: {len(df_characters)}\\\")\\nprint(f\\\"Locations Dataset: {len(df_locations)}\\\")\\nprint(f\\\"Script Dataset: {len(df_script)}\\\")\\nprint(f\\\"Episodes Dataset: {len(df_episodes)}\\\")\",\"Check if the data loaded correctly\\nprint(f'Characters: {len(df_characters)}')\\nprint(f'Locations: {len(df_locations)}')\\nprint(f'Script lines: {len(df_script)}')\\nprint(f'Episodes: {len(df_episodes)}')\",\"Optional run to display the number of components in each dataframe\\n# Display the number of components in each dataframe\\nprint(\\n    f'Number of components in the Simpsons character dataframe: {df_characters.size}\\\\n'\\n    f'Number of components in the Simpsons location dataframe: {df_locations.size}\\\\n'\\n    f'Number of components in the Simpsons script dataframe: {df_script.size}\\\\n'\\n    f'Number of components in the Simpsons episode dataframe: {df_episodes.size}'\\n)\",\"show some statistics for easy reference\\nprint(f'Characters dataframe has {len(df_characters)} rows and '\\n      f'{len(df_characters.columns)} columns.')\\nprint(f'Locations dataframe has {len(df_locations)} rows and '\\n      f'{len(df_locations.columns)} columns.')\\nprint(f'Script dataframe has {len(df_script)} rows and '\\n      f'{len(df_script.columns)} columns.')\\nprint(f'Episodes dataframe has {len(df_episodes)} rows and '\\n      f'{len(df_episodes.columns)} columns.')\",\" Show number of rows\\nprint(f\\\"Number of characters: {len(df_characters)}\\\")\\nprint(f\\\"Number of locations: {len(df_locations)}\\\")\\nprint(f\\\"Number of script lines: {len(df_script)}\\\")\\nprint(f\\\"Number of episodes: {len(df_episodes)}\\\")\",\"Show some statistics about the datasets\\nprint(\\\"Number of characters:\\\", len(df_characters))\\nprint(\\\"Number of locations:\\\", len(df_locations))\\nprint(\\\"Number of script lines:\\\", len(df_script))\\nprint(\\\"Number of episodes:\\\", len(df_episodes))\",\"Prune all bad data at the start\\nprint(len(df_characters))\\nprint(len(df_locations))\\nprint(len(df_script))\\nprint(len(df_episodes))\",\"collapse multi-line pandas DataFrames to a single line\\nprint(f\\\"{len(df_characters)} characters, {len(df_locations)} locations, {len(df_script)} script lines, {len(df_episodes)} episodes\\\")\",\" Check file integrity\\nlen(df_episodes)\",\"Show overview of the datasets\\nprint(f'There are {len(df_characters)} characters, {len(df_locations)} locations, {len(df_script)} script lines and {len(df_episodes)} episodes.')\",\"Sanity check\\nprint('Characters:', len(df_characters))\\nprint('Locations:', len(df_locations))\\nprint('Script:', len(df_script))\\nprint('Episodes:', len(df_episodes))\",\"Len of each df\\nlen(df_characters), len(df_locations), len(df_script), len(df_episodes)\"],\"marker\":{\"opacity\":0.5,\"size\":5},\"mode\":\"markers+text\",\"name\":\"19_Count of Data Points and Components in Simpsons Dataset\",\"text\":[\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\"],\"textfont\":{\"size\":12},\"x\":[1.2915425300598145,1.4263113737106323,0.5971155762672424,1.9016057252883911,2.1054065227508545,2.1449508666992188,1.5470598936080933,1.3887479305267334,1.629543423652649,2.020397424697876,2.3194544315338135,2.056279420852661,1.3461813926696777,1.9340955018997192,1.2066813707351685,1.6994863748550415,2.0357720851898193,1.65854811668396,1.7006295919418335,0.9183260798454285,2.5342812538146973,2.203254461288452,1.3303390741348267,1.4017471075057983,1.6245423555374146,1.690602421760559,2.120368003845215,2.3158109188079834,1.5205066204071045,2.242382049560547,1.9518892765045166,1.1518915891647339,1.6229774951934814,1.6144156455993652,1.61512291431427,2.0473952293395996,1.2083849906921387,1.7168513536453247,1.6001216173171997,1.9272713661193848,1.196394681930542,7.100746154785156,1.5889164209365845,2.0136590003967285,1.768629789352417,1.6264793872833252,1.4772003889083862,1.875760555267334,1.6371206045150757,2.364346504211426,1.7365076541900635,1.2129278182983398,1.9070353507995605,2.0958919525146484,2.1036317348480225,1.4208779335021973,2.019122838973999],\"y\":[0.1448887437582016,0.49102696776390076,0.21020834147930145,0.20230089128017426,0.38654080033302307,0.09558753669261932,0.9809348583221436,1.356715202331543,0.6847859025001526,0.8940502405166626,1.4124809503555298,0.20512312650680542,0.5599039793014526,0.8102772831916809,1.2189899682998657,0.19591116905212402,0.8140259981155396,0.8239088654518127,0.33162516355514526,1.226394772529602,0.3336283564567566,0.8828747868537903,2.3850479125976562,1.0972018241882324,0.9500385522842407,0.6801576614379883,0.581610381603241,0.4704367220401764,1.0728251934051514,0.02126627415418625,1.1032708883285522,0.7803828716278076,0.11587388813495636,1.2178698778152466,0.8656951785087585,0.9761630892753601,1.0438086986541748,1.1787549257278442,0.8678173422813416,0.9972022175788879,1.2100175619125366,7.246188640594482,0.6163577437400818,0.4414823651313782,1.2112618684768677,1.3796993494033813,0.7804074287414551,0.12618803977966309,0.16124367713928223,0.217579647898674,0.8779920935630798,2.3588967323303223,0.6385468244552612,2.1600043773651123,1.4815988540649414,1.3119885921478271,1.4076725244522095],\"type\":\"scattergl\"},{\"hoverinfo\":\"text\",\"hovertext\":[\"View first few rows of the Simpsons script DataFrame\\ndf_script.head()\",\" Display the first few rows of the table\\nprint(df_script.head())\",\" Display the first few rows of the dataframe 'df_script'.\\ndf_script.head()\",\"Display the first few rows of the script lines dataframe\\ndf_script.head()\",\" View the first few rows of the dataframe\\ndf_script.head()\",\" Use pandas' head method to print the first 10 rows in df_script\\ndf_script.head(10)\",\" Show first rows of \\\"script\\\" data\\ndf_script.head()\",\" Display first rows of the scripts dataframe\\ndf_script.head()\",\" Show first 10 rows of df_script.\",\" Display the first few rows of the script DataFrame\\ndf_script.head()\",\"Display the first few rows of the script dataframe\\ndf_script.head()\",\" Display the first few entries of the script data frame\\ndisplay(df_script.head())\",\"Display the first few rows of the dataframe df_script\\ndf_script.head()\",\" Optional: Display first rows of the \\\"script\\\" table to have a quick glance\\nprint(df_script.shape)\\ndf_script.head()\",\"The head method shows the first few rows of a DataFrame.\",\"# Display the number of lines and the first few rows of the df_script dataframe\\nprint(df_script.shape)\\ndf_script.head()\",\"View the first few rows of the dataframe\\ndf_script.head()\",\"Display the first few rows\\ndf_script.head()\",\" Display the first few rows of the scripts dataframe\\ndf_script.head()\",\"Display first rows of DataFrame\\ndf_script.head()\",\" Display the first entries of the dataframe containing the script of the Simpson series\\ndf_script.head()\",\" Display the first few rows of the script dataframe\\ndf_script.head()\",\"Display the first rows of the dataframe\\ndf_script.head()\",\" Display the first few rows of the script dataframe\\ndf_script.head()\",\"Display the first few rows to ensure everything is loaded correctly\\ndf_script.head()\",\"Display the first few rows of the script dataframe\\ndf_script.head()\",\"Display the first few rows of the script dataframe\\ndf_script.head()\",\"Show the first few rows of the script dataframe\\ndf_script.head()\",\"View the first 3 rows of the script dataframe\\ndf_script.head(3)\",\" Display the first 10 rows of the \\\"df_script\\\" DataFrame\\ndf_script.head(10)\",\"Show first few rows\\ndf_script.head()\",\"Display the first few rows of the script dataframe\\ndf_script.head()\",\"Display the first few records of the script dataframe\\ndf_script.head()\",\" Displaying first rows of script dataframe\\ndf_script.head()\",\" Show the first few rows of the dataframe \\\"df_script\\\"\\ndf_script.head()\",\"Display the first few rows of the script data\\nprint(df_script.head())\",\"Print the first 10 rows of the script dataframe\\ndf_script.head(10)\",\" Quick visualization of the first few rows in the dataframe\\ndf_script.head()\",\"Print the first few rows of the df script\\ndf_script.head()\",\"Preview first rows of the dataframe\\ndf_script.head()\",\"Remove the excess index column and display the first few rows of the dataframe\\ndf_script = df_script.iloc[:, 1:]\\ndf_script.head()\",\" Show first rows of the table\\ndf_script.head()\",\"Show the first few rows of the dataframe containing the script data\\ndf_script.head()\",\" Show the first rows of the dataframe\\ndf_script.head()\",\"Display the first few rows of the script DataFrame\\ndf_script.head()\",\" View the first few rows of the dataframe\\ndf_script.head()\",\"Optional: Uncomment the line below to view the first few rows of the dataframe\\n# df_script.head()\",\"View the first few rows of the script data\\ndf_script.head()\",\"Display first rows of the script data\\ndf_script.head()\",\"Remove quotes from 'raw_text'\\ndf_script['raw_text'] = df_script['raw_text'].str.replace('\\\"', '')\\n\\n# Display the first rows of the dataframe\\ndf_script.head()\",\"Display the first few rows of the script dataframe\\ndf_script.head()\",\"Display the first few rows of the script dataframe\\ndf_script.head()\",\"Show the first rows of the script dataframe\\ndf_script.head()\",\"Optional: View the columns and first few rows of one of the dataframes\\nprint(df_script.columns)\\ndf_script.head()\",\"# Show first rows\\ndf_script.head()\",\"View the first few rows of the script dataframe\\ndf_script.head()\",\"Display the first few rows of the script lines dataframe\\ndf_script.head()\"],\"marker\":{\"opacity\":0.5,\"size\":5},\"mode\":\"markers+text\",\"name\":\"20_Viewing First Few Rows of a Script DataFrame\",\"text\":[\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\"],\"textfont\":{\"size\":12},\"x\":[2.4351449012756348,1.4226861000061035,1.6170039176940918,1.7934201955795288,2.7668540477752686,1.4165362119674683,2.0695934295654297,2.261148452758789,1.7860466241836548,1.0028526782989502,0.9577360153198242,1.7825100421905518,1.134755253791809,2.4325413703918457,3.4443352222442627,2.3099236488342285,2.693686008453369,1.5346311330795288,1.4615343809127808,2.2268571853637695,2.627578020095825,1.0336635112762451,2.4958455562591553,1.0578296184539795,1.4754738807678223,1.1965824365615845,1.1285293102264404,1.714232087135315,3.052764892578125,1.3386410474777222,1.920456051826477,1.0725668668746948,2.0173869132995605,2.4790279865264893,1.5304888486862183,1.3672301769256592,1.0829824209213257,2.4070823192596436,1.0100743770599365,1.9994698762893677,2.0413975715637207,2.112647771835327,1.3728944063186646,2.3616268634796143,1.0090248584747314,2.5750815868377686,2.5762970447540283,2.468027114868164,2.0382232666015625,2.438171863555908,1.181130290031433,0.9386886358261108,2.4059314727783203,3.195483684539795,2.371671438217163,2.6406283378601074,1.9009884595870972],\"y\":[-6.937604904174805,-7.34130334854126,-7.62872838973999,-7.860893249511719,-6.872167110443115,-6.293120384216309,-7.330382823944092,-7.534169673919678,-6.194797992706299,-7.955425262451172,-7.89570426940918,-8.084868431091309,-7.61369514465332,-6.916631698608398,-7.943167209625244,-7.4063262939453125,-7.080384731292725,-7.278337478637695,-8.179170608520508,-7.8754754066467285,-7.753664016723633,-7.740370273590088,-7.808587074279785,-8.033478736877441,-7.685925006866455,-8.075393676757812,-7.9451775550842285,-7.688457489013672,-7.038577079772949,-7.066810131072998,-7.134036064147949,-7.751503944396973,-8.021028518676758,-7.836834907531738,-7.559815883636475,-7.616153717041016,-7.036046981811523,-7.516470432281494,-7.178235054016113,-6.938614845275879,-8.01542854309082,-7.209499835968018,-7.892383575439453,-7.730891227722168,-7.850521564483643,-7.220051288604736,-7.145036220550537,-6.243863105773926,-7.557625770568848,-8.257046699523926,-7.943132400512695,-7.959168434143066,-7.346803188323975,-6.715278625488281,-7.5631866455078125,-6.878387928009033,-7.85456657409668],\"type\":\"scattergl\"},{\"hoverinfo\":\"text\",\"hovertext\":[\"# show the first 5 lines of the dataframe\\ndf_script.head()\",\"Declare print function for head of tables\\ndef print_head(df, n=5):\\n    print(df.shape)\\n    display(df.head(n))\",\"Display up to 6 rows\\ndf_script.head(6)\",\"Print the first 5 rows of the script dataframe\\ndf_script.head()\",\"Show the first 5 rows of the script dataframe\\ndf_script.head()\",\"display the first 5 rows of the script data frame\\ndf_script.head()\",\"# Show the first 5 rows of the dataframe\\ndf_script.head()\",\"View first 5 records of df_script\\ndf_script.head(5)\",\"Show first 5 rows of dataframe to ensure everything's been read correctly\\ndf_script.head()\",\" Show the first 5 rows of the script dataframe\\ndf_script.head()\",\"Display the first 5 rows of each dataframe\\ndf_script.head()\",\" Show the first 5 rows of the script dataframe\\ndf_script.head(5)\",\"Preview the first 5 rows of the script data\\ndf_script.head()\",\"Preview the first 5 rows of the main dataframe (for Simpsons script lines)\\ndf_script.head()\",\"Print the first 5 rows of the script dataframe\\nprint(df_script.head())\",\"# output the first 5 rows of the script dataframe\\ndf_script.head()\",\"View the first 5 rows of the script dataframe\\ndf_script.head()\",\"Display first 5 records\\ndf_script.head()\",\"Print the first 5 entries of the script dataframe\\ndf_script.head()\",\" Display the first five rows of the script data\\ndf_script.head()\",\"# Print the first 5 lines of the dataframe to ensure it was properly imported\\nprint(df_script.head())\",\" Display first 5 rows of the dataframe\\ndf_script.head()\",\"inspect first 5 rows of script dataframe\\ndf_script.head()\",\" Show first 5 rows of script_lines DataFrame\\ndf_script.head()\",\"# Show first 5 rows\\ndf_script.head(5)\",\" Show the first 5 lines of the script dataframe\\ndf_script.head()\",\"# Outputs first n rows of a dataframe\\ndef firstn(df, n=5):\\n    return df.head(n)\",\" Display the top 5 rows of the script dataframe\\ndf_script.head()\",\"Display the first 5 lines of the dataframe for inspection\\ndf_script.head()\",\"Display the first 5 rows of each file to have a first look of the data\\nprint('Loaded {} samples.'.format(len(df_script)))\\ndf_script.head()\",\"Display the first 5 rows of the script dataframe\\ndf_script.head()\",\"Display the first 5 rows of the \\\"script\\\" dataframe to understand its structure and content\\ndf_script.head()\",\"Display the first 5 rows of the script dataframe\\ndf_script.head()\",\"Display first 5 records of script lines (caption, raw_text, spoken_words)\\ndf_script.head()\",\" Display the first 5 rows of the script dataset\\ndf_script.head()\",\" Get the first 5 rows of the script dataframe\\ndf_script.head()\",\"View first 5 rows of script data\\ndf_script.head()\",\" Display the first 5 rows of the script dataframe\\ndf_script.head()\",\"Preview the first 5 lines of the table\\ndf_script.head()\",\"Print first 5 rows of the script data\\ndf_script.head()\",\"Print first 5 rows of the script dataset\\nscript_dataset = df_script\\nprint(script_dataset.head())\",\"Create a Pandas DataFrame and display the first 5 rows\\ndf_script = pd.DataFrame(df_script)\\ndf_script.head()\",\"Display first 5 rows of df_script\\ndf_script.head(5)\",\" Print first 5 rows from 'script' dataframe\\ndf_script.head()\",\"Display first 5 rows of the script dataframe.\\ndf_script.head()\",\" Display the first five rows of the script dataframe\\ndf_script.head()\",\"Iterating through the pandas dataframe\\nfor index, row in df_script.iterrows():\\n    if index == 5:\\n        break\\n    # Do something by accessing the row\\n    print(row)\",\"Show the first 5 rows of the script dataframe\\ndf_script.head()\",\" Show first 5 rows of the dataframe\\ndf_script.head()\",\"Display top 5 rows of dataframe\\ndf_script.head()\",\"Display the first 5 rows of the table to understand its structure\\ndf_script.head()\",\"# Display the first 5 records of the script lines dataframe\\ndf_script.head()\",\"# Print first 5 rows of the dataframe\\ndf_script.head()\",\" Show the top 5 rows of the dataframe to understand the data\\ndf_script.head()\",\"display the 5 first rows\\ndf_script.head()\",\" Display the first 5 rows of the script dataframe\\ndf_script.head()\",\"Display the first 5 rows of the script dataframe\\ndf_script.head()\"],\"marker\":{\"opacity\":0.5,\"size\":5},\"mode\":\"markers+text\",\"name\":\"21_Displaying and Accessing Rows in a Pandas DataFrame\",\"text\":[\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\"],\"textfont\":{\"size\":12},\"x\":[2.4135544300079346,2.667501211166382,1.505017638206482,1.7698371410369873,2.026007652282715,1.4771648645401,1.705269694328308,1.2983142137527466,1.5675982236862183,1.8156219720840454,1.089756727218628,1.5842723846435547,1.6214416027069092,1.9771144390106201,1.876360297203064,1.15935218334198,1.8164664506912231,1.469871163368225,1.3949456214904785,1.2287278175354004,2.101820230484009,1.0615745782852173,2.2742221355438232,2.105492115020752,1.5216829776763916,2.5431010723114014,1.5861048698425293,0.8840624690055847,2.474273681640625,1.6233888864517212,1.4842808246612549,2.211559534072876,1.1489962339401245,2.072702169418335,1.6964008808135986,2.2465105056762695,1.4768117666244507,1.0217325687408447,1.4684287309646606,1.812734603881836,1.884469747543335,1.2032525539398193,0.99114590883255,1.885084867477417,0.997814953327179,1.150706171989441,2.7994120121002197,2.0789637565612793,1.5793964862823486,0.902854859828949,1.6089742183685303,1.8518052101135254,1.8627734184265137,1.3538696765899658,1.1867197751998901,1.0628938674926758,1.30794358253479],\"y\":[-5.296508312225342,-4.643836498260498,-5.995453834533691,-4.787648677825928,-4.526993274688721,-5.069785118103027,-4.717733860015869,-5.02066707611084,-4.309444904327393,-4.648416996002197,-4.476099967956543,-4.5966081619262695,-6.090609073638916,-5.417892932891846,-4.7180562019348145,-4.880780220031738,-4.886293888092041,-5.424799919128418,-4.471801280975342,-5.43386697769165,-4.752984046936035,-4.341275691986084,-4.9593963623046875,-4.972625255584717,-5.39437198638916,-5.264975547790527,-4.326778411865234,-4.4550909996032715,-6.005527496337891,-4.717727184295654,-4.403692722320557,-5.607059955596924,-4.575564861297607,-5.453977584838867,-5.227723598480225,-4.557793617248535,-5.415757656097412,-4.671983242034912,-5.662412643432617,-5.193491458892822,-5.31856632232666,-4.282494068145752,-5.110939979553223,-4.910624027252197,-4.574466705322266,-4.584682464599609,-5.045433044433594,-4.375415325164795,-4.511789321899414,-4.292446136474609,-5.831361293792725,-5.0149664878845215,-4.454107284545898,-4.299925327301025,-5.258622646331787,-4.823257923126221,-4.70697021484375],\"type\":\"scattergl\"},{\"hoverinfo\":\"text\",\"hovertext\":[\" Retrieve a subset of the Simpsons massive dataset\\nseed = 42  # Seed used for every random function\\ndocs_fraction = 0.05  # Fraction of the complete dataset we want to use\\n\\n# Get a subset of all characters\\ndf_characters_sub = df_characters.sample(frac=docs_fraction, random_state=seed)\\n# Get a subset of all location\\ndf_locations_sub = df_locations.sample(frac=docs_fraction, random_state=seed)\\n# Get a subset of all episodes\\ndf_episodes_sub = df_episodes.sample(frac=docs_fraction, random_state=seed)\\n# Get a subset of all script lines\\ndf_script_sub = df_script[df_script['episode_id'].isin(df_episodes_sub['id'])]  # Use only script lines from the subselected episodes\",\"Filter valid episode scripts\\ndf_script = df_script[df_script['episode_id'].isin(df_episodes['id'])]\",\"Select season 2's data\\nseason2_episode_ids = df_episodes[df_episodes.season == 2].index\\nseason2_script = df_script[df_script['episode_id'].isin(season2_episode_ids)]\",\" Filter scripts to only use episodes from the TV show\\ndf_script = df_script[df_script['episode_id'] \\u003c= 600].reset_index(inplace=False, drop=True)\",\" Look for data with NaNs in the episode data\\ndf_script[df_script['episode_id'].isna()]\",\"Reduce the size of the dataset for the purpose of this lecture\\ndf_script = df_script[df_script['episode_id'] \\u003c 150]\",\"Some cleanup\\ndf_script = df_script[df_script['episode_id'].isin(df_episodes['id'])]\",\"Filter in script lines only\\ndf_script = df_script[df_script['episode_id'].isin(df_episodes[df_episodes[\\\"original_air_date\\\"] \\u003c= '2003-04-27'][\\\"id\\\"])]\",\" filter some bad rows\\ndf_script = df_script[df_script['episode_id'] != 's']\\ndf_episodes = df_episodes[df_episodes['id'] != 's']\",\"Filter episodes from season 1 and 2\\ndf_episodes_1_2 = df_episodes[(df_episodes['season']==1) | (df_episodes['season']==2)]\",\"Limit script to the episodes in the dataset\\nall_ep_ids = df_episodes.id.values\\ndf_script = df_script[df_script['episode_id'].isin(all_ep_ids)]\",\"# Filter out the data with invalid episode_id\\nvalid_episode_ids = set(df_episodes.id)\\ndf_script = df_script[df_script['episode_id'].isin(valid_episode_ids)].reset_index(drop=True)\",\"df_script_subset = df_script[df_script['episode_id'].isin(df_episodes['id'])]\",\"# Extracting the script for a specific episode\\nepisode_id = 168\\nscript = df_script[df_script['episode_id'] == episode_id]\\nscript\",\"\\ndf_script = df_script[df_script[\\\"episode_id\\\"].notna()]\",\"Subset of the first 100 episodes from \\\"The Simpsons\\\" dataset\\ndf_episodes_subset = df_episodes[df_episodes['id'] \\u003c= 100]\",\"Extract just the lines of a single episode to make the example more managable\\nepisode_mask = (df_script['episode_id'] == 1) & (df_script['character_id'] == 9)\\ndf_script = df_script[episode_mask]\",\"Create a subset of episodes if needed\\ndf_subset_episodes = df_episodes[df_episodes[\\\"id\\\"] \\u003c= 600].copy()\",\" Select only the first 10 episodes for simplicity\\ndf_script = df_script[df_script[\\\"episode_id\\\"].isin(df_episodes[\\\"id\\\"].values[:10])].reset_index(inplace=False, drop=True)\",\" Filter and select dataset\\n# Filter dataframe with the episodes of interest by their title\\ndf_episodes_selected = df_episodes[df_episodes['title'] == 'Lisa the Simpson'].reset_index(inplace=False, drop=True)\\n# We use only the first match\\ndf_episodes_selected = df_episodes_selected.iloc[[0]]\",\"Remove episodes without a location\\ndf_script = df_script[df_script['episode_id'].isin(df_locations['episode_id'])]\",\"Reduce data size to speed up training\\ndf_script = df_script[df_script['episode_id'] \\u003c 150].reset_index(inplace=False, drop=True)\",\"Filter out episode titles that are in df_script but not in df_episodes\",\"Check if the episode ID from the script lines are in the episode dataframe\\ndf_script_in_eps = df_script[df_script['episode_id'].isin(df_episodes['id'])]\",\"Filter from season 3 onwards\\ndf_script = df_script[df_script.season \\u003e= 3]\",\"Limit the data to the first 20 seasons for efficiency\\ndf_script = df_script[df_script['episode_id'] \\u003c= 44186]\",\" Select script from episode 1 and 2\\ndf_script_12 = df_script[(df_script[\\\"episode_id\\\"]==1) | (df_script[\\\"episode_id\\\"]==2)].reset_index(inplace=False, drop=True)\",\"Filter relevant seasons and reset index\\ndf_episodes = df_episodes[(df_episodes['season'] \\u003e= 3) & (df_episodes['season'] \\u003c= 28)].reset_index(inplace=False, drop=True)\",\" Filter only the script of the episode with the specified id\\ndf_script_episode = df_script[df_script['episode_id'] == 11]\",\" Remove invalid episode_ids from df_script\\ndf_script = df_script[df_script['episode_id'].isin(df_episodes['id'].values)]\",\"Filter out incorrect rows in df_episodes\",\"Select only 10 random episodes due to computation limits\\nnp.random.seed(0)\\ndf_episode_sample = df_episodes.loc[np.sort(np.random.choice(df_episodes.index, 10, replace=False))]\\ndf_episode_sample.reset_index(inplace=True, drop=True)\",\"ensuring uniformity of data\\ndf_script = df_script[df_script['episode_id'] \\u003c= 600]\",\"remove episode id = 1 as it contains no proper information i.e. script\\u002fseason\\u002fepisode name, etc\\ndf_script = df_script[df_script['episode_id'] != 1]\",\"Select an episode at random\\nnp.random.seed(42)\\nepisode_id = np.random.choice(df_script['episode_id'].unique())\\ndf_script[df_script['episode_id'] == episode_id].head(10)\",\" Filtered season scripts\\ndf_script_filtered = df_script[df_script['episode_id'] \\u003c= df_script[df_script['season']==15]['episode_id'].max()]\",\" Remove invalid IDs from script\\nvalid_ids = set(df_episodes['id'].unique())\\n\\ndf_script = df_script[df_script['episode_id'].isin(valid_ids)].reset_index(inplace=False, drop=True)\",\"Filter by the Simpsons TV show\\ndf_script = df_script[df_script[\\\"episode_id\\\"].isin(df_episodes[df_episodes[\\\"imdb_rating\\\"] \\u003e 7.5][\\\"id\\\"])]\",\"Filter to have only the lines from the first seasons\\ndf_script_first_season = df_script.loc[df_script['episode_id'] \\u003c= 138].copy()\",\"Filter some seasons\\nseasons = list(range(3, 10)) + [11]\\n\\ndf_script = df_script[df_script.season.isin(seasons)]\",\"df_script = df_script[df_script[\\\"episode_id\\\"].isin(df_episodes[df_episodes[\\\"season\\\"].isin(range(2, 10))][\\\"id\\\"])]\\ndf_script = df_script.reset_index(inplace=False, drop=True)\",\" Extract script for requested episode\\nepisode_id = 12\\ndf_episode_script = df_script[df_script['episode_id'] == episode_id]\",\" Filter the script dataframe to only keep the first 20 seasons\\ndf_script = df_script[df_script['episode_id'] \\u003c= 441].reset_index(drop=True)\",\"ignore episodes with missing data\\ndf_script = df_script[~df_script[\\\"episode_id\\\"].isnull()]\",\"Filter episode to have only the Simpsons (no specials)\\ndf_episodes = df_episodes[~df_episodes['title'].str.contains('special')].reset_index(drop=True)\",\"Select Season 1\\ndf_script_s1 = df_script[df_script['episode_id'].isin(df_episodes[df_episodes['season']==1]['id'])]\",\"Query the latest version of a dataset\\nprint(df_script.query('episode_id == 75 and number_in_episode \\u003e= 2 and number_in_episode \\u003c= 5'))\",\"Create a subset of the script dataframe to contain only episodes 1 to 500\",\"Filter out lines from the script that were not included in a specific episode\\ndf_script = df_script[df_script.episode_id.isin(df_episodes['id'])]\",\"Filter out the non-Simpsons episodes\\ndf_episodes = df_episodes[df_episodes['id'].isin(df_script['episode_id'])]\",\"Only use the top 300 episodes to avoid memory errors\\ndf_script = df_script[df_script['episode_id'] \\u003c= 300]\",\"Filter only by the \\\"The Simpsons\\\" show\\ndf_episodes = pd.merge(df_episodes, df_script, on='episode_id')\\ndf_episodes = df_episodes[df_episodes['title'].str.contains('Simpsons')]\\n\\ndf_episodes.groupby('title').agg({\\n    'number': 'first',\\n    'us_viewers_in_millions': 'first',\\n    'views': 'first',\\n    'imdb_rating': 'first'\\n})\",\" Select only the first 6 seasons of the data\\ndf_script = df_script[df_script['season'] \\u003c= 6]\",\" Filter data frame and display it\\ndf_script_filtered = df_script[(df_script['episode_id'] == 652) & (df_script['number'] \\u003c 4)]\\ndf_script_filtered\",\"Set the episode_id for: df_script, df_characters, df_locations\",\" Remove faulty:\\ndf_script = df_script[df_script[\\\"episode_id\\\"] != 394]\"],\"marker\":{\"opacity\":0.5,\"size\":5},\"mode\":\"markers+text\",\"name\":\"22_Filtering and selecting data from a script dataframe and episodes dataframe\",\"text\":[\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\"],\"textfont\":{\"size\":12},\"x\":[4.423309803009033,4.704447269439697,4.24824857711792,4.672640800476074,4.752161026000977,3.7986366748809814,4.321940898895264,4.483236789703369,4.790399074554443,4.045003414154053,3.8645846843719482,4.388551712036133,4.254965305328369,3.9941561222076416,4.662503719329834,4.628684997558594,4.4661946296691895,4.327770233154297,3.7682950496673584,3.899674654006958,4.576763153076172,3.8196732997894287,5.542440891265869,4.958195686340332,5.729372978210449,4.591938495635986,3.6492502689361572,4.4342427253723145,4.723591327667236,4.460465431213379,5.680354118347168,3.7151038646698,3.9544789791107178,4.032543659210205,3.43544602394104,4.92094612121582,3.9415390491485596,4.6327338218688965,4.221273899078369,5.7418437004089355,4.257917404174805,4.345902442932129,4.366185188293457,4.8873162269592285,4.513179779052734,4.487303256988525,4.284242153167725,3.9720184803009033,5.553306579589844,4.969753742218018,4.011694431304932,4.374135971069336,4.995536804199219,4.908641338348389,4.434829235076904,3.9722065925598145],\"y\":[5.32178258895874,4.742568016052246,4.642179012298584,4.54633092880249,4.377787113189697,4.008101940155029,4.926976680755615,4.69392728805542,4.861174583435059,4.0862932205200195,4.669753551483154,4.660613059997559,5.211302757263184,5.286466598510742,5.055657863616943,4.558268070220947,5.138178825378418,4.847379684448242,4.538914680480957,4.9747209548950195,4.947882652282715,4.048415660858154,4.853480815887451,4.696902751922607,4.260159492492676,4.194120407104492,4.910793781280518,4.614408493041992,4.508846759796143,4.961784839630127,4.181674480438232,4.25913143157959,4.241392135620117,4.946916103363037,4.902716159820557,4.731058597564697,4.281022548675537,4.722383975982666,4.930054664611816,3.8477869033813477,4.912614345550537,5.4674859046936035,4.523850440979004,4.834944725036621,5.254939556121826,4.438640594482422,4.507658958435059,3.9950313568115234,4.724238872528076,4.836579322814941,4.479801177978516,5.455804824829102,4.179740905761719,4.652534484863281,4.804934978485107,4.867802619934082],\"type\":\"scattergl\"},{\"hoverinfo\":\"text\",\"hovertext\":[\" Take a look at the content from the characters file\\ndf_characters.head()\",\"Explore the data\\ndf_characters.head()\",\"Inspect content of the characters file\\ndf_characters.head()\",\"Structure df_characters and df_locations to allow seaborn to easily plot the value_counts().\",\"\\n# Quick look at the data\\ndf_characters.head()\",\"# Let's take a look at the characters data\\ndf_characters.head()\",\"Visualize characters data\\ndf_characters.head()\",\"# Look at the first few lines of the characters data frame\\ndf_characters.head()\",\" Data example: Characters\\ndf_characters.head()\",\"Inspect the character data first\\ndf_characters.head()\",\"View a few lines of the characters data\\ndf_characters.head()\",\"Visualisation for df_characters\",\"Look at the data table for characters\\ndf_characters.head()\",\" Quick peek at the characters\\ndf_characters.head()\",\"View some of the data\\ndf_characters.head()\",\"Inspect the head of df_characters\\ndf_characters.head()\",\"# Let's take a look at the characters data\\ndf_characters.head()\",\"Take a look at the character data\\ndf_characters.head()\",\" Visualize the data\\ndf_characters.head()\",\"A quick look at the characters data\\ndf_characters.head()\",\"View Data\\ndf_characters.head()\",\"See the first few lines of the characters data.\\ndf_characters.head()\",\" Characters Avatar\\ndf_characters['raw_character_text']\",\" Display our data to get an overview\\ndf_characters.head()\",\"Let's display them to see their structure\\ndf_characters.head()\",\"# Let's take a quick look at the datasets\\ndf_characters.head()\",\"Explore the data\\ndf_characters.head()\",\" Display the data structures\\ndf_characters.head(3)\",\"ve a look at some data from characters table\\ndf_characters.head()\",\" View a sample of the data in df_characters\\ndf_characters.head()\",\"\\n# Take a look at the characters data\\ndf_characters.head()\",\"Examine the data\\ndf_characters.head()\",\"Display the data to better understand its structure and the available features\\ndf_characters.head()\",\"# Show sample data for characters\\ndf_characters.head()\",\"Quick look at characters data\\ndf_characters.head()\",\" Print few lines of data to see what is present\\ndf_characters.head()\",\"Explore the data\\ndf_characters.head()\",\"View some of the data in `df_characters`\\ndf_characters.head(3)\",\"Inspect the characters data\\ndf_characters.head()\",\"quick look at the characters data\\ndf_characters.head()\",\"Visualize columns info\\ndf_characters.head(3)\",\"Inspect data\\ndf_characters.head()\",\"Data Overview\\ndf_characters.head(3)\",\"Explore character data\\ndf_characters.head()\",\"Take a look at the characters data\\ndf_characters.head()\",\"Take a look at the first 5 rows of the characters data\\ndf_characters.head()\",\" Visualize some of the data\\ndf_characters.head()\",\"Explore the content of the characters file\\ndf_characters.head()\",\"Inspect the characters data\\ndf_characters.head()\",\"Quick look at the data\\ndf_characters.head()\",\"Inspect the characters data\\ndf_characters.head()\",\"Quick look at individual datasframes\\ndf_characters.head()\",\"Quick look at the data\\ndf_characters.head()\",\"take a peek at the characters file\\ndf_characters.head()\",\"Exploring the data\\ndf_characters.head()\",\"Quick peek at the data\\ndf_characters.head()\"],\"marker\":{\"opacity\":0.5,\"size\":5},\"mode\":\"markers+text\",\"name\":\"23_Quick look at characters data\",\"text\":[\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\"],\"textfont\":{\"size\":12},\"x\":[6.85945463180542,6.646976947784424,6.855964183807373,7.61794900894165,6.083858966827393,5.90064811706543,6.236454963684082,6.1303534507751465,7.006819725036621,6.672004699707031,6.369762420654297,6.338871002197266,6.520618438720703,6.146114349365234,6.285116672515869,6.9978413581848145,5.774491310119629,6.549635887145996,6.151206016540527,6.14068603515625,6.707833766937256,6.775845050811768,6.485020637512207,6.865225791931152,6.8691582679748535,5.503170967102051,6.617019176483154,6.812349796295166,6.16746711730957,7.013315677642822,6.247045993804932,6.3494672775268555,6.268698215484619,7.004050254821777,6.0225653648376465,5.4848527908325195,6.664233207702637,6.757270336151123,6.354085922241211,6.261266231536865,6.387718677520752,6.676716327667236,6.684729099273682,6.23336124420166,6.410672664642334,6.2278971672058105,6.3066020011901855,6.595509052276611,6.222628116607666,6.615113735198975,6.267632961273193,5.962686061859131,6.539188385009766,6.762715816497803,6.184689998626709,6.514083385467529],\"y\":[14.202584266662598,16.175125122070312,15.719932556152344,11.082923889160156,14.512222290039062,13.646206855773926,16.051074981689453,14.307866096496582,15.309733390808105,15.752102851867676,16.208171844482422,15.2194242477417,14.521798133850098,15.242461204528809,16.238309860229492,15.581985473632812,14.085143089294434,14.079329490661621,15.705262184143066,14.51197624206543,16.0841064453125,14.413224220275879,12.66801643371582,16.428382873535156,15.253148078918457,14.206905364990234,16.220258712768555,15.981389999389648,14.25679874420166,16.55709457397461,13.962193489074707,15.617330551147461,16.03689956665039,16.000980377197266,14.919489860534668,16.768192291259766,16.20933723449707,16.53737449645996,15.329023361206055,14.644875526428223,15.93625259399414,15.41639232635498,15.493714332580566,16.422147750854492,14.048283576965332,13.777264595031738,15.480576515197754,15.195688247680664,15.305057525634766,14.9542236328125,15.38880443572998,15.078269958496094,15.02216911315918,14.841837882995605,15.778167724609375,15.423921585083008],\"type\":\"scattergl\"},{\"hoverinfo\":\"text\",\"hovertext\":[\"Check the head to ensure that everything is working fine\\ndf_script.head()\",\"Check data import\\ndf_script.head()\",\"check the script data\\ndf_script.head()\",\"Check the content of a few scripts\\ndf_script.head()\",\"Check that the dataframe was loaded correctly\\ndf_script.head()\",\"# Verify the import\\ndf_script.head()\",\"Check the content of the script dataset to see what it looks like\\ndf_script.head(5)\",\"Check correct\\ndf_script.head()\",\"Check that the imports and data load ran correctly\\ndf_script.head()\",\" Check data\\ndf_script.head()\",\"Check everything is ok.\\ndf_script.head()\",\"#  Check if script has been loaded correctly\\ndf_script.head()\",\"Check that the data was loaded correctly\\ndf_script.head()\",\"Check the first row of the dataframe to ensure it loaded correctly\\ndf_script.head(1)\",\"Clean the dialoguue data\\ndf_script.head()\",\"Check if script was loaded correctly\\ndf_script.head()\",\"Check the data\\ndf_script.head()\",\" Check that the script lines dataframe loads correctly\\ndf_script.head()\",\" Check data head\\ndf_script.head()\",\"Check DataFrame contents to ensure they're correctly loaded\\ndf_script.head()\",\" Check the data sample\\ndf_script.head()\",\"Check that the content of the DataFrames was loaded correctly\\ndf_script.head()\",\"Check if the script table is correct\\ndf_script.head()\",\"Examine content of df_script\\ndf_script.head()\",\"Check import of data\\ndf_script.head()\",\"Checks the content of the script data\\ndf_script.head()\",\"Check the data structure\\ndf_script.head()\",\"Check the dataframe is correctly populated\\ndf_script.head()\",\" Check if the script is loaded correctly\\ndf_script.head()\",\"Check that the data has been loaded correctly\\ndf_script.head()\",\" Check the structure of the script lines table\\ndf_script.head()\",\"Check the data correctness\\ndf_script.head()\",\"Check if the data is correctly loaded\\ndf_script.head()\",\"Just checking the content of the file\\ndf_script.head()\",\"Check content of the script data\\ndf_script.head()\",\"check to see what the data look like\\ndf_script.head()\",\"Check data\\ndf_script.head()\",\" Check that the data is correctly loaded\\ndf_script.head()\",\"# Ensure the script is correctly imported\\ndf_script.head()\",\"Check the format of the script data\\ndf_script.head()\",\"Check data and datatypes\\ndf_script.head()\",\"Check the result\\ndf_script.head()\",\"Checking that the data has been read in correctly\\nprint(df_script.head())\",\"Use the variable to see that the CSVs have been read correctly\\ndf_script.head()\",\"Check the first three rows of the script data to see what it looks like\\ndf_script.head(3)\",\"# Check the structure of script data\\ndf_script.head()\",\"Check the data\\ndf_script.head()\",\"Check data integrity\\ndf_script.head()\",\"Check the data format\\nprint(df_script.head(5))\",\"Check the content of `df_script`\",\"Check dataframes load correctly\\ndf_script.head()\",\"check the data\\nprint(df_script.head())\\n\",\"Check\\ndf_script.head()\",\"Test that we have loaded the data correctly\\ndf_script.head()\",\"Check what the script data looks like\\ndf_script.head()\",\"checking my data\\ndf_script.head()\"],\"marker\":{\"opacity\":0.5,\"size\":5},\"mode\":\"markers+text\",\"name\":\"24_Checking if DataFrames are Loaded Correctly\",\"text\":[\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\"],\"textfont\":{\"size\":12},\"x\":[6.3964738845825195,5.194164276123047,5.440454959869385,6.118719100952148,6.4613938331604,5.924180030822754,5.164108753204346,5.868110179901123,6.641439914703369,5.419548988342285,6.360776424407959,5.798281669616699,6.49969482421875,6.127405166625977,6.113677024841309,6.194140434265137,4.993010997772217,6.139575004577637,5.092963218688965,6.5001397132873535,4.822675704956055,6.059144496917725,5.860627174377441,5.9918389320373535,4.893693923950195,6.014484405517578,5.118703365325928,6.434439659118652,6.0128655433654785,6.211285591125488,5.593499183654785,5.7271294593811035,6.186899662017822,5.795718669891357,6.028670310974121,5.759280204772949,5.5154595375061035,6.310409069061279,5.942630290985107,5.494553089141846,6.270254135131836,5.601157188415527,5.605595111846924,6.345576763153076,5.134250164031982,5.73460054397583,5.047581672668457,5.536009311676025,4.924367904663086,6.928534507751465,6.099862575531006,5.190186977386475,5.537829875946045,6.008925437927246,5.555452823638916,5.281367778778076],\"y\":[-2.954411745071411,-2.5193703174591064,-2.8956568241119385,-3.2984092235565186,-3.4112653732299805,-3.845644950866699,-3.2042367458343506,-4.077123641967773,-2.742764711380005,-2.6768221855163574,-3.4086573123931885,-3.6551296710968018,-2.493072986602783,-3.510982036590576,-2.229201078414917,-3.819425344467163,-2.4363465309143066,-3.2881486415863037,-2.5862343311309814,-3.3714756965637207,-2.7597715854644775,-2.9100329875946045,-3.6061112880706787,-3.9304075241088867,-2.574875831604004,-2.9187121391296387,-3.2122159004211426,-3.580369472503662,-4.031477451324463,-2.704052686691284,-3.771857738494873,-3.014758825302124,-3.087975263595581,-3.4369747638702393,-3.1474475860595703,-2.946042776107788,-2.5888614654541016,-2.639986991882324,-3.7316746711730957,-3.026017904281616,-2.2280118465423584,-3.733320951461792,-2.5024056434631348,-2.6292030811309814,-3.6026158332824707,-3.89853572845459,-2.6617279052734375,-2.704193115234375,-3.0799217224121094,-3.3553006649017334,-3.680245876312256,-2.606048822402954,-3.591552495956421,-2.7428410053253174,-3.6358437538146973,-2.6678261756896973],\"type\":\"scattergl\"},{\"hoverinfo\":\"text\",\"hovertext\":[\"Custom imports\",\"Check if tqdm works\",\"Checking if the import is successful.\",\"Custom imports\\nfrom tqdm import tqdm\\nfrom collections import Counter\",\"Custom code\\nfrom elephas.utils.rdd_utils import to_simple_rdd\",\"Checking the imported datasets\",\"Utils script\\nfrom collections import Counter\",\"Check if the imports are working correctly.\",\"More imports\",\"from datetime import datetime\",\"Import dataset\",\"More local imports\\nfrom scripts.features import *\\nfrom scripts.cleaning import *\",\"...and more imports\",\"Set path to data and custom :func:`~utils` (for relative imports).\",\"Plugin Initialization\\nimport nb_black\",\"Local imports\",\"Check what is imported\",\"specific imports\\nfrom sklearn.cluster import KMeans\\nfrom sklearn.feature_extraction.text import TfidfVectorizer\",\" from datetime import datetime\",\"Redo the imports with the correct syntax\",\"Check the imported datasets\",\"Checking that the content has been imported correctly\",\" Access local library\\nimport sys\",\"General imports\\nimport os\",\"Custom imports\\nfrom tqdm import tqdm\\nfrom collections import Counter\",\"# Elasticsearch imports\\nfrom elasticsearch import Elasticsearch, helpers\",\"Check the imported data for each table\",\"Check the imported data\",\"Other imports and settings\",\"Set paths for easier importing\",\"# Use the OS module to handle operating system specific operations\\nimport os\",\"General imports\",\"uer_import\",\"# Note - please ensure that the files have been placed in the correct path as mentioned in the code for the imports to work\",\"Check the import and data loading\",\"Testing whether these imports work\",\"Check to see if all imports were successful.\\nprint('imports successful')\",\"Check file imports\",\" Add a newline after the data import statements for better organization\",\"Add other file imports and related code here\",\"import the functions\\nfrom helpers import clean_text, wasserstein, simplify_movie_name\",\"\\n# Custom imports\\nfrom tqdm import tqdm \",\"fromutils import *\",\"Custom imports\\nfrom utils import preprocess_text\",\"Check the data when it has been imported\",\"Visualisations related imports\",\"Check if tables have been correctly imported\",\"\\nprint(\\\"Import successful\\\")\",\"importing our custom classes and functions\",\" Implement more general imports to work with the data\",\"Locally generated Imports\",\" Additional imports for NLP analysis\",\"Requirement 1.3: The script must make use of a function from each of the imported libraries at least once.\",\" Additional custom imports for natural language processing (NLP)\",\"# Custom imports\\nfrom tqdm import tqdm\\nfrom collections import Counter\"],\"marker\":{\"opacity\":0.5,\"size\":5},\"mode\":\"markers+text\",\"name\":\"25_Imports and Customizations\",\"text\":[\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\"],\"textfont\":{\"size\":12},\"x\":[14.70295524597168,13.82082462310791,15.049053192138672,12.857961654663086,13.931292533874512,14.609430313110352,12.84495735168457,14.84095287322998,14.682218551635742,4.414766311645508,14.440153121948242,13.617237091064453,14.884347915649414,14.605710983276367,14.529716491699219,14.70358657836914,14.972538948059082,13.503116607666016,4.242519378662109,14.369199752807617,14.807424545288086,15.168638229370117,14.70258903503418,14.92013168334961,12.70404052734375,14.35944652557373,14.474533081054688,14.751163482666016,14.463390350341797,15.219956398010254,14.720163345336914,14.419102668762207,15.120826721191406,14.850394248962402,14.971211433410645,14.574213027954102,15.322253227233887,14.863853454589844,13.126646041870117,14.51988697052002,13.961563110351562,13.050002098083496,14.777826309204102,14.228017807006836,14.77574634552002,14.320943832397461,14.445364952087402,15.371255874633789,14.1726655960083,14.313922882080078,14.494230270385742,13.597235679626465,14.144688606262207,14.264119148254395,13.022720336914062],\"y\":[3.9374945163726807,0.9501652717590332,2.554219961166382,10.238837242126465,4.504828929901123,0.5520570278167725,9.57943344116211,3.0327768325805664,3.2264676094055176,1.8136717081069946,1.031815767288208,3.742307424545288,3.596264600753784,4.154154300689697,4.298727035522461,3.5349643230438232,2.019432544708252,1.2294284105300903,2.0160975456237793,3.9683923721313477,0.6193233728408813,2.102005958557129,3.801069974899292,3.897582769393921,10.131543159484863,3.324669122695923,0.465243399143219,1.3643112182617188,3.5913965702056885,3.6126515865325928,4.126497745513916,3.3400096893310547,3.578310489654541,3.4891252517700195,1.7185484170913696,2.478431463241577,2.704578161239624,2.5698935985565186,4.024148941040039,3.716775894165039,4.513919353485107,10.321938514709473,4.1149749755859375,4.510646820068359,1.321529746055603,2.1040847301483154,0.9625265598297119,2.9577767848968506,3.7797234058380127,3.464221477508545,3.6299688816070557,4.351171493530273,3.7945144176483154,4.668375492095947,9.980782508850098],\"type\":\"scattergl\"},{\"hoverinfo\":\"text\",\"hovertext\":[\"Inspect and clean data\",\"First we need to understand the data in order to decide on any data cleaning that may be necessary.\",\"Create a new clean data frame ready for later processing.\",\"\\n# Various functions to clean data for analysis\",\"Discard data before 1989 because the data is too sparse and Springfield hasn't been revealed yet\",\"Data Cleaning and Preprocessing\",\"Data exploration and cleaning\",\" Time to redo them after reworking the the dirty data\",\"Data Preparation\",\" Data cleaning\",\"Clean Data\",\"Additional data cleaning\",\"Data Processing\",\"Cleaning data\",\"Remove any bad data points.\",\"Data preparation\",\"Clean up missing and bad data\",\"Data Preparation\",\"Data cleaning\",\" Some cleaning of fields and datatypes\",\"Data operations\",\" Data cleaning\",\"Inspect the data for any important details and initial data cleaning\",\"Data sanitization and exploration\",\"Data Preprocessing and Cleaning\",\"Mapping data for easier cleanup.\",\"Data exploration and data cleaning\",\"Checking the data and cleaning it\",\"Data Overview and Cleaning\",\"Data cleaning and formatting\",\"Data Processing\",\" Define functions to clean the data\",\"A 2-minute version of the cleaning procedure is initiated.\",\" Load the cleaned files\",\"Preprocess the data, e.g. remove unneeded columns, merge on shared information, etc.\",\"Sanitize data\",\"Data exploration and cleaning\",\"Cleaning data to remove any unnecessary columns and data.\",\"Clean the data\",\"Data cleaning and processing\",\"Some Data Cleaning\",\"Data pre-processing\",\"Data cleaning and pre-processing\",\"Data preparation\",\" Data Cleaning\",\"Inspecting and cleaning the data\",\"Data Cleaning\",\" Data Cleaning\",\"A quick look at the data shows that it needs a bit of cleaning up before it'll be very useful to us.\",\"Data cleaning and preparation\",\" Some initial cleanup\",\"Cleaning the data\",\"Cleaning the dataset\",\"Prepare data for modeling\",\"Data Cleaning and Processing\"],\"marker\":{\"opacity\":0.5,\"size\":5},\"mode\":\"markers+text\",\"name\":\"26_Data Cleaning\",\"text\":[\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\"],\"textfont\":{\"size\":12},\"x\":[13.465062141418457,13.468806266784668,11.369134902954102,12.854736328125,12.18978214263916,12.383943557739258,13.158087730407715,12.332196235656738,13.478543281555176,12.456894874572754,12.243098258972168,12.596424102783203,12.688684463500977,12.366033554077148,11.49886703491211,12.989477157592773,11.547563552856445,13.140456199645996,12.582751274108887,11.959831237792969,12.499743461608887,12.631625175476074,14.016563415527344,12.748041152954102,12.547826766967773,12.78632640838623,13.075212478637695,13.160482406616211,13.15837287902832,12.36966609954834,12.893723487854004,12.502191543579102,13.500602722167969,12.466981887817383,11.812737464904785,12.520455360412598,13.176706314086914,11.375940322875977,12.234492301940918,12.580971717834473,12.965673446655273,13.101846694946289,13.17431926727295,12.987152099609375,12.66504192352295,13.12686538696289,12.646554946899414,12.555350303649902,14.659417152404785,12.997575759887695,13.190327644348145,12.039960861206055,11.391408920288086,13.514525413513184,12.68675708770752],\"y\":[0.8087747693061829,0.6871502995491028,0.7407957911491394,1.4320582151412964,1.1632922887802124,1.8176170587539673,1.4504860639572144,1.5226131677627563,1.8114031553268433,1.1318838596343994,1.5058507919311523,0.6728518009185791,0.9310681819915771,1.4713331460952759,1.3702956438064575,2.1142332553863525,1.2152199745178223,1.9790713787078857,1.1315762996673584,1.6318378448486328,1.0072557926177979,1.211706280708313,0.8356477618217468,1.8656120300292969,2.284539222717285,0.7878627777099609,1.0125821828842163,0.6932836771011353,1.1931183338165283,1.9243571758270264,1.4495649337768555,1.2948603630065918,1.5341682434082031,2.3609511852264404,1.6560304164886475,1.4509367942810059,1.2781652212142944,1.6127907037734985,0.9327532649040222,1.422743558883667,1.1432771682739258,1.6419291496276855,1.984221339225769,2.1910479068756104,0.9931579828262329,0.8217092752456665,1.3238153457641602,1.0678116083145142,0.46408575773239136,1.53147292137146,1.918985366821289,1.4863284826278687,0.9336421489715576,2.7306175231933594,1.4621374607086182],\"type\":\"scattergl\"},{\"hoverinfo\":\"text\",\"hovertext\":[\" Reformat dataframe to have a consistent '_id' column\\ndf_characters['_id'] = df_characters['id']\\ndf_locations['_id'] = df_locations['id']\\ndf_script['_id'] = df_script['id']\\ndf_episodes['_id'] = df_episodes['id']\\n\\n# Set the indices to '_id'\\ndf_characters.set_index('_id', inplace=True)\\ndf_locations.set_index('_id', inplace=True)\\ndf_script.set_index('_id', inplace=True)\\ndf_episodes.set_index('_id', inplace=True)\",\"Change index name for better consistency\\ndf_characters.index.name = 'character_id'\\ndf_locations.index.name = 'location_id'\\ndf_episodes.index.name = 'episode_id'\\ndf_script.index.name = 'line_id'\",\"Set the `index` of each DataFrame to the `id` column\\ndf_characters.set_index('id', inplace=True)\\ndf_locations.set_index('id', inplace=True)\\ndf_script.set_index('id', inplace=True)\\ndf_episodes.set_index('id', inplace=True)\",\"Drop the index from the DataFrames\\ndf_characters.reset_index(inplace=True, drop=True)\\ndf_locations.reset_index(inplace=True, drop=True)\\ndf_script.reset_index(inplace=True, drop=True)\\ndf_episodes.reset_index(inplace=True, drop=True)\",\"Drop the unnecessary 'index' column from each dataframe\\ndf_characters.drop('index', axis=1, inplace=True)\\ndf_locations.drop('index', axis=1, inplace=True)\\ndf_script.drop('index', axis=1, inplace=True)\\ndf_episodes.drop('index', axis=1, inplace=True)\",\" Set the character_id column as the index for the characters and locations DataFrames\\ndf_characters.set_index('id', inplace=True)\\ndf_locations.set_index('id', inplace=True)\",\"del df_characters['Unnamed: 0']\\ndel df_locations['Unnamed: 0']\\ndel df_script['Unnamed: 0']\\ndel df_episodes['Unnamed: 0']\",\"Smaller samples for testing\\ndf_characters = df_characters.sample(100).reset_index(drop=True)\\ndf_locations = df_locations.sample(100).reset_index(drop=True)\\ndf_script = df_script.sample(1000).reset_index(drop=True)\\ndf_episodes = df_episodes.reset_index(drop=True)\",\"Set the 'id' column as the index for each DataFrame\\ndf_characters.set_index('id', inplace=True)\\ndf_locations.set_index('id', inplace=True)\\ndf_episodes.set_index('id', inplace=True)\\ndf_script.set_index('id', inplace=True)\",\"Set the 'id' column as the index for each DataFrame\\ndf_characters.set_index('id', inplace=True)\\ndf_locations.set_index('id', inplace=True)\\ndf_episodes.set_index('id', inplace=True)\",\"Set index for faster searches\\ndf_characters.set_index('id', inplace=True)\\ndf_locations.set_index('id', inplace=True)\\ndf_episodes.set_index('id', inplace=True)\",\"Ensure that 'id' field is unique for all the dataframes\\nassert df_characters['id'].nunique() == len(df_characters)\\nassert df_locations['id'].nunique() == len(df_locations)\\nassert df_script['id'].nunique() == len(df_script)\\nassert df_episodes['id'].nunique() == len(df_episodes)\",\"# Correctly identify the index column\\ndf_characters = df_characters.set_index('id')\\ndf_locations = df_locations.set_index('id')\\ndf_script = df_script.set_index('id')\\ndf_episodes = df_episodes.set_index('id')\",\" ensure every dataframe has an 'id' column\\ndf_characters['id'] = df_characters.index\\ndf_locations['id'] = df_locations.index\\ndf_script['id'] = df_script.index\\ndf_episodes['id'] = df_episodes.index\",\"Cleans up a few things first\\nfor df in [df_characters, df_locations, df_script, df_episodes]:\\n    if 'Unnamed: 0' in df.columns:\\n        df.drop(['Unnamed: 0'], axis=1, inplace=True)\",\"Set the 'id' column as index for faster lookups\\ndf_characters.set_index('id', inplace=True)\\ndf_locations.set_index('id', inplace=True)\\ndf_episodes.set_index('id', inplace=True)\",\"Set index accordingly\\ndf_characters.set_index('character_id', inplace=True)\\ndf_locations.set_index('location_id', inplace=True)\\ndf_script.set_index('id', inplace=True)\\ndf_episodes.set_index('id', inplace=True)\",\" make it easier to access data by using index\\ndf_episodes.set_index('id', inplace=True)\\ndf_script.set_index('id', inplace=True)\\ndf_characters.set_index('id', inplace=True)\\ndf_locations.set_index('id', inplace=True)\",\" Set pandas to use 'id' as the index for all DataFrames\\ndf_characters.set_index('id', inplace=True)\\ndf_locations.set_index('id', inplace=True)\\ndf_script.set_index('id', inplace=True)\\ndf_episodes.set_index('id', inplace=True)\",\" Set the index to the unique identifier\\ndf_characters.set_index('id', inplace=True)\\ndf_locations.set_index('id', inplace=True)\\ndf_episodes.set_index('id', inplace=True)\\ndf_script.set_index('id', inplace=True)\",\"Remove column containing index\\ndf_episodes = df_episodes.iloc[:, 1:]\",\"Manually set the index to the 'id' field\\ndf_characters.set_index('id', inplace=True)\\ndf_locations.set_index('id', inplace=True)\\ndf_script.set_index('id', inplace=True)\\ndf_episodes.set_index('id', inplace=True)\",\"Set the index of the datasets to the unique id of the associated elements\\ndf_characters.set_index('id', inplace=True)\\ndf_locations.set_index('id', inplace=True)\\ndf_episodes.set_index('id', inplace=True)\\ndf_script.set_index('id', inplace=True)\",\"Update index and print shapes\\ndf_characters.reset_index(inplace=True, drop=True)\\ndf_locations.reset_index(inplace=True, drop=True)\\ndf_script.reset_index(inplace=True, drop=True)\\ndf_episodes.reset_index(inplace=True, drop=True)\\n\\n# Print shapes\\nprint(df_characters.shape)\\nprint(df_locations.shape)\\nprint(df_script.shape)\\nprint(df_episodes.shape)\",\"Set the 'id' column as the index for each dataframe\\ndf_characters.set_index('id', inplace=True)\\ndf_locations.set_index('id', inplace=True)\\ndf_script.set_index('id', inplace=True)\\ndf_episodes.set_index('id', inplace=True)\",\"  Drop first column from all dataframes\\ndf_characters = df_characters.iloc[:,1:]\\ndf_locations = df_locations.iloc[:,1:]\\ndf_script = df_script.iloc[:,1:]\\ndf_episodes = df_episodes.iloc[:,1:]\",\"Set index to take full use of Pandas functionalities\\ndf_characters.set_index('id', inplace=True)\\ndf_locations.set_index('id', inplace=True)\\ndf_script.set_index('id', inplace=True)\\ndf_episodes.set_index('id', inplace=True)\",\"Delete the first column\\ndf_characters = df_characters.iloc[:, 1:]\\ndf_locations = df_locations.iloc[:, 1:]\\ndf_script = df_script.iloc[:, 1:]\\ndf_episodes = df_episodes.iloc[:, 1:]\",\" Set index to 'id' for all dataframes\\ndf_script.set_index('id', inplace=True)\\ndf_characters.set_index('id', inplace=True)\\ndf_locations.set_index('id', inplace=True)\\ndf_episodes.set_index('id', inplace=True)\",\"Set the 'id' column as index for easier access\\ndf_characters.set_index('id', inplace=True)\\ndf_locations.set_index('id', inplace=True)\\ndf_script.set_index('id', inplace=True)\\ndf_episodes.set_index('id', inplace=True)\",\"Check\\u002fReset Index\\ndf_characters = df_characters.reset_index(inplace=False, drop=True)\\ndf_locations = df_locations.reset_index(inplace=False, drop=True)\\ndf_script = df_script.reset_index(inplace=False, drop=True)\\ndf_episodes = df_episodes.reset_index(inplace=False, drop=True)\",\"Set index for fast row selection and filtering\\ndf_characters.set_index('id', inplace=True)\\ndf_locations.set_index('id', inplace=True)\\ndf_episodes.set_index('id', inplace=True)\\ndf_script.set_index('id', inplace=True)\",\" Add dummy index to unique identify rows in the original dataframes\\ndf_characters['orig_index'] = df_characters.index\\ndf_locations['orig_index'] = df_locations.index\\ndf_episodes['orig_index'] = df_episodes.index\\ndf_script['orig_index'] = df_script.index\",\"Set index after loading the csv files\\ndf_script.set_index('id',inplace=True)\\ndf_characters.set_index('id', inplace=True)\\ndf_locations.set_index('id',inplace=True)\\ndf_episodes.set_index('id',inplace=True)\",\" Change index of all the dataframes to id of each corresponding entry\\ndf_characters.set_index('id', inplace=True)\\ndf_locations.set_index('id', inplace=True)\\ndf_script.set_index('id', inplace=True)\\ndf_episodes.set_index('id', inplace=True)\",\"Set consistent index name for all datasets\\ndf_script.index.name = 'script_index'\\ndf_locations.index.name = 'location_index'\\ndf_characters.index.name = 'character_index'\\ndf_episodes.index.name = 'episode_index'\",\"# Add index in each dataframe\\ndf_characters.index.name = 'character_id'\\ndf_locations.index.name = 'location_id'\\ndf_script.index.name = 'line_id'\\ndf_episodes.index.name = 'episode_id'\",\" remove 'id' column which is equivalent to the index\\ndf_characters.drop('id',axis=1,inplace=True)\\ndf_locations.drop('id',axis=1,inplace=True)\\ndf_script.drop('id',axis=1,inplace=True)\\ndf_episodes.drop('id',axis=1,inplace=True)\",\"# Reset index for all df except df_script\\ndf_characters = df_characters.reset_index(inplace=False, drop=True)\\ndf_locations = df_locations.reset_index(inplace=False, drop=True)\\ndf_episodes = df_episodes.reset_index(inplace=False, drop=True)\",\"Remove the first index column from DataFrames\\ndf_episodes = df_episodes.iloc[:,1:]\\ndf_characters = df_characters.iloc[:,1:]\\ndf_locations = df_locations.iloc[:,1:]\\ndf_script = df_script.iloc[:,1:]\",\" Set index for faster access\\ndf_characters.set_index('id', inplace=True)\\ndf_locations.set_index('id', inplace=True)\\ndf_episodes.set_index('id', inplace=True)\",\" Remove extra index column from dataframes\\ndf_characters = df_characters.iloc[:,1:]\\ndf_locations = df_locations.iloc[:,1:]\\ndf_script = df_script.iloc[:,1:]\\ndf_episodes = df_episodes.iloc[:,1:]\",\" Check that location_id and episode_id are meaningful indices\\nprint(df_locations.index)\\nprint(df_episodes.index)\",\"Set the index for optimal merge and search performance\\ndf_characters.set_index('id', inplace=True)\\ndf_locations.set_index('id', inplace=True)\\ndf_episodes.set_index('id', inplace=True)\",\"set index to unique keys\\ndf_characters = df_characters.set_index('id')\\ndf_locations = df_locations.set_index('id')\\ndf_script = df_script.set_index('id')\\ndf_episodes = df_episodes.set_index('id')\",\"We'll use the 'episode_id' field as index for every dataframe\\ndf_characters.set_index('episode_id', inplace=True)\\ndf_locations.set_index('episode_id', inplace=True)\\ndf_script.set_index('episode_id', inplace=True)\\ndf_episodes.set_index('id', inplace=True)\",\" Set index of dataframe to id column\\ndf_characters.set_index('id', inplace=True)\\ndf_locations.set_index('id', inplace=True)\\ndf_episodes.set_index('id', inplace=True)\",\" Create an index for quicker lookup\\ndf_characters.set_index('id', inplace=True)\\ndf_locations.set_index('id', inplace=True)\\ndf_episodes.set_index('id', inplace=True)\",\" Remove 'id' column from all DataFrames\\ndf_characters.drop(columns=['id'], inplace=True)\\ndf_locations.drop(columns=['id'], inplace=True)\\ndf_script.drop(columns=['id'], inplace=True)\\ndf_episodes.drop(columns=['id'], inplace=True)\",\"Setting \\\"Unnamed: 0\\\" as index for all dataframes\\ndf_characters.index = df_characters['Unnamed: 0']\\ndf_locations.index = df_locations['Unnamed: 0']\\ndf_script.index = df_script['Unnamed: 0']\\ndf_episodes.index = df_episodes['Unnamed: 0']\",\"Setting the index for easier data retrieval and searches\\ndf_characters.set_index('id', inplace=True)\\ndf_locations.set_index('id', inplace=True)\\ndf_episodes.set_index('id', inplace=True)\",\" Set id as index\\ndf_characters.set_index('id', inplace=True)\\ndf_locations.set_index('id', inplace=True)\\ndf_episodes.set_index('id', inplace=True)\\ndf_script.set_index('id', inplace=True)\",\"Clean the dataframes from potentially corrupted rows\\ndf_script = df_script.dropna(subset=['character_id', 'location_id', 'id']).reset_index(inplace=False, drop=True)\\ndf_episodes = df_episodes.dropna(subset=['id', 'original_air_date']).reset_index(inplace=False, drop=True)\",\"Set the index appropriately for each DataFrame\\ndf_characters.set_index(\\\"id\\\", inplace=True)\\ndf_locations.set_index(\\\"id\\\", inplace=True)\\ndf_episodes.set_index(\\\"id\\\", inplace=True)\\ndf_script.set_index(\\\"id\\\", inplace=True)\",\"Set the 'id' column as the index for each dataframe\\ndf_characters.set_index('id', inplace=True)\\ndf_locations.set_index('id', inplace=True)\\ndf_script.set_index('id', inplace=True)\\ndf_episodes.set_index('id', inplace=True)\"],\"marker\":{\"opacity\":0.5,\"size\":5},\"mode\":\"markers+text\",\"name\":\"27_Dataframe Index and Column Transformation\",\"text\":[\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\"],\"textfont\":{\"size\":12},\"x\":[2.784069061279297,3.26401948928833,2.583111047744751,3.143320322036743,3.2770698070526123,3.5142996311187744,4.181556224822998,3.5625476837158203,2.3893840312957764,2.909475803375244,3.282362461090088,3.021803379058838,3.0508172512054443,2.8756608963012695,3.9837639331817627,3.090808391571045,2.8710997104644775,2.7883288860321045,2.615098476409912,2.6578967571258545,3.6205923557281494,2.5078983306884766,2.3546700477600098,3.2655370235443115,2.671823740005493,3.491659641265869,2.6144859790802,3.420930862426758,2.555687427520752,2.6167376041412354,3.454026222229004,2.7890725135803223,2.431896209716797,2.166332721710205,2.6631698608398438,3.1509525775909424,3.1778345108032227,3.508185863494873,3.541217565536499,3.5109264850616455,2.949354410171509,3.276151180267334,2.949368715286255,3.217217206954956,3.0406014919281006,2.8973371982574463,3.061896800994873,2.988426685333252,3.586069107055664,3.443640947341919,3.1697514057159424,2.5692026615142822,4.040643692016602,2.569011926651001,2.754401683807373],\"y\":[5.094765663146973,4.3764567375183105,4.7064313888549805,4.194234848022461,4.464869976043701,6.355252265930176,3.725029230117798,4.8514180183410645,4.613972187042236,5.026772499084473,3.3883018493652344,5.063963890075684,4.812560081481934,4.4738335609436035,4.414265155792236,3.4068377017974854,4.18333101272583,4.018765926361084,4.987891674041748,4.030632495880127,4.428308486938477,4.365354537963867,4.268104553222656,4.5341596603393555,5.100341320037842,4.554091453552246,4.298064708709717,4.3141069412231445,4.5053815841674805,4.215767860412598,4.632728576660156,3.9057836532592773,4.110715866088867,3.88399076461792,4.4205522537231445,3.8042125701904297,4.552589416503906,4.515686511993408,4.806241989135742,3.9962644577026367,3.594470739364624,4.352821350097656,4.680339336395264,3.676516056060791,4.783156394958496,4.920447826385498,4.723774433135986,3.6432793140411377,4.940341949462891,3.9347734451293945,4.0609917640686035,4.0726799964904785,5.015810012817383,4.423429012298584,5.0988359451293945],\"type\":\"scattergl\"},{\"hoverinfo\":\"text\",\"hovertext\":[\"Checkin some dataframes basic info\\ndf_characters.info(), df_locations.info(), df_script.info(), df_episodes.info()\",\"Print basic info on each dataframe\\nprint(\\\"Characters\\\")\\nprint(df_characters.info())\\nprint(\\\"Locations\\\")\\nprint(df_locations.info())\\nprint(\\\"Script Lines\\\")\\nprint(df_script.info())\\nprint(\\\"Episodes\\\")\\nprint(df_episodes.info())\",\" Print info of the datasets\\nprint('Characters:')\\nprint(df_characters.info())\\nprint()\\nprint('Locations:')\\nprint(df_locations.info())\\nprint()\\nprint('Script:')\\nprint(df_script.info())\",\"Display some information about the datasets\\nprint(\\\"Characters info:\\\")\\nprint(df_characters.info())\\nprint(\\\"\\\\nLocations info:\\\")\\nprint(df_locations.info())\\nprint(\\\"\\\\nScript info:\\\")\\nprint(df_script.info())\\nprint(\\\"\\\\nEpisodes info:\\\")\\nprint(df_episodes.info())\",\"Dataset information\\nprint(df_characters.info())\\nprint(df_locations.info())\\nprint(df_script.info())\\nprint(df_episodes.info())\",\"Display some basic information about the datasets\\nprint('Characters')\\nprint(df_characters.info())\\nprint(df_characters.head())\\nprint()\\nprint('Locations')\\nprint(df_locations.info())\\nprint(df_locations.head())\\nprint()\\nprint('Script')\\nprint(df_script.info())\\nprint(df_script.head())\\nprint()\\nprint('Episodes')\\nprint(df_episodes.info())\\nprint(df_episodes.head())\",\" Display data details\\ndf_characters.info()\\ndf_locations.info()\\ndf_script.info()\\ndf_episodes.info()\",\" Evaluating data quality\\ndf_characters.info(), df_locations.info(), df_script.info(), df_episodes.info()\",\"Print a summary of the data in each DataFrame\\nprint('Characters:')\\nprint(df_characters.info())\\nprint('\\\\nLocations:')\\nprint(df_locations.info())\\nprint('\\\\nScript:')\\nprint(df_script.info())\\nprint('\\\\nEpisodes:')\\nprint(df_episodes.info())\",\"View information of key tables\\nprint('Characters')\\ndisplay(df_characters.info())\\ndisplay(df_characters.head())\\n\\nprint('Locations')\\ndisplay(df_locations.info())\\ndisplay(df_locations.head())\",\"We have the following dataframes available:\\n# - df_characters: Information about the characters\\n# - df_locations: Information about the locations\\n# - df_script: Information about the script lines\\n# - df_episodes: Information about the episodes\",\"Display basic information of each dataframe\\n[df.info() for df in [df_characters, df_locations, df_script, df_episodes]]\",\" Display basic information about the datasets\\nprint(df_characters.info())\\nprint(df_locations.info())\\nprint(df_script.info())\\nprint(df_episodes.info())\",\"Display basic information about the dataframes\\nprint('\\\\n---Characters---')\\nprint(df_characters.info())\\nprint(df_characters.head())\\n\\nprint('\\\\n---Locations---')\\nprint(df_locations.info())\\nprint(df_locations.head())\\n\\nprint('\\\\n---Script---')\\nprint(df_script.info())\\nprint(df_script.head())\\n\\nprint('\\\\n---Episodes---')\\nprint(df_episodes.info())\\nprint(df_episodes.head())\",\"Print basic info for each dataframe\\nprint(\\\"Characters Dataset:\\\")\\nprint(df_characters.info())\\n\\nprint(\\\"\\\\nLocations Dataset:\\\")\\nprint(df_locations.info())\\n\\nprint(\\\"\\\\nScript Dataset:\\\")\\nprint(df_script.info())\\n\\nprint(\\\"\\\\nEpisodes Dataset:\\\")\\nprint(df_episodes.info())\",\" Profiling of data\\nprint(\\\"Episodes\\\"); df_episodes.info()\\nprint(\\\"\\\\nLocations\\\"); df_locations.info()\\nprint(\\\"\\\\nCharacters\\\"); df_characters.info()\\nprint(\\\"\\\\nScript\\\"); df_script.info()\",\" Display general information about the datasets\\ndf_characters.info()\\ndf_locations.info()\\ndf_script.info()\\ndf_episodes.info()\",\"Display the basic information about datasets\\nprint(\\\"\\\\n- Simpsons Episodes - \\\")\\nprint(df_episodes.info())\\nprint(\\\"\\\\n- Simpsons Characters - \\\")\\nprint(df_characters.info())\\nprint(\\\"\\\\n- Simpsons Locations - \\\")\\nprint(df_locations.info())\\nprint(\\\"\\\\n- Simpsons Scripts - \\\")\\nprint(df_script.info())\",\" Inspect DataFrame details\\nprint(\\\"\\\\n\\\\n==== Characters ====\\\")\\nprint(df_characters.info())\\n\\nprint(\\\"\\\\n\\\\n==== Locations ====\\\")\\nprint(df_locations.info())\\n\\nprint(\\\"\\\\n\\\\n==== Episodes ====\\\")\\nprint(df_episodes.info())\\n\\nprint(\\\"\\\\n\\\\n==== Script Lines ====\\\")\\nprint(df_script.info())\",\" Display some general information about the datasets\\nprint('Characters\\\\n')\\nprint(df_characters.info())\\nprint(df_characters.head())\\nprint('\\\\nLocations\\\\n')\\nprint(df_locations.info())\\nprint(df_locations.head())\\nprint('\\\\nScript\\\\n')\\nprint(df_script.info())\\nprint(df_script.head())\\nprint('\\\\nEpisodes\\\\n')\\nprint(df_episodes.info())\\nprint(df_episodes.head())\",\" Show info for each dataframe\\ndf_characters.info()\\ndf_locations.info()\\ndf_script.info()\\ndf_episodes.info()\",\" Display general information about the datasets\\nprint(\\\"Characters Data:\\\")\\ndisplay(df_characters.info())\\ndisplay(df_characters.head(3))\\n\\nprint(\\\"\\\\nLocations Data:\\\")\\ndisplay(df_locations.info())\\ndisplay(df_locations.head(3))\\n\\nprint(\\\"\\\\nScript Data:\\\")\\ndisplay(df_script.info())\\ndisplay(df_script.head(3))\\n\\nprint(\\\"\\\\nEpisodes Data:\\\")\\ndisplay(df_episodes.info())\\ndisplay(df_episodes.head(3))\",\"Inspect structure of each DataFrame\\ndf_characters.info(), df_locations.info(), df_script.info(), df_episodes.info()\",\" Quick look at the data\\nprint(df_characters.info())\\nprint(df_locations.info())\\nprint(df_script.info())\\nprint(df_episodes.info())\",\"View dataframe info\\nprint(df_characters.info())\\nprint(df_locations.info())\\nprint(df_script.info())\\nprint(df_episodes.info())\",\"Some lines exploration\\nprint(df_characters.info())\\nprint(df_locations.info())\",\"Display general information about the datasets\\nprint('[INFO] Characters')\\ndf_characters.info()\\nprint('\\\\n[INFO] Locations')\\ndf_locations.info()\\nprint('\\\\n[INFO] Script')\\ndf_script.info()\\nprint('\\\\n[INFO] Episodes')\\ndf_episodes.info()\",\"Get some info of datas\\nprint(df_characters.info())\\nprint(df_locations.info())\",\"# Check the structure of the dataframes\\nprint(df_characters.info())\\nprint(df_locations.info())\\nprint(df_script.info())\\nprint(df_episodes.info())\",\" Print some information about the obtained datasets\\nprint(\\\"Characters:\\\")\\nprint(df_characters.info())\\nprint(\\\"\\\\n_________________________\\\\nLocations:\\\")\\nprint(df_locations.info())\\nprint(\\\"\\\\n_________________________\\\\nScript:\\\")\\nprint(df_script.info())\\nprint(\\\"\\\\n_________________________\\\\nEpisodes:\\\")\\nprint(df_episodes.info())\",\" View dataframe structure\\nprint(df_characters.info())\\nprint(df_locations.info())\\nprint(df_script.info())\\nprint(df_episodes.info())\",\"ECOMMENDATION_ID: rQs3QxgK\\n# We get basic information about thtdf_characters.info()e datasets to know what we are dealing with\\nprint('Characters:', df_characters.info())\\n# print('Locations:', df_locations.info())\\n# print('Script lines:', df_script.info())\\n# print('Episodes:', df_episodes.info())\",\"Check dataframes information\\nprint(df_characters.info())\\nprint(df_locations.info())\\nprint(df_script.info())\\nprint(df_episodes.info())\",\"Print info about each dataframe\\nprint('Characters:')\\nprint(df_characters.info())\\n\\nprint('Locations:')\\nprint(df_locations.info())\\n\\nprint('Script:')\\nprint(df_script.info())\\n\\nprint('Episodes:')\\nprint(df_episodes.info())\",\" Display some information about the datasets\\nprint(\\\"\\\\nInformation about the dataset - Characters\\\")\\ndf_characters.info()\\n\\nprint(\\\"\\\\n\\\\nInformation about the dataset - Locations\\\")\\ndf_locations.info()\\n\\nprint(\\\"\\\\n\\\\nInformation about the dataset - Script lines\\\")\\ndf_script.info()\\n\\nprint(\\\"\\\\n\\\\nInformation about the dataset - Episodes\\\")\\ndf_episodes.info()\",\" show schema of characters\\nprint(df_characters.dtypes)\\nprint(df_characters.head())\\n\\n# show schema of locations\\nprint(df_locations.dtypes)\\nprint(df_locations.head())\",\" Print out a summary of each dataset\\nprint(\\\"Characters:\\\")\\nprint(df_characters.info())\\n\\nprint(\\\"\\\\nLocations\\\")\\nprint(df_locations.info())\\n\\nprint(\\\"\\\\nScript\\\")\\nprint(df_script.info())\\n\\nprint(\\\"\\\\nEpisodes\\\")\\nprint(df_episodes.info())\",\"# Print the dataframes information to have a better understanding of their structure\\nprint(df_characters.info())\\nprint(df_locations.info())\\nprint(df_script.info())\\nprint(df_episodes.info())\",\" Quick overview of the characters dataset\\nprint(df_characters.head())\\n\\n# Quick overview of the locations dataset\\nprint(df_locations.head())\\n\\n# Quick overview of the script dataset\\nprint(df_script.head())\\n\\n# Quick overview of the episodes dataset\\nprint(df_episodes.head())\",\"Display basic information for each DataFrame\\nprint(\\\"Characters DataFrame\\\")\\ndf_characters.info()\\nprint(\\\"Locations DataFrame\\\")\\ndf_locations.info()\\nprint(\\\"Script DataFrame\\\")\\ndf_script.info()\\nprint(\\\"Episodes DataFrame\\\")\\ndf_episodes.info()\",\" Display basic information on the datasets\\nprint(\\\"Characters Dataset\\\\n\\\")\\nprint(df_characters.head())\\nprint(\\\"\\\\n-------------------------------------\\\\n\\\")\\nprint(\\\"Locations Dataset\\\\n\\\")\\nprint(df_locations.head())\\nprint(\\\"\\\\n-------------------------------------\\\\n\\\")\\nprint(\\\"Script Dataset\\\\n\\\")\\nprint(df_script.head())\\nprint(\\\"\\\\n-------------------------------------\\\\n\\\")\\nprint(\\\"Episodes Dataset\\\\n\\\")\\nprint(df_episodes.head())\",\" Quick look at each dataframe\\nprint('Characters')\\nprint(df_characters.info())\\nprint(df_characters.head(2))\\n\\nprint('Locations')\\nprint(df_locations.info())\\nprint(df_locations.head(2))\",\"Show content of each dataset\\nprint(\\\"\\\\n[INFO] Show content of each data set.\\\")\\nprint(\\\"\\\\n[INFO] 1. Simpsons characters.\\\")\\nprint(df_characters.head())\\nprint(\\\"\\\\n[INFO] 2. Simpsons locations.\\\")\\nprint(df_locations.head())\\nprint(\\\"\\\\n[INFO] 3. Simpsons episodes.\\\")\\nprint(df_episodes.head())\\nprint(\\\"\\\\n[INFO] 4. Simpsons script.\\\")\\nprint(df_script.head())\",\" Display some info\\ndf_characters.info()\\ndf_locations.info()\\ndf_script.info()\\ndf_episodes.info()\",\"Show summary\\nprint(df_characters.info())\\nprint(df_locations.info())\\nprint(df_script.info())\\nprint(df_episodes.info())\",\" Display some basic information about our datasets\\nprint(\\\"Characters:\\\")\\nprint(df_characters.info())\\nprint(df_characters.head())\\nprint()\\nprint(\\\"Locations:\\\")\\nprint(df_locations.info())\\nprint(df_locations.head())\\nprint()\\nprint(\\\"Script:\\\")\\nprint(df_script.info())\\nprint(df_script.head())\\nprint()\\nprint(\\\"Episodes:\\\")\\nprint(df_episodes.info())\\nprint(df_episodes.head())\",\"View general information of the datasets\\nprint(df_characters.info())\\nprint(df_locations.info())\\nprint(df_script.info())\\nprint(df_episodes.info())\",\"View some data info\\nprint('Characters info')\\nprint(df_characters.info())\\n\\nprint('\\\\n-------------------\\\\n')\\nprint('Locations info')\\nprint(df_locations.info())\\n\\nprint('\\\\n-------------------\\\\n')\\nprint('Script info')\\nprint(df_script.info())\\n\\nprint('\\\\n-------------------\\\\n')\\nprint('Episodes info')\\nprint(df_episodes.info())\",\" Quick view on the Simpsons Dataset\\nprint(\\\"Characters' dataset:\\\")\\nprint(df_characters.head())\\nprint(\\\"\\\\nLocations' dataset:\\\")\\nprint(df_locations.head())\\nprint(\\\"\\\\nEpisodes' dataset:\\\")\\nprint(df_episodes.head())\\nprint(\\\"\\\\nScript' dataset:\\\")\\nprint(df_script.head())\",\"View statistics of all DataFrames\\nprint(\\\"\\\\n- Springfield's Data -\\\")\\nprint(\\\"\\\\n- Characters -\\\\n\\\", df_characters.info())\\nprint(\\\"\\\\n- Locations -\\\\n\\\", df_locations.info())\\nprint(\\\"\\\\n- Episodes -\\\\n\\\", df_episodes.info())\\nprint(\\\"\\\\n- Scripts -\\\\n\\\", df_script.info())\",\"Quickly show basic information for each data frame\\nprint('characters:')\\nprint(df_characters.info())\\nprint('locations:')\\nprint(df_locations.info())\\nprint('script:')\\nprint(df_script.info())\\nprint('episodes:')\\nprint(df_episodes.info())\",\"Display general information of the datasets\\nprint('Characters dataset')\\nprint(df_characters.info())\\nprint(df_characters.head())\\nprint('\\\\nLocations dataset')\\nprint(df_locations.info())\\nprint(df_locations.head())\",\"Obtain a high-level overview of the dataset\\nprint(\\\"Characters dataset\\\")\\nprint(df_characters.info())\\n\\nprint(\\\"Locations dataset\\\")\\nprint(df_locations.info())\\n\\nprint(\\\"Script dataset\\\")\\nprint(df_script.info())\\n\\nprint(\\\"Episodes dataset\\\")\\nprint(df_episodes.info())\",\"Inspect the data types and missing values for each dataframe\\nprint(df_characters.info())\\nprint(df_locations.info())\\nprint(df_script.info())\\nprint(df_episodes.info())\"],\"marker\":{\"opacity\":0.5,\"size\":5},\"mode\":\"markers+text\",\"name\":\"28_Displaying Dataset Information\",\"text\":[\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\"],\"textfont\":{\"size\":12},\"x\":[-0.2339424043893814,0.11548926681280136,0.21175448596477509,0.49768099188804626,0.5545528531074524,-0.0204779002815485,-0.124634750187397,-0.5109909176826477,0.581092357635498,0.15880346298217773,0.5460432767868042,0.3446647524833679,0.33145132660865784,-0.16393689811229706,0.31403446197509766,0.11030048131942749,0.3812026083469391,0.23911507427692413,-0.08932315558195114,0.062275130301713943,0.41587305068969727,-0.03184965252876282,-0.06839149445295334,0.27969586849212646,0.3259279429912567,0.4675542116165161,-0.17255966365337372,0.5392019152641296,0.07414126396179199,0.2141529768705368,0.6358652710914612,-0.12568211555480957,0.22117982804775238,0.5065770149230957,0.16586557030677795,0.16028724610805511,0.32116565108299255,-0.23143474757671356,-0.8698492646217346,0.1742563247680664,-0.4931545853614807,0.6064234972000122,0.10189152508974075,0.3044971227645874,0.569337785243988,0.17935720086097717,-0.02453574538230896,0.3604015111923218,-0.011141432449221611,-0.1938295066356659,0.3307240307331085,0.34820204973220825,-0.1352907121181488,1.271924614906311],\"y\":[1.8204057216644287,2.4684038162231445,3.013025999069214,2.492826461791992,2.3387746810913086,2.62257981300354,2.3485107421875,1.7325711250305176,2.7424182891845703,3.6584079265594482,2.5028908252716064,2.4382925033569336,2.2467055320739746,2.8244192600250244,2.430755376815796,2.557752847671509,2.3381242752075195,2.1935155391693115,3.100369453430176,2.6119167804718018,2.346329689025879,2.508232355117798,1.9035710096359253,1.8225092887878418,2.0551650524139404,3.4079809188842773,1.9088798761367798,3.1965160369873047,1.736861228942871,2.7232537269592285,2.030973196029663,2.187981367111206,1.7270845174789429,2.1350879669189453,2.4864189624786377,3.145673990249634,2.894460439682007,2.1219942569732666,2.381277084350586,2.2384238243103027,2.950800895690918,3.8348371982574463,2.0657668113708496,2.469125270843506,2.4781126976013184,2.702397346496582,2.4642245769500732,2.51108717918396,1.6233280897140503,1.961032748222351,2.2244999408721924,3.317039966583252,2.0684092044830322,1.6305917501449585],\"type\":\"scattergl\"},{\"hoverinfo\":\"text\",\"hovertext\":[\"Check for null values in each dataframe\\ndf_characters.isnull().sum()\",\" Check for nulls\\nprint(df_script.isnull().sum())\",\"Get some information on each dataframe (i.e., data types and non-null values)\",\"# Checking for missing lines\\n(df_script.isnull().sum() \\u002f len(df_script)) * 100\",\"Check if the script dataframe contains duplicate rows\\nprint(f\\\"Number of duplicate rows in script dataframe: {df_script.duplicated().sum()}\\\")\",\"Check for null values in the dataframe\",\"check for null values\",\"Check if there are any NULL or empty rows in the script data\\nprint(df_script.isnull().sum())\",\"check the number of null values in each column of the df_script dataframe\\ndf_script.isnull().sum()\",\"Check for missing data\\ndf_characters.isnull().sum()\",\" Check the character dataframe for NaN values\\nprint(df_characters.isna().sum())\",\"Check for missing and null values\\ndf_script.isnull().sum()\",\"Check to see if there are any missing values in the datasets\\ndf_characters.isna().sum()\",\"\\u65b9\\u6cd5\\ndef missing_values_table(df):\\n    mis_val = df.isnull().sum()\\n    mis_val_percent = 100 * df.isnull().sum() \\u002f len(df)\\n    mis_val_table = pd.concat([mis_val, mis_val_percent], axis=1)\\n    mis_val_table_ren_columns = mis_val_table.rename(\\n    columns = {0 : 'Missing Values', 1 : '% of Total Values'})\\n    mis_val_table_ren_columns = mis_val_table_ren_columns[\\n        mis_val_table_ren_columns.iloc[:,1] != 0].sort_values(\\n    '% of Total Values', ascending=False).round(1)\\n    print (\\\"Your selected dataframe has \\\" + str(df.shape[1]) + \\\" columns.\\\\n\\\"      \\n        \\\"There are \\\" + str(mis_val_table_ren_columns.shape[0]) +\\n          \\\" columns that have missing values.\\\")\\n    return mis_val_table_ren_columns\",\"# Display the number of missing values in the script DataFrame\\nprint(df_script.isnull().sum())\",\"Check for missing data\\ndf_script.isnull().sum()\",\"Check missing values and df size\",\"Check for null values\\nprint(df_script.isnull().sum())\",\"# Check for missing data\\ndf_script.isnull().sum()\",\"Show missing values again\\ndf_script.isnull().sum()\",\"Checking for any null values \\ndf_script.isnull().sum()\",\"Count the number of non-null values in each column of the dataframe\\ndf_script.info()\",\"Sanitizing script\\ndf_script.isnull().sum()\",\"Check the number of missing values in each column\\ndf_script.isnull().sum()\",\"Brief exploration and cleaning\\n(df_script['timestamp_in_ms'].notna()).sum()\",\"Check for missing values\\nmissing_values_df = pd.DataFrame(df_script.isnull().sum(), columns=['missing values'])\\nmissing_values_df['percentage'] = round(missing_values_df['missing values'] \\u002f df_script.shape[0] * 100, 2)\\nmissing_values_df = missing_values_df[missing_values_df['missing values'] \\u003e 0]\\nmissing_values_df = missing_values_df.sort_values(by='missing values', ascending=False)\\n\\nmissing_values_df\",\"Check for missing values in the characters dataframe\\ndf_characters.isnull().sum()\",\"Check missing values\\ndf_script.isnull().sum()\",\"Check for missing values\\ndf_script.isna().sum()\",\"Check integrity of the datasets\\nprint(\\\"Checking Characters DataFrame...\\\")\\nprint(df_characters.isnull().sum())\",\"Count the number of missing values in each column of df_script\\ndf_script.isnull().sum()\",\"Check for missing values\\ndf_script.isnull().sum()\",\"Check for null values in the dataframes\\ndf_characters.isnull().sum()\",\" Check missing values in the dataset\\ndf_script.isna().sum()\",\"check for missing values\\ndf_script.isnull().sum()\",\"Inspect dataset for missing values\\ndf_script.isna().sum()\",\"Check for missing data\\ndf_script.isnull().sum()\",\"Check whether script dataframe has null values\\ndf_script.isnull().sum()\",\"Check for missing values in the datasets\\nprint(df_characters.isnull().sum())\",\"Check for missing data\\ndf_script.isnull().sum()\",\" Check for missing data\\ndf_characters.isnull().sum()\",\"Check if null values are present in the datasets\\nprint(\\\"Null character_birth_date: \\\", df_characters['character_birth_date'].isnull().values.any())\",\"Checking number of null values in each dataframe\",\"check missing data\\ndf_script.isnull().sum()\",\"Checking for nulls in each dataframe\",\"check missings\\ndf_script.isnull().sum()\",\"Check for missing script lines and drop them\\nmissing = df_script.isnull().sum()\\nprint(missing[missing \\u003e 0])\",\" Checking for missing values in the dataset\\nmissing_values = df_script.isnull().sum()\\nmissing_values\",\"count the null values in the dataframe\\ndf_script.isnull().sum()\",\"Check for missing values in the script data\\ndf_script.isnull().sum()\",\"Check for missing values\\ndf_script.isna().sum()\",\"Check for any NaN values in our dataset\\ndf_script.isnull().sum()\",\"Check for null values in the characters dataframe\\nprint(df_characters.isnull().sum())\"],\"marker\":{\"opacity\":0.5,\"size\":5},\"mode\":\"markers+text\",\"name\":\"29_Check for Missing and Null Values in DataFrame\",\"text\":[\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\"],\"textfont\":{\"size\":12},\"x\":[5.184031963348389,5.0659260749816895,7.056902885437012,5.180816650390625,5.737968444824219,6.190464019775391,7.175045013427734,5.017548084259033,5.245855808258057,4.8336567878723145,4.385003089904785,5.5238847732543945,5.15100622177124,4.907248020172119,5.771976470947266,5.401483535766602,6.80607795715332,5.252527236938477,5.444941520690918,5.543049335479736,5.492856979370117,5.506351470947266,5.459467887878418,5.453768253326416,5.711551189422607,5.5494914054870605,4.544777870178223,5.348074436187744,5.844726085662842,4.652575492858887,5.654541492462158,5.293722629547119,4.975550651550293,6.292358875274658,5.316681385040283,6.312320232391357,5.599031448364258,5.033103942871094,4.503864765167236,5.36607027053833,4.909510135650635,4.5067267417907715,6.197215557098389,5.402559280395508,6.157323360443115,5.118945598602295,5.6031036376953125,6.311395645141602,5.421248912811279,5.631776809692383,5.889983654022217,5.970271110534668,4.714488506317139],\"y\":[0.4611976742744446,0.16545003652572632,-0.47437915205955505,1.0853471755981445,0.739834189414978,0.04438789188861847,0.20872101187705994,0.6654060482978821,0.27716004848480225,0.6108314394950867,1.4577165842056274,0.8480718731880188,1.308724045753479,0.6221964955329895,0.47130197286605835,1.124943733215332,0.186545729637146,0.4794311225414276,1.046724557876587,0.9772785305976868,0.45022258162498474,0.028396010398864746,1.0011324882507324,0.3626693785190582,2.0192437171936035,0.6816702485084534,0.5232946872711182,0.9476661682128906,0.8583502173423767,0.9571589827537537,0.49089986085891724,0.7796372771263123,0.2566029727458954,0.5984994769096375,0.6823825240135193,0.5325718522071838,1.119876503944397,0.3116740584373474,0.8581361770629883,1.0658681392669678,0.8944029211997986,0.424106240272522,0.29559072852134705,1.2088247537612915,0.12106037884950638,0.8739593029022217,1.0660828351974487,0.7077385783195496,-0.06869114190340042,0.7638186812400818,0.7217651009559631,1.423743486404419,0.7670757174491882],\"type\":\"scattergl\"},{\"hoverinfo\":\"text\",\"hovertext\":[\"Display the first 5 rows of the characters dataframe\\ndf_characters.head()\",\" Display the first 5 rows of the characters dataframe\\ndf_characters.head()\",\"Display the first 5 rows of the characters dataframe\\ndf_characters.head()\",\"# Display the first 5 rows of the 'df_characters' dataframe\\ndf_characters.head()\",\"Display the first 5 rows of the characters dataframe\\ndf_characters.head()\",\"Display the first 5 rows of the characters dataframe\\ndf_characters.head()\",\"Display the first 5 rows of the characters dataframe\\ndf_characters.head()\",\"Display the first 5 rows of the characters dataframe\\ndf_characters.head()\",\"Display the first 5 rows of the characters dataframe\\ndf_characters.head()\",\" Display the first 5 rows of the characters dataframe\\ndf_characters.head()\",\"Display the first 5 rows of the characters dataframe\\ndf_characters.head()\",\"Display the first 5 rows of the characters dataframe\\ndf_characters.head()\",\"Display the first 5 rows of the characters dataframe\\ndf_characters.head()\",\"Display the first 5 rows of the characters dataframe\\ndf_characters.head()\",\"Display the first 5 rows of the characters data frame\\ndf_characters.head()\",\"Display the first 5 rows of the characters dataframe\\ndisplay(df_characters.head(5))\",\" display the first 5 rows of the characters dataframe\\ndf_characters.head()\",\"Display the first 5 rows of the characters dataframe\\ndf_characters.head()\",\" Display the first 5 rows of the characters dataframe\\ndf_characters.head()\",\"Display the first 5 rows of the characters dataframe\\ndf_characters.head()\",\"Display the first 5 rows of the characters dataframe\\ndf_characters.head()\",\"Display the first 5 rows of the characters dataframe\\ndf_characters.head()\",\"Display the first 5 rows of the characters DataFrame\\ndf_characters.head()\",\"Display the first 5 rows of the characters dataframe\\ndf_characters.head()\",\" Display the first 5 rows of the characters DataFrame\\ndf_characters.head()\",\"display the columns and first 5 rows of the characters dataframe\\ndf_characters.head()\",\"Display the first 5 rows of the characters dataframe\\ndf_characters.head()\",\"Display the first 5 rows of the characters dataframe\\ndf_characters.head()\",\"Display the first 5 rows of the characters dataframe\\ndf_characters.head()\",\"Display the first 5 rows of the characters dataframe\\ndf_characters.head()\",\"Display the first 5 rows of the characters DataFrame\\ndf_characters.head(5)\",\"Display the first 5 rows of the characters DataFrame\\ndf_characters.head()\",\"# Display the last 5 rows of the character DataFrame\\ndf_characters.tail(5)\",\"Display the first 5 rows of the characters dataframe\\ndf_characters.head()\",\" 1. Display the first 5 rows for the characters dataframe\\ndf_characters.head()\",\"Display the first 5 rows of the characters DataFrame\\ndf_characters.head()\",\"Display the first 5 rows of the characters dataframe\\ndf_characters.head()\",\" Display the first 5 rows of the characters dataframe\\ndf_characters.head()\",\"Display the first 5 rows of the characters dataframe\\ndf_characters.head()\",\"display the first 5 rows of the characters dataframe\\ndf_characters.head()\",\"Display the first 5 rows of the characters dataframe\\ndf_characters.head()\",\"Display the first 5 rows of the characters dataframe\\ndf_characters.head()\",\" Display the first 5 rows of the characters dataframe\\ndf_characters.head()\",\" Display the first 5 rows of the characters DataFrame\\ndf_characters.head()\",\"Display the first 5 rows of the characters dataframe\\ndf_characters.head()\",\"Display the first 5 rows of the characters dataframe\\ndf_characters.head()\",\" Display the first 5 rows of the characters DataFrame\\ndf_characters.head()\",\"display the first 5 rows of the characters dataframe\\ndf_characters.head()\",\"Display the first 5 rows of the characters dataframe\\ndf_characters.head()\",\" Display the first 5 rows of the characters dataframe\\ndf_characters.head()\",\"return the first 5 rows in the characters DataFrame\\ndf_characters.head()\",\" Display the first 5 rows of the characters dataframe\\ndf_characters.head()\",\"Display the first 5 rows of the characters dataframe\\ndf_characters.head()\"],\"marker\":{\"opacity\":0.5,\"size\":5},\"mode\":\"markers+text\",\"name\":\"30_Display first 5 rows of characters dataframe\",\"text\":[\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\"],\"textfont\":{\"size\":12},\"x\":[-4.876651287078857,-4.567148685455322,-4.667683124542236,-3.6602795124053955,-4.452928066253662,-4.1182861328125,-4.587403774261475,-4.346122741699219,-4.383382797241211,-4.282879829406738,-4.475646495819092,-4.745121002197266,-4.4690093994140625,-4.645187854766846,-4.036176681518555,-3.752610445022583,-4.363402366638184,-4.501490116119385,-4.952155590057373,-4.599100589752197,-3.9540276527404785,-4.475374221801758,-4.567525386810303,-4.898858070373535,-4.863215446472168,-4.045646667480469,-4.452686309814453,-4.563261985778809,-4.588523864746094,-4.266140460968018,-3.936324119567871,-4.5099077224731445,-2.931309700012207,-4.696105480194092,-4.899159908294678,-4.510221481323242,-4.548337936401367,-4.535358905792236,-4.59193754196167,-4.840561389923096,-4.744821071624756,-4.826591491699219,-4.708256244659424,-4.516496181488037,-4.663671016693115,-4.3120012283325195,-4.37033748626709,-5.0295329093933105,-4.993360996246338,-4.568533897399902,-3.634176254272461,-4.779134273529053,-4.356351375579834],\"y\":[13.337578773498535,13.219480514526367,12.785597801208496,13.479710578918457,13.110746383666992,13.289319038391113,13.058789253234863,13.202054977416992,12.869930267333984,13.401430130004883,13.347908020019531,13.257356643676758,13.736371994018555,13.000027656555176,13.083763122558594,13.211094856262207,13.11178970336914,13.353668212890625,13.26366901397705,13.370965003967285,13.19458293914795,12.983633041381836,12.931427001953125,13.60849380493164,13.300660133361816,12.79893970489502,13.4635591506958,13.736749649047852,13.65986156463623,13.620291709899902,13.139269828796387,13.687633514404297,13.00448226928711,13.707472801208496,12.938995361328125,13.650108337402344,12.757732391357422,13.381863594055176,13.058887481689453,12.910482406616211,13.570696830749512,13.626611709594727,13.015202522277832,13.71364688873291,13.427678108215332,13.433831214904785,13.082534790039062,13.529715538024902,13.136489868164062,13.410988807678223,13.770499229431152,13.325428009033203,13.05457592010498],\"type\":\"scattergl\"},{\"hoverinfo\":\"text\",\"hovertext\":[\" Limit the amount of rows displayed for better display in Jupyter notebook\\npd.set_option('display.max_rows', 5)\\npd.set_option('display.max_columns', 500)\",\"Set pd display options for better data visualization in Jupyter notebooks\",\"Increase pandas display\\npd.set_option('display.max_columns', None)\",\" Setting up pandas display options for easy debugging\",\"Optional: Set options for pandas.\",\"# Set some display parameters for pandas\\npd.set_option('display.max_columns', None)\",\"Function to display dataframes in Jupyter notebooks with a cleaner format\\ndef display_df(df):\\n    return df.style.hide_index()\",\"Display settings for dataframes\\npd.set_option('display.max_columns', None)\",\"Set some display options for better readability of DataFrames in Jupyter notebooks\\npd.set_option('display.max_columns', 60)\",\"Option configuration for pandas\",\" Set display options for pandas dataframe\\npd.set_option('display.max_columns', None)\",\"Some pandas options for better display and more helpful default behaviour.\\npd.set_option('display.max_columns', None)\\npd.options.mode.chained_assignment = None  # default='warn'\",\"Set custom options for pandas display and read the data.\",\"Set display options for dataframes\",\" pandas will default to truncating the output, so let's change it to display the all content of DataFrames in Jupyter.\\npd.set_option('display.max_colwidth', None)\",\" Set some Pandas specific options for better display\\npd.set_option('display.max_columns', None)\",\" Set default pandas option\\npd.set_option('display.max_columns', None)\",\" Display settings for Pandas dataframes\\npd.set_option('display.max_columns', None)\",\"Some configuration for pandas and numpy\\npd.set_option('display.max_columns', None)\\nnp.random.seed(42)\",\"Set display options for pandas dataframes, so that we'll be able to see the entire content.\",\"Show all the available pandas options\",\"Set options for pandas\\npd.set_option('display.max_columns', None)\",\"Display settings for pandas dataframes\\npd.set_option('display.max_columns', None)\",\"Setting display configuration to display all columns of the DataFrames in Jupyter notebook\",\"Some settings for all the dataframe display\\npd.set_option('display.max_columns', None)\\npd.set_option('display.max_rows', None)\",\"Display set-up for pandas dataframe\\npd.set_option('display.max_columns', None)\",\"Display pandas outputs as we expect\\npd.set_option('display.max_columns', None)\",\"Extend pandas show method to improve visibility of dataframe columns in Jupyter notebooks\",\"Set the pandas display options for the presentation of the data in the Jupyter Notebook\",\"Set display options for the dataframes\",\"Jupyter notebook configuration\\npd.set_option('display.max_columns', None)\",\"Optional: Set custom Pandas options for viewing better DataFrame visualizations.\",\"Set pandas options to display all columns\",\"Set options for pandas\\npd.set_option('display.max_columns', None)\",\"Set the display options to properly display dataframes\",\"Set display options for pandas dataframes\\npd.set_option('display.max_columns', None)\\npd.set_option('display.max_rows', None)\",\" Set option to display dataframe in Jupyter\\npd.set_option('display.max_columns', None)\",\"Set parameters for dataframe pretty print\\npd.set_option('display.max_columns', None)\",\"Display options for pandas data frames\\npd.set_option('display.max_columns', None)\",\"Set Jupyter output display options for large dataframes\\npd.set_option('display.max_columns', 500)\\npd.set_option('display.max_rows', 500)\\npd.set_option('display.width', 1000)\",\"Customize pandas display settings\\npd.set_option('display.max_columns', None)\",\"Set pandas to display in Jupyter as many columns as possible\\npd.set_option('display.max_columns', None)\",\"Setting some pandas display options for better readability of dataframes\",\"Display settings for the pandas dataframe viewer in Jupyter notebooks\\npd.options.display.max_columns = None\\npd.options.display.max_rows = None\",\" Set pandas settings (these could also be at the top of the file)\\npd.set_option('display.max_columns', None)\",\"Pandas default display options\\npd.options.display.max_columns = None\\npd.options.display.max_rows = None\",\"Optional: display pandas tables in notebook format\",\"Set numpy and pandas options for better display\\nnp.set_printoptions(precision=2)\\npd.set_option('display.max_columns',None)\",\"Display multiple dataframe side-by-side\\nfrom IPython.display import display_html\\ndef display_side_by_side(*args):\\n    html_str=''\\n    for df in args:\\n        html_str+=df.to_html()\\n    display_html(html_str.replace('table','table style=\\\"display:inline\\\"'), raw=True)\",\"set some pandas options for better display\\npd.set_option('display.max_columns', None)\",\"Setting to display all columns in Jupyter\\npd.set_option('display.max_columns', None)\",\" Beautiful display for tables\\ndef display_df(df):\\n    display(HTML(df.to_html()))\"],\"marker\":{\"opacity\":0.5,\"size\":5},\"mode\":\"markers+text\",\"name\":\"31_Setting display options for pandas dataframes in Jupyter notebooks\",\"text\":[\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\"],\"textfont\":{\"size\":12},\"x\":[21.135744094848633,19.884416580200195,21.766904830932617,20.75545883178711,20.155105590820312,21.74372673034668,19.642507553100586,21.295440673828125,20.69594955444336,20.293672561645508,21.218551635742188,21.32832145690918,20.357309341430664,20.88637351989746,21.396183013916016,21.758607864379883,21.37647247314453,20.74715805053711,21.738855361938477,21.278812408447266,20.423105239868164,21.395620346069336,20.695096969604492,19.88885498046875,21.6904354095459,20.8597354888916,21.299644470214844,20.133729934692383,19.779794692993164,20.741167068481445,21.063650131225586,21.0644474029541,20.65278434753418,21.27392578125,20.755149841308594,21.586040496826172,20.68953514099121,21.061283111572266,20.61724853515625,20.791370391845703,21.05786895751953,20.623458862304688,20.51899528503418,20.397165298461914,21.48305892944336,21.4112548828125,20.144010543823242,22.4345760345459,19.71826171875,21.843786239624023,21.029720306396484,19.942886352539062],\"y\":[1.3972641229629517,1.8598884344100952,1.4631035327911377,2.07861590385437,2.0367867946624756,1.5671992301940918,2.123624801635742,1.2006151676177979,1.8314857482910156,2.4009158611297607,1.5219647884368896,1.5807771682739258,1.8043733835220337,1.9937204122543335,2.042261838912964,1.2749333381652832,1.5122216939926147,1.7100014686584473,1.7448127269744873,1.2150053977966309,1.6616472005844116,1.1508110761642456,1.6668596267700195,1.8714821338653564,0.7018871307373047,1.2322421073913574,1.5542467832565308,1.6188079118728638,2.140228748321533,1.9122782945632935,1.1658458709716797,1.964806318283081,1.007370114326477,1.555975317955017,2.0988972187042236,1.1125447750091553,1.5516918897628784,1.429473638534546,1.5838207006454468,1.599435567855835,1.6982409954071045,1.1211113929748535,2.1685447692871094,1.76183021068573,1.0925134420394897,1.306138277053833,1.671925663948059,1.3528610467910767,2.1841444969177246,1.4039158821105957,1.0014429092407227,1.7863473892211914],\"type\":\"scattergl\"},{\"hoverinfo\":\"text\",\"hovertext\":[\" Let's take a look at the structure of the dataframes.\",\"Let's take a look at the dataframes we have to understand how we can use them.\",\"Let's first take a look at the dataframes to understand their structure and content.\",\"Create temporally sorted dataframes to facilitate the creation of animations.\",\"Let's take a look at each dataframe.\",\"Let's take a look at the dataframes we have thus far.\",\" Let's now take a quick look at the structure and contents of these dataframes.\",\"Let's take a look at the dataframes to understand their structures.\",\"Let's first take a look at these dataframes to see what information we have available.\",\"let's look at the schema of the data from each of these dataframes\",\" Let's take a look at the dataframes\",\"Let's take a quick look at the dataframes to understand their structure.\",\"Now we have the datasets loaded into DataFrames, let's take a look at each one of them.\",\" Let's take a look at the structure of these DataFrames.\",\"Let's take a look at the structure of each of the DataFrames.\",\"Let's take a look at the contents of these DataFrames.\",\"Let's take a look at the shape of each DataFrame to understand how much data we're dealing with.\",\"Preliminary analysis of the dataframes\",\"Let's take a first look at this dataframe.\",\" Let's take a look at the structure of each dataframe.\",\"Let's look at the shape and content of these DataFrames\",\" Let's take a quick look at all of our dataframes.\",\"Let's take a look at the dataframes.\",\"Take a look at the dataframes\",\" Let's take a look at the structure of these dataframes.\",\" Let's take a look at the data in each of these dataframes.\",\"Look at a statististical summary of the dataframes\",\" Let's first inspect the structure of these dataframes.\",\" Let's take a look at each of these DataFrames to better understand the data.\",\"First, let's investigate the structure of the dataframes.\",\"Let's look at the structure of each of these DataFrames.\",\"Let's take a look at the contents of these DataFrames.\",\" Let's take a closer look at the structure of the DataFrames.\",\"Let's take a look at the structure of our dataframes.\",\"Let's take a look at the dataframes to understand their structure and the type of information we have.\",\" We'll have a look first at the structure and contents of these DataFrames.\",\"Now, let's take a look at the structure and content of each of these dataframes.\",\"Let's inspect these DataFrames to understand the data better.\",\" Let's take a look at the structure of these dataframes.\",\"Let's take a look at the structure of each dataframe.\",\"To get an insight, let's first look at how the various dataframes look like.\",\" Let's have a look at the loaded dataframes.\",\"Let's take a look at our dataframes.\",\" Let's take a look at the structure of the dataframes.\",\" Let's take a look at the structure of the dataframes.\",\"Let's take a look at the dataframes to see what we're working with.\",\"Potential dataframe for results then and there.\",\" Let's take a look at the dataframes.\",\"Let's have a look at the dataframes and the structure of the data.\",\" Let's take a peek at the first few lines of each dataframe to get an idea of what we are working with.\",\"Let's see the heads of the loaded dataframes.\",\"Take a look inside the dataframes.\"],\"marker\":{\"opacity\":0.5,\"size\":5},\"mode\":\"markers+text\",\"name\":\"32_Understanding DataFrame Structure and Contents\",\"text\":[\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\"],\"textfont\":{\"size\":12},\"x\":[8.086592674255371,8.332544326782227,8.081216812133789,8.881608963012695,9.23000717163086,8.573931694030762,8.732950210571289,8.464344024658203,8.715126037597656,8.836215019226074,8.799703598022461,8.395939826965332,8.91659164428711,8.448334693908691,8.75487995147705,8.871628761291504,9.0609130859375,10.226725578308105,8.876250267028809,8.624671936035156,9.001622200012207,9.241601943969727,8.248371124267578,8.459453582763672,8.423135757446289,9.041170120239258,8.628405570983887,8.57874870300293,9.305646896362305,7.966257095336914,8.499218940734863,8.562601089477539,8.30514144897461,8.600820541381836,8.636622428894043,9.029511451721191,8.957318305969238,9.485212326049805,8.126582145690918,8.760835647583008,8.930438041687012,8.85533618927002,8.73744010925293,8.258875846862793,8.216928482055664,8.604883193969727,9.087496757507324,8.335180282592773,8.26430892944336,9.363357543945312,9.226922035217285,9.019438743591309],\"y\":[-6.405035018920898,-5.9304046630859375,-6.96073579788208,-5.361023902893066,-5.855396747589111,-5.932663440704346,-6.250969886779785,-6.918048858642578,-6.422597408294678,-5.9525346755981445,-5.898843288421631,-7.221604347229004,-5.860758304595947,-5.868773937225342,-6.241703510284424,-5.8628106117248535,-6.907940864562988,-5.47430944442749,-6.291775703430176,-6.261773586273193,-5.612814426422119,-6.240742206573486,-6.072539806365967,-5.422571659088135,-6.114763259887695,-6.462291240692139,-6.0979228019714355,-5.793774604797363,-6.234692573547363,-6.190727233886719,-5.795897960662842,-5.991405010223389,-6.559952259063721,-5.988999366760254,-6.845744609832764,-5.858260154724121,-5.802600383758545,-6.061972618103027,-5.980025291442871,-6.209444522857666,-6.027027130126953,-5.978942394256592,-6.30300760269165,-6.374352931976318,-6.304781436920166,-6.368048667907715,-5.906326770782471,-6.073248863220215,-6.148410320281982,-6.055115699768066,-6.260621070861816,-5.383865833282471],\"type\":\"scattergl\"},{\"hoverinfo\":\"text\",\"hovertext\":[\"Explicitly set encoding for docstring compatibility\\ndf_characters = pd.read_csv('data\\u002fsimpsons_characters.csv', encoding='utf-8').reset_index(drop=True)\",\"Since 'simpsons_script_lines.csv' is very large, we're going to use the first 100000 rows for the initial analysis\\ndf_script = df_script[:100000]\",\" Load previously saved data from these pickles. Uncomment if you have ran the cells above and have pickled before\\n\\n# df_characters = pd.read_pickle('data\\u002fpickles\\u002fcharacters.pkl')\\n# df_locations = pd.read_pickle('data\\u002fpickles\\u002flocations.pkl')\\n# df_script = pd.read_pickle('data\\u002fpickles\\u002fscript.pkl')\",\"# Setting up paths\\ninput_filepath = 'data\\u002fsimpsons_script_lines.csv'\\noutput_filepath = 'data\\u002fsimpsons_preprocessed_lines.csv'\",\"Joining lines with \\\"\\\\\\\"\\ndf_script = pd.read_csv('data\\u002fsimpsons_script_lines.csv').\\\\\\n    reset_index(inplace=False, drop=True)\",\"Set the file paths to be used\\nscript_path = 'data\\u002fsimpsons_script_lines.csv'\\ncharacters_path = 'data\\u002fsimpsons_characters.csv'\\nlocations_path = 'data\\u002fsimpsons_locations.csv'\\nepisodes_path = 'data\\u002fsimpsons_episodes.csv'\",\"During the code above, the code loads the necessary datasets using pandas and the `read_csv` function. The datasets loaded include `simpsons_characters.csv`, `simpsons_locations.csv`, `simpsons_script_lines.csv`, and `simpsons_episodes.csv`. Each dataset is read into a pandas DataFrame and then reset the index to ensure a clean, continuous index.\",\" Load smaller datasets\\ndf_characters_s = pd.read_csv('data\\u002fsimpsons_characters_small.csv').reset_index(inplace=False, drop=True)\\ndf_locations_s = pd.read_csv('data\\u002fsimpsons_locations_small.csv').reset_index(inplace=False, drop=True)\\ndf_script_s = pd.read_csv('data\\u002fsimpsons_script_lines_small.csv').reset_index(inplace=False, drop=True)\\ndf_episodes_s = pd.read_csv('data\\u002fsimpsons_episodes_small.csv').reset_index(inplace=False, drop=True)\",\"data\\u002fsimpsons_script_lines.csv is represented as 'data\\u002fsimpsons_script_lines.csv'\",\"As an AI model, I don't have access to the local files on your machine. However, it seems like this code snippet is reading data from CSV files into pandas DataFrames. The code is using the 'read_csv' function of pandas to read from files called 'simpsons_characters.csv', 'simpsons_locations.csv', 'simpsons_script_lines.csv', and 'simpsons_episodes.csv'. These DataFrames are then reset to have a new index.\",\"Set the paths to the datasets\\nEPISODES_DATASET_PATH = \\\"data\\u002fsimpsons_episodes.csv\\\"\\nSCRIPT_DATASET_PATH = \\\"data\\u002fsimpsons_script_lines.csv\\\"\\nCHARACTERS_DATASET_PATH = \\\"data\\u002fsimpsons_characters.csv\\\"\\nLOCATIONS_DATASET_PATH = \\\"data\\u002fsimpsons_locations.csv\\\"\",\" Load locations and main characters CSV files\\ndf_locations = pd.read_csv('data\\u002fsimpsons_locations.csv')\\ndf_characters = pd.read_csv('data\\u002fsimpsons_characters.csv')\",\"filePath = data_path + '\\\\simpsons_script_lines.csv'\",\"# Selection of information useful for this task\\ndata = df_script[['episode_id', 'character_id', 'raw_text']]\\ndata = data.dropna()  # Remove missing (NaN) data\\n\\n# Database with relations between characters and locations\\nrelations = pd.read_csv('data\\u002fsimpsons_locations.csv', usecols=['location_id', 'name'])\",\" Use the same data in data\\u002fsimpsons_script_lines.csv as used before\\ndf_script.head()\",\"In this code, we are importing the necessary libraries and reading the data using pandas from the given CSV files. We are resetting the index of the dataframes and storing them in the variables df_characters, df_locations, df_script, and df_episodes respectively.\",\"def load_data():\\n    #  Load data\\n    df_characters = pd.read_csv('data\\u002fsimpsons_characters.csv').reset_index(inplace=False, drop=True)\\n    df_locations = pd.read_csv('data\\u002fsimpsons_locations.csv').reset_index(inplace=False, drop=True)\\n    df_script = pd.read_csv('data\\u002fsimpsons_script_lines.csv').reset_index(inplace=False, drop=True)\\n    df_episodes = pd.read_csv('data\\u002fsimpsons_episodes.csv').reset_index(inplace=False, drop=True)\\n    \\n    return df_characters, df_locations, df_script, df_episodes\",\" Set environment variable to specify data location\\nos.environ['SIMPSONS_SCRIPT_LINE_DATA'] = 'data\\u002fsimpsons_script_lines.csv'\",\"Check the content of the 'simpsons_script_lines.csv' dataset\\ndf_script.head()\",\"def read_data():\\n    # characters, locations, script lines, and episodes\\n    df_characters = pd.read_csv('data\\u002fsimpsons_characters.csv').reset_index(inplace=False, drop=True)\\n    df_locations = pd.read_csv('data\\u002fsimpsons_locations.csv').reset_index(inplace=False, drop=True)\\n    df_script = pd.read_csv('data\\u002fsimpsons_script_lines.csv').reset_index(inplace=False, drop=True)\\n    df_episodes = pd.read_csv('data\\u002fsimpsons_episodes.csv').reset_index(inplace=False, drop=True)\\n    return df_characters, df_locations, df_script, df_episodes\",\" Ensure that the dataset has the correct encoding to avoid errors when dealing with text data\\ndf_script = pd.read_csv('data\\u002fsimpsons_script_lines.csv', encoding='latin1')\\ndf_script.head()\",\"# Load data\\ndf_characters = pd.read_csv('data\\u002fsimpsons_characters.csv').reset_index(inplace=False, drop=True)\\ndf_locations = pd.read_csv('data\\u002fsimpsons_locations.csv').reset_index(inplace=False, drop=True)\\ndf_script = pd.read_csv('data\\u002fsimpsons_script_lines.csv').reset_index(inplace=False, drop=True)\\ndf_episodes = pd.read_csv('data\\u002fsimpsons_episodes.csv').reset_index(inplace=False, drop=True)\",\"merge the information from `simpsons_events.csv` into `simpsons_script_lines.csv`\\ndf_events = pd.read_csv('data\\u002fsimpsons_events.csv').reset_index(inplace=False, drop=True)\",\"# This variable stores the file paths to the csv files in the data folder\\nfile_paths = {\\n    'characters': 'data\\u002fsimpsons_characters.csv',\\n    'locations': 'data\\u002fsimpsons_locations.csv',\\n    'script': 'data\\u002fsimpsons_script_lines.csv',\\n    'episodes': 'data\\u002fsimpsons_episodes.csv'\\n}\",\" save the script data to disk\\nscript_file = 'data\\u002fsimpsons_script.csv'\\n\\nif not os.path.isfile(script_file):\\n    print(f\\\"Saving script data to {script_file}\\\")\\n    df_script.to_csv(script_file, index=False)\",\"Get the size of the files\\ndf_characters_size = os.path.getsize('data\\u002fsimpsons_characters.csv') \\u002f (1024 * 1024)\\ndf_locations_size = os.path.getsize('data\\u002fsimpsons_locations.csv') \\u002f (1024 * 1024)\\ndf_script_size = os.path.getsize('data\\u002fsimpsons_script_lines.csv') \\u002f (1024 * 1024)\\ndf_episodes_size = os.path.getsize('data\\u002fsimpsons_episodes.csv') \\u002f (1024 * 1024)\",\"Inspect the content of the \\\"simpsons_script_lines.csv\\\" dataset\\ndf_script.head()\",\"Declare paths to be used\\nimport_path = 'data\\u002fsimpsons_script_lines.csv'\\nexport_path = 'data\\u002fsimpsons_script_lines_preprocessed.csv'\",\"Inspect contents of the 'simpsons_script_lines.csv' file\\ndf_script.head()\",\" A small hack as PySpark expects the file to end in \\\".parquet\\\" while pandas saves it just with \\\".gzip\\\".\\nfilename = 'data\\u002fsimpsons_script_lines.csv.gzip'\\nif not os.path.isfile(filename):\\n    import shutil\\n    shutil.copy('data\\u002fsimpsons_script_lines.csv.gzip_temp', filename)\",\" Load dialogues set\\ndf_script = pd.read_csv('data\\u002fsimpsons_script_lines.csv', error_bad_lines=False)\\nprint(df_script.head())\",\"Create dataframe with important informations \\ndf_episodes_clean = pd.read_csv('data\\u002fcleaned_episodes.csv').reset_index(inplace=False, drop=True)\",\"def load_simpsons_datasets():\\n    # Load datasets\\n    df_characters = pd.read_csv('data\\u002fsimpsons_characters.csv').reset_index(inplace=False, drop=True)\\n    df_locations = pd.read_csv('data\\u002fsimpsons_locations.csv').reset_index(inplace=False, drop=True)\\n    df_script = pd.read_csv('data\\u002fsimpsons_script_lines.csv').reset_index(inplace=False, drop=True)\\n    df_episodes = pd.read_csv('data\\u002fsimpsons_episodes.csv').reset_index(inplace=False, drop=True)\\n\\n    return df_characters, df_locations, df_script, df_episodes\",\"Merge characters, locations and script\\ndf_episodes = pd.read_csv('data\\u002fsimpsons_episodes.csv').reset_index(inplace=False, drop=True)\",\"Check the Simpsons script data\\ndf_script.head()\",\"\\ndf_character_ep = pd.read_csv('data\\u002fsimpsons_episodes_characters.csv')\",\"Load kaggle dataset\\n#df_characters = pd.read_csv('\\u002fkaggle\\u002finput\\u002fthe-simpsons-dataset\\u002fsimpsons_characters.csv').reset_index(inplace=False, drop=True)\\n#df_locations = pd.read_csv('\\u002fkaggle\\u002finput\\u002fthe-simpsons-dataset\\u002fsimpsons_locations.csv').reset_index(inplace=False, drop=True)\\n#df_script = pd.read_csv('\\u002fkaggle\\u002finput\\u002fthe-simpsons-dataset\\u002fsimpsons_script_lines.csv').reset_index(inplace=False, drop=True)\\n#df_episodes = pd.read_csv('\\u002fkaggle\\u002finput\\u002fthe-simpsons-dataset\\u002fsimpsons_episodes.csv').reset_index(inplace=False, drop=True)\",\"fixes a bug on the simpsons script which causes an index column to be loaded.\",\"Load a large csv file in chunks for memory efficiency.\\n# reading in a loop\\nchunks = []\\nchunksize = 10**6\\nfor chunk in pd.read_csv('data\\u002fsimpsons_script_lines.csv', chunksize=chunksize):\\n    chunks.append(chunk)\",\" Check the content of the 'simpsons_script_lines.csv' DataFrame\\ndf_script.head()\",\" Load scripts since some characters don't appear in the provided script (about 500MB)\\nif os.path.isfile('data\\u002fsimpsons_script_lines_sc.csv'):\\n    df_script_sc = pd.read_csv('data\\u002fsimpsons_script_lines_sc.csv').reset_index(inplace=False, drop=True)\\nelse:\\n    df_script_sc = pd.read_csv('data\\u002fsimpsons_script_lines.csv').sample(frac=0.25).reset_index(drop=True)\\n    df_script_sc.to_csv('data\\u002fsimpsons_script_lines_sc.csv')\",\"\\nprint(\\\"The file simpsons_script_lines.csv has loads of columns: \\\", *df_script.columns, \\\"\\\\n\\\")\",\"Load the preprocessed script as it was computed before in script_preprocessing.ipynb\\ndf_script_processed = pd.read_csv('data\\u002fsimpsons_script_lines_preprocessed.csv')\",\"Load the data in memory\\nimport zipfile\\n\\nwith zipfile.ZipFile('data\\u002fsimpsons.zip', 'r') as zip_ref:\\n    zip_ref.extractall('data\\u002f')\",\" switch data to built-in datasets if file not found\\ndf_characters = df_characters if not df_characters.empty else pd.read_csv('https:\\u002f\\u002fraw.githubusercontent.com\\u002fbri-bri\\u002fydata_synopsis\\u002fmain\\u002fdata\\u002fsimpsons_characters.csv').reset_index(inplace=False, drop=True)\\ndf_locations = df_locations if not df_locations.empty else pd.read_csv('https:\\u002f\\u002fraw.githubusercontent.com\\u002fbri-bri\\u002fydata_synopsis\\u002fmain\\u002fdata\\u002fsimpsons_locations.csv').reset_index(inplace=False, drop=True)\\ndf_script = df_script if not df_script.empty else pd.read_csv('https:\\u002f\\u002fraw.githubusercontent.com\\u002fbri-bri\\u002fydata_synopsis\\u002fmain\\u002fdata\\u002fsimpsons_script_lines.csv').reset_index(inplace=False, drop=True)\\ndf_episodes = df_episodes if not df_episodes.empty else pd.read_csv('https:\\u002f\\u002fraw.githubusercontent.com\\u002fbri-bri\\u002fydata_synopsis\\u002fmain\\u002fdata\\u002fsimpsons_episodes.csv').reset_index(inplace=False, drop=True)\",\"Check the first few entries of the Simpsons script dataset to understand its structure and contents\\ndf_script.head()\",\"Data directiory\\nroot_data_dir = '\\u002fkaggle\\u002finput\\u002fthe-simpsons\\u002fthesimpsons\\u002f'\\n\\n# Check the content of the directory\\nfor root, _, files in os.walk(root_data_dir):\\n    level = root.replace(root_data_dir, '').count(os.sep)\\n    indent = ' ' * 4 * (level)\\n    logger.info('{}{}\\u002f'.format(indent, os.path.basename(root)))\\n    subindent = ' ' * 4 * (level + 1)\\n    for f in files:\\n        logger.info('{}{}'.format(subindent, f))\",\" Helper for production side\\ndef load_all():\\n    \\\"\\\"\\\"\\n    Load datasets from the input file\\n    \\\"\\\"\\\"\\n    global df_characters, df_locations, df_script, df_episodes\\n    df_characters = pd.read_csv('data\\u002fsimpsons_characters.csv').reset_index(inplace=False, drop=True)\\n    df_locations = pd.read_csv('data\\u002fsimpsons_locations.csv').reset_index(inplace=False, drop=True)\\n    df_script = pd.read_csv('data\\u002fsimpsons_script_lines.csv').reset_index(inplace=False, drop=True)\\n    df_episodes = pd.read_csv('data\\u002fsimpsons_episodes.csv').reset_index(inplace=False, drop=True)\",\"\\n# from the 'simpsons_script_lines.csv' dataset, only keeping the first 5061 rows to decrease the dataset size and uploading time\\ndf_script = df_script[:5061]\",\"Add GDP data to the dataframe\\ngdp_per_capita_data = pd.read_csv('data\\u002fgdp_per_capita.csv')\\n\\n# Set the ISO 3166-2 codes as the index to facilitate combining the datasets\\ngdp_per_capita_data.set_index('Country Code', inplace=True)\\n\\n# Convert any special or missing values (e.g. '..') to NaN\\ngdp_per_capita_data.replace('..', np.NaN, inplace=True)\\n\\n# Save the converted data\\ngdp_per_capita_data.to_csv('data\\u002fgdp_per_capita_cleaned.csv')\",\"Check the content of the 'simpsons_script_lines.csv' file\\ndf_script.head()\",\"Preprocessed dataframe from Jasper's notebook\\ndf_script = pd.read_parquet('..\\u002foutput\\u002fscript_preprocessed.parquet')\"],\"marker\":{\"opacity\":0.5,\"size\":5},\"mode\":\"markers+text\",\"name\":\"33_Reading and Loading Simpsons Data into Pandas DataFrames\",\"text\":[\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\"],\"textfont\":{\"size\":12},\"x\":[11.820868492126465,11.696866989135742,10.785017013549805,13.363741874694824,11.715279579162598,13.59274959564209,10.668170928955078,11.395054817199707,12.601202011108398,10.653404235839844,13.520511627197266,11.474868774414062,13.23636531829834,10.617212295532227,11.592853546142578,10.636370658874512,11.06143569946289,13.628010749816895,11.612462997436523,10.900909423828125,11.335919380187988,11.038900375366211,11.565569877624512,13.255517959594727,12.41773509979248,11.07513427734375,11.618083953857422,13.275934219360352,11.867097854614258,12.318772315979004,11.611174583435059,10.986008644104004,10.994816780090332,11.35344409942627,10.984740257263184,11.25479507446289,10.99897575378418,4.550197601318359,11.46029281616211,11.480138778686523,11.56268310546875,12.070240020751953,11.64484691619873,11.151823043823242,11.02214527130127,11.372797966003418,13.659672737121582,10.913941383361816,11.571764945983887,10.262048721313477,11.727087020874023,7.709115028381348],\"y\":[2.6719229221343994,3.4439237117767334,1.9465515613555908,4.548198699951172,2.4068048000335693,4.517540454864502,2.690600872039795,2.4775116443634033,4.268767833709717,2.5026016235351562,4.236260414123535,2.1197736263275146,4.551657676696777,1.800299882888794,3.766925811767578,1.8242595195770264,2.3054111003875732,4.528042793273926,4.011523723602295,2.0914108753204346,3.30757737159729,2.1737754344940186,2.066725254058838,4.603488445281982,3.9768824577331543,2.2366247177124023,4.114710807800293,4.546172618865967,4.349234580993652,3.507690906524658,3.5818793773651123,1.8551422357559204,2.5222387313842773,2.0351250171661377,3.293349027633667,2.349137306213379,2.032822847366333,3.3009934425354004,3.404301166534424,3.5794448852539062,2.6808841228485107,4.252054691314697,3.3544437885284424,2.890808582305908,2.165212869644165,3.6965034008026123,4.7652387619018555,2.020357131958008,3.1225638389587402,2.4252519607543945,4.009213924407959,-2.2677366733551025],\"type\":\"scattergl\"},{\"hoverinfo\":\"text\",\"hovertext\":[\"Check if the indexes are correct in each dataframe\\ndf_characters.head()\",\"Check the characters DataFrame\\ndf_characters.head()\",\"Check result for each DataFrame\\ndf_characters.head()\",\"Check dataframes\\ndf_characters.head()\",\"Check the head of the characters dataframe\",\"  check the data that we have available in the characters dataframe\\ndf_characters.head()\",\"Check the contents of the characters dataframe for any missing or NaN values\\ndf_characters.head()\",\"Checking for the head of the characters dataframe\",\" Check the head of the characters dataframe\",\"Check dataframes structure\\ndf_characters.head()\",\" Check the content of the characters dataframe\\ndf_characters.head()\",\"Check the structure and contents of those DataFrames\\ndf_characters.head()\",\"Check the contents of the Characters dataframe\\ndf_characters.head()\",\"# You can ignore this cell, it is only for checking the available attributes and methods of a pandas DataFrame\\n[df_characters.\",\"Check the content of the characters dataframe\\nprint(df_characters.head())\",\"Check the shape and top rows of each dataframe\\ndf_characters.head(), df_characters.shape\",\"Check the resulting DataFrames\\ndf_characters.head()\",\"# Checking the df_characters dataframe\\ndf_characters.head()\",\"Check the contents of df_characters dataframe\\ndf_characters.head()\",\"Check the contents of the characters DataFrame\\ndf_characters.head()\",\"Check the content of each dataframe\\ndf_characters.head()\",\"df_main_chars = df_characters[df_characters['raw_character_text'].isin(main_chars)]\\ndf_main_chars.head()\",\"\\n# Check dataframe head\\ndf_characters.head()\",\"Check the content of the characters dataframe\\ndf_characters.head()\",\"Check dataframes\\ndf_characters.head()\",\" Rerun the similar code and use the head and tail commands to check the data of each dataframe individually\\ndf_characters.head()\",\"Checking the dataframes\\ndf_characters.head()\",\"Check the head of the characters dataframe\",\"Check the contents of the characters DataFrame\\ndf_characters.head()\",\"Check the dataframes\\ndf_characters.head()\",\"Check how the dataframes look\\ndf_characters.head()\",\"Check dataframes structure\\nprint(df_characters.head(5))\",\"Check the dataframe\\ndf_characters.head()\",\" Checking out the characters DataFrame\\ndf_characters.head()\",\" Check the dataframes\\ndf_characters.head()\",\" Check the content of the characters dataframe\\ndf_characters.head()\",\"Check the schema of the characters DataFrame\\ndf_characters.head()\",\"Check the dataframes\\ndf_characters.head()\",\"Check the contents of the character dataframe\\ndf_characters.head()\",\"Check some content from the characters DataFrame\\ndf_characters.head()\",\"Check a sample of the characters dataframe\\ndf_characters.head()\",\"Check the structure of the dataframes\\ndf_characters.head()\",\"Check the structure of the characters DataFrame\\ndf_characters.head()\",\"Check the general structure of the dataframes\\ndf_characters.head()\",\"Check df_characters columns\\ndf_characters.head()\",\" Check the content of the characters dataframe\\ndf_characters.head()\",\" Check the characters dataframe\\ndf_characters.head()\",\"Check the content of the characters dataframe\\ndf_characters.head()\",\"Check the contents of the characters dataframe\\ndf_characters.head()\",\"# Check the contents of the characters DataFrame\\ndf_characters.head()\"],\"marker\":{\"opacity\":0.5,\"size\":5},\"mode\":\"markers+text\",\"name\":\"34_Checking Contents of DataFrame df_characters.head()\",\"text\":[\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\"],\"textfont\":{\"size\":12},\"x\":[4.757733345031738,4.061208248138428,4.284896373748779,4.450864791870117,7.799408912658691,4.776413440704346,5.1465959548950195,7.710172176361084,7.581775188446045,4.408321857452393,3.929699420928955,5.113029479980469,4.136486053466797,5.683410167694092,4.601309776306152,4.680375099182129,4.476693630218506,4.830851078033447,4.530284404754639,4.225846290588379,4.558837890625,5.667697429656982,4.710063934326172,4.046878814697266,4.447148323059082,5.60537052154541,4.425785064697266,7.851966857910156,3.9860517978668213,4.432746410369873,5.031250476837158,4.347570419311523,4.458076000213623,4.304304599761963,4.515711784362793,3.8474082946777344,3.982802152633667,4.606197357177734,4.164593696594238,3.602166175842285,4.29453182220459,4.460218906402588,4.116964817047119,4.44821310043335,4.2278733253479,4.063708305358887,4.41917085647583,3.92093825340271,4.091655731201172,4.746167182922363],\"y\":[13.974294662475586,12.871267318725586,13.542811393737793,13.303690910339355,16.346881866455078,12.734954833984375,12.950510025024414,16.102651596069336,16.43183708190918,14.134781837463379,12.72856616973877,14.12719440460205,12.68209171295166,12.489493370056152,13.172330856323242,13.29951000213623,13.761204719543457,12.81688117980957,12.397904396057129,13.001928329467773,13.344801902770996,11.210136413574219,13.0244779586792,12.866900444030762,13.45068359375,13.898200988769531,13.666068077087402,16.247114181518555,12.770528793334961,13.542512893676758,15.017451286315918,14.20936393737793,13.418726921081543,13.052701950073242,13.57577896118164,13.090021133422852,13.105107307434082,13.510531425476074,13.165295600891113,12.773490905761719,12.909223556518555,14.296721458435059,13.778898239135742,14.329377174377441,12.956671714782715,12.961750030517578,12.896866798400879,12.819351196289062,12.56409740447998,12.487639427185059],\"type\":\"scattergl\"},{\"hoverinfo\":\"text\",\"hovertext\":[\"Now let's take a look at the first few rows of each dataframe to understand the structure and content of the data.\",\"Let's take a look at the structure of each of these DataFrames and their first few rows.\",\" Let's take a look at the columns of each dataframe and some of its rows to understand the data.\",\" The first 3 lines of this code are meant to ensure that the spacing and the output of the dataframe are as expected.\",\"Let's take a look at the first few rows of each dataframe to understand the data structure.\",\"Let's start by taking a look at the first few rows of each dataframe to understand their structure and contents.\",\"Let's take a look at the first few rows of each DataFrame to understand its structure.\",\"Let us take a look at the first few rows from each dataframe to figure out their structure.\",\"Let's examine the first few rows of each DataFrame to better understand their structure.\",\" Now, let's take a look at the first few rows of each of these DataFrames to understand their structure and the kind of data they contain.\",\"Before continuing, let's take a look at the first few rows of each dataframe to understand their structure and contents.\",\"Understand the structure of each dataframe\",\" Now let's take a look at the first few rows of each dataframe to understand their structure and contents.\",\" Now let's take a look at the first few rows of each dataframe to understand their structure and contents.\",\"Let's take a look at the first few rows of each DataFrame to understand the data's structure.\",\"Let's take a look at the first few lines of each dataframe to understand their structure and contents.\",\"Let's look at the first few rows of each of these dataframes to understand their structure and contents.\",\"Let's take a look at the first few rows of each dataframe to understand the data structure.\",\"Let's take a look at the first 5 rows of each dataframe to understand their structure.\",\"Let's look at the first few rows of each of these dataframes to understand their structure better.\",\"Let's take a look at the first few rows of each DataFrame to understand their structure.\",\"Let's check the first few rows of each DataFrame to understand its structure better.\",\"Let's check the first few rows of each dataframe to understand its structure.\",\"We'll start by taking a look at the first few rows of each of the dataframes to understand their structure and the kind of data they contain.\",\"OK, now that we have loaded the data, let's take a look at the first few rows of each dataframe to understand its structure and the kind of data we're working with.\",\"Let's take a look at the first couple of rows in each dataframe to understand the structure and content.\",\" Let's inspect the first few rows of each DataFrame to understand their structure and contents.\",\"Let's take a look at the first lines from each DataFrame to understand their structure.\",\"Let's take a look at the first few rows in each dataframe to understand the data structure.\",\"Let's have a look at the first few rows of each DataFrame to understand their structure.\",\" Let's take a look at the first few rows of each DataFrame to understand their structure and contents.\",\"Let's take a look at the first rows of each dataframe to understand what data is available:\",\"Let's inspect the first few rows of each of these DataFrames to understand their structure and content.\",\" Let's take a look at the first few rows of each dataframe to understand their structure and contents.\",\"Let's take a look at the structure and first few rows of each DataFrame.\",\"Let's take a look at the structure of each of the dataframes by printing the first few rows.\",\"First, let's take a look at the first few rows of each DataFrame to understand their structure.\",\" Let's take a look at the first few rows of each dataframe to understand their structure and contents.\",\" Let's take a look at the first few rows of each DataFrame to understand the structure of the data.\",\"Let's start by taking a look at the first few rows of each of these DataFrames to understand their structure and contents.\",\" Let's inspect each DataFrame to understand its structure and the data it contains.\",\"Let's start by taking a look at the first few rows of each dataframe to understand its structure and the kind of data it contains.\",\"Let's inspect the first few lines of each dataframe to understand the structure of the data.\",\" We should also take a look at the first few lines of each DataFrame to understand their structure and data.\",\" We want to begin by exploring the contents of these DataFrames and understand how they are related to each other.\",\"Let's take a look at the first 5 rows of each dataframe to understand their structure and the type of data they contain.\",\" Let's take a look at the first few rows of each dataframe to understand its structure.\",\"Let's check the first few rows of each dataframe to understand its structure.\",\"Now we have all the data loaded. Let's explore each DataFrame to understand its structure and the kind of information it provides.\"],\"marker\":{\"opacity\":0.5,\"size\":5},\"mode\":\"markers+text\",\"name\":\"35_Understanding DataFrame Structure\",\"text\":[\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\"],\"textfont\":{\"size\":12},\"x\":[8.490278244018555,9.759319305419922,8.936613082885742,9.603464126586914,9.199138641357422,9.646288871765137,9.19613265991211,9.212979316711426,9.388199806213379,9.055049896240234,8.86656379699707,9.266114234924316,8.709477424621582,8.772259712219238,8.824795722961426,8.696654319763184,8.950274467468262,9.314208030700684,9.628225326538086,9.304137229919434,8.967489242553711,9.635141372680664,9.115117073059082,9.655492782592773,9.098697662353516,8.378451347351074,9.345386505126953,8.928308486938477,9.036559104919434,8.799276351928711,8.855616569519043,9.690563201904297,9.433743476867676,8.748526573181152,9.55751895904541,9.92025089263916,9.167590141296387,8.727241516113281,8.918610572814941,9.304976463317871,9.291433334350586,9.415982246398926,9.463628768920898,8.829471588134766,9.556191444396973,9.25723934173584,9.072147369384766,9.24415111541748,8.798951148986816],\"y\":[-8.067498207092285,-7.903286933898926,-7.940095901489258,-6.699848175048828,-8.096607208251953,-7.665851593017578,-8.484232902526855,-7.594503402709961,-8.40956974029541,-8.00793170928955,-7.863240718841553,-7.91525411605835,-8.126852035522461,-8.220252990722656,-7.941374778747559,-7.581000328063965,-8.428069114685059,-8.037834167480469,-8.292845726013184,-8.248051643371582,-8.284915924072266,-7.865992546081543,-7.913966655731201,-7.251325607299805,-7.261564254760742,-8.476263999938965,-8.294028282165527,-7.779058933258057,-8.017509460449219,-8.163792610168457,-8.049756050109863,-8.006806373596191,-8.692856788635254,-8.215058326721191,-8.385704040527344,-8.482470512390137,-7.920317649841309,-8.20523738861084,-8.016863822937012,-7.514474391937256,-7.293238639831543,-7.878721714019775,-7.742079257965088,-7.257626056671143,-6.910074710845947,-8.363265991210938,-8.459077835083008,-7.973238945007324,-7.076314926147461],\"type\":\"scattergl\"},{\"hoverinfo\":\"text\",\"hovertext\":[\"Limit the number of script lines (for quicker testing)\\ndf_script = df_script[:1000]\",\"Limit the number of script lines for this example\\ndf_script = df_script.head(5000)\",\"Create a sampling of the data to speed up the process\\ndf_script = df_script.sample(frac=1)\",\"Create a sample of the dataset for performance reasons\\ndf_script_sample = df_script.sample(5000, random_state=42).reset_index(drop=True)\",\"Limit the rows for the script dataframe\",\"For demonstration purpose, we limit the analysis to a short subset\\ndf = df_script.loc[:1000].copy()\\ndf.head()\",\"Reduce dataframe size to first 1000 rows for testing\\ndf_script = df_script.iloc[:1000]\",\"Limit the number of lines to use due to the large size of the data set\\nnum_lines = 10000 \",\"Remove unnecessary index column\\ndf_script = df_script.iloc[:,1:]\",\"limit the number of rows to use for easy of computation\\ndf_script_subset = df_script.iloc[:10000]\",\"Limit the number of rows to 5000 to speed up computations\\ndf_script = df_script.head(5000)\",\"Limit of records to read from each data frame.\\nLIMIT = int(1e6)\",\"Limit the number of script lines for this example\\ndf_script = df_script.head(10000)\",\"df_script = df_script.sample(1000)  # Speed up computation\",\"Extract a smaller random sample of the data for faster visualization and exploration\\ndf_script_sample = df_script.sample(n=10000, random_state=1)\",\"Limit number of script lines for testing purposes\\ndf_script = df_script.head(5000)\",\"Limit the dataframe to the first 5,000 rows for faster experimentation\\ndf_script = df_script.iloc[:5000]\",\"Limit rows to 50000 to avoid memory errors and makes things faster\\ndf_script = df_script[:50000]\",\" For better performance, just use the latest 1000 lines of the script for now\\ndf_script = df_script.loc[:1000]\",\"#split the huge script file to disable the huge warning of 15GB\\ndf_script1 = df_script.iloc[:300000]\\ndf_script2 = df_script.iloc[300000:]\",\" Define a sample size that you want to analyze to speed up computations\\nsample_size = 10000\",\"subset making the code run faster\\ndf_script_subset = df_script.iloc[:50000]\",\"Limit the number of script lines for now\\ndf_script = df_script.iloc[:10000]\",\" Limiting the number of documents to 500 for performance reasons.\\ndf_script = df_script.iloc[:500]\",\" Optional: limit the number of script lines to speed up computation\\n# df_script = df_script.head(1000)\",\"Create a sample of the line dataframe that works fast\\nnp.random.seed(1)\\ndf_script_sample = df_script.sample(n=10000)\",\"Extract the first 1000 lines of the script for analysis\\ndf_first_1000_lines = df_script.iloc[:1000]\",\"Limiting the database to only 5,000 lines\",\"Limit the number of script lines to 5,000 for speed reasons\\ndf_script = df_script[:5000]\",\" Optionally, limit the number of script lines for faster performance\\n# df_script = df_script[:5000]\",\"Limiting data to first 10,000 records for quicker results\\ndf_script = df_script.head(10000)\",\" To make the script smaller, we will only use the first 10,000 rows of `df_script`.\\ndf_script = df_script.iloc[:10000]\",\" Displaying only the first 1000 records for performance reasons\\ndf_script = df_script.head(1000)\",\"Limit the number of script lines for now\\n# df_script = df_script[:50000]\",\"Remove temporarily\\nscript_subset = df_script.iloc[:5000].copy()\",\"Limiting the data in the script to only 10,000 rows to improve computational performance\\ndf_script = df_script.head(10000)\",\"Limit the number of rows to 10000\\ndf_script = df_script.head(10000)\",\"Limit the number of script lines to 10000 to speed up computation\\ndf_script = df_script.sample(n=10000, random_state=1)\",\" Limit the number of rows to speed up the development of the notebook\\n# df_script = df_script.head(15000)\",\"Limit the number of scripts to not run out of memory during these computations\\ndf_script = df_script.iloc[:100000]\",\"Set the LIMIT constant\\nLIMIT = 10000\",\" Limit the number of lines in the script dataframe for the sake of example\\ndf_script = df_script.iloc[:10000]\",\" Limit rows for quick debugging\\n# df_script = df_script[:100000]\",\"Extract a small subset for testing\\ndf_script = df_script.head(100000)\",\" Limit the number of script lines for faster execution\\nLIMIT = 50000\\ndf_script = df_script.iloc[:LIMIT]\",\" Select first 10k\\ndf_script = df_script.iloc[:10000]\",\"Limiting the number of records for the sake of memory and CPU limitations\\ndf_script = df_script.sample(n=1000, random_state=1)\",\"Limit the number of script lines for faster processing time\\ndf_script_limit = df_script.sample(n=600000, random_state=1)\",\"Limiting the amount of information for brevity\\ndf_script = df_script.iloc[:300000]\"],\"marker\":{\"opacity\":0.5,\"size\":5},\"mode\":\"markers+text\",\"name\":\"36_Limiting script lines for faster execution and performance\",\"text\":[\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\"],\"textfont\":{\"size\":12},\"x\":[10.307635307312012,10.290107727050781,9.305685997009277,9.036771774291992,11.363842010498047,10.086194038391113,9.849550247192383,12.71995735168457,9.0731782913208,9.876240730285645,10.539981842041016,10.652807235717773,10.062104225158691,10.021661758422852,9.187986373901367,10.371774673461914,9.913310050964355,10.713641166687012,10.003043174743652,8.986693382263184,11.42265510559082,9.613036155700684,9.66965103149414,9.990010261535645,9.95866584777832,9.36842155456543,9.816726684570312,13.564237594604492,10.137303352355957,10.132026672363281,10.216279983520508,9.565088272094727,9.927800178527832,10.332923889160156,9.24945068359375,10.66537857055664,10.818658828735352,9.247617721557617,10.996757507324219,9.503803253173828,13.027130126953125,9.963713645935059,10.83211898803711,9.718313217163086,9.593160629272461,9.496809005737305,9.960003852844238,9.53223705291748,9.875603675842285],\"y\":[-2.088829278945923,-1.8721286058425903,-1.8970619440078735,-2.065383195877075,-4.028171539306641,-1.8682026863098145,-1.9519318342208862,-0.11026950925588608,-1.6986557245254517,-2.2214865684509277,-2.172264814376831,-3.041924476623535,-2.24011492729187,-1.5585538148880005,-2.2448008060455322,-2.4241385459899902,-1.7899473905563354,-1.5348756313323975,-2.156175136566162,-1.821711540222168,-0.7227612137794495,-1.5885307788848877,-2.382920265197754,-2.1259067058563232,-2.0915212631225586,-2.166630983352661,-2.128401041030884,0.5662133693695068,-2.4323160648345947,-1.9002387523651123,-2.2995026111602783,-2.072517156600952,-2.6385064125061035,-2.401700019836426,-1.852374792098999,-2.0901834964752197,-2.665069818496704,-2.005016803741455,-2.1422839164733887,-1.5884959697723389,0.24841523170471191,-1.9710923433303833,-2.6956658363342285,-1.86866295337677,-1.8750017881393433,-1.8141844272613525,-2.1086926460266113,-1.8097707033157349,-2.013530969619751],\"type\":\"scattergl\"},{\"hoverinfo\":\"text\",\"hovertext\":[\"Inspect the first few rows of the characters dataframe\\nprint(df_characters.head())\",\"Inspect the first few records of the characters dataframe\\ndf_characters.head()\",\"Inspect the first few rows of the characters DataFrame\\ndf_characters.head()\",\"Inspect the first few rows of the characters DataFrame\\ndf_characters.head()\",\"Inspecting the first elements of the characters dataframe\\ndf_characters.head()\",\"Inspect first rows of characters dataframe\\ndf_characters.head()\",\"Inspect the first few rows of the characters dataframe\\ndf_characters.head()\",\"Examine the first few rows of the characters dataframe\\ndf_characters.head()\",\"Looking at the first rows of the characters dataframe\\ndf_characters.head()\",\"Inspect the first 2 rows of the characters dataframe\\ndf_characters.head(2)\",\"inspect the first few rows of each dataframe\\nprint(df_characters.head())\",\"Inspect the first few rows of the characters dataframe\\ndf_characters.head()\",\"Inspect the first few rows of the characters dataframe\\ndf_characters.head()\",\"Inspect the first few rows of the characters dataframe\\ndf_characters.head()\",\"Inspect the first few rows of the characters data frame\\ndf_characters.head()\",\"Inspect the first few rows of the characters dataframe\\nprint(df_characters.head())\",\"Inspect the first few rows of the characters dataframe\\ndf_characters.head()\",\"Inspect the first few rows of the first dataframe\\ndf_characters.head()\",\"Inspect the first few rows of the characters DataFrame\\ndf_characters.head()\",\"Exploring the first few rows of the dataframe\\ndf_characters.head()\",\" Explore the first few rows of the characters dataframe\\ndf_characters.head()\",\" Explore the first few rows of the characters DataFrame\\ndf_characters.head()\",\"Quick look at the first rows of each DataFrame\\ndf_characters.head()\",\"Inspect the first few rows of the character dataframe\\ndf_characters.head()\",\"Inspect the first few rows of the characters dataframe\\ndf_characters.head()\",\"Inspect the first few rows of the characters dataframe\\ndf_characters.head()\",\"Inspecting the first few rows of the characters dataframe\\ndf_characters.head()\",\"Inspect first few rows of the characters DataFrame\\ndf_characters.head()\",\"Inspect the first few rows of the characters dataframe\\ndf_characters.head()\",\"Inspect the first few rows of the characters dataframe\\ndf_characters.head()\",\"Inspect the first few rows of the characters dataframe\\nprint(df_characters.head())\",\"Inspect the first few rows of the characters dataframe\\ndf_characters.head()\",\"# Print the first few rows of df_characters to see the data\\ndf_characters.head()\",\"Inspect the first few rows of the characters dataframe\\ndf_characters.head()\",\"Inspect the first few rows of the characters dataframe\\ndf_characters.head()\",\"Inspect the first few rows of the characters dataframe\\ndf_characters.head()\",\"Inspect the first few rows of the characters dataframe\\ndf_characters.head()\",\"Inspect the first few rows of the characters dataframe\\ndf_characters.head()\",\"inspect first few rows of the dataframe\\ndf_characters.head()\",\"inspect the first rows of the characters DataFrame\\ndf_characters.head()\",\"inspect the first few records of the dataframe\\ndf_characters.head()\",\"Inspect the first few rows of the characters DataFrame\\ndf_characters.head()\",\"Inspect first few rows of the characters data\\nprint(df_characters.head())\",\"Inspect the first few rows of the characters dataframe\\ndf_characters.head()\",\"Inspect the first few rows of the characters dataframe\\ndf_characters.head()\",\"Inspect the first few rows of the characters dataframe\\ndf_characters.head()\",\"Inspect the first few rows of the characters DataFrame\\ndf_characters.head()\",\"Look at first rows of characters dataframe\\ndf_characters.head()\"],\"marker\":{\"opacity\":0.5,\"size\":5},\"mode\":\"markers+text\",\"name\":\"37_Inspecting the first few rows of the characters dataframe\",\"text\":[\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\"],\"textfont\":{\"size\":12},\"x\":[5.52982234954834,5.152312278747559,6.367485046386719,6.237192153930664,5.6530842781066895,5.733865261077881,6.240199089050293,5.861572265625,5.794174671173096,6.0600266456604,4.9924235343933105,5.97402811050415,5.884415626525879,5.9925761222839355,5.99924898147583,5.623841285705566,6.222019672393799,5.875439643859863,6.184189319610596,5.661169052124023,5.895246505737305,6.042586803436279,5.9837965965271,6.055093288421631,6.014349460601807,6.023085117340088,5.637069225311279,6.212716579437256,5.782834529876709,6.048486709594727,5.673685073852539,5.748208999633789,4.758214950561523,6.129335880279541,5.618494033813477,5.823338508605957,6.027562618255615,5.821150302886963,5.666113376617432,5.6510491371154785,5.599775791168213,5.900448322296143,5.086878776550293,5.958242893218994,5.974723815917969,6.061375617980957,6.370828151702881,5.268534183502197],\"y\":[19.73158073425293,20.02526092529297,20.43248748779297,20.212888717651367,19.11335563659668,20.10205841064453,20.43280029296875,19.902441024780273,19.592334747314453,20.62992286682129,19.81829071044922,20.49230194091797,20.06886100769043,19.962371826171875,19.915307998657227,19.717500686645508,20.387893676757812,19.985002517700195,20.351408004760742,19.521732330322266,19.676685333251953,19.8668270111084,18.986526489257812,20.126296997070312,20.33995819091797,20.355531692504883,19.72328758239746,20.21597671508789,20.555402755737305,20.799917221069336,19.69981575012207,20.53730010986328,17.807100296020508,20.656570434570312,20.383319854736328,20.370107650756836,20.217601776123047,20.5584774017334,19.825349807739258,19.69622039794922,20.49630355834961,20.434463500976562,18.80038833618164,20.558290481567383,20.45195198059082,20.10952377319336,20.48941421508789,19.502010345458984],\"type\":\"scattergl\"},{\"hoverinfo\":\"text\",\"hovertext\":[\"Inspect the dataframes\",\"Inspect Dataframes\",\"Inspect the dataframes\",\"Inspect the dataframes\",\"We'll quickly inspect each of these dataframes.\",\" Let's quickly inspect the dataframes\",\"Start an analysis session using pandas and matplotlib\",\"Inspect the dataframes\",\"Inspect the dataframes\",\"We can now use the previously defined read-in data frames for further data processing and analysis.\",\"Quick look at the dataframes\",\"Inspect the dataframes\",\"Inspect dataframesidency and common features\",\"Inspect the dataframes\",\"Inspect all dataframes and their features\",\"Inspect dataframes\",\"Create a dataframe with the lines we intend to analyze.\",\"Explore the contents of the dataframes\",\"Inspect data frames\",\"Inspect the dataframes dtype\",\"Let's peek into each of the DataFrames\",\"Inspect the dataframes\",\"Inspect the dataframe shapes.\",\" Explore the content of the dataframes.\",\"Inspect dataframes\",\"Inspect the dataframes\",\"Inspect the dataframes\",\"Inspecting the dataframes\",\"Inspect the data frames\",\"Inspect Dataframes\",\"Inspect the content of the dataframes\",\"Inspect the dataframes\",\"Creating and inspecting the spark DataFrame\",\" Inspect what the dataframes look like\",\"Inspect the dataframes\",\"Inspect dataframes\",\"Inspecting the data frames\",\"Example of value you have access in the dataframe\",\"Inspect the dataframes\",\"Inspect dataframes\",\"Inspecting the dataframes\",\"Inspect the dataframes\",\"Inspecting the dataframes\",\"Quick look at the dataframes\",\"Inspect dataframes quickly\",\"Inspect the dataframes\",\"Quick look at the dataframes\"],\"marker\":{\"opacity\":0.5,\"size\":5},\"mode\":\"markers+text\",\"name\":\"38_Inspecting dataframes\",\"text\":[\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\"],\"textfont\":{\"size\":12},\"x\":[12.036731719970703,12.250479698181152,11.976851463317871,11.898503303527832,9.92145824432373,11.14684772491455,12.196951866149902,11.955998420715332,12.17284107208252,10.61785888671875,11.601024627685547,12.047249794006348,12.175793647766113,12.190118789672852,12.182814598083496,11.968573570251465,11.323012351989746,10.95122241973877,11.62868881225586,11.603882789611816,10.937749862670898,12.194242477416992,11.484018325805664,11.47034740447998,12.14205551147461,12.193249702453613,11.830077171325684,11.576996803283691,11.496964454650879,12.309840202331543,11.450864791870117,12.0066499710083,12.390521049499512,11.573474884033203,11.946626663208008,12.197314262390137,11.401444435119629,11.177440643310547,12.199378967285156,12.063528060913086,11.678120613098145,12.059015274047852,11.476141929626465,11.76013469696045,12.478339195251465,11.936599731445312,11.884117126464844],\"y\":[-4.313653469085693,-3.729092836380005,-4.378213405609131,-4.320102214813232,-5.569831371307373,-4.894935607910156,-1.3514313697814941,-4.02227258682251,-4.265838146209717,-5.2313127517700195,-4.757190227508545,-4.529181003570557,-4.1571125984191895,-4.486554145812988,-3.7330641746520996,-3.91451358795166,-3.3867695331573486,-4.140089988708496,-4.656551837921143,-5.3172101974487305,-5.383452415466309,-4.229269504547119,-4.25579309463501,-4.706993103027344,-3.9695498943328857,-4.4212188720703125,-4.43568754196167,-4.244217872619629,-4.9003705978393555,-3.90455961227417,-4.234531402587891,-4.583675861358643,-3.8480377197265625,-4.572047710418701,-3.984408140182495,-3.772106647491455,-5.110513210296631,-4.4276533126831055,-4.420422077178955,-3.932861328125,-4.088303565979004,-4.202491760253906,-4.243202209472656,-5.042335033416748,-4.008543491363525,-4.624411582946777,-4.939743518829346],\"type\":\"scattergl\"},{\"hoverinfo\":\"text\",\"hovertext\":[\"Merge dataframes to have all in one dataframe\",\"Merge the datasets to include all relevant information in one dataframe.\",\" Apply ?? over the different dataframes to look samples\",\"Merge dataframes to have all relevant information in one place\",\"Merge the datasets to get all the information in a single dataframe\",\"Create a single dataframe that contains all the information we need.\",\"Merge the dataset to get all the information in a single dataframe\",\" Join the dataframes to obtain a single unified dataframe containing all information.\",\"Merge the dataframes to get all the relevant information in one single dataframe\",\"merging the data to have all pertinent information in one dataframe\",\"Merge the datasets to get a single dataframe\",\"Create a simplified dataframe with only relevant information\",\"Merge the datasets to create a single dataframe with all the information we need.\",\" To achieve this, we'll use the `merge` function provided by Pandas to join our datasets together.\",\"Merge the tables to have all relevant information in one data frame\",\" Merge the datasets to get all the data in one dataframe\",\"Merge all data into one dataframe\",\"Merge all data into a single dataframe\",\" Merge the dataframes to get a single dataframe containing all the information we need.\",\"Apply slight transformation to each dataframe\",\"Merge all dataframes into a single one for more convenience\",\"Merge all dataframes into one, creating a unified dataframe with all information\",\"Merge dataframes to join the information into one dataframe\",\"We join the dataframes to have a unique dataframe containing all the relevant information.\",\"Merge all the information in a single DataFrame.\",\"Merge all dataframes into a single one\",\"Merge the related datasets into a single dataframe\",\"Merge datasets to have conversations with Chris on the same DataFrame\",\"Merge the datasets to create one single dataframe\",\"Create one big DataFrame containing all the informations needed for the following analysis:\",\"Merge the datasets to get all relevant information in one dataframe\",\" Integrating the data: combine the information from the different dataframes into a single dataframe.\",\"let's merge the dataframes to get a dataset with all information in one place.\",\"Combine the data from multiple dataframes into one dataframe for simplicity and ease of analysis.\",\"Merge the necessary data and filter the dataframe rows based on the conditions mentioned in the prompt.\",\"Concatenate CSVs to a single dataframe\",\"Merge the datasets to create a single dataframe with all the information we need.\",\" Combine the data in a single DataFrame for ease of manipulation.\",\"Merge all available data into one dataframe.\",\"I will merge some of the DataFrames, to be able to get all the necessary information in one DataFrame.\",\"Merge the datasets to include all relevant information in one dataframe.\",\"Create lists from the dataframes to transfer more complex df operations to SQL in order to improve speed\",\"Merge the datasets in order to have a unified dataframe containing all necessary information.\",\"merge all into one dataframe\",\" Merge the datasets to get all the relevant info in one dataframe\",\"Merge datasets to get all relevant information into one dataframe\",\"Merges all labeled data in one dataframe.\"],\"marker\":{\"opacity\":0.5,\"size\":5},\"mode\":\"markers+text\",\"name\":\"39_Merging Datasets for Unified Relevant Information\",\"text\":[\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\"],\"textfont\":{\"size\":12},\"x\":[6.032012462615967,6.846232891082764,6.509474277496338,6.270779132843018,5.823029041290283,6.993074893951416,5.650112152099609,6.720371723175049,6.113433837890625,6.154332160949707,6.050146579742432,6.652238845825195,7.349278450012207,6.41610050201416,5.963758945465088,6.06508207321167,6.3286237716674805,6.273638725280762,7.12681245803833,6.394998073577881,6.8150410652160645,6.528215408325195,5.950683116912842,7.110945224761963,6.294124603271484,6.501258373260498,6.367574691772461,6.334481239318848,6.493757247924805,7.493745803833008,6.181403636932373,6.906250953674316,6.976377010345459,6.8154706954956055,7.323936939239502,5.8964457511901855,7.469964027404785,6.184072017669678,6.719444751739502,7.436315536499023,6.811254501342773,7.7270073890686035,7.241413593292236,6.115394115447998,5.993922710418701,6.3898138999938965,5.977782249450684],\"y\":[-0.6244175434112549,-0.5259408354759216,-1.7343693971633911,-1.0461214780807495,-1.14264714717865,-0.6158241629600525,-0.848779022693634,-0.858574390411377,-1.1983050107955933,-1.3704018592834473,-0.6123759746551514,-0.8119328618049622,-0.6463798880577087,-0.8166868090629578,-0.764842689037323,-0.9761759042739868,-0.7970424890518188,-0.9197394251823425,-0.8461835384368896,-0.2821851968765259,-0.5280497670173645,-0.9723086953163147,-0.9251126050949097,-0.8268711566925049,-1.1203386783599854,-0.6636422276496887,-0.9571198225021362,-0.6476768851280212,-0.37721484899520874,-1.198652744293213,-0.4535690248012543,-1.0179747343063354,-0.47122636437416077,-1.252923607826233,0.3171935975551605,-1.2088888883590698,-0.7289235591888428,-1.1784236431121826,-0.9119614958763123,-0.7366694211959839,-0.683118999004364,-0.3927333950996399,-0.7205994725227356,-1.166391372680664,-0.599555492401123,-0.660507082939148,-0.9454323649406433],\"type\":\"scattergl\"},{\"hoverinfo\":\"text\",\"hovertext\":[\" Display the script dataframe\\ndf_script.head()\",\" Display several columns to see the data\\ndf_script.head()\",\"Print the head of the dataframe containing the script lines.\",\" Show the script lines dataframe\\ndf_script.head()\",\"View script head\\ndf_script.head()\",\"Show data\\ndf_script.head()\",\" Display script lines dataframe\\ndf_script.head()\",\"Display dataframe\\ndf_script.head()\",\"Display the script\\ndf_script.head()\",\" Show df_scirpt for testing purposes\\ndf_script.head()\",\" Show the head of the script\\ndf_script.head()\",\"Display scripts dataframe\\ndf_script.head(3)\",\"- Element displaysdf_script.head()\",\"View the script lines dataframe\\ndf_script.head()\",\"Display the data\\ndf_script.head()\",\"Display resulting dataframe head\\ndf_script.head()\",\"View script dataframe\\ndf_script.head()\",\"Show dataframe\\ndf_script.head()\",\"View scripts\\ndf_script.head()\",\"Display the scripts dataframe\\ndf_script.head()\",\"Show the head of the script dataframe\\ndf_script.head()\",\" Display data from the scripts\\ndf_script.head()\",\" Show head of script dataframe\\ndf_script.head()\",\"# Display some dataframes\\ndf_script.head()\",\" Display scripts\\ndf_script.head()\",\"View data\\ndf_script.head()\",\" Print the head of the script data frame\\ndf_script.head()\",\"Display head of the script data\\ndf_script.head()\",\" Display script data\\ndf_script.head()\",\"Display\\ndf_script.head()\",\"Printing the head of the scripts dataframe\\ndf_script.head()\",\"Display script dataframe\\ndf_script.head()\",\" Display head of script dataframe\\ndf_script.head()\",\" Show the head of the data\\ndf_script.head()\",\"# View the overall script\\ndf_script.head()\",\" Print head of script lines dataframe\\ndf_script.head()\",\"Display head of scripts DataFrame\\ndf_script.head()\",\"Display dataframe\\ndf_script.head()\",\"View format of `script` DataFrame\\ndf_script.head()\",\"Display the scripts dataframe\\ndf_script.head()\",\"Format and display the script data\\ndf_script.head()\",\"  display(df_script.head())\",\" Display head of lines\\ndf_script.head()\",\"Display script dataframe\\ndf_script.head()\",\"Display the scripts DataFrame\\ndf_script.head()\",\"Display the data in the dataframe for script lines with a head function\",\" Display the dataframe\\ndf_script.head()\"],\"marker\":{\"opacity\":0.5,\"size\":5},\"mode\":\"markers+text\",\"name\":\"40_Displaying and Viewing Scripts DataFrame\",\"text\":[\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\"],\"textfont\":{\"size\":12},\"x\":[7.10159158706665,4.108335494995117,6.456945419311523,6.359211444854736,6.16492223739624,5.420073986053467,6.57296085357666,7.181075572967529,6.070603847503662,5.638641834259033,6.403249263763428,6.508109092712402,6.512465476989746,6.893641948699951,5.350616455078125,7.512203693389893,6.310417175292969,7.072571277618408,5.9563889503479,6.816468715667725,6.721864223480225,5.817147254943848,6.892812252044678,7.301749229431152,6.235203266143799,5.29053258895874,6.255528450012207,6.005262851715088,5.880227088928223,6.272924423217773,6.429006099700928,7.107419490814209,6.927022457122803,5.6679792404174805,6.0586419105529785,6.477406024932861,6.8255934715271,7.281792163848877,6.519380569458008,6.876138210296631,6.057724475860596,6.601707458496094,5.846770763397217,7.041662693023682,6.737880229949951,7.055100917816162,7.083558559417725],\"y\":[-5.431171894073486,-6.146592617034912,-4.980530738830566,-5.3153276443481445,-5.675449371337891,-5.653534889221191,-5.1899638175964355,-5.521719455718994,-5.796815872192383,-5.155693531036377,-5.920206546783447,-5.774731159210205,-5.188822269439697,-5.404221057891846,-5.62862491607666,-5.52716588973999,-5.7366862297058105,-5.718691349029541,-5.843449592590332,-5.469161510467529,-6.1931376457214355,-5.748252868652344,-6.231656074523926,-5.182701110839844,-5.793322563171387,-5.389368057250977,-6.116489410400391,-5.909636974334717,-5.257111549377441,-5.623581409454346,-6.318641185760498,-5.490557670593262,-6.044206142425537,-5.857246398925781,-5.80086088180542,-5.841912269592285,-6.003999710083008,-5.3337788581848145,-5.961062431335449,-5.383067607879639,-5.653589725494385,-5.366063594818115,-5.543338298797607,-5.231520652770996,-5.340133190155029,-5.37325382232666,-5.231209754943848],\"type\":\"scattergl\"},{\"hoverinfo\":\"text\",\"hovertext\":[\"Visualising the occurences of character names with wordclouds\",\"Word cloud of the simpsons locations\",\"This script is intended to turn script lines into bag of words format, and then create word clouds.\\n# To do so, we start by processing script lines to obtain bag of words.\\n# We then implement a function to display the word cloud for a subset of episodes or a subset of speakers.\",\"visualize wordcloud of Simpson script data\",\"Caching the Word Embeddings to quickly iterate on the same computations.\",\"This process builds WordClouds for the 10 most common words of each script line, character, and location.\",\"We will be using the script dataset to extract insights and create a word cloud.\",\"Visualize the most common words in the script lines of The Simpsons using WordCloud\",\"Analyzing the character lines and building word clouds\",\"Visualizing The Most Common Words with WordClouds\",\"Word cloud visualization for the entire Simpsons script\\nscript_texts = ' '.join([str(x) for x in df_script['normalized_text'].values])\\nwordcloud = WordCloud(width = 2000, height = 1000, random_state=21, max_font_size=200).generate(script_texts)\\nplt.figure(figsize=(20, 10))\\nplt.imshow(wordcloud, interpolation=\\\"bilinear\\\")\\nplt.axis('off')\",\"Creating the word cloud for the most common words in the script lines\",\" Collecting personal stopwords, frequent mispellings, common words referring to the simpsons, and imperatives\",\" Visualize the top 20 most common words in the script lines.\",\" Visualise the top k most frequently used words in script lines in a word cloud\",\"Creating wordcloud of character dialogue\\n# Process of creating wordcloud\\n# 1. merges the script lines dataframe with the characters dataframe \\n# on the character, episode_id columns of the script lines dataframe and the \\n# id column of the characters dataframe\\n# 2. filter out characters where gender is not provided\\n# 3. filter out script lines that are not spoken or have no spoken_words\\n# 4. filter out episodes that have not been aired or have not started\\n# 5. perform sentiment analysis on the spoken_words and assign the sentiment through a column\\n# 6. create word cloud of the dialogue of a character\",\"Ways to handle and format a list of fastText word vectors.\",\"Visualize the most common words in the simpsons script lines\",\"Show Word Cloud for every Season Word Clouds for each season - top 100 lemmas displayed, sizes based on the number of occurrences in the whole season\",\"Visualize the most common words in the script lines using a word cloud\",\" Displaying the word cloud for the most common words in The Simpsons script lines\",\"Plot WordCloud of character for a specific episode\",\" Select the 4000 most common words in the dataset\",\"Visualize the distribution of the most common words in the script lines.\",\"Visualizing the Simpsons script: A wordcloud of the most popular words in the script\",\"To Do: Implement word cloud for Simpsons script lines\",\"This script uses the `WordCloud` package to visualize the most common words found in the Simpsons script.\",\"WordCloud of the Simpsons script\\n# Word cloud of all the scripts spoken by each character\\nall_scripts = ' '.join(df_script.normalized_text)\\nwordcloud = WordCloud(width = 800, height = 400, random_state=21, max_font_size=110, background_color='white').generate(all_scripts)\\n\\nplt.figure(figsize=(10, 5))\\nplt.imshow(wordcloud, interpolation=\\\"bilinear\\\")\\nplt.axis('off')\\nplt.show()\",\"Visualizing a word cloud for the script lines\",\" Visualize the most common words in the script lines\",\"Word clouds are a popular way to visualize word frequencies in a corpus of text. Let's create a word cloud for the Simpsons script lines to see which words are most common.\",\"Visualize The Word Frequency In The Script Lines\",\" Let's start by visualizing a word cloud of the most common words in the script lines.\",\"Code to set up NLP model and visualize word frequencies\",\"Visualize the most common words using a word cloud\",\"Visualize the most frequent words in the script lines.\",\"Let's check the top word frequency in the simpsons lines\",\"Milestone 1: WordClouds and Frequency Analysis\\n# TODO: Create masks for the Gender of the Characters and their respective WordClouds for several episodes.\\n\\n# Store the punctuation characters to remove\\npunctuation = '!\\\"#$%&\\\\'()*+,-.\\u002f:;\\u003c=\\u003e?@[\\\\\\\\]^_`{|}~'\",\"Counting lines of each script to measure which characters play an important role in The Simpsons series and plot a word cloud\",\"Show word cloud of the previous amount of words spoken by the character with the most words.\",\" WordCloud requires text data to generate word clouds. We will use the Simpsons script lines as our text data to generate word clouds for each character's dialogues.\",\" Wordcloud for simpsons words\",\"Transform plain text to a bag of words representation for each spring line\",\"Let's create a simple word cloud for the Simpsons script lines.\",\"Visualize the most spoken words by Homer Simpson\",\"Let's visualize the Word Clouds of the script lines of the Simpsons.\"],\"marker\":{\"opacity\":0.5,\"size\":5},\"mode\":\"markers+text\",\"name\":\"41_Creating word clouds to visualize the most common words in The Simpsons script lines\",\"text\":[\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\"],\"textfont\":{\"size\":12},\"x\":[11.976263046264648,11.74006175994873,11.401910781860352,11.75656509399414,13.857025146484375,12.097304344177246,11.86818790435791,11.736124038696289,12.074068069458008,11.785432815551758,11.502893447875977,11.71960735321045,11.814306259155273,11.361498832702637,11.646943092346191,10.411840438842773,12.784497261047363,11.44338607788086,11.325026512145996,11.503033638000488,11.841824531555176,11.482954978942871,10.016590118408203,11.486820220947266,11.328177452087402,11.661595344543457,11.630561828613281,11.002745628356934,11.813436508178711,11.418243408203125,11.65188217163086,11.202274322509766,11.783683776855469,11.334502220153809,11.724919319152832,11.053911209106445,11.712742805480957,11.438692092895508,11.552094459533691,11.020508766174316,11.863682746887207,11.61345100402832,11.581400871276855,11.622941970825195,11.743551254272461,11.907538414001465],\"y\":[7.23372220993042,7.747687339782715,6.768264293670654,6.999483585357666,7.5996198654174805,6.849567890167236,5.929366588592529,7.276258945465088,7.234426021575928,7.474515438079834,7.954387664794922,7.1294121742248535,7.03163480758667,6.181721210479736,6.857815742492676,6.731083869934082,6.775777816772461,6.975235462188721,7.7289934158325195,7.024982929229736,7.513401508331299,6.985223293304443,7.588737487792969,6.368051528930664,7.415952682495117,7.3017168045043945,7.73687219619751,7.845580101013184,6.688503742218018,6.718774318695068,7.443428993225098,6.6835432052612305,6.606510162353516,7.170963287353516,7.506092548370361,6.351377964019775,7.281590461730957,6.894266128540039,7.0233025550842285,7.602350234985352,6.952375411987305,7.185507774353027,6.784576892852783,7.57476806640625,6.778755187988281,7.623038291931152],\"type\":\"scattergl\"},{\"hoverinfo\":\"text\",\"hovertext\":[\"Check the shape of dfs\\nprint(df_characters.shape, df_locations.shape, df_script.shape,  df_episodes.shape)\",\"Check shape of the DataFrames\\nprint(df_characters.shape)\\nprint(df_locations.shape)\\nprint(df_script.shape)\\nprint(df_episodes.shape)\",\"Check dataframe shapes\\nprint('Characters shape:', df_characters.shape)\\nprint('Locations shape:', df_locations.shape)\\nprint('Script shape:', df_script.shape)\\nprint('Episodes shape:', df_episodes.shape)\",\"Check the shape of the dataframes\\nprint(df_characters.shape)\\nprint(df_locations.shape)\\nprint(df_script.shape)\\nprint(df_episodes.shape)\",\" Check shape of dataframes\\nprint(f\\\"Characters: {df_characters.shape} | Locations: {df_locations.shape} | Script: {df_script.shape} | Episodes: {df_episodes.shape}\\\")\",\" Look at the shape of the dataframes\\nprint(df_characters.shape)\\nprint(df_locations.shape)\\nprint(df_script.shape)\\nprint(df_episodes.shape)\",\"Checking the shapes of the data\\nprint(f'Shapes Characters: {df_characters.shape}, Locations: {df_locations.shape}, '\\n      f'Script: {df_script.shape}, Episodes: {df_episodes.shape}')\",\"Check the dataframe shapes\\nprint(\\\"Characters dataframe shape:\\\", df_characters.shape)\\nprint(\\\"Locations dataframe shape:\\\", df_locations.shape)\\nprint(\\\"Script dataframe shape:\\\", df_script.shape)\\nprint(\\\"Episodes dataframe shape:\\\", df_episodes.shape)\",\"check shapes\\nprint(f\\\"df_characters: {df_characters.shape}\\\")\\nprint(f\\\"df_locations: {df_locations.shape}\\\")\\nprint(f\\\"df_script: {df_script.shape}\\\")\\nprint(f\\\"df_episodes: {df_episodes.shape}\\\")\",\"Check the shape of each dataframe\\nprint(df_characters.shape)\\nprint(df_locations.shape)\\nprint(df_script.shape)\\nprint(df_episodes.shape)\",\"Data validation and some general statistics\\nprint('Episodes Dataframe shape: ', df_episodes.shape)\\nprint('Script Dataframe shape: ', df_script.shape)\",\"check the shape of all the datasets\\nprint('The shape of the character dataset is: {}'.format(df_characters.shape))\\nprint('The shape of the location dataset is: {}'.format(df_locations.shape))\\nprint('The shape of the script dataset is: {}'.format(df_script.shape))\\nprint('The shape of the episodes dataset is: {}'.format(df_episodes.shape))\",\"Check the shape of all datasets\\nprint(f'Shape of df_characters: {df_characters.shape}')\\nprint(f'Shape of df_locations: {df_locations.shape}')\\nprint(f'Shape of df_script: {df_script.shape}')\\nprint(f'Shape of df_episodes: {df_episodes.shape}')\",\"Check the dataset shapes\\nprint(df_characters.shape)\\nprint(df_locations.shape)\\nprint(df_script.shape)\\nprint(df_episodes.shape)\",\"Check that the shape of each dataframe is correct\\nprint(f'Shape of characters dataframe: {df_characters.shape}')\\nprint(f'Shape of locations dataframe: {df_locations.shape}')\\nprint(f'Shape of script dataframe: {df_script.shape}')\\nprint(f'Shape of episodes dataframe: {df_episodes.shape}')\",\"Checking DataFrame shapes\\nprint(f\\\"Characters: {df_characters.shape}\\\")\\nprint(f\\\"Locations: {df_locations.shape}\\\")\\nprint(f\\\"Script: {df_script.shape}\\\")\\nprint(f\\\"Episodes: {df_episodes.shape}\\\")\",\"Check a few attributes of our datasets\\nprint(df_characters.shape)\\nprint(df_locations.shape)\\nprint(df_script.shape)\\nprint(df_episodes.shape)\",\" Check the shape of the datasets\\nprint(\\\"Characters dataset shape: {}\\\".format(df_characters.shape))\\nprint(\\\"Locations dataset shape: {}\\\".format(df_locations.shape))\\nprint(\\\"Script dataset shape: {}\\\".format(df_script.shape))\\nprint(\\\"Episodes dataset shape: {}\\\".format(df_episodes.shape))\",\"Check dataframe shapes\\nprint('Characters:', df_characters.shape)\\nprint('Locations:', df_locations.shape)\\nprint('Script:', df_script.shape)\\nprint('Episodes:', df_episodes.shape)\",\"View the dataset shapes\\ndf_characters.shape, df_locations.shape, df_script.shape, df_episodes.shape\",\"Check the dataset shapes\\nprint(df_characters.shape)\\nprint(df_locations.shape)\\nprint(df_script.shape)\\nprint(df_episodes.shape)\",\" Check data\\nprint(\\\"Characters shape\\\", df_characters.shape)\\nprint(\\\"Locations shape\\\", df_locations.shape)\\nprint(\\\"Scripts shape\\\", df_script.shape)\\nprint(\\\"Episodes shape\\\", df_episodes.shape)\",\"Check the shapes of the datasets\\nprint(df_characters.shape)\\nprint(df_locations.shape)\\nprint(df_script.shape)\\nprint(df_episodes.shape)\",\"Check the shape of each DataFrame\\nprint(\\\"Characters shape:\\\", df_characters.shape)\\nprint(\\\"Locations shape:\\\", df_locations.shape)\\nprint(\\\"Script shape:\\\", df_script.shape)\\nprint(\\\"Episodes shape:\\\", df_episodes.shape)\",\"Print shapes of the dataframes to check if everything went okay\\nprint(f\\\"Characters: {df_characters.shape}\\\")\\nprint(f\\\"Locations:  {df_locations.shape}\\\")\\nprint(f\\\"Script:     {df_script.shape}\\\")\\nprint(f\\\"Episodes:   {df_episodes.shape}\\\")\",\"Check dataframe shape\\nprint(df_characters.shape)\\nprint(df_locations.shape)\\nprint(df_script.shape)\\nprint(df_episodes.shape)\",\"Inspecting the dataframe shapes\\nprint(df_characters.shape)\\nprint(df_locations.shape)\\nprint(df_script.shape)\\nprint(df_episodes.shape)\",\"Checking the shape of each DataFrame\\nprint(f'Shapes: characters = {df_characters.shape}, locations = {df_locations.shape}, script = {df_script.shape}, episodes = {df_episodes.shape}')\",\"Check the shape of the dataframes\\nprint('Characters:', df_characters.shape)\\nprint('Locations:', df_locations.shape)\\nprint('Script:', df_script.shape)\\nprint('Episodes:', df_episodes.shape)\",\" Check data shapes\\nprint(df_characters.shape)\\nprint(df_locations.shape)\\nprint(df_script.shape)\\nprint(df_episodes.shape)\",\"To validate the shapes of each dataframe\\nprint(df_characters.shape)\\nprint(df_locations.shape)\\nprint(df_script.shape)\\nprint(df_episodes.shape)\",\"Check data shape\\nprint('Characters:', df_characters.shape)\\nprint('Locations:', df_locations.shape)\\nprint('Episodes:', df_episodes.shape)\\nprint('Script:', df_script.shape)\",\" Check dataframe shapes\\nprint(\\\"Characters dataframe shape:\\\", df_characters.shape)\\nprint(\\\"Locations dataframe shape:\\\", df_locations.shape)\\nprint(\\\"Script dataframe shape:\\\", df_script.shape)\\nprint(\\\"Episodes dataframe shape:\\\", df_episodes.shape)\",\"Check the shapes of the imported DataFrames\\nprint(\\\"Shape of characters DataFrame: \\\", df_characters.shape)\\nprint(\\\"Shape of locations DataFrame: \\\", df_locations.shape)\\nprint(\\\"Shape of script DataFrame: \\\", df_script.shape)\\nprint(\\\"Shape of episodes DataFrame: \\\", df_episodes.shape)\",\"Checking the data shapes\\nprint('Characters:', df_characters.shape)\\nprint('Locations:', df_locations.shape)\\nprint('Script:', df_script.shape)\\nprint('Episodes:', df_episodes.shape)\",\"Check the shape of the dataframes\\nprint(df_characters.shape)\\nprint(df_locations.shape)\\nprint(df_script.shape)\\nprint(df_episodes.shape)\",\" Check the shapes of the imported DataFrames\\nprint(f'df_characters shape: {df_characters.shape}')\\nprint(f'df_locations shape: {df_locations.shape}')\\nprint(f'df_script shape: {df_script.shape}')\\nprint(f'df_epsiodes shape: {df_episodes.shape}')\",\"Check the shape of each DataFrame\\nprint('Characters:', df_characters.shape)\\nprint('Locations:', df_locations.shape)\\nprint('Script:', df_script.shape)\\nprint('Episodes:', df_episodes.shape)\",\"Check the shape of each dataframe\\nprint(\\\"Characters df shape:\\\", df_characters.shape)\\nprint(\\\"Locations df shape:\\\", df_locations.shape)\\nprint(\\\"Script df shape:\\\", df_script.shape)\\nprint(\\\"Episodes df shape:\\\", df_episodes.shape)\",\"Check our datasets\\nprint(\\\"Characters dataset shape\\\", df_characters.shape)\\nprint(df_characters.head())\\n\\nprint(\\\"\\\\nLocations dataset shape\\\", df_locations.shape)\\nprint(df_locations.head())\\n\\nprint(\\\"\\\\nScript dataset shape\\\", df_script.shape)\\nprint(df_script.head())\\n\\nprint(\\\"\\\\nEpisodes dataset shape\\\", df_episodes.shape)\\nprint(df_episodes.head())\",\"Let's check the shape of each DataFrame\\nprint(\\\"Characters DataFrame:\\\", df_characters.shape)\\nprint(\\\"Locations DataFrame:\\\", df_locations.shape)\\nprint(\\\"Script DataFrame:\\\", df_script.shape)\\nprint(\\\"Episodes DataFrame:\\\", df_episodes.shape)\",\"Check the number of characters and locations\\nprint(\\\"Number of characters:\\\", df_characters.shape[0])\\nprint(\\\"Number of locations:\\\", df_locations.shape[0])\",\"Check data shapes\\nprint(\\\"Characters shape:\\\", df_characters.shape)\\nprint(\\\"Locations shape:\\\", df_locations.shape)\\nprint(\\\"Script shape:\\\", df_script.shape)\\nprint(\\\"Episodes shape:\\\", df_episodes.shape)\",\"Check the number of rows and columns for each dataframe\\nprint(f\\\"Simpsons Characters: {df_characters.shape}\\\")\\nprint(f\\\"Simpsons Locations: {df_locations.shape}\\\")\\nprint(f\\\"Simpsons Script Lines: {df_script.shape}\\\")\\nprint(f\\\"Simpsons Episodes: {df_episodes.shape}\\\")\",\"Check the dataframes shape\\nprint(\\\"Characters dataframe shape:\\\", df_characters.shape)\\nprint(\\\"Locations dataframe shape:\\\", df_locations.shape)\\nprint(\\\"Script dataframe shape:\\\", df_script.shape)\\nprint(\\\"Episodes dataframe shape:\\\", df_episodes.shape)\",\"Verify shape of the datasets\\nprint(df_characters.shape)\\nprint(df_locations.shape)\\nprint(df_script.shape)\\nprint(df_episodes.shape)\"],\"marker\":{\"opacity\":0.5,\"size\":5},\"mode\":\"markers+text\",\"name\":\"42_DataFrame Shapes\",\"text\":[\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\"],\"textfont\":{\"size\":12},\"x\":[0.14087066054344177,0.03138910233974457,0.3799252510070801,-0.0022580858785659075,0.2981293797492981,-0.0873238742351532,0.08986799418926239,-0.007876421324908733,0.3063027560710907,0.3500370979309082,0.13668803870677948,-0.5403879284858704,-0.38768550753593445,-0.1647387444972992,-0.3277492821216583,0.3677707612514496,-0.35564732551574707,-0.3789258897304535,0.06338298320770264,-0.45178166031837463,-0.10984295606613159,0.39936092495918274,-0.035836733877658844,0.31371092796325684,0.09910832345485687,-0.033424053341150284,-0.5114248991012573,0.21822912991046906,-0.2160150408744812,0.618529736995697,0.4716050326824188,-0.15711535513401031,0.5245791077613831,-0.30103546380996704,-0.20922109484672546,0.28909996151924133,0.23106442391872406,0.43113216757774353,0.3009915053844452,-0.15324531495571136,-0.37679368257522583,1.1338388919830322,0.22441211342811584,-0.041712891310453415,-0.019985049962997437,-0.28863656520843506],\"y\":[-0.614938497543335,-1.3384109735488892,-1.5048354864120483,-0.8064197897911072,-2.088562488555908,-0.8884950280189514,-2.5400006771087646,-1.4188193082809448,-2.5367534160614014,-1.1049503087997437,-1.1356384754180908,-2.0517568588256836,-2.3175673484802246,-1.1152063608169556,-2.1409778594970703,-2.3496432304382324,-0.7808475494384766,-1.5712790489196777,-1.3325098752975464,-0.8451853394508362,-1.2428401708602905,-1.2963786125183105,-1.33859121799469,-1.1606782674789429,-2.4351706504821777,-1.3559532165527344,-1.3461620807647705,-1.7554152011871338,-0.49146273732185364,-1.5296149253845215,-1.5585474967956543,-1.4059373140335083,-1.4821134805679321,-1.2862279415130615,-1.4658966064453125,-1.394873023033142,-1.6319270133972168,-0.8845163583755493,-0.666283905506134,-0.3513675928115845,-1.1981277465820312,-0.8948990106582642,-1.2693580389022827,-1.4560986757278442,-1.2261461019515991,-1.2357816696166992],\"type\":\"scattergl\"},{\"hoverinfo\":\"text\",\"hovertext\":[\"General config\\npd.set_option('display.max_colwidth', None)\",\"Display configuration\\npd.options.display.max_columns = 999\\npd.options.display.max_colwidth = 100\",\"def print_full(x):\\n    pd.set_option('display.max_rows', len(x))\\n    pd.set_option('display.max_columns', None)\\n    pd.set_option('display.width', 2000)\\n    pd.set_option('display.float_format', '{:20,.2f}'.format)\\n    pd.set_option('display.max_colwidth', None)\\n    print(x)\\n    pd.reset_option('display.max_rows')\\n    pd.reset_option('display.max_columns')\\n    pd.reset_option('display.width')\\n    pd.reset_option('display.float_format')\\n    pd.reset_option('display.max_colwidth')\",\" Set series limits to view more data\\npd.set_option('display.max_rows', 300)\\npd.set_option('display.max_colwidth', 300)\",\"Set display.max_colwidth to None to display large columns in full\\npd.set_option('display.max_colwidth', None)\",\"Expand the width of columns in order to view text data more completely\\npd.options.display.max_colwidth = 400\",\" Display setup\\npd.set_option('display.max_columns', None)\\npd.set_option('display.max_colwidth', 60)\",\"Read Data\\n# Set configurations\\npd.set_option('display.max_colwidth', 100)\\npd.set_option('display.max_columns', None)\",\"# Display options\\npd.set_option('display.max_rows', None)\\npd.set_option('display.max_columns', None)\\npd.set_option('display.width', None)\\npd.set_option('display.max_colwidth', None)\",\"Display max word in each column of the datasets\\npd.options.display.max_colwidth = None\",\"Setting display options for the notebooks\\npd.set_option('display.max_colwidth', None)\",\"Set text column width to see whole text\\npd.set_option('display.max_colwidth', None)\",\"Set max column width to see more of the conversation\\npd.set_option('max_colwidth', 150)\",\"Truncate script titles because of their length for printed result clarity\\npd.set_option('display.max_colwidth', 50)\",\" Some nice-to-have package settings\\npd.set_option('display.max_colwidth', None)\",\"Display options\\npd.set_option('display.max_columns', 500)\\npd.set_option('display.width', 1000)\",\"settings\\npd.set_option('display.max_rows', 500)\\npd.set_option('display.max_columns', 500)\\npd.set_option('display.width', 1000)\",\"Setting for the length of the lines displayed\\npd.options.display.max_colwidth = 200\",\"Set max display columns and width\\npd.set_option('display.max_columns', 30)\\npd.set_option('display.width', 180)\",\"Display settings\\npd.set_option('display.max_columns', 500)\\npd.set_option('display.max_colwidth', None)\",\"pd.set_option('display.max_columns', 500)\\npd.set_option('display.max_colwidth', -1)\",\"Display setting\\npd.set_option('display.max_rows', 1000)\\npd.set_option('display.max_columns', 1000)\\npd.set_option('display.width', 1000)\",\" Set the number of words after which a \\\"...\\\" should show in print\\npd.set_option('display.max_colwidth', 20)\",\" Tweak the display parameters to always show at least a part of every column's content\\npd.set_option('max_colwidth', 300)\",\"Display limitations\\npd.set_option('display.max_columns', 100)\\npd.set_option('display.max_rows', 50)\\npd.set_option('display.min_rows', 150)\\npd.set_option('display.max_colwidth', 200)\",\"Set maximum column width to display more content\\npd.set_option('display.max_colwidth', 500)\",\" Display maximum columns and expanded width\\npd.set_option('display.max_columns', None)\\npd.set_option('display.width', None)\",\"Display settings\\npd.set_option('display.max_columns', None)\\npd.set_option('display.max_rows', None)\\npd.set_option('max_colwidth', None)\",\"Set max display rows and increase display width\\npd.set_option('display.max_rows', 500)\\npd.set_option('display.max_colwidth', 400)\",\"Display width to show most of the conversation\\nNone;pd.set_option('display.max_colwidth', None)\",\"Display settings for tables\\npd.set_option('display.max_columns', None)\\npd.set_option('display.expand_frame_repr', False)\\npd.set_option('max_colwidth', -1)\",\"Set max_columns and max_colwidth\\npd.set_option('display.max_columns', None)\\npd.set_option('max_colwidth', None)\",\"Setting custom parameters for better visualization of head\\u002ftail\\npd.set_option('display.max_columns', 500)\\npd.set_option('display.width', 1000)\",\"# Set the max width of the columns for better visibility\\npd.options.display.max_colwidth = 100\",\"Make the rows display up to 200 characters\\npd.set_option('display.max_colwidth', 200)\",\"General configuration\\nLARGE_SIZE = 22\\nMEDIUM_SIZE = 18\\nSMALL_SIZE = 14\",\" Settings for pretty print\\nnp.set_printoptions(suppress=True)\\npd.set_option('display.max_columns', None)\\npd.set_option('display.expand_frame_repr', False)\",\"Visual representation and render output \\npd.set_option('display.max_columns', None)\\npd.set_option('display.expand_frame_repr', False)\\npd.set_option('max_colwidth', -1)\",\"Visualization and styling parameters\\ncolors = {\\n    'background': '#111111',\\n    'text': '#7FDBFF',\\n    'data': '#FF851B',\\n    'title': '#FF4136'\\n}\\n\\n# Display settings\\npd.set_option('display.max_colwidth', 120)\",\"Display settings\\npd.set_option('display.max_columns', None)  # Unlimited max columns\\npd.set_option('display.max_colwidth', None)  # Unlimited max column width\",\"# Display options\\npd.set_option('max_colwidth', 100)\",\"Optional set display width and max columns for tables\\npd.set_option('display.max_columns', 100)\\npd.set_option('max_colwidth', 100)\",\" Set the maximum column width to avoid output or data representation issues\",\" Expand the max column width to display the entire script line\\npd.set_option('display.max_colwidth', None)\",\"# Ensure that displayed column limit is sufficiently large\\npd.set_option('display.max_colwidth', 200)\",\" Display options\\npd.set_option('display.width', 1000)\\npd.set_option('display.max_columns', 25)\"],\"marker\":{\"opacity\":0.5,\"size\":5},\"mode\":\"markers+text\",\"name\":\"43_Column Width Settings in pandas\",\"text\":[\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\"],\"textfont\":{\"size\":12},\"x\":[24.923343658447266,24.926837921142578,24.06861686706543,24.24928855895996,24.472463607788086,24.071012496948242,24.578510284423828,24.972856521606445,24.448816299438477,23.71773338317871,24.627906799316406,23.969308853149414,24.419851303100586,23.73470687866211,24.90412139892578,24.22237777709961,24.23670196533203,24.868806838989258,24.60073471069336,24.931495666503906,24.313966751098633,24.166419982910156,24.258520126342773,24.032772064208984,23.76055335998535,24.155521392822266,24.3533935546875,24.75244903564453,24.392780303955078,24.75349998474121,24.357872009277344,24.552326202392578,24.03055763244629,25.017045974731445,24.47770118713379,20.081592559814453,23.689170837402344,23.870222091674805,23.695363998413086,24.719379425048828,24.502086639404297,24.727258682250977,23.94036293029785,23.79828643798828,24.621334075927734,24.299293518066406],\"y\":[2.4152982234954834,1.5366154909133911,1.6139999628067017,0.8370072841644287,2.436636447906494,2.7226338386535645,2.013266086578369,2.2118372917175293,1.6090258359909058,2.6403896808624268,2.2860207557678223,2.550234794616699,2.2580976486206055,2.3382890224456787,2.1024043560028076,1.5140812397003174,1.3127686977386475,2.0461337566375732,1.6697092056274414,2.0331873893737793,2.0355687141418457,1.3215785026550293,2.551344633102417,2.40334415435791,1.2500817775726318,1.9830536842346191,1.4329054355621338,1.7352091073989868,1.4307024478912354,2.042008399963379,1.4965152740478516,2.17541241645813,1.0208457708358765,2.361696481704712,1.4366763830184937,7.328390121459961,1.0036156177520752,1.660243272781372,2.5670902729034424,1.900577425956726,2.333009958267212,1.7939562797546387,2.15594744682312,1.7428427934646606,1.9717693328857422,1.4885399341583252],\"type\":\"scattergl\"},{\"hoverinfo\":\"text\",\"hovertext\":[\"Setting up the model and analyzing the script data\",\"As the next step, we will now preprocess the script data before performing any analysis.\",\"We'll also need some basic NLP tools, such as tokenization and lemmatization, for analyzing the script lines.\",\"I will start by examining the script data.\",\"Let's first have a look at the scripts data.\",\"Create a small sample of the script for performances\",\"\\n# Scraping script information\\n#\",\"Let's have a look at the script data:\",\"Check script head\",\" For this analysis, we'll focus on the script dataset.\",\"The first part of the notebook examines the scripts to build a simple chatbot.\",\"Check for broken scripts\",\"Let's take a peek at the script data!\",\"We will start by analyzing the script data.\",\"We will start by analyzing the script data.\",\"Let's start by taking an example script line and it's metadata to demonstrate the quality of our dataset.\",\"Let's take a look at the script data.\",\"For this tutorial, we focus on the script data only.\",\"Exploring the script data\",\"Check the script dataset\",\"Let's take a look at the first few script lines.\",\" Let's first start by focusing on the script data.\",\"The first step is to preprocess the data, starting with the script lines.\",\"Visualizing the script data\",\"We'll start by performing some data exploration on the script data to get a feel for the data.\",\" we'll subset the data: only consider the complete script lines, and remove any stage directions.\",\"Check the script data\",\"Discover the script dataset:\",\" Check the data; specifically, the script data.\",\" Let's start by loading the script data and taking a look at the first few rows.\",\"In this section, we will explore the data in the script dataset.\",\" First we tokenize the script into words.\",\"Let's take a look at the format and content of the script data.\",\" The script would continue by exploring and analyzing the datasets, but the provided code is enough to load the necessary data and proceed with the analysis.\",\"Initializing model and processing scripts...\",\"This script will focus on analyzing the script data.\",\" Look at the first 5 script lines to get an overview.\",\"Em primeira instancia vamos fazer uma analise nos caracteres, depois analisaremos os locais e finalmente os scripts, por isto vou\\n# separar cada uma em sua propria variavel para cada uma das analises.\",\" Check if script has bee properly loaded\",\"Let's take a quick look at the scripts data.\",\"Inspect content of scripts and extract relevant metadata\",\"We\\u2019ll start by analyzing the script data. Let\\u2019s take a look at the first few rows.\",\"Inspect the content of the script dataset.\",\" Check the contents of script data.\",\"Check the content of the script dataset.\"],\"marker\":{\"opacity\":0.5,\"size\":5},\"mode\":\"markers+text\",\"name\":\"44_Script Data Analysis\",\"text\":[\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\"],\"textfont\":{\"size\":12},\"x\":[11.713957786560059,11.037578582763672,11.747978210449219,10.873004913330078,10.942771911621094,10.90621280670166,12.106085777282715,11.275537490844727,11.60612964630127,11.59518814086914,11.218128204345703,11.97763729095459,10.936929702758789,11.470226287841797,11.46262264251709,11.663690567016602,11.248075485229492,11.343193054199219,11.251490592956543,11.523151397705078,11.25745964050293,10.808794975280762,11.323410987854004,10.686594009399414,10.985153198242188,10.331514358520508,12.069548606872559,11.435314178466797,11.868456840515137,10.733024597167969,11.54741382598877,12.208420753479004,10.91492748260498,11.261086463928223,12.627660751342773,11.532792091369629,11.437690734863281,11.702821731567383,13.115314483642578,11.359150886535645,11.045951843261719,10.917412757873535,11.566876411437988,12.028555870056152,11.393641471862793],\"y\":[3.1087024211883545,2.983736038208008,3.9738144874572754,3.091719388961792,3.159721851348877,3.661670207977295,3.3673951625823975,2.8001155853271484,2.6348209381103516,3.7085354328155518,3.663518190383911,2.5886361598968506,3.0506906509399414,2.9626290798187256,3.153958797454834,2.655566453933716,2.822068452835083,3.014195442199707,3.2658417224884033,1.929004192352295,3.593392848968506,3.288912296295166,3.0530858039855957,3.903860330581665,3.1942527294158936,2.9198572635650635,2.6163463592529297,2.169711112976074,2.6601150035858154,2.9578697681427,2.8524410724639893,4.4929399490356445,3.2305760383605957,2.722928524017334,3.2024195194244385,3.00057053565979,3.5009653568267822,3.1372406482696533,2.0519750118255615,3.0612094402313232,3.4621613025665283,3.1297669410705566,2.215458631515503,2.4068970680236816,2.524143934249878],\"type\":\"scattergl\"},{\"hoverinfo\":\"text\",\"hovertext\":[\"Get the \\\"Characters\\\" and \\\"Locations\\\" columns from the \\\"Script\\\" DataFrame in order to study only those lines that are related to characters and locations.\",\"quick look at the dataframes\\nprint(\\\"Characters: \\\\n\\\", df_characters.head())\\nprint(\\\"\\\\nLocations: \\\\n\\\", df_locations.head())\\nprint(\\\"\\\\nScript: \\\\n\\\", df_script.head())\\nprint(\\\"\\\\nEpisodes: \\\\n\\\", df_episodes.head())\",\" Show the general overview of the data\\nprint(\\\"Character dataframe:\\\")\\nprint(df_characters.head(3))\\nprint(\\\"\\\\nLocations dataframe:\\\")\\nprint(df_locations.head(3))\\nprint(\\\"\\\\nScript lines dataframe:\\\")\\nprint(df_script.head(3))\\nprint(\\\"\\\\nEpisodes dataframe:\\\")\\nprint(df_episodes.head(3))\",\" Display an overview of the dataframes\\nprint(\\\"Characters: \\\")\\ndisplay(df_characters.head())\\n\\nprint(\\\"\\\\nLocations: \\\")\\ndisplay(df_locations.head())\\n\\nprint(\\\"\\\\nScript: \\\")\\ndisplay(df_script.head())\\n\\nprint(\\\"\\\\nEpisodes: \\\")\\ndisplay(df_episodes.head())\",\"# Example data\\nprint('Characters:')\\nprint(df_characters.head(10))\\nprint('\\\\nLocations:')\\nprint(df_locations.head(10))\\nprint('\\\\nScript:')\\nprint(df_script.head(10))\\nprint('\\\\nEpisodes:')\\nprint(df_episodes.head(10))\",\" Show the head of each DataFrame\\nprint('Characters:')\\nprint(df_characters.head())\\n\\nprint('\\\\nLocations:')\\nprint(df_locations.head())\\n\\nprint('\\\\nScript:')\\nprint(df_script.head())\\n\\nprint('\\\\nEpisodes:')\\nprint(df_episodes.head())\",\"Quick overview of the data\\nprint(\\\"Characters\\\")\\nprint(df_characters.head())\\nprint(\\\"\\\\nLocations\\\")\\nprint(df_locations.head())\\nprint(\\\"\\\\nScript Lines\\\")\\nprint(df_script.head())\\nprint(\\\"\\\\nEpisodes\\\")\\nprint(df_episodes.head())\",\"Quick overview of the data\\nprint(\\\"Characters data:\\\")\\nprint(df_characters.head())\\nprint(\\\"\\\\nLocations data:\\\")\\nprint(df_locations.head())\\nprint(\\\"\\\\nScript data:\\\")\\nprint(df_script.head())\\nprint(\\\"\\\\nEpisodes data:\\\")\\nprint(df_episodes.head())\",\"Print the characters dataframe\\nprint('Characters dataframe')\\nprint(df_characters.head())\\n\\n# Print the locations dataframe\\nprint('\\\\nLocations dataframe')\\nprint(df_locations.head())\\n\\n# Print the script dataframe\\nprint('\\\\nScript dataframe')\\nprint(df_script.head())\\n\\n# Print the episodes dataframe\\nprint('\\\\nEpisodes dataframe')\\nprint(df_episodes.head())\",\"Checking the first few lines of the DataFrames for sanity check.\\nprint('Characters:')\\nprint(df_characters.head(), end='\\\\n\\\\n')\\n\\nprint('Locations:')\\nprint(df_locations.head(), end='\\\\n\\\\n')\\n\\nprint('Script lines:')\\nprint(df_script.head(), end='\\\\n\\\\n')\",\"## Take a look at the data\\nprint('Characters')\\nprint(df_characters.head())\\nprint('\\\\nLocations')\\nprint(df_locations.head())\\nprint('\\\\nScript')\\nprint(df_script.head())\\nprint('\\\\nEpisodes')\\nprint(df_episodes.head())\",\"Print some lines of the script\\nfor i in range(5):\\n    print(f'{df_script.iloc[i].character_id} ({df_characters[df_characters.id == df_script.iloc[i].character_id].name.values[0]]}): {df_script.iloc[i].raw_text}')\",\" Let's take a look at the first few rows of each dataframe to understand the data better.\\nprint(\\\"Characters:\\\")\\nprint(df_characters.head())\\n\\nprint(\\\"\\\\nLocations:\\\")\\nprint(df_locations.head())\\n\\nprint(\\\"\\\\nScript:\\\")\\nprint(df_script.head())\\n\\nprint(\\\"\\\\nEpisodes:\\\")\\nprint(df_episodes.head())\",\"Display\\nprint(\\\"Characters\\\")\\nprint(df_characters.head())\\nprint(\\\"\\\\nLocations\\\")\\nprint(df_locations.head())\\nprint(\\\"\\\\nScript\\\")\\nprint(df_script.head())\\nprint(\\\"\\\\nEpisodes\\\")\\nprint(df_episodes.head())\",\" Sample the data in order to understand its structure and contents\\nprint(\\\"Sample from the characters dataframe:\\\")\\nprint(df_characters.sample(5))\\nprint(\\\"\\\\n\\\")\\nprint(\\\"Sample from the locations dataframe:\\\")\\nprint(df_locations.sample(5))\\nprint(\\\"\\\\n\\\")\",\"inspect data\\nprint(\\\"Characters data frame\\\")\\nprint(df_characters.head())\\nprint(\\\"\\\\nScript data frame\\\")\\nprint(df_script.head())\",\" Check the dataframes\\nprint('Characters:')\\nprint(df_characters.head())\\n\\nprint('\\\\nLocations:')\\nprint(df_locations.head())\\n\\nprint('\\\\nScript:')\\nprint(df_script.head())\\n\\nprint('\\\\nEpisodes:')\\nprint(df_episodes.head())\",\"Set of characters to consider when analyzing the script\\ncharacters_set = set(df_characters[df_characters[\\\"is_main_cast\\\"] == True].index)\\n\\n# Set of locations to consider when analyzing the script\\nlocations_set = set(df_locations[df_locations[\\\"normalized\\\"] == True].index)\",\" View a sample of each dataframe\\nprint('\\\\nDataframe of Characters:')\\nprint(df_characters.sample(5))\\nprint('\\\\nDataframe of Locations:')\\nprint(df_locations.sample(5))\\nprint('\\\\nDataframe of Script Lines:')\\nprint(df_script.sample(5))\\nprint('\\\\nDataframe of Episodes:')\\nprint(df_episodes.sample(5))\",\" Basic information on the datasets\\nprint('Characters:')\\nprint(df_characters.head(2).T)\\nprint('\\\\nLocations:')\\nprint(df_locations.head(2).T)\\nprint('\\\\nScript lines:')\\nprint(df_script.head(2).T)\",\"Objectives\\n# Extract script lines where at least 2 of the characters are in the same location\\n# Perform NER for each line by using Spacy\\n# Calculate the entity frequency for the dataframe\\n# Calculate the named entity frequency for each location that is shared between the characters\\n# Analyze the results and visualize them\",\"Preview the data\\nprint(\\\"Characters data\\\")\\nprint(df_characters.head(2))\\nprint(\\\"\\\\nLocations data\\\")\\nprint(df_locations.head(2))\\nprint(\\\"\\\\nScript data\\\")\\nprint(df_script.head(2))\\nprint(\\\"\\\\nEpisodes data\\\")\\nprint(df_episodes.head(2))\",\"Inspect the dataframes for the first time\\nprint('Characters dataframe')\\nprint(df_characters.head(5))\\nprint('\\\\n\\\\nLocations dataframe')\\nprint(df_locations.head(5))\\nprint('\\\\n\\\\nScript dataframe')\\nprint(df_script.head(5))\\nprint('\\\\n\\\\nEpisodes dataframe')\\nprint(df_episodes.head(5))\",\"Test the import of the data\\nprint(\\\"Characters:\\\")\\nprint(df_characters.head(5))\\nprint(\\\"\\\\nLocations:\\\")\\nprint(df_locations.head(5))\\nprint(\\\"\\\\nScript:\\\")\\nprint(df_script.head(5))\\nprint(\\\"\\\\nEpisodes:\\\")\\nprint(df_episodes.head(5))\",\"# Explore each dataframe\\nprint(\\\"Characters dataframe:\\\")\\nprint(df_characters.head())\\nprint(\\\"\\\\nLocations dataframe:\\\")\\nprint(df_locations.head())\\nprint(\\\"\\\\nScript dataframe:\\\")\\nprint(df_script.head())\\nprint(\\\"\\\\nEpisodes dataframe:\\\")\\nprint(df_episodes.head())\",\" Display basic information for the dataframes\\nprint('Characters dataframe:')\\nprint(df_characters.head())\\nprint('\\\\nLocations dataframe:')\\nprint(df_locations.head())\\nprint('\\\\nScript dataframe:')\\nprint(df_script.head())\\nprint('\\\\nEpisodes dataframe:')\\nprint(df_episodes.head())\",\"# Investigate the data\\nprint(\\\"Characters:\\\")\\nprint(df_characters.head())\\nprint(\\\"\\\\nLocations:\\\")\\nprint(df_locations.head())\\nprint(\\\"\\\\nScript:\\\")\\nprint(df_script.head())\\nprint(\\\"\\\\nEpisodes:\\\")\\nprint(df_episodes.head())\",\"Checking the content of each data set\\nprint(\\\"Characters: \\\")\\nprint(df_characters.info())\\nprint(df_characters.head(10))\\n\\nprint(\\\"\\\\nLocations: \\\")\\nprint(df_locations.info())\\nprint(df_locations.head(10))\\n\\nprint(\\\"\\\\nScript (lines): \\\")\\nprint(df_script.info())\\nprint(df_script.head(10))\\n\\nprint(\\\"\\\\nEpisodes: \\\")\\nprint(df_episodes.info())\\nprint(df_episodes.head(10))\",\"Inspecting the first 5 rows of all datasets to understand their structure\\nprint(\\\"Characters Data:\\\")\\nprint(df_characters.head())\\nprint(\\\"\\\\nLocations Data:\\\")\\nprint(df_locations.head())\\nprint(\\\"\\\\nScript Data:\\\")\\nprint(df_script.head())\\nprint(\\\"\\\\nEpisodes Data:\\\")\\nprint(df_episodes.head())\",\"Print headers and .head() of dataframes\\nprint(\\\"\\\\nCharacters:\\\")\\nprint(df_characters.head())\\nprint(\\\"\\\\nLocations:\\\")\\nprint(df_locations.head())\\nprint(\\\"\\\\nScript:\\\")\\nprint(df_script.head())\\nprint(\\\"\\\\nEpisodes:\\\")\\nprint(df_episodes.head())\",\"Inspect the data\\nprint('Characters:')\\nprint(df_characters.head())\\nprint('\\\\nLocations:')\\nprint(df_locations.head())\\nprint('\\\\nScript:')\\nprint(df_script.head())\\nprint('\\\\nEpisodes:')\\nprint(df_episodes.head())\",\" Check the content and the type of each of the DataFrames\\nprint(\\\"Characters DataFrame\\\")\\nprint(df_characters.head())\\nprint(\\\"\\\\nLocations DataFrame\\\")\\nprint(df_locations.head())\\nprint(\\\"\\\\nScript DataFrame\\\")\\nprint(df_script.head())\\nprint(\\\"\\\\nEpisodes DataFrame\\\")\\nprint(df_episodes.head())\",\"Visual exploration of the data\\n# Display random samples of each dataframe\\nprint('Characters dataframe :')\\nprint(df_characters.sample(5))\\nprint('\\\\nLocations dataframe :')\\nprint(df_locations.sample(5))\\nprint('\\\\nScript dataframe :')\\nprint(df_script.sample(5))\\nprint('\\\\nEpisodes dataframe :')\\nprint(df_episodes.sample(5))\",\"# Print basic information about the data\\nprint(\\\"Characters:\\\")\\nprint(df_characters.info())\\nprint(df_characters.head(2))\\nprint(\\\"\\\\nScript:\\\")\\nprint(df_script.info())\\nprint(df_script.head(2))\",\"Take a look at the content of each dataframe\\nprint(\\\"Characters dataframe:\\\")\\nprint(df_characters.head())\\nprint(\\\"\\\\nLocations dataframe:\\\")\\nprint(df_locations.head())\\nprint(\\\"\\\\nScript dataframe:\\\")\\nprint(df_script.head())\\nprint(\\\"\\\\nEpisodes dataframe:\\\")\\nprint(df_episodes.head())\",\"Quick overview of the data\\nprint(\\\"Characters\\\")\\nprint(df_characters.head())\\nprint(\\\"\\\\nLocations\\\")\\nprint(df_locations.head())\\nprint(\\\"\\\\nScript\\\")\\nprint(df_script.head())\\nprint(\\\"\\\\nEpisodes\\\")\\nprint(df_episodes.head())\",\" Ensure data is loaded correctly\\nprint(\\\"Characters:\\\")\\nprint(df_characters.head())\\n\\nprint(\\\"\\\\nLocations:\\\")\\nprint(df_locations.head())\\n\\nprint(\\\"\\\\nScript:\\\")\\nprint(df_script.head())\\n\\nprint(\\\"\\\\nEpisodes:\\\")\\nprint(df_episodes.head())\",\" We start by printing out the begining of each dataframe to see what we are working with\\nprint('Characters head')\\nprint(df_characters.head())\\nprint('\\\\nLocations head')\\nprint(df_locations.head())\\nprint('\\\\nScript head')\\nprint(df_script.head())\\nprint('\\\\nEpisodes head')\\nprint(df_episodes.head())\",\"Display of a few samples of datas\\nprint('Dataset examples')\\nprint('\\\\nCharacters')\\nprint(df_characters.sample(5))\\nprint('\\\\nLocations')\\nprint(df_locations.sample(5))\\nprint('\\\\nScript')\\nprint(df_script.sample(5))\\nprint('\\\\nEpisodes')\\nprint(df_episodes.sample(5))\",\" Generate a sample of each data frame to understand its structure\\nprint(\\\"Characters dataset\\\")\\ndisplay(df_characters.sample(5))\\n\\nprint(\\\"\\\\nLocations dataset\\\")\\ndisplay(df_locations.sample(5))\\n\\nprint(\\\"\\\\nScript dataset\\\")\\ndisplay(df_script.sample(5))\\n\\nprint(\\\"\\\\nEpisodes dataset\\\")\\ndisplay(df_episodes.sample(5))\",\"Explore the content of these 4 dataframes\\nprint(\\\"Characters:\\\\n\\\", df_characters.head())\\nprint(\\\"\\\\n\\\\nLocations:\\\\n\\\", df_locations.head())\\nprint(\\\"\\\\n\\\\nScript:\\\\n\\\", df_script.head())\\nprint(\\\"\\\\n\\\\nEpisodes:\\\\n\\\", df_episodes.head())\",\" Show head of each DataFrame\\nprint(\\\"Characters DataFrame:\\\")\\nprint(df_characters.head())\\nprint(\\\"\\\\nLocations DataFrame:\\\")\\nprint(df_locations.head())\\nprint(\\\"\\\\nScript DataFrame:\\\")\\nprint(df_script.head())\\nprint(\\\"\\\\nEpisodes DataFrame:\\\")\\nprint(df_episodes.head())\",\"Check the content of all DataFrames\\nprint(\\\"Characters:\\\")\\nprint(df_characters.head())\\nprint(\\\"\\\\n\\\\nLocations:\\\")\\nprint(df_locations.head())\\nprint(\\\"\\\\n\\\\nScript:\\\")\\nprint(df_script.head())\\nprint(\\\"\\\\n\\\\nEpisodes:\\\")\\nprint(df_episodes.head())\",\"Inspect the structure of each dataframe\\nprint('\\\\nCharacters:')\\nprint(df_characters.head(2))\\nprint('\\\\nLocations:')\\nprint(df_locations.head(2))\\nprint('\\\\nScript:')\\nprint(df_script.head(2))\\nprint('\\\\nEpisodes:')\\nprint(df_episodes.head(2))\",\" Checking the structure of the dataframes\\nprint(\\\"Characters dataframe:\\\")\\nprint(df_characters.info())\\n\\nprint(\\\"\\\\nLocations dataframe:\\\")\\nprint(df_locations.info())\\n\\nprint(\\\"\\\\nScript dataframe:\\\")\\nprint(df_script.info())\\n\\nprint(\\\"\\\\nEpisodes dataframe:\\\")\\nprint(df_episodes.info())\"],\"marker\":{\"opacity\":0.5,\"size\":5},\"mode\":\"markers+text\",\"name\":\"45_Extracting Characters and Locations from a Script Dataframe\",\"text\":[\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\"],\"textfont\":{\"size\":12},\"x\":[6.734158992767334,-0.5955865383148193,-0.34837406873703003,-1.1181511878967285,-0.15267015993595123,-0.8622201085090637,-0.06237491965293884,-0.1494331657886505,-0.5271391868591309,-0.2507055699825287,-0.6414780616760254,0.19846144318580627,-0.9824293255805969,-0.47055748105049133,-0.28531545400619507,0.04655469208955765,-0.3303622603416443,4.428625106811523,-1.133981704711914,0.200717955827713,7.343880653381348,-0.647225558757782,-0.7062373161315918,-0.18966782093048096,-0.41544026136398315,-0.10984889417886734,-0.44521036744117737,-0.4077076315879822,-0.42767849564552307,-1.0961703062057495,-0.42322245240211487,-0.3543979227542877,-0.9492111206054688,-0.052982211112976074,-0.5445439219474792,-0.15644097328186035,-0.6155821084976196,-1.4563654661178589,-0.4029126763343811,-0.6775854825973511,-0.7666526436805725,-0.7518038153648376,-0.6645631790161133,-0.3112437427043915,-0.23560303449630737],\"y\":[4.177752494812012,3.8773295879364014,4.179254531860352,3.8144121170043945,4.11764669418335,4.013886451721191,3.8255515098571777,3.512235164642334,4.592635631561279,3.322221517562866,3.9953787326812744,3.8019516468048096,4.40467643737793,4.11672306060791,4.013062477111816,4.247209548950195,4.320544719696045,8.330310821533203,4.14383602142334,3.453152894973755,3.7287864685058594,3.5857350826263428,4.327008247375488,3.651857614517212,4.671679973602295,4.2063751220703125,3.907723903656006,3.224119186401367,3.1565372943878174,4.117824554443359,3.9148924350738525,4.163427829742432,4.471096992492676,3.9379961490631104,4.736337184906006,3.946600914001465,3.051238775253296,3.2667458057403564,3.453467845916748,3.4217190742492676,3.818239450454712,3.9658963680267334,3.4044010639190674,4.5606465339660645,4.528338432312012],\"type\":\"scattergl\"},{\"hoverinfo\":\"text\",\"hovertext\":[\"Create a spacy model for the English language and set a variable to files directory\",\"Because we're going to be doing some text processing notebooks, we will load in the natural language processing model from `spaCy`.\",\"Setup data for spacy processing\",\" We will use `spacy` library for text pre-processing, which is large and may take a little while to download.\",\"We need to load the spaCy model that we will use for natural language processing.\",\"Creating the model.\",\"Load the required models from spacy module\",\" Get this NLP party started!\",\"Setting up Spacy\",\"Set up a personal spacy model.\",\"Set up the spaCy model and the function to properly clean sentences.\",\"Set the configuration for the Spacy language model.\",\"Create an instance of the English spacy model\",\"Load the custom Spacy pipeline if available, if not initialize and save it for later.\",\"The below code snippet shows how we load the preprocessed models from the cache directory.\",\"Set PATH to use the spaCy linguistic models.\",\"Create an instance of the English class of the spacy load.\",\"Research on NLP and SpaCy, stemming and lemmatization libraries\",\"Creating a NLP model with spacy\",\"Initiate the spaCy model for natural language processing.\",\"Initialize a spaCy nlp pipeline for part of speech tagging, entity recognition and word vectors.\",\"Create a Spacy NLP object\",\"Define spacy model and stop words\",\" Initializes a spaCy pipeline with the English model\",\"Initialize a spaCy model for natural language processing.\",\"Download the large English model for spaCy\",\"Setting spacy configuration with English model\",\" Import necessary spacy models and libraries\",\"to run the language model.\",\" Process basic Natural Language tasks using Spacy\",\"Setting up a spacy pipeline with the English model.\",\"Declare and intialize a new spacy model\",\"Create Doc class from spacy annotations\",\"Setting up Spacy models\",\"Define the location of the pretrained model and load it\",\"Instantiate the nlp object of Spacy\",\"Text data will be manipulated with spaCy and some langague model (medium or large one) is needed to preceed.\",\" Load Wikipedia and GLoVe with Spacy's medium model\",\"Create a spacy model for pre-processing episodes\",\"Downloading the spacy model for English\",\"Creating a spacy model and disabling the component we don't need\",\"Spacy's nlp pipeline, thanks to this pipeline we can have access to the entities recognized.\",\" We will instantiate a `nlp` spacy model and then suppress and serach the tokens.\",\"Create an instance of the English class in spaCy.\",\"Load spacy model.\"],\"marker\":{\"opacity\":0.5,\"size\":5},\"mode\":\"markers+text\",\"name\":\"46_spaCy model initialization and loading for natural language processing\",\"text\":[\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\"],\"textfont\":{\"size\":12},\"x\":[15.045308113098145,14.898653030395508,15.148223876953125,14.702064514160156,14.778682708740234,14.373710632324219,15.735002517700195,14.323984146118164,15.669864654541016,14.934501647949219,14.139091491699219,15.471179008483887,14.746536254882812,14.736063003540039,15.018552780151367,14.633416175842285,15.326717376708984,14.688769340515137,14.549510955810547,14.548715591430664,13.994731903076172,14.556648254394531,14.348505020141602,14.864407539367676,14.475577354431152,15.439414978027344,15.202442169189453,15.458382606506348,14.830754280090332,14.483535766601562,14.912699699401855,15.014997482299805,14.857605934143066,15.538288116455078,15.024648666381836,14.49424934387207,14.527445793151855,15.198837280273438,14.890663146972656,15.695369720458984,15.029340744018555,14.447453498840332,14.202256202697754,14.939602851867676,15.504903793334961],\"y\":[5.989444732666016,6.2233805656433105,5.910624980926514,6.416168212890625,6.2821245193481445,4.294261455535889,5.99837589263916,5.4703874588012695,6.204326152801514,5.5261945724487305,5.850589752197266,6.71142578125,6.1375813484191895,6.702315807342529,5.136094093322754,6.265988826751709,6.756425380706787,6.468684673309326,6.113979816436768,5.865081310272217,6.053840160369873,6.472782135009766,6.196554660797119,6.122420787811279,6.324374675750732,6.121170520782471,6.453452110290527,5.6372199058532715,5.399272441864014,5.778430461883545,5.962226390838623,5.802724838256836,6.798213481903076,5.521500587463379,5.311738014221191,6.513366222381592,6.847531318664551,6.291131496429443,5.758270263671875,6.134984970092773,5.651664733886719,6.68509578704834,6.063405990600586,6.92961311340332,6.221106052398682],\"type\":\"scattergl\"},{\"hoverinfo\":\"text\",\"hovertext\":[\"Display the dataframes\\nprint(df_characters.head(10))\\nprint(df_locations.head(10))\\nprint(df_script.head(10))\\nprint(df_episodes.head(10))\",\" Check the contents of the files\\nprint(df_characters.head())\\nprint(df_locations.head())\\nprint(df_script.head())\\nprint(df_episodes.head())\",\"check what the dataframes look like\\nprint(df_characters.head())\\nprint(df_locations.head())\\nprint(df_script.head())\\nprint(df_episodes.head())\",\"Check the structure of the dataframes\\nprint(df_characters.head())\\nprint(df_locations.head())\\nprint(df_script.head())\\nprint(df_episodes.head())\",\"Print the header of each loaded dataset\\nprint('### Characters ###')\\nprint(df_characters.head(), end='\\\\n\\\\n')\\nprint('### Locations ###')\\nprint(df_locations.head(), end='\\\\n\\\\n')\\nprint('### script lines ###')\\nprint(df_script.head(), end='\\\\n\\\\n')\\nprint('### Episodes ###')\\nprint(df_episodes.head(), end='\\\\n\\\\n')\",\"# Show head of data\\nprint(df_characters.head())\\nprint(df_locations.head())\\nprint(df_script.head())\\nprint(df_episodes.head())\",\" Sample the data\\nprint(df_characters.head())\\nprint(df_locations.head())\\nprint(df_script.head())\\nprint(df_episodes.head())\",\"Check data\\nprint(df_characters.head())\\nprint(df_locations.head())\\nprint(df_script.head())\\nprint(df_episodes.head())\",\"Inspect dataframes\\nprint(df_characters.head(5))\\nprint(df_locations.head(5))\\nprint(df_script.head(5))\\nprint(df_episodes.head(5))\",\"Check data\\nprint(\\\"Characters\\\")\\nprint(df_characters.head(5))\\nprint(\\\"Locations\\\")\\nprint(df_locations.head(5))\\nprint(\\\"Script\\\")\\nprint(df_script.head(5))\\nprint(\\\"Episodes\\\")\\nprint(df_episodes.head(5))\",\"\\n# Let's start by taking a look at the dataframes\\nprint(df_characters.head())\\nprint(df_locations.head())\\nprint(df_script.head())\\nprint(df_episodes.head())\",\" Check the loaded data\\nprint(\\\"\\\\n\\\\n============ Checking Characters data head ============\\\\n\\\\n\\\")\\nprint(df_characters.head(5))\\n\\nprint(\\\"\\\\n\\\\n============ Checking Locations data head ============\\\\n\\\\n\\\")\\nprint(df_locations.head(5))\\n\\nprint(\\\"\\\\n\\\\n============ Checking Script data head ============\\\\n\\\\n\\\")\\nprint(df_script.head(5))\\n\\nprint(\\\"\\\\n\\\\n============ Checking Episodes data head ============\\\\n\\\\n\\\")\\nprint(df_episodes.head(5))\",\"Check the data\\nprint(df_characters.head())\\nprint(df_locations.head())\\nprint(df_script.head())\\nprint(df_episodes.head())\",\"Get a sense for the data and the columns involved\\nprint(df_characters.head(5))\\nprint(df_locations.head(5))\\nprint(df_script.head(5))\\nprint(df_episodes.head(5))\",\"display the head of the dataframes\\nprint(df_characters.head())\\nprint(df_locations.head())\\nprint(df_script.head())\\nprint(df_episodes.head())\",\"Quick look at the data\\nprint(df_characters.head())\\nprint(df_locations.head())\\nprint(df_script.head())\\nprint(df_episodes.head())\",\"Check the dataframes\\nprint(\\\"Characters dataframe\\\")\\nprint(df_characters.head())\\nprint()\\nprint(\\\"Locations dataframe\\\")\\nprint(df_locations.head())\\nprint()\\nprint(\\\"Episodes dataframe\\\")\\nprint(df_episodes.head())\\nprint()\\nprint(\\\"Script dataframe\\\")\\nprint(df_script.head())\",\"Check the data in each DataFrame\\nprint(\\\"Characters\\\")\\ndisplay(df_characters.head(4))\\n\\nprint(\\\"Locations\\\")\\ndisplay(df_locations.head(4))\\n\\nprint(\\\"Script\\\")\\ndisplay(df_script.head(4))\\n\\nprint(\\\"Episodes\\\")\\ndisplay(df_episodes.head(4))\",\"Explore the data\\nprint('Characters\\\\n', df_characters.head(), '\\\\n')\\nprint('Locations\\\\n', df_locations.head(), '\\\\n')\\nprint('Script\\\\n', df_script.head(), '\\\\n')\\nprint('Episodes\\\\n', df_episodes.head())\",\"Check out the data\\nprint(df_characters.head())\\nprint(df_locations.head())\\nprint(df_script.head())\\nprint(df_episodes.head())\",\" Display (head) of those dataframes\\nprint(df_characters.head())\\nprint(df_locations.head())\\nprint(df_script.head())\\nprint(df_episodes.head())\",\"Check data structures\\nprint(df_characters.head())\\nprint(df_locations.head())\\nprint(df_script.head())\\nprint(df_episodes.head())\",\"Optional print dataframes for a quick overview\\nprint(df_characters.head())\\nprint(df_locations.head())\\nprint(df_script.head())\\nprint(df_episodes.head())\",\"Quick look at the data\\nprint(df_characters.head())\\nprint(df_locations.head())\\nprint(df_script.head())\\nprint(df_episodes.head())\",\"# First look at the data\\nprint('First look at the data')\\nprint(df_episodes.head(), '\\\\n\\\\n', df_episodes.info())\\nprint(df_characters.head(), '\\\\n\\\\n', df_characters.info())\\nprint(df_locations.head(), '\\\\n\\\\n', df_locations.info())\\nprint(df_script.head(), '\\\\n\\\\n', df_script.info())\",\"Checking the data and its shape\\nprint(df_characters.head(5))\\nprint(df_locations.head(5))\\nprint(df_script.head(5))\\nprint(df_episodes.head(5))\",\"Look into the first few records\\nprint(\\\"Characters\\\")\\nprint(df_characters.head(5))\\n\\nprint(\\\"Locations\\\")\\nprint(df_locations.head(5))\\n\\nprint(\\\"Script\\\")\\nprint(df_script.head(5))\\n\\nprint(\\\"Episodes\\\")\\nprint(df_episodes.head(5))\",\"Inspect data\\nprint(df_characters.head())\\nprint(df_locations.head())\\nprint(df_script.head())\\nprint(df_episodes.head())\",\" Headers of each dataframe\\nprint(\\\"\\\\n### Characters\\\\n\\\", df_characters.columns.tolist())\\nprint(\\\"\\\\n### Locations\\\\n\\\", df_locations.columns.tolist())\\nprint(\\\"\\\\n### Script lines\\\\n\\\", df_script.columns.tolist())\\nprint(\\\"\\\\n### Episodes\\\\n\\\", df_episodes.columns.tolist())\",\"Check all the datasets\\nprint(\\\"df_characters\\\\n\\\")\\ndisplay(df_characters.head(5))\\nprint(\\\"\\\\n\\\\n\\\")\\n\\nprint(\\\"df_locations\\\\n\\\")\\ndisplay(df_locations.head(5))\\nprint(\\\"\\\\n\\\\n\\\")\\n\\nprint(\\\"df_script\\\\n\\\")\\ndisplay(df_script.head(5))\\nprint(\\\"\\\\n\\\\n\\\")\\n\\nprint(\\\"df_episodes\\\\n\\\")\\ndisplay(df_episodes.head(5))\",\"Check dataframes\\nprint(df_characters.head())\\nprint(df_locations.head())\\nprint(df_script.head())\\nprint(df_episodes.head())\",\"Inspecting the data\\nprint(df_characters.head())\\nprint(df_locations.head())\\nprint(df_script.head())\\nprint(df_episodes.head())\",\"data exploration\\nprint(df_characters.head())\\nprint(df_locations.head())\\nprint(df_script.head())\\nprint(df_episodes.head())\",\" Display how the dataframe looks\\nprint(df_characters.head())\\nprint(df_locations.head())\\nprint(df_episodes.head())\\nprint(df_script.head())\",\" Print all the datasets\\nprint('Character Data: ', df_characters.head())\\nprint('Location Data: ', df_locations.head())\\nprint('Script Data: ', df_script.head())\\nprint('Episode Data: ', df_episodes.head())\",\"Print head of each dataframe\\nprint(df_characters.head())\\nprint(df_locations.head())\\nprint(df_script.head())\\nprint(df_episodes.head())\",\"Check the dataframes\\nprint(df_characters.head())\\nprint(df_locations.head())\\nprint(df_script.head())\\nprint(df_episodes.head())\",\"# Check data content\\nprint(df_characters.head())\\nprint(df_locations.head())\\nprint(df_script.head())\\nprint(df_episodes.head())\",\"Check what we have in each DataFrame\\nprint(df_characters.head(5))\\nprint(df_locations.head(5))\\nprint(df_script.head(5))\\nprint(df_episodes.head(5))\",\"View data structure\\nprint(df_characters.head())\\nprint(df_locations.head())\\nprint(df_script.head())\\nprint(df_episodes.head())\",\"Print out head of each dataframe\\nprint(df_characters.head())\\nprint(df_locations.head())\\nprint(df_script.head())\\nprint(df_episodes.head())\",\"Print sample data\\nprint(df_characters.head(2))\\nprint(df_locations.head(2))\\nprint(df_script.head(2))\\nprint(df_episodes.head(2))\",\" Sample the script, characters, and locations DataFrames\\ndf_characters.head(), df_locations.head(), df_script.head()\",\"display basic statistics\\nprint(df_characters.head())\\nprint(df_locations.head())\\nprint(df_script.head())\\nprint(df_episodes.head())\",\"data overview\\nprint(\\\"\\\\n======== Characters =======\\\")\\nprint(df_characters.head(3))\\n\\nprint(\\\"\\\\n======== Locations =======\\\")\\nprint(df_locations.head(3))\\n\\nprint(\\\"\\\\n======== Script =======\\\")\\nprint(df_script.head(3))\\n\\nprint(\\\"\\\\n======== Episodes =======\\\")\\nprint(df_episodes.head(3))\"],\"marker\":{\"opacity\":0.5,\"size\":5},\"mode\":\"markers+text\",\"name\":\"47_Quick look at the data\",\"text\":[\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\"],\"textfont\":{\"size\":12},\"x\":[-2.366691827774048,-1.6098476648330688,-1.5045956373214722,-1.9223926067352295,-1.0984892845153809,-1.8408454656600952,-1.4467439651489258,-2.0707221031188965,-1.9748588800430298,-1.2003018856048584,-2.3882627487182617,-0.998438835144043,-1.887805700302124,-1.1762880086898804,-2.3705825805664062,-1.708219051361084,-1.2031948566436768,-1.5560967922210693,-0.8762037754058838,-1.3366219997406006,-2.2428908348083496,-1.7621341943740845,-1.945219874382019,-1.4213203191757202,-0.8308795094490051,-1.5641111135482788,-1.2621756792068481,-1.7649095058441162,-1.1590911149978638,-1.1035844087600708,-1.6417779922485352,-1.5209084749221802,-1.9516514539718628,-2.1168766021728516,-0.7804171442985535,-2.407559633255005,-1.7748007774353027,-1.787912130355835,-1.829937219619751,-1.524970293045044,-2.5659847259521484,-1.7135794162750244,-2.1250104904174805,-1.1798479557037354,-1.2873289585113525],\"y\":[2.9161336421966553,1.6721718311309814,1.3766778707504272,1.5664628744125366,2.2469451427459717,2.623532772064209,2.3044681549072266,1.5959581136703491,2.0547831058502197,2.0558278560638428,2.433938503265381,2.9424068927764893,1.6394518613815308,1.9865576028823853,2.70038104057312,2.276628255844116,1.4563658237457275,2.3089354038238525,2.870995283126831,2.2605679035186768,2.8605637550354004,1.3846055269241333,2.1389191150665283,2.3428661823272705,2.644294023513794,1.6915806531906128,2.7210116386413574,2.0863912105560303,2.509061098098755,2.795534610748291,1.4414196014404297,2.164456367492676,1.9615635871887207,2.61102032661438,2.47467041015625,2.914159059524536,1.4421628713607788,1.8678010702133179,1.7455099821090698,2.5057826042175293,3.018690347671509,2.1712682247161865,2.524636745452881,2.1491804122924805,2.54038143157959],\"type\":\"scattergl\"},{\"hoverinfo\":\"text\",\"hovertext\":[\"Display 5 rows of the dataframe to check if the data is loaded successfully.\",\"Let's display the first 5 rows of each dataframe to understand what kind of data we are working with.\",\"Display the first 5 rows of each dataframe to understand their structure and the data they contain.\",\"Print the first 5 rows of each dataframe to understand the data\",\" Extract the first five items of each dataframe\",\" Display the first 5 rows of each dataframe to get a quick look at the data\",\"Let's use the head() method to display the first 5 rows of each DataFrame and understand how the data is structured.\",\" Display the first 5 rows of each dataframe to get an idea of the data\",\"Note: in the following dataframe printouts, instead of providing the full row, only the first \\n# five items are printed.\",\"Display the first 5 rows of each dataframe to have an idea on the structure of the data.\",\"Display the first 5 rows of each dataframe to ensure everything loaded correctly.\",\"Display first 5 records of all the dataframes\",\"Print the first 5 rows of each dataframe to understand the data structure better\",\"Let's explore the data by showing the first 5 rows of each dataframe.\",\"Display the first 5 lines of each dataframe to understand the data better\",\" Display the first 5 rows of each dataframe to get a quick overview of the data\",\"Display the first 5 rows of each dataframe to understand the structure of the data.\",\"Let's take a glimpse of the first 5 rows of this dataframe-\",\"Display first 5 rows of each dataframe to understand the data\",\"Inspect dataframes first 5 rows\",\"Display the first 5 lines of each dataframe to understand its structure and the information available.\",\"Inspect each dataframe and display its first five rows\",\"Display the first 5 rows of each DataFrame to understand the data.\",\"Show the first 5 rows of each dataframe to get a sense of the data\",\"Get the first 5 rows of each DataFrame for a quick look at the data\",\" We start by displaying the 5 first lines of each dataframe.\",\"Explore the first 5 rows of each dataframe\",\"Display first 5 rows of each dataframe\",\"Show the first five rows of each dataframe to understand the data\",\" Display the first 5 rows of each dataframe\",\"Display the first 5 rows of each dataframe to understand the data\",\"Preview the first 5 rows of each dataframe\",\"Display the first 5 rows of each dataframe to understand the data\",\" Show the first 5 records for each DataFrame\",\" Display the first 5 rows of each dataframe to display the structure of the data.\",\"Display the first 5 rows of each dataframe to better understand the data\",\"Let's print the first 5 rows from each dataframe to better understand their structure.\",\"Let's display the first 5 rows of each dataframe to understand better the data structure.\",\"Show the first 5 rows of each dataframe to understand the data structure\",\"View the data.head() to check the first 5 rows of data\\tload_data()\",\"Display the first 5 rows of each dataframe\",\"Print the first 5 rows of each dataframe to understand the data\",\" Display the first 5 rows of each dataframe to get an overview of the data\",\"This will display the first 5 rows of each dataframe with their names.\",\"Show the first 5 records of each dataframe to understand the structure and content of the data.\"],\"marker\":{\"opacity\":0.5,\"size\":5},\"mode\":\"markers+text\",\"name\":\"48_Understanding Dataframe Structure\",\"text\":[\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\"],\"textfont\":{\"size\":12},\"x\":[13.179299354553223,13.350214958190918,13.719225883483887,13.920003890991211,13.40373706817627,14.262664794921875,13.655537605285645,14.128201484680176,13.666952133178711,13.93579387664795,13.75117015838623,14.105454444885254,13.923965454101562,12.93804931640625,13.648554801940918,14.629342079162598,13.790867805480957,13.654960632324219,14.188516616821289,13.555237770080566,13.32573413848877,14.18914794921875,13.918785095214844,14.616922378540039,13.969229698181152,13.041240692138672,13.805103302001953,14.221355438232422,14.050981521606445,14.281643867492676,14.159528732299805,14.68114948272705,14.276443481445312,14.122371673583984,14.186493873596191,14.320096015930176,13.610574722290039,13.573481559753418,13.570779800415039,13.179231643676758,14.051558494567871,13.97207260131836,14.287784576416016,14.261663436889648,14.06562328338623],\"y\":[-6.813449382781982,-7.141805171966553,-7.245490550994873,-5.912996292114258,-6.537238597869873,-6.404334545135498,-7.1167168617248535,-6.3679423332214355,-5.855767726898193,-7.336101055145264,-7.075196743011475,-6.299884796142578,-6.330864906311035,-6.94727897644043,-7.077182769775391,-6.387020587921143,-7.244197368621826,-6.256067276000977,-6.366934776306152,-6.088922500610352,-7.783407688140869,-6.643470764160156,-6.6653547286987305,-6.312687873840332,-6.217311859130859,-7.55448579788208,-6.4729461669921875,-6.699467658996582,-6.759786605834961,-6.479487895965576,-6.494353294372559,-6.558698654174805,-6.450819969177246,-6.115588188171387,-7.444342136383057,-6.781304836273193,-6.613032341003418,-7.389528274536133,-7.08021354675293,-6.488542079925537,-6.4809956550598145,-5.86885404586792,-6.630331039428711,-6.9411821365356445,-7.097327709197998],\"type\":\"scattergl\"},{\"hoverinfo\":\"text\",\"hovertext\":[\"select the necessary columns from the dataframes\",\"Remove unwanted columns from the dataframe\",\"Filtering out \\\"bad\\\" records on on df_script\",\"Remove unnecessary columns from dataframe\",\"Remove invalid rows from df_script\",\"Remove unnecessary columns from the dataframe\",\"Drop unwanted columns from the dataframes\",\" Remove unused columns from the dataframes\",\"Remove unnecessary columns from df_script\",\"Remove items which weren't referenced in another dataframe\",\"To get rid of some columns that we don't need in some dataframes\",\"filtering out bad data from each dataframe\",\"Remove unwanted columns and simplify the characters dataframe\",\"Remove useless columns in some dataframes\",\"Remove useless columns from each dataframe\",\"Smaller dataframes with the essential columns only\",\"Remove unnecessary columns from the dataframes\",\"Remove unwanted columns from each dataframe\",\"Remove unnecessary columns from the characters dataframe\",\"Remove unnecessary columns from dataframes\",\"Remove the 'Unnamed: 0' column from all dataframes since it is not needed\",\"Remove duplicate columns from the dataframes\",\"Filtering out of the dataframe to only retain the useful columns\",\"Remove the unamed column from dataframes\",\"Remove unnecessary columns and NA values from df_script\",\"Removing unnecessary unnamed columns if any from the dataframes.\",\"Remove unnecessary columns in some dataframes\",\"Remove unwanted columns from the characters, locations and script DataFrames\",\"Fixing name of the columns with right index numbers in dataframe and discarding unwanted columns\",\"Filter and remove rows with information unvailable in any df\",\"Remove all unnecessary columns from the dataframe\",\"Filtering raw dataframe\",\"Remove unnecessary columns and join the dataframes\",\"Remove columns that we don't need from the dataframes\",\"Don't truncate text fields in the DataFrame display\",\"Remove unwanted columns from the dataframes\",\" Remove unwanted column from the dataframes\",\"Remove redundant columns from the dataframe\",\"Filters irrelevant columns from the characters dataframe\",\"Select only the necessary columns for this MVP (Minimum Viable Product) in the df_script dataframe.\",\"Do some cleanup on the original DataFrames and drop unnecesary columns\",\"Remove unwanted columns from the dataframes\",\"Remove rows with missing values from the following DataFrames:\",\"Removing data that doesn't fit our use case from the dataframe\"],\"marker\":{\"opacity\":0.5,\"size\":5},\"mode\":\"markers+text\",\"name\":\"49_Remove unnecessary columns from dataframes\",\"text\":[\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\"],\"textfont\":{\"size\":12},\"x\":[7.761807441711426,7.806645393371582,8.182208061218262,7.619580268859863,7.290384292602539,7.583189487457275,8.300676345825195,8.20497989654541,7.362990856170654,7.709957599639893,8.03711986541748,9.142326354980469,7.249267101287842,8.157466888427734,7.996958255767822,8.044218063354492,7.776873588562012,8.1091890335083,7.120450019836426,7.708583354949951,7.684241771697998,7.411504745483398,8.257111549377441,7.654820442199707,7.114143371582031,7.434487342834473,7.954927444458008,7.039430141448975,7.854111194610596,8.182069778442383,7.609581470489502,8.670400619506836,7.348477840423584,7.995174407958984,21.29368782043457,7.752932548522949,7.6815690994262695,7.490294456481934,6.865366458892822,7.365446090698242,8.289543151855469,8.022821426391602,8.082329750061035,7.831474304199219],\"y\":[0.8537012934684753,2.102628469467163,2.3619210720062256,1.5489884614944458,2.7569241523742676,1.5330678224563599,1.6444915533065796,1.3914583921432495,0.7894105315208435,1.7988777160644531,1.96201753616333,1.9998722076416016,2.5528173446655273,1.6495692729949951,1.2813087701797485,1.031281590461731,1.6804975271224976,1.9505939483642578,3.036843776702881,1.4672907590866089,2.7788822650909424,2.3695545196533203,1.5767855644226074,2.103708267211914,2.153841018676758,1.7984273433685303,1.5849277973175049,2.8164055347442627,1.5517969131469727,2.3380215167999268,1.3978091478347778,1.8883202075958252,1.3077973127365112,1.7297900915145874,2.4288549423217773,1.9655574560165405,2.0643436908721924,2.1440913677215576,4.038015842437744,2.268247365951538,1.0059505701065063,2.061445713043213,0.9587026238441467,1.6604262590408325],\"type\":\"scattergl\"},{\"hoverinfo\":\"text\",\"hovertext\":[\" View the dataframes' head\\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()\",\"Inspect df_script and df_episodes DataFrames\\ndf_script.head()\",\"View dataframes head\\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()\",\"Show all dataframes\\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()\",\"A quick preview of the dataframes\\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()\",\"Display the loaded pandas dataframes\\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()\",\"Inspect data\\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()\",\"View the data\\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()\",\"View data in the different csv files\\nprint(df_characters.head())\\nprint(df_locations.head())\\nprint(df_script.head())\\nprint(df_episodes.head())\",\" Show header of all dataframes\\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()\",\"Display all dataframes - Checking Data\\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()\",\"view_dataframes(df_characters, df_locations, df_script, df_episodes)\",\"Display the dataframes\\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()\",\"Show the available dataframes\\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()\",\" Display a sample of the data for each dataframe\\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()\",\"View the dataframes\\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()\",\"Display data\\ndf_characters.head()\\ndf_locations.head()\\ndf_script.head()\\ndf_episodes.head()\",\" Display the data\\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()\",\"Display the dataframes\\ndf_script.head(), df_characters.head(), df_locations.head(), df_episodes.head()\",\"Displaying the content of the new dataframes\\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()\",\"displaying all dataframes for exploration\\ndf_characters.head(), \\ndf_locations.head(), \\ndf_script.head(), \\ndf_episodes.head()\",\"view each dataframe\\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()\",\"# Data preload\\ncharacters = df_characters.to_dict(orient='records')\\nlocations = df_locations.to_dict(orient='records')\\nepisodes = df_episodes.to_dict(orient='records')\\n\\n# Show episodes' data\\ndf_episodes.head()\",\"Display the loaded data\\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()\",\"Display the data frames\\ndf_characters, df_locations, df_script, df_episodes\",\" Show head of dataframes\\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()\",\" Display the contents of the four DataFrames with the .head() method\\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()\",\"View data tables\\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()\",\"Inspecting Data\\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()\",\"Inspect dataframes\\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()\",\"Uncomment and run the following lines to display part of the content in each dataframe\\n# df_episodes.head(3)\\n# df_locations.head(3)\\n# df_characters.head(3)\\n# df_script.head(3)\",\"View some data from the locations DataFrame\\ndf_locations.head()\",\"Display the head of the dataframes\\ndf_episodes.head(), df_characters.head(), df_locations.head(), df_script.head()\",\"Display head of the dataframes\\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()\",\"Displaying the data.\\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()\",\"Display the data\\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()\",\" Display the data\\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()\",\" Take a quick look at the first few lines of each data frame\\ndisplay(df_characters.head(5))\\ndisplay(df_locations.head(5))\\ndisplay(df_script.head(5))\\ndisplay(df_episodes.head(5))\",\" Display the different dataframes\\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()\",\"Inspect dataframes\\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()\",\"Display data from all datasets\\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()\",\"Show the head of each loaded dataframe\\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()\",\"Explore data\\n(df_characters[:5], df_locations[:5], df_script[:5], df_episodes[:5])\",\" view dataframes\\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()\"],\"marker\":{\"opacity\":0.5,\"size\":5},\"mode\":\"markers+text\",\"name\":\"50_Viewing Dataframes\",\"text\":[\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\"],\"textfont\":{\"size\":12},\"x\":[-3.568922758102417,-2.5718157291412354,-3.2361984252929688,-3.3908028602600098,-3.749009847640991,-3.0756521224975586,-3.1894891262054443,-3.30222749710083,-2.9607105255126953,-2.9113762378692627,-3.675985336303711,-2.827846050262451,-2.7505886554718018,-3.0431673526763916,-2.3590056896209717,-3.317934989929199,-3.1164655685424805,-2.7139103412628174,-2.8584256172180176,-2.9593677520751953,-3.365762948989868,-3.5580458641052246,-3.361156702041626,-3.337397575378418,-1.9667760133743286,-3.503018379211426,-2.864806652069092,-3.041179656982422,-3.3810575008392334,-3.2981925010681152,-3.301616668701172,-2.6647543907165527,-3.323949098587036,-3.0189945697784424,-2.958655834197998,-3.1680688858032227,-3.060945987701416,-2.981626272201538,-3.164226531982422,-3.4169154167175293,-2.945474624633789,-3.4348175525665283,-2.9201974868774414,-3.2509045600891113],\"y\":[2.1044061183929443,1.698046326637268,2.334959030151367,2.32855486869812,2.237921714782715,2.4496731758117676,1.8378651142120361,2.1963579654693604,2.1961255073547363,2.188776731491089,1.9865880012512207,2.3202924728393555,2.158670663833618,1.6708816289901733,2.914247751235962,1.764360785484314,2.328326463699341,2.1427159309387207,2.4575843811035156,2.646869659423828,2.455348014831543,2.1565780639648438,2.838961124420166,2.622147798538208,2.5547420978546143,2.3788578510284424,2.2179946899414062,2.5863516330718994,1.7422071695327759,2.1236870288848877,2.9221763610839844,2.0341126918792725,2.323164939880371,2.486987352371216,2.1625125408172607,2.264735698699951,2.1197733879089355,2.7617692947387695,2.2961204051971436,2.07275390625,2.8376760482788086,2.5475656986236572,2.700578212738037,2.5701420307159424],\"type\":\"scattergl\"},{\"hoverinfo\":\"text\",\"hovertext\":[\"Get division lines from each script line.\",\"Create a subset of the script data that contains only the fields of interest\",\"preprocessing the script data\",\"Remove punctuation from the script lines and lowercase the text.\",\"Check if script lines contain uppercase words\",\" Extracting the text of the script lines for further analysis\",\"Display the list of available script lines.\",\"Clean up some of the script line columns to strings.\",\"Build corpus for script lines\",\" How many lines of script do we have?\",\"Check the first few script lines\",\"Display the script lines.\",\" preprocess each script line\",\"Preprocess script lines\",\"Create columns with lower and punctuation-free lines of scripts for faster and smoother processing.\",\"I'm going to clean the script data.\",\"Show top 20 script lines\",\"Let's clean the Script data first.\",\"Filtered script lines for performing text analysis\",\"Mixin external data into script data\",\"Lower case the script lines\",\"Display the first 5 script lines.\",\" Set the script type to string\",\"Show the first few script lines.\",\"We do this to avoid retyping these lines every time we make a change to our python scripts.\",\"print the number of script lines \",\"Look at the first 5 script lines\",\"Let's print a single script line.\",\"Get a random script line\",\"Set up path to find the `style` module\\nos.sys.path.append('script_parser')\",\" Display output of all lines of code and not just the output of the last line\",\" Reformat the script data to include only the information that is relevant to our project\",\"Script lines contain more information that we won't need for this analysis, so we'll filter the columns we want to keep.\",\"Start by checking the number of rows (i.e. lines, with one line being a character's speaking turn) in the script data.\",\" Hashing of the script line text column\",\"List first 5 script lines.\",\"Combining script lines with metadata\",\"Function to load the category of a script line from its line id.\",\"Categorize the script lines by character\",\"Set up the script column map for easier retrieval of script lines\",\"Takes around 30 seconds to import 1.3 million script lines\",\"let's see how the scripts looks with all the cleaned text\",\"Store all unique script IDs in a list for further processing.\",\"Set the script line ID as the index for easy retrieval of script lines\"],\"marker\":{\"opacity\":0.5,\"size\":5},\"mode\":\"markers+text\",\"name\":\"51_Script line preprocessing and retrieval\",\"text\":[\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\"],\"textfont\":{\"size\":12},\"x\":[10.697877883911133,9.544520378112793,10.859158515930176,10.566123008728027,10.346748352050781,10.974136352539062,10.586097717285156,10.204920768737793,11.545169830322266,10.648327827453613,10.917583465576172,11.343180656433105,10.96146297454834,10.721590995788574,9.403430938720703,10.61764144897461,10.792346000671387,10.171567916870117,10.769136428833008,9.805511474609375,10.760048866271973,10.914650917053223,11.356526374816895,10.935053825378418,11.022192001342773,10.644996643066406,11.170730590820312,11.287701606750488,10.369658470153809,12.369904518127441,10.948736190795898,9.948431968688965,10.30919361114502,10.341609001159668,10.327086448669434,11.0916109085083,10.548345565795898,9.45615005493164,10.233707427978516,9.914670944213867,11.949250221252441,10.668941497802734,8.804902076721191,8.634855270385742],\"y\":[4.3030805587768555,2.341668128967285,3.1318166255950928,3.8405637741088867,4.6495161056518555,3.919025182723999,3.8685665130615234,3.5814151763916016,4.544612407684326,4.464941501617432,3.5971837043762207,3.7700130939483643,3.8205995559692383,3.7043521404266357,4.01765251159668,3.236752510070801,4.459152698516846,2.9841747283935547,3.8830933570861816,2.236253499984741,3.9679601192474365,4.235803604125977,2.9113264083862305,4.0495991706848145,3.6660821437835693,5.084746360778809,3.8292930126190186,4.338467121124268,3.920454263687134,3.834111213684082,4.619104862213135,2.675215482711792,3.23547101020813,3.744370698928833,4.13510274887085,4.264306545257568,4.044471740722656,3.766007661819458,4.376863479614258,3.525545835494995,3.5528926849365234,3.3823299407958984,3.178393840789795,3.476670742034912],\"type\":\"scattergl\"},{\"hoverinfo\":\"text\",\"hovertext\":[\"We will start by exploring the data to understand its structure, contents, and how everything relates together.\",\"We will take a brief look at the data to understand its structure and contents.\",\"First, let's take a look at the data to understand its structure and the type of information it contains.\",\"Let's start by having an overview of the data.\",\"Let's take a look at the data to understand its structure.\",\"We'll need to do some data preprocessing before we can start the analysis.\",\" Let's take a quick look at the data and understand its structure.\",\"Let's take a look at the structure of our data.\",\"Let's take a look at the structure of our data.\",\"Let's start by exploring the data and understand its structure and contents.\",\"Explore the data to understand the structure and content.\",\" Now it would be a good time to look into the data to see how it is structured and what kind of data is actually stored inside.\",\" Let's first examine the structure of the data.\",\" The next step is to preprocess and explore the data to gain insights.\",\"Let's take a look at the data to understand its structure and content.\",\" Let's start by exploring the data and visualizing some interesting statistics.\",\" Sure, I can help you with that. What would you like to do next?\",\"Let's print some basic information to start with.\",\"The first step is to load the data into our notebook so we can begin exploring it.\",\"We'll start by exploring the data to understand its structure and contents.\",\"Let's take a quick look at the data to understand its structure.\",\"We will start by taking a look at the data to understand its structure and content.\",\" Now, we will prepare the data for analysis.\",\"Let's explore the data to understand its structure and content.\",\"We'll first take a look at how the data is structured and what it looks like.\",\"We will first review the data to understand its structure and content.\",\"Let's first explore the data to see what fields we have and what kind of data is in them.\",\"Let's start by taking a quick look at some of the data to understand its structure.\",\" We'll start by doing a bit of initial exploration of the data that we have.\",\" We will start our analysis by exploring the data and understanding its structure.\",\"We'll start by having a look at the data to understand its structure and content.\",\"Let's take a look at the data to understand its structure and content.\",\"We will start by doing some exploration of the data.\",\" For simplicity, only keep the data we'll need for this analysis.\",\" It's plain to observe that we may need an write to the database.\",\"Let's start by exploring the data.\",\" We will first clean and preprocess the data to get it into a form suitable for analysis.\",\"Let's first take a look at the structure of our data.\",\"The following will be about what we will do next.\",\"# We are now ready to start the analysis.\",\"Let's take a quick look at the data to understand its structure and content.\",\"Let's take a look at the data to understand its structure.\",\" Let's start by overviewing the data.\"],\"marker\":{\"opacity\":0.5,\"size\":5},\"mode\":\"markers+text\",\"name\":\"52_Understanding data structure through exploration\",\"text\":[\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\"],\"textfont\":{\"size\":12},\"x\":[16.367496490478516,17.293601989746094,16.6379451751709,16.4094295501709,17.140050888061523,16.318157196044922,17.126617431640625,17.592845916748047,17.727073669433594,16.533781051635742,16.31174087524414,16.941280364990234,17.565988540649414,16.163387298583984,17.180803298950195,16.792022705078125,17.012224197387695,16.857585906982422,16.29237937927246,16.231691360473633,17.18279457092285,16.7889404296875,17.069913864135742,17.030263900756836,17.21541976928711,16.76862907409668,17.702104568481445,16.720369338989258,16.748754501342773,16.484878540039062,16.49380111694336,17.46137046813965,16.882905960083008,17.093425750732422,16.296768188476562,16.855731964111328,15.80381965637207,17.723548889160156,17.344194412231445,16.954591751098633,17.24069595336914,17.35976791381836,16.311355590820312],\"y\":[-0.9341530203819275,-1.0464709997177124,-1.123314380645752,-1.0671433210372925,-0.8242862820625305,0.14185108244419098,-1.0039860010147095,-0.43273717164993286,-0.2784993648529053,-0.634485125541687,-0.9831566214561462,-0.3469304144382477,-0.7971687316894531,0.5262160301208496,-1.125167965888977,-1.3646034002304077,-0.3685495853424072,-1.1073158979415894,-0.9755256175994873,-0.757450520992279,-1.0175061225891113,-0.9304915070533752,0.2227095067501068,-0.85254967212677,-0.43575215339660645,-0.8905156850814819,-0.9076288342475891,-1.0510873794555664,-0.626855731010437,-0.28045618534088135,-0.8624212145805359,-0.6137742400169373,-0.5054419636726379,0.1642588973045349,0.13555863499641418,-0.5985727906227112,0.5923594832420349,-0.8342587351799011,0.025759048759937286,-0.35349905490875244,-0.6647472977638245,-0.6464464068412781,-1.073885440826416],\"type\":\"scattergl\"},{\"hoverinfo\":\"text\",\"hovertext\":[\"Let's take a quick look at the data to understand what we are working with.\",\"Let's see what's inside the skript data.\",\"let's take a look at the data\",\"Let's take a peak at some of the data.\",\" Let's take a look at the data to understand what we are working with.\",\" Now we'll come up with a few potential questions to answer with the data.\",\" Let's have a look at the data.\",\"Let's have a look at the data.\",\" Let's check the data available.\",\"Inspecting the raw data to see what we have here...\",\"Lets take a sneak peak at the data.\",\"Let's have a first look at the data we have.\",\" Let's take a look at the data.\",\" Let's take a quick look at our data!\",\" Let's take a look at the data we have.\",\"Let's see what we are working with.\",\"Let's inspect the data.\",\"Let's have a look at the data.\",\"Let's take a closer look at the data we're working with.\",\" Let's examine the available data.\",\"Let's take a look at the data.\",\"Let's take a look at the data.\",\"now, let's get an overall sense of the data we're working with.\",\"let's explore data provided.\",\"Let's have a look at our data.\",\"Let's examine the data further.\",\"Let's take a brief look at the some sample data.\",\"Let's take a closer look at the data provided.\",\" Let's preview the data to understand what we have.\",\"Let's peek into the data to understand what we are working with.\",\"Let's have a look at the data.\",\"Let's take a look at the data.\",\" Let's take a look at the data.\",\"Let's take a look at some of the data.\",\"Let's take a look at what we're dealing with in each case\",\"Let's take a look at the available data.\",\"Now let's have a quick look at our data.\",\"Let's take a look at the data.\",\"Let's take a look at the data.\",\"Let's take a look at the data.\",\"We'll perform a quick check on the data.\",\"Let's explore the data we have.\",\"Let's get a glimpse of the data we have imported.\"],\"marker\":{\"opacity\":0.5,\"size\":5},\"mode\":\"markers+text\",\"name\":\"53_Let's take a closer look at the data we have\",\"text\":[\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\"],\"textfont\":{\"size\":12},\"x\":[18.507755279541016,19.208471298217773,19.178699493408203,18.15928077697754,18.579540252685547,18.69768524169922,18.857397079467773,18.762353897094727,18.237794876098633,18.2632999420166,18.583877563476562,18.748428344726562,19.23695182800293,18.66236686706543,18.964752197265625,18.14246940612793,17.952129364013672,18.906328201293945,18.781980514526367,18.81633186340332,19.3489990234375,19.202411651611328,18.483182907104492,18.239389419555664,18.5670166015625,18.741334915161133,19.695383071899414,19.22199821472168,17.871625900268555,18.35550308227539,19.027376174926758,19.124353408813477,19.330810546875,19.2017765045166,18.283180236816406,19.03445816040039,18.54837417602539,19.312997817993164,19.24614143371582,19.29393196105957,17.928482055664062,18.324792861938477,18.553651809692383],\"y\":[-0.41810306906700134,-0.9228184819221497,-0.7236592173576355,-1.4490290880203247,-0.3512154221534729,-0.7933068871498108,-0.28411707282066345,-0.54761803150177,-0.5371307134628296,-0.30810800194740295,-1.410544514656067,-1.3151921033859253,-0.4598301649093628,-1.1953389644622803,-1.0206912755966187,-0.30515724420547485,-0.4374193251132965,-0.25570443272590637,-0.4644215404987335,-0.37352725863456726,-0.7897578477859497,-0.6820533275604248,-0.5113072991371155,-0.3743768334388733,-0.6964592337608337,-0.04570608586072922,-0.5327322483062744,-0.6210864186286926,-0.36592912673950195,-0.372993141412735,-0.5191879868507385,-0.6666067838668823,-0.634140133857727,-0.7248015403747559,-0.006446369457989931,-0.8426835536956787,-0.9052994251251221,-0.5369043350219727,-0.824737012386322,-0.747484564781189,-0.5225858688354492,-0.3472018837928772,-0.7339603900909424],\"type\":\"scattergl\"},{\"hoverinfo\":\"text\",\"hovertext\":[\"Ensure all data was loaded successfully\\nprint('Characters:', df_characters.shape)\\nprint('Locations:', df_locations.shape)\\nprint('Script:', df_script.shape)\\nprint('Episodes:', df_episodes.shape)\",\" Display the dataframe shapes\\nprint(\\\"Characters:\\\", df_characters.shape)\\nprint(\\\"Locations:\\\", df_locations.shape)\\nprint(\\\"Script:\\\", df_script.shape)\\nprint(\\\"Episodes:\\\", df_episodes.shape)\",\"print('Characters shape:', df_characters.shape)\\nprint('Locations shape:', df_locations.shape)\\nprint('Script shape:', df_script.shape)\\nprint('Episodes shape:', df_episodes.shape)\",\"Kernel -\\u003e Restart & Run All to refresh DataFrame shapes\\n# New episode shapes\\nprint(f\\\"df_episodes shape: {df_episodes.shape}\\\")\\n\\n# New script shapes\\nprint(f\\\"df_script shape: {df_script.shape}\\\")\",\"Display shapes\\nprint(df_characters.shape)\\nprint(df_locations.shape)\\nprint(df_script.shape)\\nprint(df_episodes.shape)\",\"print('df_characters shape: {}'.format(df_characters.shape))\\nprint('df_locations shape: {}'.format(df_locations.shape))\\nprint('df_script shape: {}'.format(df_script.shape))\\nprint('df_episodes shape: {}'.format(df_episodes.shape))\",\"Inspect loaded data\\nprint('characters:', df_characters.shape)\\nprint('locations:', df_locations.shape)\\nprint('script_lines:', df_script.shape)\\nprint('episodes:', df_episodes.shape)\",\"Visualiza\\u00e7\\u00e3o do tamanho dos dataframes\\nprint(\\\"df_characters.shape\\\", df_characters.shape)\\nprint(\\\"df_locations.shape\\\", df_locations.shape)\\nprint(\\\"df_script.shape\\\", df_script.shape)\\nprint(\\\"df_episodes.shape\\\", df_episodes.shape)\",\"Explore the data structure\\nprint(\\\"Characters:   \\\", df_characters.shape)\\nprint(\\\"Locations:    \\\", df_locations.shape)\\nprint(\\\"Script:       \\\", df_script.shape)\\nprint(\\\"Episodes:     \\\", df_episodes.shape)\",\"Print data shapes\\nprint('Characters:', df_characters.shape)\\nprint('Locations:', df_locations.shape)\\nprint('Script:', df_script.shape)\\nprint('Episodes:', df_episodes.shape)\",\"Print shape of each dataframe\\nprint(\\\"Characters:\\\", df_characters.shape)\\nprint(\\\"Locations:\\\", df_locations.shape)\\nprint(\\\"Script:\\\", df_script.shape)\\nprint(\\\"Episodes:\\\", df_episodes.shape)\",\"Print file shapes\\nprint('Characters:', df_characters.shape)\\nprint('Locations:', df_characters.shape)\\nprint('Script:', df_characters.shape)\\nprint('Episodes:', df_characters.shape)\",\"print shape of each dataframe\\nprint(\\\"Characters DataFrame Shape: \\\", df_characters.shape)\\nprint(\\\"Locations DataFrame Shape: \\\", df_locations.shape)\\nprint(\\\"Script DataFrame Shape: \\\", df_script.shape)\\nprint(\\\"Episodes DataFrame Shape: \\\", df_episodes.shape)\",\"# Print shapes of the DataFrames\\nprint(df_characters.shape)\\nprint(df_locations.shape)\\nprint(df_script.shape)\\nprint(df_episodes.shape)\",\"print('Characters:', df_characters.shape)\\nprint('Locations:', df_locations.shape)\\nprint('Script:', df_script.shape)\\nprint('Episodes:', df_episodes.shape)\",\"Display some simple informatoin basic infomraiton about the DataFrames\\nprint(f'Characters dataframe shape: {df_characters.shape}')\\nprint(f'Locations dataframe shape:  {df_locations.shape}')\\nprint(f'Script dataframe shape:      {df_script.shape}')\\nprint(f'Episodes dataframe shape:    {df_episodes.shape}')\",\"View some basic info\\nprint('Script lines:', df_script.shape)\\nprint('Episodes:', df_episodes.shape)\\nprint('Characters:', df_characters.shape)\\nprint('Locations:', df_locations.shape)\",\" Display the dataframes' shapes\\nprint(df_characters.shape, df_locations.shape, df_script.shape, df_episodes.shape)\",\"Print shapes of dataframes\\nprint(df_characters.shape)\\nprint(df_locations.shape)\\nprint(df_script.shape)\\nprint(df_episodes.shape)\",\"View data shapes\\nprint('Characters shape:', df_characters.shape)\\nprint('Locations shape:', df_locations.shape)\\nprint('Script shape:', df_script.shape)\\nprint('Episodes shape:', df_episodes.shape)\",\"print('Script:', df_script.shape)\\nprint('Locations:', df_locations.shape)\\nprint('Characters:', df_characters.shape)\\nprint('Episodes:', df_episodes.shape)\",\"Most of the data:\\nprint('Characters:', df_characters.shape)\\nprint('Locations:', df_locations.shape)\\nprint('Script:', df_script.shape)\\nprint('Episodes:', df_episodes.shape)\",\"\\u000f# 1.2 Load all data into a pandas dataframes\\n# Show the dataframes structure\\nprint(f'df_characters.shape:   {df_characters.shape}')\\nprint(f'df_locations.shape:    {df_locations.shape}')\\nprint(f'df_script.shape:       {df_script.shape}')\\nprint(f'df_episodes.shape:     {df_episodes.shape}')\",\" Print the shapes of our dataset\\nprint(\\\"Characters shape:\\\", df_characters.shape)\\nprint(\\\"Locations shape:\\\", df_locations.shape)\\nprint(\\\"Script shape:\\\", df_script.shape)\\nprint(\\\"Episodes shape:\\\", df_episodes.shape)\",\"# Print DataFrame characteristics\\nprint_characters(df_characters)\\nprint_locations(df_locations)\\nprint_script(df_script)\\nprint_episodes(df_episodes)\",\"Quick overview of the dataset\\nprint('Characters:', df_characters.shape)\\nprint('Locations:', df_locations.shape)\\nprint('Script:', df_script.shape)\\nprint('Episodes:', df_episodes.shape)\",\"Check the files\\nprint('Characters: ', df_characters.shape)\\nprint('Locations: ', df_locations.shape)\\nprint('Script: ', df_script.shape)\\nprint('Episodes: ', df_episodes.shape)\",\" Print the shape of the DataFrames\\nprint(\\\"Characters df shape :\\\", df_characters.shape)\\nprint(\\\"Locations df shape :\\\", df_locations.shape)\\nprint(\\\"Script df shape :\\\", df_script.shape)\\nprint(\\\"Episodes df shape :\\\", df_episodes.shape)\",\"Display some basic information about the datasets\\nprint('Characters:', df_characters.shape)\\nprint('Locations:', df_locations.shape)\\nprint('Script lines:', df_script.shape)\\nprint('Episodes:', df_episodes.shape)\",\"\\n# Initially show the first 5 rows of the dataframes to get an understanding of the data\\nprint('Character df shape:', df_characters.shape)\\nprint('Location df shape:', df_locations.shape)\\nprint('Script df shape:', df_script.shape)\\nprint('Episode df shape:', df_episodes.shape)\",\"Display shape and info\\nprint('Characters shape:', df_characters.shape)\\nprint('Locations shape:', df_locations.shape)\\nprint('Script shape:', df_script.shape)\\nprint('Episodes shape:', df_episodes.shape)\",\"print('Script shape:', df_script.shape)\\nprint('Character shape:', df_characters.shape)\\nprint('Location shape:', df_locations.shape)\\nprint('Episodes shape:', df_episodes.shape)\",\"Print the dataframes shapes\\nprint('Characters df shape: ', df_characters.shape)\\nprint('Locations df shape: ', df_locations.shape)\\nprint('Script df shape: ', df_script.shape)\\nprint('Episodes df shape: ', df_episodes.shape)\",\"Check the shape and headers\\nprint('Shape of characters:', df_characters.shape)\\nprint('Shape of locations:', df_locations.shape)\\nprint('Shape of script lines:', df_script.shape)\\nprint('Shape of episodes:', df_episodes.shape)\\n\\ndf_characters.head()\",\"summary of data\\nprint(\\\"characters:\\\", df_characters.shape)\\nprint(df_characters.head())\\nprint(\\\"locations:\\\", df_locations.shape)\\nprint(df_locations.head())\\nprint(\\\"script:\\\", df_script.shape)\\nprint(df_script.head())\\nprint(\\\"episodes:\\\", df_episodes.shape)\\nprint(df_episodes.head())\",\"Inspect DataFrame shapes\\nprint(\\\"Characters:\\\", df_characters.shape)\\nprint(\\\"Locations:\\\", df_locations.shape)\\nprint(\\\"Script lines:\\\", df_script.shape)\\nprint(\\\"Episodes:\\\", df_episodes.shape)\",\" Print the shape of each DataFrame\\nprint(f'Shapes: Characters={df_characters.shape}, Locations={df_locations.shape}, Script={df_script.shape}, Episodes={df_episodes.shape}')\",\" Check loaded data\\nprint('Characters: {}'.format(df_characters.shape))\\nprint('Locations: {}'.format(df_locations.shape))\\nprint('Script: {}'.format(df_script.shape))\\nprint('Episodes: {}'.format(df_episodes.shape))\",\"Show the dataframes shape\\nprint('Characters:', df_characters.shape)\\nprint('Locations:', df_locations.shape)\\nprint('Script:', df_script.shape)\\nprint('Episodes:', df_episodes.shape)\",\"Print dataframe shapes\\nprint(df_characters.shape)\\nprint(df_locations.shape)\\nprint(df_script.shape)\\nprint(df_episodes.shape)\",\"Dataset content\\nprint(\\\"characters shape:\\\", df_characters.shape)\\nprint(\\\"locations shape:\\\", df_locations.shape)\\nprint(\\\"script shape:\\\", df_script.shape)\\nprint(\\\"episodes shape:\\\", df_episodes.shape)\",\" Explore data\\nprint('Characters:', df_characters.shape)\\nprint('Locations:', df_locations.shape)\\nprint('Script:', df_script.shape)\\nprint('Episodes:', df_episodes.shape)\",\"Quick overview of the datasets\\nprint('Characters: {}'.format(df_characters.shape))\\nprint('Locations: {}'.format(df_locations.shape))\\nprint('Script: {}'.format(df_script.shape))\\nprint('Episodes: {}'.format(df_episodes.shape))\"],\"marker\":{\"opacity\":0.5,\"size\":5},\"mode\":\"markers+text\",\"name\":\"54_Printing DataFrame Shapes\",\"text\":[\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\"],\"textfont\":{\"size\":12},\"x\":[-1.3384901285171509,-1.8642338514328003,-1.7905329465866089,-1.9408704042434692,-1.4230575561523438,-1.4187672138214111,-0.877078115940094,-1.3351496458053589,-1.0027775764465332,-1.1550627946853638,-1.555907964706421,-1.289237380027771,-1.5558726787567139,-1.3874056339263916,-1.363589882850647,-1.204456090927124,-1.1998575925827026,-1.677988886833191,-1.598214030265808,-1.3366223573684692,-1.5684175491333008,-1.1145777702331543,-1.1789331436157227,-0.6434641480445862,-1.3473104238510132,-0.5687178373336792,-0.9857050776481628,-1.1463266611099243,-0.647533118724823,-1.0200432538986206,-1.6065362691879272,-1.5555553436279297,-1.5179274082183838,-1.2520837783813477,-1.0581557750701904,-1.2769629955291748,-0.8837157487869263,-0.9913210868835449,-1.6131078004837036,-1.4928879737854004,-0.7778050303459167,-1.0978498458862305,-0.7773997783660889],\"y\":[-1.0911865234375,-1.3799220323562622,-0.751899778842926,-1.3322538137435913,-1.4321845769882202,-1.4482169151306152,-0.6113200187683105,-1.04938805103302,-0.06480300426483154,-0.6084800958633423,-1.850102186203003,-0.874298632144928,-2.021571159362793,-1.7389428615570068,-0.29454588890075684,-1.6356325149536133,-0.8677178621292114,-1.0756150484085083,-1.6457598209381104,-1.0036128759384155,-0.7228574752807617,-0.5020142197608948,-1.8921602964401245,-1.049856424331665,-0.862068772315979,-0.6290793418884277,-0.6590784788131714,-1.7281959056854248,-0.2205725610256195,-1.253849983215332,-1.138428807258606,-0.89876788854599,-1.7036947011947632,-0.5844822525978088,0.6365618705749512,-1.2047953605651855,-2.10469126701355,-1.5326449871063232,-1.1776553392410278,-1.877638578414917,-0.7808217406272888,-0.6062220931053162,-1.3168327808380127],\"type\":\"scattergl\"},{\"hoverinfo\":\"text\",\"hovertext\":[\"Define helper function to join script snippets\",\"Define some cosmetic global parameters.\",\" Setting up constants\",\" Extract Environment Variables\",\"Check internal constants\",\"Simple example functions to test the interaction of the extension with the specific environment.\",\"Setting up variables needed for pre-processing\",\"Integration of my methods\",\"Declare variable with all seasons\",\"Setting important variables\",\"Define constants\",\"Stat helper functions\",\"Define custom functions and classes\",\"Helper functions to display data in a nice format.\",\"Auxiliary functions to simplify and clean the code below.\",\"Declare globally-used variables\",\" Define Project Constants\",\"Create some global variables\",\"Load the saved variables\",\"Defining some functions\",\"Helper functions\",\" Helper functions and constants\",\"# Helper function to display information in percentage\\ndef percent(x, pos=0):\\n    \\\"\\\"\\\"The two args are the value and tick position.\\n    Label ticks with the percentage of the total\\\"\\\"\\\"\\n    return '%1.1f%%' % (x * 100)\",\"Definitions (for brevity)\",\"Declare input parameters\",\"Functions\",\" define a fixed value variable.\",\"Declare variable for working with the lemma of the words\",\"Setup constants\",\" Helper functions\",\" Setuptools' entry point\\ndef main():\\n    \\\"\\\"\\\"\\n    Main function\\n    \\\"\\\"\\\"\",\"Declare global variables\",\"Define constant strings for specific data fields.\",\"a single collaborator is going to be used in this example\\nCOLLABORATOR_NAME = 'Colab1'\",\"Utility functions\",\"Check whether the Helper label shows up for APIWidget.\",\"Setting up variables\",\"define some helpful functions\",\"Functions for feature engineering\",\"Declare the global variables\",\"Helper functions and variables\",\"Auxiliary functions\"],\"marker\":{\"opacity\":0.5,\"size\":5},\"mode\":\"markers+text\",\"name\":\"55_Helper functions, variables, and constants\",\"text\":[\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\"],\"textfont\":{\"size\":12},\"x\":[10.831618309020996,14.304080963134766,13.5072021484375,14.525836944580078,13.807417869567871,13.813972473144531,13.621495246887207,12.514986991882324,11.656179428100586,13.863367080688477,13.121967315673828,13.329377174377441,13.800936698913574,13.749302864074707,12.269728660583496,13.944009780883789,13.601840019226074,14.306517601013184,14.599377632141113,13.597132682800293,13.456927299499512,13.46052074432373,13.644978523254395,13.544119834899902,13.501206398010254,13.339253425598145,13.636545181274414,13.157533645629883,13.433184623718262,13.74355411529541,14.163683891296387,13.942195892333984,12.532325744628906,13.615456581115723,13.481396675109863,14.264647483825684,14.143479347229004,13.62470817565918,14.080757141113281,13.663554191589355,13.429252624511719,13.195831298828125],\"y\":[3.981930732727051,2.554899215698242,1.4934439659118652,3.5193655490875244,1.465889811515808,2.4639222621917725,2.691638708114624,1.8489937782287598,2.830963134765625,2.3601291179656982,1.7832961082458496,2.7939343452453613,3.0020318031311035,2.461987257003784,2.948946714401245,2.876476287841797,1.7004578113555908,2.843998908996582,2.179253101348877,2.575000047683716,2.6783370971679688,2.15691876411438,3.6933248043060303,2.4336748123168945,2.7109766006469727,2.372795820236206,2.088233232498169,3.162386417388916,1.9477940797805786,2.7047762870788574,3.634364366531372,2.9554264545440674,1.3686871528625488,4.519054412841797,2.91951847076416,3.310558319091797,2.3776094913482666,2.504566192626953,1.7935855388641357,2.942173719406128,2.5414977073669434,2.7433886528015137],\"type\":\"scattergl\"},{\"hoverinfo\":\"text\",\"hovertext\":[\"Multiline mode DataFrame print\\nfrom IPython.display import display\",\"# Ensure matplotlib works correctly with Jupyter\\n%matplotlib inline\",\" The first cell of the Jupyter notebook, imports libraries and custom packages, loads the necessary data files using pandas, and sets up matplotlib for visualization.\",\"Display plots inline in Jupyter notebook\",\"Visualisation for the jupyter notebook\",\"Display multiples output at once.\\nfrom IPython.core.interactiveshell import InteractiveShell\\nInteractiveShell.ast_node_interactivity = \\\"all\\\"\",\"# Display markdown\\nfrom IPython.display import display, Markdown\",\" Custom header\\nfrom jupyterthemes import jtplot\\njtplot.style(theme='chesterish', context='notebook', ticks=True, grid=False)\",\"# Make autocompletion work\\n# Note: This is a temporary solution, the correct way to do it is by installing the plotnine package\\nfrom plotnine import *\",\"Since we are using Jupyter notebooks, we add the magic command %matplotlib inline to ensure that matplotlib works correctly with Jupyter.\",\"Show version information for reproducibility\\nprint(\\\"Pandas version: \\\", pd.__version__)\\nprint(\\\"Matplotlib version: \\\", matplotlib.__version__)\\nprint(\\\"Numpy version: \\\", np.__version__)\",\"*Note: If you're using a Jupyter notebook, make sure to run the `%matplotlib inline` command to display the visualization within the notebook.*\",\"Set configuration options for pandas and matplotlib\",\"# Ensure correct versions\\nprint(f\\\"spacy=={spacy.__version__}\\\")\\nprint(f\\\"pandas=={pd.__version__}\\\")\\nprint(f\\\"numpy=={np.__version__}\\\")\\nprint(f\\\"matplotlib=={matplotlib.__version__}\\\")\",\" To integrate plotly with matplotlib, we need to install another library.\",\"to make this last import work without error\\nmatplotlib use the tkinter Agg backend\\nmatplotlib.use('Agg')\",\"Jupyter notebook needs some modifications in the matplotlib settings to properly show the visualizations.\",\"Set custom matplotlib configurations\",\"Setting plot space to be for Jupyter notebook specifically\",\" Enable jupyter_contrib_nbextensions for easier notebook use\\n!jupyter contrib nbextension install\",\"ensure matplotlib works correctly with Jupyter\\n%matplotlib inline\",\"get_ipython().run_line_magic('matplotlib', 'inline')\",\"Specify how the plots should be displayed in jupyter notebook\",\"#enable interactive plotting in Jupyter notebook\\nmatplotlib.use('nbagg')\",\" Jupyter-notebook-like help to visualize DataFrames easily\\nfrom IPython.display import display\",\"skipping the possible \\\"locale is not supported\\\" warning\\n# No longer needed in pandas 1.1.0\\npd.plotting.register_matplotlib_converters()\",\"Display rich content\\nfrom IPython.display import display\",\"Set environment variable for matplotlib\\nos.environ['MPLCONFIGDIR'] = os.getcwd()\",\"# These imports will be useful in this notebook\\nfrom pandas.plotting import register_matplotlib_converters\\nregister_matplotlib_converters()\",\"Displays the output from the function instead of just showing the last plot\\nmatplotlib.use('module:\\u002f\\u002fipykernel.pylab.backend_inline')\",\" To avoid compatibility issues with matplotlib, you should specify the type of backend you want to use. For example:\",\"interactively display plots\\n%matplotlib notebook\",\"jupyter nbconvert --to html notebook.ipynb\",\"Uncomment following line in case you are unable to see the plots\\n# %matplotlib inline\",\"Setting the backend of matplotlib to a specific value to avoid any issues\",\"Ensuring the PI works well in Jupyter for Matplotlib rebinding the\\n# show() function to bypass the one provided by Jupyter\\ndef show():\\n   plt.show()\",\"jupyter notebook compatible code\\nfrom IPython.core.interactiveshell import InteractiveShell\\nInteractiveShell.ast_node_interactivity = \\\"all\\\"\",\" Add the following line in order to keep the matplotlib plots in the notebook for \\n# evaluation. Note that in regular Python we could use plt.show() which is not\\n# needed in jupyter notebooks.\\n%matplotlib inline\",\"Set IPython indentation mode to always indent after line breaks\\nfrom IPython.core.interactiveshell import InteractiveShell\\nInteractiveShell.ast_node_interactivity = 'all'\",\" All print() output will be written directly to the Jupyter notebook\\nfrom IPython.core.interactiveshell import InteractiveShell\\nInteractiveShell.ast_node_interactivity = \\\"all\\\"\",\"Set notebook-related options for pandas and matplotlib\"],\"marker\":{\"opacity\":0.5,\"size\":5},\"mode\":\"markers+text\",\"name\":\"56_Using matplotlib inline in Jupyter notebooks\",\"text\":[\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\"],\"textfont\":{\"size\":12},\"x\":[18.792829513549805,19.19129753112793,18.669837951660156,18.981332778930664,18.5098934173584,18.4696044921875,18.992694854736328,18.95737648010254,18.6528263092041,19.015390396118164,19.773096084594727,19.224245071411133,19.84844207763672,19.132434844970703,19.29238510131836,19.60658073425293,19.023563385009766,19.739919662475586,18.85093879699707,17.939491271972656,19.508407592773438,19.485382080078125,18.819978713989258,19.287857055664062,18.912059783935547,19.21149253845215,18.89687728881836,18.976749420166016,19.379138946533203,19.523937225341797,19.43851661682129,18.99565315246582,18.5031795501709,19.56513023376465,19.634544372558594,19.061418533325195,18.524394989013672,19.433490753173828,18.486257553100586,18.28207015991211,19.29773712158203],\"y\":[2.326948404312134,4.23469877243042,3.0822770595550537,3.296292304992676,2.9326417446136475,2.6741082668304443,2.326882839202881,3.0750181674957275,3.4012041091918945,3.8655717372894287,3.2981340885162354,3.855947256088257,3.407790422439575,3.9756581783294678,3.750232458114624,3.886345624923706,3.273632049560547,4.238548278808594,3.6897900104522705,2.7169859409332275,4.0438032150268555,4.029007911682129,3.2802340984344482,3.5645573139190674,2.4227688312530518,4.043517112731934,2.2585015296936035,4.515571594238281,3.610352039337158,3.557884693145752,4.150632858276367,3.25358247756958,2.3672449588775635,3.990543842315674,4.648711204528809,3.870680093765259,2.658067226409912,3.604654550552368,2.3115785121917725,2.337576389312744,3.0087292194366455],\"type\":\"scattergl\"},{\"hoverinfo\":\"text\",\"hovertext\":[\"Let's take a quick look at what our datasets contain.\",\"Data\\n# Let's have a first look at the datasets.\",\"Let's see some basic information from each dataset.\",\"Let's take a first look at each of these datasets.\",\"Let us examine our datasets to see what's inside and what can be interesting\",\"let's have a brief look at the data sets\",\" Let's quickly look at what is contained in the datasets.\",\"Let's take the first look at the loaded datasets.\",\"Let's have a quick overview of each dataset.\",\" Let's get an overview of these datasets.\",\"Let's see how the datasets look.\",\" Let's apply some basic data explorations to see what is inside these datasets.\",\"Let's explore the content of these datasets.\",\"Let's explore the data to have an idea what is in the dataset.\",\"Let's first look at the structure of the datasets.\",\"Let's first get a feel for our datasets by taking a look at the first few lines.\",\"Let's first explore what each dataset looks like.\",\" Let's preview the datasets.\",\" Let's take a quick look at each of the datasets.\",\"Let's take a quick look at the various datasets.\",\"Let's take a quick look at our datasets.\",\"Let's take a quick look at the datasets we have.\",\"Let's have a look at the content of each of these datasets.\",\" Let's see what's in these datasets\",\"We will display our dataset here\",\"Let's explore the dataset one by one.\",\"Let's take a quick look at what these datasets contain.\",\"Let's have an overview of our datasets\",\"Let's take a look at these datasets.\",\"Let's see what these datasets actually contain.\",\"Let's get an overview of these datasets.\",\"Let's see an overview of these datasets.\",\"Let's first take a look at the schema of each dataset.\",\"Let's take a look at our datasets\",\" Let's take a look at these datasets.\",\"Let's see what our datasets look like.\",\"Let's see what's inside these datasets:\",\" Let's first take a look at the structure and content of each of these datasets.\",\"Let's take a glimpse at these datasets.\",\"Let's inspect our datasets\"],\"marker\":{\"opacity\":0.5,\"size\":5},\"mode\":\"markers+text\",\"name\":\"57_exploring dataset content\",\"text\":[\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\"],\"textfont\":{\"size\":12},\"x\":[16.35257911682129,16.346420288085938,16.4438533782959,16.80257797241211,16.619272232055664,16.58845329284668,15.79798412322998,15.650662422180176,16.948240280151367,16.980289459228516,16.1726131439209,15.90676212310791,16.591344833374023,15.921056747436523,15.80123233795166,16.11728858947754,16.216049194335938,16.58159065246582,16.527698516845703,16.886951446533203,16.647775650024414,16.9967041015625,16.949508666992188,16.410675048828125,16.196670532226562,16.516033172607422,16.668344497680664,16.87478256225586,17.101598739624023,16.467546463012695,16.74091911315918,17.220129013061523,15.886598587036133,16.609325408935547,17.05222511291504,16.506193161010742,16.085161209106445,16.32628059387207,16.73345947265625,16.156963348388672],\"y\":[-3.116450548171997,-3.357179641723633,-3.037879705429077,-3.1712417602539062,-2.952908754348755,-3.7650790214538574,-3.3348121643066406,-2.527376651763916,-2.969689130783081,-3.0459389686584473,-2.967521905899048,-2.8442916870117188,-3.3893003463745117,-2.6904945373535156,-3.7609810829162598,-3.2712550163269043,-2.7110791206359863,-2.57605242729187,-3.4094979763031006,-3.2559092044830322,-3.373919725418091,-3.355903387069702,-3.2471375465393066,-3.602288246154785,-3.4413001537323,-3.3000731468200684,-3.6301727294921875,-3.541370153427124,-3.732182264328003,-3.4936444759368896,-3.0850775241851807,-3.4847724437713623,-3.2623894214630127,-3.20037841796875,-3.6619296073913574,-3.283799171447754,-3.584413528442383,-3.29632306098938,-3.324594736099243,-2.8251209259033203],\"type\":\"scattergl\"},{\"hoverinfo\":\"text\",\"hovertext\":[\" Replace NaN values with empty strings\\ndf_script = df_script.fillna('')\",\"Replace NaN with an empty string\\ndf_script = df_script.replace(np.nan, '', regex=True)\",\"Replace NaN values with empty strings\\ndf_script = df_script.fillna('')\",\"replace NaN values with empty strings\\ndf_script.fillna('', inplace=True)\",\"Replace NaN values\\ndf_characters.replace({np.nan: None}, inplace=True)\\ndf_locations.replace({np.nan: None}, inplace=True)\\ndf_script.replace({np.nan: None}, inplace=True)\\ndf_episodes.replace({np.nan: None}, inplace=True)\",\"Ensure all NaN values are replaced with an empty string\\ndf_script = df_script.fillna('')\",\"Clean the texts of NaN values\\ndf_script.cleaned_text = df_script.cleaned_text.fillna('')\",\"Clean gender information\\n# Convert empty strings in gender column to NaN\\ndf_characters['gender'] = df_characters['gender'].apply(lambda x: np.NaN if x == '' else x)\\n\\n# Replace unknown genders with NaN\\ndf_characters['gender'] = df_characters['gender'].replace('?', np.NaN)\",\"Replace NaN values in episode_id with -1\\ndf_script['episode_id'].fillna(-1, inplace=True)\",\" Set `np.NaN` untuk string kosong\\ndf_script.replace('', np.NaN, inplace=True)\",\"Replace NaN values\\ndf_characters['normalized_name'] = df_characters['normalized_name'].fillna('')\",\"Add missing value to data\\ndf_script.fillna('')\",\"Replace missing gender\\ndf_characters.gender.replace({'non-specific': np.nan}, inplace=True)\",\"clean empty string rows\\ndf_script.replace('', np.nan, inplace=True)\\ndf_script.dropna(inplace=True)\",\"Replace NaN values with empty strings\\ndf_script = df_script.fillna('')\",\"We should change NaNs for empty strings\\ndf_script = df_script.fillna('')\",\"Replace NaN with empty string\\ndf_script = df_script.replace(np.nan, '', regex=True)\",\"Label 'other' as gender for np.nan values in the gender column\\ndf_characters['gender'] = df_characters['gender'].replace({np.nan: 'other'})\",\"Fill in the NaN values in the raw script data with empty strings to avoid issues with the text processing later on\\ndf_script = df_script.fillna('')\",\"Clean dataframe \\\"df_script\\\" from NaN and duplicated data\",\"Replace NaN values with empty strings\\ndf_script = df_script.fillna('')\",\" Set NaN strings to NaN values\",\"Replace NaN values with an empty string\\ndf_script = df_script.fillna('')\",\" Replacing NaN with empty string\\ndf_script.fillna(\\\"\\\", inplace=True)\",\"Replace NaN values with empty strings\\ndf_script = df_script.fillna('')\",\" Preprocessing\\n# Replacing NaN with np.nan\\ndf_script = df_script.replace({pd.np.nan: None})\",\"We need to also force the conversion of str-``NaN`` to ``np.nan`` again as done during Data Cleaning.\",\" Replace NaN with empty string\\ndf_script = df_script.fillna('')\",\"Fill \\\\'NA\\\\' values with empty strings\\ndf_script = df_script.fillna('')\",\"Setting 'UNKNOWN' for NaN values, to avoid surprises later\\ndf_script['raw_character_text'] = df_script['raw_character_text'].fillna('UNKNOWN')\\ndf_script['raw_location_text'] = df_script['raw_location_text'].fillna('UNKNOWN')\",\"Replace NaN with empty string\\ndf_script = df_script.fillna('')\",\" Turn NaN values into empty strings\\ndf_script = df_script.fillna('')\",\"# Fill NaN with empty strings\\ndf_script = df_script.fillna('')\",\"Replace nans with empty strings\\ndf_characters.fillna(value=\\\"\\\", inplace=True)\\ndf_locations.fillna(value=\\\"\\\", inplace=True)\\ndf_script.fillna(value=\\\"\\\", inplace=True)\\ndf_episodes.fillna(value=\\\"\\\", inplace=True)\",\"Replace NaN with empty strings\\ndf_script = df_script.fillna('')\",\" Replace original_na values with Python's NaN valuemarker\\ndf_characters.replace([r'\\\\N'], np.nan, inplace=True)\\ndf_locations.replace([r'\\\\N'], np.nan, inplace=True)\\ndf_script.replace([r'\\\\N'], np.nan, inplace=True)\\ndf_episodes.replace([r'\\\\N'], np.nan, inplace=True)\",\"replacing empty string with NaN\\ndf_script.replace(\\\"\\\", np.nan, inplace=True)\",\"Replace nans with empty strings\\ndf_script = df_script.fillna('')\",\"Replace all NaN values with an empty string\\ndf_script.fillna('', inplace=True)\"],\"marker\":{\"opacity\":0.5,\"size\":5},\"mode\":\"markers+text\",\"name\":\"58_Replace NaN values with empty strings\",\"text\":[\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\"],\"textfont\":{\"size\":12},\"x\":[5.99805212020874,6.340763568878174,6.24641752243042,5.858875274658203,5.659393310546875,6.398327350616455,6.5074028968811035,6.497527122497559,5.546412944793701,6.23769998550415,6.258854389190674,5.869754791259766,6.207024574279785,6.047995567321777,5.90074348449707,6.684896469116211,6.3791375160217285,6.322559833526611,6.494514465332031,6.945486068725586,6.204604625701904,6.470622539520264,5.959224700927734,5.7828450202941895,6.011282444000244,6.106019496917725,6.736347675323486,5.876905918121338,6.085987567901611,6.1954803466796875,6.1551833152771,6.321874141693115,5.845190048217773,5.346573829650879,6.319087028503418,5.25302267074585,6.316530227661133,6.093020439147949,6.053258419036865],\"y\":[2.6230556964874268,3.4002716541290283,2.6459829807281494,3.0979695320129395,3.669498920440674,2.580272912979126,3.302725076675415,5.067682266235352,3.9083175659179688,3.0058412551879883,3.871382474899292,2.2623231410980225,4.5704731941223145,3.831120252609253,2.78702974319458,2.639688491821289,3.294832944869995,5.662113189697266,3.1154706478118896,2.532536506652832,2.7103848457336426,2.4617104530334473,2.462733268737793,2.728320598602295,2.618795156478882,3.0706393718719482,2.659553289413452,3.0300636291503906,2.8756260871887207,3.1806395053863525,3.081923246383667,2.258838415145874,2.4397308826446533,3.478301525115967,2.979205846786499,3.987675666809082,2.920830011367798,3.0786447525024414,2.508655548095703],\"type\":\"scattergl\"},{\"hoverinfo\":\"text\",\"hovertext\":[\"Set random seed for reproducibility\\nnp.random.seed(0)\",\" Set random seed for reproducibility\\nnp.random.seed(0)\",\" Set random seed for reproducibility\\nnp.random.seed(0)\",\" Set random seed for reproducibility\\nnp.random.seed(0)\",\"Set random seed for reproducibility\\nnp.random.seed(0)\",\"Set random seed for reproducibility\\nnp.random.seed(0)\",\"Set random seed for reproducibility\\nnp.random.seed(0)\",\"Set random seed for reproducibility\\nnp.random.seed(0)\",\"Set random seed for reproducibility\\nnp.random.seed(0)\",\" Set random seed for reproducibility\\nnp.random.seed(0)\",\"Set random seed for reproducibility\\nnp.random.seed(0)\",\"Set random seed for reproducibility\\nnp.random.seed(0)\",\"Setting random seed for reproducibility\\nnp.random.seed(0)\",\"Set random seed for reproducibility\\nnp.random.seed(0)\",\"Set random seed for reproducibility\\nnp.random.seed(0)\",\"Set random seed for reproducibility\\nnp.random.seed(0)\",\" Set random seed for reproducibility\\nnp.random.seed(0)\",\" Set random seed for reproducibility\\nnp.random.seed(0)\",\" Set random seed for reproducibility\\nnp.random.seed(0)\",\"Set random seed for reproducibility\\nnp.random.seed(0)\",\" Set random seed for reproducibility\\nnp.random.seed(0)\",\" Set random seed for reproducibility\\nnp.random.seed(0)\",\"Set random seed for reproducibility\\nnp.random.seed(0)\",\"set random seed for reproducibility\\nnp.random.seed(0)\",\" Set random seed for reproducibility\\nnp.random.seed(0)\",\" Set random seed for reproducibility\\nnp.random.seed(0)\",\"Set random seed for reproducibility\\nnp.random.seed(0)\",\"Set random seed for reproducibility\\nnp.random.seed(0)\",\"Set random seed for reproducibility\\nnp.random.seed(0)\",\"Set random seed for reproducibility\\nnp.random.seed(0)\",\" Set random seed for reproducibility\\nnp.random.seed(0)\",\"Set random seed for reproducibility\\nnp.random.seed(0)\",\"Set random seed for reproducibility\\nnp.random.seed(0)\",\" Set random seed for reproducibility\\nnp.random.seed(0)\",\" Set random seed for reproducibility\\nnp.random.seed(0)\",\"Set random seed for reproducibility\\nnp.random.seed(0)\",\" Set random seed for reproducibility\\nnp.random.seed(0)\",\"Set random seed for reproducibility\\nnp.random.seed(0)\",\" Set random seed for reproducibility\\nnp.random.seed(0)\"],\"marker\":{\"opacity\":0.5,\"size\":5},\"mode\":\"markers+text\",\"name\":\"59_Setting random seed for reproducibility\",\"text\":[\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\"],\"textfont\":{\"size\":12},\"x\":[32.43060302734375,32.445377349853516,32.30109786987305,32.761165618896484,32.63078689575195,32.094547271728516,31.807403564453125,32.69490432739258,32.09781265258789,32.67265701293945,32.59006118774414,31.645692825317383,32.1412353515625,31.926652908325195,32.310115814208984,32.568294525146484,32.18379592895508,32.243003845214844,32.23027038574219,32.55449295043945,32.24699401855469,32.008602142333984,32.15522766113281,31.685543060302734,32.293479919433594,32.373046875,32.478878021240234,32.243736267089844,32.50189208984375,32.091312408447266,32.31181335449219,32.056270599365234,32.037166595458984,32.16328811645508,31.78811264038086,31.975299835205078,32.67593002319336,32.40864562988281,32.55464172363281],\"y\":[14.226208686828613,14.232354164123535,14.146671295166016,14.633275032043457,14.243759155273438,14.628693580627441,14.776082992553711,14.075785636901855,14.566924095153809,14.68737506866455,14.558796882629395,14.71842098236084,13.788216590881348,14.67795467376709,14.747591972351074,14.525257110595703,14.323404312133789,14.765800476074219,14.214624404907227,14.760272979736328,14.771308898925781,14.627769470214844,14.792393684387207,14.278910636901855,14.697455406188965,14.276999473571777,14.813602447509766,14.776106834411621,14.431392669677734,14.508299827575684,14.592157363891602,14.284341812133789,14.258102416992188,14.344918251037598,14.080315589904785,14.394161224365234,14.561406135559082,14.408828735351562,14.294722557067871],\"type\":\"scattergl\"},{\"hoverinfo\":\"text\",\"hovertext\":[\"# Ensure the data has been imported correctly\\nprint(df_characters.head())\\nprint(df_locations.head())\\nprint(df_script.head())\\nprint(df_episodes.head())\",\"Check the imported data\\nprint(df_characters.head())\\nprint(df_locations.head())\\nprint(df_script.head())\\nprint(df_episodes.head())\",\"Check the imported data\\nprint(\\\"Characters data\\\")\\nprint(df_characters.head())\\nprint(\\\"Locations data\\\")\\nprint(df_locations.head())\\nprint(\\\"Script data\\\")\\nprint(df_script.head())\\nprint(\\\"Episodes data\\\")\\nprint(df_episodes.head())\",\"Check the import content\\nprint(\\\"Characters: \\\", df_characters.head())\\nprint(\\\"Locations: \\\", df_locations.head())\\nprint(\\\"Script: \\\", df_script.head())\\nprint(\\\"Episodes: \\\", df_episodes.head())\",\"Check the data has been loaded correctly\\nprint(df_characters.head())\\nprint(df_locations.head())\\nprint(df_script.head())\\nprint(df_episodes.head())\",\" Some dataframes are too large, and loading them temporarily consume a lot of memory.\\n# print(df_characters.head())\\n# print(df_locations.head())\\n# print(df_script.head())\\n# print(df_episodes.head())\",\"Check the imported dataframes\\nprint(df_characters.head(3))\\nprint(df_locations.head(3))\\nprint(df_script.head(3))\\nprint(df_episodes.head(3))\",\"Check that the data has been properly loaded\\nprint(df_characters.head())\\nprint(df_locations.head())\\nprint(df_script.head())\\nprint(df_episodes.head())\",\"Check that everything is loaded correctly\\nprint(df_characters.head(1))\\nprint(df_locations.head(1))\\nprint(df_script.head(1))\\nprint(df_episodes.head(1))\",\" Ensure reading worked correctly\\nprint(df_characters.head())\\nprint(df_locations.head())\\nprint(df_script.head())\\nprint(df_episodes.head())\",\"Check the files we have\\nprint(\\\"Simpsons characters\\\")\\nprint(df_characters.head())\\nprint(\\\"\\\")\\nprint(\\\"Simpsons locations\\\")\\nprint(df_locations.head())\\nprint(\\\"\\\")\\nprint(\\\"Simpsons script\\\")\\nprint(df_script.head())\\nprint(\\\"\\\")\\nprint(\\\"Simpsons episodes\\\")\\nprint(df_episodes.head())\",\"# Ensure the data has been loaded correctly\\nprint(df_characters.head())\\nprint(df_locations.head())\\nprint(df_script.head())\\nprint(df_episodes.head())\",\"Check to make sure everything was read in properly\\nprint(df_characters.head())\\nprint(df_locations.head())\\nprint(df_script.head())\\nprint(df_episodes.head())\",\"Check the import results\\nprint(df_characters.head())\\nprint(df_locations.head())\\nprint(df_script.head())\\nprint(df_episodes.head())\",\"Check that the data has been read in correctly\\nfor df in [df_characters, df_locations, df_script, df_episodes]:\\n    print(df.head(2))\\n    print('-'*50)\",\"Check whether data has been split correctly\\nprint(df_script.head())\\nprint(df_characters.head())\\nprint(df_locations.head())\\nprint(df_episodes.head())\",\"Check if the data files have been read correctly\\nprint(df_characters.head())\\nprint(df_locations.head())\\nprint(df_script.head())\\nprint(df_episodes.head())\",\"check that data read correctly\\nprint(df_characters.head())\\nprint(df_locations.head())\\nprint(df_script.head())\\nprint(df_episodes.head())\",\"Encode the text data to UTF-8 to handle any special characters\\ndf_characters = df_characters.apply(lambda x: x.astype(str).str.encode('utf-8', errors='ignore').str.decode('utf-8'))\\ndf_locations = df_locations.apply(lambda x: x.astype(str).str.encode('utf-8', errors='ignore').str.decode('utf-8'))\\ndf_script = df_script.apply(lambda x: x.astype(str).str.encode('utf-8', errors='ignore').str.decode('utf-8'))\\ndf_episodes = df_episodes.apply(lambda x: x.astype(str).str.encode('utf-8', errors='ignore').str.decode('utf-8'))\",\"Check if the data loaded properly\\nprint(df_characters.head())\\nprint(df_locations.head())\\nprint(df_script.head())\\nprint(df_episodes.head())\",\"Check if the data loaded correctly\\nprint(\\\"Characters\\\")\\ndisplay(df_characters.head(2))\\nprint(\\\"Locations\\\")\\ndisplay(df_locations.head(2))\\nprint(\\\"Script\\\")\\ndisplay(df_script.head(2))\\nprint(\\\"Episodes\\\")\\ndisplay(df_episodes.head(2))\",\"Check the imported dataframes\\nprint(\\\"Characters\\\")\\nprint(df_characters.head())\\nprint(\\\"Locations\\\")\\nprint(df_locations.head())\\nprint(\\\"Script\\\")\\nprint(df_script.head())\\nprint(\\\"Episodes\\\")\\nprint(df_episodes.head())\",\"Check that the imports worked\\nprint(df_characters.head())\\nprint(df_locations.head())\\nprint(df_script.head())\\nprint(df_episodes.head())\",\"Check if the data loaded properly\\nprint(df_characters.head())\\nprint(df_locations.head())\\nprint(df_script.head())\",\"Checking that the data was in fact loaded\\nprint(df_characters.head())\\nprint(df_locations.head())\\nprint(df_script.head())\\nprint(df_episodes.head())\",\"Check the dataframes to see that everything is as expected\\nprint(df_characters.head(5))\\nprint(df_locations.head(5))\\nprint(df_script.head(5))\\nprint(df_episodes.head(5))\",\"Check dataframes loaded correctly\\nprint(df_characters.head())\\nprint(df_locations.head())\\nprint(df_episodes.head())\\nprint(df_script.head())\",\"Check if the data has been loaded correctly\\nprint(df_characters.head())\\nprint(df_locations.head())\\nprint(df_script.head())\\nprint(df_episodes.head())\",\"Ensure that the paths to the data files are correct\\nfor df in [df_characters, df_locations, df_script, df_episodes]:\\n    print(os.path.exists(df))\",\"Check that everything was loaded correctly\\nprint(df_characters.head())\\nprint(df_locations.head())\\nprint(df_script.head())\\nprint(df_episodes.head())\",\"Checking whether the data was loaded correctly\\nprint(df_characters.head())\\nprint(df_locations.head())\\nprint(df_script.head())\\nprint(df_episodes.head())\",\"Check if loaded correctly\\nprint(df_characters)\\nprint(df_locations)\\nprint(df_script)\\nprint(df_episodes)\",\"Check that the data has been loaded correctly\\nprint(df_characters.head())\\nprint(df_locations.head())\\nprint(df_script.head())\\nprint(df_episodes.head())\",\"Prints to make sure everything is working properly.\\nprint(df_characters.head())\\nprint(df_locations.head())\\nprint(df_script.head())\\nprint(df_episodes.head())\",\"Check data read correctly\\nprint(df_characters.head())\\nprint(df_locations.head())\\nprint(df_script.head())\\nprint(df_episodes.head())\",\"Ensure you're using the correct data types\\ndf_characters.info()\\ndf_locations.info()\\ndf_script.info()\\ndf_episodes.info()\",\"Checking that the data has been loaded correctly\\nprint('Characters')\\ndisplay(df_characters)\\nprint('Locations')\\ndisplay(df_locations)\\nprint('Script')\\ndisplay(df_script)\\nprint('Episodes')\\ndisplay(df_episodes)\",\"Check that the data has been loaded correctly\\nprint(df_characters.sample(5))\\nprint(df_locations.sample(5))\\nprint(df_script.sample(5))\\nprint(df_episodes.sample(5))\",\"Check that data has been loaded correctly\\nprint(df_characters.head())\\nprint(df_locations.head())\\nprint(df_script.head())\\nprint(df_episodes.head())\"],\"marker\":{\"opacity\":0.5,\"size\":5},\"mode\":\"markers+text\",\"name\":\"60_Checking Data Loading\",\"text\":[\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\"],\"textfont\":{\"size\":12},\"x\":[-1.6791292428970337,-1.5662851333618164,-1.4549353122711182,-1.8099654912948608,-2.3125216960906982,-2.2316172122955322,-1.8574059009552002,-2.053659200668335,-1.9877680540084839,-1.9338918924331665,-1.5071169137954712,-1.9059228897094727,-2.1449766159057617,-1.906856894493103,-1.8564645051956177,-2.1024296283721924,-2.5426416397094727,-2.443521738052368,-1.6505353450775146,-2.0512218475341797,-2.1234965324401855,-1.650363564491272,-1.8180875778198242,-2.265249729156494,-2.194744825363159,-2.0476138591766357,-1.9996525049209595,-2.5093069076538086,-2.309457778930664,-1.9996204376220703,-2.613140821456909,-2.63783597946167,-2.062615156173706,-1.7575148344039917,-1.9529451131820679,-2.38981032371521,-2.3808481693267822,-2.484692096710205,-2.123088836669922],\"y\":[0.776931643486023,0.5682710409164429,0.526119589805603,0.9991512894630432,0.7416665554046631,0.7626150846481323,0.6868782043457031,0.4517901539802551,0.39242666959762573,0.4290897846221924,1.2760668992996216,1.110924482345581,0.711745023727417,0.6819756627082825,0.4174489676952362,0.8408636450767517,0.16228140890598297,0.4536355435848236,0.8263655304908752,0.6491729021072388,1.3931578397750854,0.6808066964149475,0.1928485631942749,1.023606777191162,0.8604363799095154,0.9723626971244812,0.9622378945350647,0.5800372958183289,0.133716881275177,0.21568986773490906,1.087041974067688,0.7668299078941345,0.6569889783859253,0.5992869734764099,0.7847009897232056,0.4364683926105499,1.001210331916809,0.44822484254837036,0.6192994713783264],\"type\":\"scattergl\"},{\"hoverinfo\":\"text\",\"hovertext\":[\"Create a new column 'raw_character_text' in df_script that contains the character's text as it is.\",\"Convert raw_text to string\\ndf_script['raw_text'] = df_script['raw_text'].astype(str)\",\"Set locations to lowercase\\ndf_script['raw_location'] = df_script['raw_location'].str.lower()\",\"Convert 'raw_text' column to string type to avoid merge incompatibility later on\\ndf_script['raw_text'] = df_script['raw_text'].astype(str)\",\"Remove recurring spaces and drop duplicates\\ndf_script['normalized_text'] = df_script.raw_text.str.lower().str.replace(r\\\"\\\\s+\\\", \\\" \\\").str.strip()\\ndf_script = df_script.drop_duplicates('normalized_text')\",\"Strip leading\\u002ftrailing whitespaces in text\\n\\ndf_script['raw_text'] = df_script['raw_text'].str.strip()\",\"Create lowercase 'raw_text' column in df_script\\ndf_script['raw_text'] = df_script['raw_text'].apply(lambda x: x.lower())\",\"Extract the 'raw_text' from 'df_script' DataFrame and convert it to a list\",\"Converts raw text into dataframes.\",\"Ensure all scripts are in the same format (remove leading\\u002ftrailing whitespace, convert to lowercase, remove brackets and their contents)\\n\\ndf_script['raw_text'] = df_script['raw_text'].str.strip()\\ndf_script['raw_text'] = df_script['raw_text'].str.lower()\\ndf_script['raw_text'] = df_script['raw_text'].str.replace(r\\\"\\\\(.*\\\\)\\\", \\\"\\\")\",\" Remove the newline and tab tokens from script\\ndf_script['normalized_text'] = df_script['normalized_text'].str.replace('\\\\n', ' ')\\ndf_script['normalized_text'] = df_script['normalized_text'].str.replace('  ', ' ')\",\"Starting with basic text preproceessing on 'raw_text' in 'df_script'.\",\"Generate new column that concatenates raw_text and normalized_text\\ndf_script['raw_and_normalized_text'] = df_script['raw_text'] + ' ' + df_script['normalized_text']\",\" Remove special characters from raw lines in script\\ndf_script['raw_character_text'] = df_script['raw_character_text'].str.replace(r'\\\\r+|\\\\n+|\\\\t+','', regex=True)\",\" Remove punctuation and lowercase all text\\ndf_script['normalized_text'] = df_script['raw_text'].str.replace('[^\\\\w\\\\s]','').str.lower()\",\"Set scripts to lower case\\ndf_script['raw_text_lc'] = df_script.raw_text.str.lower()\",\"# Fix errors and clean character names\\ndf_characters['name'] = df_characters['name'].apply(lambda x: x.strip().replace('-', ' ').replace('_', ' '))\\ndf_script['normalized_text'] = df_script['normalized_text'].apply(lambda x: x.strip().replace('-', ' ').replace('_', ' '))\",\"# Frequent regex replacements\\ndf_script['raw_text'] = df_script['raw_text'].str.replace(r'-', ' ', regex=True)\",\"Create a column for the script\\ndf_script['text'] = df_script['normalized_text'].str.lower()\",\"Replace all newline characters with \\u003cbr\\u003e and cache the pre-processed script\\ndf_script.raw_text = df_script.raw_text.str.replace('\\\\n', '\\u003cbr\\u003e')\",\"']]['raw_text'] = df_script['raw_text'].str.replace('[^\\\\w\\\\s]','')\",\"Put all the text data into lowercase\\ndf_script['normalized_text'] = df_script['raw_text'].apply(lambda x: x.lower())\",\"Create a text variable for the script\\nscript = \\\" \\\".join(df_script.raw_text)\",\" Extracting the text for analysis\\nscript = df_script['raw_text'].to_list()\",\"Remove leading\\u002ftrailing whitespaces from scripts\\ndf_script['raw_text'] = df_script['raw_text'].apply(lambda x: x.strip())\",\"Clean the text in the 'raw_text' column by removing extra spaces and converting to lowercase\\ndf_script['clean_text'] = df_script['raw_text'].str.replace('\\\\'', ' ').str.lower().str.replace('[^a-z ]', '')\\ndf_script['clean_text'] = df_script['clean_text'].str.replace(' +', ' ')\",\"Convert to lower case\\ndf_script = df_script.apply(lambda x: x.astype(str).str.lower())\",\" Unnest the raw script, as largely used by DrQA's datasets and readers\\ndf_script_unnested = (df_script['raw_character_text']\\n .str.split(';', expand=True)\\n .stack()\\n .reset_index(level=0)\\n .set_index('level_0')\\n .rename(columns={0:'raw_character_text'})\\n)\\ndf_script_unnested.index.name = 'index'\\ndf_script_unnested['raw_character_text'] = df_script_unnested['raw_character_text'].str.strip()\",\" Remove newlines and leading\\u002ftrailing whitespaces from character_short column\\ndf_script['character_short'] = df_script['character_short'].str.strip().str.replace(r'\\\\n', '')\",\"Remove punctuation and lowercase the text\\ndf_script['normalized_text'] = df_script['raw_text'].str.replace('[^\\\\w\\\\s]','').str.lower()\",\"# There is a known wrong character in the dataset\\ndf_script['raw_character_text'] = df_script['raw_character_text'].str.replace('docter', 'doctor')\\n\\n# Lower case for character names and locations\\ndf_characters['character_name'] = df_characters['character_name'].str.lower()\\ndf_locations['raw_location_text'] = df_locations['raw_location_text'].str.lower()\\ndf_script['raw_character_text'] = df_script['raw_character_text'].str.lower()\\ndf_script['raw_location_text'] = df_script['raw_location_text'].str.lower()\",\" Extract only the first and second part of each script\\ndf_script['part'] = df_script.apply(lambda x: x['raw_text'].split(' | ')[0], axis=1)\",\"Convert text to lower case\\ndf_script['raw_text'] = df_script['raw_text'].str.lower()\",\"Create a lower case version\\ndf_script['normalized_text'] = df_script['raw_text'].str.lower()\",\"Create the 'raw_text' field\\ndf_script['raw_text'] = df_script['normalized_text'].str.replace('\\\\r\\\\n', ' ').str.lower()\",\"Remove unwanted characters\\ncharacters_to_remove = ['(', ')', '[', ']', '\\\\\\\"', '\\\\'', '\\\\`']\\nfor c in characters_to_remove:\\n    df_script['raw_character_text'] = df_script['raw_character_text'].str.replace(c, '')\\n\\n# Lowercase the character names\\ndf_script['raw_character_text'] = df_script['raw_character_text'].str.lower()\",\"Remove apostrophes\\ndf_script_normalized = df_script\\ndf_script_normalized['normalized_text'] = df_script_normalized['normalized_text'].str.replace(\\\"'\\\", \\\"\\\")\",\" Remove punctuation from 'raw_text' feature in the 'df_script' DataFrame\\ndf_script['raw_text'] = df_script['raw_text'].str.replace('[^\\\\w\\\\s]','')\",\"Remove special values and characters from the 'raw_text' column of the script dataframe\\ndf_script['raw_text'] = df_script['raw_text'].str.replace('-', ' ')\\ndf_script['raw_text'] = df_script['raw_text'].str.replace('\\\\.\\\\.\\\\.', ' ')\"],\"marker\":{\"opacity\":0.5,\"size\":5},\"mode\":\"markers+text\",\"name\":\"61_Text preprocessing and cleaning techniques using Python and pandas\",\"text\":[\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\"],\"textfont\":{\"size\":12},\"x\":[6.457821846008301,6.65964412689209,5.8498358726501465,6.897541046142578,6.88016939163208,6.825691223144531,6.69600772857666,5.984645843505859,6.365423679351807,6.319680213928223,7.0597686767578125,6.419796466827393,6.932551383972168,6.659270286560059,6.778679847717285,6.368213653564453,6.229098320007324,6.167535781860352,6.665454387664795,7.249652862548828,6.323946475982666,6.589338302612305,6.043493270874023,5.608638763427734,6.505185127258301,6.5341362953186035,6.873495101928711,6.133548736572266,7.09357213973999,6.695156097412109,5.3964033126831055,5.1949591636657715,6.939053058624268,7.033497333526611,6.875370025634766,6.183206558227539,6.711818218231201,6.89279317855835,6.260565757751465],\"y\":[9.923591613769531,9.038835525512695,9.052698135375977,9.030988693237305,9.465694427490234,8.849357604980469,9.093013763427734,8.237201690673828,9.098244667053223,9.493978500366211,9.40112590789795,8.696834564208984,8.05300521850586,9.242830276489258,9.662556648254395,8.9647216796875,9.260082244873047,9.376387596130371,8.618449211120605,8.852354049682617,9.201088905334473,8.744879722595215,7.389055252075195,7.826805114746094,8.724213600158691,9.765660285949707,8.856768608093262,8.706172943115234,8.869670867919922,9.600800514221191,8.821366310119629,7.4644455909729,8.90938663482666,8.875450134277344,9.199831008911133,9.360631942749023,9.753687858581543,9.438797950744629,9.61305046081543],\"type\":\"scattergl\"},{\"hoverinfo\":\"text\",\"hovertext\":[\"Check the number of rows of each DataFrame\",\"Determine the number of records in each of the dataframes.\",\"Check the first few rows of each data frame\",\"Check the first few rows of each dataframe\",\" Verify the number of rows for each dataframe\",\"Check the first entries of each DataFrame\",\"Inspecting the first few rows of each DataFrame\",\"Checking the first few rows of each dataframe\",\"Limit the dataframe only to the first column\",\"Checking the first few rows of the dataframe for visual inspection\",\" Check the first few rows of each dataframe\",\"Looking at the first few records of each dataframe\",\"Check that the file in each DataFrame are ordered in the same way as the corresponding IDs\",\"Check the first rows of each DataFrame to understand what I'm dealing with\",\" Checking the number of rows in each dataframe\",\"Extract first `n` records from each dataframe\",\"Checking the first rows for the script dataframe.\",\"Checking the first few rows of each dataframe\",\"Checking the first entry of each dataframe\",\"Check the first few rows of each dataframe to get an understanding of the data\",\"Check the first few rows of each dataframe to understand how the data is structured\",\"Check basic informations (for instance, the first rows) of each dataframe\",\"Check the first rows for each dataframe\",\"Checking first few rows of each dataframe.\",\" Visual check of the first rows of the dataframes\",\" Checking the first few rows of each DataFrame to understand the data\",\" Check the content of the first DataFrame\",\" Check the first few rows of each DataFrame\",\" Checking the first few rows of the script dataframe\",\"Check the shape and the first rows of each DataFrame\",\"Check the first few lines of each dataframe\",\"Looking at the first rows of each dataframe\",\"Find the number of rows for each dataframe\",\"Check the first dataframes rows\",\" Check all dataframe's first entries to have an idea of their columns and data\",\"Checking out the first few rows of each dataframe\",\"Check the first few rows of each dataframe to understand the data\",\"Checking the first few rows of DataFrame.\",\"Check the first few lines of each dataframe\"],\"marker\":{\"opacity\":0.5,\"size\":5},\"mode\":\"markers+text\",\"name\":\"62_Checking the First Few Rows of Each DataFrame for Understanding and Verification\",\"text\":[\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\"],\"textfont\":{\"size\":12},\"x\":[12.427407264709473,11.686169624328613,12.49282169342041,12.564705848693848,12.368399620056152,12.249168395996094,12.839768409729004,12.669808387756348,12.032624244689941,12.452862739562988,12.669726371765137,12.728976249694824,7.136024475097656,12.535697937011719,12.220144271850586,13.035553932189941,12.153757095336914,12.329851150512695,11.87804889678955,12.957064628601074,12.892618179321289,12.992908477783203,12.335710525512695,12.264726638793945,12.383477210998535,12.767401695251465,11.22921371459961,12.671295166015625,12.279908180236816,12.34835433959961,12.707275390625,12.384848594665527,11.96112060546875,12.111831665039062,12.560070991516113,12.498257637023926,12.795807838439941,12.485763549804688,12.902875900268555],\"y\":[-6.108978748321533,-5.67487907409668,-5.968267917633057,-6.761633396148682,-6.217940330505371,-6.311218738555908,-7.491508483886719,-6.373892307281494,-5.486801624298096,-6.740137577056885,-6.784916400909424,-7.885965347290039,0.10105220228433609,-6.341213703155518,-5.922259330749512,-8.030623435974121,-5.688318252563477,-6.46572732925415,-5.882345676422119,-6.992048263549805,-6.717426776885986,-6.572890281677246,-6.476093292236328,-6.4837646484375,-6.428190231323242,-6.337735652923584,-4.996685028076172,-6.678287506103516,-5.667212963104248,-5.87697172164917,-7.220124244689941,-7.174245834350586,-6.123039722442627,-5.996644020080566,-6.101694583892822,-6.881056308746338,-6.710640907287598,-6.164538383483887,-7.176046848297119],\"type\":\"scattergl\"},{\"hoverinfo\":\"text\",\"hovertext\":[\"# Download and load the spacy model\\n!python -m spacy download en_core_web_sm\",\"spacy.cli.download(\\\"en_core_web_sm\\\")\",\"rake is a Python implementation of the BLAST protein alignment algorithm.\\n\\n# Usage:\\n# pip install biopython\\n# python -m pip install biopython\\n\\n# Import BLAST tools\\nfrom Bio.Blast import NCBIWWW, NCBIXML\",\"Language model\\nimport spacy\\n\\n# Download the language model\\n!python -m spacy download en_core_web_sm\",\"Download spacy model\\npython -m spacy download en_core_web_md\",\"Enable or download spacy English language model\\n# !python -m spacy download en \",\" Required if you get errors that the 'en' model was not found\\n# !python -m spacy download en\",\"!python -m spacy download en_core_web_sm\",\"Install spacy models\\n!python -m spacy download en_core_web_sm\",\"Download 'en_core_web_md' before starting\\nspacy.cli.download(\\\"en_core_web_md\\\")\",\"get request parameters\\nrequest_args = request.args\",\" Installs the en_core_web_sm model for spaCy\",\"Install the French model for spaCy if not present\\nif 'fr_core_news_sm' not in spacy.util.get_installed_models():\\n    !python -m spacy download fr_core_news_sm\",\" Download the SpaCy model for English if not already downloaded\\npython -m spacy download en\",\"View the installed spaCy models\\n!python -m spacy validate\",\"download \\\"en_core_web_md\\\" model to make sure benchmarks are reproducible\\n!python -m spacy download en_core_web_md\",\"Check if the package is installed properly\\npackage_name = 'spacy'\\ntry:\\n    __import__(package_name)\\nexcept ImportError:\\n    print(f'{package_name} is not installed properly. Please re-install the package and try again.')\",\" Download 'en_core_web_sm'\\n!python -m spacy download en_core_web_sm\",\"# Install language model and dictionary for Enlgish\\n!python -m spacy download en\",\" Install the 'en_core_web_sm' model of spaCy\\n!python -m spacy download en_core_web_sm\",\"ensure we're using the correct version of spacy for compatibility\\n!pip install spacy==3.0.6\",\"Download the spacy model\\n! python -m spacy download en_core_web_sm\",\" #\\u00a0Install spaCy languages\\n!python -m spacy download en_core_web_sm\",\"Limpar dados desnecess\\u00e1rios\",\"Enable or download the following models by running:\\n# !python -m spacy download en_core_web_sm\\n# !python -m spacy download en_core_web_md\",\"ModuleNotFoundError: No module named 'spacy'\\n# Install spacy by typing it into the anaconda terminal\\n# pip install -U spacy\",\" Enable the Levenshtein's measure for Bratko-Klic's algorithm\\n# Note: Requires installing the jellyfish package\\nos.system('pip install jellyfish')\\nimport jellyfish\",\"Install textual analysis library and the the language model for English\\n!python -m spacy download en\",\"Optional: install spacy language model\\n!python -m spacy download en_core_web_sm\",\"Install spacy language model for NER\\n!python -m spacy download en_core_web_sm\",\"! python -m spacy download en_core_web_md\",\"Install spaCy language model\\n!python -m spacy download en\",\" Voc\\u00eas tamb\\u00e9m precisar\\u00e3o fazer o download do modelo de l\\u00edngua inglesa do spaCy. Voc\\u00ea pode fazer isso executando o seguinte comando no terminal ou prompt de comando:\\n\\npython -m spacy download en\",\" Install the standard model (en_core_web_sm) in case it's not installed\\n!python -m spacy download en_core_web_sm\",\"Install missing dependencies for spacy\\n!python -m spacy download en_core_web_sm\",\"Download Spacy English model\\n!python -m spacy download en\",\" conda install -c conda-forge spacy\",\"Download `en` model from spacy if not already in cache\\ntry:\\n    _ = spacy.load('en')\\nexcept OSError:\\n    _ = spacy.cli.download('en')\",\"Install spaCy models\\n!python -m spacy download en_core_web_sm\"],\"marker\":{\"opacity\":0.5,\"size\":5},\"mode\":\"markers+text\",\"name\":\"63_SpaCy model installation and download using Python\",\"text\":[\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\"],\"textfont\":{\"size\":12},\"x\":[16.61798858642578,17.196369171142578,15.815980911254883,15.77065372467041,16.797922134399414,15.590470314025879,16.12801170349121,16.847185134887695,16.429418563842773,17.113292694091797,17.19656753540039,16.5408878326416,16.323997497558594,15.72236442565918,16.101337432861328,16.722997665405273,15.75405216217041,17.143779754638672,16.000703811645508,16.587505340576172,16.501813888549805,16.54607391357422,16.183277130126953,14.201560974121094,16.510263442993164,16.073543548583984,15.934922218322754,15.724776268005371,15.919354438781738,15.974334716796875,16.86297607421875,15.987236976623535,15.409761428833008,16.896324157714844,16.03798484802246,15.878495216369629,16.42547035217285,16.37091064453125,16.62274932861328],\"y\":[6.025078296661377,6.247669219970703,5.577268123626709,6.106354236602783,6.254739761352539,5.927750110626221,5.560107707977295,5.933647632598877,5.944357395172119,6.090778350830078,6.753813743591309,5.801571846008301,6.043481826782227,5.717205047607422,5.346482753753662,6.349379539489746,5.921930313110352,6.110905647277832,6.306760311126709,6.00344181060791,6.4783220291137695,5.708595275878906,6.267420768737793,3.2691755294799805,6.226867198944092,6.127774715423584,6.272557258605957,5.667203426361084,5.941243648529053,6.538832664489746,6.2234697341918945,5.9784979820251465,5.047797203063965,6.037099838256836,5.671360492706299,5.749452590942383,6.475192546844482,5.884483337402344,6.05042839050293],\"type\":\"scattergl\"},{\"hoverinfo\":\"text\",\"hovertext\":[\"Check the contents of the characters dataframe.\",\"Start by looking at the first few rows of the characters DataFrame.\",\"We'll look at the character and location dataframes first.\",\" Let's take a look at the first few rows of the characters dataframe.\",\"Inspect the characters dataframe.\",\"Let's see the first entries of the characters dataframe.\",\"Look at the first few rows of the characters dataframe.\",\"Look at the first 3 rows of the characters dataframe and check if there are missing values\",\"Inspect the structure of the characters DataFrame.\",\"Inspect the data types and missing values of the characters dataframe.\",\" Let's have a look at the first few rows of the characters dataframe.\",\"Let's have a look at the characters dataframe.\",\" Let's analyze the structure of the dataframe characters.\",\"A quick peak into the character dataframe\",\"Let's take a look at the first few lines of the characters and locations DataFrames.\",\"Let's take a look at the characters DataFrame.\",\" Display the characters and locations DataFrames\",\"Let's first display general info about the characters dataframe (e.g. no of entries, no of columns, columns names, data types, and memory usage).\",\"Let's check the contents of the characters dataframe.\",\" Let's look at the structure of the characters DataFrame.\",\"We can now have a look at the characters and locations dataframes.\",\"Inspecting the Characters data frame.\",\"Check the content of the characters dataframe.\",\" Look at the first 5 rows of the characters dataframe.\",\"Let's check how the characters dataframe looks like.\",\" Let's check the structure of the character dataframe.\",\"Let's take a look at the first 5 rows of the characters dataframe.\",\"Now it's time to explore the data. Let's start by inspecting the first few rows of the characters dataframe.\",\"Take a peek at the first 5 lines of the characters dataframe.\",\"Let's take a look at the first few rows of the characters dataframe to understand its structure.\",\"Let's check what the characters dataframe looks like.\",\"Inspect the contents of the characters DataFrame.\",\"Let's take a look at the characters dataframe.\",\"Inspect the DataFrame containing information about the characters.\",\"A quick view at both characters and locations dataframe\",\"Inspect the characters dataframe.\",\"Let's have a look at the first few rows of the characters dataframe.\",\"Let's start by taking a look at the first few rows of the characters dataframe.\",\"Quick look at the characters dataframe\"],\"marker\":{\"opacity\":0.5,\"size\":5},\"mode\":\"markers+text\",\"name\":\"64_Inspecting Characters Dataframe\",\"text\":[\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\"],\"textfont\":{\"size\":12},\"x\":[9.42365837097168,9.198859214782715,9.466574668884277,9.920368194580078,9.085854530334473,9.241987228393555,9.59837818145752,9.382999420166016,9.273334503173828,8.772741317749023,9.684764862060547,9.740488052368164,9.57009220123291,9.44812297821045,9.625691413879395,9.658949851989746,7.9820332527160645,8.914578437805176,9.875761032104492,9.721765518188477,9.299003601074219,9.577987670898438,9.636411666870117,9.79189682006836,9.963165283203125,10.251851081848145,9.5971040725708,9.73454761505127,10.012572288513184,10.033915519714355,10.0368013381958,9.12169075012207,9.94831371307373,9.396544456481934,8.5241060256958,9.249013900756836,9.899121284484863,9.704842567443848,8.831542015075684],\"y\":[11.811844825744629,11.201746940612793,9.283239364624023,10.621103286743164,11.620381355285645,11.29350471496582,10.873164176940918,11.647847175598145,11.328289031982422,11.541409492492676,10.696471214294434,10.085413932800293,10.652458190917969,11.58337688446045,8.762014389038086,9.950177192687988,9.422100067138672,11.703633308410645,11.286874771118164,10.23757266998291,8.330366134643555,10.954604148864746,12.020398139953613,11.099528312683105,10.699868202209473,10.791202545166016,10.76372241973877,10.67199993133545,10.401944160461426,10.504465103149414,10.86543083190918,11.804788589477539,9.756877899169922,11.321810722351074,9.238076210021973,11.782657623291016,10.692018508911133,10.555977821350098,11.852884292602539],\"type\":\"scattergl\"},{\"hoverinfo\":\"text\",\"hovertext\":[\"Setting up environment for plot\\nmatplotlib.rcParams['figure.figsize'] = [20, 10]\\nnlp = spacy.load('en_core_web_sm')\",\" Set the default figure size for matplotlib plots\\nmatplotlib.rcParams['figure.figsize'] = (15, 10)\",\"Plot parameters\\nfontsize = 15\\nfigsize = (15, 8)\",\"Show big pictures\\nmatplotlib.rcParams['figure.figsize'] = [40, 20]\",\"set the plot size for all the upcoming notebook\\nplt.rcParams['figure.figsize'] = [10, 5]\",\"sns.set(style=\\\"whitegrid\\\")\\nplt.figure(figsize=(8,5))\",\" Set up the figure and axis\\nfig, (ax1, ax2) = plt.subplots(1, 2, figsize=(20, 10))\",\" Set the size of the graphs\\nmatplotlib.rcParams['figure.figsize'] = (10, 5)\",\"Optional: use larger font size and set the default figure size\\nplt.rcParams.update({'font.size': 22, 'figure.figsize': (10, 8)})\",\"# Jupyter scatter plot size\\nmatplotlib.rcParams['figure.figsize'] = (10.0, 6.0)\",\" inline matplotlib\\nmatplotlib.rcParams['figure.figsize'] = (13, 7)\",\"reate a new plot\\nplt.figure( figsize=(20,10) )\",\"Use this to render graphs. Filter to \\\"x11\\\" if it doesn't render.plt.gca().get_figure_manager().window.showMaximized()\",\"Set the default figure size for matplotlib to (14,7)\\nmatplotlib.rcParams['figure.figsize'] = (14, 7)\",\"Leave this cell to display images in notebook\\nmatplotlib.rcParams['figure.figsize'] = (10, 10)\",\"matplotlib.rcParams['figure.figsize'] = (10, 7)\",\"Ensure matplotlib is correctly enabled in Jupyter notebooks\\nmatplotlib.rcParams['figure.figsize'] = [10, 5]\",\" Visual settings\\nmatplotlib.rcParams['figure.figsize'] = [10, 5]\\nmatplotlib.rcParams['figure.dpi'] = 200\",\" graphical preferences\\nmatplotlib.rcParams['figure.figsize'] = (10.0, 5.0)\",\"Visualize the correlation matrix of the dataset\\nmatplotlib.rcParams['figure.figsize'] = [12, 7]\\nmatplotlib.rcParams['figure.dpi'] = 80\\ncorrelation_matrix = df_script.corr()\\nplt.imshow(correlation_matrix, cmap='hot', interpolation='nearest')\\nplt.colorbar()\\nplt.title('Correlation matrix')\\nplt.show()\",\"Set plot size\\nmatplotlib.rcParams['figure.figsize'] = [10, 7]\",\"Setup Matplotlib\\nmatplotlib.rcParams['figure.figsize'] = (10, 6)  # Use bigger plots\",\"Setting the figure sizes\\nmatplotlib.rcParams['figure.figsize'] = (20, 15)\",\"Set figure size\\nplt.rcParams[\\\"figure.figsize\\\"] = [15, 6]\",\"Rescale the large image for easier viewing.\\nplt.figure(figsize=(12, 12))\\nplt.imshow(img, interpolation='nearest')\\nplt.axis('off')\\nplt.show()\",\"Visualization settings\\nmatplotlib.rcParams['figure.figsize'] = (10, 5)\\n\\n# Load the spaCy model\\nnlp = spacy.load('en')\",\" General plotting settings\\nmatplotlib.rcParams['figure.figsize'] = [10, 5]\\nmatplotlib.rcParams['figure.dpi'] = 80\",\"Show matplotlib plots\\nmatplotlib.rcParams['figure.figsize'] = (12, 12)\",\"Set up matplotlib\\nmatplotlib.rcParams['figure.figsize'] = [10, 5]\",\"matplotlib.rcParams['figure.figsize'] = [12, 8]\",\"# General configuration\\npd.set_option('display.max_columns', 100)\\npd.set_option('display.max_colwidth', 1000)\\nmatplotlib.rcParams['figure.figsize'] = (10.0, 5.0)\",\"Set figure size for all matplotlib figures\\nmatplotlib.rcParams['figure.figsize'] = [10, 5]\",\"# Data Visualization Setup\\nplt.style.use('fivethirtyeight')\\nplt.rcParams[\\\"figure.figsize\\\"] = (14,7)\",\"Set up figure size\\nmatplotlib.rcParams['figure.figsize'] = (10, 10)\",\"Set the default plot size for matplotlib for better visibility\",\"Create a subplot\\nfig, ax = plt.subplots(nrows=1, ncols=1, figsize=(13, 20))\",\"set(base linewidth for matplotlib)\\nmatplotlib.rcParams['lines.linewidth'] = 1.0\",\"Adjust size of plots in the notebook\\nplt.rcParams['figure.figsize'] = [15, 8]\"],\"marker\":{\"opacity\":0.5,\"size\":5},\"mode\":\"markers+text\",\"name\":\"65_matplotlib figures and sizes\",\"text\":[\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\"],\"textfont\":{\"size\":12},\"x\":[19.584144592285156,19.81386947631836,20.32040023803711,19.46949005126953,19.744558334350586,19.89392852783203,19.594505310058594,19.593379974365234,20.385704040527344,19.390722274780273,19.795024871826172,19.721473693847656,19.957138061523438,19.748044967651367,19.345407485961914,19.387563705444336,19.369068145751953,19.394989013671875,19.456676483154297,19.64797019958496,19.193296432495117,19.67215347290039,19.737415313720703,20.00614356994629,19.632787704467773,19.05997657775879,19.684206008911133,19.72713279724121,19.32837677001953,19.297163009643555,19.96938133239746,19.519088745117188,19.893474578857422,19.513399124145508,19.6126708984375,19.437223434448242,19.46986961364746,19.995384216308594],\"y\":[6.952796936035156,6.835124969482422,7.506413459777832,7.28658390045166,6.557328224182129,6.3797502517700195,6.332533359527588,6.887729167938232,6.635431289672852,6.500288009643555,7.377148628234863,6.677799224853516,6.3765869140625,7.111027717590332,6.758097171783447,7.23350715637207,6.145308017730713,6.972296714782715,6.801797866821289,6.084070682525635,6.817231178283691,6.685113430023193,7.246731281280518,6.975810527801514,6.952038288116455,6.672847270965576,6.853226661682129,6.78941535949707,6.904745101928711,7.3502197265625,6.53993558883667,7.0126519203186035,6.892078399658203,7.246325969696045,6.061252593994141,6.822967052459717,7.241033554077148,6.868173599243164],\"type\":\"scattergl\"},{\"hoverinfo\":\"text\",\"hovertext\":[\"Define the main directory path where the datasets are located\",\" Paths\\ndataset_name = 'thesimpsons'\\nsaved_path = f'..\\u002fDatasets\\u002f{dataset_name}\\u002f'\",\"te: replace 'data\\u002f' with the correct path if the data files are not located in the 'data' subdirectory.\",\" Data files\\nos.listdir('data')\",\"Optional: If you are using Google Colab and your storage has a folder called 'gdrive', you are able to read the files from 'data\\u002f' through there, given the fact that the data folder is directly inside 'gdrive'.\",\"To use Google Colab's data from Google Drive\\nfrom google.colab import drive\\ndrive.mount('\\u002fcontent\\u002fdrive')\",\"Creatign a path for the assets folder\",\"Set path to local data as the data folder is not in the working directory\",\" Data folder path\\ndata_folder = 'data\\u002f'\",\"Optional line if 'data' folder is not in the same as the script and '(df_characters...)' is commented out\\nbasepath = 'data\\u002f'\",\"Add your data directory to the path\\ndata_path = '.\\u002fdata'\",\"Set a path to the data directory.\",\"Look for file\\nos.listdir('data')\",\"Data directory\\nDATA_DIR = 'data'\",\"Set path to data dir\\nDATA_DIR = 'data\\u002f'\",\"Setting up the data directory path\\ndata_dirpath = \\\"data\\\"\",\" define data path\\ndata_path = 'data'\",\"Check if working directory contains data files\\nprint(os.listdir('data'))\",\"Ensure the correct path for the data folder is set by running the code below:\\nos.path.abspath('data')\",\"Optional exploration - SysCall\\nos.system(\\\"\\u002fbin\\u002fls -lh\\\")\",\"# Change the input path here\\ninput_path = \\\"data\\\"\",\"Create a variable with the file name to easily reference and open it\",\"Remove the data folder and create a clean data folder\",\"Check the folder structure and contents to see if data sets have been loaded successfully\\nos.listdir('data')\",\"# Set data folder\\ndata_folder = 'data\\u002f'\",\"data directories\\nos.listdir(\\\"data\\u002f\\\")\",\"Check                               filenames\\nfor eachfilename in os.listdir('data'):\\n    print(eachfilename)\",\"Check for the presence of the 'data' directory\",\"Extract the data path\\ndata_path = 'data\\u002f'\",\"Connect to Google Drive to save\\u002fload data\\nfrom google.colab import drive\\ndrive.mount('\\u002fcontent\\u002fdrive')\",\"Create global variables for data directory and files\\nDATA_DIR = \\\"data\\\"\",\"Check if files are present\\nos.listdir(\\\"data\\\")\",\"Define the path of the data directory\",\"ndata_folders = ['data_copy', 'data_clean']\",\"define MAIN_DIR\\nMAIN_DIR = 'data'\",\" Look at directory contents\\n!ls data\",\"Set and display the top level directory for data assets\",\"Browse files in the data directory\\nos.listdir('data')\"],\"marker\":{\"opacity\":0.5,\"size\":5},\"mode\":\"markers+text\",\"name\":\"66_Setting the Path to Local Data in the Working Directory\",\"text\":[\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\"],\"textfont\":{\"size\":12},\"x\":[16.062482833862305,16.338642120361328,16.04958724975586,16.056583404541016,16.085268020629883,15.735825538635254,16.37799644470215,16.25884246826172,16.426660537719727,16.05524253845215,16.320432662963867,16.197965621948242,15.615660667419434,16.523649215698242,16.717100143432617,16.464048385620117,16.554624557495117,15.518452644348145,15.916708946228027,15.561436653137207,16.525468826293945,14.60007095336914,15.853404998779297,15.68867301940918,16.547168731689453,15.990097999572754,15.595462799072266,15.740923881530762,16.8210506439209,15.89653205871582,15.631197929382324,15.416078567504883,16.587800979614258,16.888566970825195,16.23059844970703,15.451640129089355,16.77884292602539,15.889044761657715],\"y\":[3.1063575744628906,2.8820691108703613,2.2564845085144043,2.7707693576812744,2.3114726543426514,2.2397327423095703,3.318902015686035,2.662095308303833,2.3834431171417236,1.791763424873352,2.643781900405884,2.8497347831726074,2.829826593399048,2.3464701175689697,2.4841744899749756,2.446030616760254,2.4411239624023438,2.6191134452819824,2.87475848197937,3.0091114044189453,2.4708402156829834,2.4323067665100098,2.5049145221710205,2.979886054992676,2.2351479530334473,3.0637311935424805,2.5312891006469727,2.448840379714966,2.8135170936584473,2.5958499908447266,2.3325018882751465,2.7244763374328613,2.651254177093506,2.333740711212158,2.5501058101654053,2.201531171798706,2.817958116531372,3.0385074615478516],\"type\":\"scattergl\"},{\"hoverinfo\":\"text\",\"hovertext\":[\" Display the first 5 rows of each DataFrame\\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()\",\" Visualize the first 5 rows of each dataframe\\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()\",\"display first 5 rows of each dataframe\\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()\",\"Display the first 5 rows of each dataframe to inspect their contents\\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()\",\"Display the first five rows of each dataframe\\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()\",\" Display the first 5 rows of each dataframe\\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()\",\" Display first 5 records from all dataframes\\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()\",\"Display first 5 rows of each DataFrame\\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()\",\" Display the first 5 rows of each dataframe\\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()\",\"\\n# Display the first 5 records of each dataframe to get an initial feel for the data\\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()\",\"Display the first 5 rows of each dataframe to understand its structure\\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()\",\" Output the first 5 rows of each dataframe to understand the data structure\\ndf_characters.head(5), df_locations.head(5), df_script.head(5), df_episodes.head(5)\",\" Display the first 5 rows of each DataFrame\\ndf_episodes.head(), df_characters.head(), df_locations.head(), df_script.head()\",\"Display the first 5 rows of each of the 4 DataFrames\\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()\",\" Display the first 5 rows of each DataFrame\\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()\",\"Display the first 5 rows of each dataframe\\ndf_script.head(), df_characters.head(), df_locations.head(), df_episodes.head()\",\"Display the first 5 rows of each dataframe to understand the data better\\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()\",\"\\n# Display the first 5 rows of each dataframe to understand its structure\\ndf_characters.head(), df_locations.head(), df_episodes.head(), df_script.head()\",\"Display the first 5 rows of the dataframes to inspect them\\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()\",\"Display the first 5 rows of each dataframe to understand their structure\\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()\",\"Display the first 5 rows of each dataframe\\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()\",\" Display the first 5 rows of each DataFrame\\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()\",\"Display first 5 rows of each dataframe\\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()\",\"Display first 5 rows of each dataframe\\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()\",\"display first 5 rows of each dataframe\\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()\",\" Display the first 5 rows of each dataframe\\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()\",\"Display the first 5 rows of each dataframe\\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()\",\"Display the first 5 rows of each DataFrame\\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()\",\"# Display the first 5 rows of the characters dataframe\\ndf_episodes.head()\",\"Display the first 5 rows of each dataframe\\ndisplay(df_characters.head(), df_locations.head(), df_script.head(), df_episodes.head())\",\" Display the first five rows of each dataframe.\\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()\",\"# Display the first 5 rows of each dataframe\\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()\",\"Display the first 5 rows of each dataframe\\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()\",\"Display the first 5 rows of each dataframe to understand its structure\\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()\",\"Show the first 5 rows of each of these dataframes to understand better what data is available in them\\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()\",\"Display the first 5 rows of each dataframe\\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()\",\"Display the first 5 rows of each dataframe\\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()\",\" Display the first 5 rows of the dataframes\\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()\"],\"marker\":{\"opacity\":0.5,\"size\":5},\"mode\":\"markers+text\",\"name\":\"67_Displaying first 5 rows of each dataframe to understand their structure and initial data records\",\"text\":[\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\"],\"textfont\":{\"size\":12},\"x\":[-1.7278556823730469,-2.21586537361145,-1.5310367345809937,-2.406494140625,-1.3084663152694702,-1.7762494087219238,-1.4729210138320923,-1.6996372938156128,-1.7945243120193481,-1.1068975925445557,-2.6052258014678955,-2.7065374851226807,-1.235022783279419,-1.4592719078063965,-1.362317442893982,-1.677320122718811,-2.1862025260925293,-2.4726507663726807,-2.4607198238372803,-2.50642728805542,-1.4061585664749146,-1.5951400995254517,-1.6116235256195068,-1.6091139316558838,-1.566965937614441,-1.4278570413589478,-1.5799100399017334,-1.8404691219329834,-0.7182384133338928,-1.6318010091781616,-1.4564071893692017,-1.337769627571106,-1.3944941759109497,-2.401416301727295,-2.524622678756714,-1.614896297454834,-1.4912354946136475,-1.7987778186798096],\"y\":[8.224812507629395,7.739753723144531,8.370863914489746,7.7050347328186035,7.786684513092041,8.012425422668457,8.294266700744629,8.635202407836914,8.2813720703125,7.800567626953125,7.0989089012146,6.885069370269775,7.733851432800293,8.20251178741455,8.093833923339844,7.768216133117676,7.876264572143555,6.875454902648926,7.539729118347168,7.198027610778809,8.16396427154541,8.070035934448242,8.543679237365723,8.552657127380371,8.469653129577637,7.918786525726318,7.981912136077881,7.972923278808594,6.8483805656433105,7.591723918914795,7.731717586517334,7.605307102203369,8.436371803283691,7.325934410095215,6.964156150817871,8.289958953857422,7.976806163787842,8.13857650756836],\"type\":\"scattergl\"},{\"hoverinfo\":\"text\",\"hovertext\":[\"Display all columns of a dataframe\\npd.set_option('display.max_columns', None)\",\" Display the first rows of the dataframe\\npd.set_option('display.max_columns', None)\",\"Display output of all the lines in the dataframe\\npd.set_option('display.max_rows', None)\",\"Display all dataframe columns\\npd.set_option('display.max_columns', None)\",\"# Show entire dataframes in printed output\\npd.set_option('display.max_columns', None)\\npd.set_option('display.max_rows', None)\",\"Display all columns in dataframes\\npd.set_option('display.max_columns', None)\",\"Display all the columns of the dataframe\\npd.set_option('display.max_columns', None)\",\"Display all columns for the script dataframe\\npd.set_option('display.max_columns', None)\\ndf_script.head()\",\"Display some lines from the main dataframe\\nwith pd.option_context(\\\"display.max_rows\\\", 3, \\\"display.max_columns\\\", 6):\\n    display(df_script.head(2))\",\"Display all columns of the script dataframe to visualise what information is available\\npd.set_option('display.max_columns', None)\\ndf_script.head()\",\"Setting to display all columns in the dataframe\\npd.set_option('display.max_columns', None)\",\"Display all columns of the dataframe\\npd.set_option('display.max_columns', None)\",\"Display all the columns in the dataframes\\npd.options.display.max_columns = None\",\"Display all columns and the first 5 rows\\nwith pd.option_context('display.max_columns', None):\\n    display(df_script.head())\",\"Display all columns (handy when dealing with large DataFrames)\\npd.set_option('display.max_columns', None)\",\" Set output to display all columns in a dataframe\\npd.set_option('display.max_columns', None)\",\"Show all columns for DataFrame\\npd.set_option('display.max_columns', None)\",\"Display maximum columns when showing the dataframe\\npd.set_option('display.max_columns', None)\",\"Displaying all columns in the dataframe\\npd.set_option('display.max_columns', None)\",\" Display all columns of the dataframe\\npd.set_option('display.max_columns', None)\\n# Display all rows of the dataframe\\npd.set_option('display.max_rows', None)\",\"Display for DataFrame\\npd.options.display.max_columns = None\",\"Show all script lines\\npd.set_option('display.max_colwidth', -1)\\ndf_script.head()\",\"to display all columns in the dataframes\\npd.set_option('display.max_columns', None)\",\"# Display all dataframe columns\\npd.set_option('display.max_columns', None)\",\"Display all columns for each dataframe\\npd.set_option('display.max_columns', None)\",\"Display all columns from the script DataFrame\\npd.set_option('display.max_columns', None)\",\"Some initial configurations\\npd.options.display.max_columns = None  # Shows all columns when printing the dataframe\",\" Display all columns of the dataframe\\npd.set_option('display.max_columns', None)\",\"Display all columns of the dataframe\\npd.set_option('display.max_columns', None)\",\"Display all the columns of the df_script dataframe\\npd.set_option('display.max_columns', None)\\ndf_script.head()\",\"Display all columns in dataframe\\npd.set_option('display.max_columns', None)\",\"Display option to show all columns when displaying dataframe\\npd.set_option('display.max_columns', None)\",\"Show all columns of each dataframe for easy access\\npd.set_option('display.max_columns', None)\",\"Display all columns of the dataframes\\npd.set_option('display.max_columns', None)\",\"Display all columns of the dataframes\\npd.set_option('display.max_columns', None)\",\"Display all columns in the dataframes\\npd.set_option('display.max_columns', None)\",\" Show all columns for the script dataframe\\npd.set_option('display.max_columns', None)\\npd.set_option('display.width', None)\"],\"marker\":{\"opacity\":0.5,\"size\":5},\"mode\":\"markers+text\",\"name\":\"68_Displaying All Columns in DataFrames\",\"text\":[\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\"],\"textfont\":{\"size\":12},\"x\":[20.882692337036133,21.560686111450195,21.52802276611328,21.2393798828125,21.366666793823242,20.912065505981445,21.503067016601562,21.367380142211914,21.291061401367188,21.583515167236328,21.475236892700195,21.126676559448242,21.35284996032715,21.922405242919922,21.678871154785156,20.72643280029297,21.05711555480957,21.806194305419922,21.13212776184082,21.160541534423828,20.917016983032227,22.26430320739746,21.559175491333008,21.641883850097656,20.66283416748047,21.10220718383789,21.650236129760742,21.16411781311035,21.212539672851562,21.308815002441406,21.068574905395508,20.892885208129883,20.875377655029297,21.087244033813477,20.970083236694336,21.201597213745117,21.452367782592773],\"y\":[-0.9270766377449036,-0.7361519932746887,-0.47188079357147217,-0.5695235729217529,0.0375710166990757,-0.5351744294166565,-0.6882880330085754,-0.02401208132505417,-0.03033648431301117,-0.29648661613464355,-0.23653532564640045,-0.7774057984352112,-0.33706164360046387,-0.22181639075279236,-0.16239169239997864,-0.5631957650184631,-0.33401811122894287,-0.49414342641830444,-0.5272144079208374,-0.17060434818267822,-0.8806605935096741,0.7749148011207581,-0.2958887219429016,-0.492218554019928,-0.41512399911880493,-0.4905616343021393,-0.2662654221057892,-0.9342459440231323,-0.8208261132240295,0.007773657329380512,-0.410287082195282,-0.6252732276916504,-0.038349393755197525,-0.508271336555481,-0.3763267695903778,-0.5654769539833069,0.30721062421798706],\"type\":\"scattergl\"},{\"hoverinfo\":\"text\",\"hovertext\":[\"Checking the first few rows of the characters dataframe.\",\"Check the character data first few rows\",\"Checking the first few rows of the characters dataframe to understand the data\",\" Check first few rows of 'df_characters' DataFrame\",\" Checking the first few rows of the characters dataframe.\",\"Inspecting the first rows of the characters dataframe\",\"Look at the first few rows of the characters dataframe\",\"Inspecting the first few records of the characters dataframe.\",\"Checking the first few rows of the characters data frame\",\"Check the first rows of the characters dataframe.\",\"Check the first few rows of the characters dataframe.\",\"Check the first rows of the characters dataframe\",\"Check the first few rows of the dataframe for characters.\",\" Check the first lines of the \\\"Characters\\\" dataframe\",\"Checking the first few rows of the characters dataframe\",\"Check the first 10 rows of the characters dataframe\",\" Checking the first few rows of the characters dataframe.\",\"Check first 3 rows of characters dataset\",\"Inspecting the first few rows of the characters dataframe.\",\"Check the first few rows of the characters DataFrame.\",\" Check the first few rows of the characters dataframe\",\"Checking the first few rows of the characters dataframe\",\"Inspecting first 3 rows of the characters DataFrame to understand the data\",\"Check the first few rows of the characters data frame\",\"Checking the first few rows of the characters dataframe\",\"Inspecting first few entries of `df_characters` DataFrame\",\"Checking the first few entries of the characters dataframe\",\" Checking the shape and the first entries of the characters dataframe\",\"Inspect the first 3 records of the characters dataframe\",\"Checking the first few rows of the characters dataframe\",\"Check a few rows of characters dataframe\",\"Check the first few rows of the characters data\",\"Inspect the first few entries of the characters dataframe\",\" Checking the first few rows of the characters dataframe\",\"check the first few lines of the characters dataframe\",\"Check the first few rows of the characters DataFrame\",\"Get first rows of the character dataframe\"],\"marker\":{\"opacity\":0.5,\"size\":5},\"mode\":\"markers+text\",\"name\":\"69_Inspecting First Few Rows of Characters Dataframe\",\"text\":[\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\"],\"textfont\":{\"size\":12},\"x\":[10.50864028930664,10.770980834960938,10.61121654510498,9.496203422546387,10.327014923095703,10.098763465881348,9.793718338012695,9.821124076843262,10.649405479431152,10.204010963439941,10.042797088623047,10.40900707244873,10.203191757202148,10.700946807861328,10.732756614685059,10.43332290649414,10.626641273498535,10.719687461853027,9.60627555847168,10.238051414489746,10.733332633972168,10.441387176513672,9.884191513061523,10.811697959899902,10.801546096801758,8.658689498901367,10.20620346069336,10.375251770019531,9.980929374694824,10.651496887207031,10.561728477478027,10.747671127319336,9.532249450683594,10.546831130981445,10.866031646728516,10.40326976776123,9.786614418029785],\"y\":[12.273233413696289,10.139751434326172,12.356884956359863,12.780943870544434,12.178367614746094,12.58183479309082,12.391533851623535,12.577788352966309,11.292943000793457,11.953962326049805,12.177154541015625,11.939544677734375,12.164128303527832,12.035453796386719,12.310708045959473,12.08858585357666,11.95827579498291,10.698835372924805,12.506534576416016,12.152515411376953,11.696351051330566,11.786338806152344,12.525527954101562,11.265066146850586,11.845856666564941,13.400681495666504,12.506173133850098,12.265963554382324,12.582572937011719,12.17940616607666,12.151908874511719,9.983657836914062,12.752184867858887,12.064576148986816,11.72432804107666,11.759052276611328,12.64627742767334],\"type\":\"scattergl\"},{\"hoverinfo\":\"text\",\"hovertext\":[\"Inspect the Characters dataframe\",\"Check the content of the dataframe of the characters\",\"Inspect characters dataframe\",\"Checking the structure of the characters dataframe\",\" Explore data - characters dataframe\",\" Explore the characters DataFrame\",\"Check the structure and dtypes of the character dataframe\",\"Checking the contents of the character dataframe\",\"Inspect the contents of the characters dataframe\",\"Check character dataframe\",\"Inspect the dataframe with the characters\",\" Exploring the characters dataframe\",\"Inspect the content of the `characters` dataframe\",\"Inspect dataframe for characters\",\"Inspect one of the dataframes (e.g. characters)\",\"Check the character dataframe\",\"Join dataframe to retrieve character's information\",\"Inspect the characters dataframe\",\"Inspection of the characters DataFrame\",\"Print out the Characters dataframe, note that this will return a huge table that might be slow to render\",\"View the structure of the characters dataframe\",\" Check the data from the characters dataframe\",\"Inspect the content of the characters dataframe\",\"Inspecting the characters dataframe\",\"Check basic info on characters and locations dataframe\",\"Inspect the structure of the characters DataFrame\",\"Inspect the structure of the characters data frame\",\"Inspecting the characters dataframe\",\"Checking the characters dataframe\",\" View the characters dataframe\",\"View the characters dataframe\",\"Checking the content of the characters dataframe\",\"Inspect the characters dataframe\",\"Inspecting the characters dataframe\",\"Examine the structure of the characters DataFrame\",\"Inspect the characters DataFrame\",\"Inspect the characters dataframe\"],\"marker\":{\"opacity\":0.5,\"size\":5},\"mode\":\"markers+text\",\"name\":\"70_Inspecting Characters DataFrame\",\"text\":[\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\"],\"textfont\":{\"size\":12},\"x\":[8.338890075683594,7.894205093383789,8.70333480834961,8.47362232208252,8.400975227355957,8.357034683227539,8.5504732131958,7.899231433868408,8.15046501159668,7.826694011688232,8.710350036621094,8.700607299804688,8.279435157775879,8.830009460449219,8.48591423034668,8.058377265930176,8.019495010375977,8.514809608459473,8.256784439086914,8.517154693603516,8.877249717712402,7.887796878814697,8.562024116516113,8.265174865722656,7.9822516441345215,9.070008277893066,9.191720008850098,8.425798416137695,7.728480339050293,8.173206329345703,8.51060962677002,7.834527492523193,8.50521183013916,8.1802978515625,8.977020263671875,8.623285293579102,8.409399032592773],\"y\":[11.967757225036621,11.321012496948242,12.201253890991211,11.370869636535645,11.845512390136719,11.650723457336426,11.461333274841309,11.258990287780762,12.113365173339844,11.453107833862305,12.251338958740234,11.408177375793457,12.51573657989502,12.175222396850586,12.412423133850098,11.406275749206543,11.114632606506348,11.817266464233398,11.746221542358398,11.645546913146973,11.86683464050293,11.037632942199707,12.090213775634766,11.68492317199707,10.25896167755127,11.302700996398926,11.168944358825684,11.686553955078125,11.365904808044434,12.096288681030273,11.784900665283203,11.159967422485352,12.164945602416992,11.601274490356445,11.11004638671875,12.085393905639648,12.078544616699219],\"type\":\"scattergl\"},{\"hoverinfo\":\"text\",\"hovertext\":[\" nlp = spacy.load('en')\",\" Dictionary to store tokenized documents\\ntokenized_documents = {}\\n\\n# Load spacy models\\nnlp = spacy.load('en')\",\"Create an English language class\\nnlp = spacy.load('en')\",\"Optionally for spacy\\nnlp = spacy.load('en')\",\" Set the `nlp` variable to the SpaCy model for English and disable parsing\\nnlp = spacy.load('en', disable=['parser'])\",\"Enable the 'en' module if there's no model loaded\\nif not 'nlp' in locals():\\n    print(\\\"Loading English module...\\\")\\n    nlp = spacy.load('en')\",\"Setup Spacy\\nnlp = spacy.blank('en')\",\"Load Spacy's English language models\\nnlp = spacy.load('en')\",\"Load the trained English tokenizer, tagger, parser, NER and word vectors\",\"For numerical method and manipulations\\nfrom scipy.optimize import minimize\\n\\n# Natural Language Processing\\nimport spacy\\nnlp = spacy.load('en')\",\"Define ufoc\\nUFOC = spacy.blank('en')\",\"Create an object of class 'spacy.lang.en.English' and name it 'nlp'.\",\"Load spacy model\\nnlp = spacy.load('en')\",\"Global variable:\\nnlp = spacy.load('en')\",\"Load spacy model\\nnlp = spacy.load('en')\",\"# Load spacy pre-trained model\\nnlp = spacy.load('en')\",\"Function to load pre-trained English NER model from spacy and apply it to a string\",\"Set up spaCy\\nnlp = spacy.load('en')\",\"Load spacy model to get word embeddings\",\"Enable or download the spacy module by running the command below in the terminal:\\n# python -m spacy download en\\nimport spacy\\nnlp = spacy.load(\\\"en\\\")\",\"Set up spacy\\nnlp = spacy.blank(\\\"en\\\")\",\"Init spacy\\nnlp = spacy.load('en')\",\"Proranpdopting for NLP for both character and location names to handle misspellings and sense\\nnlp = spacy.load(\\\"en_core_web_md\\\")\",\"Set up Spacy\\nnlp = spacy.load('en')\",\"Load the custom NLP pipeline\\nnlp = spacy.load('simpsons')\",\" Inicializa spaCy\\nnlp = spacy.load('en')\",\"setup spacy\\nnlp = spacy.load('en')\",\" Load the pre-built NLP model - spacy.load('en')\",\"Declare the path to the word embeddings from Spacy\",\" Load the Spacy pre-trained model for English language\\nnlp = spacy.load('en')\",\"Loading pre-trained English tokenizer, tagger, parser, NER and word vectors\\nnlp = spacy.load('en')\",\"english pipeline\\nnlp = spacy.blank(\\\"id\\\")\",\"# Set up the spacy model for preprocessing\\nnlp = spacy.load('en')\",\"Setting up Spacy\\nnlp = spacy.load('en')\",\"BERT model\\nnlp = spacy.load('en_trf_bertbaseuncased_lg')\"],\"marker\":{\"opacity\":0.5,\"size\":5},\"mode\":\"markers+text\",\"name\":\"71_Loading Spacy's English language model\",\"text\":[\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\"],\"textfont\":{\"size\":12},\"x\":[15.991878509521484,15.129495620727539,15.734408378601074,15.709443092346191,14.984345436096191,15.362373352050781,15.639384269714355,15.456704139709473,14.543993949890137,15.280348777770996,15.95877456665039,15.178030967712402,15.670808792114258,15.59482192993164,15.870148658752441,15.705090522766113,15.300813674926758,15.803205490112305,15.04196548461914,15.539009094238281,15.597834587097168,16.063701629638672,16.053428649902344,15.61539077758789,15.40898323059082,15.763875007629395,15.82623291015625,15.62419319152832,15.155757904052734,15.291337966918945,15.224015235900879,16.053438186645508,15.338362693786621,15.467960357666016,15.595281600952148],\"y\":[7.208773136138916,7.618193626403809,6.849852085113525,7.394243240356445,7.414340972900391,7.422755241394043,7.326460838317871,7.039181232452393,6.990739822387695,7.4243268966674805,7.548670768737793,6.7516303062438965,7.27786922454834,7.04081916809082,7.452914714813232,7.6307501792907715,7.498314380645752,7.063572883605957,7.773372650146484,7.0409016609191895,7.33116340637207,7.152633190155029,7.307089328765869,7.278883457183838,7.421642780303955,6.58275842666626,7.186563014984131,7.433906078338623,7.345640182495117,7.53912878036499,7.236217498779297,7.661019325256348,7.538403511047363,7.075535774230957,7.751138687133789],\"type\":\"scattergl\"},{\"hoverinfo\":\"text\",\"hovertext\":[\"\\n\",\")\",\"(.....continues on)\",\" Remove unclosed parentheses in the code and join it together with backslashes\",\"It is not clear what the next steps are in the code, as the provided code seems to be incomplete.\",\"change the password to your student's ID number\\npassword = 123456789\",\"60*'#'\",\" Rest of the code is not provided.\",\"I'm sorry, but I cannot execute this code as it is. I can only provide code completions and extensions.\",\"Code not available for this cell.\",\"Coding as per the companion's request.\",\" To be continued...\",\"to magnetic IDE...\",\"\\n# CONFIGURATION\\n#\",\"```\",\"Code to be continued...\",\"Just continue the code from the last line\",\"Leave the rest of the code as is\",\"to be continued...\",\"# Code continues...\",\"Since the error is regarding the format the above code is correct.\",\"In[2]:\",\"Code completion not necessary.\",\" What's the complete code?\",\"#API KEY not available for the moment. Hidden away for running purposes.\\nSPOTIFY_API_KEY = '123456789abcdefghijklmnopqrstuvwxyz'\",\"tag::pre_requisites[]\",\"\\n\",\"Code complete.\",\"main()\",\"I am skipping generated example code because it is too long.\",\"Tying a newline character at the end of this code causes the error or the format to be changed. Therefore, I will end it here.\",\"I am not able to provide the next part of the code as it seems to be referencing external data and files that I do not have access to.\",\".*.\",\"Is there an error in the original code?\",\" Visual Studio code extension is used for easy live program completion.\"],\"marker\":{\"opacity\":0.5,\"size\":5},\"mode\":\"markers+text\",\"name\":\"72_Incomplete code and missing references\",\"text\":[\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\"],\"textfont\":{\"size\":12},\"x\":[13.020367622375488,13.14573860168457,13.803272247314453,11.339685440063477,13.064044952392578,12.831473350524902,13.121179580688477,12.692340850830078,12.997091293334961,12.912694931030273,13.077089309692383,13.939080238342285,14.536310195922852,13.765397071838379,12.790642738342285,13.2886381149292,12.171957015991211,12.594696044921875,14.012255668640137,13.249664306640625,12.443346977233887,12.826835632324219,13.084575653076172,12.820024490356445,13.040234565734863,13.70356273651123,12.86023998260498,12.896315574645996,13.433311462402344,12.653314590454102,11.562372207641602,13.567562103271484,13.28121280670166,12.331242561340332,13.262022972106934],\"y\":[3.3212852478027344,3.3850791454315186,3.09977650642395,4.917477130889893,4.115906238555908,4.411777496337891,3.2973124980926514,3.72277569770813,3.6358273029327393,3.63826322555542,3.0316572189331055,2.908987283706665,2.150113105773926,2.305323600769043,3.8802809715270996,3.391268730163574,4.035017013549805,3.956468105316162,2.9537465572357178,3.181697130203247,3.8113651275634766,3.0870890617370605,3.7149555683135986,3.760531187057495,4.482713222503662,3.943671226501465,3.0851519107818604,3.6771492958068848,3.4404585361480713,3.8438217639923096,4.497103214263916,3.716191530227661,3.201622486114502,3.87473201751709,3.2893714904785156],\"type\":\"scattergl\"},{\"hoverinfo\":\"text\",\"hovertext\":[\"Checking the data shapes\",\"Checking the structure of the various datasets\",\"Visually inspect initial dataset shapes and feature names\",\"Inspecting the content of the datasets.\",\" Checking how each of the dataset looks like\",\"Displaying the 3 datasets per quick check.\",\"Checking a few stats about the datasets\",\"Inspect the datasets to understand their structure and contents.\",\" Check the result and the shape.\",\"Check the shape of the datasets\",\"Checking the general structure of the datasets\",\"Inspect the structure of the datasets\",\"Inspect the structure of the datasets\",\"Inspecting each of the datasets\",\"Inspect the structure and data types of the datasets\",\"Inspect the structure of the datasets.\",\"Inspecting the data shapes\",\"Checking the data shape and the headers\",\"Checking the data in the datasets\",\" Quick inspection of each data set\",\"Check the overview of each dataset\",\"Inspecting datasets\",\"Check the content of these datasets\",\"Checking the structure of the four datasets\",\" Checking contents of the dataset\",\"TODO: Examine dataset shapes and column names\",\"Inspect the datasets\",\"Try to print the shapes of the acquired datasets to get a feeling of the data\",\"Check the information contained in the transformed datasets\",\"Check the shape of the datasets\",\"Inspect datasets\",\"Quick inspection of the data sets to understand their structure and content\",\"Checking the heads of the datasets to better understand their structure.\",\"Checking the datasets\",\" Add some basic checks to the dataset\"],\"marker\":{\"opacity\":0.5,\"size\":5},\"mode\":\"markers+text\",\"name\":\"73_Dataset Inspection and Shape Checking\",\"text\":[\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\"],\"textfont\":{\"size\":12},\"x\":[13.51076602935791,14.623939514160156,14.467580795288086,14.694133758544922,14.523094177246094,14.611101150512695,14.76365852355957,15.075471878051758,14.133383750915527,13.911760330200195,14.948443412780762,14.580533027648926,14.418522834777832,14.246987342834473,14.818197250366211,14.830151557922363,14.009764671325684,13.333620071411133,14.086044311523438,14.855857849121094,14.465832710266113,14.902708053588867,14.625077247619629,14.778486251831055,14.434090614318848,14.112166404724121,14.982269287109375,14.437026977539062,14.251180648803711,14.135400772094727,15.093530654907227,14.923004150390625,14.903349876403809,14.500978469848633,14.322694778442383],\"y\":[-2.072535514831543,-1.802114486694336,-1.7110012769699097,-1.9430872201919556,-1.501499056816101,-2.252902030944824,-1.941264033317566,-1.7594579458236694,-1.310049295425415,-1.6609082221984863,-2.098674774169922,-1.7604475021362305,-2.1239750385284424,-1.8972854614257812,-2.1284987926483154,-2.0775060653686523,-1.6472904682159424,-1.6537641286849976,-1.1332666873931885,-1.1322073936462402,-2.1251304149627686,-1.6629431247711182,-1.795783519744873,-2.4487860202789307,-1.2165549993515015,-1.2747857570648193,-1.7660472393035889,-2.3049161434173584,-1.3533436059951782,-1.6977211236953735,-1.2535676956176758,-1.496746301651001,-2.5623056888580322,-1.4688560962677002,-1.3979650735855103],\"type\":\"scattergl\"},{\"hoverinfo\":\"text\",\"hovertext\":[\"Let's check what the scripts DataFrame looks like.\",\" Let's have a look at the structure of the script dataframe.\",\" Preprocess script lines dataframe\",\"Checking the script dataframe\",\" The script contains four dataframes, each corresponding to a table in the original database.\",\"Check the columns that we currently have in the script dataframe\",\"Change script lines dataframe in order to fasten operations\",\"Inspect the structure of the raw DataFrame for script lines.\",\"Let's check a basic description of the script dataframe.\",\"Inspect script dataframe\",\"Check the script dataframe\",\"Look at what we have in the script DataFrame\",\"Checking the first couple of scripts in the Simpsons DataFrame\",\"I will start analyzing the script data. Specifically, I will begin by examining the contents of the `df_script` DataFrame.\",\"Creating a dummy script dataframe for the splash screen\",\" In order to analyse the script, we will load the data into a dataframe for easier querying\",\"Find out which scripts are in our dataframe\",\"We'll start by taking a look at the first few rows of the script lines dataframe to understand its structure and the kind of data it contains.\",\"Let's see the first few characters of the script dataframe.\",\" Let's take a look at the first five rows of the script lines dataframe.\",\" Check the structure of the dataframe containing the script lines.\",\"Check the content of the script DataFrame\",\"Get relevant features from scripts dataframe\",\"Check some lines of the script DataFrame\",\"Inspect the script dataframe to understand its structure and the kind of information it contains.\",\"We will look into script dataframe first.\",\"Let's see how the script lines dataframe look like.\",\"We'll be using the df_script dataframe to analyze the script lines.\",\"Inspect the dataframe about the script lines\",\"For this demo we will work with the script lines dataframe.\",\"Inspect the content of the script dataframe to understand its structure and content.\",\"Inspect the script dataframe\",\"Check the script dataframe\",\"Inspect the first 3 lines of the dataframe containing the script lines.\",\"Check what's in the word script dataframe\"],\"marker\":{\"opacity\":0.5,\"size\":5},\"mode\":\"markers+text\",\"name\":\"74_Data Analysis of Script Documents\",\"text\":[\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\"],\"textfont\":{\"size\":12},\"x\":[8.763154029846191,8.461596488952637,7.837610244750977,8.765888214111328,8.340291976928711,8.619721412658691,7.599264621734619,8.23562240600586,8.124557495117188,8.726274490356445,9.029590606689453,8.696370124816895,8.926785469055176,8.349047660827637,7.81620454788208,8.221611022949219,8.505167007446289,8.469945907592773,8.61265754699707,8.793556213378906,8.613912582397461,8.593764305114746,8.303863525390625,8.699260711669922,8.57182502746582,8.628608703613281,8.215556144714355,7.967004776000977,8.290027618408203,8.396445274353027,8.096128463745117,8.239007949829102,8.565079689025879,8.44033432006836,8.694278717041016],\"y\":[-2.5892481803894043,-3.201796293258667,-2.4813272953033447,-2.742488145828247,-1.892434000968933,-1.9165022373199463,-2.217242956161499,-3.169255018234253,-3.172572135925293,-3.152639865875244,-2.608088970184326,-3.0616533756256104,-1.8191543817520142,-3.026193618774414,-3.587738275527954,-3.165374755859375,-2.8085968494415283,-2.874122381210327,-3.1572988033294678,-3.107395887374878,-2.808803081512451,-2.9405078887939453,-2.7170801162719727,-2.6445531845092773,-3.394573211669922,-4.511107921600342,-2.776231527328491,-3.415682077407837,-3.2412803173065186,-3.708070993423462,-3.6356728076934814,-3.0131027698516846,-2.5114142894744873,-3.0460774898529053,-2.19919753074646],\"type\":\"scattergl\"},{\"hoverinfo\":\"text\",\"hovertext\":[\"Check the data content\",\"Check the data a bit\",\"Inspection of the data.\",\"Check what the data looks like\",\"Check point 1\",\"Checking what the data looks like\",\"Inspect the data\",\"Checking the main data and the amont of data\",\"Check the data and its structure before performing any analysis\",\"Check a random sample to see all the columns\",\"Inspect the data samples.\",\"Check the data, its type and a few rows\",\" Multiple lines of code to explore and analyze the data will go here.\",\"Check data samples\",\"Checking data first.\",\" Data inspection\",\"Inspect the data files\",\"Inspect the data\",\"Inspect and verify datasests\",\"Display available data\",\"Check the data to take the appropriate action if needed\",\"Inspect the data\",\"Inspect the data\",\"Check the input data\",\"check the available data\",\"Add what data are available\",\"Data Inspection\",\"Check how the data looks like\",\"Data inspection\",\"Checking the data samples\",\"Inspect and process the data\",\"Inspect DataSource\",\"Inspect data\",\"Inspecting the data\",\"Inspecting the data...\"],\"marker\":{\"opacity\":0.5,\"size\":5},\"mode\":\"markers+text\",\"name\":\"75_Data Inspection\",\"text\":[\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\"],\"textfont\":{\"size\":12},\"x\":[14.47757339477539,14.772595405578613,15.1054048538208,14.515429496765137,14.477218627929688,14.220394134521484,15.32759952545166,14.454239845275879,14.679716110229492,10.91087818145752,14.776727676391602,11.687018394470215,14.459278106689453,14.16053295135498,14.889786720275879,14.847465515136719,15.249436378479004,15.258759498596191,14.834771156311035,14.507938385009766,14.184319496154785,15.261998176574707,15.356274604797363,14.409749984741211,15.207457542419434,15.159293174743652,14.771512031555176,15.170515060424805,15.042160987854004,13.900178909301758,14.46868896484375,15.343777656555176,14.845535278320312,14.90565299987793,15.376163482666016],\"y\":[-0.4328339993953705,-0.1563359797000885,0.6629483699798584,0.05603447183966637,-0.6066752672195435,-0.5333916544914246,0.3389054536819458,-0.5507423877716064,-0.42820292711257935,-1.3725850582122803,0.28555208444595337,-0.7275973558425903,0.6515222191810608,-0.29032832384109497,-0.028097346425056458,0.4672733247280121,0.7393960356712341,0.08762335032224655,0.5938212275505066,-0.9614415764808655,0.10819603502750397,0.21261243522167206,0.44754916429519653,0.08557639271020889,-0.3414600193500519,-0.64189612865448,0.3803904950618744,-0.20026707649230957,-0.08761627227067947,-0.34971722960472107,0.5625091791152954,-0.1122853010892868,0.07116598635911942,-0.17818619310855865,0.37956953048706055],\"type\":\"scattergl\"},{\"hoverinfo\":\"text\",\"hovertext\":[\"Split text lines into tokens using spaCy\\nnlp = spacy.load('en_core_web_sm', disable=['ner', 'parser'])\",\"Create spaCy pipeline\\nnlp = spacy.load('en_core_web_sm', disable=['ner', 'parser'])\",\" Optionally, ensure compatibility with spaCy by disabling components that we don't need\\nnlp = spacy.load('en_core_web_sm', disable=['ner', 'parser'])\",\"define a tokenizer function using spacy\\nnlp = spacy.load(\\\"en_core_web_sm\\\")\\ndef spacy_tokenizer(sentence):\\n    return [word.lemma_ for word in nlp(sentence) \\n            if not (word.is_space or word.is_punct or word.is_stop)]\",\"# Setting up the NLP pipeline\\nnlp = spacy.load(\\\"en_core_web_sm\\\", disable=[\\\"ner\\\", \\\"parser\\\"])\",\" Load pre-trained spacy word vectors\\nnlp = spacy.load('en_core_web_md', disable=['tagger', 'parser', 'ner'])\",\"Parser to extract entities in a consistent manner.\\nnlp = spacy.load('en_core_web_sm', disable=['ner', 'textcat'])\",\" Initialize spacy 'en' model, keeping only tagger component needed for lemmatization\\nnlp = spacy.load('en', disable=['parser', 'ner'])\",\"\\\"\\n# Set the global parameters\\nglobal_params = {\\n    'REPLACE_NAME': 'Nat',\\n    'REPLACE_LOCATION': 'Boston',\\n    'DEFAULT_SUB': 'PERSON',\\n    'PLOT_FILENAME': 'nat_cloud.png',\\n    'NLP_MODEL': 'en_core_web_sm',\\n    'NLP_REGEX_RULE_PREFIX': '-',\\n    'NLP_REGEX_RULE_INFIX': '@',\\n    'POS_NAMES': ['NOUN', 'PROPN', 'ADJ']\\n}\",\" Text processing tools\\nnlp = spacy.load('en', disable=['parser', 'ner'])\",\" Optional: add spaCy language model for tokenization\\nnlp = spacy.load('en_core_web_sm', disable=['parser', 'ner'])\",\"Create the NLP model\\nnlp = spacy.load('en_core_web_sm', disable=['parser', 'ner'])\",\"Initialize spacy\\nnlp = spacy.load('en_core_web_sm', disable=['parser', 'tagger', 'ner'])\",\"# Set to initial variables.\\ncharacters_vocab = None\\nword_to_ix = None\",\"Setup spaCy\\nnlp = spacy.load('en_core_web_sm', disable=['parser', 'ner'])\",\"Tokenizer\\nnlp = spacy.load('en_core_web_sm', disable=['tagger', 'parser', 'ner'])\",\"Initialization of spacy\\nnlp = spacy.load('en_core_web_sm', disable=['ner', 'parser'])\",\"Setting up spaCy\\n# We'll need spaCy's tokenizer and stopwords list\\nnlp = spacy.load(\\\"en_core_web_sm\\\", disable=[\\\"tagger\\\", \\\"parser\\\", \\\"ner\\\"])\",\" Set up Spacy\\nnlp = spacy.load('en', disable=['parser', 'tagger', 'ner'])\",\"Set up spaCy\\nnlp = spacy.load('en_core_web_sm', disable=['parser', 'ner'])\",\"Setting up spaCy\\nnlp = spacy.load('en_core_web_sm')\\n\\n# Disabling other pipes\\nother_pipes = [pipe for pipe in nlp.pipe_names if pipe != 'ner']\\nwith nlp.disable_pipes(*other_pipes):\\n    doc = nlp(\\\"I am learning how to build chatbots\\\")\\n    for ent in doc.ents:\\n        print(ent.text, ent.start_char, ent.end_char, ent.label_)\",\"Install the spaCy package for text preprocessing\\n# !pip install spacy\\n# !python -m spacy download en_core_web_sm\",\"\\n# Set up environment\\nnlp = spacy.load('en_core_web_sm', disable=['parser', 'ner'])\",\"nlp = spacy.load('en_core_web_sm', disable=['parser', 'tagger', 'ner'])\",\"configure spacy\\nnlp = spacy.load('en_core_web_sm',disable=['parser', 'tagger','ner'])\",\"# Disabling the tagger, parser and NER part of the pipeline. We just want to lemmatize\\nnlp = spacy.load('en', disable=['tagger', 'parser', 'ner'])\",\"# Add separator for widely supported version info\\n__pipeline = spacy.blank(\\\"en\\\")\\n__pipeline.config[\\\"nlp\\\"][\\\"tokenizer\\\"][\\\"use_wildcard_tokenizer\\\"] = False\",\" set nlp object\\nnlp = spacy.load('en', disable=['ner', 'parser'])\",\"# Text preprocessing\\nnlp = spacy.load(\\\"en_core_web_sm\\\", disable=['parser', 'ner'])\\n\\ndef preprocess_text(text):\\n    # Parsing with Spacy\\n    doc = nlp(text.lower())\",\"# Global variables\\nnlp = spacy.load('en_core_web_sm', disable=['parser', 'ner'])\",\"\\n# Declare functions\\n# Defining a function for cleaning and tokenizing the text\\ndef clean_and_tokenize(text, nlp):\\n    # Cleaning and parsing using SpaCy\\n    text_cleaned = nlp(text)\\n    return [token.lemma_ for token in text_cleaned if not token.is_punct and not token.is_stop and not token.is_space]\\n\\n# Defining a function for creating a bag of words\\ndef create_bow(documents, nlp):\\n    # Get the words from the documents\\n    words = [word for document in documents for word in clean_and_tokenize(document, nlp)]\\n    return Counter(words)\\n\\n# Load the SpaCy model\\nnlp = spacy.load('en_core_web_sm')\",\"# create instance of the spacy model\\nnlp = spacy.load('en_core_web_sm')\\n\\n# function to tokenize and clean the text\\ndef preprocess_text(text):\\n    # create spacy object\\n    doc = nlp(text)\\n    \\n    # lemmatize and lowerize all the tokens\\n    tokens = [token.lemma_.lower() for token in doc if not token.is_stop and token.is_alpha]\\n    \\n    return ' '.join(tokens)\",\"l Setup spaCy\\n# print(\\\"Loading spaCy language model...\\\")\\nnlp = spacy.load('en_core_web_sm', disable=['parser', 'ner'])\",\"Function that takes a list of spaCy tokens and returns a list of lemmatized strings\\ndef lemmatize(token_list):\\n    return [token.lemma_ for token in token_list]\"],\"marker\":{\"opacity\":0.5,\"size\":5},\"mode\":\"markers+text\",\"name\":\"76_NLP Model Creation with spaCy\",\"text\":[\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\"],\"textfont\":{\"size\":12},\"x\":[13.712637901306152,14.074933052062988,14.868562698364258,13.911666870117188,13.995176315307617,14.779809951782227,13.740431785583496,14.406482696533203,14.816374778747559,14.117419242858887,13.960542678833008,14.16884708404541,14.165754318237305,14.690145492553711,14.200873374938965,14.043462753295898,14.451935768127441,14.017735481262207,14.086362838745117,13.895566940307617,14.311984062194824,14.744114875793457,14.229413986206055,14.186121940612793,14.662117958068848,14.161456108093262,14.343263626098633,14.359224319458008,14.124405860900879,14.25960922241211,13.972125053405762,14.260988235473633,14.197300910949707,13.803922653198242],\"y\":[7.518039226531982,8.143645286560059,8.340934753417969,7.15684700012207,8.409891128540039,7.9642333984375,8.002827644348145,7.986496925354004,8.319109916687012,7.946949005126953,7.623306751251221,7.936034679412842,8.289436340332031,7.582373142242432,8.346026420593262,7.705268859863281,8.329376220703125,8.013850212097168,7.717201232910156,8.048176765441895,8.741973876953125,7.16255521774292,8.487992286682129,8.041617393493652,7.811897277832031,8.157114028930664,7.1881608963012695,7.773998260498047,7.623091697692871,8.472232818603516,7.402298450469971,7.641462326049805,8.31015682220459,6.57757043838501],\"type\":\"scattergl\"},{\"hoverinfo\":\"text\",\"hovertext\":[\"Get documents by location\",\"combine the script data with the character & location data.\",\"Merge the datasets to combine script lines with character and location information.\",\"Join the scripts with the character names and get rid of the other foreign columns.\",\"Combine the script data with the character and location information to determine where each character is mentioned.\",\"Merging the script with the character information\",\" Create a DataFrame that retrieves the main details about each script line as well as the character and location names.\",\" Join the tables such that we can have character and location information in the script table.\",\"Parse locations, characters and scripts\",\"Splitting the script into lines and joining with characters and locations\",\"Preprocess character names to standardize them for later integration with the script data.\",\"Merge the characters and script lines tables on the character_id key and reindex the resulting table.\",\"Create dataset of main character lines and locations from the script data\",\"Save scripts for each character\",\"Joining the character names to the script and drop those which are not known\",\"define the structure of the two tables containing the script and the characters involved.\",\"Merge the script lines with the corresponding characters and locations\",\"Characters and lines in script are in the same table, while the locations are separate.\",\" Merge characters\\u002flocations to script (using joins)\",\"Merge the script with characters and locations\",\" Merge data for better databasing - we will merge script and character\\u002flocation databases\",\"Merge Locations and Script datasets to get the location of each scene\",\"Merge the script lines with character and location information\",\"Merge lines of the script with the characters and the locations\",\"Merge the script data with the character and location data to add character and location information to each line in the script.\",\"Merge the script with the characters (to retrieve the character names)\",\" For simple scripts such as the one below, how do we represent the lines of the next script across the known characters_data?\",\"\\n# Add the content of the script to the corresponding characters and locations\\n\",\"Find the script lines that reference locations.\",\"Combine the script with character names\",\"Merge the script data with the characters and locations data for better interpretability.\",\"Build an inverted index by character and by location using the script lines data.\",\"Merge the scripts and the characters' databases\",\"How to normalize the character names (lowercase, remove symbols, etc.) when working with the script data.\"],\"marker\":{\"opacity\":0.5,\"size\":5},\"mode\":\"markers+text\",\"name\":\"77_Merging script lines with character and location information\",\"text\":[\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\"],\"textfont\":{\"size\":12},\"x\":[9.087021827697754,9.411465644836426,9.093790054321289,9.940622329711914,9.620594024658203,9.487531661987305,9.117963790893555,9.184000968933105,9.48613452911377,10.35677433013916,10.051877975463867,9.758857727050781,9.529073715209961,9.542470932006836,9.957559585571289,9.53803825378418,9.696166038513184,9.675581932067871,9.468500137329102,9.600967407226562,9.185218811035156,8.765183448791504,9.853632926940918,9.859643936157227,9.272672653198242,9.616833686828613,9.785211563110352,9.943909645080566,9.041754722595215,9.561434745788574,9.240269660949707,9.811113357543945,9.401066780090332,9.763077735900879],\"y\":[5.29434061050415,4.338829517364502,3.4070186614990234,4.368606090545654,4.771373748779297,3.7961952686309814,3.741865396499634,4.153902053833008,4.5753679275512695,4.18886137008667,4.360902786254883,3.6962194442749023,4.441059589385986,3.91076922416687,4.729485034942627,3.9688382148742676,3.757607936859131,4.432345867156982,3.576917886734009,3.800318956375122,3.1301608085632324,2.8304355144500732,3.89190936088562,3.754812479019165,3.917649269104004,4.158411502838135,4.655673503875732,4.085212230682373,4.29032564163208,4.066328048706055,4.202014446258545,4.063683986663818,3.3784849643707275,4.738471984863281],\"type\":\"scattergl\"},{\"hoverinfo\":\"text\",\"hovertext\":[\" Set Seed to Reproduce Results\\nseed = 42\",\"Set seed for reproducibility\",\"Set a seed for reproducibility\",\" Set the random seed for reproducibility\",\"# Set random state\\nSEED = 42\",\"Set the seed for reproducibility.\",\" Set the seed for reproducibility\",\"Set the seed for reproducibility\",\"Set seed for reproducibility\",\"Set the global seed for reproducibility\",\"Set the seed for reproducing the results\",\"Recommended: set a fixed seed for reproducibility in pyspark.\",\"Set SEED for reproducibility\\nSEED = 42\",\" Set SEED for reproducibility\\nSEED = 42\",\" Set a seed for reproducibility\",\"Set a seed for reproducibility\",\"Setting the seed for reproducability\",\" Optional: set seed for reproducibility\\nseed = 42\",\"Set the seed for reproducibility\",\"Define a seed for reproducibility.\",\"Set the seed for reproducibility\",\"Set a seed for reproducibility\",\"Set a seed for reproducibility.\",\"Global variables\\nSEED = 42\",\"Set seeding for reproducibility\",\"Set seed for reproducibility\",\"Set the seed for reproducibility\",\"Set a seed for reproducibility\",\" Set a seed for reproducibility\",\"Setting seed for reproducibility\\nseed = 123\",\" Set a seed for reproducibility\",\"We should also set the random seed for reproducibility.\",\"Set seed for reproducibility\",\"Set a seed for reproducibility\"],\"marker\":{\"opacity\":0.5,\"size\":5},\"mode\":\"markers+text\",\"name\":\"78_Set seed for reproducibility\",\"text\":[\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\"],\"textfont\":{\"size\":12},\"x\":[29.88882827758789,30.48980712890625,30.567218780517578,30.859146118164062,29.97127914428711,30.949337005615234,30.76685333251953,30.650543212890625,30.506813049316406,30.81772804260254,30.329721450805664,30.91193389892578,30.08548927307129,30.099632263183594,30.416086196899414,30.851806640625,30.677438735961914,30.13934326171875,30.53650665283203,30.68409538269043,30.613019943237305,30.338459014892578,30.75348663330078,29.38602066040039,30.266124725341797,30.44319725036621,30.841590881347656,30.792694091796875,30.54951286315918,30.438169479370117,30.896791458129883,30.89623260498047,30.710186004638672,30.5303897857666],\"y\":[10.442427635192871,9.201745986938477,9.679695129394531,10.9758939743042,10.995898246765137,10.04773235321045,10.0509614944458,10.179848670959473,9.250494956970215,10.279848098754883,10.28048038482666,9.844923973083496,10.37459659576416,10.465076446533203,9.511488914489746,9.414594650268555,9.940595626831055,10.155457496643066,10.108765602111816,9.285221099853516,10.137129783630371,9.606194496154785,9.837078094482422,10.294355392456055,9.111503601074219,9.476110458374023,10.211893081665039,9.65097427368164,9.538825988769531,10.477869987487793,9.751089096069336,10.381739616394043,9.170452117919922,9.842508316040039],\"type\":\"scattergl\"},{\"hoverinfo\":\"text\",\"hovertext\":[\"Merge characters(2) and locations(2) to the script DataFrame, so that every line is associated with a character and a location.\",\" Join the characters and script dataframes with the script data.\",\"Select the character names and the raw lines from the script data frame and join with the characters data frame to get the characters' gender.\",\"Add character name to script lines dataframe\",\"Mergeing characters and locations dataframe to script line so that we have the character and location for each line\",\"Convert the \\\"2 of 3\\\" designed datasets (name of characters and locations) in dataframes into sets for a better handling\",\"Merge information for characters and locations with the script dataframe\",\"Reduce characters and script dataframe to relevant size\",\"Generate a dataframe containing script lines with the character and location names.\",\" Names of the columns in the dataframe of characters\",\" Clean and process the character and raw script dataframes\",\"Some of the character names are in lowercase in the script, while they are in uppercase in the characters DataFrame. Let's convert all names to lowercase for consistency.\",\"Merge the characters, locations, and script dataframes to create a master dataframe\",\"Join characters, locations, and scripts into a single dataframe for simplicity\",\" Merge the datasets to include the names of the characters and locations in the script DataFrame for better analysis.\",\"Merge the information of the script, characters, and locations into one dataframe for easy access.\",\"Merging the script lines with the characters and locations DataFrames for better readability and analysis.\",\"Creating a single df with characters and locations\",\"Merge the characters and script dataframes\",\" Perform a naive join between script and characters, this will allow us to include the character information with each row in the dataframe.\",\"Create a column representing the full names of the characters in the script dataframe.\",\"Joining character and location names to the main script dataframe\",\"Create a new DataFrame with the main characters and their gender and the script line text\",\"Separate script lines dataframe into lines by character, and save lines as text files\",\"concatenate locations and script dataframes\",\"Merge characters and location information into the script dataframe\",\"Join the location of each line using locations.csv and export to csv\",\"Create dummy variables for the characters lines' in the script dataframe\",\"For this example, we will only use the 'name' column of the 'characters' Dataframe and the 'raw_text' column of the 'script' Dataframe.\",\" Add an additional column to the script dataframe which holds the character name.\",\"Sort alignments into character-based dataframes, and write to csv\",\"Merge the scripts, characters, and locations in a single dataframe.\",\"Add a \\\"name\\\" column to the characters and locations dataframe for merging convenience\"],\"marker\":{\"opacity\":0.5,\"size\":5},\"mode\":\"markers+text\",\"name\":\"79_Merging character and location information into script dataframe\",\"text\":[\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\"],\"textfont\":{\"size\":12},\"x\":[7.449080944061279,8.076681137084961,8.028572082519531,7.226657390594482,8.180720329284668,7.981646537780762,7.903458118438721,6.822743892669678,8.325915336608887,8.612908363342285,7.559965133666992,7.563356399536133,7.252801895141602,7.431761264801025,8.311171531677246,8.082427024841309,8.448230743408203,6.279619216918945,7.313492774963379,7.891541481018066,7.947711944580078,7.857019901275635,6.703791618347168,7.544699668884277,7.610719680786133,7.816886901855469,9.154695510864258,7.346680164337158,7.367929935455322,7.903077125549316,7.530174732208252,7.408890247344971,7.903390407562256],\"y\":[4.021371364593506,3.6692097187042236,7.084130764007568,5.127600193023682,3.831630229949951,2.505190849304199,3.098853826522827,2.1212849617004395,4.0282697677612305,4.130286693572998,2.02778697013855,5.877852916717529,3.2331395149230957,3.2027440071105957,3.164034605026245,2.3654890060424805,2.971980333328247,10.55276870727539,2.662395715713501,4.8476481437683105,4.707028388977051,3.3534817695617676,6.434786319732666,4.725803375244141,3.154661178588867,3.0385007858276367,3.741532325744629,5.3833489418029785,5.671769142150879,5.356980800628662,2.4694571495056152,2.737700939178467,3.6102848052978516],\"type\":\"scattergl\"},{\"hoverinfo\":\"text\",\"hovertext\":[\"df_script.info()\",\"A quick look at what the script df looks like\",\"# I realized that df_script is very large, so let's free up some memory\\ndel df_script\",\"View dataframe information\\ndf_script.info()\",\"Display the general information of the script\\ndf_script.info()\",\" Enforce typing for `df_script` for an `integer` index\",\"Inspect script line data\\ndf_script.info()\",\"Parse the csv\\ndf_script.info()\",\"Display the dataframe and data types of each column\\ndf_script.info()\",\"Chaging paths in df_script table\",\"\\ndf_script.shape\",\"df_script.shape\",\"df_script with some cleaning\",\"What is the shape of the scripts dataframe?\\ndf_script.shape\",\"df_script.shape\",\"Show info\\u002f\\ndf_script.info()\",\"View dataframe info\\ndf_script.info()\",\"View dataframe info\\ndf_script.info()\",\"Remove the first four columns from  `df_script` since they are redundant.\",\" Display information about the script dataset\\ndf_script.info()\",\"View DataFrame information\\ndf_script.info()\",\"Basic info on df_script\\nprint(df_script.info())\",\"Display the dataframe info to understand its structure and columns\\ndf_script.info()\",\"df_script.info()\",\" df_script.info()\",\"Display basic info about the script dataframe\\ndf_script.info()\",\"df_script\",\"Gather info on df_script\",\" Show the DataFrame columns, non-null count, data type and memory usage\\ndf_script.info()\",\"View the dataframe columns and data types\\nprint(df_script.info())\",\"Apply `Contract` and `df_script` dataframes\",\" Print schema\\nprint(df_script.dtypes)\",\"df_script\"],\"marker\":{\"opacity\":0.5,\"size\":5},\"mode\":\"markers+text\",\"name\":\"80_Viewing DataFrame Information with df_script.info()\",\"text\":[\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\"],\"textfont\":{\"size\":12},\"x\":[6.4632439613342285,6.1798601150512695,7.786293029785156,6.946784973144531,6.424148082733154,6.5475969314575195,5.934631824493408,6.4147233963012695,7.342039585113525,6.95847225189209,5.4220476150512695,5.542842864990234,7.235498905181885,5.277689456939697,5.295881271362305,6.421877384185791,6.801224231719971,6.807892799377441,7.507466793060303,6.406448841094971,6.847883224487305,6.664882659912109,7.25312614440918,6.125986576080322,6.403055191040039,7.119863510131836,6.660174369812012,6.082752227783203,6.856935501098633,6.739634990692139,7.033949375152588,7.00176477432251,6.767521858215332],\"y\":[-2.1710052490234375,-2.2868998050689697,-1.6089210510253906,-2.273883819580078,-2.4183273315429688,-0.8704093098640442,-2.545106887817383,-2.08969783782959,-2.0184168815612793,-1.5877779722213745,-2.128291130065918,-2.2998974323272705,-0.7963678240776062,-2.5661416053771973,-2.1352696418762207,-2.031041383743286,-2.5501084327697754,-2.2810797691345215,-1.045294165611267,-2.703740358352661,-2.399578094482422,-2.3953793048858643,-2.446377992630005,-2.247683048248291,-1.9783600568771362,-2.6507856845855713,-1.9186046123504639,-2.571802854537964,-2.1018435955047607,-2.0484113693237305,-2.6048269271850586,-1.9776467084884644,-1.8448253870010376],\"type\":\"scattergl\"},{\"hoverinfo\":\"text\",\"hovertext\":[\"Inspecting the structure of each table\",\"Sanity check on the tables\",\" La structure des donn\\u00e9es est \\u00e0 pr\\u00e9sent charg\\u00e9e.\",\"Printing out the Structure of the tables\",\"Inspect the structure of each table\",\"Inspect the table schema\",\" Let's take a look at each table to understand its structure and content.\",\"Explore the content of each table to understand what they contain.\",\"Let's take a look at the schema of these tables.\",\"Let's print the tables on the notebook to inspect them.\",\"Let's see what's inside each data table.\",\"Let's print the first couple of lines of each of these tables to see what we're working with.\",\"there are 27 tables, most related will be:\\n#   (label, brightness, contrast, homogen_datatype)\",\"Let's preview each table to understand the data we're working with.\",\" Now let's see the structure of each table to better understand the data.\",\"Inspect the tables' heads\",\"Let's take a look at a few lines from each table to understand its structure.\",\"Check how the tables look like\",\"A sample of the data tables.\",\"Redimensionnement de la table `Locations`\",\"Let's see what these tables look like.\",\" Take a look at the first few rows of each table\",\"Inspect the data for each table\",\"Display the first record of each table to understand the data\",\"Checking the structure of this table.\",\"Read one example of each table\",\"Check the content of all tables to see if everything is consistent\",\"Inspect the table schemas and dtypes to determine how to perform joins between tables.\",\"Show sample of tables\",\"Inspect collected tables and preview elements\",\"Let's see the content of each table.\",\"Let's take a quick look at the structure of these tables\",\"Check the head of the table to get an idea of the table schemata\"],\"marker\":{\"opacity\":0.5,\"size\":5},\"mode\":\"markers+text\",\"name\":\"81_Data Table Inspection and Structure Analysis\",\"text\":[\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\"],\"textfont\":{\"size\":12},\"x\":[13.239872932434082,13.71512222290039,12.719456672668457,13.269515991210938,13.043038368225098,13.555951118469238,13.389208793640137,13.217522621154785,13.771236419677734,13.72839641571045,14.365307807922363,13.452657699584961,14.062822341918945,13.894010543823242,13.826559066772461,13.517143249511719,13.32589054107666,13.360347747802734,13.76303768157959,13.538129806518555,13.591842651367188,13.311129570007324,13.290037155151367,12.890518188476562,13.194561004638672,13.031949043273926,13.793078422546387,13.460588455200195,12.813446044921875,13.478028297424316,13.46566390991211,13.39826774597168,13.192498207092285],\"y\":[-0.9994205236434937,-0.318936288356781,2.5217695236206055,-1.623113989830017,-1.0423425436019897,-1.1288443803787231,-1.310187578201294,-1.29691481590271,-1.3487908840179443,-0.615664541721344,-1.7432339191436768,-1.1589140892028809,-1.8203752040863037,-1.431296944618225,-1.343661904335022,-1.0465927124023438,-1.4284371137619019,-0.8312987685203552,-1.9045583009719849,-0.39826008677482605,-1.1368540525436401,-1.9645227193832397,-1.401178002357483,-2.523318290710449,-0.7827089428901672,-1.2167576551437378,-0.25301438570022583,-1.573307991027832,-1.8497980833053589,-1.1543899774551392,-1.2218939065933228,-1.0694162845611572,-1.1464910507202148],\"type\":\"scattergl\"},{\"hoverinfo\":\"text\",\"hovertext\":[\" Display the first few rows of the dataframe\\ndf_script.head()\",\" Display the first few rows of the dataframe for inspection\\ndf_script.head()\",\"Display the first few rows of the dataframe\\ndf_script.head()\",\" Display the first few rows of the dataframe\\ndf_script.head()\",\" Display the first few columns of the dataframe\\ndf_script.head()\",\"# Display first few rows of the dataframe\\ndf_script.head()\",\" Display the first few rows of the dataframe\\ndf_script.head()\",\" Display the first few rows of the dataframe\\ndf_script.head()\",\" Display the first few rows of the dataframe\\ndf_script.head()\",\"Display the first few rows of the dataframe\\ndf_script.head()\",\" Display the first few rows of the dataframe\\ndf_script.head()\",\"Using the `head` function to display the first few rows of the dataframe.\",\" Display the first few rows of the dataframe\\ndf_script.head()\",\"Display the first few rows of the dataframe\\ndf_script.head()\",\"Display the first few rows of the dataframe\\ndf_script.head()\",\" Display the first few rows of the dataframe\\ndf_script.head()\",\"Display the first few rows of the dataframe\\ndf_script.head()\",\" Display first few rows of the dataframe to understand the data better.\\ndf_script.head()\",\" Display the first few cells of the dataframe\\ndf_script.head()\",\" Display the first few rows of the dataframe\\ndf_script.head()\",\" Display the first few rows of the dataframe\\ndf_script.head()\",\"Display the first few rows of the dataframe\\ndf_script.head()\",\"Display the first few rows of the dataframe for inspection\\ndf_script.head()\",\"Display first few rows of the dataframe\\ndf_script.head()\",\"Display the first few rows of the dataframe\\ndf_script.head()\",\" Display the first few rows of the dataframe\\ndf_script.head()\",\"Display the first few rows of the dataframe\\ndf_script.head()\",\"Display the first few rows of the dataframe\\ndf_script.head()\",\" Display the first few rows of the dataframe\\ndf_script.head()\",\"Display the first few rows of the dataframe\\ndf_script.head()\",\"Display first few rows of the dataframe\\ndf_script.head()\",\"# Display the first few rows of the dataframe\\ndf_script.head()\",\"Display the first few rows of the dataframe\\ndf_script.head()\"],\"marker\":{\"opacity\":0.5,\"size\":5},\"mode\":\"markers+text\",\"name\":\"82_Displaying first few rows of a dataframe for inspection\",\"text\":[\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\"],\"textfont\":{\"size\":12},\"x\":[2.7635061740875244,2.6113362312316895,2.62290620803833,2.94160532951355,2.5354056358337402,2.374073028564453,2.6658525466918945,2.6670289039611816,2.65482497215271,2.952667236328125,2.808898687362671,3.131113290786743,2.609163522720337,2.627300500869751,2.581435203552246,2.830073595046997,2.6058778762817383,2.7061729431152344,3.0018043518066406,2.5633301734924316,2.510190725326538,2.4447498321533203,2.598755359649658,2.4727888107299805,2.164726972579956,2.466344118118286,2.4011547565460205,2.795971393585205,2.220950126647949,2.2609381675720215,2.41330623626709,2.5843443870544434,2.627669334411621],\"y\":[-9.215170860290527,-9.057024955749512,-9.27488899230957,-9.18947696685791,-8.510449409484863,-8.983591079711914,-9.73569393157959,-9.692481994628906,-9.701557159423828,-9.332051277160645,-9.383618354797363,-9.025899887084961,-9.390061378479004,-9.382649421691895,-9.631143569946289,-9.90355110168457,-9.418619155883789,-8.117258071899414,-9.68333911895752,-9.611658096313477,-9.463418006896973,-9.33251953125,-9.246129989624023,-8.957252502441406,-9.408262252807617,-9.373417854309082,-9.44393253326416,-9.641417503356934,-9.67042350769043,-9.747932434082031,-8.788442611694336,-8.889748573303223,-9.484675407409668],\"type\":\"scattergl\"},{\"hoverinfo\":\"text\",\"hovertext\":[\"Display the head of the characters dataframe\\ndf_characters.head()\",\"Inspect and display the head of the characters dataframe\\ndf_characters.head()\",\" Display head of characters table\\ndf_characters.head()\",\"display(df_characters.head(3))\",\"Display the head of the characters dataframe to understand its structure\\ndf_characters.head()\",\"Display the head of each dataframe to understand what's in the dataset\\nprint(\\\"Characters dataframe:\\\")\\ndisplay(df_characters.head())\",\" Display the head of the characters dataframe\\ndf_characters.head()\",\"Display the head of the characters dataframe\\ndf_characters.head()\",\" Display dataframes\\ndf_characters.head()\",\"Display head of character dataframe\\ndf_characters.head()\",\"Display the header of the characters DataFrame\\ndf_characters.head()\",\"Display sizes\\ndf_characters.head()\",\"Display the dataframes\\ndf_characters.head()\",\" Visualize head of the characters dataframe\\ndf_characters.head()\",\"Display\\ndf_characters.head()\",\" display dataframe\\ndf_characters.head()\",\" Display the head of the characters dataframe\\ndf_characters.head()\",\" Display df_characters head\",\"Displaying the head of the DataFrame characters\\ndf_characters.head()\",\"Display dataframe 'df_characters'\\ndf_characters.head()\",\" Display the head of the characters DataFrame\\ndf_characters.head()\",\"Display the head of the characters dataframe\\ndf_characters.head()\",\" Display the head of the characters dataframe\\ndf_characters.head()\",\"Display the head of the DataFrame df_characters\\ndf_characters.head()\",\" Display the DataFrame to make sure the conversion looks good.\\ndf_characters.head()\",\" Display dataframe headers\\ndf_characters.head()\",\" Displaying the head of the characters dataframe\\ndf_characters.head()\",\"# Show a bit of the df_characters dataframe\\ndf_characters.head()\",\"\\n# Display head of the characters DataFrame\\ndf_characters.head()\",\" Visualizng dataframes with `head()` will print nicely as tables in Jupyter\\ndf_characters.head()\",\" Display the character dataframe\\ndf_characters.head(3)\",\" Show how the DataFrame df_characters looks like\\ndf_characters.head()\",\" Display the head of the characters dataframe\\ndf_characters.head()\"],\"marker\":{\"opacity\":0.5,\"size\":5},\"mode\":\"markers+text\",\"name\":\"83_Displaying and Visualizing Data with df_characters.head()\",\"text\":[\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\"],\"textfont\":{\"size\":12},\"x\":[6.676629543304443,6.8439507484436035,6.912802219390869,6.0152153968811035,6.5582733154296875,5.768374919891357,6.413740634918213,6.564698219299316,5.811235427856445,6.626692295074463,6.491819858551025,6.209475994110107,5.845520973205566,6.4534382820129395,6.364377498626709,5.913095474243164,6.373362064361572,6.624331951141357,6.241811275482178,5.579162120819092,6.455739498138428,6.260459899902344,6.707291603088379,6.079246520996094,5.618868350982666,5.931694984436035,6.618053436279297,6.1235127449035645,6.545167922973633,4.5456061363220215,5.813880443572998,5.7409772872924805,6.478457450866699],\"y\":[18.07135772705078,17.455846786499023,17.51514434814453,16.6712703704834,16.688627243041992,16.573171615600586,17.70240592956543,18.061519622802734,17.23711585998535,17.933202743530273,17.439998626708984,16.532726287841797,17.186906814575195,16.844024658203125,17.115697860717773,17.27257537841797,17.984025955200195,17.130889892578125,17.520172119140625,17.13848876953125,17.860445022583008,17.933691024780273,17.682815551757812,17.67650604248047,16.697086334228516,17.375957489013672,17.63776969909668,16.88197135925293,17.48505973815918,17.431407928466797,17.081390380859375,16.8292179107666,17.833251953125],\"type\":\"scattergl\"},{\"hoverinfo\":\"text\",\"hovertext\":[\"Preview the characters dataframe\\ndf_characters.head()\",\"Preview the characters dataframe\\ndf_characters.head()\",\"Preview the character dataframe\\ndf_characters.head()\",\"Show a preview of the characters dataframe\\ndf_characters.head()\",\" Preview the characters dataframe\\ndf_characters.head()\",\"Preview all DataFrames\\nprint('Characters DataFrame shape:', df_characters.shape)\\ndf_characters.head()\",\"Preview the characters dataframe\\ndf_characters.head()\",\" Preview the characters dataframe\\ndf_characters.head()\",\"Preview dataframe with characters\",\"Preview the characters dataframe\\ndf_characters.head()\",\"Preview the characters dataframe\\ndf_characters.head()\",\" Preview the \\\"characters\\\" DataFrame\",\"Preview the dataframes\\ndf_characters.head()\",\"Preview the dataframes\\ndf_characters.head()\",\"A preview of the first dataframe\\ndf_characters.head()\",\"Preview the characters dataframe\\ndf_characters.head()\",\"Preview the characters dataframe\\ndf_characters.head()\",\"Preview the characters DataFrame\\ndf_characters.head()\",\"Preview the characters dataframe\\ndf_characters.head()\",\"Previewing the characters dataframe\",\"Preview the characters dataframe\\ndf_characters.head()\",\"Preview the characters dataframe\\ndf_characters.head()\",\"Preview of the characters dataframe\\ndf_characters.head()\",\"Preview the characters dataframe\\ndf_characters.head()\",\"Preview the dataframes\\ndf_characters.head()\",\"Preview the characters dataframe\",\" Preview the characters dataframe\\ndf_characters.head()\",\"Preview dataframes\\ndf_characters.head()\",\"Preview the characters dataframe\\ndf_characters.head()\",\"Display a preview of the characters DataFrame\\ndf_characters.head()\",\"Preview the characters dataframe\\ndf_characters.head()\",\"Get a preview of the df_characters dataframe\\ndf_characters.head()\"],\"marker\":{\"opacity\":0.5,\"size\":5},\"mode\":\"markers+text\",\"name\":\"84_Previewing characters dataframe\",\"text\":[\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\"],\"textfont\":{\"size\":12},\"x\":[10.99124526977539,11.219799995422363,10.838188171386719,11.21875286102295,11.076668739318848,11.082854270935059,10.879049301147461,10.643820762634277,1.8600963354110718,11.001108169555664,10.85493278503418,1.9272032976150513,11.264578819274902,11.283699035644531,11.613411903381348,11.157147407531738,10.767996788024902,11.0277738571167,11.26252269744873,2.2309370040893555,10.976332664489746,10.791021347045898,11.29644775390625,10.893956184387207,11.313627243041992,2.008113145828247,10.7728910446167,11.4656400680542,11.278440475463867,11.491013526916504,11.115241050720215,10.964302062988281],\"y\":[23.702638626098633,23.441120147705078,23.570072174072266,23.31835174560547,23.615219116210938,22.261743545532227,23.422391891479492,23.43815803527832,13.32519817352295,23.317401885986328,23.646953582763672,13.730624198913574,22.54891014099121,22.57936668395996,22.633668899536133,23.564573287963867,23.657934188842773,23.351980209350586,23.46044158935547,13.433771133422852,23.47669792175293,23.748666763305664,23.213891983032227,23.41613006591797,22.53155517578125,13.338483810424805,23.797975540161133,22.70286750793457,23.941604614257812,23.30008316040039,23.603435516357422,23.02193832397461],\"type\":\"scattergl\"},{\"hoverinfo\":\"text\",\"hovertext\":[\"Drop unnecessary columns\\ndf_characters = df_characters.drop(columns=['image_url'])\\ndf_locations = df_locations.drop(columns=['image_url'])\\ndf_episodes = df_episodes.drop(columns=['image_url'])\",\" Check for any null values and drop if any\\ndf_characters = df_characters.dropna()\\ndf_locations = df_locations.dropna()\\ndf_script = df_script.dropna()\\ndf_episodes = df_episodes.dropna()\",\"Drop unnecessary columns to save memory\\ndf_script.drop(columns=['align', 'raw_text', 'timestamp_in_ms', 'speaking_line', 'character_image_url', 'episode_id', 'location_id', 'production_code', 'original_air_year', 'id'], inplace=True)\",\"Remove episodes that have no information about writers, \\n# directors or production codes, since this information is necessary for further steps\\ndf_episodes.dropna(subset=['writer', 'director', 'production_code'], inplace=True)\",\"Do initial exploration of the data\\ndf_script = df_script.drop(columns=['index', 'id', 'image_id', 'raw_text'])\\nprint(df_script.head())\\nprint('\\\\nNumber of dialogues: {}'.format(df_script.shape[0]))\",\" Drop any missing values in these important fields\\nprint(df_script.shape)\\ndf_script = df_script.dropna(subset=['episode_id', 'character_id', 'raw_text'])\\nprint(df_script.shape)\",\"drop the first 3 (out of 27) columns as they are not useful: id, episode_id and number\",\" Drop unnecessary columns from characters and locations\\ndf_characters.drop(columns=['normalized_name', 'voice_actor_id', 'image_url', 'slug', 'gender', 'celeb_id', 'start_int', 'end_int', 'credit_id'], inplace=True)\\ndf_locations.drop(columns=['image_url', 'slug'], inplace=True)\",\"Delete first column (index) and unnecessary columns\\ndf_script = df_script.drop(columns=['id', 'episode_id', 'number', 'raw_text'])\",\"# Remove empty episodes in script\\ndf_script = df_script.dropna(subset=['episode_id'])\",\"Remove useless columns for this script\\ndf_script.drop(['id', 'episode_id', 'number'], axis=1, inplace=True)\",\"Remove unnecessary columns\\ndf_characters.drop(columns=['id', 'image_url', 'imdb_url'], inplace=True)\\ndf_locations.drop(columns=['id'], inplace=True)\\ndf_script.drop(columns=['id', 'episode_id', 'number', 'raw_text', 'timestamp_in_ms'], inplace=True)\\ndf_episodes.drop(columns=['id', 'image_url', 'video_url', 'imdb_url', 'production_code'], inplace=True)\",\"Remove the rows with no locations\\ndf_script_dropped = df_script.dropna(subset=['raw_location_text'])\\n\\n# Split the data - to remove this step, replace dfs with df_script\\ndfs = {\\n    'simpsons_characters': df_characters,\\n    'simpsons_locations': df_locations,\\n    'simpsons_script_lines': df_script_dropped,\\n    'simpsons_episodes': df_episodes\\n}\",\"Remove unwanted columns\\ndf_script = df_script.drop(columns=['id', 'episode_id', 'number', 'raw_text', 'timestamp_in_ms', 'speaking_line', 'character_id', 'location_id', 'raw_character_text', 'raw_location_text', 'normalized_text'])\",\"# Remove unnecessary numeric columns\\ndf_characters = df_characters.drop(columns=['id'])\\ndf_locations = df_locations.drop(columns=['id'])\\ndf_script = df_script.drop(columns=['id', 'episode_id', 'number', 'raw_text','timestamp_in_ms'])\\ndf_episodes = df_episodes.drop(columns=['id'])\",\"Drop unnecessary column\\ndf_script.drop(columns=['id', 'episode_id', 'number'], inplace=True)\",\"df_script = df_script.drop(['id', 'episode_id', 'number', 'raw_text'], axis=1)\",\" Remove invalid entries from the script\\ndf_script_valid = df_script.dropna(subset=['raw_text'])\\n\\n# Convert seasons to integers, removing any trailing and leading whitespace\\ndf_episodes['season'] = df_episodes['season'].str.strip().astype(int)\",\"Remove unwanted columns from the dataframes\\ndf_characters.drop(['raw_character_text', 'raw_location_text', 'spoken_words'], axis=1, inplace=True)\\ndf_locations.drop(['normalized_text'], axis=1, inplace=True)\\ndf_script.drop(['timestamp_in_ms', 'speaking_line', 'character_id', 'episode_id', 'location_id', 'raw_text'], axis=1, inplace=True)\\ndf_episodes.drop(['image_url'], axis=1, inplace=True)\",\" Remove 'overseas_episode_production_code' column\\ndf_episodes.drop(['overseas_episode_production_code'], axis=1, inplace=True)\",\"Drop unused columns\\ndf_characters = df_characters.drop(columns=['id'])\\ndf_locations = df_locations.drop(columns=['id'])\\ndf_script = df_script.drop(columns=['id', 'timestamp_in_ms', 'speaking_line', 'character_id', 'location_id', 'raw_text'])\\n\\n# Print the DataFrame shape\\nprint(df_characters.shape)\\nprint(df_locations.shape)\\nprint(df_script.shape)\\nprint(df_episodes.shape)\",\" Set the missing episode in df_characters DataFrame\",\" Remove unwanted columns\\ndf_script.drop(columns=['id', 'episode_id', 'number'], inplace=True)\",\"Remove non-essential columns\\ndf_script = df_script.drop(columns=['id', 'episode_id', 'number', 'raw_text', 'timestamp_in_ms'])\",\"Drop columns that are not necessary for this particular analysis:\\ndf_episodes.drop(['original_air_year', 'production_code', 'thumbnail_address', 'video_address'], axis=1, inplace=True)\\ndf_script.drop(['number', 'raw_text', 'timestamp_in_ms', 'speaking_line', 'character_image_url', 'location_id', 'raw_character_text', 'raw_location_text', 'spoken_words', 'normalized_text'], axis=1, inplace=True)\\ndf_locations.drop(['number', 'image_url', 'modification_date', 'special'], axis=1, inplace=True)\\ndf_characters.drop(['number', 'image_url', 'gender', 'hair', 'modification_date', 'imdb_url'], axis=1, inplace=True)\",\"Remove unwanted columns\\ndf_script = df_script.drop(columns=['id', 'episode_id'])\",\"Remove unnecessary columns from dfs\\ndf_characters = df_characters.drop(columns=['id'])\\ndf_locations = df_locations.drop(columns=['id'])\\ndf_script = df_script.drop(columns=['id', 'number', 'raw_text', 'timestamp_in_ms', 'speaking_line', 'character_id', 'location_id', 'production_code', 'original_air_date'])\\ndf_episodes = df_episodes.drop(columns=['id', 'image_url', 'video_url'])\",\" Remove all lines with missing values in the following columns\\ncolumns_to_clean = ['episode_id', 'number', 'raw_text']\\n\\ndf_script = df_script.dropna(subset=columns_to_clean)\",\"Dropping lines that have not been assigned to an episode\\ndf_script = df_script.dropna(subset=['episode_id'])\",\"Drop rows with missing values\\ndf_characters = df_characters.dropna(subset=['name'])\\ndf_locations = df_locations.dropna(subset=['name'])\\ndf_script = df_script.dropna(subset=['raw_text', 'character_id', 'location_id', 'episode_id'])\\ndf_episodes = df_episodes.dropna(subset=['title'])\",\" Remove unwanted columns from the dataframes\\ncolumns_to_drop = ['id', 'number', 'raw_text', 'timestamp_in_ms']\\n\\ndf_characters.drop(columns=columns_to_drop, inplace=True, errors='ignore')\\ndf_locations.drop(columns=columns_to_drop, inplace=True, errors='ignore')\\ndf_script.drop(columns=columns_to_drop, inplace=True, errors='ignore')\\ndf_episodes.drop(columns=columns_to_drop, inplace=True, errors='ignore')\",\"Remove unwanted columns\\ndf_script = df_script[['episode_id', 'character_id', 'location_id', 'raw_text']]\\n\\n# Drop rows with missing values\\ndf_script = df_script.dropna()\"],\"marker\":{\"opacity\":0.5,\"size\":5},\"mode\":\"markers+text\",\"name\":\"85_Remove unnecessary columns from dataframes\",\"text\":[\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\"],\"textfont\":{\"size\":12},\"x\":[4.560877323150635,4.7589311599731445,5.205194473266602,4.892553806304932,5.761860370635986,4.960466384887695,5.546411037445068,4.952663898468018,4.860647678375244,4.841768741607666,5.126678466796875,4.532940864562988,5.032098293304443,5.143403053283691,4.554090976715088,5.014378547668457,5.092947959899902,4.7469611167907715,4.536129474639893,4.6229705810546875,4.714929103851318,3.9488680362701416,4.930564880371094,5.0857768058776855,4.722996711730957,4.9286208152771,4.591665267944336,5.651342391967773,5.281432151794434,4.380221366882324,4.827287673950195,5.14180850982666],\"y\":[6.2978034019470215,5.304986476898193,4.9472198486328125,4.998878479003906,6.435298442840576,5.2618327140808105,4.495777130126953,5.925455093383789,4.795116424560547,4.958743095397949,4.529782772064209,5.702368259429932,5.77142333984375,5.653761386871338,5.321275234222412,4.829691410064697,5.372673511505127,5.917134761810303,5.887298583984375,4.647308826446533,6.0650434494018555,4.8297905921936035,4.548862934112549,4.721524238586426,5.887401103973389,4.723366737365723,5.567392826080322,5.260092735290527,4.954878330230713,5.561882972717285,4.954217910766602,5.29162073135376],\"type\":\"scattergl\"},{\"hoverinfo\":\"text\",\"hovertext\":[\"Data Preprocessing\",\" Preprocess columns for easier access\",\"Data loading and preprocessing\",\"Data Preprocessing\",\"Preprocessing\\n# \",\"Pravdepodobne som niekde spravil chybu, preto\\u017ee z tejto \\u010dasti neviem odhadn\\u00fa\\u0165, \\u010do sa stalo. Pros\\u00edm, odk\\u00e1\\u017ete ma na predch\\u00e1dzaj\\u00faci riadok.\",\" Preprocessing\",\" Data Preprocessing\",\"Preprocessing function\",\" Transform raw data before feature creation\",\"Data Preprocessing\",\" Preprocess the data\",\"Define code snippets to preprocess the data further\",\"Load and preprocess data\",\"Data Preprocessing\",\"Data preprocessing tasks\",\"Some preprocessing\",\"Data preprocessing\",\"The first step is to preprocess the data.\",\"--------------  Preprocessing  --------------\",\" Apply initial preprocessing steps\",\"Data Preprocessing\",\"------------------ Preprocessing ---------------------\",\"Preprocessing\\n# We first need to see what the data looks like.\",\"Data Preprocessing\",\"Data preprocessing\",\"Data Preprocessing\",\"Preprocess data\",\"Part 1: Data preprocessing\",\"Data Preprocessing\",\"1. Data overview and preprocessing\"],\"marker\":{\"opacity\":0.5,\"size\":5},\"mode\":\"markers+text\",\"name\":\"86_Data Preprocessing\",\"text\":[\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\"],\"textfont\":{\"size\":12},\"x\":[12.758255958557129,11.665373802185059,13.599937438964844,12.735369682312012,13.53492546081543,14.665803909301758,13.36258602142334,12.812582015991211,13.37210464477539,13.286238670349121,12.893505096435547,13.039057731628418,12.343972206115723,13.430072784423828,12.725640296936035,12.767115592956543,13.558923721313477,12.923962593078613,13.603104591369629,13.651080131530762,13.306731224060059,12.653759002685547,13.655179023742676,13.09111213684082,12.488248825073242,12.493277549743652,12.639408111572266,12.491811752319336,12.945975303649902,12.920466423034668,13.445855140686035],\"y\":[2.1246237754821777,2.267090320587158,1.8486483097076416,2.4868040084838867,3.2822105884552,4.194388389587402,3.2680301666259766,2.4863851070404053,3.176862955093384,2.532388925552368,2.728464365005493,2.6726317405700684,2.788774251937866,2.282271385192871,2.0121800899505615,2.5498266220092773,2.9220738410949707,2.2794528007507324,2.218939781188965,3.450866937637329,3.14060115814209,2.6105191707611084,3.628563642501831,2.560192584991455,2.2041094303131104,2.270270586013794,2.321791887283325,2.86380934715271,2.5428481101989746,2.3175272941589355,2.131645441055298],\"type\":\"scattergl\"},{\"hoverinfo\":\"text\",\"hovertext\":[\"Print first records of df_episodes dataframe\\ndf_episodes.head()\",\" Display the dataframe of episodes using the head() function to display the first 5 rows.\",\"Preview the first 5 lines of the episodes DataFrame\\ndf_episodes.head()\",\" Display the first few rows of the dataframe\\ndf_episodes.head()\",\"The head method can be used to display the first few rows of the dataframe.\\n# Display the first 10 rows of the dataframe\\ndf_episodes.head(10)\",\"Display the first few rows of the dataframe\\ndf_episodes.head()\",\"Display the first 5 rows of the episodes dataframe\\ndf_episodes.head()\",\"Inspecting first few rows of dataset\\ndf_episodes.head()\",\"Print the first 5 rows of the episodes dataframe to understand how the data is structured\\ndf_episodes.head()\",\"Display the first few rows of the episodes dataframe to understand the data.\",\"Display first rows by episodes dataframe\",\"Preview the first 5 lines of df_episodes\\ndf_episodes.head()\",\"Display the first rows of the episodes dataframe\\ndf_episodes.head()\",\"\\n# Display the first rows of the table 'Episodes'\\ndf_episodes.head()\",\"# Show the first 5 rows of the episodes dataframe\\ndf_episodes.head()\",\" Preview the first 5 lines of the dataframe\\ndf_episodes.head()\",\"Displaying the first lines of the episodes dataframe\",\"Display the first few lines of the episodes dataframe\\ndf_episodes.head()\",\"# Display the first 5 rows of the episodes dataframe\\ndf_episodes.head()\",\"Displaying the first rows of the DataFrame to get a sense of the data distribution \\ndf_episodes.head()\",\"Display the first 5 rows of the episodes dataframe\\ndf_episodes.head()\",\"Display the first few rows of the episodes data\\ndf_episodes.head()\",\" Show top 10 rows of the episodes dataframe\\ndf_episodes.head(10)\",\"Show the first few rows of the episodes DataFrame\\ndf_episodes.head()\",\"Displaying the first 5 rows of the episodes dataframe to visualize the data\",\"# Display the first few rows of the dataframe\\ndf_episodes.head()\",\"Print the first rows of the episodes DataFrame\\ndf_episodes.head()\",\"Check the number of episodes in the dataset and the first few lines of the dataframe\",\" Display first 5 records.\\ndf_episodes.head()\",\" Show the top 5 rows of the episodes DataFrame\\ndf_episodes.head()\",\"Explore first 10 records of the dataset\\ndf_episodes.head(10)\"],\"marker\":{\"opacity\":0.5,\"size\":5},\"mode\":\"markers+text\",\"name\":\"87_Displaying first rows of episodes dataframe\",\"text\":[\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\"],\"textfont\":{\"size\":12},\"x\":[0.7544695138931274,0.7758128643035889,0.8478504419326782,0.9641799330711365,0.7536119222640991,0.7682178020477295,0.4596982002258301,1.3519238233566284,0.3134922981262207,1.9391690492630005,1.8813989162445068,1.0363306999206543,0.9183180332183838,1.2452945709228516,0.5239543318748474,0.5376942157745361,2.4584453105926514,1.0956838130950928,0.303911417722702,0.866626501083374,0.3928956985473633,1.1431125402450562,-0.278196781873703,1.1744351387023926,1.4652491807937622,0.8963108062744141,1.1321953535079956,2.753528356552124,0.7350298762321472,-0.20742909610271454,1.707277774810791],\"y\":[4.3399739265441895,4.8993635177612305,4.235754013061523,4.276859283447266,4.675269603729248,4.5204949378967285,5.1930999755859375,3.879967212677002,5.189580917358398,3.8328564167022705,4.084076404571533,3.921868085861206,4.535006523132324,4.338977813720703,5.169179916381836,4.465951442718506,4.127415657043457,4.4888505935668945,5.459396839141846,4.170071601867676,4.990525722503662,4.0079755783081055,5.630600929260254,4.371062755584717,4.491871356964111,4.472735404968262,4.365350246429443,3.0969362258911133,4.7416510581970215,5.691103458404541,3.7023909091949463],\"type\":\"scattergl\"},{\"hoverinfo\":\"text\",\"hovertext\":[\"function to convert string to lowercase and strip white space\\ndef lowercase_and_strip(column):\\n    return column.astype(str).str.lower().str.strip()\",\" Function to pre-process text\\ndef clean_text(text):\\n    # Remove numbers\\n    text = ''.join(word for word in text if not word.isdigit())\\n    # Remove punctuation and make everything lower case\\n    return ''.join(word.lower() for word in text if word.isalpha() or word.isspace())\",\"Custom functions\\n# Custom functions\\ndef clean_text(text):\\n    \\\"\\\"\\\"Clean text data by removing special characters and extra whitespace.\\\"\\\"\\\"\\n    return ' '.join(\\n        word for word in text.split()\\n        if (\\n            not word.startswith('@')\\n            and not word.startswith('http')\\n            and not word.startswith('www')\\n        )\\n    )\",\"Clean text data\",\"Clean text data and remove special characters, punctuation, etc.\",\"Define a function to clean and preprocess text data\",\"Light text preprocessing\",\" Remove unwanted or unnecessary characters from `raw_text` dictionary values and convert them to lowercase\",\"Remove punctuation and format text data\",\"Function to preprocess text data\",\"Clean text\",\"Data prep: lowercase, remove punctuation, remove stop words\",\"Function to convert text to lowercase and remove punctuation and extra spaces\",\"Make everything lower case.\",\"Turning off the scientific notation (e) when displaying numbers\",\"Text preprocessing: removing useless characters and reducing words to their root form.\",\"Text preprocessing and cleaning\",\"Functions to clean and preprocess text data\",\"Helper function to clean text.\",\"remove punctuation and numbers from the text\",\"Slight clean up to ensure consistency (convert to lower case)\",\"Clean data and preprocess text\",\" Strip leading whitespace characters\",\"Remove all characters but keep the letters, make it lowercase and strip\\ndef clean_line(line):\\n    return ''.join(char for char in line if char.isalpha()).lower().strip()\",\"Define function to pre-process the text\",\"Character job_text cleaning\",\" Set text cleaning settings\\nnlp = spacy.load(\\\"en_core_web_md\\\", disable=[\\\"parser\\\", \\\"ner\\\"])\\n\\n# Constants\\nwhite_list_chars = [\\n    \\\"bart\\\", \\\"homer\\\", \\\"marge\\\", \\\"maggie\\\", \\\"lisa\\\", \\\"krusty\\\", \\\"burns\\\",\\n    \\\"millhouse\\\", \\\"apu\\\", \\\"moe\\\", \\\"ned\\\", \\\"edna\\\", \\\"skinner\\\", \\\"ralph\\\",\\n    \\\"barney\\\", \\\"todd\\\", \\\"rod\\\", \\\"hans\\\", \\\"troy\\\", \\\"citizen\\\", \\\"abraham\\\",\\n    \\\"lenny\\\", \\\"carl\\\", \\\"lionel\\\", \\\"selma\\\", \\\"patty\\\", \\\"milhouse\\\", \\\"montgomery\\\",\\n    \\\"clancy\\\", \\\"waylon\\\", \\\"apu_nahasapeemapetilon\\\"\\n]\\n\\n# Function to preprocess texts\\ndef clean_text(text: str) -\\u003e str:\\n    # Convert to lowercase\\n    text = text.lower()\\n    \\n    # Remove punctuation, digits and special characters\\n    text = \\\" \\\".join(token.lemma_ for token in nlp(text) if token.is_alpha)\\n    \\n    return text\",\"Text preprocssing\",\"Define functions to preprocess text data\",\"Functions to make the text easier to process\",\"Helper function to clean a line of text and process it with spaCy\"],\"marker\":{\"opacity\":0.5,\"size\":5},\"mode\":\"markers+text\",\"name\":\"88_Text Preprocessing\",\"text\":[\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\"],\"textfont\":{\"size\":12},\"x\":[9.055501937866211,11.503246307373047,11.40230655670166,11.48188304901123,11.182724952697754,12.167765617370605,12.596962928771973,9.618392944335938,11.154021263122559,12.213286399841309,11.804208755493164,10.76392650604248,10.396976470947266,10.852636337280273,10.891509056091309,12.760499954223633,12.173151016235352,12.132431030273438,12.035967826843262,11.047120094299316,10.470544815063477,11.8558931350708,9.348918914794922,10.441200256347656,12.720267295837402,11.481521606445312,12.226584434509277,12.717737197875977,12.725225448608398,12.5943021774292,12.382244110107422],\"y\":[6.735701560974121,5.624926567077637,5.58055305480957,3.8380959033966064,4.4334564208984375,4.233659744262695,4.296097755432129,6.12894344329834,4.542234420776367,3.7740046977996826,4.788051605224609,4.771390438079834,5.508068084716797,4.867087364196777,4.6529998779296875,4.467979907989502,4.679388999938965,3.9930756092071533,4.796713829040527,4.790691375732422,4.235605716705322,3.771718978881836,7.109116077423096,6.202260494232178,4.433672904968262,5.048855781555176,6.353689193725586,4.246476650238037,3.6882174015045166,4.95515251159668,5.044402122497559],\"type\":\"scattergl\"},{\"hoverinfo\":\"text\",\"hovertext\":[\"Display all columns\\npd.set_option('display.max_columns', None)\",\"Display all columns for visibility\\npd.set_option('display.max_columns', None)\",\"Display all columns to know which one to remove\\npd.set_option('display.max_columns', None)\",\"Show all columns\\npd.set_option('display.max_columns', None)\",\"# Display all columns\\npd.set_option('display.max_columns', None)\",\"display all columns\\npd.options.display.max_columns = None\",\"Display all columns as there might be many columns in the datasets\\npd.set_option('display.max_columns', None)\",\"Display all columns to understand the dataset better\\npd.set_option('display.max_columns', None)\",\"Display all columns\\npd.set_option('display.max_columns', None)\",\"Display all columns to be able to choose\\npd.options.display.max_columns = None\",\"Auxiliary code to display all columns\\npd.set_option('display.max_columns', None)\",\"Display all columns so that we can make an informed decision on what to use\\npd.options.display.max_columns = None\",\"Ensure we can see all the columns\\npd.set_option('display.max_columns', 500)\",\"Display all columns to understand the structure of the data\\npd.options.display.max_columns = None\",\"Display all available columns\\npd.options.display.max_columns = None\",\"Show all columns explicitly\\npd.set_option('display.max_columns', None)\",\"Set this option to characteristic_size so as to show at most the characteristic number of relevant columns.\",\" Show all columns\\npd.set_option('display.max_columns', None)\",\"Displays all columns\\npd.set_option('display.max_columns', None)\",\" Set option to display all columns in the notebook\\npd.set_option('display.max_columns', None)\",\"Set to display all columns\\npd.set_option('display.max_columns', None)\",\"isplay all columns\\npd.set_option('display.max_columns', None)\",\"Set parameter to display all columns\",\"Set the display options when displaying all columns.\",\"Show all columns\\npd.options.display.max_columns = None\",\"Show all available columns\\npd.set_option('display.max_columns', None)\",\"Display all tables\\npd.set_option('display.max_columns', None)\",\"Show more columns\\npd.set_option('display.max_columns', None)\",\"Display all columns for a better view\\npd.options.display.max_columns = None\",\"Set option to display all columns at any time\",\" Display all columns\\npd.set_option('display.max_columns', None)\"],\"marker\":{\"opacity\":0.5,\"size\":5},\"mode\":\"markers+text\",\"name\":\"89_display options for columns in pandas dataframe\",\"text\":[\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\"],\"textfont\":{\"size\":12},\"x\":[22.87675666809082,22.449907302856445,23.10712242126465,23.07203483581543,23.382965087890625,22.494346618652344,22.648529052734375,23.164470672607422,22.914901733398438,22.536046981811523,22.796037673950195,23.1783447265625,23.998991012573242,23.02702522277832,22.645036697387695,22.814197540283203,23.309181213378906,22.668094635009766,23.08765411376953,22.467866897583008,23.179702758789062,23.377323150634766,22.294147491455078,22.465713500976562,22.652141571044922,22.64725685119629,23.0423526763916,23.262256622314453,22.81560707092285,22.00054931640625,23.036008834838867],\"y\":[-1.6988674402236938,-1.9359233379364014,-1.4123995304107666,-2.067390203475952,-1.435486078262329,-2.1372177600860596,-1.1000834703445435,-1.3833969831466675,-1.6443594694137573,-1.617776870727539,-1.7875508069992065,-1.8213677406311035,-0.9208330512046814,-1.7077007293701172,-1.7746589183807373,-1.9320803880691528,-1.3477863073349,-1.8261351585388184,-1.370652198791504,-0.8773791193962097,-1.3358757495880127,-1.7931302785873413,-1.595520257949829,-1.2646852731704712,-1.8978101015090942,-1.7480899095535278,-1.9493367671966553,-1.6200876235961914,-2.0516510009765625,-1.0203107595443726,-1.5159962177276611],\"type\":\"scattergl\"},{\"hoverinfo\":\"text\",\"hovertext\":[\" Top-5 rows of the characters DataFrame\\ndf_characters.head()\",\"Display top rows of the characters dataframe\\ndf_characters.head()\",\" Print top 5 rows of the characters dataset\\ndf_characters.head()\",\" Display top 5 rows of characters dataframe\\ndf_characters.head()\",\"Display the top 5 records of each dataframe\\ndf_characters.head()\",\"Check top few rows of the dataframe of simpsons_characters\",\"Filter for \\\"Lisa Simpson\\\" character\\ndf_lisa_lines = df_script[df_script['character_id'] == 9]\\n\\n# Show the top 5 rows\\ndf_lisa_lines.head()\",\"Checking top 5 records to understand data better\\ndf_characters.head()\",\"Display top 5 rows of characters dataframe\\ndf_characters.head()\",\" The top few rows of the character dataset\\nprint(df_characters.head())\",\"Print the top 5 rows of the characters dataframe\\ndf_characters.head()\",\"View top few rows of character dataset\\ndf_characters.head()\",\"View the top 5 rows of the characters DataFrame\\ndf_characters.head()\",\" Display top of the Characters DF\\ndf_characters.head()\",\" Show the top 5 rows of the characters dataframe\\ndf_characters.head()\",\"Show the top 20 rows of the characters dataframe\\ndf_characters.head(20)\",\"Show the top 5 rows of the characters dataframe\\ndf_characters.head()\",\" View top rows of characters dataframe\\ndf_characters.head()\",\"Check top 5 records of each dataset\\ndf_characters.head()\",\"Print the top 5 rows of the characters dataframe\\ndf_characters.head()\",\"Inspect top rows of df_characters\\ndf_characters.head()\",\"Show top 10 rows of Simpsons character dataframe\\ndf_characters.head(10)\",\"Display the top 5 rows of the characters dataframe\\ndf_characters.head()\",\" Display top 5 rows of characters dataframe\",\"top 5 rows of the characters dataframe\\ndf_characters.head()\",\" Display the top few rows of the DataFrame\\ndf_characters.head()\",\"View top few rows of characters dataframe\\ndf_characters.head()\",\" Print the top 5 records of the characters dataframe\\nprint(df_characters.head(5))\",\"Display the top 5 rows of the 'characters' dataframe\\ndf_characters.head()\",\" Display the top 5 rows of the characters dataframe\\ndf_characters.head()\",\"top 5 rows of the characters dataframe\\ndf_characters.head()\"],\"marker\":{\"opacity\":0.5,\"size\":5},\"mode\":\"markers+text\",\"name\":\"90_Viewing top rows of characters dataframe\",\"text\":[\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\"],\"textfont\":{\"size\":12},\"x\":[2.3039779663085938,2.6924374103546143,1.8662035465240479,2.5362436771392822,1.9361791610717773,2.0934839248657227,2.511104106903076,1.3560583591461182,2.389124870300293,3.2997961044311523,1.611586093902588,2.503565788269043,2.488032579421997,3.4339828491210938,2.0054938793182373,2.0557286739349365,2.182497262954712,2.918945074081421,0.9195274114608765,1.8655000925064087,3.030829668045044,1.5407049655914307,2.166063070297241,3.0854554176330566,2.113986015319824,2.6457903385162354,2.7146048545837402,1.759408712387085,2.391841173171997,2.10517954826355,2.1785166263580322],\"y\":[14.334050178527832,15.422988891601562,14.801796913146973,14.652112007141113,14.301068305969238,13.426156044006348,13.753087997436523,13.692858695983887,14.622097969055176,15.633853912353516,15.015874862670898,16.047786712646484,14.885125160217285,15.893425941467285,14.409622192382812,14.403365135192871,14.310914993286133,15.481498718261719,13.893656730651855,14.893007278442383,16.086515426635742,13.830946922302246,14.698101043701172,14.360917091369629,14.16971492767334,15.283724784851074,15.475069046020508,14.525745391845703,14.662880897521973,14.674236297607422,14.1421537399292],\"type\":\"scattergl\"},{\"hoverinfo\":\"text\",\"hovertext\":[\"Set some options for pandas\\npd.set_option('display.max_columns', 999)\\npd.set_option('display.max_rows', 999)\",\" Set the display options of pandas to have a\\n# larger number of elements and to display more columns\\npd.options.display.max_rows = 999\\npd.options.display.max_columns = 999\",\" Display maximum 5 rows and columns of a data frame\\npd.set_option('display.max_columns', 5)\\npd.set_option('display.max_rows', 5)\",\"To avoid truncating the display of DataFrames, we're going to tell pandas to display up to 100 columns and 100 rows.\\npd.set_option('display.max_columns', 100)\\npd.set_option('display.max_rows', 100)\",\"Increases the range of the rows displayed when 'print' displays the dataframe.\",\" This will cause pandas  to pretty print upto 200 columns and 100 rows.\",\"Increase the max number of columns to display for the PD dataframes, as follows\",\" Set the maximum number of rows and columns displayed when printing DataFrames\\npd.set_option('display.max_rows', 500)\",\"# Set the maximum number of rows and columns displayed when printing a DataFrame\\npd.set_option('display.max_rows', 300)\\npd.set_option('display.max_columns', 300)\",\" Function to display large dataframes in a more human friendly way.\\ndef display_df(df, n_lines = 5):\\n    pd.set_option('display.max_colwidth', 200)\\n    if (len(df) \\u003e n_lines*2):\\n        display(df[:n_lines])\\n        print('...')\\n        display(df[-n_lines:])\\n    else:\\n        display(df)\\n    pd.reset_option('display.max_colwidth')\",\" Set the display options for the dataframes to print all the columns and to show the max number of rows\",\"Limit the number of rows displayed when printing DataFrames\\npd.options.display.max_rows = 10\",\"Limit the number of rows displayed for the dataframes to a maximum of 5\\npd.set_option('max_rows', 5)\",\"Limits the number of displayed rows in a pandas DataFrame to improve the output readability\\npd.set_option('display.max_rows', 5)\",\" Set the max display of rows in pandas display to 10\",\" Set max display of rows and columns for pandas dataframes\\npd.set_option('display.max_rows', 10)\\npd.set_option('display.max_columns', 10)\",\"Setting to display the max amount of columns as 200, this is just for ease of viewing the dataframe.\",\" Set pandas display options to better show long data\\npd.set_option('display.max_columns', 500)\",\"Configure pandas to display all columns and show dataframes'\\n# up to a maximum of 10 rows (for readability)\\npd.set_option('display.max_columns', None)\\npd.set_option('display.max_rows', 10)\",\" Display expanded rows and columns when displaying DataFrames\\npd.set_option('display.max_columns', 500)\\npd.set_option('display.max_rows', 150)\",\" Set a limit on the number of rows and columns displayed by pandas DataFrames\\npd.set_option('display.max_rows', 10)\\npd.set_option('display.max_columns', 100)\",\"Sets up dataframe display\\npd.set_option('display.max_columns', 500)\",\"Options for pandas\\npd.set_option('display.max_rows', 200)\\npd.set_option('display.max_columns', 200)\",\"Setting limit of rows and columns to see when displaying dataframes\\npd.set_option('display.max_columns', 100)\\npd.set_option('display.max_rows', 100)\",\"Set some pandas defaults for nicer printing\\npd.set_option('display.max_columns', 500)\\npd.set_option('display.max_rows', 500)\",\" Set the display options for large DataFrames\\npd.set_option('display.max_columns', None)\",\"Enable the processing of large datasets by pandas\\npd.options.display.max_rows = 10\",\"Set maximum columns\\u002frows to display for dataframes\\npd.set_option('display.max_columns', 500)\\npd.set_option('display.max_rows', 500)\",\"pd.set_option('max_rows', 10)  # show at most 10 rows for each DataFrame in this notebook\",\"# Display up to 35 columns (if the dataframe has more than 35 columns)\\npd.set_option('display.max_columns', 35)\\n\\n# Display up to 200 rows\\npd.set_option('display.max_rows', 200)\",\"Limit the amount of displayed rows for each dataframe\\npd.set_option('display.max_rows', 10)\"],\"marker\":{\"opacity\":0.5,\"size\":5},\"mode\":\"markers+text\",\"name\":\"91_Setting maximum number of rows and columns for displaying DataFrames in Pandas\",\"text\":[\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\"],\"textfont\":{\"size\":12},\"x\":[22.379833221435547,22.383193969726562,22.600208282470703,22.082050323486328,22.366390228271484,22.5244083404541,22.35542869567871,22.864151000976562,22.390869140625,22.246051788330078,22.516359329223633,23.0684871673584,22.47665786743164,22.80872917175293,22.754478454589844,22.582944869995117,22.285507202148438,22.552236557006836,21.806257247924805,22.871360778808594,22.471694946289062,22.783061981201172,22.59061050415039,22.56148910522461,22.68963050842285,22.629301071166992,22.41215705871582,22.638837814331055,22.736812591552734,22.39357566833496,22.8104305267334],\"y\":[0.7414491772651672,1.1418581008911133,-0.21964260935783386,1.1344141960144043,0.1015501618385315,0.8222919702529907,0.4714851677417755,0.35604822635650635,0.13907533884048462,1.0612276792526245,0.4214368760585785,0.12921567261219025,-0.07308097183704376,0.0026709793601185083,0.3813946843147278,0.16437716782093048,0.4001637399196625,1.3861150741577148,0.49646785855293274,0.4809293746948242,0.33364251255989075,-0.12379888445138931,0.6215729713439941,-0.03418263420462608,0.9034382104873657,0.48680630326271057,0.9334600567817688,0.29420962929725647,0.16746720671653748,0.21205438673496246,-0.0638347789645195],\"type\":\"scattergl\"},{\"hoverinfo\":\"text\",\"hovertext\":[\"Show the first few characters of each dataframe\\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()\",\" Displaying the first few rows of each dataframe\\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()\",\"Display the first few rows of each dataframe\\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()\",\"imple display the first few rows of each DataFrame for a quick inspection\\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()\",\"Display the first few rows of each dataframe\\ndf_episodes.head(), df_characters.head(), df_locations.head(), df_script.head()\",\" Display the first 3 rows of each dataframe\\ndisplay(df_characters.head(3),\\n        df_locations.head(3),\\n        df_script.head(3),\\n        df_episodes.head(3))\",\" Display first rows of all DataFrames related to the Simpsons dataset\\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()\",\" Display the first few rows of each dataframe\\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()\",\" Display first few rows of each dataframe\\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()\",\"Show first few rows of each dataframe\\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()\",\" Display the first few rows of each dataframe\\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()\",\" Display the first few characters of the episodes dataframe\\ndf_episodes.head()\",\"Display first few rows of each dataframe\\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()\",\"Displaying the first few rows of each data set\\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()\",\" Display the first few rows of each dataframe\\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()\",\" Display the first few characters of each dataframe\\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()\",\"Display first rows of each dataframe\\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()\",\"Display the first few rows of the dataframes\\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()\",\"Show the first rows for each dataframe\\ndf_list = [df_characters, df_locations, df_script, df_episodes]\",\"Return the first few records\\nfor df in [df_characters, df_locations, df_script, df_episodes]:\\n    display(df.head())\",\"Show the first couple of rows of each dataframe\\ndf_episodes.head(), df_script.head(), df_characters.head(), df_locations.head()\",\" Show the first few rows of each dataframe\\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()\",\"Show the first few rows of each dataframe\\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()\",\"Show first data in each dataframe\\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()\",\"Display the first few rows of each dataframe\\ndf_characters.head(), df_locations.head(), df_episodes.head(), df_script.head()\",\"Display the first few rows of each dataframe\\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()\",\" Display the first few records of each dataframe\\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()\",\"display the first few rows of each dataframe\\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()\",\" Display the first few rows of each dataframe\\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()\",\" Display first few rows of each dataset\\ndf_episodes.head(), df_characters.head(), df_locations.head(), df_script.head()\"],\"marker\":{\"opacity\":0.5,\"size\":5},\"mode\":\"markers+text\",\"name\":\"92_Displaying first few rows of related dataframes\",\"text\":[\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\"],\"textfont\":{\"size\":12},\"x\":[-3.0961551666259766,-3.5398523807525635,-3.817349910736084,-4.148089408874512,-3.799283742904663,-3.6029231548309326,-3.676621437072754,-3.8520240783691406,-4.012237548828125,-4.2775444984436035,-3.917235851287842,-1.3148393630981445,-4.041881084442139,-3.500420331954956,-3.747182607650757,-2.9241068363189697,-3.8454535007476807,-4.076230049133301,-4.269696235656738,-4.061245918273926,-3.6226022243499756,-3.930316686630249,-3.779844045639038,-4.374457359313965,-3.8215830326080322,-4.0669074058532715,-4.006932735443115,-3.8224267959594727,-3.698197603225708,-3.4744367599487305],\"y\":[6.9273810386657715,7.08547830581665,7.467024326324463,7.371377944946289,7.887430667877197,6.908595085144043,7.812162399291992,7.333422660827637,7.673900127410889,7.599391460418701,7.430133819580078,5.933964729309082,7.653641223907471,7.087433815002441,7.311695575714111,6.722973823547363,7.336970329284668,7.064126491546631,7.610344409942627,7.742070198059082,7.563851356506348,7.31175422668457,7.596118927001953,7.128333568572998,7.509984970092773,7.446109771728516,7.819452285766602,7.574499607086182,7.568714618682861,7.256825923919678],\"type\":\"scattergl\"},{\"hoverinfo\":\"text\",\"hovertext\":[\"Load pre-trained spacy model\\nnlp = spacy.load('en_core_web_sm')\",\"Set up spacy model\\nnlp = spacy.load('en_core_web_md')\",\"Load the pre-trained Spacy NLP model\\nnlp = spacy.load('en_core_web_md')\",\"Load pre-trained model\\nnlp = spacy.load('en_core_web_md')\",\"Load the pre-trained spacy model\\nnlp = spacy.load('en_core_web_sm')\",\" Load model\\nnlp = spacy.load('en_core_web_md')\",\" Optional, you can run below, if you want to use the medium model. It takes some time to load.\\nnlp = spacy.load('en_core_web_md')\",\" Load the spaCy model\\nnlp = spacy.load('en_core_web_md')\",\" text processing and nlp\\nnlp = spacy.load('en_core_web_md')\",\"Define and load the model\\nnlp = spacy.load('en_core_web_md')\",\"# We use spacy's medium English model\\nnlp = spacy.load('en_core_web_md')\",\"Spacy model\\nnlp = spacy.load(\\\"en_core_web_md\\\")\",\"Load the serialized version of the SpaCy pre-trained model 'en_core_web_md'\\nnlp = spacy.load('en_core_web_md')\",\"# Load the spacy model (medium model is sufficient, small would be too small and big too large)\\nnlp = spacy.load(\\\"en_core_web_md\\\")\",\"Load Spacy\\nnlp = spacy.load('en_core_web_md')\",\"Load spaCy model\\nnlp = spacy.load('en_core_web_md')\",\" Load the pre-trained Spacy model\\nnlp = spacy.load('en_core_web_sm')\",\"Load the pre-trained spaCy NLP model\\nnlp = spacy.load('en_core_web_sm')\",\"Initialize spacy\\nnlp = spacy.load('en_core_web_md')\",\"Set up spacy\\nnlp = spacy.load('en_core_web_md')\",\"Load spacy\\nnlp = spacy.load(\\\"en_core_web_md\\\")\",\" Load the pre-trained spacy NLP model\\nnlp = spacy.load('en_core_web_sm')\",\"Load pre-trained spaCy model\\nnlp = spacy.load('en_core_web_sm')\",\"\\n# Caching pre-trained model\\nnlp = spacy.load('en_core_web_sm')\",\"Load language model\\n# This may take a while\\nnlp = spacy.load('en_core_web_md')\",\"Create a new instance of the nlp pipeline\\nnlp = spacy.load('en_core_web_md')\",\"Load the pre-trained spacy model\\nnlp = spacy.load('en_core_web_md')\",\"NLP model\\nnlp = spacy.load('en_core_web_md')\",\"spacy.load('en_core_web_md')\\nnlp = spacy.load('en')\",\"Path to where the pre-trained model is stored.\\npath_to_model = 'model'\\n\\n# Load the pre-trained model\\nnlp = spacy.load(path_to_model)\"],\"marker\":{\"opacity\":0.5,\"size\":5},\"mode\":\"markers+text\",\"name\":\"93_spacy load pretrained NLP model\",\"text\":[\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\"],\"textfont\":{\"size\":12},\"x\":[16.517311096191406,17.7513484954834,16.917016983032227,16.880752563476562,16.546619415283203,17.636606216430664,17.69428825378418,17.72275733947754,18.166465759277344,17.864648818969727,17.954679489135742,17.99054718017578,17.267492294311523,18.194265365600586,18.110904693603516,17.628780364990234,16.651485443115234,16.179414749145508,17.993680953979492,17.972349166870117,18.069061279296875,16.146251678466797,16.447477340698242,16.377641677856445,17.717973709106445,17.41860580444336,17.01343536376953,17.66870880126953,17.722929000854492,16.188806533813477],\"y\":[7.4272050857543945,7.77129602432251,7.751218795776367,7.31459903717041,7.943729877471924,7.63766622543335,7.217322826385498,7.594123840332031,8.066932678222656,7.719091415405273,8.011152267456055,7.871971607208252,7.707732200622559,7.774460315704346,7.959009647369385,7.692429065704346,7.837639808654785,7.986832141876221,8.178874969482422,7.981590747833252,8.163033485412598,8.183004379272461,7.683818340301514,7.395164966583252,8.0018949508667,7.8849406242370605,7.673384666442871,7.641910076141357,8.22282600402832,6.909470558166504],\"type\":\"scattergl\"},{\"hoverinfo\":\"text\",\"hovertext\":[\"Creating the wordclouds requires some data-wrangling, so I'm going to start by providing me  the functions for pre-processing the data.\",\"Utils\\nfrom utils import get_text_entities, clean_dialogue, plot_wordcloud\",\"Installation TIP - if you don't have wordcloud installed, you might need to run !pip install wordcloud in a notebook cell.\",\"Setting the parameters for the word cloud.\",\"Set the stopwords and create the word cloud.\",\"Create word cloud function\",\"Question 5: Should we preprocess the text data further before we create a Wordcloud?\",\"Setting up the Word Cloud parameters and extracting the tokens\\nwordcloud = WordCloud(width = 800, height = 800, \\n                background_color ='white', \\n                stopwords = stopwords, \\n                min_font_size = 10)\",\"Function to display and store word cloud\",\"Set up wordcloud\\nfont_path = '\\u002fusr\\u002fshare\\u002ffonts\\u002ftruetype\\u002fdejavu\\u002fDejaVuSans-Bold.ttf'\\nwordcloud = WordCloud(\\n    width = 900,\\n    height = 500,\\n    background_color = 'black',\\n    stopwords = STOPWORDS,\\n    contour_width = 0.5,\\n    contour_color = 'steelblue',\\n    collocations = False,\\n    colormap = 'viridis',\\n    font_path = font_path\\n)\",\"Create the word cloud function using the WordCloud package.\",\"Define the path to the word frequency image that we will generate using WordCloud.\",\"Set text variable and create a word cloud.\",\"Sets the amount of words to display in WordCloud and also the font size.\",\"Create a background WordCloud for an image.\",\"Set up the WordCloud with the parameters specified in the task\",\"Wordcloud setup\\nwc = WordCloud(width=800, height=400, max_words=200, background_color='white')\",\"Create and init default wordcloud configuration\\nwc_default_config = {\\n    \\\"max_words\\\": 100,\\n    \\\"width\\\" : 800,\\n    \\\"height\\\" : 400,\\n    \\\"collocations\\\" : False #\\\"False colocations\\\" are a pair or more of words that are commonly co-located in a text. In general, they tend to appear together more than would be expected by chance\\n}\",\" from wordcloud import WordCloud\",\"Creating an instance of the WordCloud class.\",\"Set the max budget for the individual wordclouds\\nmax_b = 100\",\"# To create the wordclouds we will need the large language model \\n# and some additional utility code from the course NLP repository\\n!wget https:\\u002f\\u002fgithub.com\\u002fSDS-AAU\\u002fSDS-master\\u002fraw\\u002fmaster\\u002fM3\\u002fnlp\\u002fnlp.py -O nlp\\u002fnlp.py\\n!wget https:\\u002f\\u002fgithub.com\\u002fSDS-AAU\\u002fSDS-master\\u002fraw\\u002fmaster\\u002fM3\\u002fnlp\\u002fsdsai_ofehome.py -O nlp\\u002fsdsai_ofehome.py\",\"Create an instance of the WordCloud class and model the word cloud using the script data\",\"Create an instance of the WordCloud class\",\"Define a function to create a word cloud from a given text\",\"Set the dimension of word cloud to be created.\",\"Helper functions to create WordClouds\",\"Create an instance of the WordCloud class.\",\"Set up a basic word cloud using WordCloud.\",\"Set up the word cloud dictionary and the function to plot it.\"],\"marker\":{\"opacity\":0.5,\"size\":5},\"mode\":\"markers+text\",\"name\":\"94_Creating a Word Cloud\",\"text\":[\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\"],\"textfont\":{\"size\":12},\"x\":[12.569016456604004,13.366557121276855,13.318922996520996,12.880955696105957,12.695133209228516,13.001433372497559,12.698562622070312,13.03169059753418,13.016080856323242,13.021075248718262,13.013912200927734,12.299534797668457,12.787455558776855,12.704282760620117,12.74463939666748,13.334756851196289,12.87796401977539,12.420695304870605,13.48798942565918,13.488014221191406,12.967490196228027,13.156044006347656,13.308241844177246,13.106772422790527,12.401341438293457,12.96860122680664,13.111029624938965,13.2726469039917,12.996909141540527,12.494791984558105],\"y\":[6.744438171386719,6.154358863830566,6.8847575187683105,7.370049953460693,7.843613624572754,7.556560039520264,5.836143493652344,7.56648063659668,7.689146041870117,7.177070140838623,7.3732171058654785,7.5557661056518555,7.525168418884277,7.423478603363037,7.548572063446045,6.913782596588135,7.5382256507873535,7.258279323577881,6.700088977813721,6.995993614196777,7.076213836669922,6.970451831817627,6.959115028381348,7.272034168243408,7.334074974060059,7.9084086418151855,6.848330974578857,7.027601718902588,6.931781768798828,8.256111145019531],\"type\":\"scattergl\"},{\"hoverinfo\":\"text\",\"hovertext\":[\"Inspect first few rows of each dataframe\\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()\",\"Inspect the first few rows of each dataframe\\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()\",\"inspect the first few lines of each dataframe\\ndf_script.head(), df_characters.head(), df_locations.head(), df_episodes.head()\",\"View the dataset headers and the first five records in the dataframes.\\ndf_episodes.head(), df_characters.head(), df_locations.head(), df_script.head()\",\" inspect datasets' first few rows\\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()\",\"Look at the first few rows of each dataframe\\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()\",\"Extracting the character, location, and episode data from the script data\\ncharacters = sorted(df_script.raw_character_text.unique())\\nlocations = sorted(df_script.raw_location_text.unique())\\nepisodes = sorted(df_script.raw_location_text.unique())\",\"Inspect the first few rows of each dataframe\\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()\",\"Look at first 5 rows of each dataframe\\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()\",\"Inspecting the data for first rows\\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()\",\"Inspect the first few rows of each dataframe\\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()\",\"inspect the first few entries of each dataframe\\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()\",\"Inspect the first few rows of each DataFrame\\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()\",\"Inspect the first few rows of each dataframe\\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()\",\"Look at the first 5 rows of each dataframe\\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()\",\"Explore the first few rows of each dataframe\\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()\",\"Inspect the first five rows of each dataframe\\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()\",\"Explore the first rows of each dataframe\\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()\",\"Browse the first few rows of each DataFrame\\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()\",\"Inspect first few rows of each dataframe\\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()\",\"Let's display the heads of the DataFrames to have a first look at the data\\ndf_locations.head(), df_characters.head(), df_episodes.head(), df_script.head()\",\"Inspect the first few rows of each dataframe\\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()\",\"Inspect the first few lines of each dataframe\\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()\",\"Inspect the first rows of each dataframe\\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()\",\"View the top 5 records of all the Dataset\\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()\",\"Look at the first 5 rows of each dataframe\\ndf_script.head(), df_characters.head(), df_locations.head(), df_episodes.head()\",\"Let's display the first couple of rows of each of our dataframes to see what they look like:\\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()\",\"First let's display the first few rows of each dataframe, to inspect what kind of information we've got:\\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()\",\" Check out the first few rows of each DataFrame\\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()\",\"Look at the first 5 rows in each dataset\\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()\"],\"marker\":{\"opacity\":0.5,\"size\":5},\"mode\":\"markers+text\",\"name\":\"95_Exploring Dataframes with First Few Rows\",\"text\":[\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\"],\"textfont\":{\"size\":12},\"x\":[-4.333655834197998,-4.279210090637207,-4.259525775909424,-3.345651388168335,-3.4029524326324463,-3.9178946018218994,1.3232128620147705,-4.3237624168396,-3.4700779914855957,-4.077340126037598,-4.248616695404053,-4.103243827819824,-4.416697025299072,-4.190308094024658,-3.549823760986328,-3.9798920154571533,-3.5455570220947266,-4.389713764190674,-4.2498602867126465,-4.314661502838135,-4.136541843414307,-4.204813480377197,-4.19199800491333,-4.434942245483398,-3.123142957687378,-3.7226569652557373,-4.031577110290527,-4.357059001922607,-3.7083518505096436,-3.0781211853027344],\"y\":[4.4754319190979,4.165947437286377,3.226093292236328,3.848781108856201,4.026841163635254,3.373667001724243,5.709084510803223,4.031835556030273,3.828016757965088,3.9724016189575195,3.9658360481262207,3.592031478881836,4.260091304779053,4.089324951171875,3.6567747592926025,4.099430561065674,4.305058479309082,4.128446102142334,4.49118709564209,4.543044090270996,3.0162148475646973,3.999661445617676,3.1492292881011963,4.134511947631836,3.3363564014434814,3.526167154312134,3.4855051040649414,3.418379783630371,2.856879234313965,3.2101802825927734],\"type\":\"scattergl\"},{\"hoverinfo\":\"text\",\"hovertext\":[\" Display the first few rows of the dataframe to understand its structure\\ndf_characters.head()\",\"Display the first few rows of the characters dataset to understand its structure\\nprint(df_characters.head())\",\"Display the first few rows of the characters dataframe to understand its structure\\ndf_characters.head()\",\"Show the first few rows of the dataset to understand its structure\\ndf_characters.head()\",\"Display the first few rows of the characters dataframe to understand its structure\\ndf_characters.head()\",\" Print the first few entries of the characters table to understand its structure and the information available.\\ndf_characters.head()\",\"Display the first few rows of the dataframe to understand its structure and content\\ndf_characters.head()\",\"Displaying the first few rows of the characters DataFrame to understand its structure\\ndf_characters.head()\",\"Load the data and display the first few rows to understand the structure of the data\\ndf_characters.head()\",\" Display the first few rows of each dataframe to understand their structure\\ndf_characters.head()\",\"Display the first few rows of the dataframe to understand its structure.\\ndf_characters.head()\",\" Display the first few rows of the dataframe to understand its structure and contents\\ndf_characters.head()\",\" Display the first few lines of each dataframe to understand better their structure\\ndf_characters.head()\",\"Display the first few rows of the dataframe to understand its attributes and values\\ndf_characters.head()\",\"Display the first few entries of each table to understand its structure and content\\ndf_characters.head()\",\"Display the first few lines of the characters data frame to understand its structure\\ndf_characters.head()\",\"Show the first few elements of the characters dataframe to understand its structure\\ndf_characters.head()\",\" Display the first few rows of each dataframe to understand the data better\\ndf_characters.head()\",\" Display the first few rows of each DataFrame to understand its structure\\ndf_characters.head()\",\"display the first few rows of each dataframe to understand its structure\\ndf_characters.head()\",\"View the first few rows of the dataframe to understand the data better\\ndf_characters.head()\",\"Display the first few rows of each dataframe to understand its structure and contents.\\ndf_characters.head()\",\"View the first 5 rows of the characters DataFrame to understand its structure and content\\ndf_characters.head()\",\" Display the first few rows of the characters DataFrame to understand its structure.\\ndf_characters.head()\",\"Display the first few rows of each dataframe to understand their structure\\ndf_characters.head()\",\"Looking at the first few rows of the characters dataset to understand its structure and contents\\nprint(df_characters.head())\",\" Print first rows of the dataframe to understand the data structure\\nprint(df_characters.head())\",\"Inspect the first few rows of each dataframe to understand its structure and content\\ndf_characters.head()\",\" Display the first few rows of the dataframe to understand its structure\\ndf_characters.head()\",\" Visualize the first few rows of each dataframe to understand its structure\\ndf_characters.head()\"],\"marker\":{\"opacity\":0.5,\"size\":5},\"mode\":\"markers+text\",\"name\":\"96_Understanding the structure of the characters dataframe by displaying its first few rows\",\"text\":[\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\"],\"textfont\":{\"size\":12},\"x\":[3.574429512023926,4.007792949676514,3.8884124755859375,4.002033710479736,4.0418477058410645,3.487870693206787,3.698249340057373,3.781529426574707,3.7633090019226074,3.4761743545532227,3.5688376426696777,3.358102798461914,3.6608848571777344,3.5519511699676514,1.8956738710403442,3.863896369934082,4.313465595245361,3.81215500831604,3.746429443359375,3.575802803039551,4.169159412384033,3.404700517654419,3.9931297302246094,3.4981331825256348,3.6482796669006348,4.425571441650391,3.7324233055114746,3.6830272674560547,3.8140108585357666,4.209090232849121],\"y\":[17.274738311767578,16.248178482055664,16.95166015625,16.51905632019043,17.09714126586914,15.834543228149414,17.219833374023438,16.977346420288086,16.909900665283203,17.082401275634766,17.298934936523438,17.30058479309082,17.352401733398438,17.517383575439453,15.212467193603516,17.076658248901367,17.13949966430664,17.201467514038086,17.003189086914062,16.89081382751465,17.792509078979492,17.2458553314209,16.782533645629883,17.01953887939453,16.973770141601562,15.529043197631836,17.79618263244629,16.48579978942871,17.426847457885742,16.65070343017578],\"type\":\"scattergl\"},{\"hoverinfo\":\"text\",\"hovertext\":[\"Merge the datasets\",\"Merge the datasets to get more context and consistency\",\"Merge datasets\",\"merging the datasets and looking at some examples\",\"FIREST, let's take a look at the schema of the data we have and decide how we should best merge it all together.\",\"Merge all the datasets to get the full dataset\",\"Merge datasets to get one big dataset\",\"Merge the datasets\",\"Merge the datasets to obtain a single dataset containing all the information needed for analysis.\",\" Merge the datasets based on their respective keys.\",\"Merge the datasets to make it more useful for analysis.\",\" Preprocesing - Merge datasets\",\"Merge all datasets\",\"Merge the datasets.\",\"Merge the datasets to get all the information at one place.\",\"Merging the datasets based on the IDs to create one large dataset.\",\" Merge the datasets\",\"Fixing types and merging datasets\",\"Merge datasets to simplify analysis\",\"Merge the datasets\",\" Combining all the different datasets\",\" Combine and sort the datasets based on the key IDs\",\"Merge the datasets together to create a single coherent dataset.\",\"Merge the files\",\"Merge datasets\",\" Merge data to enrich dataset\",\" Merge the datasets\",\"Merge the datasets on foreign keys\",\"Merge all the datasets based on the common column (id)\"],\"marker\":{\"opacity\":0.5,\"size\":5},\"mode\":\"markers+text\",\"name\":\"97_Merging Datasets\",\"text\":[\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\"],\"textfont\":{\"size\":12},\"x\":[9.661069869995117,9.943281173706055,9.923524856567383,9.40796947479248,10.290925979614258,9.61958122253418,9.359965324401855,9.714651107788086,9.549478530883789,9.8305082321167,10.11577320098877,9.921493530273438,9.5466890335083,10.139270782470703,9.633233070373535,9.631067276000977,9.830734252929688,10.16858196258545,9.961773872375488,9.56831169128418,9.506620407104492,9.424209594726562,9.88292121887207,10.354565620422363,9.990755081176758,10.195311546325684,9.752998352050781,9.90147590637207,9.423203468322754],\"y\":[-0.775830864906311,-0.6854009032249451,-0.42464616894721985,-0.6092526912689209,-0.11851540207862854,-0.9616194367408752,-0.4040786623954773,-0.5475029945373535,-0.4392533600330353,-0.43285563588142395,-0.6143152713775635,-0.06472219526767731,-0.4443051517009735,-0.7524576187133789,-0.7456499934196472,-0.3939402997493744,-0.6604800820350647,-0.21498598158359528,-0.5134743452072144,-0.49228930473327637,-0.4488627314567566,-0.42758500576019287,-0.880443811416626,-0.18344685435295105,-0.39458951354026794,-0.4449831545352936,-0.5500125288963318,-0.37450045347213745,-0.11473696678876877],\"type\":\"scattergl\"},{\"hoverinfo\":\"text\",\"hovertext\":[\"Hide warnings\\nimport warnings\\nwarnings.filterwarnings('ignore')\",\" optionally suppress some warnings\\nimport warnings\\nwarnings.simplefilter(\\\"ignore\\\", UserWarning)\",\"Hide warnings\\nimport warnings\\nwarnings.filterwarnings('ignore')\",\"Remove annoying SettingWithCopyWarning\",\" Disabling the Warnings\\nimport warnings\\nwarnings.filterwarnings('ignore')\",\"\\nimport warnings\\nwarnings.filterwarnings('ignore')\",\"\\u0645import warnings\\nwarnings.filterwarnings('ignore')\",\"Hide all warnings\\nimport warnings\\nwarnings.filterwarnings('ignore')\",\"Ignore certain warnings\\nimport warnings\\nwarnings.filterwarnings('ignore')\",\"\\nimport warnings\\nwarnings.filterwarnings('ignore')\",\"Set styles and ignore warnings\",\"Ignore the warnings\\nimport warnings\\nwarnings.filterwarnings('ignore')\",\"Ignore deprication warnings\\nimport warnings\\nwarnings.filterwarnings(\\\"ignore\\\", category=DeprecationWarning)\",\"I disabled the warning about the settingwithcopywarning.\",\"Project settings\\nimport warnings\\nwarnings.filterwarnings(\\\"ignore\\\")\",\" Ignore the warnings\\nimport warnings\\nwarnings.filterwarnings('ignore')\",\"Ignore warnings\\nimport warnings\\nwarnings.filterwarnings('ignore')\",\"ignore warnings\\nimport warnings\\nwarnings.filterwarnings('ignore')\",\"Ignore all future warnings to improve readibility, since they clutter the output too much\\nimport warnings\\nwarnings.simplefilter(action='ignore', category=FutureWarning)\",\"Hide warnings (this is usually a bad idea, but just for this exercise)\",\"Optional: Disable warnings\\nimport warnings\\nwarnings.filterwarnings('ignore')\",\"# Enable extra logging for debugging (set to False for normal operation)\\nDEBUG = False\",\" To display logger output\\nimport logging\",\"import warnings\",\"Hide warning messages\\nimport warnings\\nwarnings.filterwarnings('ignore')\",\"%%\\n#warning\\n\",\"Set up logging\\nimport logging\",\" Set logging level\\nimport logging\\nlogging.getLogger().setLevel(logging.CRITICAL)\",\"Hide warnings\\nimport warnings\\nwarnings.filterwarnings('ignore')\"],\"marker\":{\"opacity\":0.5,\"size\":5},\"mode\":\"markers+text\",\"name\":\"98_Warning Management\",\"text\":[\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\"],\"textfont\":{\"size\":12},\"x\":[18.20047950744629,17.33910369873047,18.162078857421875,17.41359519958496,17.080373764038086,17.202030181884766,16.966175079345703,18.19146156311035,17.409963607788086,17.162460327148438,18.095867156982422,17.346099853515625,17.232872009277344,17.40007209777832,16.98790740966797,17.302175521850586,17.3153133392334,17.554349899291992,17.787757873535156,17.804706573486328,17.320131301879883,16.557353973388672,16.094633102416992,16.529760360717773,17.720901489257812,17.110618591308594,15.646132469177246,16.293508529663086,17.834304809570312],\"y\":[4.6925177574157715,4.530151844024658,4.576405048370361,4.932920932769775,4.385833263397217,4.99395751953125,4.808770179748535,4.438063621520996,4.797119140625,4.953085899353027,4.390002727508545,4.652158260345459,4.713348865509033,4.678589344024658,4.910923004150391,4.95424747467041,4.953551769256592,4.9461517333984375,4.938572883605957,4.554496765136719,4.714183807373047,3.956993818283081,3.483384370803833,4.488191604614258,4.418269634246826,4.557476997375488,3.5913596153259277,4.244793891906738,4.6425018310546875],\"type\":\"scattergl\"},{\"hoverinfo\":\"text\",\"hovertext\":[\"We will explore the dataframes first by looking at the first few rows of each dataframe.\",\" Let's start by looking at what's in the dataframes\",\" First, let's take a look at the data quickly by looking at the first few entries of each dataframe.\",\" Let's start by inspecting the structure of the dataframes.\",\"We start by examining the first few rows of each dataframe.\",\"Let's start by looking at the first few entries of each DataFrame.\",\" Let's start by having a look at a few rows of each of our dataframes.\",\" Let us first take a look at the structure of the data of each dataframe.\",\"Let's start by taking a quick look at the first rows of each dataframe.\",\"Start by exploring the first few rows of each dataframe.\",\" Let's start by exploring the data in each DataFrame to see what we're working with.\",\" Let's start by taking a look at the structure and content of each of these dataframes.\",\"We can then start by exploring the content of each Dataframe.\",\"We'll start by exploring the data in each of these dataframes.\",\" Let's start by taking a look at the first few rows of each dataframe.\",\"We'll start by taking a look at the first few lines of each of our DataFrames.\",\" Let's start by taking a look at the first few rows of each dataframe.\",\" Let's start by taking a look at the first few rows of each DataFrame.\",\"Let's start by looking at the structure of the dataframes and the first few rows of each dataframe.\",\" Let's start by taking a look at the first few rows of each of these DataFrames.\",\"Let's start by taking a look at the structure of each dataframe.\",\"First, let's explore the data and look at the first few rows of each dataframe.\",\" Let's start by taking a look at the first few rows of each dataframe.\",\"We will start by inspecting the unique values contained in these dataframes.\",\"We can now start to take a look at the data with a simple head of each dataframe.\",\"Let's start by taking a look at the first few lines of each dataframe.\",\"To get started, let's take a look at the first few rows of each dataframe to understand what kind of data we're working with.\",\"Let's start by taking a look at the first few rows of each dataframe.\",\"Let's first familiarize with data topics by first exploring the structure of each DataFrame.\"],\"marker\":{\"opacity\":0.5,\"size\":5},\"mode\":\"markers+text\",\"name\":\"99_Exploring DataFrames and Familiarizing with First Few Rows\",\"text\":[\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\"],\"textfont\":{\"size\":12},\"x\":[11.259450912475586,10.380650520324707,10.845484733581543,10.4737548828125,11.166749954223633,10.820326805114746,10.433431625366211,9.390506744384766,10.754404067993164,11.041187286376953,9.69946002960205,9.651482582092285,10.406722068786621,10.265117645263672,10.549931526184082,10.705994606018066,10.70769214630127,10.432762145996094,10.694390296936035,10.718547821044922,9.805927276611328,11.076194763183594,10.81908130645752,10.58425521850586,9.733772277832031,10.294679641723633,9.858682632446289,10.445281028747559,10.206629753112793],\"y\":[-6.115280628204346,-5.530313968658447,-6.2470550537109375,-5.904116153717041,-6.711877822875977,-5.8226470947265625,-5.366241455078125,-6.067050933837891,-6.366959571838379,-6.16065788269043,-5.983598232269287,-6.405943870544434,-5.395447254180908,-5.762035846710205,-5.821423530578613,-4.941518306732178,-6.086155891418457,-6.165702819824219,-6.354584217071533,-6.246475696563721,-6.216190814971924,-6.663430690765381,-5.920864582061768,-5.698042392730713,-5.767192363739014,-5.629558086395264,-6.471927165985107,-5.810512542724609,-6.713274955749512],\"type\":\"scattergl\"},{\"hoverinfo\":\"text\",\"hovertext\":[\"# Function to display the wordcloud\\ndef plot_wordcloud(wordcloud):\\n    plt.imshow(wordcloud, interpolation='bilinear')\\n    plt.axis(\\\"off\\\")\",\" Generate wordcloud of the most common character names\\nwordcloud = WordCloud(background_color='white',\\n                      width=1600,\\n                      height=800,\\n                      max_words=50).generate_from_frequencies(dict(df_characters['name'].value_counts(normalize=False)))\\n\\nplt.figure(1, figsize=(16, 8))\\nplt.imshow(wordcloud)\\nplt.axis('off')\\nplt.show()\",\"Visualizations\\n# Wordcloud of the most common words of the script\\nall_words = ' '.join(df_script['normalized_text'].values)\\nwordcloud = WordCloud(width = 1000, height = 500).generate(all_words)\\n\\nplt.figure(figsize=(15,8))\\nplt.imshow(wordcloud, interpolation='bilinear')\\nplt.axis('off')\",\"WordCloud generates word cloud data.\\nnlp = spacy.load(\\\"en_core_web_sm\\\")\\n\\n# Remove duplicates and missing values in the data\\ndf_script = df_script.drop_duplicates(['episode_id', 'number']).dropna()\\n\\n# Iterating over each row and generating the word cloud for every episode\\nfor episode_id, episode_df in tqdm(df_script.groupby('episode_id'), total=len(df_script['episode_id'].unique())):\\n    text = ' '.join(episode_df['raw_text'])\\n    \\n    doc = nlp(text)\\n    \\n    words = [token.text for token in doc if token.is_alpha and not token.is_stop and len(token.text) \\u003e 2]\\n    \\n    word_freq = Counter(words)\\n    \\n    wc = WordCloud(width=800, height=800, margin=10).generate_from_frequencies(word_freq)\\n    \\n    plt.imshow(wc, interpolation='bilinear')\\n    plt.axis('off')\\n    plt.savefig(f'episode_wordclouds\\u002f{episode_id}.png')\",\"Dependencies:\\n# pandas\\n# numpy\\n# spacy\\n# matplotlib\\n# wordcloud\\n# tqdm\",\"Helper function\\ndef show_wordcloud(text):\\n    # Create and generate a word cloud image:\\n    wordcloud = WordCloud().generate(text)\\n\\n    # Display the generated image:\\n    plt.imshow(wordcloud, interpolation='bilinear')\\n    plt.axis(\\\"off\\\")\\n    plt.show()\",\"Create a word cloud of the most common words in the script lines\\nscript = \\\" \\\".join(df_script.raw_text.values)\\nwordcloud = WordCloud(width = 2000, height = 1000, random_state=1, background_color='black',\\n                      colormap='Set2', collocations=False, stopwords = WordCloud.STOPWORDS,\\n                     max_words=50).generate(script)\\n\\n# Plot the word cloud\\nplt.figure(figsize=(20, 10), facecolor=None)\\nplt.imshow(wordcloud, interpolation=\\\"bilinear\\\")\\nplt.axis('off')\\nplt.tight_layout(pad=0)\\n\\nplt.show()\",\"Words clouds for most common words in Simpson show\\n# Prepare data\\ntext = ' '.join(df_script.raw_text.fillna(''))\\n\\n# Generate word cloud\\nwordcloud = WordCloud(width = 800, height = 400, \\n                background_color ='black', \\n                min_font_size = 10).generate(text)\\n\\n# plot the WordCloud image                        \\nplt.figure(figsize = (8, 8), facecolor = None) \\nplt.imshow(wordcloud) \\nplt.axis(\\\"off\\\") \\nplt.tight_layout(pad = 0)\",\"Function to display word cloud for a given text\\ndef plot_wordcloud(text, title, ax, max_words=200, stopwords=None):\\n    # Generate the word cloud\\n    wordcloud = WordCloud(width=800, height=400, background_color='white', max_words=max_words, colormap='viridis', stopwords=stopwords).generate(text)\\n\\n    # Display the word cloud using matplotlib\\n    ax.imshow(wordcloud, interpolation='bilinear')\\n    ax.set_title(title)\\n    ax.axis('off')\\n    return ax\",\"Define a function to plot word cloud for given text.\",\" Set up a nice background for the wordcloud\\nbackground = np.array(Image.open('data\\u002fhomer.png'))\",\"A 100% of the wordcloud is being shown\\nmatplotlib.rcParams['figure.figsize'] = [20, 12]\",\"Merge characters and script tables on character_id\\ndf = pd.merge(df_script, df_characters, left_on='character_id', right_on='id')\\n\\n# Get the main characters' names\\nmain_characters = list(df['name'].value_counts().head(10).index)\\n\\n# Plot function\\ndef plot_wordclouds(data, title):\\n    # Instantiate wordcloud\\n    wc = WordCloud(background_color='white', max_words=100)\\n\\n    # Generate word cloud\\n    wc.generate_from_frequencies(data)\\n\\n    # Plot\\n    plt.figure(figsize=(10, 5))\\n    plt.imshow(wc, interpolation='bilinear')\\n    plt.axis('off')\\n    plt.title(title)\",\" Helper function to display an image\\ndef display_wordcloud(wordcloud):\\n    plt.figure(figsize=(10, 5))\\n    plt.imshow(wordcloud, interpolation='bilinear')\\n    plt.axis(\\\"off\\\")\",\"Word cloud function\\ndef plot_wordcloud(words, title, save_as=None):\\n    word_cloud = WordCloud(width = 1000, height = 500, background_color='black', stopwords=STOPWORDS).generate(words)\\n\\n    plt.figure(figsize=(15,8))\\n    plt.imshow(word_cloud)\\n    plt.title(title, fontdict={'size':20})\\n    plt.axis('off')\\n\\n    if save_as:\\n        plt.savefig(save_as, format='png')\\n        plt.close()\\n    else:\\n        plt.show()\",\"Visualisationgies\\nfontsize, collocations=False, random_state=42).generate_from_frequencies(word_freq)\\nplt.figure(figsize=(12,10))\\nplt.imshow(wordcloud, interpolation='bilinear')\\nplt.axis(\\\"off\\\")\\nplt.show()\",\"Function to display a word cloud\\ndef plot_wordcloud(text, title, image_name):\\n    wordcloud = WordCloud(width = 800, height = 800, \\n                background_color ='black', \\n                stopwords = None, \\n                min_font_size = 10).generate(text)\\n    # set the figsize\\n    plt.figure(figsize = (8, 8), facecolor = None) \\n    plt.imshow(wordcloud) \\n    plt.axis(\\\"off\\\") \\n    plt.tight_layout(pad = 0) \\n    plt.title(title, fontsize=20)\\n    plt.savefig(f'images\\u002f{image_name}.png')\\n    plt.show()\",\" Visualize the number of lines per character\\ncharacter_name = 'homer simpson'\\ncharacter_lines = df_script[df_script['character_id'] == character_name]['raw_character_text']\\n\\n# Generate the word cloud\\nwordcloud = WordCloud(width = 1000, height = 500).generate(' '.join(character_lines))\\n\\n# Plot the word cloud\\nplt.figure(figsize=(15, 5))\\nplt.imshow(wordcloud, interpolation='bilinear')\\nplt.axis(\\\"off\\\")\",\"cosine similarity between two word vectors\\ndef get_cosine_similarity(x, y):\\n    return np.dot(x, y) \\u002f (np.linalg.norm(x) * np.linalg.norm(y))\",\"Wordcloud on character's names\\n# Convert the list of character's names to a single string\\nall_names = df_characters['name'].str.cat(sep=' ')\\n\\n# Create a WordCloud object\\nwordcloud = WordCloud(width=800, height=400, max_font_size=150, background_color='black').generate(all_names)\\n\\n# Display the word cloud using matplotlib\\nplt.figure(figsize=(10, 5))\\nplt.imshow(wordcloud, interpolation='bilinear')\\nplt.axis('off')\\nplt.show()\",\"Set up the wordcloud\\nfig, ax = plt.subplots(1, 1, figsize=(15, 15))\\nwc = WordCloud(width=800, height=800, background_color='white', max_words=150, relative_scaling=0.5).generate(' '.join(df_script['raw_text'].values))\\nax.imshow(wc)\\nax.axis('off')\",\" Helper function to display a word cloud\\ndef plot_wordcloud(wordcloud):\\n    plt.figure(figsize=(10, 5))\\n    plt.imshow(wordcloud, interpolation='bilinear')\\n    plt.axis(\\\"off\\\")\",\"peat word cloud code for character dialogues\\nwordcloud = WordCloud(width = 1000, height = 500, max_font_size = 110, collocations = False).generate(characters_dialogues_text)\\nplt.figure(figsize=(16, 8))\\nplt.imshow(wordcloud, interpolation=\\\"bilinear\\\")\\nplt.axis('off')\",\"# Set up word cloud\\nmatplotlib.rcParams['figure.figsize'] = (12, 12)\\nwordcloud = WordCloud(width = 4000, height = 4000, \\n                background_color ='white', \\n                stopwords = None, \\n                min_font_size = 10)\",\"Generating the wordcloud for an episode script line\\ndef generate_wordcloud(episode_id, char_name=None, loc_name=None):\\n    \\\"\\\"\\\"\\n    Generate the wordcloud for a specific episode and an optional character and location appearing in it\\n    \\n    Args:\\n    - episode_id: integer, identifier of the episode\\n    - char_name: string, name of the character\\n    - loc_name: string, name of the location\\n\\n    Returns:\\n    - wordcloud: wordcloud object\\n    - doc: spacy document\\n    - counter_words: counter object\\n    \\\"\\\"\\\"\\n    # Retuning results\\n    return wordcloud, doc, counter_words\",\"Extracts the text column of a dataframe, creates a word cloud and plots it.\",\"Functions for plotting WordClouds\",\" Helper function to visualize a word cloud\\ndef plot_wordcloud(wordcloud):\\n    plt.figure(figsize=(10, 5))\\n    plt.imshow(wordcloud, interpolation='bilinear')\\n    plt.axis(\\\"off\\\")\",\"Utility functions\\ndef generate_wordcloud(text):\\n    wordcloud = WordCloud(width=800, height=400, max_font_size=100, background_color=\\\"white\\\").generate(text)\\n    plt.figure(figsize=(15, 10))\\n    plt.imshow(wordcloud, interpolation=\\\"bilinear\\\")\\n    plt.axis('off')\\n    plt.show()\"],\"marker\":{\"opacity\":0.5,\"size\":5},\"mode\":\"markers+text\",\"name\":\"100_Word Cloud Visualization\",\"text\":[\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\"],\"textfont\":{\"size\":12},\"x\":[12.379876136779785,11.50748348236084,11.802128791809082,11.363069534301758,13.233839988708496,12.794885635375977,11.801785469055176,11.227839469909668,12.655973434448242,12.152748107910156,12.306230545043945,13.333630561828613,11.578533172607422,12.991352081298828,12.602958679199219,11.921881675720215,12.613144874572754,11.424859046936035,10.381272315979004,11.822972297668457,12.262601852416992,12.69612979888916,12.63847827911377,13.269821166992188,11.996261596679688,11.989029884338379,12.711278915405273,12.62272834777832,12.581278800964355],\"y\":[8.013984680175781,8.67724895477295,8.864444732666016,8.165803909301758,9.607728004455566,7.885747909545898,8.807385444641113,8.362333297729492,8.72825813293457,7.894323825836182,8.090410232543945,8.544379234313965,8.937419891357422,8.069887161254883,8.40478515625,8.641398429870605,8.640169143676758,8.753889083862305,8.963132858276367,8.922073364257812,8.769492149353027,8.339259147644043,7.439551830291748,8.567313194274902,7.273816108703613,8.648787498474121,8.408419609069824,8.488212585449219,8.101818084716797],\"type\":\"scattergl\"},{\"hoverinfo\":\"text\",\"hovertext\":[\"A_D = {'she': 'Marge', 'her': 'Marge', \\\"he\\\": \\\"Homer\\\", \\\"him\\\": \\\"Homer\\\"}\",\" Character we are interested in\\ncharacter_name = \\\"Bart Simpson\\\"\",\" Select only the lines for the 8 main characters\\nmain_characters = [\\n    'marge simpson',\\n    'homer simpson',\\n    'bart simpson',\\n    'lisa simpson',\\n    'maggie simpson',\\n    'ned flanders',\\n    'seymour skinner',\\n    'milhouse van houten'\\n]\",\"Select only The Simpsons family member\\nmain_characters = [\\n    'marge', 'homer', 'bart', 'lisa', 'maggie', \\n    'abraham', 'patty', 'selma', 'krusty'\\n]\\n\\n# Scraped from URL\\nplayable_characters = [\\n    'ned', 'apu', 'moe', 'skinner', 'flanders',\\n    'barney', 'lenny', 'carl', 'duffman', \\n    'snake', 'otto', 'manjula', 'bont', 'herman', \\n    'jasper', 'hibbert', 'milhouse', 'ralph', \\n    'wiggum', 'frink', 'edna', 'lovejoy', 'nelson', \\n    'carlson', 'quimby', 'stampy', 'krabappel', \\n    'snake', 'willie'\\n]\\n\\n# Combine the two lists of characters\\ncharacters = main_characters + playable_characters\\n\",\"Reduce dataset to only relevant characters\\ncharacters = [\\n    \\\"Lisa Simpson\\\",\\n    \\\"Bart Simpson\\\",\\n    \\\"Marge Simpson\\\",\\n    \\\"Homer Simpson\\\",\\n    \\\"Maggie Simpson\\\",\\n    \\\"Charles Montgomery Burns\\\",\\n    \\\"Milhouse Van Houten\\\",\\n    \\\"Ned Flanders\\\",\\n    \\\"Principal Skinner\\\",\\n    \\\"Lenny Leonard\\\",\\n    \\\"Carl Carlson\\\",\\n    \\\"Waylon Smithers\\\",\\n    \\\"Krusty the Clown\\\",\\n    \\\"Grampa Simpson\\\",\\n    \\\"Dr. Julius Hibbert\\\",\\n    \\\"Selma Bouvier\\\",\\n    \\\"Patty Bouvier\\\",\\n    \\\"Kent Brockman\\\",\\n    \\\"Edna Krabappel\\\",\\n    \\\"Nelson Muntz\\\",\\n    \\\"Sherri and Terri\\\",\\n    \\\"Jimbo Jones\\\",\\n    \\\"Martin Prince\\\",\\n    \\\"Seymour Skinner\\\",\\n    \\\"Rod Flanders\\\",\\n    \\\"Todd Flanders\\\",\\n    \\\"Moe Szyslak\\\",\\n    \\\"Barney Gumble\\\",\\n    \\\"Kirk Van Houten\\\",\\n    \\\"Luann Van Houten\\\",\\n    \\\"Apu Nahasapeemapetilon\\\",\\n    \\\"Ralph Wiggum\\\",\\n    \\\"Chief Wiggum\\\",\\n    \\\"Snake Jailbird\\\",\\n    \\\"Judge Constance Harm\\\"\\n]\",\"\\n# Retaining only the main characters from Simpsons character data\\nmain_characters = [\\n    \\\"marge\\\", \\n    \\\"homer\\\",\\n    \\\"bart\\\",\\n    \\\"lisa\\\",\\n    \\\"maggie\\\",\\n    \\\"skinner\\\",\\n    \\\"ned\\\",\\n    \\\"burns\\\",\\n    \\\"moe\\\",\\n    \\\"krusty\\\",\\n    \\\"milhouse\\\",\\n    \\\"chief\\\",\\n    \\\"abraham\\\",\\n    \\\"edna\\\",\\n    \\\"ralph\\\",\\n    \\\"apu\\\",\\n    \\\"barney\\\",\\n    \\\"nelson\\\",\\n    \\\"kent\\\",\\n    \\\"waylon\\\"\\n]\",\"hansoo = ['Homer Simpson', 'Marge Simpson', 'Bart Simpson', 'Lisa Simpson', 'Maggie Simpson', \\n          'Ned Flanders', 'Krusty the Clown', 'Milhouse Van Houten', 'Chief Wiggum', 'Grampa Simpson', \\n          'Lenny Leonard', 'Mayor Quimby', 'Nelson Muntz', 'Principal Skinner', 'Sideshow Bob', \\n          'C. Montgomery Burns', 'Comic Book Guy', 'Edna Krabappel', 'Moe Szyslak', 'Apu Nahasapeemapetilon', \\n          'Kent Brockman', 'Waylon Smithers', 'Ralph Wiggum', 'Groundskeeper Willie', 'Martin Prince', \\n          'Doctor Hibbert', 'Officer Lou', 'Mrs. Krabappel']\",\"Extract main characters\\nmain_characters = [\\\"homer\\\", \\\"marge\\\", \\\"bart\\\", \\\"lisa\\\", \\\"maggie\\\", \\\"skinner\\\", \\\"ned\\\", \\\"burns\\\", \\\"milhouse\\\", \\\"moe\\\", \\n                   \\\"krusty\\\", \\\"edna\\\", \\\"sideshow\\\", \\\"apu\\\", \\\"chief\\\", \\\"barney\\\", \\\"carl\\\", \\\"lenny\\\", \\\"duffman\\\", \\\"selma\\\", \\n                   \\\"patty\\\", \\\"ralph\\\", \\\"nelson\\\", \\\"todd\\\", \\\"mcbain\\\", \\\"groundskeeper\\\", \\\"maggie's\\\", \\\"waylon\\\", \\\"rod\\\", \\n                   \\\"troy\\\", \\\"helen\\\", \\\"fat tony\\\", \\\"lionel\\\", \\\"gary\\\", \\\"karl\\\", \\\"frink\\\"]\",\" Apply Character and Location Filter\\ncharacter_list = ['homer simpson', 'marge simpson', 'bart simpson', 'lisa simpson', 'maggie simpson', 'grampa simpson',\\n                  'ned flanders', 'moe szyslak', 'krusty the clown', 'chief wiggum',\\n                  'lenny leonard', 'carl carlson', 'waylon smithers', 'milhouse van houten', 'edna krabappel',\\n                  'kent brockman', 'nelson muntz', 'apu nahasapeemapetilon', 'sideshow bob',\\n                  'reverend lovejoy', 'mrs. krabappel', 'principal skinner', 'mrs. simpson', 'hugo simpson']\\n\\nlocation_list = ['simpson home', 'moe\\\\'s tavern', 'springfield nuclear power plant', 'kwik-e-mart',\\n                 'springfield elementary school', 'kitchen', 'jake\\\\'s unisex hair palace', 'springfield street']\",\"Dude, select the specific character we are  gonna be using\\ncharacter_name = \\\"Bart Simpson\\\"\",\"Filter out boring Simpsons characters\",\"Extract the main characters\\nmain_characters = ['marge', 'homer', 'bart', 'lisa', 'maggie', 'skinner', 'ned', 'krabappel', 'burns', 'milhouse', 'moe',\\n                   'comic', 'carl', 'lenny', 'apu', 'duffman', 'barney', 'abraham', 'edna', 'jimbo', 'nelson', 'patty',\\n                   'selma', 'waylon', 'mrburns', 'reverend', 'snake', 'willie', 'karl', 'ralph', 'troy', 'lionel', 'hawk',\\n                   'artie', 'snowball', 'herb', 'maggie', 'frink', 'jasper', 'kishimoto', 'montgomery', 'hans', 'lou',\\n                   'krusty', 'barney', 'barney', 'mayor', 'sideshow', 'krustofsky', 'robert', 'lucas', 'luann']\\ndf_script = df_script[df_script.raw_character_text.str.lower().isin(main_characters)]\",\"Define character name either KILLER (The murderer or being killed) or VICTIM (The person being killed or the victim of the murderer).\",\" Extracting the main characters and locations\\nmain_characters = [\\n    'marge', 'homer', 'bart', 'lisa', 'maggie',\\n    'ned', 'flanders', 'moe', 'krusty', 'milhouse',\\n    'chief', 'edna', 'selma', 'patty', 'lenny',\\n    'carl', 'cletus', 'professor', 'snake', 'apu',\\n    'rainier', 'seymour', 'waylon', 'nelson', 'ralph',\\n    'barney', 'patty', 'martin', 'hans'\\n]\\n\\nmain_locations = [\\n    'Simpson House', 'Springfield Elementary School', 'Springfield Nuclear Power Plant',\\n    'Kwik-E-Mart', 'Moe\\\\'s Tavern', 'Springfield Retirement Castle', 'Springfield',\\n    '742 Evergreen Terrace', 'Springfield Town Hall', 'Burns Manor', 'Ned Flanders\\\\' House'\\n]\",\"Create character roles\\nmain_characters = [\\n    \\\"marge_simpsons\\\", \\\"homer_simpsons\\\", \\\"bart_simpson\\\",\\n    \\\"lisa_simpson\\\", \\\"maggie_simpson\\\", \\\"abraham_grampa_simpson\\\",\\n    \\\"ned_flanders\\\", \\\"moe_szyslak\\\", \\\"krusty_the_clown\\\",\\n    \\\"chief_wiggum\\\", \\\"charles_montgomery_burns\\\", \\\"milhouse_van_houten\\\",\\n    \\\"seymour_skinner\\\", \\\"nelson_muntz\\\", \\\"edna_krabappel\\\",\\n    \\\"lenny_leonard\\\", \\\"carl_carlson\\\", \\\"waylon_smithers\\\", \\\"kent_brockman\\\"\\n]\\n\\nsupporting_characters = [\\n    \\\"apu_nahasapeemapetilon\\\", \\\"comic_book_guy\\\", \\\"ralph_wiggum\\\",\\n    \\\"english\\\", \\\"snake_jailbird\\\", \\\"kent_brockman\\\", \\\"mayor_quimby\\\",\\n    \\\"barney_gumble\\\", \\\"selma_bouvier\\\", \\\"patty_bouvier\\\",\\n    \\\"martin_prince\\\", \\\"troy_mcclure\\\", \\\"lionel_hutz\\\", \\\"groundskeeper_willie\\\",\\n    \\\"fat_tony\\\", \\\"professor_john_frink\\\", \\\"dr_julius_hibbert\\\",\\n    \\\"cletus_spuckler\\\", \\\"otto_mann\\\"\\n]\\n\\n# This role list is not exhaustive\\nminor_characters = [\\n    \\\"apu_nahasapeemapetilon\\\", \\\"milhouse_van_houten\\\",\\n    \\\"comic_book_guy\\\", \\\"snake_jailbird\\\", \\\"troy_mcclure\\\",\\n    \\\"kent_brockman\\\", \\\"martin_prince\\\", \\\"ralph_wiggum\\\",\\n    \\\"mayor_quimby\\\", \\\"edna_krabappel\\\"\\n]\",\"Visualise the top characters in The Simpsons\",\"Select main characters identified by the community\\nmain_characters = [\\\"bart\\\", \\\"homer\\\", \\\"marge\\\", \\\"lisa\\\", \\\"maggie\\\", \\\"krusty\\\", \\\"burns\\\", \\\"milhouse\\\", \\\"chief\\\", \\\"skinner\\\", \\\"n edna\\\", \\\"bob\\\", \\\"apu\\\", \\\"moe\\\", \\\"ned\\\"]\",\"Get the names of the characters in the Simpsons\",\"Extract main characters\\nmain_characters = [\\n    \\\"marge\\\", \\\"bart\\\", \\\"homer\\\", \\\"lisa\\\", \\\"maggie\\\",\\n    \\\"kirk\\\", \\\"otto\\\", \\\"duffman\\\", \\\"selma\\\", \\\"patty\\\",\\n    \\\"milhouse\\\", \\\"krusty\\\", \\\"apu\\\", \\\"moe\\\", \\\"carl\\\",\\n    \\\"lenny\\\", \\\"ned\\\", \\\"cletus\\\", \\\"barney\\\", \\\"ralph\\\",\\n    \\\"wiggum\\\", \\\"skinner\\\", \\\"hibbert\\\", \\\"frink\\\", \\\"snake\\\",\\n    \\\"burns\\\", \\\"nelson\\\", \\\"edna\\\", \\\"rod\\\", \\\"todd\\\",\\n    \\\"lovejoy\\\", \\\"apu\\\", \\\"frink\\\", \\\"fat tony\\\", \\\"duff\\\",\\n    \\\"flanders\\\", \\\"bob\\\", \\\"artie\\\", \\\"sanjay\\\", \\\"ruth\\\",\\n    \\\"sideshow\\\", \\\"tahiti bob\\\", \\\"tahiti bob\\\", \\\"disco stu\\\", \\\"wiggum\\\",\\n    \\\"skinner\\\", \\\"krustofski\\\", \\\"lampwick\\\", \\\"krusty\\\", \\\"mccallister\\\", \\n    \\\"lenford\\\", \\\"leopold\\\", \\\"selma\\\", \\\"patty\\\", \\\"shary\\\", \\\"edna\\\",\\n    \\\"horatio\\\", \\\"junun\\\", \\\"roscoe\\\", \\\"chase\\\", \\\"chase\\\", \\\"thompson\\\", \\n    \\\"frederick\\\", \\\"harvest\\\", \\\"eve\\\", \\\"martha\\\", \\\"lou\\\"\\n]\",\"Where are Simpsons Characters mentioned the most.\",\"hood_character(e.g. Homer Simpson, Marge Simpson, Mr. Burns), name of the characterhood_location(e.g. Street Name, House of Ned Flanders), name of the location, dialogue(Text by character), timestamp_in_ms(Millisecond of dialogue)\",\"Limiting the data to only Marge, Lisa, and Bart.\",\"Find the set of all episodes that feature the character \\\"Marge\\\"\",\"Selecting the main characters of the Simpsons\",\"Find the most common professions of characters in The Simpsons\",\"Filter for the regular characters only\\nmain_characters = [\\n    'marge', 'homer', 'bart', 'lisa', 'maggie', 'chief_wiggum', 'moe', 'ned', 'skinner',\\n    'patty', 'selma', 'milhouse', 'krusty', 'burns', 'moe', 'ted', 'apu', 'barney', 'lenny',\\n    'carl', 'waylon_smithers', 'nelson', 'jimbo', 'martin', 'professor_frink', 'snake', \\n    'cletus', 'edna', 'rainier_wolfcastle', 'simpsons'\\n]\",\"Filter the main characters of the Simpsons series\",\"filter main characters\\nmain_characters = [\\n    \\\"marge\\\",\\n    \\\"homer\\\",\\n    \\\"bart\\\",\\n    \\\"lisa\\\",\\n    \\\"maggie\\\",\\n    \\\"grampa\\\",\\n    \\\"abraham jay simpson\\\",\\n    \\\"krusty\\\",\\n    \\\"sideshow bob\\\",\\n    \\\"charles montgomery burns\\\",\\n    \\\"milhouse\\\",\\n    \\\"chief wiggum\\\",\\n    \\\"ned flanders\\\",\\n    \\\"apu\\\",\\n    \\\"moe\\\",\\n    \\\"professor frink\\\",\\n    \\\"barney\\\",\\n    \\\"troy mcclure\\\",\\n    \\\"lionel hutz\\\",\\n    \\\"selma\\\",\\n    \\\"patty\\\",\\n    \\\"mayor quimby\\\",\\n    \\\"waylon smithers\\\",\\n    \\\"edna krabappel\\\",\\n    \\\"dr. hibbert\\\",\\n    \\\"reverend lovejoy\\\",\\n    \\\"kent brockman\\\",\\n    \\\"miss hoover\\\",\\n    \\\"miss krabappel\\\",\\n    \\\"groundskeeper willie\\\",\\n    \\\"otto\\\",\\n    \\\"maude flanders\\\",\\n]\",\"Define name of character\\nname = \\\"Homer Simpson\\\"\"],\"marker\":{\"opacity\":0.5,\"size\":5},\"mode\":\"markers+text\",\"name\":\"101_The Simpsons - Main Characters and Locations\",\"text\":[\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\"],\"textfont\":{\"size\":12},\"x\":[8.643101692199707,10.420002937316895,9.212230682373047,9.105023384094238,9.539421081542969,9.665777206420898,10.222909927368164,9.293213844299316,9.788054466247559,9.960262298583984,9.599343299865723,8.492979049682617,10.448936462402344,9.921319961547852,9.918675422668457,10.70262336730957,9.624757766723633,10.316170692443848,9.168722152709961,10.364977836608887,10.17924690246582,10.210149765014648,9.158071517944336,10.034828186035156,10.685494422912598,9.547979354858398,9.607952117919922,9.663928985595703,10.263893127441406],\"y\":[7.5059638023376465,6.52034330368042,6.474789619445801,7.077290058135986,6.8491621017456055,6.8204264640808105,7.1845574378967285,7.047359466552734,6.666128158569336,6.802826881408691,6.0943169593811035,7.313738822937012,7.092144966125488,7.090976715087891,7.008194923400879,6.585662841796875,7.171591758728027,6.232266902923584,7.104981422424316,6.508814334869385,6.271312236785889,6.276293754577637,5.736482620239258,6.570858001708984,6.699488639831543,7.067413806915283,6.056260585784912,6.849367618560791,6.835646629333496],\"type\":\"scattergl\"},{\"hoverinfo\":\"text\",\"hovertext\":[\"Show the first rows of the characters dataframe\\ndf_characters.head()\",\" Show first rows of the characters DataFrame\\ndf_characters.head()\",\" Show first elements of df_characters\\ndf_characters.head()\",\"# Show first rows\\ndf_characters.head()\",\" Show first rows of characters dataframe\\ndf_characters.head()\",\" Display the first rows from the characters dataframe\\ndf_characters.head()\",\" Show first rows\\ndf_characters.head()\",\"Displaying the first data frame (characters)\\ndf_characters.head()\",\"Show the first rows of the characters dataframe\\ndf_characters.head()\",\" Show first data frame\\ndf_characters.head()\",\" Show the first rows of the characters data frame\\ndf_characters.head()\",\"Show first row of data\\ndf_characters.head(1)\",\"Display the first rows of the characters DataFrame\\ndf_characters.head()\",\"Show the df_characters first entries\\ndf_characters.head()\",\"Basic EDA\\n# Show the first entries for the characters dataframe\\ndf_characters.head()\",\"display the first rows of the df_characters dataframe\\ndf_characters.head()\",\"# Show the first rows of the characters DataFrame\\ndf_characters.head()\",\" Show the first entries for the characters table\\ndf_characters.head()\",\" Display first rows of the characters dataframe\\ndf_characters.head()\",\"- Display the first rows of the characters dataframe\\ndf_characters.head()\",\"Display first and last rows of the characters DataFrame\\nprint(df_characters.head(1))\\nprint(df_characters.tail(1))\",\" Show first rows of the dataframe 'df_characters'\\ndf_characters.head()\",\" Display first rows of df_characters\\ndf_characters.head()\",\" Show first rows of df\\ndf_characters.head()\",\" Display the first rows of the characters dataframe\\ndf_characters.head()\",\" Displaying first characters in df_characters\\ndf_characters.head()\",\"Display the first rows of the characters DataFrame\\ndf_characters.head()\",\"Show first rows of the characters dataframe\\ndf_characters.head()\",\"Show first rows of characters df\\ndf_characters.head()\"],\"marker\":{\"opacity\":0.5,\"size\":5},\"mode\":\"markers+text\",\"name\":\"102_Displaying first rows of data frame\",\"text\":[\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\"],\"textfont\":{\"size\":12},\"x\":[1.4701731204986572,1.0362175703048706,1.2293680906295776,2.0556187629699707,1.1102837324142456,1.858521580696106,1.754404067993164,0.44396743178367615,1.500954508781433,0.6796530485153198,0.6826711893081665,1.6121550798416138,1.4772117137908936,0.9257336258888245,1.6388859748840332,1.2955219745635986,2.0729007720947266,1.5153634548187256,1.2465717792510986,1.7419281005859375,-3.5981087684631348,1.2841817140579224,1.262014627456665,1.5577994585037231,1.5582503080368042,1.036644697189331,1.4408676624298096,1.2603219747543335,1.3262771368026733],\"y\":[19.190786361694336,18.976327896118164,18.463090896606445,17.84781837463379,18.917322158813477,18.451507568359375,17.85350227355957,19.067787170410156,19.21439552307129,19.03858757019043,19.23196792602539,17.444808959960938,18.391019821166992,18.097858428955078,18.959041595458984,18.40220069885254,18.247486114501953,17.364116668701172,18.504802703857422,18.5029354095459,21.967857360839844,18.961782455444336,17.81719207763672,18.221601486206055,18.331480026245117,18.536148071289062,18.51145362854004,18.972808837890625,18.318540573120117],\"type\":\"scattergl\"},{\"hoverinfo\":\"text\",\"hovertext\":[\" Visualize number of lines per character\\nline_counts = df_script['character_id'].value_counts()\\nline_counts = line_counts.reset_index()\\nline_counts.columns=['character_id', 'count']\\nline_counts = line_counts.merge(df_characters, on='character_id')\\nline_counts = line_counts.sort_values(by='count', ascending=False)\\n\\nfig, ax = plt.subplots(1,1,figsize=(15,10))\\nax.bar(line_counts['name'][:30], line_counts['count'][:30])\\nax.set_xlabel('Character')\\nax.set_ylabel('Number of lines')\\nax.set_title('Number of lines per character')\\nax.set_xticklabels(line_counts['name'][:30], rotation=90)\\nplt.show()\",\"Visualize the ten most frequent characters, locations and spoken words\\n\\n# Characters\\ntop_characters = df_script['raw_character_text'].value_counts().head(10)\\ntop_characters.plot(kind='barh', figsize=(12, 6), title='10 most frequent characters')\\nplt.show()\",\" Get the top 10 characters with the most lines in the script\\ntop10_characters = df_script['raw_character_text'].value_counts().head(10)\\n\\n# Define a bar plot for the top10_characters\\nplt.figure(figsize=(10,10))\\ntop10_characters.plot(kind='bar')\\n\\n# Set the title and labels\\nplt.title('Top 10 Main Characters by Number of Lines')\\nplt.xlabel('Character name')\\nplt.ylabel('Number of lines')\\n\\n# Show the bar plot\\nplt.show()\",\"Visualize each character's distribution of lines in the dataset\\ndf_characters_count = df_script['raw_character_text'].value_counts()\\ndf_characters_count = df_characters_count[df_characters_count \\u003e 50]  # Filter low count characters\\n\\n# Sort by value count\\ndf_characters_count.sort_values(inplace=True)\\n\\n# Plot histogram\\nplt.barh(df_characters_count.index, df_characters_count.values)\\nplt.title('Character line count distribution')\\nplt.xlabel('Line count')\\nplt.ylabel('Character')\\nplt.show()\",\" Visualize the number of lines per character\\n# Number of dialog lines per character (in descending order)\\nlines_per_character = df_script['character_id'].value_counts()\\n\\n# Only keep the 20 most frequent characters\\ntop_20_characters = lines_per_character.head(20)\\ntop_20_characters_list = top_20_characters.index.tolist()\\n\\n# Data frame containing only the top 20 characters\\ntop_20_characters_df = df_script[df_script['character_id'].isin(top_20_characters_list)]\\n\\n# Count the number of lines per character\\nlines_per_character = top_20_characters_df['character_id'].value_counts()\\n\\n# Create a barplot of the number of lines per character\\nplt.figure(figsize=(20,10))\\nplt.bar(lines_per_character.index, lines_per_character.values)\\nplt.xticks(rotation=90)\\nplt.xlabel('Character')\\nplt.ylabel('Number of lines')\\nplt.title('Number of dialog lines per character')\\nplt.show()\",\" Visualizing the 10 most frequent locations\\ntop_10_locations = list(dict(Counter(df_script['raw_location_text'])).items())\\ntop_10_locations.sort(key=lambda x: x[1], reverse=True)\\ntop_10_locations = top_10_locations[:10]\\n\\nplt.bar([x[0] for x in top_10_locations], [x[1] for x in top_10_locations])\\nplt.xticks(rotation=90)\\nplt.show()\",\" Visualize the top 20 characters in terms of number of lines in the show\\ntop_characters = df_script['character_id'].value_counts().head(20)\\ntop_characters = top_characters.to_frame().merge(df_characters, how='left', left_index=True, right_on='id').iloc[:,1]\\ntop_characters = top_characters[::-1]\\n\\nplt.figure(figsize=(10, 8))\\nplt.barh(top_characters.index, top_characters.values, color='skyblue')\\nplt.xlabel('Number of lines', fontsize=12)\\nplt.title('Top 20 characters by number of lines', fontsize=16)\\nplt.gca().invert_yaxis()\",\" Compute the top 10 characters, using the number of words in their lines\\ntop_10_characters = df_script[df_script['raw_character_text'].isin(df_characters['character'])]\\ntop_10_characters = top_10_characters.groupby('raw_character_text').apply(lambda x: x['word_count'].sum()).reset_index(name='num_words')\\ntop_10_characters = top_10_characters.sort_values(by='num_words', ascending=False)\\ntop_10_characters = top_10_characters.head(10)\",\"Get a feel of the data\\nprint(df_script.head(3))\\n\\n# Plot the 10-most frequent characters\\nplt.figure(figsize=(18, 6))\\ntop_characters = df_script['raw_character_text'].value_counts().head(10)\\ntop_characters.plot(kind='bar')\\nplt.title('Top-10 most frequent characters')\\nplt.show()\",\" Visualize Content\\nplt.hist(df_script['character_id'].value_counts().values, bins=np.arange(0, 500, 10))\\nplt.xlabel('Utterances per character')\\nplt.ylabel('Number of characters')\\nplt.title('Utterances per character')\",\"Visualize the top 20 characters by number of lines\\nplt.figure(figsize=(14, 8))\\ntop_characters = df_script['character_id'].value_counts().head(20)\\ntop_characters_names = [df_characters[df_characters['id'] == i]['name'].values[0] for i in top_characters.index]\\ntop_characters_names\\nplt.bar(top_characters_names, top_characters.values)\\nplt.xticks(rotation=90)\\nplt.title('Top 20 characters by number of lines')\\nplt.show()\",\" Visualise the top 10 characters by number of spoken words\\ndf_script.groupby(\\\"character_id\\\")[\\\"word_count\\\"].sum().nlargest(10).sort_values().plot(kind=\\\"barh\\\", color=\\\"skyblue\\\")\\nplt.xlabel(\\\"Number of words\\\")\\nplt.title(\\\"Top 10 Characters by Number of Spoken Words\\\")\\nplt.show()\",\" Visualize the number of lines per character\\ndf_script['character_id'] = df_script['character_id'].fillna(-1).astype(int)\\ndf_script['character_id'] = df_script['character_id'].replace(-1, 'NA')\\nlines_per_character = df_script['character_id'].value_counts()\\n\\nplt.bar(np.arange(30), lines_per_character[:30])\\nplt.xticks(np.arange(30), lines_per_character.index[:30], rotation='vertical')\\nplt.ylabel('Number of lines')\\nplt.title('Number of lines per character')\",\"Visualise lines and word count\\nline_lengths = df_script['raw_text'].str.len()\\nword_lengths = df_script['raw_text'].str.split().apply(lambda x : len(x) if x != [''] else 0)\\n\\nplt.figure(figsize=(20, 5))\\n\\nplt.subplot(1, 2, 1)\\nline_lengths.plot(kind='hist', bins=100, ax=plt.gca())\\nplt.title('Line lengths')\\n\\nplt.subplot(1, 2, 2)\\nword_lengths.plot(kind='hist', bins=100, ax=plt.gca())\\nplt.title('Word lengths')\\n\\nplt.show()\",\"Visualize the top 30 characters by number of appearances\\ntop_30_characters = df_script.speaking_line_id.value_counts()[:30]\\n\\nfig, ax = plt.subplots(figsize=(20, 10))\\nax.bar(top_30_characters.index, top_30_characters.values, color='b')\\n\\nax.set(title='Top 30 characters by number of appearances', xlabel='Character id', ylabel='Number of appearances')\\nax.grid(True)\\nplt.xticks(rotation=90)\",\"# Visualize the number of lines per character\\nline_counts = df_script['character_id'].value_counts()\\n\\nplt.hist(line_counts, bins=100, range=(1, 100))\\nplt.yscale('log')\\nplt.title('Number of Lines per Character')\\nplt.xlabel('Number of Lines')\\nplt.ylabel('Number of Characters')\\nplt.show()\",\"Visualization of the class distribution\\nplt.figure(figsize=(12,5))\\nax = df_script['raw_character_text'].value_counts().plot(kind='bar',\\n                                    color=list(plt.rcParams['axes.prop_cycle'].by_key()['color']),\\n                                    title='Distribution of the character speaking')\\n\\nax.set_xlabel(\\\"Character name\\\")\\nax.set_ylabel(\\\"Frequency\\\")\\nplt.show()\",\"Look at the number of words per line and sentence in the script data\\ndf_script['words_per_line'] = df_script['normalized_text'].map(lambda x: len(x.split()))\\ndf_script['words_per_sentence'] = df_script['normalized_text'].map(lambda x: len(x.split('.')))\\n\\n# Plot histograms for the number of words per line and sentence\\nplt.figure(figsize=(14, 6))\\n\\nplt.subplot(1, 2, 1)\\nplt.hist(df_script['words_per_line'], bins=200, color='skyblue', edgecolor='black')\\nplt.title('Distribution of words per line')\\nplt.xlabel('# words')\\nplt.ylabel('Frequency')\\n\\nplt.subplot(1, 2, 2)\\nplt.hist(df_script['words_per_sentence'], bins=200, color='lightgreen', edgecolor='black')\\nplt.title('Distribution of words per sentence')\\nplt.xlabel('# words')\\nplt.ylabel('Frequency')\\n\\nplt.show()\",\" Visualization 1: Top 10 Characters by Number of Lines\\ntop_10_characters_by_lines = df_script['normalized_name'].value_counts().head(10)\\ntop_10_characters_by_lines.plot(kind='bar', figsize=(20,10))\\nplt.xticks(rotation=45)\\nplt.title('Top 10 Characters by Number of Lines')\\nplt.xlabel('Character Name')\\nplt.ylabel('Number of Lines')\\nplt.show()\",\"Create a bar chart with the 10 most frequent characters\",\"Draw countplots for characters and locations\\nplt.figure(figsize=(18, 10))\\nplt.subplot(2, 1, 1)\\nsns.countplot(y='raw_character_text', data=df_script, palette='dark:salmon_r', order=df_script['raw_character_text'].value_counts().index)\\nplt.title('Character Counts')\\n\\nplt.subplot(2, 1, 2)\\nsns.countplot(y='raw_location_text', data=df_script, palette='dark:salmon_r', order=df_script['raw_location_text'].value_counts().index)\\nplt.title('Location Counts')\\n\\nplt.tight_layout()\\nplt.show()\",\"Visualise the frequency of each character in the script dataset\\nchar_distribution = dict(df_script['raw_character_text'].value_counts())\\ntop_10_char, top_10_count = list(char_distribution.keys())[:10], list(char_distribution.values())[:10]\\n\\nfig, ax = plt.subplots(figsize=(16, 8))\\nax.bar(np.arange(len(top_10_char)), top_10_count, color='purple')\\nax.set_xlabel('Top 10 Characters', fontsize=24)\\nax.set_ylabel('Frequency', fontsize=24)\\nax.set_title('Top 10 Characters by Frequency', fontsize=36)\\nax.set_xticks(np.arange(len(top_10_char)))\\nax.set_xticklabels(top_10_char, rotation=45, ha='right', fontsize=16)\\nax.set_yticklabels(np.arange(0, max(top_10_count)+10, 10), fontsize=16)\\nplt.show()\",\"Visualize the top 10 characters by number of lines\\ndf_character_lines = df_script.groupby('character_id')['id'].count().reset_index()\\ndf_character_lines = df_character_lines.sort_values('id', ascending=False).head(10)\\ndf_character_lines = df_character_lines.merge(df_characters, left_on='character_id', right_on='id')\\ndf_character_lines = df_character_lines.set_index('name')\\n\\nplt.figure(figsize=(15, 8))\\nplt.bar(df_character_lines.index, df_character_lines['id'], color='orange')\\nplt.title('Top 10 Characters by Number of Lines')\\nplt.xlabel('Character')\\nplt.ylabel('Number of Lines')\\nplt.xticks(rotation=45)\\nplt.show()\",\"Get top 10 characters with the most lines\\ntop_characters = df_script['character_id'].value_counts().head(10)\\n\\n# Get top 10 locations with the most lines\\ntop_locations = df_script['location_id'].value_counts().head(10)\",\"Visualize the top 10 characters with the most lines in the script\\ntop_10_characters = df_script['character_id'].value_counts().head(10)\\ntop_10_characters_names = [df_characters[df_characters['id'] == character_id]['name'].values[0] for character_id in top_10_characters.index]\\n\\nplt.figure(figsize=(20,10))\\nplt.bar(top_10_characters_names, top_10_characters.values)\\nplt.title('Top 10 characters with the most lines in the script')\\nplt.xlabel('Character')\\nplt.ylabel('Number of lines')\\nplt.xticks(rotation=45)\\nplt.show()\",\" Visualize most common characters\\ntop_characters = df_script['character_id'].value_counts().head(50)\\ncharacters = [df_characters[df_characters['id']==i]['name'].values[0] for i in top_characters.index]\\n\\nplt.figure(figsize=(16, 8))\\nplt.bar(characters, top_characters.values)\\nplt.xticks(rotation=90)\\nplt.show()\",\"Visualize the proportion of lines for each character\\ndf_characters_counts = pd.merge(df_script, \\n                                df_characters, \\n                                left_on='character_id', \\n                                right_on='id').groupby('name').count()['id'].sort_values()\\n\\nplot = df_characters_counts.plot(\\n    kind='pie',\\n    figsize=(12,12),\\n    title='Proportion of lines for each character',\\n    autopct=lambda p: '{:.0f}% ({:.0f})'.format(p, p\\u002f100 * df_characters_counts.sum())\\n    )\\n\\n# Change font size\\nfor text in plot.texts:\\n    text.set_fontsize(10)\\n\\nplt.show()\",\"Plotting a bar plot of the 10 most common characters in the dataset\",\" Visualise data\\nplt.figure(figsize=(12, 5))\\nplt.subplot(1, 2, 1)\\nplt.hist(df_script.speaking_line)\\nplt.title('Speaking lines', fontsize=15)\\nplt.xlabel('')\\n\\nplt.subplot(1, 2, 2)\\nplt.hist(df_script.character_id.value_counts(), bins=50)\\nplt.title('Number of lines per character', fontsize=15)\\nplt.xlabel('Number of lines')\\nplt.show()\"],\"marker\":{\"opacity\":0.5,\"size\":5},\"mode\":\"markers+text\",\"name\":\"103_Visualize Top 10 Most Frequent Characters and Locations\",\"text\":[\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\"],\"textfont\":{\"size\":12},\"x\":[8.511809349060059,8.554950714111328,8.397950172424316,8.5649995803833,8.284225463867188,8.385420799255371,8.832091331481934,8.406907081604004,8.03725814819336,8.336569786071777,8.690234184265137,8.422739028930664,8.212994575500488,9.313957214355469,8.5502290725708,8.364097595214844,8.522762298583984,9.227652549743652,8.508044242858887,8.651039123535156,8.241987228393555,8.3405122756958,8.96445083618164,7.837363243103027,8.338552474975586,8.228824615478516,8.623820304870605,8.434703826904297,8.810032844543457],\"y\":[9.915648460388184,9.642269134521484,10.041417121887207,9.536641120910645,10.465049743652344,10.073498725891113,10.205717086791992,9.45187759399414,9.997629165649414,9.930891990661621,10.371847152709961,9.049988746643066,9.902921676635742,9.084840774536133,10.211469650268555,9.546281814575195,10.281460762023926,9.585968017578125,10.116621017456055,10.026596069335938,10.126358985900879,10.698701858520508,10.339704513549805,10.177817344665527,10.231120109558105,10.199393272399902,9.68986988067627,9.984234809875488,9.657095909118652],\"type\":\"scattergl\"},{\"hoverinfo\":\"text\",\"hovertext\":[\" Look at the first few rows of `df_characters` dataframe\\ndf_characters.head()\",\"\\n# To look into the dataframes, we just run the cell\\n# Characters DataFrame\\ndf_characters.head()\",\"\\n# Let's take a look at the first rows of the characters dataframe\\ndf_characters.head()\",\" Take a look at the first 5 rows of the characters dataframe\\ndf_characters.head()\",\"look into the first 10 rows of the characters dataframe\\ndf_characters.head(10)\",\" Look at the first few rows of the characters dataframe\\ndf_characters.head()\",\"Look at the first few records of the characters dataframe\\ndf_characters.head()\",\" Take a look at the first 5 rows of the characters dataframe\\ndf_characters.head()\",\"Look at the first 5 rows of the characters dataframe\\ndf_characters.head()\",\" Let's take a look at the first 5 rows of our character dataframe to see what it looks like.\\ndf_characters.head()\",\"Look at the characters dataframe\\ndf_characters.head()\",\" Look at the first few rows of the characters DataFrame\\ndf_characters.head()\",\"Check out the first few rows of each dataframe\\ndf_characters.head()\",\"Check out the first few rows of the characters dataframe\\ndf_characters.head()\",\"Take a look at the first rows from `df_characters` DataFrame\\ndf_characters.head()\",\"Take a look at the characters dataframe\\ndf_characters.head()\",\" Look at the first few rows of the characters dataframe\\ndf_characters.head()\",\"Have a quick look at the dataframes\\ndf_characters.head(3)\",\"Look at the first five rows of the characters dataframe\\ndf_characters.head()\",\" Look at the first few rows of the characters DataFrame\\ndf_characters.head()\",\"Look at first characters in the datasets to decide which column to use as character in script dataframe\\ndf_characters.head()\",\"Take a look at the dataframes\\ndf_characters.head()\",\"Look at first entries of the characters DataFrame\\ndf_characters.head()\",\" Take a look at the first 5 rows of the characters dataframe\\ndf_characters.head()\",\" Look at the first few rows of the dataframe\\ndf_characters.head()\",\" Look at the first few rows of the characters dataframe\\ndf_characters.head()\",\" Look at the first 5 elements in the characters dataframe\\ndf_characters.head()\",\"Look at the few first rows of the first dataframe\\ndf_characters.head()\"],\"marker\":{\"opacity\":0.5,\"size\":5},\"mode\":\"markers+text\",\"name\":\"104_Exploring the Characters DataFrame\",\"text\":[\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\"],\"textfont\":{\"size\":12},\"x\":[7.944317817687988,6.679063320159912,7.419121265411377,7.54856014251709,7.72353458404541,7.533504009246826,7.5911970138549805,7.655891418457031,7.400634765625,7.977952480316162,6.978768825531006,7.57210111618042,6.742335319519043,7.075654983520508,7.560824394226074,7.191456317901611,7.407100677490234,6.470273494720459,7.7739996910095215,7.410120964050293,7.749509811401367,6.9876179695129395,7.223089694976807,7.619692325592041,7.3210930824279785,7.634094715118408,7.996654510498047,7.673671722412109],\"y\":[15.121504783630371,14.826333999633789,14.718987464904785,14.18032169342041,14.477776527404785,14.987637519836426,14.725440979003906,14.295348167419434,14.57816219329834,14.093201637268066,14.864343643188477,14.937108993530273,14.748271942138672,14.928584098815918,15.616180419921875,14.495792388916016,14.898000717163086,14.464129447937012,14.443862915039062,15.0556640625,15.057145118713379,14.570791244506836,15.498979568481445,14.093417167663574,14.92122745513916,15.04038143157959,14.652641296386719,15.376038551330566],\"type\":\"scattergl\"},{\"hoverinfo\":\"text\",\"hovertext\":[\"Examine the data\\ndf_script.head()\",\"Exploring the data\\ndf_script.head()\",\"Explore the data\\ndf_script.head()\",\" Sneak peek at the data\\ndf_script.head()\",\"Get an overview of the data\\ndf_script.head()\",\" Explore the structure of the data\\ndf_script.head()\",\"Data overview\\ndf_script.head()\",\"Inspect data\\ndf_script.head()\",\"Exploring the core data selected for analysis & sentiment analysis -\\ndf_script.head(5), df_characters.head(5), df_locations.head(5)\",\"Inspect the script data\\ndf_script.head()\",\"Explore the data\\ndf_script.head()\",\"Inspect scripts data\\ndf_script.head()\",\"Inspect basic structure of the data\\ndf_script.head()\",\"Show some lines to get a feeling of how the data looks like\\ndf_script.head(2)\",\"look at the data\\ndf_script.head()\",\"Take a look at the structure of script data\\ndf_script.head()\",\"Inspect the data\\ndf_script.head()\",\"Initial data observation\\ndf_script.head()\",\"Inspect data\\ndf_script.head()\",\"Quick look on the data\\nprint(df_script.head())\",\"Inspect some sample data\\ndf_script.head()\",\"Explore the data\\ndf_script.head()\",\"Data overview\\ndf_script.head()\",\"A sample of the data\\ndf_script.head()\",\"Examine the data\\ndf_script.head()\",\"Inspecting the data\\ndf_script.head()\",\"Inspect the script data\\ndf_script.head()\",\"Inspect the contents and structure of the script data\\ndf_script.head()\"],\"marker\":{\"opacity\":0.5,\"size\":5},\"mode\":\"markers+text\",\"name\":\"105_Exploring and Inspecting the Data Structure and Overview\",\"text\":[\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\"],\"textfont\":{\"size\":12},\"x\":[4.559761047363281,4.491542816162109,4.820623397827148,4.5365800857543945,4.943301200866699,4.425585746765137,4.797522068023682,4.604745864868164,3.926410436630249,4.926853656768799,4.72053337097168,4.580038547515869,4.272663116455078,4.7787322998046875,4.6485724449157715,4.7880048751831055,4.375329971313477,4.292624473571777,4.309040546417236,4.901632308959961,4.440881252288818,4.734719276428223,4.515934467315674,4.281351089477539,4.39902925491333,4.415194988250732,4.858642578125,4.703709602355957],\"y\":[-3.969758987426758,-4.880652904510498,-4.655694007873535,-4.374232292175293,-4.579421520233154,-5.073383331298828,-5.140114784240723,-4.417810440063477,-4.355982303619385,-4.238132953643799,-4.5983381271362305,-4.152450084686279,-4.651652812957764,-5.500093460083008,-4.700406074523926,-5.187998294830322,-4.104741096496582,-4.568782329559326,-4.291242599487305,-4.171590805053711,-4.851149082183838,-4.671384811401367,-4.9080023765563965,-5.098244667053223,-3.9915034770965576,-4.442054271697998,-4.385031223297119,-4.511026859283447],\"type\":\"scattergl\"},{\"hoverinfo\":\"text\",\"hovertext\":[\"Display available columns for each dataset\\nfor name, df in {\\n    'characters': df_characters,\\n    'locations': df_locations,\\n    'script': df_script,\\n    'episodes': df_episodes\\n}.items():\\n    print(f'{name}: {df.columns.values}\\\\n')\",\"Display available columns in each dataframe\\nprint(\\\"Characters columns:\\\", df_characters.columns)\\nprint(\\\"Locations columns:\\\", df_locations.columns)\\nprint(\\\"Script columns:\\\", df_script.columns)\\nprint(\\\"Episodes columns:\\\", df_episodes.columns)\",\"Display all columns for each dataframe\\nfor df in [df_characters, df_locations, df_script, df_episodes]:\\n    print(df.columns)\",\"Inspect general information from the datasets\\nprint('characters columns',df_characters.columns)\\nprint('\\\\n\\\\nlocations columns',df_locations.columns)\\nprint('\\\\n\\\\nscript lines columns',df_script.columns)\\nprint('\\\\n\\\\nepisodes columns',df_episodes.columns)\",\"Functions and Classes\\ndef getNameMap(df_map, key_col, value_col):\\n    '''\\n    Get a dictionary using two columns one for the key and one for the value\\n    Parameters\\n    ----------\\n    df_map: pd.DataFrame\\n            DataFrame with the key-value mapping\\n    key_col: str\\n            Name of the column with the keys\\n    value_col:str\\n            Name of the column with the values\\n            \\n    Returns\\n    -------\\n    name_map: Dictionary\\n            Dictionary with the mapping of the DataFrame\\n    '''\\n    name_map = dict(zip(df_map[key_col], df_map[value_col]))\\n    return name_map\",\" print the dataframe columns\\nprint(df_characters.columns)\\nprint(df_locations.columns)\\nprint(df_script.columns)\\nprint(df_episodes.columns)\",\" view available data columns for characters, locations, and script\\nprint(df_characters.columns)\\nprint(df_locations.columns)\\nprint(df_script.columns)\",\"\\n# Let's start by checking which columns we have in each dataframe\\nprint('Characters:', df_characters.columns)\\nprint('Locations:', df_locations.columns)\\nprint('Script:', df_script.columns)\\nprint('Episodes:', df_episodes.columns)\",\"Check for duplicate columns\\nassert len(df_characters.columns.unique()) == len(df_characters.columns)\\nassert len(df_locations.columns.unique()) == len(df_locations.columns)\\nassert len(df_script.columns.unique()) == len(df_script.columns)\\nassert len(df_episodes.columns.unique()) == len(df_episodes.columns)\",\"Explore column names\\nprint('Characters:', df_characters.columns.tolist())\\nprint('Locations:', df_locations.columns.tolist())\\nprint('Script lines:', df_script.columns.tolist())\\nprint('Episodes:', df_episodes.columns.tolist())\",\"Columns in df_episodes\\nfor col in df_episodes.columns:\\n    print(col)\",\" Check columns and example of some of the dataframes\\nprint(df_characters.columns, df_characters.head())\\nprint(df_locations.columns, df_locations.head())\\nprint(df_script.columns, df_script.head())\\nprint(df_episodes.columns, df_episodes.head())\",\"Look at the available data\\nprint(df_characters.columns)\\nprint(df_locations.columns)\\nprint(df_script.columns)\\nprint(df_episodes.columns)\",\"Display available columns for each dataset\\nprint('Characters:', df_characters.columns.tolist())\\nprint('Locations:', df_locations.columns.tolist())\\nprint('Script:', df_script.columns.tolist())\\nprint('Episodes:', df_episodes.columns.tolist())\",\"Print the columns of the characters, lines, and episodes DataFrames to understand their structure\\nprint(df_characters.columns)\\nprint(df_script.columns)\\nprint(df_episodes.columns)\",\"Encoding all the dataframes by ASR for simplicity\\ndf_characters = df_characters.astype('category')\\ndf_locations = df_locations.astype('category')\\ndf_episodes = df_episodes.astype('category')\",\" Check columns of each dataframe\\nprint(\\\"Characters columns:\\\", df_characters.columns)\\nprint(\\\"Locations columns:\\\", df_locations.columns)\\nprint(\\\"Script columns:\\\", df_script.columns)\\nprint(\\\"Episodes columns:\\\", df_episodes.columns)\",\"Display the column names for each dataframe\\nprint(\\\"Characters data:\\\\n\\\", df_characters.columns)\\nprint(\\\"\\\\nLocations data:\\\\n\\\", df_locations.columns)\\nprint(\\\"\\\\nScript data:\\\\n\\\", df_script.columns)\\nprint(\\\"\\\\nEpisodes data:\\\\n\\\", df_episodes.columns)\",\"List all data that exists in each dataframe\\nprint(\\\"##################### COLUMNS NAMES #############################\\\")\\nprint(\\\"Characters columns: \\\", df_characters.columns)\\nprint()\\nprint(\\\"Locations columns: \\\", df_locations.columns)\\nprint()\\nprint(\\\"Script lines columns: \\\", df_script.columns)\\nprint()\\nprint(\\\"Episodes columns: \\\", df_episodes.columns)\",\"Check the columns present in the datasets\\nprint('Characters:', df_characters.columns)\\nprint('Locations:', df_locations.columns)\\nprint('Script:', df_script.columns)\\nprint('Episodes:', df_episodes.columns)\",\"Display data information\\nprint(\\\"\\\\n\\\\nDimensions and columns of each dataset:\\\")\\nprint(\\\"Characters: \\\", df_characters.shape, df_characters.columns)\\nprint(\\\"Locations: \\\", df_locations.shape, df_locations.columns)\\nprint(\\\"Script: \\\", df_script.shape, df_script.columns)\\nprint(\\\"Episodes: \\\", df_episodes.shape, df_episodes.columns)\",\"Check if all columns are read correctly\\nprint(\\\"Columns in characters: \\\", df_characters.columns.tolist())\\nprint(\\\"Columns in locations: \\\", df_locations.columns.tolist())\\nprint(\\\"Columns in script: \\\", df_script.columns.tolist())\\nprint(\\\"Columns in episodes: \\\", df_episodes.columns.tolist())\",\"Display columns to identify the data available in each DataFrame\\nprint(\\\"Characters DataFrame columns: \\\", df_characters.columns)\\nprint(\\\"Locations DataFrame columns: \\\", df_locations.columns)\\nprint(\\\"Script DataFrame columns: \\\", df_script.columns)\\nprint(\\\"Episodes DataFrame columns: \\\", df_episodes.columns)\",\"Display column names\\nprint(\\\"Columns in character dataframe:\\\")\\nprint(df_characters.columns)\\nprint(\\\"\\\\nColumns in location dataframe:\\\")\\nprint(df_locations.columns)\\nprint(\\\"\\\\nColumns in script dataframe:\\\")\\nprint(df_script.columns)\\nprint(\\\"\\\\nColumns in episodes dataframe:\\\")\\nprint(df_episodes.columns)\",\" Show all columns to know what can be used from each table\\nfor column in [df_characters.columns, df_locations.columns, df_script.columns, df_episodes.columns]:\\n    print(column)\\n    print()\",\"Display available columns for each dataset\\nprint(df_characters.columns)\\nprint(df_locations.columns)\\nprint(df_script.columns)\\nprint(df_episodes.columns)\",\" LIst of dataframes and their column names\\ndfs = {\\\"characters\\\": df_characters, \\\"locations\\\": df_locations, \\\"script\\\": df_script, \\\"episodes\\\": df_episodes}\\nfor name, df in dfs.items():\\n    print(f\\\"{name}: {', '.join(df.columns)}\\\")\"],\"marker\":{\"opacity\":0.5,\"size\":5},\"mode\":\"markers+text\",\"name\":\"106_Displaying Available Columns in DataFrames\",\"text\":[\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\"],\"textfont\":{\"size\":12},\"x\":[-0.2304614782333374,0.09420689940452576,-0.14105962216854095,0.44844186305999756,8.057129859924316,0.07553255558013916,-0.042120955884456635,-0.0707123801112175,1.5382736921310425,-0.1431073397397995,0.5564835667610168,-0.886882483959198,-0.12355294823646545,-0.0003935809072572738,-0.11466700583696365,-0.8676285147666931,-0.31728583574295044,0.05788344889879227,-0.12394297122955322,-0.5934926867485046,0.14210544526576996,0.3433820307254791,0.13134895265102386,-0.21774546802043915,0.25902649760246277,0.12100449949502945,-0.6220157742500305],\"y\":[1.4661147594451904,0.8773830533027649,1.096808671951294,1.1528676748275757,-3.2946219444274902,1.127245545387268,1.1127619743347168,0.8284948468208313,1.5636404752731323,1.3971607685089111,1.3311190605163574,1.213375210762024,1.0101200342178345,0.8297896385192871,0.9076611995697021,0.17046010494232178,0.6392046213150024,1.2853600978851318,0.824411153793335,0.9232059121131897,0.8555446267127991,0.6847931146621704,0.8619967699050903,0.7075130343437195,0.9011450409889221,0.8658589124679565,1.5686367750167847],\"type\":\"scattergl\"},{\"hoverinfo\":\"text\",\"hovertext\":[\"Visualisation of the data\",\"modules required for data visualization and analysis\",\"Some basic visualisations to understand our datasets better.\",\"Visualizing and understanding the data\",\"Realizamos un pr\\u00e9stamo de alias para la apariencia del set de datos en los cuadernos de jupyter.\",\" Visualisation code\",\"Visualization Functions\",\"Visualizing the data\",\"Visualize some example data.\",\"\\n# Import the required modules for processing data and creating visualizations\",\"Visualizing the data\",\" Enable the TQDM notebook extension to visualize loop processing.\",\" Visualisation Preliminaries\",\"Visualizacion de los datos\",\"Display the dimension of each data infront\",\" Test and visualize data\",\"Visualise the data in the table\",\"Visualization function\",\" Visualization Utils\",\"Visualizing data, to understand it better!\",\"Visualize the data\",\"Seeing that the function was removed, I can only assume it was some form of data exploration or manipulation. If you have a specific function in mind, feel free to ask for its inclusion.\",\"Visualise the data\",\"Visualizing data\",\"Visualization functions\",\"Merge the data to combine fields and for better visualization.\",\"That's all for now - let's get started with the data visualization!\"],\"marker\":{\"opacity\":0.5,\"size\":5},\"mode\":\"markers+text\",\"name\":\"107_Data visualization and analysis modules\",\"text\":[\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\"],\"textfont\":{\"size\":12},\"x\":[13.070243835449219,13.45595645904541,14.210951805114746,13.615537643432617,11.937664031982422,13.408892631530762,13.469878196716309,13.046247482299805,13.373151779174805,13.851926803588867,12.952922821044922,13.720954895019531,13.451550483703613,13.205758094787598,8.21146297454834,12.877177238464355,12.985392570495605,13.474151611328125,13.305908203125,13.61233139038086,12.96953010559082,13.516057014465332,13.145965576171875,12.974310874938965,13.339570045471191,11.933808326721191,14.457539558410645],\"y\":[-0.1443328708410263,0.11930351704359055,-0.5502026081085205,-0.053750671446323395,3.2328014373779297,1.0505539178848267,0.8232929706573486,0.22668743133544922,0.07047662883996964,0.3805467188358307,0.09560474753379822,10.275705337524414,0.58518385887146,0.7993467450141907,-3.6297380924224854,-0.1445235162973404,-0.8125825524330139,0.5759824514389038,0.852715015411377,-0.15667755901813507,-0.0867658481001854,1.2763783931732178,-0.19821088016033173,-0.0012061846209689975,0.9166548252105713,0.4483276307582855,-0.20414140820503235],\"type\":\"scattergl\"},{\"hoverinfo\":\"text\",\"hovertext\":[\"Display the first few rows of the dataframe containing the characters in the Simpsons dataset.\",\"Preview the 'simpsons_characters.csv' dataset\\ndf_characters.head()\",\"Preview of Simpsons Characters data\\ndf_characters.head()\",\" Display the first 5 entries of the 'simpsons_characters.csv' file\\ndf_characters.head()\",\" Preview the 'simpsons_characters.csv' table\\ndf_characters.head()\",\" Show the first 5 rows of the 'simpsons_characters' DataFrame\\ndf_characters.head()\",\"Display in Jupyter notebook the top 5 rows of the Simpsons characters dataset\\ndf_characters.head()\",\"Inspect the first 5 rows of 'simpsons_characters.csv'\\ndf_characters.head()\",\"Display first 5 rows of Simpsons characters dataframe\\ndf_characters.head()\",\"# Display the first few lines of the Simpsons characters dataset\\ndf_characters.head()\",\" Examine the first few rows of data from the 'simpsons_characters.csv' file\\ndf_characters.head()\",\"Data understanding\\n# Characters in the Simpsons\\ndf_characters.head()\",\" Check the first 5 rows of Simpsons characters dataset\\ndf_characters.head()\",\"gallery of Simpson's character\\ndf_characters.head()\",\"View a sample of the Simpsons characters dataset\\ndf_characters.head()\",\"Checking the first 5 rows of the \\\"simpsons_characters.csv\\\" file\\ndf_characters.head()\",\" Display the first few lines of the \\\"simpsons_characters.csv\\\" dataset\\ndf_characters.head()\",\"Display sample rows for Simpsons characters\\ndf_characters.head()\",\"Display the first 5 lines of simpsons_characters table\\ndf_characters.head()\",\"# Display the characters of the Simpsons series\\ndf_characters.head()\",\"Display records for Simpsons character data\\ndf_characters.head()\",\"# Show first 5 entries of 'simpsons_characters.csv'\\ndf_characters.head()\",\"Show first rows of Simpsons Characters dataset\\ndf_characters.head()\",\"Preview the Simpsons characters dataset\\ndf_characters.head()\",\" Display the first 5 rows of the Simpsons characters dataset\\ndf_characters.head()\",\" Check the first 5 rows of the \\\"Simpsons Characters\\\" dataset\\ndf_characters.head()\",\"Display the first records of the Simpsons characters dataset\\ndf_characters.head()\"],\"marker\":{\"opacity\":0.5,\"size\":5},\"mode\":\"markers+text\",\"name\":\"108_Previewing the Simpsons Characters dataset by checking the first 5 rows\",\"text\":[\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\"],\"textfont\":{\"size\":12},\"x\":[2.918248414993286,2.050823211669922,2.6404662132263184,1.1335434913635254,2.138974905014038,0.14009569585323334,1.4279134273529053,1.2455254793167114,0.11690948158502579,2.485582113265991,1.6997779607772827,3.570204019546509,1.2904993295669556,2.8961124420166016,2.66680645942688,1.2069737911224365,1.9649267196655273,2.137021064758301,0.8119683265686035,3.093038320541382,2.703291654586792,1.2921215295791626,1.980006217956543,2.2174341678619385,1.2354000806808472,1.6657190322875977,1.9647272825241089],\"y\":[13.42001724243164,13.287306785583496,13.418495178222656,13.120311737060547,13.112663269042969,13.83404541015625,13.853577613830566,13.168496131896973,13.43781566619873,13.399670600891113,13.411250114440918,13.75157356262207,13.473976135253906,13.167394638061523,13.203353881835938,13.231056213378906,13.544754981994629,13.443480491638184,13.222322463989258,13.554545402526855,13.3301420211792,12.884966850280762,14.031536102294922,13.376455307006836,13.500741004943848,13.317797660827637,13.684525489807129],\"type\":\"scattergl\"},{\"hoverinfo\":\"text\",\"hovertext\":[\"Display a sample of each dataframe to know the data features\",\" Display basic information about dataframes\",\" Display general information of each dataframe.\\ndef display_df_info(df, name):\\n    print(name)\\n    print(df.info())\\n    display(df.head(5))\",\"A function to display basic info about a dataframe\\ndef df_summary(df, title=\\\"\\\"):\\n    print(f'\\\\033[1m{title}\\\\033[0m')\\n    print(df.info())\",\"Display some records of each dataframe to understand the data\",\" Let's display basic informations for every dataframe\",\"def get_info(df: pd.DataFrame, info: str):\\n    \\\"\\\"\\\"\\n    Prints the shape, the columns names and the first 5 rows of a DataFrame.\\n\\n    :param df: The DataFrame to get information from.\\n    :param info: The name of the DataFrame.\\n    \\\"\\\"\\\"\\n    print(f'{info} shape:', df.shape, '\\\\n\\\\n')\\n    print(f'{info} columns:', df.columns, '\\\\n\\\\n')\\n    print(f'{info}:', df.head(), '\\\\n\\\\n')\",\"Display available columns per dataframe for reference when inspecting the data.\",\" Display basic informations about the dataframes\",\"Check the basic information in each dataset\\ndef info_data(dataframe, name):\\n    print(\\\"Exploring the Data\\\")\\n    print(\\\"Overview of the data \\\"+name+\\\":\\\" )\\n    return (dataframe.head())\",\"To display some basic information about the dataframes\",\"display available dataframes\\ndir()\",\" Displaying basic information from each dataframe\",\"printing out attributes of the dataframes\",\"Displaying all the dataframes as there should be direct download source available is allowed under `data` folder.\",\"Load the data and display the different DataFrames.\",\"Display some samples of each dataframes.\",\"# Simple function to inspect the data frames\\ndef inspect_data(df, name):\\n    print(f\\\"{name} dataframe info\\\".center(50, '='))\\n    print(df.info())\\n    print(f\\\"{name} dataframe describe\\\".center(50, '='))\\n    print(df.describe(include='all'))\",\"Sample the dataframe and identify the column names and their associated meanings\",\"Display all the dataframes to understand what is actually present in them\",\"Specify input and output dataframes\",\"Show simple breakdowns of dataframes\",\" Display basic information for all DataFrames\",\"Display some basic information about each dataframe\",\"Display a sample of each dataframe to understand the data\",\" Show dataframes schemas\",\"View the content of the dataframes\"],\"marker\":{\"opacity\":0.5,\"size\":5},\"mode\":\"markers+text\",\"name\":\"109_Displaying Basic Information about DataFrames\",\"text\":[\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\"],\"textfont\":{\"size\":12},\"x\":[9.519330024719238,9.216100692749023,8.128742218017578,8.6817626953125,9.37283706665039,9.399144172668457,7.752174377441406,8.67491340637207,9.4753999710083,8.732339859008789,9.93781852722168,9.484886169433594,9.055548667907715,9.605557441711426,9.185159683227539,10.112642288208008,9.571236610412598,8.886601448059082,9.271385192871094,9.21653938293457,9.84017562866211,9.642743110656738,8.863529205322266,8.855016708374023,9.566315650939941,9.782716751098633,10.221638679504395],\"y\":[-4.158840179443359,-4.068958282470703,-3.922122001647949,-3.8597679138183594,-4.632263660430908,-3.71893048286438,-3.2048513889312744,-3.343386173248291,-4.197732448577881,-3.863006353378296,-4.161005973815918,-3.668623924255371,-4.063244342803955,-3.963313579559326,-3.437166452407837,-3.672628164291382,-4.159616470336914,-4.024783134460449,-3.393700122833252,-3.6612892150878906,-3.054628372192383,-3.7078490257263184,-3.5935001373291016,-3.8762660026550293,-4.153101921081543,-4.012218952178955,-3.8656864166259766],\"type\":\"scattergl\"},{\"hoverinfo\":\"text\",\"hovertext\":[\"check that the data is as expected\\ndf_characters.head()\",\"Confirming the data has been loaded correctly\\ndf_characters.head()\",\"Check if all the csv files in data were loaded correctly\\ndf_characters.head()\",\"Check that the data has been properly loaded\\ndf_characters.head()\",\" Check the loaded data\\ndf_characters.head()\",\"Check if everything is reand correctly\\ndf_characters.head()\",\"Check data has been read correctly\\ndf_characters.head()\",\"Check if data loaded correctly\\ndf_characters.head()\",\"Check files have been correctly loaded\\ndf_characters.head()\",\"Test to ensure the data has been read correctly\\ndf_characters.head()\",\"Verify the data has been correctly loaded.\\ndf_characters.head()\",\"Check if the data has been read correctly\\ndf_characters.head()\",\"Check if data has been loaded successfully\\ndf_characters.head()\",\" Check that the data has been loaded correctly\\nprint(df_characters.head())\",\"algunas veces aparece un error en la lectura del dataframe con formato incorrecto o inesperado, por lo que se debe ajustar el formato con un encoding espec\\u00edfico.\",\" Check the loaded data\\ndf_characters.head()\",\"Check that the datasets have been loaded properly\\ndf_characters.head()\",\"Check if data was correctly loaded\\ndf_characters.head()\",\"checks the right columns have been loaded\\ndf_characters.head()\",\" Verify that the data was read correctly\\ndf_characters.head()\",\"Check the loaded data\\ndf_characters.head()\",\"check if datraframe loaded correctly\\nprint(df_characters.head())\",\"Check that the datasets have been loaded correctly\\ndf_characters.head()\",\"Check the data loaded correctly\\ndf_characters.head()\",\"Checking if the CSV files have been loaded correctly\\ndf_characters.head()\",\"Check that the dfs are read correctly\\ndf_characters.head()\",\" Check if the dataset was loaded correctly\\ndf_characters.head()\"],\"marker\":{\"opacity\":0.5,\"size\":5},\"mode\":\"markers+text\",\"name\":\"110_Data Loading Verification\",\"text\":[\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\"],\"textfont\":{\"size\":12},\"x\":[5.799869537353516,5.802257537841797,5.757038593292236,5.597143173217773,5.363808631896973,5.979368686676025,5.600564956665039,5.139566421508789,5.146988391876221,6.000870227813721,5.571400165557861,5.542672157287598,5.197514533996582,5.438724994659424,6.220273017883301,4.967629432678223,5.706663131713867,5.149702072143555,5.467155456542969,5.637289524078369,5.1295270919799805,5.157169342041016,5.477534770965576,5.3702216148376465,5.385786533355713,5.814745903015137,5.418811321258545],\"y\":[12.12595272064209,11.459691047668457,11.11116886138916,11.944530487060547,11.816699028015137,12.177643775939941,12.178095817565918,11.893818855285645,11.580305099487305,12.434450149536133,11.839555740356445,12.205245971679688,12.33322811126709,11.696845054626465,10.83957576751709,12.127385139465332,11.768420219421387,11.965310096740723,11.920572280883789,11.821120262145996,12.351300239562988,11.812304496765137,11.736287117004395,11.921586036682129,11.516275405883789,11.833911895751953,11.656401634216309],\"type\":\"scattergl\"},{\"hoverinfo\":\"text\",\"hovertext\":[\"Initializing spaCy\\nnlp = spacy.load(\\\"en_core_web_sm\\\")\",\"Set up spaCy\\nnlp = spacy.load(\\\"en_core_web_sm\\\")\",\" Configure spacy\\nnlp = spacy.load('en_core_web_sm')\",\" Set up spacy\\nnlp = spacy.load('en_core_web_sm')\",\"Set up spacy\\nnlp = spacy.load('en_core_web_sm')\",\" Spacy nlp only needs to be initiated once\\nnlp = spacy.load('en_core_web_sm')\",\"Load spaCy\\nnlp = spacy.load(\\\"en_core_web_sm\\\")\",\"Set up Spacy\\nnlp = spacy.load('en_core_web_sm')\",\"\\n# Setting up Spacy\\nnlp = spacy.load(\\\"en_core_web_sm\\\")\",\"Set up spaCy\\nnlp = spacy.load('en_core_web_sm')\",\"Set up spacy\\nnlp = spacy.load('en_core_web_sm')\",\" Set up spaCy\\nnlp = spacy.load('en_core_web_sm')\",\"# Set up Spacy\\nnlp = spacy.load('en_core_web_sm')\",\"# Initialize spaCy\\nnlp = spacy.load(\\\"en_core_web_sm\\\")\",\" Load spacy\\nnlp = spacy.load('en_core_web_sm')\",\" Setting up spacy\\nnlp = spacy.load(\\\"en_core_web_sm\\\")\",\"Load Spacy\\nnlp = spacy.load('en_core_web_sm')\",\"Setup\\nnlp = spacy.load(\\\"en_core_web_sm\\\")\",\"# Initialize spaCy's tokenizer\\nnlp = spacy.load('en_core_web_sm')\",\" Set up spaCy\\nnlp = spacy.load(\\\"en_core_web_sm\\\")\",\"Set up Spacy\\nnlp = spacy.load(\\\"en_core_web_sm\\\")\",\"# Setup spacy\\nnlp = spacy.load('en_core_web_sm')\",\"Load spacy core\\nnlp = spacy.load(\\\"en_core_web_sm\\\")\",\"Setting up Spacy\\nnlp = spacy.load('en_core_web_sm')\",\"Initialize spacy\\nnlp = spacy.load('en_core_web_sm')\",\"Initializing spacy\\nnlp = spacy.load(\\\"en_core_web_sm\\\")\",\"Set up spacy\\nnlp = spacy.load('en_core_web_sm')\"],\"marker\":{\"opacity\":0.5,\"size\":5},\"mode\":\"markers+text\",\"name\":\"111_Spacy setup\",\"text\":[\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\"],\"textfont\":{\"size\":12},\"x\":[16.79141616821289,15.974617004394531,16.431299209594727,16.99842071533203,17.065610885620117,17.06920051574707,15.889931678771973,16.871864318847656,16.063087463378906,17.298080444335938,17.036821365356445,17.37435531616211,17.394004821777344,16.70250701904297,16.598299026489258,16.24810791015625,16.447032928466797,15.684924125671387,16.564559936523438,15.829743385314941,15.728108406066895,16.8100643157959,16.37225914001465,17.028451919555664,17.074918746948242,17.11077880859375,16.981155395507812],\"y\":[8.838020324707031,8.386384010314941,8.223529815673828,8.904696464538574,8.739694595336914,8.718904495239258,8.816792488098145,9.03272533416748,8.300973892211914,8.686285018920898,8.730499267578125,9.048877716064453,9.043575286865234,8.79102611541748,9.073973655700684,8.425259590148926,9.100201606750488,7.87978458404541,8.505563735961914,8.444119453430176,8.367593765258789,8.575639724731445,8.78641414642334,8.65949821472168,8.610089302062988,8.721877098083496,9.047334671020508],\"type\":\"scattergl\"},{\"hoverinfo\":\"text\",\"hovertext\":[\"View the content of each dataset\\ndf_characters.head()\",\"Explore the structure of the datasets\\ndf_characters.head()\",\"Inspect the character dataset\\ndf_characters.head()\",\" Quick exploration of the characters dataset\\ndf_characters.head()\",\"Inspect a few entries in the characters dataset\\ndf_characters.head()\",\"Summary statistics of the characters dataset\\ndf_characters.head()\",\"A quick view of the characters dataset\\ndf_characters.head()\",\"Exploring the datasets\\ndf_characters.head()\",\"Inspecting the character dataset\\ndf_characters.head()\",\"Explore the characters dataset\\ndf_characters.head()\",\"Explore the characters dataset\\ndf_characters.head()\",\"# Let's display each dataset to understand its structure\\ndf_characters.head()\",\"View dataset\\ndf_characters.head()\",\"Explore the characters dataset\\ndf_characters.head()\",\"Overview of the characters dataset\\nprint(df_characters.shape)\\ndf_characters.head()\",\"Let's see how the characters dataset looks like\\ndf_characters.head()\",\"Quick peek at the character dataset\\ndf_characters.head()\",\"Quick overview of the characters dataset\\ndf_characters.head()\",\"Initial exploration of the datasets\\ndf_characters.head()\",\"Explore the datasets\\ndf_characters.head()\",\"Brief look at our datasets\\ndf_characters.head()\",\"Inspect the contents of the Character dataset\\ndf_characters.head()\",\"Explore the dataset\\ndf_characters.head()\",\"Sample of the characters dataset\\ndf_characters.head()\",\"Show examples of each dataset\\ndf_characters.head()\",\"A sample of the characters dataset\\ndf_characters.head()\",\"Explore the characters dataset\\ndf_characters.head()\"],\"marker\":{\"opacity\":0.5,\"size\":5},\"mode\":\"markers+text\",\"name\":\"112_Exploring Characters Dataset with df_characters.head()\",\"text\":[\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\"],\"textfont\":{\"size\":12},\"x\":[5.135653972625732,4.982851982116699,5.183717250823975,4.962274074554443,5.189783573150635,5.03621768951416,5.356815814971924,4.902403831481934,4.95690393447876,4.609320163726807,4.917878150939941,4.949100494384766,5.790241718292236,4.736451625823975,5.488430023193359,5.4747161865234375,5.1188154220581055,5.361203193664551,5.271289348602295,4.880404949188232,4.971792697906494,5.62370491027832,4.918378829956055,5.116976261138916,4.6881103515625,5.336688995361328,4.746137619018555],\"y\":[15.30492115020752,14.499214172363281,14.542190551757812,14.859920501708984,14.892168045043945,14.70409870147705,15.481633186340332,15.006077766418457,14.679647445678711,14.989038467407227,15.104727745056152,15.056818962097168,15.457401275634766,14.95963191986084,14.725896835327148,14.316985130310059,15.236235618591309,14.908285140991211,15.02234935760498,14.614309310913086,14.31050968170166,14.496283531188965,14.78415584564209,14.562529563903809,15.030397415161133,14.363509178161621,15.191940307617188],\"type\":\"scattergl\"},{\"hoverinfo\":\"text\",\"hovertext\":[\" Filter only the contributions of the main characters\\nmain_characters = ['marge', 'homer', 'bart', 'lisa', 'maggie', 'sideshow', 'ned', 'krusty', 'milhouse', 'chief']\\ndf_script_main_characters = df_script[df_script['raw_character_text'].str.lower().isin(main_characters)]\",\" Extract all lines side by side and all names\\nsimpsons_lines = list(df_script['raw_text'])\\nsimpsons_characters = list(df_script['raw_character_text'])\",\"Selecting only the lines spoken by Homer\\ndf_homer = df_script[df_script['raw_character_text'] == 'Homer Simpson'].reset_index(drop=True)\",\"Extract all lines concerning Marge from the script dataframe\",\"Extract only parts of the script featuring the Simpson family\\ndf_simpsons_script = df_script[(df_script.raw_character_text == 'Marge')\\n                      | (df_script.raw_character_text == 'Homer')\\n                      | (df_script.raw_character_text == 'Bart')\\n                      | (df_script.raw_character_text == 'Lisa')\\n                      | (df_script.raw_character_text == 'Maggie')]\",\"# Create a DataFrame with the lines relevant to the character 'Homer Simpson' \\nhomer_lines = df_script[df_script['character_id'] == 2].reset_index(inplace=False, drop=True)\",\"Filter lines that are spoken by the main characters\\nmain_characters = df_characters[df_characters['char_is_primary']==1]\",\"Filter main characters\\nmain_characters = [\\\"Lisa\\\", \\\"Bart\\\", \\\"Homer\\\", \\\"Marge\\\", \\\"Maggie\\\", \\\"Mr. Burns\\\"]\\n\\ndf_script_main_characters = df_script[df_script.raw_character_text.isin(main_characters)]\",\" Select main characters only\\nmain_characters = [\\n    \\\"marge\\\", \\\"homer\\\", \\\"bart\\\", \\\"lisa\\\", \\\"maggie\\\", \\\"skinner\\\", \\\"ned\\\", \\\"burns\\\",\\n    \\\"milhouse\\\", \\\"moe\\\", \\\"krusty\\\", \\\"ralph\\\", \\\"apu\\\", \\\"barney\\\", \\\"nelson\\\", \\\"todd\\\",\\n    \\\"edna\\\", \\\"bob\\\", \\\"itchy\\\", \\\"patty\\\", \\\"selma\\\", \\\"lionel\\\", \\\"patty\\\", \\\"selma\\\",\\n    \\\"tilly\\\", \\\"sideshow\\\", \\\"abe\\\", \\\"krabappel\\\", \\\"carl\\\", \\\"lenny\\\", \\\"frink\\\"\\n]\\n\\n# Filter main characters lines\\ndf_script_main = df_script[df_script.raw_character_text.str.lower().isin(main_characters)]\\n\\n# Filter non trivial lines\\ndf_script_main = df_script_main[df_script_main.spoken_words.str.len() \\u003e 2]\",\"Reduce the script data for a character-centric analysis\\nmain_characters = ['marge', 'homer', 'bart', 'lisa', 'maggie', 'skinner', 'patty', 'selma', 'ned', 'krabappel', 'burns', 'milhouse']\\nscript_idx = (df_script.raw_character_text.str.lower().isin(main_characters)) | (df_script.raw_character_text.isna())\\ndf_script = df_script[script_idx]\\n\\n# Parse the data for a character-centric analyis\\ndf_script.reset_index(drop=True, inplace=True)\",\"Filtering characters with name \\\"Lisa\\\" in 'The Simpsons' dataset\\nlisa_id = df_characters[df_characters['character_name'].str.contains('lisa', case=False)]['id'].values[0]\\n\\nlisa_lines = df_script[df_script['character_id'] == lisa_id]\",\" Create a DataFrame consisting of only Bart's lines.\\nbart_id = df_characters[df_characters.character_name == 'Bart Simpson'].character_id.values[0]\",\"# Select only lines spoken by Homer\\nhomer_script_lines = df_script[df_script['raw_character_text'] == 'Homer Simpson']\",\"Clean script\\ndf_script = df_script[df_script['utterance'].str.find('SIMPSON') != 0]\\ndf_script = df_script[df_script['utterance'].str.find('HOMER') != 0]\\ndf_script = df_script[df_script['utterance'].str.find('BART') != 0]\\ndf_script = df_script[df_script['utterance'].str.find('LISA') != 0]\\ndf_script = df_script[df_script['utterance'].str.find('MARGE') != 0]\",\"select only the lines spoken by Homer Simpson\\ndf_homer = df_script[df_script['character_id'] == 2]\\n\\n# inspect the result\\ndf_homer.head()\",\"# We will provide examples based on quotes involving 'Homer Simpson'.\\nhomer_id = df_characters.loc[df_characters['character_name'].str.contains('Homer Simpson')].index[0]\\nhomer_quotes = df_script.loc[df_script['character_id'] == homer_id]\\nhomer_quotes.head()\",\"# Strip plotlines (out of memory exception, beware!)\\nMAX_LINES = 100000\\ndf_script = df_script[:MAX_LINES]\\ndf_script = df_script[df_script['character_id'] != 2]  # Remove lines by Homer\\ndf_script = df_script[df_script['raw_text'] != '']  # Remove empty lines\",\"Extract script with characters and their gender\\ndf_script_characters = df_script.merge(df_characters, left_on='character_id', right_on='id')\\n\\n# Filter only episodes in English\\ndf_script_characters = df_script_characters[df_script_characters['episode_id'].isin(df_episodes[df_episodes['original_air_date']!='un-aired']['id'])]\\n\\n# Remove non-spoken lines\\ndf_script_characters = df_script_characters[-df_script_characters.raw_text.str.contains('Marge:[\\\\s\\\\S]*|Homer:[\\\\s\\\\S]*|Bart:[\\\\s\\\\S]*|Lisa:[\\\\s\\\\S]*|Maggie:[\\\\s\\\\S]*|Gerald:[\\\\s\\\\S]*|Carl: [\\\\s\\\\S]*|Lenny:[\\\\s\\\\S]*|Seymour:[\\\\s\\\\S]*|Moe:[\\\\s\\\\S]*|Chief Wiggum: [\\\\s\\\\S]*|Montgomery Burns:[\\\\s\\\\S]*|Waylon Smithers:[\\\\s\\\\S]*|Krusty:[\\\\s\\\\S]*|Ned:[\\\\s\\\\S]*|Rev. Lovejoy:[\\\\s\\\\S]*|Edna: [\\\\s\\\\S]*|Milhouse:[\\\\s\\\\S]*|Skinner:[\\\\s\\\\S]*|Patty:[\\\\s\\\\S]*|Selma:[\\\\s\\\\S]*|Barney:[\\\\s\\\\S]*|Apu:[\\\\s\\\\S]*|Nelson:[\\\\s\\\\S]*|Jimbo:[\\\\s\\\\S]*|Dolph:[\\\\s\\\\S]*|Kearney:[\\\\s\\\\S]*|Rod:[\\\\s\\\\S]*|Todd:[\\\\s\\\\S]*|Maude:[\\\\s\\\\S]*|Helen:[\\\\s\\\\S]*|Miss.Hoover:[\\\\s\\\\S]*|Sherri:[\\\\s\\\\S]*|Terri:[\\\\s\\\\S]*|Martin:[\\\\s\\\\S]*|Santa\\\\'s Little Helper:[\\\\s\\\\S]*|Patty and Selma:[\\\\s\\\\S]*|Groundskeeper Willie:[\\\\s\\\\S]*|Bob:[\\\\s\\\\S]*|Frank:[\\\\s\\\\S]*|Dr. Hibbert:[\\\\s\\\\S]*|Jasper:[\\\\s\\\\S]*|Cletus:[\\\\s\\\\S]*|Sideshow Bob:[\\\\s\\\\S]*|Mayor Quimby:[\\\\s\\\\S]*|Snake:[\\\\s\\\\S]*|Disco Stu:[\\\\s\\\\S]*|Reverend Lovejoy:[\\\\s\\\\S]*|Wiggum:[\\\\s\\\\S]*|Ap...\",\"Choosing a subset of the characters to focus on\\ncharacters_focus = [\\n    'Lisa_Simpson',\\n    'Bart_Simpson',\\n    'Homer_Simpson',\\n    'Marge_Simpson',\\n    'C._Montgomery_Burns',\\n    'Seymour_Skinner',\\n    'Ned_Flanders',\\n    'Moe_Szyslak',\\n    'Grampa_Simpson',\\n    'Milhouse_Van_Houten',\\n    'Krusty_The_Clown',\\n    'Chief_Wiggum',\\n    'Waylon_Smithers'\\n]\\n\\n# Reduce the dataframes to what we need\\ndf_script = df_script[df_script['raw_character_text'].isin(characters_focus)]\\ndf_characters = df_characters[df_characters['name'].isin(characters_focus)]\\ndf_characters['character_id'] = df_characters['id']\\ndf_locations = df_locations[df_locations['normalized_name'].str.contains('springfield', case=False, na=False)]\\ndf_script = df_script[df_script['episode_id'].isin(df_locations['episode_id'])]\",\"Keep only Homer speaking lines\\nhomer_utterances = df_script[(df_script['character_id'] == df_characters[df_characters['raw_character_text'] == 'Homer Simpson'].iloc[0]['id'])]\",\"Unify character IDs in 'df_script' CRUCIAL TO EXECUTE FIRST\\ndf_script['character_id'] = np.where(df_script.raw_character_text == 'Other_Spuckler', 132,\\n                               np.where(df_script.raw_character_text == 'Sherri\\u002fTerri', 140,\\n                                        np.where(df_script.raw_character_text == 'Question\\\\'s Voice', 180,\\n                                                 np.where(df_script.raw_character_text == 'French President', 321,\\n                                                          df_script.character_id))))\\ndf_script['character_id'].replace(df_characters.set_index('character_id').raw_character.str.split().to_dict()['Homer'], 1, inplace=True)\\ndf_script['character_id'].replace(df_characters.set_index('character_id').raw_character.str.split().to_dict()['Marge'], 2, inplace=True)\\ndf_script['character_id'].replace(df_characters.set_index('character_id').raw_character.str.split().to_dict()['Bart'], 8, inplace=True)\\ndf_script['character_id'].replace(df_characters.set_index('character_id').raw_character.str.split().to_dict()['Lisa'], 9, inplace=True)\\ndf_script['character_id'].replace(df_characters.set_index('character_id').raw_character.str.split().to_dict()['Maggie'], 10, inplace=True)\\ndf_script['character_id'].replace(df_characters.set_index('character_id').raw_character.str.split().to_dict()['Santa\\\\'s Little Helper'], 14, inplace=True)\\ndf_script['character_id'].replace(df_characters.set_index('character_id').raw_character.str.split().to_dict()['Seymour Skinner'], 15, inplace=True)\\ndf_script['character_id'].replace(df_characters.set_index('character_id').raw_character.str.split().to_dict()['Ned Flanders'], 16, inplace=True)\\ndf_script['character_id'].replace(df_characters.set_index('character_id').raw_character.str.split().to_dict()['Grampa'], 17, inplace=True)\\ndf_script['character_id'].replace(df_characters.set_index('character_id').raw_character.str.split().to_dict()[\\\"Krusty the Clown\\\"], 20, inplace=True)\\ndf_script['character_id'].replace(df_characters.set_index('character_id').raw_character.str.split().to_dict()['Rev. Timothy Lovejoy'], 21, inplace=True)\\ndf_script['character_id'].replace(df_characters.set_index('character_id').raw_character.str.split().to_dict()['Edna Krabappel'], 22, inplace=True)\\ndf_script['character_id'].replace(df_characters.set_index('character_id').raw_character.str.split().to_dict()['Kent Brockman'], 25, inplace=True)\",\"Remove any neutral or irrelevant sentences and characters from the scripts\\ndf_script = df_script[~df_script['raw_text'].str.contains(\\\"MAGGIE|MARGE|LISA|HOMER|BART|MAYOR QUIMBY|AINSWORTH|MAN'S VOICE|WOMAN'S VOICE|ALLURING VOICE|BART AND LISA|SQUEAKY VOICE|SFX|TALKING TO MAIN DOOR|SFX\\\")]\",\" Generate a DataFrame with only the data we are interested in\\ndf_script_mentions = df_script[(df_script.raw_character_text != ' ') & \\n                     (df_script.raw_character_text != 'Marge_Simpson') & \\n                     (df_script.raw_character_text != 'Lisa_Simpson') & \\n                     (df_script.raw_character_text != 'Bart_Simpson') & \\n                     (df_script.raw_character_text != 'Homer_Simpson') & \\n                     (df_script.raw_character_text != 'Couch_Gag')].reset_index(inplace=False, drop=True)\",\"Extract lines for specific character\\nhomer = df_script[df_script['character_id'] == 2]\\nmarge = df_script[df_script['character_id'] == 1]\\nbart = df_script[df_script['character_id'] == 8]\\nlisa = df_script[df_script['character_id'] == 9]\\nmaggie = df_script[df_script['character_id'] == 16]\",\"Limiting to main characters\\nmain_characters = [\\n    'marge',\\n    'homer',\\n    'bart',\\n    'lisa',\\n    'maggie',\\n    'krusty',\\n    'moe',\\n    'lenny',\\n    'carl',\\n    'ned',\\n    'burns',\\n    'skinner',\\n    'apu',\\n    'abe',\\n    'barney',\\n    'milhouse',\\n    'nelson',\\n    'ralph',\\n    'jimbo',\\n    'patty',\\n    'selma',\\n    'patty_selma',\\n    'martin',\\n    'todd',\\n    'melt',\\n    'milhouse_dad',\\n    'milhouse_mom',\\n    'skinner_mother',\\n    'clancy',\\n    'snake',\\n    'mrs_krabappel',\\n    'principal_knobbe',\\n    'captain_mccallister',\\n    'fat_tony',\\n    'comic_book_guy',\\n    'miss_hoover'\\n]\\n\\ndf_script_main = df_script[\\n    df_script.raw_character_text.str.lower().isin(main_characters)\\n]\",\"Select only Homer's lines \\ndf_homer = df_script[df_script.character_id == 2]\",\"# Name of the character we want to analyze\\ncharacter_name = 'Lisa Simpson'\\n\\n# Filter the scripts df for the selected character\\ndf_character = df_script[df_script.raw_character_text == character_name]\"],\"marker\":{\"opacity\":0.5,\"size\":5},\"mode\":\"markers+text\",\"name\":\"113_Character-Centric Analysis on Simpson's Main Characters\",\"text\":[\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\"],\"textfont\":{\"size\":12},\"x\":[6.179996013641357,5.023408889770508,5.5216288566589355,6.358156204223633,5.796576976776123,5.176877975463867,6.740157604217529,6.082879543304443,6.344040870666504,5.4819488525390625,5.281001091003418,4.968353748321533,6.1307501792907715,5.852427005767822,5.761517524719238,5.191442012786865,4.633995532989502,5.213858604431152,5.07314920425415,5.467442989349365,4.737197399139404,6.289778709411621,5.203256130218506,5.370481491088867,7.189770221710205,5.845903396606445,5.4268646240234375],\"y\":[8.929422378540039,7.410016059875488,7.294764995574951,6.53528356552124,7.661623477935791,6.917562961578369,8.943082809448242,8.474607467651367,8.131318092346191,7.91060733795166,8.071154594421387,7.423593521118164,7.452406406402588,7.918712615966797,7.021749496459961,7.723353862762451,7.140495777130127,7.767259120941162,8.112671852111816,7.527571201324463,7.590237140655518,7.818728923797607,7.437047481536865,7.241001129150391,7.889196395874023,7.236144065856934,8.323680877685547],\"type\":\"scattergl\"},{\"hoverinfo\":\"text\",\"hovertext\":[\"Creation of the spacy model\\nnlp = spacy.load('en_core_web_sm')\",\"Load spacy model\\nnlp = spacy.load('en_core_web_sm')\",\"Load Spacy model\\nnlp = spacy.load(\\\"en_core_web_sm\\\")\",\"Load spacy model\\nnlp = spacy.load('en_core_web_sm')\",\"Load Spacy model\\nnlp = spacy.load('en_core_web_sm')\",\"Load spacy models\\nnlp = spacy.load('en_core_web_sm')\",\"Initialize spaCy model\\nnlp = spacy.load(\\\"en_core_web_sm\\\")\",\"nitialize spaCy model\\nnlp = spacy.load('en_core_web_sm')\",\"Load NLP models\\nnlp = spacy.load(\\\"en_core_web_sm\\\")\",\"Path to spacy model\\nnlp = spacy.load('en_core_web_sm')\",\"load spacy model\\nnlp = spacy.load('en_core_web_sm')\",\" Load spaCy model\\nnlp = spacy.load('en_core_web_sm')\",\"Load Spacy model\\nnlp = spacy.load('en_core_web_sm')\",\" Initialize models\\nnlp = spacy.load('en_core_web_sm')\",\" Load Spacy NLP model\\nnlp = spacy.load('en_core_web_sm')\",\"Path to Spacy model\\nnlp = spacy.load('en_core_web_sm')\",\"Explicitly load in the required spacy model.\\nnlp = spacy.load(\\\"en_core_web_sm\\\")\",\"Home directory\\nhome = os.path.expanduser('~')\\n\\n# Spacy model\\nnlp = spacy.load('en_core_web_sm')\",\"Load spacy model\\nnlp = spacy.load(\\\"en_core_web_sm\\\")\",\"Load spaCy model\\nnlp = spacy.load(\\\"en_core_web_sm\\\")\",\"Initialization of Spacy model\\nnlp = spacy.load('en_core_web_sm')\",\"Load SpaCy NLP model\\nnlp = spacy.load('en_core_web_sm')\",\"Load spacy model\\nnlp = spacy.load('en_core_web_sm')\",\"Load Spacy model\\nnlp = spacy.load('en_core_web_sm')\",\"Load spaCy model\\nnlp = spacy.load('en_core_web_sm')\",\"Load embeddings model\\nnlp = spacy.load('en_core_web_lg')\",\"Load the spaCy model\\nnlp = spacy.load(\\\"en_core_web_sm\\\")\"],\"marker\":{\"opacity\":0.5,\"size\":5},\"mode\":\"markers+text\",\"name\":\"114_Spacy load encore web sm model\",\"text\":[\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\"],\"textfont\":{\"size\":12},\"x\":[16.02137565612793,15.826312065124512,16.012617111206055,15.765942573547363,15.621726036071777,15.65906047821045,16.721397399902344,16.4298095703125,15.76655101776123,16.17735481262207,15.861745834350586,15.89155101776123,15.678619384765625,16.347013473510742,15.526432037353516,16.00252914428711,16.327470779418945,16.92928123474121,16.32887077331543,16.315776824951172,16.607145309448242,15.63028621673584,15.594108581542969,15.750321388244629,15.851972579956055,15.29311752319336,16.3033447265625],\"y\":[9.832995414733887,10.459482192993164,10.382193565368652,10.452584266662598,10.472428321838379,10.009184837341309,9.85717487335205,10.230237007141113,9.328131675720215,9.437338829040527,10.546607971191406,10.274618148803711,10.096699714660645,9.831827163696289,9.738936424255371,9.412623405456543,9.949809074401855,9.148561477661133,10.344496726989746,10.420075416564941,9.921873092651367,9.882956504821777,10.293730735778809,10.292949676513672,10.227765083312988,9.047389030456543,10.197250366210938],\"type\":\"scattergl\"},{\"hoverinfo\":\"text\",\"hovertext\":[\"inspect the first 5 rows of the df_characters dataframe\\ndf_characters.head()\",\"# Access the first 5 characters\\ndf_characters.head()\",\"Inspect the first 5 rows of the characters dataframe\\ndf_characters.head()\",\"Inspect first 5 rows of character dataset\\ndf_characters.head()\",\"Inspect the first 5 rows of the characters dataframe\\ndf_characters.head()\",\"Inspect the first five rows of the characters DataFrame\\ndf_characters.head()\",\"Inspect first 5 rows of the characters dataframe\\ndf_characters.head()\",\"Inspect the first 5 rows of the characters DataFrame\\ndf_characters.head()\",\"Inspect the first 5 rows of the characters dataframe\\ndf_characters.head()\",\"Inspect the first 5 rows of the characters DataFrame\\ndf_characters.head()\",\"Explore the first 5 rows of the characters dataframe\\ndf_characters.head()\",\"Inspect the first 5 rows of the characters DataFrame\\ndf_characters.head()\",\"Inspect the first 5 rows of the characters dataframe\\ndf_characters.head()\",\"Inspect the first 5 rows of the characters dataframe\\ndf_characters.head()\",\"Explore the first 5 rows of the characters dataframe\\ndf_characters.head()\",\"Examine the first 5 rows of the characters dataframe\\ndf_characters.head()\",\"Inspect the first 5 rows of df_characters\\ndf_characters.head()\",\" inspect the first 5 rows of the characters dataframe\\ndf_characters.head()\",\"Inspect the first 5 lines of df_characters\\ndf_characters.head()\",\"Inspect the first 5 rows of the characters dataframe\\ndf_characters.head()\",\" Visual inspection of the first 5 rows of the `df_characters` dataframe\\ndf_characters.head()\",\"Inspect the first 5 rows of the characters dataframe\\ndf_characters.head()\",\"Inspect the first 5 records of the characters dataframe\\ndf_characters.head()\",\"# Inspect first 5 rows of df_characters\\ndf_characters.head()\",\"Inspect the content of the first 5 rows of the characters dataframe\\ndf_characters.head()\",\"Inspect the first 5 rows of the characters dataframe\\ndf_characters.head()\",\"Df tail for inspection\\nprint(df_characters.tail(5))\"],\"marker\":{\"opacity\":0.5,\"size\":5},\"mode\":\"markers+text\",\"name\":\"115_Character dataframe inspection\",\"text\":[\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\"],\"textfont\":{\"size\":12},\"x\":[0.6956695914268494,-0.03723438084125519,0.8823257088661194,0.5350973606109619,1.1150500774383545,1.224211573600769,1.2234772443771362,1.2560548782348633,1.0884413719177246,1.1310174465179443,0.9381269812583923,0.761724054813385,1.1814669370651245,1.1949998140335083,0.7673284411430359,1.0103856325149536,0.6303859353065491,0.8933296799659729,0.5250437259674072,1.3013672828674316,0.7018909454345703,0.960599958896637,0.6974563598632812,0.3922559916973114,0.9777366518974304,0.9336279630661011,-0.5677937269210815],\"y\":[11.703015327453613,12.452908515930176,11.601638793945312,11.949932098388672,11.387921333312988,11.396007537841797,11.285147666931152,11.575774192810059,11.656160354614258,11.405633926391602,11.220762252807617,11.244062423706055,11.345375061035156,11.508708000183105,11.080466270446777,11.314806938171387,12.281004905700684,11.566841125488281,12.533651351928711,11.444034576416016,11.493406295776367,11.674065589904785,12.102018356323242,11.9744291305542,11.227108001708984,11.460305213928223,12.484833717346191],\"type\":\"scattergl\"},{\"hoverinfo\":\"text\",\"hovertext\":[\"Information about the datasets\",\"Basic overview of datasets\",\"Exploring the dataset and quick looks at the data.\",\"Initial exploration of datasets\",\"Exploring the obtained datasets\",\"Explore datasets dimensions\",\"\\n# Some basic information about the datasets\",\" Some basic exploration of the datasets\",\" Exploring the datasets\",\"Quick analysis of the input datasets\",\"Profiling the different dataset\",\"Exploring the datasets\",\"Explore the datasets\",\"General analysis on the datasets.\",\"Initial investigation of the datasets\",\"Example of using the dataset.\",\"Dataset Exploration\",\"Explore datasets\",\"Exploring the dataset\",\"Exploring the datasets\",\"Description of the datasets\",\"Exploring the content of the datasets\",\"Description of the datasets.\",\"Explore the content of the datasets\",\"Exploring the dataset.\",\"Some basic info of the datasets\",\"Exploring dataset\"],\"marker\":{\"opacity\":0.5,\"size\":5},\"mode\":\"markers+text\",\"name\":\"116_Exploring Datasets\",\"text\":[\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\"],\"textfont\":{\"size\":12},\"x\":[15.887296676635742,16.177001953125,16.33953094482422,16.892873764038086,16.63550567626953,15.982524871826172,15.493408203125,16.335607528686523,16.84232521057129,15.783390998840332,16.162471771240234,16.693904876708984,16.260343551635742,16.696603775024414,16.130088806152344,15.711280822753906,16.795677185058594,16.463960647583008,16.738548278808594,16.623886108398438,15.805662155151367,16.21881866455078,15.673367500305176,15.64235782623291,16.972909927368164,15.973705291748047,16.862510681152344],\"y\":[-2.531475067138672,-2.4935646057128906,-1.888274073600769,-1.8766999244689941,-2.138035774230957,-2.908308267593384,-2.918982744216919,-2.0866689682006836,-2.2512104511260986,-2.309039831161499,-2.677255630493164,-1.972651720046997,-2.2485032081604004,-2.3618149757385254,-2.220625400543213,-2.256962776184082,-0.585424542427063,-2.01444935798645,-2.0234951972961426,-2.1832125186920166,-2.498851776123047,-2.4563019275665283,-2.595200777053833,-2.139259099960327,-2.284135341644287,-2.3715837001800537,-1.6796207427978516],\"type\":\"scattergl\"},{\"hoverinfo\":\"text\",\"hovertext\":[\"Convert timestamp_in and timestamp_out columns to datetime format\",\"Filtering dataset to include only the first 20 seasons\\ndf_episodes_first_20_seasons = df_episodes[df_episodes['season'] \\u003c= 20]\\n# converting date of release to a datetime object\\ndf_episodes_first_20_seasons['original_air_date'] = pd.to_datetime(df_episodes_first_20_seasons['original_air_date'])\\n\\ndf_episodes_first_20_seasons.head()\",\" convert date from string to datetime in episodes data\\ndf_episodes['original_air_date'] = pd.to_datetime(df_episodes['original_air_date'])\",\"Create a column for the episode's season and convert the date to a datetime type\\ndf_episodes['season'] = df_episodes['production_code'].str.slice(2, 4)\\ndf_episodes['original_air_date'] = pd.to_datetime(df_episodes['original_air_date'], infer_datetime_format=True)\",\" One-hot encode the year and season\\ndf_episodes = df_episodes.join(pd.get_dummies(df_episodes.season, prefix='season'))\\ndf_episodes = df_episodes.join(pd.get_dummies(df_episodes.air_date.dt.year, prefix='year'))\",\"Convert the episode air date to datetime object\\ndf_episodes['original_air_date'] = pd.to_datetime(df_episodes['original_air_date'])\\n\\n# Show first 5 characters in the characters dataset\\ndf_characters.head()\",\"Fix dates\\ndf_episodes['original_air_date'] = pd.to_datetime(df_episodes['original_air_date'], errors='coerce')\\ndf_episodes.moveToFirstAirenDate = pd.to_datetime(df_episodes.moveToFirstAirenDate, errors='coerce')\",\"Remove very beginning of date from date column in df_episodes\\ndf_episodes['date'] = df_episodes['date'].apply(lambda x: str(x)[10:] if pd.notnull(x) else x)\",\"Change format of air_date to date and change TZ to UTC\\ndf_episodes['original_air_date'] = pd.to_datetime(df_episodes['original_air_date'], errors='coerce')\\ndf_episodes['original_air_date'] = df_episodes['original_air_date'].dt.tz_localize('US\\u002fPacific').dt.tz_convert('UTC')\",\" Converts strings to datetime\\ndf_episodes['original_air_date'] = pd.to_datetime(df_episodes['original_air_date'], format='%Y-%m-%d')\",\" Convert the date and time attribute to datetime\\ndf_episodes['original_air_date'] = pd.to_datetime(df_episodes['original_air_date'])\",\" Convert the date from string to datetime\\ndf_episodes['original_air_date'] = pd.to_datetime(df_episodes['original_air_date'])\",\"Convert timestamps to datetime\\ndf_script['timestamp_in_ms'] = pd.to_numeric(df_script['timestamp_in_ms'], errors='coerce').fillna(0).astype(np.int64)\\ndf_script['timestamp'] = pd.to_datetime(df_script['timestamp_in_ms'], unit='ms')\\n\\n# Convert timestamps to datetime\\ndf_episodes['original_air_date'] = pd.to_datetime(df_episodes['original_air_date'], errors='coerce')\",\"Convert date attributes to datetime\\ndf_episodes['original_air_date'] = pd.to_datetime(df_episodes['original_air_date'])\",\"Change the episode air date to a datetime object\\ndf_episodes['original_air_date'] = pd.to_datetime(df_episodes['original_air_date'], infer_datetime_format=True)\",\"Converts date attributes to Python date objects\\ndf_episodes['original_air_date'] = pd.to_datetime(df_episodes['original_air_date'])\\n\\n# Drop unnecessary columns and rename others\\ndf_episodes.drop(['id', 'image_url', 'video_url'], axis=1, inplace=True)\\ndf_episodes.rename(columns={'id_s': 'episode_id', 'id': 'character_id', 'name': 'character_name'}, inplace=True)\",\"Change episodes to its datetime column\\ndf_episodes['original_air_date'] = pd.to_datetime(df_episodes['original_air_date'])\",\"Create a list with episodes dates\\nep_dates = df_episodes['original_air_date'].tolist()\\nep_dates\",\"Format date\\ndf_episodes.is_airing = pd.to_datetime(df_episodes.is_airing, errors='coerce')\\ndf_episodes.production_code = pd.to_numeric(df_episodes.production_code, errors='coerce')\",\"Create a datetime object from the air date of each episode\",\"Convert to datetime the air_date and create a timestamp index\",\"Ensure that the dataframe the correct dtypes\\ndf_episodes['original_air_year'] = pd.to_numeric(df_episodes['original_air_year'], errors='coerce')\\ndf_episodes['production_code'] = pd.to_numeric(df_episodes['production_code'], errors='coerce')\\ndf_script['timestamp_in_ms'] = pd.to_numeric(df_script['timestamp_in_ms'], errors='coerce')\",\"Change the format of the air_date column to datetime\\ndf_episodes['air_date'] = pd.to_datetime(df_episodes['air_date'])\",\"Create a column with only the year of the episode for ease of analysis\\ndf_episodes['year'] = df_episodes['original_air_date'].apply(lambda x: int(x.split('-')[0]))\",\"Change epsiode air date to datetime\\ndf_episodes['original_air_date'] = pd.to_datetime(df_episodes['original_air_date'])\",\"# Time idx's\\ntime_since_release = pd.to_datetime(df_episodes.timestamp, unit='s') - pd.to_datetime(df_episodes.timestamp, unit='s').min()\\nyears_since_release = time_since_release.dt.days \\u002f 365.25\",\"Convert datePublished column to pandas datetime\\ndf_episodes['datePublished'] = pd.to_datetime(df_episodes['datePublished'])\"],\"marker\":{\"opacity\":0.5,\"size\":5},\"mode\":\"markers+text\",\"name\":\"117_Converting dates to datetime in episodes data\",\"text\":[\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\"],\"textfont\":{\"size\":12},\"x\":[4.298065662384033,4.163503646850586,4.06547212600708,3.539191484451294,3.4440629482269287,3.9458861351013184,3.9160916805267334,3.7483408451080322,3.6490159034729004,4.052380561828613,3.762505292892456,3.7637665271759033,4.118590831756592,3.8082773685455322,3.818223237991333,3.574470281600952,3.8873565196990967,3.634592056274414,3.7004847526550293,3.942063808441162,3.929079532623291,3.8140621185302734,3.713643789291382,3.2809507846832275,3.78752064704895,3.5986647605895996,3.959878444671631],\"y\":[2.1872217655181885,3.2337818145751953,1.978622317314148,2.690556526184082,3.067110538482666,2.277524709701538,2.3953564167022705,3.10538649559021,2.115021228790283,1.8243334293365479,1.9365777969360352,2.2882487773895264,2.125812292098999,1.8821439743041992,1.9939191341400146,2.3321287631988525,2.5427656173706055,2.9556546211242676,1.819912314414978,2.242981195449829,1.8467248678207397,2.229362964630127,1.9186484813690186,3.588785171508789,2.1663668155670166,2.2444777488708496,1.93282151222229],\"type\":\"scattergl\"},{\"hoverinfo\":\"text\",\"hovertext\":[\"Preview the first 5 rows of the characters dataset\\ndf_characters.head()\",\"Preview first 5 entries of df_characters\\ndf_characters.head()\",\"Preview the first 5 rows of the characters dataframe\\ndf_characters.head()\",\"Preview the first 5 rows of the characters dataframe\\ndf_characters.head()\",\"Preview the first 5 rows of the characters dataframe\\ndf_characters.head()\",\"Preview the first three rows of the characters data\\ndf_characters.head(3)\",\"Preview the first 5 lines of the characters dataframe\\ndf_characters.head()\",\"Preview the first 5 rows of the characters dataframe\\ndf_characters.head()\",\"Preview the first 5 rows of 'df_characters' DataFrame\\ndf_characters.head()\",\"Preview the first few rows of the characters dataframe\\ndf_characters.head()\",\"Preview the first 5 rows of the characters dataframe\\ndf_characters.head()\",\"Preview the first 5 rows of the characters dataframe\\ndf_characters.head()\",\"Preview the first five rows of the characters dataframe\\ndf_characters.head()\",\"Preview the first 5 rows of the characters dataframe\\ndf_characters.head()\",\"Preview the first 5 rows of the characters dataframe\\ndf_characters.head()\",\"Preview the first 5 rows of the characters dataframe\\ndf_characters.head()\",\"Preview the first 5 rows of the characters dataframe\\ndf_characters.head()\",\"Preview the first 5 rows of the dataset\\ndf_characters.head()\",\"Previewing the first 5 lines of the dataframe containing the characters and the first 5 lines of the dataframe containing the locations\",\"Preview the first 5 rows of the characters dataframe\\ndf_characters.head()\",\"Preview the first 5 rows of the characters dataframe\\ndf_characters.head()\",\" Preview the first 5 rows of the characters dataframe\\ndf_characters.head()\",\" Preview the first 5 rows of the characters dataframe\\ndf_characters.head()\",\"Preview the first 5 rows of the characters dataframe\\ndf_characters.head()\",\" Preview the first 5 rows of the characters dataset\\ndf_characters.head()\",\"Preview the first 5 rows of the characters dataframe\\ndf_characters.head()\"],\"marker\":{\"opacity\":0.5,\"size\":5},\"mode\":\"markers+text\",\"name\":\"118_Previewing the first 5 rows of the characters dataframe\",\"text\":[\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\"],\"textfont\":{\"size\":12},\"x\":[-7.438317775726318,-7.7040510177612305,-7.773566722869873,-7.125810146331787,-7.357280254364014,-7.244059085845947,-6.917205333709717,-7.516027927398682,-7.1372551918029785,-7.650065898895264,-7.558701515197754,-7.257658958435059,-7.102442741394043,-7.440272808074951,-7.576173782348633,-7.61530065536499,-7.447253227233887,-7.399932861328125,-5.717746257781982,-7.519309997558594,-7.344157695770264,-7.50693941116333,-7.460546493530273,-7.570826530456543,-7.1813764572143555,-7.420230865478516],\"y\":[7.149905681610107,6.457686901092529,6.840263366699219,6.908172130584717,6.540593147277832,7.315430641174316,6.450938701629639,6.576046466827393,6.3310160636901855,6.680788516998291,6.8190531730651855,6.515664577484131,6.298465728759766,6.4968671798706055,6.716794013977051,6.866822242736816,6.662441730499268,6.987102031707764,6.255563735961914,6.7746124267578125,6.625888824462891,6.58855676651001,6.668496131896973,6.736334800720215,7.2176432609558105,6.447887420654297],\"type\":\"scattergl\"},{\"hoverinfo\":\"text\",\"hovertext\":[\"# The 'df_script' dataframe contains all the script lines. Let's take a look at the first few rows.\\ndf_script.head()\",\" Look at the script data frame\\ndf_script.head()\",\"Quick overview of the script dataframe\\ndf_script.head()\",\" Explore the content of one of the dataframes\\ndf_script.head()\",\"Inspect the contents of the scriptlines DataFrame to understand its structure and the kind of data it contains.\\ndf_script.head()\",\"Sample of script dataframe\\ndf_script.head()\",\"Inspect dataframe\\ndf_script.head()\",\"The structure for the script line dataframe is:\\ndf_script.head()\",\"Look at the first few rows of the script dataframe\\ndf_script.head()\",\" Look at the first 5 rows of the script dataframe\\ndf_script.head()\",\"Check the head of the script dataframe to understand its structure\\ndf_script.head()\",\" Explore the dataframe\\ndf_script.head()\",\" Look at the head of the script dataframe to understand its structure\\ndf_script.head()\",\"Inspecting the structure of script lines dataframe\\ndf_script.head()\",\"Optional - Explore a dataframe\\ndf_script.head()\",\"Inspecting the DataFrame head\\ndf_script.head()\",\" Merge dataframes to get all the information in one place\\n# Let's analyze the line by line script data\\ndf_script.head()\",\" Review the merged dataframe\\ndf_script.head()\",\"Check the first few lines of the dataframe to understand its structure\\ndf_script.head()\",\"Quick 'n dirty peek at the script dataframe\\ndf_script.head()\",\"Let's have a look at the content of the script dataframe:\\ndf_script.head()\",\"Take a peek at the first few rows of the \\\"script\\\" dataframe\\ndf_script.head()\",\"Look at the top 5 rows of df_script\\ndf_script.head()\",\"Quick look at the scripts dataframe\\ndf_script.head()\",\"# Assessing the dataframe quickly\\ndf_script.head()\",\"let's focus on the script dataframe for now\\ndf_script.head()\"],\"marker\":{\"opacity\":0.5,\"size\":5},\"mode\":\"markers+text\",\"name\":\"119_Exploring and Reviewing DataFrames in Python\",\"text\":[\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\"],\"textfont\":{\"size\":12},\"x\":[5.940707683563232,5.349546432495117,5.998857498168945,6.637335300445557,5.714324951171875,5.875072479248047,6.60667085647583,5.628426551818848,4.992537498474121,4.719744682312012,5.481146812438965,6.142026424407959,5.202146053314209,5.621458053588867,6.251135349273682,6.380434989929199,6.272228717803955,6.247647285461426,4.935079097747803,6.271449565887451,6.0105509757995605,5.771035194396973,4.884444713592529,5.6391825675964355,6.631340980529785,6.039464473724365],\"y\":[-4.996739864349365,-4.998600959777832,-5.634850025177002,-4.780200958251953,-4.438992023468018,-6.219767093658447,-5.301758766174316,-4.950715065002441,-5.267045497894287,-5.1885762214660645,-4.556173801422119,-5.40593147277832,-4.761643886566162,-5.031070232391357,-5.5533905029296875,-4.856078147888184,-4.0460381507873535,-4.838844299316406,-4.633986949920654,-5.281553268432617,-4.995001792907715,-5.303869247436523,-4.857287883758545,-5.605619430541992,-5.822227954864502,-5.830677032470703],\"type\":\"scattergl\"},{\"hoverinfo\":\"text\",\"hovertext\":[\"Test out the dataframes\",\" Checking all DataFrames\",\"Check a sample of the data for each dataframe\",\"Checking the simpons dataframe data.\",\" Print the shape of the dataframes to check if the files are read correctly\",\"Check the content inside the dataframe\",\" Check that everything worked by printing a snippet of each DataFrame\",\" Check the content of the dataframes\",\" Validate the integration by printing a few lines of each dataframe\",\"Checking the content of the dataframes\",\" Check the information in each dataframe.\",\" Check what's in the dataframes\",\"Check how the dataframes are looking\",\"Check if we have the correct dataframes\",\"Checking dataframes\",\"Check the dataframe schema\",\"Check the general information of the Python DataFrames\",\"Check dataframes shape and types\",\"Check what the dataframes look like\",\"Check the content of each DataFrame\",\"Check the contents of each dataframe\",\"Checking the shape of each dataframe\",\"# Room for checking the contents of the dataframes\",\"Checking the dataframes\",\"Checking Python version for compatibility\",\"Check content of dataframe with confirmed deduplication\"],\"marker\":{\"opacity\":0.5,\"size\":5},\"mode\":\"markers+text\",\"name\":\"120_Dataframe Checking and Deduplication\",\"text\":[\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\"],\"textfont\":{\"size\":12},\"x\":[10.940844535827637,10.199901580810547,9.980046272277832,10.904794692993164,10.766112327575684,9.811761856079102,10.013586044311523,9.86974048614502,9.99400806427002,10.090570449829102,10.285046577453613,10.125527381896973,10.662156105041504,9.898860931396484,10.169995307922363,10.076619148254395,10.491256713867188,10.640633583068848,10.487356185913086,9.954168319702148,10.066174507141113,10.686403274536133,9.969463348388672,10.327869415283203,10.547057151794434,9.334877967834473],\"y\":[-3.772329330444336,-3.2522943019866943,-3.135481595993042,-3.7709267139434814,-3.91416072845459,-3.228377342224121,-3.4384782314300537,-3.578956127166748,-3.5104503631591797,-3.4556164741516113,-4.705386161804199,-3.8599936962127686,-4.02166748046875,-2.979374647140503,-3.292083740234375,-3.9329326152801514,-3.830974817276001,-2.8060712814331055,-4.230959892272949,-3.5076022148132324,-3.2558369636535645,-3.8886361122131348,-3.0416276454925537,-3.617450475692749,-2.7079415321350098,-2.577840805053711],\"type\":\"scattergl\"},{\"hoverinfo\":\"text\",\"hovertext\":[\"Let's start by looking at the first few rows of the characters, locations, script, and episodes DataFrames.\",\"Check the first 5 entries of the characters, locations, script and episodes datasets.\",\"Check for names, locations and episode mentioned in the script data\",\"Exploring the data: characters, locations, and episodes.\",\"###############################################################################\\n# Unique Characters, Locations, Episodes\\n###############################################################################\",\" For the characters and locations datasets, we only want characters that are in at least 5 episodes, and locations that appeared in at least 3 episodes.\",\"# Given a character, determining how many unique locations that character has been to.\",\"This data consists of four tables: characters, locations, script lines, and episodes.\",\"Show the number of scenes, number of characters, and number of locations.\",\"Filter episodes where the character interacts with a location.\",\" Now, let's take a look on characters, script, episode and locations DataFrames.\",\"Build lookup tables for characters, locations, and episodes\",\" Assign colors to characters, locations, and episodes so that plots are understandable.\",\"Explore characters, locations, script lines, and episodes dataframes\",\" Let's display the number of characters, locations, script lines and episodes.\",\"Let's display the first few rows of characters, locations, script and episodes dataframes.\",\" Encode characters, locations and episodes\",\"Extract main locations from the episodes and count the number of episodes in each location.\",\"Query: Total number of characters, locations and episodes available in the dataset\",\"Let's explore the data by displaying information about the characters, locations, episodes, and script lines.\",\"This will allow us to see how many unique and major characters, episodes, and locations we are working with.\",\"Next, let's see how many unique characters, locations, and episodes are present in the dataset.\",\" Take a look at the characters, locations, script and episodes dataframes\",\"Check the number of characters, locations and episodes\",\"Define the main characters, seasons, and locations for the analysis.\",\"Let's take a look at the characters, locations, script and episodes DataFrames.\"],\"marker\":{\"opacity\":0.5,\"size\":5},\"mode\":\"markers+text\",\"name\":\"121_Determining Number of Unique Characters, Locations, and Episodes\",\"text\":[\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\"],\"textfont\":{\"size\":12},\"x\":[8.536088943481445,8.160601615905762,8.470663070678711,8.852123260498047,8.75790023803711,8.320247650146484,8.405075073242188,8.525565147399902,8.993034362792969,8.325020790100098,9.010275840759277,8.248486518859863,9.904749870300293,8.265877723693848,8.749332427978516,8.519735336303711,8.220047950744629,7.972224235534668,8.480436325073242,8.503751754760742,8.496302604675293,8.819243431091309,8.793339729309082,8.453666687011719,9.17996883392334,8.939080238342285],\"y\":[5.975276947021484,5.473281383514404,4.943573951721191,5.825862407684326,5.143496990203857,5.060222148895264,6.072122573852539,5.350042819976807,5.516519546508789,5.172798156738281,6.654595375061035,5.535815238952637,6.389922142028809,5.569836616516113,5.657204627990723,5.616372585296631,5.579838275909424,5.465085506439209,5.768927574157715,5.807010650634766,5.323390007019043,5.711135387420654,6.043769836425781,5.872736930847168,5.53485107421875,6.19073486328125],\"type\":\"scattergl\"},{\"hoverinfo\":\"text\",\"hovertext\":[\"Check if datasets were loaded properly\\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()\",\"Check that the dataframes were loaded successfully\\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()\",\"Check dataframes are correctly loaded\\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()\",\"Check files have been correctly loaded\\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()\",\"Check if dataframes are correctly loaded\\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()\",\"Reduce the size of the datasets for testing, not required for final use\\ndf_script = df_script.head(10000)\\ndf_episodes = df_episodes.head(1000)\",\"Check if all dataframes have been imported correctly\\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()\",\" Ensure all csv files were correctly loaded\\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()\",\"Check that the dataframes were imported correctly\\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()\",\"Check all files have been loaded properly\\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()\",\"Check if each dataframe was correctly loaded\\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()\",\"Check if the dataframes have been read correctly\\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()\",\"Check if all dataframes have been loaded successfully\\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()\",\"Check that the dataframes have been loaded correctly\\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()\",\"# ensure all dataset load correctly\\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()\",\"Check if all files are properly loaded\\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()\",\" Check the imported datasets\\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()\",\"Check if all datasets have been loaded correctly\\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()\",\"Check the loaded dataframes' contents\\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()\",\"Check first few lines of all imported datasets\\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()\",\"Check if the dataframe is loaded correctly\\ndf_episodes.head()\",\"Check if all datasets were loaded correctly\\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()\",\" Check if all datasets have been successfully loaded\\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()\",\" Test the dataframes loaded correctly\\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()\",\"check if all finishes properly\\n[df_characters.shape, df_locations.shape, df_script.shape, df_episodes.shape]\",\"Check that all imports have been successful\\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()\"],\"marker\":{\"opacity\":0.5,\"size\":5},\"mode\":\"markers+text\",\"name\":\"122_Checking successful import of datasets and dataframes\",\"text\":[\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\"],\"textfont\":{\"size\":12},\"x\":[-2.552370071411133,-3.0873024463653564,-3.118304491043091,-3.2535288333892822,-2.973231792449951,-1.6763741970062256,-3.001051902770996,-3.3817131519317627,-3.2551355361938477,-2.684530019760132,-3.1070432662963867,-3.377678394317627,-2.798814296722412,-3.069920539855957,-2.80023455619812,-2.94333553314209,-2.6049370765686035,-2.4209530353546143,-3.5871410369873047,-2.556807279586792,-2.0918312072753906,-2.6814048290252686,-2.7550241947174072,-3.344977378845215,-1.2540723085403442,-2.4475090503692627],\"y\":[0.5509411096572876,-0.3996216952800751,-0.1240118071436882,-0.38485074043273926,-0.19013874232769012,1.0965230464935303,0.010510760359466076,-0.448354572057724,-0.3713385760784149,-0.3496339023113251,0.14085285365581512,-0.19916076958179474,-0.014321934431791306,-0.16004574298858643,0.5097247362136841,-0.3632259964942932,0.9432334303855896,-0.04202777147293091,0.13251619040966034,0.7013619542121887,0.3596314787864685,0.18106386065483093,0.18302080035209656,-0.30313628911972046,0.07290638238191605,-0.03529808670282364],\"type\":\"scattergl\"},{\"hoverinfo\":\"text\",\"hovertext\":[\"Create a connection to the PostgreSQL database\",\"Connections -- Create PostgreSQL tables and upload the DataFrames\",\" Create an engine to run SQL queries on the database\\nfrom sqlalchemy import create_engine\",\" Define the database file\\ndb_file = \\\"simpsons.sqlite\\\"\",\"Connections and configurations for your database\",\"# Ensure the PostgreSQL server is running\\n!service postgresql start\",\"connectionstring = \\\"postgresql:\\u002f\\u002fuser:password@localhost\\u002fsimpsons\\\"\\n\",\"import sqlite3\",\"Connect to sqlite db\\nimport sqlite3\\n\\nconn = sqlite3.connect('data\\u002fsimpsons_script_database.db')\",\"Create a connection to Postgres database using sqlalchemy library.\",\"Create a connection to the database and extract the script lines\",\"Set verbose=True for SQL debugging\\nos.environ['SQLALCHEMY_ECHO'] = 'True'\\n\\n# Create a connector using the preferred settings\\n!username='' password='' host AWS_Web_Services_key='' Database_name='' !pip install records\\nimport records  # from Database name ORM determined which database it should be connected and ORM performs this operation on behalf of us\\n\\ndef db_connector(*args, **kwargs):\\n    return records.Database(*args, **kwargs)\",\"Create a limited number of connections and a limited number of command functions.\",\"# Ensure sqlite3 works in Jupyter\\n%load_ext sql\\n\\n# Connect to the pre-loaded SQLite database\\n%sql sqlite:\\u002f\\u002f\\u002fdata\\u002fsimpsons-database.db\",\"# Connect to local PostgreSQL database\\nfrom sqlalchemy import create_engine\\nengine = create_engine('postgresql:\\u002f\\u002flocalhost\\u002fsimpsons')\\nconn = engine.connect()\",\" Connect to the SQLite database using the sqlalchemy package using the create_engine function in the sqlalchemy module.\",\"Create a connection to the database\",\"Create a connection to the PostgreSQL database\",\"Create an in-memory SQLite database that we can use to execute SQL queries\\nfrom sqlalchemy import create_engine\\n\\n# This is a simple way to store and manipulate data.\\n# We could also use this in-memory storage to filter data and create useful\\n# transformations that we could then export to a more scalable solution\\nengine = create_engine('sqlite:\\u002f\\u002f', echo=False)\",\"Create a connection to a database\",\"Create a connection to the SQLite database containing the data\\nconn = sqlite3.connect('data\\u002fsimpsons.sqlite')\",\"# Creating a connection\\nfrom sqlalchemy import create_engine\\nengine = create_engine('sqlite:\\u002f\\u002f\\u002fdata\\u002fsimpsons.db')\",\" Connect to the database\",\"Add relative path for SQL connections\\nimport sys\\nsys.path.append('..')\",\" Connect to our DB\\ncon = sqlite3.connect(\\\"data\\u002fsimpsons_script_database.db\\\")\\n\\n# Create cursor\\ncur = con.cursor()\",\"Connect to SQL Database\"],\"marker\":{\"opacity\":0.5,\"size\":5},\"mode\":\"markers+text\",\"name\":\"123_Database Connection in SQL and SQLAlchemy\",\"text\":[\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\"],\"textfont\":{\"size\":12},\"x\":[15.652950286865234,15.050455093383789,14.945097923278809,14.49500846862793,15.904143333435059,14.834376335144043,15.324872016906738,14.683259963989258,14.79421615600586,15.457202911376953,15.574248313903809,15.04781723022461,13.312265396118164,14.389641761779785,15.073479652404785,15.059395790100098,15.795384407043457,15.530210494995117,15.049764633178711,15.727405548095703,14.759247779846191,14.879535675048828,15.83303165435791,15.215120315551758,14.51424789428711,15.88532543182373],\"y\":[-5.620190143585205,-5.390946865081787,-5.098666667938232,-4.6594157218933105,-5.600085258483887,1.7481704950332642,-5.444742679595947,-4.812591075897217,-4.864520072937012,-5.34506893157959,-4.906728744506836,-4.4987688064575195,1.070399522781372,-4.62131404876709,-5.135873794555664,-5.209005355834961,-5.4594926834106445,-5.633216857910156,-5.215784549713135,-5.511723041534424,-4.979032039642334,-4.955245494842529,-5.587146282196045,2.6598100662231445,-5.065469741821289,-5.499955177307129],\"type\":\"scattergl\"},{\"hoverinfo\":\"text\",\"hovertext\":[\"Initially reset the index of the DataFrames for consistency.\",\"Read data from CSV files and reset index to ensure the data is correctly formatted for further processing.\",\"Load the datasets and reset their indices to start from 0.\",\"It is a good practice to reset the index of DataFrames after reading them from CSV files, as it will avoid potential issues with index misalignment.\",\" Load the data from the CSV files and reset the index of each DataFrame.\",\"TODO: Make sure the dataframe indexes are reset.\",\"Load dataset and reset index\",\"Reading the datasets from CSV files and resetting the index of each DataFrame.\",\" Remove the index from csv load\",\" remove index from csv imports\",\"Loading the CSV files and resetting the index to ensure the data is correctly loaded and indexed.\",\"We start by loading the datasets using pandas `read_csv` function. Then we reset the index using the `reset_index` method to have a fresh index.\",\"The first step is to load the data into DataFrames using pandas. We then reset the index of each DataFrame to ensure everything is properly aligned.\",\"Load the data into dataframes and reset the index to ensure the indexes are correct.\",\"\\n#* Here we read in the data using pandas read_csv function and reset the index on the dataframes.\",\"We have imported the necessary libraries and now we are loading the datasets using pandas.read_csv() function and resetting the index for each dataframe.\",\"First, we read in the data from CSV files into pandas DataFrames. We reset the index and drop the previous index to ensure the index remains continuous integers.\",\"In this code, we are reading CSV files into pandas dataframes using the `pd.read_csv` method. This allows us to work with the data from these files using the DataFrame data structure provided by the pandas library. We also use the `reset_index` method to reset the index of the dataframes.\",\"Delete the index from the CSV files\",\"Since there is no specific file path for the datasets, the code reads the CSV files with the 'read_csv' function from the pandas library and then resets the index of the resulting dataframes.\",\"We are reading the datasets from CSV files and resetting the index of each dataframe.\",\"Drop the index column from the dataframes that was read with the csv.\",\" Remove the column that has been passed as an index from the CSV file\",\" For some reason, the index column `Unnamed: 0` is created during csv\\n#  reading; we need to remove this from the dataframes.\",\"use read_csv from pandas to read in the csv files and reset the index of each dataframe\",\"Since we are working with data from the Simpsons TV show, we are importing the required data from CSV files using pandas. This code snippet reads the data from CSV files and resets the index of each dataframe.\"],\"marker\":{\"opacity\":0.5,\"size\":5},\"mode\":\"markers+text\",\"name\":\"124_Resetting Indexes and Loading CSV Files Using Pandas\",\"text\":[\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\"],\"textfont\":{\"size\":12},\"x\":[9.090780258178711,9.940231323242188,10.286890029907227,9.508089065551758,9.673428535461426,8.651991844177246,10.051798820495605,9.954014778137207,9.763023376464844,9.743000984191895,10.041171073913574,9.614950180053711,9.306693077087402,9.060161590576172,9.392765045166016,9.797850608825684,9.300214767456055,10.231364250183105,9.691749572753906,9.997987747192383,9.842305183410645,9.399858474731445,9.259191513061523,9.669715881347656,9.754194259643555,10.193870544433594],\"y\":[0.25638118386268616,1.0417848825454712,0.5689087510108948,0.38451817631721497,0.7897080779075623,-0.4089658260345459,1.0765310525894165,0.8928532600402832,1.5348845720291138,1.2350053787231445,1.467846155166626,0.673940122127533,0.628818690776825,0.35135161876678467,0.6311666965484619,0.9088286757469177,0.7553173303604126,1.0568995475769043,1.3298677206039429,0.812429666519165,0.9038732647895813,0.5664175748825073,1.2878975868225098,0.4213230609893799,0.8560345768928528,1.855394721031189],\"type\":\"scattergl\"},{\"hoverinfo\":\"text\",\"hovertext\":[\"Merge episodes with script\\ndf_episodes = df_episodes.rename(columns={'id':'episode_id'})\\ndf_script = pd.merge(df_script, df_episodes, on='episode_id')\",\"Merge episodes and scripts\\ndf_episodes.rename(columns={'id':'episode_id'}, inplace=True)\\ndf = pd.merge(df_script, df_episodes, on='episode_id')\\n\\n# Display the first rows of the dataframe\\ndf.head()\",\" Merge episodes and scripts into a single dataframe\\ndf_episodes.rename(columns={'id': 'episode_id'}, inplace=True)\\ndf = pd.merge(df_script, df_episodes, on='episode_id')\",\"Add status to script lines dataframe\\ndf_script = df_script.merge(df_episodes[['id', 'production_code', 'season', 'number_in_season', 'number_in_series', 'air_date']], left_on='episode_id', right_on='id', suffixes=(False, False)).fillna(\\\"\\\")\\ndf_script.rename(columns={'production_code': 'episode_production_code', \\n                          'id': 'episode_id', \\n                          'season': 'episode_season', \\n                          'number_in_season': 'episode_number_in_season', \\n                          'number_in_series': 'episode_number_in_series', \\n                          'air_date': 'episode_air_date'}, inplace=True)\",\"Change Name of the First Column for Each Dataframe\\ndf_characters.rename(columns={'id': 'character_id'}, inplace=True)\\ndf_locations.rename(columns={'id': 'location_id'}, inplace=True)\\ndf_script.rename(columns={'id': 'line_id'}, inplace=True)\\ndf_episodes.rename(columns={'id': 'episode_id'}, inplace=True)\",\"Merge lines with episodes\\nepisode_lines=pd.merge(df_script, df_episodes, left_on='episode_id', right_on='id').rename(columns={\\\"id_x\\\": \\\"line_id\\\"}).rename_axis('id').reset_index(drop = True)\",\"Rename speaker and episode_id columns for clarity\\ndf_script = df_script.rename(columns={'episode_id': 'id', 'character_id': 'speaker_id'})\",\" Simplify DataFrame and lowercase the episode name\\ndf_characters = df_characters[['id', 'name']].rename({'id': 'character_id', 'name': 'character_name'}, axis=1)\\n\\n# Simplify DataFrame and lowercase the episode name\\ndf_episodes = df_episodes[['id', 'title', 'original_air_date', 'production_code']].rename({'id': 'episode_id', 'title': 'episode_title'}, axis=1)\\ndf_episodes['episode_title'] = df_episodes['episode_title'].str.lower()\",\"Following code will rename the column 'id' to 'episode_id'.\",\"df_script.rename(columns={\\\"episode_id\\\": \\\"id\\\"}, inplace=True)\",\"define primary key (episode_id and number)\\ndf_episodes = df_episodes.rename(columns={'id':'episode_id'})\\ndf_episodes = df_episodes.set_index('episode_id', drop=False)\",\"\\n# Merge scripts with other tables for better style\\ndf_script = pd.merge(df_script, df_episodes, \\n                     left_on='episode_id', right_on='id',\\n                     suffixes=('_script_line', '_ep')).drop(columns=['id_ep']).rename(columns={'name': 'episode_name', 'number': 'episode_number', 'id_script_line': 'id'})\\n\\ndf_script = pd.merge(df_script, df_characters, \\n                     left_on='character_id', right_on='id',\\n                     suffixes=('_script', '_character')).drop(columns=['id_character']).rename(columns={'name': 'character_name', 'normalized_name': 'character_normalized_name', 'id_script': 'id_character'})\",\"Filtering relevant columns from df_script\\ndf_script = df_script[['episode_id', 'number', 'raw_text', 'character_id', 'location_id']].rename(\\n    columns={'number': 'id', 'raw_text': 'dialogue'}\\n)\\n\\n# Remame Episode id to not conflict with location_id\\ndf_script = df_script.rename(columns={'episode_id': 'episode'})\",\"Rename wrongly named character_id column\\ndf_episodes = df_episodes.rename(columns={'id': 'episode_id'})\",\"Rename 'id' to 'episode_id' and 'season' to 'episode_season' to enable easier linking between metadata\\ndf_episodes = df_episodes.rename(columns={'id': 'episode_id', 'season': 'episode_season'})\",\"Join episodes data to script data\\ndf_episodes = df_episodes.rename({'id':'episode_id'}, axis=1)\",\"# Merge scripts and episodes tables\\ndf_episodes.rename(columns={'id': 'episode_id'}, inplace=True)\\ndf_joined = df_script.merge(df_episodes, on='episode_id', how='left')\",\"Merge the script lines with character names and episode titles\\ndf = df_script.merge(df_characters[['id', 'name']], left_on='character_id', right_on='id').rename(columns={'name': 'character_name'})\\ndf = df.merge(df_episodes[['id', 'title']], left_on='episode_id', right_on='id').rename(columns={'title': 'episode_title'})\",\"Create character-episode mapping dataframe\\ndf_char_ep = df_script[['episode_id', 'character_id']].copy()\\ndf_char_ep.dropna(inplace=True)\\ndf_char_ep['character_id'] = df_char_ep['character_id'].astype(int)\\ndf_ep_char_map = (df_episodes[['id', 'title']]\\n                  .merge(df_char_ep, how='left', left_on='id', right_on='episode_id')\\n                  .drop(columns=['id'])\\n                  .rename(columns={'title': 'episode_title', 'episode_id': 'episode_id'})\\n                  .groupby('character_id')['episode_title']\\n                  .apply(list)\\n                  .reset_index(name='episode_titles'))\",\"Merge script lines with corresponding episodes and characters\\ndf_episodes = df_episodes.rename(columns={'id': 'episode_id'})\\n\\ndf_script = pd.merge(df_script, df_episodes, on='episode_id')\\ndf_script = pd.merge(df_script, df_characters, on='character_id')\",\"Merge episodes and script\\ndf_episodes = df_episodes.rename(columns={'id':'episode_id'})\\ndf = df_script.merge(df_episodes, on='episode_id')\",\"Rename the \\\"id\\\" columns to uniquely identify each table\\ndf_characters.rename(columns={'id':'character_id'}, inplace=True)\\ndf_locations.rename(columns={'id':'location_id'}, inplace=True)\\ndf_script.rename(columns={'id':'line_id'}, inplace=True)\\ndf_episodes.rename(columns={'id':'episode_id'}, inplace=True)\",\"Merge lines and episodes\\ndf_episodes.rename(columns={'id':'episode_id'}, inplace=True)\\ndf_script_lines_episodes = df_script.merge(df_episodes, on='episode_id')\",\"# identifiers should be slugs as per README\\ndf_characters.rename(columns= {'id': 'character_id'}, inplace=True)\\ndf_locations.rename(columns= {'id': 'location_id'}, inplace=True)\\ndf_episodes.rename(columns= {'id': 'episode_id'}, inplace=True)\",\"Filter out bad script lines\\ndf_script_good = df_script.loc[df_script['speaking_line'] == 'true']\\n# Remove bad characters\\ndf_script_good = df_script_good[df_script_good['normalized_text'] != \\\"\\\"]\\n# Remove non-primary characters\\ndf_script_good = df_script_good[df_script_good['raw_character_text'] != \\\"\\\"]\\n# Rename text column\\ndf_script_good = df_script_good.rename({'normalized_text': 'text'}, axis=1)\\n# add episode number and name to script lines\\ndf_script_good = pd.merge(df_script_good, df_episodes[['id', 'title', 'season', 'number']], left_on='episode_id', right_on='id')\",\"Merge script with episodes, characters and locations\\ndf_episodes = df_episodes.rename(columns={'id':'episode_id'})\\n\\ndf = df_script.merge(\\n    df_episodes[['episode_id', 'title', 'original_air_date']],\\n    on='episode_id',\\n    how='inner'\\n    )\"],\"marker\":{\"opacity\":0.5,\"size\":5},\"mode\":\"markers+text\",\"name\":\"125_Dataframe script filtering and merging\",\"text\":[\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\"],\"textfont\":{\"size\":12},\"x\":[2.7968409061431885,2.709890842437744,2.6740031242370605,2.6029844284057617,3.5442583560943604,2.3356218338012695,4.100426197052002,2.971254825592041,4.346131801605225,3.8206732273101807,3.2569098472595215,2.5614538192749023,3.5653395652770996,3.440988063812256,3.2591769695281982,2.892756938934326,2.0382466316223145,2.9053609371185303,2.2902023792266846,2.4660725593566895,2.6598002910614014,3.600020408630371,2.927276849746704,3.6857924461364746,3.1353611946105957,2.4396464824676514],\"y\":[6.929141044616699,6.505040645599365,6.440577030181885,6.612170219421387,7.688538074493408,6.861416339874268,7.411660194396973,7.394497871398926,6.101051330566406,6.8121232986450195,6.504754543304443,7.401603698730469,7.089146614074707,7.222687721252441,6.891625881195068,7.05506706237793,6.89152717590332,7.167520999908447,7.417190074920654,6.993344783782959,6.8988847732543945,7.852784156799316,7.318382263183594,7.874285697937012,7.679521083831787,6.8870649337768555],\"type\":\"scattergl\"},{\"hoverinfo\":\"text\",\"hovertext\":[\"Print the first 3 lines of df_characters\\ndf_characters.head(3)\",\" Display the first few lines of the characters dataframe\\ndf_characters.head()\",\"Display the first few lines of the characters dataframe\\ndf_characters.head()\",\"Print the first few lines of the characters dataframe\\nprint(df_characters.head())\",\" Display the first few lines of the characters DataFrame\\ndf_characters.head()\",\"Show the first three lines of the characters dataframe\\ndf_characters.head(3)\",\" Show first lines of characters dataframe\\ndf_characters.head()\",\" Show the first lines of the characters dataframe\\ndf_characters.head()\",\"# Display the first few lines of the characters dataframe\\ndf_characters.head()\",\"\\n# Show the first few lines of the characters DataFrame\\ndf_characters.head()\",\"Print the first few lines of the characters data frame\\nprint(df_characters.head())\",\"Display the first few lines of the dataframe with the character data\\ndf_characters.head()\",\" Display the first few lines of the characters dataframe\\ndf_characters.head()\",\"Show the first lines of the `df_characters` dataframe\\ndf_characters.head()\",\" View the first few lines of the characters dataframe\\ndf_characters.head()\",\" Display a few lines of the characters dataframe\\ndf_characters.head()\",\" Show the first lines of the characters dataframe\\ndf_characters.head()\",\"Display the first few lines of the dataframe\\ndf_characters.head()\",\"function to display character lines\\ndef display_lines(df, character_name, lines_to_display=10):\\n    display(df[df['raw_character_text'] == character_name].head(lines_to_display))\",\" Show the first lines of the characters dataframe\\nprint(df_characters.head())\",\"Show the first few lines of the characters dataframe\\ndf_characters.head()\",\"Show the first few lines of the characters dataframe\\ndf_characters.head()\",\"Show the first lines of the characters data\\ndf_characters.head()\",\"Display the first few lines of the characters dataframe\\ndf_characters.head()\",\"View the first few lines of the characters dataframe\\ndf_characters.head()\"],\"marker\":{\"opacity\":0.5,\"size\":5},\"mode\":\"markers+text\",\"name\":\"126_Displaying First Lines of Characters DataFrame\",\"text\":[\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\"],\"textfont\":{\"size\":12},\"x\":[3.3728435039520264,4.662578582763672,4.743408203125,4.932660102844238,4.8677897453308105,3.9039719104766846,4.986626148223877,4.8410964012146,5.029470443725586,4.480601787567139,4.977197647094727,4.953747749328613,4.794363498687744,4.726765155792236,5.401170253753662,4.420092582702637,4.868357181549072,4.690937519073486,5.383749485015869,5.323917388916016,4.974795818328857,5.025029182434082,4.759945392608643,4.755401134490967,5.503162384033203],\"y\":[15.707175254821777,18.616437911987305,18.659992218017578,18.481473922729492,18.572824478149414,15.833566665649414,18.144243240356445,18.2210693359375,18.271907806396484,18.222381591796875,18.489559173583984,18.076522827148438,18.391239166259766,18.216392517089844,18.178104400634766,17.956480026245117,17.81639289855957,18.77000617980957,16.683170318603516,17.89786720275879,18.31475830078125,18.39488410949707,17.718795776367188,18.659454345703125,18.531009674072266],\"type\":\"scattergl\"},{\"hoverinfo\":\"text\",\"hovertext\":[\"Check the content of the dataframes and the columns\\ndf_script.head()\",\"Optional: Use this line of code to check the content of a dataframe to get a look at the data organization\\n#df_script.head()\",\"Check the content of the df_script DataFrame\\ndf_script.head()\",\"Check the script dataframe\\ndf_script.head()\",\"# Check the general structure of the script dataframe\\ndf_script.head()\",\"Check a sample of data from each dataframe\\ndf_script.head()\",\"Check the content of one of the DataFrames\\ndf_script.head()\",\"Checking the script data\\nprint(\\\"We have\\\", len(df_script), \\\"script lines\\\")\\ndf_script.head()\",\"Check if dataframe have been sorted correctly\\ndf_script.head()\",\" Check the structure of one of the dataframes\\ndf_script.head()\",\"Check the data in one of the dataframes, e.g. df_script\\nprint(df_script.head())\",\" Check dataframes\\ndf_script.head()\",\"Check the dataframes\\ndf_script.head()\",\"check the structure of the scripts dataframe\\ndf_script.head()\",\"Check how the script dataframe looks like\\ndf_script.head()\",\"Check the script lines dataframe\\ndf_script.head()\",\" Check content of one of the dataframes\\ndf_script.head(10)\",\"Check the structure of script dataframe\\ndf_script.head()\",\" Check the script dataframe structure\\ndf_script.head()\",\"Verify the script dataframe\\ndf_script.head()\",\"Check loaded DataFrame\\ndf_script.head()\",\"Check the structure of the script dataframe\\ndf_script.head()\",\"Check the dataframes content\\nprint(df_script.head())\",\"# Check the content of script lines\\nprint(df_script.head())\",\"Check the content of the script lines DataFrame\\ndf_script.head()\"],\"marker\":{\"opacity\":0.5,\"size\":5},\"mode\":\"markers+text\",\"name\":\"127_Checking the content of dataframes and script lines\",\"text\":[\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\"],\"textfont\":{\"size\":12},\"x\":[7.228628158569336,6.786321640014648,6.748007774353027,6.786210536956787,6.283726692199707,7.446746349334717,7.364880561828613,5.919062614440918,6.416945457458496,6.505677223205566,7.056969165802002,7.094861030578613,7.041805267333984,6.440719127655029,6.038825511932373,6.628655433654785,6.898049354553223,6.220829963684082,6.443415641784668,6.863491058349609,6.598354816436768,6.271266460418701,6.999148845672607,6.3072829246521,6.633388996124268],\"y\":[-3.600691795349121,-4.079802989959717,-3.7331066131591797,-4.202878475189209,-5.034589767456055,-4.169976711273193,-3.9482390880584717,-3.5736236572265625,-3.917785406112671,-4.339724540710449,-3.512173891067505,-4.252784252166748,-4.196264743804932,-4.506126880645752,-4.3041157722473145,-4.176680088043213,-3.6678266525268555,-4.591907024383545,-4.527326583862305,-4.290981292724609,-3.9088616371154785,-4.50018835067749,-3.624927520751953,-3.45236873626709,-3.8873744010925293],\"type\":\"scattergl\"},{\"hoverinfo\":\"text\",\"hovertext\":[\"Inspect the first few rows of each dataframe to understand their structure and contents.\\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()\",\"Let's display the first few elements of the following DataFrames to understand what data we are working with:\\n# - df_characters\\n# - df_locations\\n# - df_script\\n# - df_episodes\",\"Let's look at the first few rows of each dataframe to understand the data better.\\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()\",\"Take a look at the first couple of lines in each of the dataframe to see what kind of data we'll be working with\\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()\",\"Inspect the first few lines of each dataframe to understand their structure\\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()\",\"Inspect the first few rows of each DataFrame to understand their structures and contents\\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()\",\"Examine the structure of the dataframes\\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()\",\"check the first few rows of each dataframe to understand their structure\\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()\",\"Check the contents of each dataframe to understand their structure\\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()\",\"Inspect the first few rows of each dataframe to understand their structure and contents\\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()\",\"Inspect the first few rows of each dataframe to understand its structure and content\\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()\",\"Just taking a look at the first few rows of each DataFrame to understand the data better\\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()\",\"Check the first few entries in each dataframe to understand their structure\\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()\",\"Look at the head of each dataset to understand their structure\\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()\",\"# Let's start by displaying the first rows of each dataframe to understand the structure of the data\\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()\",\"check the first 5 lines of the dataframes to understand their structure\\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()\",\"Inspect the first few lines of each dataframe to understand its structure and content\\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()\",\"# Let's print the head of each dataframe to better understand the structure of the data\\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()\",\" quick look to our datasets\\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()\",\"Inspect the first few rows of each dataframe to understand its structure\\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()\",\"Look at the first 5 lines of the first 3 DataFrames to understand their structure\\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()\",\"\\n# Let's start by taking a look at the structure of our dataframes\\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()\",\" Take a look at the dataframes to understand their structure and content\\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()\",\"# Now let's take a look at the first few rows of each dataframe to understand their structure\\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()\",\"Inspect the first few rows of each dataframe to understand its structure\\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()\"],\"marker\":{\"opacity\":0.5,\"size\":5},\"mode\":\"markers+text\",\"name\":\"128_Examining DataFrame Structures and Contents\",\"text\":[\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\"],\"textfont\":{\"size\":12},\"x\":[-4.693421840667725,-4.80125093460083,-4.837740898132324,-4.542218208312988,-5.025663375854492,-4.929191589355469,-4.186244964599609,-4.90725040435791,-4.9452805519104,-4.817490100860596,-4.668123722076416,-4.750157833099365,-4.9559807777404785,-3.6547300815582275,-5.017954349517822,-5.347050666809082,-4.756539821624756,-4.405951976776123,-2.959012269973755,-5.177726745605469,-5.493203163146973,-4.20457649230957,-4.487898349761963,-5.107964992523193,-5.142871856689453],\"y\":[2.8593640327453613,3.2694969177246094,2.5142598152160645,2.084609031677246,2.518136501312256,2.715009927749634,2.0258076190948486,2.3454270362854004,2.1290295124053955,2.9342494010925293,2.7990264892578125,2.310232639312744,2.3186285495758057,2.4880640506744385,3.0129852294921875,2.4408488273620605,2.997812509536743,2.8332409858703613,2.42928409576416,2.6977288722991943,2.5341732501983643,1.9970965385437012,2.4117588996887207,2.593017339706421,2.6107897758483887],\"type\":\"scattergl\"},{\"hoverinfo\":\"text\",\"hovertext\":[\" Merge script and episode data\\ndf_script_episode = df_script.merge(df_episodes, how='left', on='episode_id')\",\"Merge script and episodes\\ndf_script_episodes = pd.merge(df_script, df_episodes, how = 'left', on = ['episode_id'])\",\"Preprocess data\\n# Simpsons script data\\n# 1. Merge script and episodes data\\ndf_script_episodes = pd.merge(df_script, df_episodes, how='left', on='episode_id')\",\"Merge the tables\\ndf = df_script.merge(df_episodes, how='left', on='episode_id')\",\" create new (and final) dataframe by merging 'df_episodes' and 'df_script' dataframes using a left join merging on 'episode_id' column\\ndf_final = pd.merge(df_episodes, df_script, on='episode_id', how='left')\",\"merge episodes\\ndf_script_ep = pd.merge(df_script, \\n                        df_episodes, \\n                        on='episode_id', \\n                        how='left')\",\"Merge episodes and scripts\\ndf = pd.merge(df_script, df_episodes, on=\\\"episode_id\\\", how=\\\"left\\\")\",\" Merge 'df_script' with 'df_episodes'\\ndf_merged = df_script.merge(df_episodes, on='episode_id', how='left')\",\"Merge script lines with episode data\\ndf_script_full = df_script.merge(df_episodes,\\n                                 on='episode_id',\\n                                 how='left')\",\"# Join tables script and episodes\\ndf_script_episodes = df_script.merge(df_episodes, on='episode_id', how='left')\\ndf_script_episodes.head()\",\"Merge episode information into main script dataframe\\ndf_script = df_script.merge(df_episodes, on='episode_id', how='left')\",\"Merge datasets\\ndf = df_script.merge(df_episodes, on='episode_id', how='left')\",\"Merge episodes and scripts\\ndf = df_episodes.merge(df_script, on='episode_id', how='left')\",\"Merge script lines with episode data\\ndf = df_script.merge(df_episodes, on='episode_id', how='left')\\n\\n# Split data into training and validation sets\\nnp.random.seed(0)\\ndf_train = df.sample(frac=0.8, random_state=0)\\ndf_val = df.drop(df_train.index)\\n\\n# Ensure we have a good mix of classes\\nprint(df_train['raw_character_text'].value_counts(normalize=True))\",\" Merge data together\\ndf_merged = df_script.merge(df_episodes, how='left', on='episode_id')\",\" Merge episodes with scripts\\ndf_episodes['id'] = df_episodes.id.astype(float)\\ndf_script['episode_id'] = df_script.episode_id.astype(float)\\n\\ndf_merged = pd.merge(df_script,\\n                     df_episodes,\\n                     how='left',\\n                     left_on='episode_id',\\n                     right_on='id')\",\"Join dataset to have episodes info in script dataset\\ndf_script = df_script.merge(df_episodes, on='episode_id', how='left')\",\" Merge script lines and episodes\\ndf_script_episodes = df_script.merge(df_episodes, on='episode_id', how='left')\",\"Merge script lines with episodes\\ndf_script = pd.merge(df_script, df_episodes,\\n                     on='episode_id',\\n                     how='left')\",\"Merge episode data into script\\ndf_script = df_script.merge(df_episodes, on='episode_id', how='left')\",\" Merge the episode details into the main script lines dataframe\\ndf_script = df_script.merge(df_episodes, on='episode_id', how='left')\",\"Join episode and script data\\ndf = df_script.merge(df_episodes, on='episode_id', how='left')\",\"Merge lines and episodes\\ndf_merged = df_script.merge(df_episodes, how='left', on='episode_id')\",\" Merge df_script with df_episodes to add more context to the lines of dialogue\\ndf = pd.merge(df_script, df_episodes, on='episode_id', how='left')\",\"Merge df_script and df_episodes on episode_id, using a left join\\ndf_merged = df_script.merge(df_episodes, on='episode_id', how='left')\"],\"marker\":{\"opacity\":0.5,\"size\":5},\"mode\":\"markers+text\",\"name\":\"129_Merging episode and script data\",\"text\":[\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\"],\"textfont\":{\"size\":12},\"x\":[0.4638417959213257,0.9063484072685242,1.4790353775024414,0.9597618579864502,0.6437272429466248,0.7107852697372437,0.7918097972869873,0.4460260570049286,0.8284249305725098,0.461753249168396,0.09792892634868622,0.5774238109588623,0.6757708787918091,1.284374475479126,0.4225122034549713,0.9710209369659424,0.20610320568084717,0.8884138464927673,0.9835450649261475,0.5424767136573792,0.49462199211120605,0.7401543259620667,0.8424035906791687,1.7075400352478027,0.6186347007751465],\"y\":[6.688244819641113,6.81558895111084,6.81016731262207,6.594943523406982,6.223280429840088,6.561631202697754,6.598525524139404,6.760115623474121,6.7968573570251465,6.449312210083008,6.670931339263916,6.848578929901123,6.542118072509766,6.902904510498047,6.406463146209717,6.3847198486328125,6.4656572341918945,6.9289679527282715,6.7995734214782715,6.746291637420654,6.9155592918396,6.250787258148193,6.503448486328125,6.860167980194092,6.259646415710449],\"type\":\"scattergl\"},{\"hoverinfo\":\"text\",\"hovertext\":[\"Check the loaded data\",\"Just checking if the data loaded properly\",\"print('Data loaded successfully!')\",\" Check if the data is correctly loaded\",\"Setting and checking if the data is loaded correctly\",\" Check the data to ensure everything is loaded correctly\",\"Checking if the data has been loaded properly\",\"Check all of the databases have been correctly loaded\",\"Checking loading of data done correctly\",\"check the data files and whether they all have been loaded successfully\",\"Checking if the data is loaded correctly\",\"Let's make sure it's loaded correctly\",\" Check the data to examine if it has been loaded correctly.\",\"Check if the data was properly loaded\",\"Checkpoint: All data is loaded and looks fine\",\" Check whether the data has been read successfully\",\"Checking the data to see if it has been loaded correctly\",\"Check the loaded data\",\"Run some code to verify everything is loaded as expected\",\"Check the recent data before starting the work.\",\"Check if the code execution meets the objective\",\"Load it as read access to avoid writing permissions\",\"Check data you just loaded\",\" Check that the data was loaded correctly\",\" Verify data loading\"],\"marker\":{\"opacity\":0.5,\"size\":5},\"mode\":\"markers+text\",\"name\":\"130_Checking data loading success\",\"text\":[\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\"],\"textfont\":{\"size\":12},\"x\":[14.81464958190918,15.094761848449707,15.360278129577637,15.260427474975586,15.304988861083984,15.148916244506836,14.833666801452637,14.78794002532959,14.994352340698242,15.008035659790039,14.810356140136719,15.345308303833008,14.726801872253418,15.365111351013184,14.381695747375488,14.336088180541992,14.558980941772461,15.128889083862305,14.228198051452637,15.477396011352539,13.282888412475586,14.514168739318848,15.499650955200195,15.114394187927246,15.235625267028809],\"y\":[1.0260357856750488,1.1496163606643677,1.3639228343963623,1.4681527614593506,1.2495150566101074,1.360141634941101,1.3531149625778198,1.0133583545684814,0.9835673570632935,1.2195202112197876,1.6452504396438599,1.7343088388442993,1.4966020584106445,1.3038203716278076,0.39130932092666626,1.4662086963653564,1.4318313598632812,1.2483911514282227,1.7988489866256714,0.8123717308044434,1.650225043296814,1.6235419511795044,1.0151190757751465,1.1993873119354248,1.0004448890686035],\"type\":\"scattergl\"},{\"hoverinfo\":\"text\",\"hovertext\":[\"Merge dataframes\",\"Merge the dataframes\",\"Merge dataframes\",\"Merge dataframes together\",\"Merge dataframes to simplify the analysis of the data\",\"Merge DataFrames\",\"Merge dataframes\",\"to-do: combine dataframes\",\"Merge dataframes\",\"Merge dataframes\",\"Merge data frames to simplify the code and remove duplicate ids\",\" Merge these dataframes into a single one\",\"Merge dataframes to improve data analysis capabilities.\",\"Merge DataFrames\",\"Merge data frames\",\"Creating a full df from merging the other dfs.\",\"Merge data frames\",\" Merge the dataframes\",\" Merge the dataframes\",\"Merge dataframes\",\"Merge dataframes for easy data manipulation\",\"Merge dataframes\",\"Merge the relevant dataframes\",\" Function to merge and filter the DataFrames\",\"Merge necessary dataframes and columns\"],\"marker\":{\"opacity\":0.5,\"size\":5},\"mode\":\"markers+text\",\"name\":\"131_Merge DataFrames\",\"text\":[\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\"],\"textfont\":{\"size\":12},\"x\":[4.643605709075928,5.265430450439453,4.652855396270752,4.883501052856445,5.611950874328613,4.7349467277526855,4.486887454986572,5.106680393218994,4.568136692047119,4.8088202476501465,5.183515548706055,5.681605815887451,5.305211544036865,4.587846755981445,4.847280025482178,5.538570880889893,4.755825519561768,5.292321681976318,5.2253289222717285,4.793635845184326,4.837456703186035,4.642491817474365,6.172657012939453,4.364240646362305,5.023201942443848],\"y\":[-0.9334073066711426,-0.9637270569801331,-0.8964526653289795,-0.628010094165802,-0.7732753753662109,-0.7741983532905579,-0.8477637767791748,-0.6543827056884766,-0.8622108101844788,-0.8246363997459412,-0.38209739327430725,-1.0487829446792603,-0.8513745069503784,-0.6962922215461731,-0.8947795033454895,-1.0502742528915405,-0.8549826145172119,-1.1008013486862183,-1.0377507209777832,-0.7787824273109436,-0.7312837243080139,-0.9482619166374207,-0.8172478079795837,-0.9991927146911621,-0.4589427709579468],\"type\":\"scattergl\"},{\"hoverinfo\":\"text\",\"hovertext\":[\"Now we will display the first 5 rows of the characters dataframe.\",\"Show the first 5 rows of the characters dataframe\",\"Displays the first 5 records in the characters dataframe.\",\"\\n# Display each of the 5 datasets\\nprint('Characters:')\",\"We  will now display the first 5 rows of the characters dataframe.\",\" Show the first 5 rows of the characters dataframe\",\"Display the 5 first rows of the dataframe containing the characters\",\"Display the first 5 rows of the dataframe containing the characters.\",\"Inspect the first 5 rows of the characters dataframe\",\"Inspect first 5 rows of the characters dataframe\",\"Inspect the first 5 records of the characters dataframe\",\"Inspecting the first 5 rows of the characters DataFrame\",\"View the first 5 rows of the characters dataframe.\",\"Visually show the first 5 rows of the characters dataframe.\",\" Display first 5 lines of characters dataset\",\"Insepct the first 5 records of the character dataframe\",\"View the first 5 characters DataFrame rows.\",\"View first 5 records of characters dataframe\",\"Get the first five rows of the characters dataframe.\",\"Inspect first 5 rows of the characters dataframe\",\"Let's view the first 5 rows of the characters DataFrame.\",\"Displaying the first five rows of the characters dataframe\",\"Display the first 5 rows of the dataframe containing the characters.\",\"View the first 5 rows of the characters dataframe\",\" Show first 5 rows of the characters DataFrame.\"],\"marker\":{\"opacity\":0.5,\"size\":5},\"mode\":\"markers+text\",\"name\":\"132_Inspecting DataFrame Rows\",\"text\":[\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\"],\"textfont\":{\"size\":12},\"x\":[11.100550651550293,11.892704010009766,11.418839454650879,10.246140480041504,11.327408790588379,11.855826377868652,12.279489517211914,11.731614112854004,11.404314041137695,11.699921607971191,11.324785232543945,11.319766998291016,11.612056732177734,11.313278198242188,10.773189544677734,11.3078031539917,11.441530227661133,11.633155822753906,11.574689865112305,11.736200332641602,10.823905944824219,11.563177108764648,11.765948295593262,11.795243263244629,11.64050579071045],\"y\":[11.609676361083984,11.568779945373535,11.48983383178711,10.455327033996582,11.517274856567383,11.721722602844238,11.800646781921387,11.699145317077637,12.345884323120117,12.527995109558105,12.472213745117188,12.92929458618164,11.845868110656738,11.102901458740234,10.064428329467773,12.784875869750977,11.67297649383545,11.854378700256348,12.161402702331543,12.560771942138672,11.706421852111816,11.214630126953125,11.66673469543457,11.541056632995605,11.385855674743652],\"type\":\"scattergl\"},{\"hoverinfo\":\"text\",\"hovertext\":[\" To verify the data has been imported correctly, let's take a look at each DataFrame using the .head() method.\",\"function: load_dataframes_cache: Load and cache dataframe functions\\ndef load_dataframes_cache(f):\\n    def wrapper(*args, **kw):\\n        if os.path.exists(f.__name__):\\n            print(f'Load {f.__name__} from cache')\\n            return pd.read_pickle(f.__name__)\\n        else:\\n            df = f(*args, **kw)\\n            print(f'Save {f.__name__} to cache')\\n            df.to_pickle(f.__name__)\\n            return df\\n    return wrapper\",\"Check if the dataframes are loaded correctly\",\"Check the loaded dataframes\",\"Inspect the content of the loaded DataFrames\",\"Check the loaded dataframes\",\"Check the types of the loaded dataframes\",\"Checking the dataframe, that it loads with the top of it\",\"Checking the imported dataframes\",\"Evaluating the dimensions of the imported dataframes to ensure data has been loaded successfully.\",\"Check the size of the imported DataFrames\",\"Check if dataframes were correctly loaded\",\"Check the dataframes are correctly loaded\",\"Checking if the dataframes are loaded correctly\",\"# Run this cell to verify if pandas module is imported or not within the current environment\\n\\\"pandas\\\" in locals()\",\"Check the loaded dataframes\",\"Check dimensions\",\"Check the imported dataframes\",\" Checking dataframes dimensions\",\"Notification that the dataframes have been loaded\",\"A fresh copy of the DataFrame is saved on-disk every time we preprocess the data, so we can load from that in future runs instead of having to re-run the code above.\",\"CHECKPOINT: all dataframes are loaded\",\"Check if main dataframe loads correctly\",\"Check if the dataframes have been properly loaded\"],\"marker\":{\"opacity\":0.5,\"size\":5},\"mode\":\"markers+text\",\"name\":\"133_DataFrame Loading and Caching\",\"text\":[\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\"],\"textfont\":{\"size\":12},\"x\":[10.529433250427246,10.422648429870605,11.235673904418945,11.515605926513672,11.62653636932373,11.546151161193848,11.063419342041016,11.334214210510254,10.920963287353516,10.684497833251953,10.448598861694336,11.506646156311035,11.364829063415527,11.36999225616455,11.391538619995117,11.433772087097168,9.373636245727539,10.896387100219727,9.572644233703613,11.620675086975098,9.365551948547363,11.885371208190918,11.47974681854248,11.43968391418457],\"y\":[-3.448674201965332,-2.46734619140625,-2.4516654014587402,-2.600738525390625,-3.4073233604431152,-2.712951898574829,-2.4162821769714355,-3.080605983734131,-3.321889877319336,-3.0407516956329346,-3.635502338409424,-2.6348061561584473,-2.4452061653137207,-2.650632381439209,-3.267554521560669,-2.6623826026916504,-3.8768320083618164,-3.252962589263916,-4.198194980621338,-2.824026584625244,-2.294495105743408,-1.9907348155975342,-2.56817626953125,-2.742392063140869],\"type\":\"scattergl\"},{\"hoverinfo\":\"text\",\"hovertext\":[\" Check first 5 rows of the characters dataset\\ndf_characters.head()\",\" Check the first five rows of the characters dataframe\\ndf_characters.head()\",\"check the first 5 rows of one of the dataframes\\ndf_characters.head()\",\"Check the first 5 rows of the characters DataFrame\\ndf_characters.head()\",\"Check the first five rows of the characters DataFrame\\ndf_characters.head()\",\"Checking the first 5 rows of 'df_characters' dataframe\\ndf_characters.head()\",\"Check the first 5 rows of the characters dataframe\\ndf_characters.head()\",\"Check the first 5 rows of the characters dataframe\\ndf_characters.head()\",\"Check the first 5 records of the characters dataframe\\ndf_characters.head()\",\"Checking the first 5 rows of the characters dataframe\\ndf_characters.head()\",\"Check the first 5 rows of the characters dataframe\\ndf_characters.head()\",\"Check the first five rows of the characters dataframe\\ndf_characters.head()\",\"# Checking the first 5 rows of the characters dataframe\\ndf_characters.head()\",\"Check the first 5 rows of the characters DataFrame\\ndf_characters.head()\",\"Check the first 5 rows of the characters dataframe\\ndf_characters.head()\",\"Check the first 5 rows of the characters dataframe.\\ndf_characters.head()\",\"Check the first 5 rows of df_characters DataFrame\\ndf_characters.head()\",\"Checking the first 5 rows of the characters dataframe.\\ndf_characters.head(5)\",\"Check the content of the first 5 rows\\nprint(df_characters.head())\",\"Checking the first 5 rows of the characters dataframe\\ndf_characters.head()\",\"Check first 5 rows of the Characters dataframe\\ndf_characters.head()\",\"Check the first 5 rows of the characters DataFrame\\ndf_characters.head()\",\"Check the first five rows of the characters dataframe\\ndf_characters.head()\",\" Check the first five rows of the characters DataFrame\\ndf_characters.head()\"],\"marker\":{\"opacity\":0.5,\"size\":5},\"mode\":\"markers+text\",\"name\":\"134_Checking first five rows of characters DataFrame\",\"text\":[\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\"],\"textfont\":{\"size\":12},\"x\":[-3.1834664344787598,-3.745138168334961,-3.108116626739502,-3.5831875801086426,-3.3326237201690674,-2.998074769973755,-3.514110803604126,-3.4979264736175537,-3.9759740829467773,-2.9773964881896973,-3.625002384185791,-3.8054308891296387,-3.4879937171936035,-3.5488338470458984,-3.4394032955169678,-3.285032033920288,-3.2957239151000977,-2.971536636352539,-3.3307223320007324,-3.201354503631592,-3.4288828372955322,-3.695300579071045,-3.4068453311920166,-3.8467469215393066],\"y\":[16.497554779052734,16.379961013793945,16.494901657104492,16.662633895874023,16.396839141845703,16.42283058166504,16.890066146850586,16.598665237426758,16.817447662353516,16.15978240966797,16.742740631103516,16.837228775024414,16.86941146850586,16.713960647583008,16.746334075927734,16.66363525390625,16.572782516479492,16.3997745513916,16.589139938354492,16.345930099487305,16.574003219604492,16.68754768371582,16.45623779296875,16.2686767578125],\"type\":\"scattergl\"},{\"hoverinfo\":\"text\",\"hovertext\":[\"Check the dataframes\\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()\",\"# Print heads to verify\\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()\",\"check the resulting DataFrames\\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()\",\"Check the head of each dataframe\\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()\",\"Check loaded data\\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()\",\"Check contents of each dataframe\\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()\",\"Check data load success\\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()\",\"Check the head of each dataset\\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()\",\"Check if all the data is present\\ndf_episodes.head(), df_characters.head(), df_locations.head(), df_script.head()\",\"Check the structure of characters, locations, scripts and episodes datasets\\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()\",\" Check Data\\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()\",\"Check the dataframes contents\\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()\",\"Check dataframes head\\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()\",\"Check head of dataframes\\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()\",\"Check the dataframes\\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()\",\"Checking the loaded datasets\\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()\",\"Check the contents of these dataframes\\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()\",\"Check the dataframes\\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()\",\"Check a few initial lines of each dataframe\\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()\",\"Check the dataframes\\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()\",\"Check content of these tables\\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()\",\"Check the head of the 4 dataframes\\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()\",\"Check the original dataframes\\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()\",\" Check the resulting DataFrames\\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()\"],\"marker\":{\"opacity\":0.5,\"size\":5},\"mode\":\"markers+text\",\"name\":\"135_Checking Loaded Dataframes and Contents\",\"text\":[\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\"],\"textfont\":{\"size\":12},\"x\":[-4.054387092590332,-3.2323551177978516,-4.331573486328125,-3.9949116706848145,-3.585763454437256,-4.018771171569824,-3.9821560382843018,-3.428889751434326,-3.215033769607544,-3.023785352706909,-3.617741107940674,-3.9730703830718994,-4.205862998962402,-4.438479900360107,-4.019550323486328,-3.5126969814300537,-3.9637486934661865,-4.041010856628418,-3.6688573360443115,-4.035815238952637,-3.4020137786865234,-4.568245887756348,-4.550241470336914,-4.169509410858154],\"y\":[0.6022949814796448,1.2582814693450928,0.9521486759185791,1.1198452711105347,0.17965413630008698,1.2120047807693481,0.2610040009021759,1.2416149377822876,0.48379215598106384,0.9098802208900452,0.8005971908569336,0.7621608376502991,0.9809558391571045,0.4288319945335388,0.4009476602077484,0.4673061966896057,0.9233754873275757,0.5580773949623108,1.4173479080200195,0.5665238499641418,1.3740249872207642,0.8285477757453918,0.6836704015731812,0.8031752705574036],\"type\":\"scattergl\"},{\"hoverinfo\":\"text\",\"hovertext\":[\"Let's take a look at the data first.\",\"let's take a first look at the data.\",\" Let's start by looking at the data.\",\" Let's take a look at the data first.\",\"Let's take a look at the data first.\",\"Let's take a first look at the data.\",\"We will first briefly look at the data.\",\"Let's take a look at the data first.\",\"Time to start by looking at the data.\",\"Let's take a look at the data first.\",\"Let's first check out the data to see what we're working with.\",\"Let's take a first look at the data.\",\" Let's take a first look at the data.\",\"Let's start by taking a look at the data we have available.\",\"Let's take a look at the data first.\",\"We first take a look at the available data.\",\"Let's take a look at the data first:\",\"Let's first take a look at the data.\",\"Let's first take a look at the data.\",\"Let's first have a look at the data.\",\"Let's inspect the data first.\",\"Let's start by taking a look at the data.\",\"Check the data format and potential issues in the data.\",\" We should begin with a quick about the data.\"],\"marker\":{\"opacity\":0.5,\"size\":5},\"mode\":\"markers+text\",\"name\":\"136_Taking a Quick Look at Available Data\",\"text\":[\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\"],\"textfont\":{\"size\":12},\"x\":[18.174333572387695,18.285171508789062,17.80579948425293,18.42475128173828,18.336326599121094,18.341747283935547,17.79219627380371,18.383827209472656,17.99864959716797,18.169418334960938,18.42029571533203,18.37105941772461,18.63021469116211,18.214139938354492,18.301889419555664,18.350244522094727,18.002887725830078,18.331645965576172,18.330293655395508,17.994556427001953,17.312952041625977,17.681047439575195,17.039087295532227,17.53730583190918],\"y\":[-1.9775704145431519,-1.8804922103881836,-1.5802536010742188,-2.1054749488830566,-2.1893694400787354,-2.0486505031585693,-1.3229079246520996,-2.098900556564331,-1.6781328916549683,-1.9550559520721436,-1.4272712469100952,-2.018474817276001,-2.1190547943115234,-1.1538878679275513,-2.038390636444092,-1.3082236051559448,-2.024062156677246,-1.863743543624878,-1.8049061298370361,-1.5842453241348267,-1.1407935619354248,-1.355485200881958,-1.173092007637024,-1.111267328262329],\"type\":\"scattergl\"},{\"hoverinfo\":\"text\",\"hovertext\":[\"Inspecting the content of the csv files\",\" Display a preview of the data loaded from the csv files\",\"Process CSV files\",\"Notice that 'data' is a directory containing the necessary CSV files.\",\" Check against csv files\",\"View data fetched from CSVs\",\"Load the data from the CSV files\",\"Checking data after loading from csv files.\",\"Check what we are loading from the script csv file\",\"Characters and Locations CSVs are already preprocessed. Let's display some examples to understand the data better.\",\"Remove the .csv from the name of the file so that now we only have the table name.\",\"Checking if all the csv files were read correctly\",\" check the content of the CSVs\",\"The top-level directory containing the CSV files is called \\\"data\\\". If you are using a different directory, please replace \\\"data\\\" with the appropriate directory name.\",\"Create a MongoDB database and import the data from CSV files\",\"I misunderstood the purpose of this script. The goal is to interact with the CSV files and create visualizations, so I will remove the unnecessary imports and invalid code.\",\"This will raise an error because the CSV files are not available, so let's remove it.\",\"Now let's take a look at the content of each CSV file.\",\"Set the script data type to string, to ensure it's correctly read from the CSV\",\"Make sure that the csv files are in a folder named data\",\"Let's just go ahead and display the headers for each CSV file to understand their structure and data types.\",\"Where are the .csv files stored?\",\"Display all the imported csv files\",\" Set this locally\\ncsv_exist_local = False\"],\"marker\":{\"opacity\":0.5,\"size\":5},\"mode\":\"markers+text\",\"name\":\"137_CSV file inspection and loading\",\"text\":[\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\"],\"textfont\":{\"size\":12},\"x\":[12.779403686523438,12.531380653381348,12.127059936523438,12.038446426391602,12.909465789794922,12.614483833312988,12.245766639709473,12.854531288146973,12.379684448242188,11.891037940979004,11.122182846069336,12.651912689208984,12.571825981140137,11.880341529846191,12.381355285644531,12.131123542785645,11.66995906829834,12.168335914611816,11.798994064331055,11.798944473266602,12.430543899536133,12.209089279174805,12.470467567443848,11.372767448425293],\"y\":[0.2263508290052414,0.039301589131355286,0.4734697639942169,1.0022954940795898,0.7972633838653564,-0.1112280935049057,0.29148343205451965,0.8048301935195923,1.0621484518051147,0.7963618040084839,0.9499576091766357,0.6516370177268982,0.43695083260536194,0.6727781891822815,0.4572416841983795,0.6149821281433105,0.9872930645942688,0.09761424362659454,1.7214903831481934,0.7237508296966553,-0.17460285127162933,0.08363638073205948,0.1123371571302414,1.1413729190826416],\"type\":\"scattergl\"},{\"hoverinfo\":\"text\",\"hovertext\":[\"Set seed for reproducibility\\nnp.random.seed(0)\",\" Set seed for reproducibility\\nnp.random.seed(0)\",\" Set seed for reproducibility\\nnp.random.seed(0)\",\" Set seed for reproducibility\\nnp.random.seed(0)\",\"Set seed for reproducibility\\nnp.random.seed(0)\",\" Set seed for reproducibility\\nnp.random.seed(0)\",\"Set seed for reproducibility\\nnp.random.seed(0)\",\" Setting the seed for reproducibility\\nnp.random.seed(0)\",\"Set seed for reproducibility\\nnp.random.seed(0)\",\"Set seed for reproducibility\\nnp.random.seed(0)\",\"Set seed for reproducibility\\nnp.random.seed(0)\",\"Set seed for reproducibility\\nnp.random.seed(0)\",\"Set seed for reproducibility\\nnp.random.seed(0)\",\"Set seed for reproducibility\\nnp.random.seed(0)\",\"Set seed for reproducibility\\nnp.random.seed(0)\",\"Set seed for reproducibility of the results\\nnp.random.seed(0)\",\" Set seed for reproducibility\\nnp.random.seed(10)\",\"Set seed for reproducibility\\nnp.random.seed(0)\",\" set seed for reproducibility\\nnp.random.seed(0)\",\"Set seed for reproducibility\\nnp.random.seed(0)\",\"Set seed for reproducibility\\nnp.random.seed(0)\",\" Set seed for reproducibility\\nnp.random.seed(0)\",\"Set seed for reproducibility\\nnp.random.seed(0)\",\"Set seed for reproducibility\\nnp.random.seed(0)\"],\"marker\":{\"opacity\":0.5,\"size\":5},\"mode\":\"markers+text\",\"name\":\"138_Set seed for reproducibility\",\"text\":[\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\"],\"textfont\":{\"size\":12},\"x\":[28.2721004486084,28.7279109954834,28.406269073486328,28.235944747924805,28.600160598754883,28.767892837524414,28.731733322143555,30.049850463867188,28.906780242919922,28.63652801513672,28.761241912841797,28.33858871459961,28.410320281982422,28.568769454956055,28.24629020690918,29.114084243774414,29.163978576660156,28.65705680847168,28.42076301574707,28.644147872924805,28.451488494873047,28.47608184814453,28.931184768676758,28.491310119628906],\"y\":[15.485279083251953,15.22203540802002,15.547811508178711,15.481668472290039,15.113791465759277,15.625452041625977,15.460299491882324,6.599971771240234,15.663237571716309,15.283769607543945,15.506590843200684,15.397055625915527,15.334004402160645,15.5084228515625,15.347254753112793,14.892563819885254,15.094770431518555,15.470074653625488,15.20506477355957,15.570164680480957,15.593697547912598,15.21005630493164,15.313395500183105,15.33174991607666],\"type\":\"scattergl\"},{\"hoverinfo\":\"text\",\"hovertext\":[\"Exploring data\",\"Exploring the data.\",\"Data ingestion is complete, moving on to data exploration and analysis.\",\"Create smaller subsets for exploration and model building\",\"Some basic data exploration\",\"Initial data exploration\",\"Data visualization and exploration\",\"Data exploration\",\" Data exploration\",\"Limiting and exploring the data\",\"Data exploration and analysis\",\"Data Insights and Statistics\",\"Exploring the data\",\"Exploration and data visualization\",\"Data Exploration\",\"## 2. Data exploration\",\"Conducting data exploration and analysis\",\"Data Exploration\",\"Data investigation\",\"Data Exploration\",\"Explore data available.\",\"Data Analysis\",\"Data exploration\",\"Data exploration\"],\"marker\":{\"opacity\":0.5,\"size\":5},\"mode\":\"markers+text\",\"name\":\"139_Data Exploration\",\"text\":[\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\"],\"textfont\":{\"size\":12},\"x\":[16.45584487915039,16.345687866210938,17.08681297302246,16.566516876220703,16.53919219970703,16.776782989501953,16.965763092041016,16.608800888061523,16.78994369506836,16.969938278198242,16.991968154907227,16.23509979248047,16.322343826293945,17.078224182128906,16.718637466430664,15.453298568725586,17.114837646484375,16.781583786010742,15.621644020080566,16.72022247314453,16.69939613342285,16.136037826538086,16.570995330810547,16.750898361206055],\"y\":[0.5798994898796082,0.4274490475654602,0.8812509179115295,0.4976399540901184,0.605413556098938,0.40514248609542847,1.2251348495483398,0.9834534525871277,0.9813635945320129,0.40750351548194885,1.2026654481887817,0.26951223611831665,0.3630843460559845,1.1802462339401245,1.047790765762329,1.104931116104126,1.1775327920913696,1.0378023386001587,0.5580305457115173,0.8660833835601807,0.43601733446121216,0.9966181516647339,0.9076805710792542,1.055632472038269],\"type\":\"scattergl\"},{\"hoverinfo\":\"text\",\"hovertext\":[\"Now, let's take a look at the first few rows of each dataframe.\",\"Let's take a look at the first 5 rows of these dataframes.\",\" Let's take a quick look at the first few rows of each dataframe.\",\"Let's check the first couple of rows of each data frame.\",\"Let's check the first rows of each dataframe.\",\"Let's take a look at the first few rows of each data frame.\",\"Let's take a look at the first few rows of each dataframe\",\" Let's take a look at the first few rows of each dataframe.\",\"Let's look at the first few rows of each imported dataframes\",\" Let's look at the first few records of each dataframe.\",\" Let's take a look at the first few rows of each dataframe.\",\" Let's preview the first few entries of each dataframe to understand the data better.\",\"Let's take a look at the first few rows of each dataframe.\",\" Let's take a look at the first few rows of each dataframe:\",\"Let's see the first few entries in each of these dataframes.\",\"Let's take a look at the first few rows of each dataframe.\",\"Let's take a look at the first few rows of each dataframe.\",\"We'll use strict lists for the values instead of DataFrames for quick retrieval times.\",\"Now let's take a look at the first few rows of each of these DataFrames.\",\"Let's take a look at the first few rows of each of these DataFrames.\",\"Let's take a look at the first few rows of each DataFrame.\",\"Let's take a look at the first 5 rows of each of these DataFrames.\",\"Let's take a peek at the first few entries in each dataframe.\"],\"marker\":{\"opacity\":0.5,\"size\":5},\"mode\":\"markers+text\",\"name\":\"140_DataFrames - Quick preview of imported records\",\"text\":[\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\"],\"textfont\":{\"size\":12},\"x\":[10.744146347045898,11.267884254455566,10.82295036315918,10.982661247253418,11.339229583740234,10.402342796325684,11.055011749267578,10.837363243103027,11.329635620117188,10.631114959716797,11.09158706665039,10.671825408935547,10.584084510803223,10.836368560791016,10.34668254852295,10.792407989501953,10.801600456237793,10.043593406677246,10.801986694335938,10.269776344299316,10.805042266845703,11.487988471984863,10.697412490844727],\"y\":[-7.4696197509765625,-7.219715118408203,-7.1963629722595215,-7.290215969085693,-6.701440811157227,-7.188508033752441,-7.630742073059082,-7.578613758087158,-7.756576061248779,-7.348124980926514,-7.893383979797363,-7.667957782745361,-7.508994102478027,-7.898781776428223,-6.949785232543945,-7.680249214172363,-7.6877007484436035,-6.847700595855713,-7.29056453704834,-7.199352741241455,-7.6643242835998535,-7.273447513580322,-6.715263366699219],\"type\":\"scattergl\"},{\"hoverinfo\":\"text\",\"hovertext\":[\"Checking for missing values in the datasets\\nprint(df_characters.isnull().sum())\\nprint(df_locations.isnull().sum())\\nprint(df_script.isnull().sum())\\nprint(df_episodes.isnull().sum())\",\" Check if null values exist in the datasets\\nprint(\\\"The number of null values in df_characters is:\\\", df_characters.isnull().sum().sum())\\nprint(\\\"The number of null values in df_locations is:\\\", df_locations.isnull().sum().sum())\\nprint(\\\"The number of null values in df_script is:\\\", df_script.isnull().sum().sum())\\nprint(\\\"The number of null values in df_episodes is:\\\", df_episodes.isnull().sum().sum())\",\"Calculating number of missing values in each DataFrame\\nnull_characters = df_characters.isnull().sum().sum()\\nnull_locations = df_locations.isnull().sum().sum()\\nnull_episodes = df_episodes.isnull().sum().sum()\\nnull_script = df_script.isnull().sum().sum()\",\"Check the number of null values in each dataframe\\nprint(df_characters.isnull().sum())\\nprint(df_locations.isnull().sum())\\nprint(df_script.isnull().sum())\\nprint(df_episodes.isnull().sum())\",\"Check missing data\\nprint(df_characters.isna().sum())\\nprint(df_locations.isna().sum())\\nprint(df_script.isna().sum())\\nprint(df_episodes.isna().sum())\",\"Check for nulls\\nprint(df_characters.isnull().sum(), '\\\\n')\\nprint(df_locations.isnull().sum(), '\\\\n')\\nprint(df_script.isnull().sum(), '\\\\n')\\nprint(df_episodes.isnull().sum(), '\\\\n')\",\"Check for missing values in the datasets\\nprint('Missing values for characters:')\\nprint(df_characters.isnull().sum())\\nprint('Missing values for locations:')\\nprint(df_locations.isnull().sum())\\nprint('Missing values for script:')\\nprint(df_script.isnull().sum())\\nprint('Missing values for episodes:')\\nprint(df_episodes.isnull().sum())\",\"Check for missing values in the datasets\\nprint('Missing values in the characters dataset:', df_characters.isnull().values.any())\\nprint('Missing values in the locations dataset:', df_locations.isnull().values.any())\\nprint('Missing values in the script dataset:', df_script.isnull().values.any())\\nprint('Missing values in the episodes dataset:', df_episodes.isnull().values.any())\",\" Print the missing values percentage of each dataframe\\nprint('Characters:', df_characters.isna().mean())\\nprint('Locations:', df_locations.isna().mean())\\nprint('Script:', df_script.isna().mean())\\nprint('Episodes:', df_episodes.isna().mean())\",\"Check for missing data\\nprint(df_episodes.info())\",\"Check missing values\\nprint(\\\"NaN Values in characters: \\\",df_characters[df_characters.isna().any(axis=1)].shape[0])\\nprint(\\\"NaN Values in locations: \\\",df_locations[df_locations.isna().any(axis=1)].shape[0])\\nprint(\\\"NaN Values in script: \\\",df_script[df_script.isna().any(axis=1)].shape[0])\\nprint(\\\"NaN Values in episodes: \\\",df_episodes[df_episodes.isna().any(axis=1)].shape[0])\",\"Check for NaN in each dataframe\\nprint(df_characters.isna().sum())\\nprint(df_locations.isna().sum())\\nprint(df_script.isna().sum())\\nprint(df_episodes.isna().sum())\",\"Check the presence of null values in the datasets\\nprint('Characters:', df_characters.isnull().values.any())\\nprint('Locations:', df_locations.isnull().values.any())\\nprint('Script:', df_script.isnull().values.any())\\nprint('Episodes:', df_episodes.isnull().values.any())\",\"Checking for any null values\\nprint(df_characters.isnull().sum())\\nprint(df_locations.isnull().sum())\\nprint(df_script.isnull().sum())\\nprint(df_episodes.isnull().sum())\",\"Check the data type and print as the number of missing values in each column\\nprint(f'df_characters: {df_characters.shape}')\\nprint(df_characters.dtypes, end='\\\\n\\\\n')\\nprint(df_characters.isna().sum(), end='\\\\n\\\\n')\\n\\nprint(f'df_locations: {df_locations.shape}')\\nprint(df_locations.dtypes, end='\\\\n\\\\n')\\nprint(df_locations.isna().sum(), end='\\\\n\\\\n')\\n\\nprint(f'df_episodes: {df_episodes.shape}')\\nprint(df_episodes.dtypes, end='\\\\n\\\\n')\\nprint(df_episodes.isna().sum(), end='\\\\n\\\\n')\\n\\nprint(f'df_script: {df_script.shape}')\\nprint(df_script.dtypes, end='\\\\n\\\\n')\\nprint(df_script.isna().sum(), end='\\\\n\\\\n')\",\"Check for any missing or incomplete data in the characters, locations, script, and episodes dataframes\",\"Checking for any null rows in the dataset\\nprint(\\\"Number of null rows in script dataset:\\\", df_script.isnull().sum().sum())\\nprint(\\\"Number of null rows in character dataset:\\\", df_characters.isnull().sum().sum())\\nprint(\\\"Number of null rows in location dataset:\\\", df_locations.isnull().sum().sum())\\nprint(\\\"Number of null rows in episodes dataset:\\\", df_episodes.isnull().sum().sum())\",\"# cheek NaN values in dataframes\\nprint('Characters NaN values: ' + str(sum(df_characters.isna().sum())))\\nprint('Locations NaN values: ' + str(sum(df_locations.isna().sum())))\\nprint('Script NaN values: ' + str(sum(df_script.isna().sum())))\\nprint('Episodes NaN values: ' + str(sum(df_episodes.isna().sum())))\",\"checking for missing data\\ndf_satistics = pd.DataFrame()\\ndf_satistics['characters'] = dict(count = df_characters.shape[0])\\ndf_satistics['locations'] = dict(count = df_locations.shape[0])\\ndf_satistics['episodes'] = dict(count = df_episodes.shape[0])\\ndf_satistics['script_lines'] = dict(count = df_script.shape[0])\\n\\ndf_satistics\",\"Check for null values in our datasets\\nprint(\\\"Null values in characters DataFrame:\\\\n\\\", df_characters.isna().sum(), \\\"\\\\n\\\")\\nprint(\\\"Null values in locations DataFrame:\\\\n\\\", df_locations.isna().sum(), \\\"\\\\n\\\")\\nprint(\\\"Null values in script DataFrame:\\\\n\\\", df_script.isna().sum(), \\\"\\\\n\\\")\\nprint(\\\"Null values in episodes DataFrame:\\\\n\\\", df_episodes.isna().sum())\",\"check for missing data in episodes data frame\",\"Check for missing values in each dataframe\\nprint(df_characters.isnull().sum())\\nprint(df_locations.isnull().sum())\\nprint(df_script.isnull().sum())\\nprint(df_episodes.isnull().sum())\",\"Check for null values\\nprint('Null values in df_characters:', df_characters.isnull().sum().sum())\\nprint('Null values in df_locations:', df_locations.isnull().sum().sum())\\nprint('Null values in df_script:', df_script.isnull().sum().sum())\\nprint('Null values in df_episodes:', df_episodes.isnull().sum().sum())\"],\"marker\":{\"opacity\":0.5,\"size\":5},\"mode\":\"markers+text\",\"name\":\"141_Checking for Missing and Null Values in Datasets\",\"text\":[\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\"],\"textfont\":{\"size\":12},\"x\":[3.5490505695343018,3.838474988937378,3.484362840652466,3.999230146408081,3.641775369644165,3.724104166030884,3.489365816116333,3.829927921295166,3.5295724868774414,2.595982074737549,4.766057968139648,4.25053596496582,4.079675674438477,4.00111722946167,3.0820584297180176,2.8290724754333496,3.652219772338867,4.515271186828613,2.9974710941314697,3.919351816177368,3.264561176300049,3.542954921722412,3.8827285766601562],\"y\":[1.0562785863876343,0.4925668239593506,0.665583074092865,0.5156201124191284,1.25780189037323,0.7266167998313904,1.0349501371383667,0.89180588722229,0.7986899614334106,1.71975839138031,1.4461003541946411,1.5330034494400024,0.8487464189529419,0.9083819389343262,1.260246992111206,1.2463605403900146,0.3139422833919525,1.7982724905014038,0.9596925973892212,0.9581233859062195,1.712884545326233,0.7006100416183472,0.7615945339202881],\"type\":\"scattergl\"},{\"hoverinfo\":\"text\",\"hovertext\":[\"Load the Spacy model for English language\\nnlp = spacy.load(\\\"en_core_web_sm\\\")\",\"# Load English language model and spacy parser\\nnlp = spacy.load('en_core_web_sm')\\nnlp.max_length = 10000000\",\"Create an instance of language model\\nnlp = spacy.load('en_core_web_sm')\",\"Load the spacy language model\\nnlp = spacy.load('en_core_web_sm')\",\"Load spacy language model\\nnlp = spacy.load('en_core_web_sm')\",\"# Load the English model\\nnlp = spacy.load('en_core_web_sm')\",\" Load Spacy language model\\nnlp = spacy.load('en_core_web_sm')\",\"Load the spaCy English model\\nnlp = spacy.load('en_core_web_sm')\",\"Declare the language model\\nnlp = spacy.load('en_core_web_sm')\",\" Import the spacy language model\\nnlp = spacy.load('en_core_web_sm')\",\" Load Spacy English model\\nnlp = spacy.load('en_core_web_sm')\",\"Load Spacy in English\\nnlp = spacy.load('en_core_web_sm')\",\"define language model\\nnlp = spacy.load('en_core_web_sm')\",\"\\n# Load the language model\\nnlp = spacy.load('en_core_web_sm')\",\" Load spaCy's English NLP model\\nnlp = spacy.load('en_core_web_sm')\",\"# Language model for extracting Named Entities\\nnlp = spacy.load(\\\"en_core_web_sm\\\")\",\" Load Spacy English \\\"Core Web\\\" Model\\nnlp = spacy.load('en_core_web_sm')\",\" Load Spacy model for English language\\nnlp = spacy.load('en_core_web_sm')\",\"Load language model\\nnlp = spacy.load('en_core_web_sm')\",\"language model\\nnlp = spacy.load('en_core_web_sm')\",\"Load spacy language model\\nnlp = spacy.load('en_core_web_sm')\",\"Language-specific imports and variables\\nimport en_core_web_sm\\nnlp = en_core_web_sm.load()\\n\\n# Utility function\\ndef flatten(l):\\n    return [item for sublist in l for item in sublist]\",\" Import Spacy's large english model\\nnlp = spacy.load('en_core_web_lg')\"],\"marker\":{\"opacity\":0.5,\"size\":5},\"mode\":\"markers+text\",\"name\":\"142_Language Model Loading with Spacy\",\"text\":[\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\"],\"textfont\":{\"size\":12},\"x\":[14.657806396484375,14.895315170288086,14.507210731506348,14.333196640014648,14.42487907409668,14.822637557983398,14.416641235351562,14.379626274108887,14.907707214355469,14.697129249572754,14.584158897399902,14.581840515136719,14.556845664978027,14.873346328735352,14.44473934173584,14.738743782043457,14.790095329284668,14.689874649047852,14.446453094482422,14.36218547821045,14.296236991882324,14.724068641662598,14.748052597045898],\"y\":[9.068906784057617,9.003006935119629,9.92281723022461,10.449079513549805,10.137666702270508,10.115257263183594,10.043099403381348,10.030842781066895,10.33591365814209,10.128904342651367,9.670342445373535,9.792060852050781,10.324738502502441,10.340140342712402,9.511213302612305,9.184881210327148,10.152633666992188,9.322660446166992,10.302884101867676,10.018431663513184,10.202341079711914,9.642961502075195,8.937734603881836],\"type\":\"scattergl\"},{\"hoverinfo\":\"text\",\"hovertext\":[\" Display the first 5 rows of each dataframe\\ndisplay(df_characters.head())\\ndisplay(df_locations.head())\\ndisplay(df_script.head())\\ndisplay(df_episodes.head())\",\"Displaying the first 5 records of each dataframe\\nprint('Characters')\\nprint(df_characters.head(5))\\nprint('Locations')\\nprint(df_locations.head(5))\\nprint('Script')\\nprint(df_script.head(5))\\nprint('Episodes')\\nprint(df_episodes.head(5))\",\" Display the first 5 rows of each dataframe\\ndisplay(df_characters.head())\\ndisplay(df_locations.head())\\ndisplay(df_script.head())\\ndisplay(df_episodes.head())\",\"Display the first 5 rows of each dataframe\\nprint(\\\"Characters\\\")\\ndisplay(df_characters.head(5))\\nprint(\\\"Locations\\\")\\ndisplay(df_locations.head(5))\\nprint(\\\"Episodes\\\")\\ndisplay(df_episodes.head(5))\\nprint(\\\"Scripts\\\")\\ndisplay(df_script.head(5))\",\"View the first 5 rows of each dataframe\\nprint('Characters')\\ndisplay(df_characters.head())\\nprint('Locations')\\ndisplay(df_locations.head())\\nprint('Script')\\ndisplay(df_script.head())\\nprint('Episodes')\\ndisplay(df_episodes.head())\",\"Displaying the first 5 rows of each dataset\\ndisplay(df_characters.head())\\ndisplay(df_locations.head())\\ndisplay(df_script.head())\\ndisplay(df_episodes.head())\",\"Show the first 5 rows of each dataframe\\ndisplay(df_characters.head())\\ndisplay(df_locations.head())\\ndisplay(df_script.head())\\ndisplay(df_episodes.head())\",\" Display first 5 records of each dataframe\\nprint(\\\"Characters dataframe\\\")\\ndisplay(df_characters.head())\\n\\nprint(\\\"Locations dataframe\\\")\\ndisplay(df_locations.head())\\n\\nprint(\\\"Script dataframe\\\")\\ndisplay(df_script.head())\\n\\nprint(\\\"Episodes dataframe\\\")\\ndisplay(df_episodes.head())\",\"Display 5 random rows for each dataframe\\nprint('The characters dataframe:')\\ndisplay(df_characters.sample(5))\\n\\nprint('The locations dataframe:')\\ndisplay(df_locations.sample(5))\\n\\nprint('The script dataframe:')\\ndisplay(df_script.sample(5))\\n\\nprint('The episodes dataframe:')\\ndisplay(df_episodes.sample(5))\",\"display first 5 rows of each dataframe\\ndisplay(df_characters.head())\\ndisplay(df_locations.head())\\ndisplay(df_script.head())\\ndisplay(df_episodes.head())\",\"Print first 5 rows of characters, locations, script lines and episodes dataframes\",\" Show the first 5 rows of each dataframe\\ndisplay(df_characters.head())\\ndisplay(df_locations.head())\\ndisplay(df_script.head())\\ndisplay(df_episodes.head())\",\"Display first 5 records of each dataframe\\ndisplay(df_characters.head())\\ndisplay(df_locations.head())\\ndisplay(df_script.head())\\ndisplay(df_episodes.head())\",\"Display first 5 rows of each dataframe\\ndisplay(df_characters.head())\\ndisplay(df_locations.head())\\ndisplay(df_script.head())\\ndisplay(df_episodes.head())\",\"Display the first 5 rows of each DataFrame to understand the kind of data available\\nprint('Characters:')\\ndisplay(df_characters.head())\\nprint('Locations:')\\ndisplay(df_locations.head())\\nprint('Script Lines:')\\ndisplay(df_script.head())\\nprint('Episodes:')\\ndisplay(df_episodes.head())\",\" Display dimensions and first 5 records of each data frame\\nprint('Characters:', df_characters.shape)\\nprint('Locations:', df_locations.shape)\\nprint('Script:', df_script.shape)\\nprint('Episodes:', df_episodes.shape)\\n\\nprint('Displaying Simpsons Characters')\\nprint(df_characters.head())\\nprint('Displaying Simpsons Locations')\\nprint(df_locations.head())\\nprint('Displaying Simpsons Script')\\nprint(df_script.head())\\nprint('Displaying Simpsons Episodes')\\nprint(df_episodes.head())\",\"Display first 5 records of each dataframe to understand its structure\\nprint(\\\"Characters\\\")\\ndisplay(df_characters.head())\\n\\nprint(\\\"Locations\\\")\\ndisplay(df_locations.head())\\n\\nprint(\\\"Script\\\")\\ndisplay(df_script.head())\\n\\nprint(\\\"Episodes\\\")\\ndisplay(df_episodes.head())\",\" Display the first 5 rows of each DataFrame.\\ndisplay(df_characters.head())\\ndisplay(df_locations.head())\\ndisplay(df_script.head())\\ndisplay(df_episodes.head())\",\" Display first 5 rows of each dataframe\\ndfs = {'characters': df_characters, 'locations': df_locations, 'script': df_script, 'episodes': df_episodes}\\nfor name, dframe in dfs.items():\\n    print('\\\\n' + name.upper())\\n    print(dframe.head())\",\"Preview first 5 rows of each dataframe\\nprint(\\\"--- Characters ---\\\")\\ndisplay(df_characters.head())\\n\\nprint(\\\"--- Locations ---\\\")\\ndisplay(df_locations.head())\\n\\nprint(\\\"--- Script ---\\\")\\ndisplay(df_script.head())\\n\\nprint(\\\"--- Episodes ---\\\")\\ndisplay(df_episodes.head())\",\"Preview the first 5 rows of each dataframe to see what we are working with\\nprint(\\\"Characters\\\")\\ndisplay(df_characters.head())\\n\\nprint(\\\"Locations\\\")\\ndisplay(df_locations.head())\\n\\nprint(\\\"Script\\\")\\ndisplay(df_script.head())\\n\\nprint(\\\"Episodes\\\")\\ndisplay(df_episodes.head())\",\"Display the first 5 rows of each dataframe\\ndfs = {'Characters': df_characters, 'Locations': df_locations, 'Script': df_script, 'Episodes': df_episodes}\\nfor name, df in dfs.items():\\n    print(name)\\n    print(df.head())\\n    print('\\\\n')\",\"Display first 5 rows of each DataFrame to understand their structure\\nprint(\\\"Characters data:\\\")\\ndisplay(df_characters.head())\\n\\nprint(\\\"Locations data:\\\")\\ndisplay(df_locations.head())\\n\\nprint(\\\"Script data:\\\")\\ndisplay(df_script.head())\\n\\nprint(\\\"Episodes data:\\\")\\ndisplay(df_episodes.head())\"],\"marker\":{\"opacity\":0.5,\"size\":5},\"mode\":\"markers+text\",\"name\":\"143_Displaying Simpsons Dataframes\",\"text\":[\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\"],\"textfont\":{\"size\":12},\"x\":[-2.2193288803100586,-1.3823151588439941,-2.1083688735961914,-1.7041186094284058,-1.9848350286483765,-2.721090793609619,-2.285038948059082,-1.5664441585540771,-1.5037225484848022,-1.8274171352386475,-1.5884507894515991,-2.6236226558685303,-1.6456860303878784,-1.5797226428985596,-1.8349275588989258,-1.3149430751800537,-1.9217519760131836,-1.9582886695861816,-1.4178218841552734,-2.5699470043182373,-2.4102182388305664,-1.1724110841751099,-1.8088419437408447],\"y\":[6.957778453826904,6.495814323425293,7.03509521484375,6.23745584487915,6.026312828063965,6.6552252769470215,6.812996864318848,6.429218769073486,5.5715765953063965,6.599073886871338,6.320324420928955,6.600833415985107,6.774575710296631,7.1476149559021,6.240574836730957,5.73254919052124,6.117015838623047,6.909290790557861,6.635645389556885,5.665081977844238,5.534636497497559,6.441135406494141,6.0554280281066895],\"type\":\"scattergl\"},{\"hoverinfo\":\"text\",\"hovertext\":[\"Drop duplicates from all tables\\ndf_characters.drop_duplicates(subset='character_id', inplace=True)\\ndf_locations.drop_duplicates(subset='location_id', inplace=True)\\ndf_script.drop_duplicates(subset='line_id', inplace=True)\\ndf_episodes.drop_duplicates(subset='episode_id', inplace=True)\",\"Drop duplicate lines and NaN values from the script\\ndf_script.drop_duplicates(subset=['id', 'episode_id'], inplace=True)\\ndf_script.dropna(subset=['raw_text', 'normalized_text'], inplace=True)\",\"removing duplicate entries based on the 'id' column\\ndf_characters = df_characters.drop_duplicates(subset='id')\\ndf_locations = df_locations.drop_duplicates(subset='id')\\ndf_script = df_script.drop_duplicates(subset='id')\\ndf_episodes = df_episodes.drop_duplicates(subset='id')\",\"Check if all dfs have unique string ids\",\"Ensure the 'id' column is unique for all dataframes\",\"Create a deep copy of df_script and drop duplicate rows based on 'id' column\\ndf_script_unique = df_script.copy()\\ndf_script_unique.drop_duplicates(subset='id', keep='last', inplace=True)\",\"Remove duplicates from script dataframe\\ndf_script.drop_duplicates(subset=['episode_id', 'number', 'raw_text'], inplace=True)\",\"Ensure all scripts have a unique identifier\\ndf_script = df_script.drop_duplicates(subset='id')\",\" Data preprocess\\ndf_script = df_script.rename(columns={'id': 'id_script'})\\ndf_script = df_script.drop_duplicates(subset='raw_text')\",\"Remove any possible duplicate rows in the dataframes\\ndf_characters.drop_duplicates(subset =\\\"id\\\", keep = False, inplace = True)\\ndf_locations.drop_duplicates(subset =\\\"id\\\", keep = False, inplace = True)\\ndf_script.drop_duplicates(subset =\\\"id\\\", keep = False, inplace = True)\\ndf_episodes.drop_duplicates(subset =\\\"id\\\", keep = False, inplace = True)\",\"Remove duplicates from script\\ndf_script = df_script.drop_duplicates(subset=['character_id', 'raw_text'])\",\"Deletes all columns containing duplicates in both datasets\\ndf_characters = df_characters.drop_duplicates()\\ndf_locations = df_locations.drop_duplicates()\",\" drop duplicate values from the script dataframe\\ndf_script.drop_duplicates(subset=['raw_text'], keep='first', inplace=True)\",\"Remove duplicate rows\\ndf_script.drop_duplicates(subset=['character_id', 'episode_id', 'raw_text'], inplace=True)\",\"Remove unnecessary columns and rows from the characters DataFrame\\ndf_characters = df_characters.drop(columns=['id', 'image_url', 'index'])\\ndf_characters.dropna(inplace=True)\\ndf_characters.drop_duplicates(subset =\\\"name\\\", keep = 'first', inplace = True)\",\"Remove duplicates from dataframe\",\" Remove duplicate entries in character and location dataframes\\ndf_characters = df_characters.drop_duplicates(subset='raw_character_text')\\ndf_locations = df_locations.drop_duplicates(subset='raw_location_text')\",\"Remove duplicate script lines if any\\ndf_script.drop_duplicates(subset='id', keep=False, inplace=True)\",\"Remove duplicates from characters, locations and episodes dataframes\\ndf_characters.drop_duplicates(subset=['name'], inplace=True)\\ndf_locations.drop_duplicates(subset=['name'], inplace=True)\\ndf_episodes.drop_duplicates(subset=['title'], inplace=True)\",\"unique writers\\ndf_script.writer_id.unique()\",\"Remove potential duplicate rows from characters, locations, episodes dataframes\\ndf_characters.drop_duplicates(inplace=True)\\ndf_locations.drop_duplicates(inplace=True)\\ndf_episodes.drop_duplicates(inplace=True)\",\"Remove any duplicate rows\\ndf_script.drop_duplicates(inplace=True)\",\" Remove duplicate character and location names\\ndf_characters.drop_duplicates(subset =\\\"name\\\", inplace = True)\\ndf_locations.drop_duplicates(subset =\\\"name\\\", inplace = True)\"],\"marker\":{\"opacity\":0.5,\"size\":5},\"mode\":\"markers+text\",\"name\":\"144_Removing Duplicate Rows and Values in Dataframes\",\"text\":[\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\"],\"textfont\":{\"size\":12},\"x\":[6.011853218078613,6.475913047790527,5.90300178527832,6.321181297302246,6.272099494934082,6.168031215667725,5.841244697570801,6.368790626525879,5.735710144042969,6.273908615112305,6.187617778778076,6.163234710693359,6.414609909057617,5.714129447937012,5.384355068206787,6.9088006019592285,6.011588096618652,6.302712440490723,5.649504661560059,6.005177021026611,5.688501834869385,6.389903545379639,5.92415189743042],\"y\":[6.115876197814941,5.428709506988525,6.027288913726807,4.15475606918335,2.74692964553833,4.823970794677734,5.318986415863037,4.6993513107299805,5.128721237182617,5.664516925811768,6.230840682983398,6.284775733947754,5.509791851043701,5.8447113037109375,6.73848295211792,3.6452481746673584,6.795186996459961,5.152220726013184,6.082017421722412,5.404045104980469,5.820321083068848,4.852562427520752,6.8009443283081055],\"type\":\"scattergl\"},{\"hoverinfo\":\"text\",\"hovertext\":[\"Set random seed for reproducibility\\nnp.random.seed(0)\",\"Set random seed for reproducibility\\nnp.random.seed(0)\",\"Setting random seed for reproducibility\\nnp.random.seed(0)\",\" Set random state for reproducibility\\nnp.random.seed(0)\",\"Set random seed for reproducibility\\nnp.random.seed(0)\",\"Set random seed for reproducibility\\nnp.random.seed(0)\",\"Set random seed for reproducibility\\nnp.random.seed(0)\",\" Set random seed for reproducibility\\nnp.random.seed(0)\",\"Set random seed for reproducibility\\nnp.random.seed(0)\",\"Set random seed for reproducibility\\nnp.random.seed(0)\",\"Set random seed for reproducibility\\nnp.random.seed(0)\",\"Set random seed for reproducibility\\nnp.random.seed(0)\",\"Set random seed for reproducibility\\nnp.random.seed(0)\",\"Set random seed for reproducibility\\nnp.random.seed(0)\",\"Set random seed for reproducibility\\nnp.random.seed(0)\",\"Set random seed for reproducibility\\nnp.random.seed(0)\",\"Setting random seed for reproducibility\\nnp.random.seed(0)\",\"Set random seed for reproducibility\\nnp.random.seed(0)\",\"Set random seed for reproducibility\\nnp.random.seed(0)\",\"Set random seed for reproducibility\\nnp.random.seed(0)\",\" Set a pre-defined random state for reproducibility\",\"Set random seed for reproducibility\\nnp.random.seed(0)\",\"Set random seed for reproducibility\\nnp.random.seed(0)\"],\"marker\":{\"opacity\":0.5,\"size\":5},\"mode\":\"markers+text\",\"name\":\"145_Setting random seed for reproducibility\",\"text\":[\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\"],\"textfont\":{\"size\":12},\"x\":[32.441612243652344,32.19854736328125,32.04437255859375,31.616230010986328,32.34445571899414,32.22469711303711,31.980932235717773,32.11025619506836,32.417728424072266,32.46681213378906,32.2376594543457,32.097415924072266,32.130435943603516,32.26409912109375,32.4200325012207,32.099510192871094,32.32742691040039,32.15043640136719,32.09943771362305,32.18280792236328,31.59956169128418,32.19760513305664,32.212364196777344],\"y\":[13.137787818908691,13.242997169494629,14.04147720336914,13.515433311462402,13.473072052001953,13.569721221923828,13.612604141235352,14.146363258361816,13.691664695739746,13.404744148254395,13.205784797668457,13.214498519897461,13.40043830871582,13.473856925964355,13.550578117370605,13.532320022583008,14.328460693359375,13.288575172424316,13.625518798828125,13.101011276245117,12.809103965759277,13.671055793762207,13.632975578308105],\"type\":\"scattergl\"},{\"hoverinfo\":\"text\",\"hovertext\":[\"Set default fontsize for better readability of charts\\nmatplotlib.rcParams.update({'font.size': 14})\",\"Set up matplotlib\\nfont = {'family' : 'normal',\\n        'weight' : 'bold',\\n        'size'   : 22}\\n\\nmatplotlib.rc('font', **font)\",\"Set up matplotlib parameters to make the plots look better\\nmatplotlib.rcParams['figure.figsize'] = (15, 10)\\nmatplotlib.rcParams['font.size'] = 10\\nmatplotlib.rcParams['figure.facecolor'] = '#00000000'\",\"Set the font for saving as pdf. Set properties for rendering of fonts\\n\\nmatplotlib.rcParams['pdf.fonttype'] = 42  # Embedded subset (only the used characters)\",\"For plotting\\nfont = {'family' : 'normal',\\n        'weight' : 'bold',\\n        'size'   : 22}\\n\\nmatplotlib.rc('font', **font)\",\"Set up styles\\nplt.style.use('fivethirtyeight')\\nmatplotlib.rcParams.update({\\n    'font.size': 12,\\n    'figure.figsize': (15, 5),\\n    'axes.labelsize': 10,\\n    'axes.titlesize': 14,\\n    'xtick.labelsize': 10,\\n    'ytick.labelsize': 10,\\n    'legend.fontsize': 10\\n})\",\" Set up variables\\nfontsize = 40\\nfont_path = 'data\\u002fJetBrainsMono-Bold.ttf'\",\"Configure matplotlib rcParams for a consistent style throughout the notebook\\nmatplotlib.rcParams.update({\\n    'font.size': 16,\\n    'figure.figsize': (10, 8),\\n    'axes.grid': True,\\n    'axes.axisbelow': True,\\n    'axes.labelsize': 16,\\n    'axes.titlesize': 20,\\n    'axes.linewidth': 2,\\n    'lines.linewidth': 3,\\n    'lines.markersize': 10,\\n    'xtick.labelsize': 16,\\n    'ytick.labelsize': 16,\\n    'legend.fontsize': 16\\n})\",\" Set default font size for plots\\nmatplotlib.rcParams.update({'font.size': 12})\",\"Set font for entire script\\nmatplotlib.rcParams['font.family'] = 'DejaVu Sans'\",\" Set font style\\nfont = {\\n    'family': 'DejaVu Sans',\\n    'weight': 'normal',\\n    'size': 14\\n}\\nmatplotlib.rc('font', **font)\",\"Show installed fonts\\n[f.name for f in matplotlib.font_manager.fontManager.ttflist]\",\"'Jupyter lab' theme\\nplt.rcParams.update({'axes.titlesize': 'large', 'figure.titlesize': 'large'})\",\"Set custom matplotlib settings\\nmatplotlib.rcParams.update({\\n    'font.size': 14,\\n    'figure.figsize': (10, 8),\\n    'figure.facecolor': '#00000000',\\n    'axes.labelsize': 12,\\n    'axes.labelcolor': '#ffffff',\\n    'axes.labelweight': 'bold',\\n    'axes.titlesize': 16,\\n    'axes.titlecolor': '#ffffff',\\n    'axes.titleweight': 'bold',\\n    'xtick.labelsize': 10,\\n    'ytick.labelsize': 10,\\n    'legend.fontsize': 12,\\n    'legend.title_fontsize': 14\\n})\",\"Set the font family and size for matplotlib plots\\nplt.rcParams['font.family'] = 'Arial'\\nplt.rcParams['font.size'] = 12\",\"matplotlib.rcParams.update({'font.size': 22})\",\"Plot settings\\nmatplotlib.rcParams['axes.labelsize'] = 14\\nmatplotlib.rcParams['xtick.labelsize'] = 12\\nmatplotlib.rcParams['ytick.labelsize'] = 12\\nmatplotlib.rcParams['text.color'] = 'k'\",\"Set up default plotting parameters\\nmatplotlib.rc('font', **{'size': 12})\\nmatplotlib.rc('grid', **{'color': '0.75', 'linestyle': '-', 'linewidth': 0.5})\\nmatplotlib.rc('figure', **{'figsize': (10, 6)})\\nmatplotlib.rc('axes', **{'facecolor': '0.95', 'edgecolor': '0.85', 'grid': True})\\nmatplotlib.rc('axes', **{'titlesize': 'large', 'labelsize': 'large'})\\nmatplotlib.rc('xtick', **{'color': '0.2', 'labelsize': 'large'})\\nmatplotlib.rc('ytick', **{'color': '0.2', 'labelsize': 'large'})\\nmatplotlib.rc('legend', **{'fontsize': 'large', 'numpoints': 1, 'shadow': True, 'fancybox': True})\\nmatplotlib.rc('image', **{'cmap': 'Greys', 'interpolation': 'none', 'aspect': 'equal'})\",\"Define the font to use for plots\\nplt.rcParams['font.family'] = 'DejaVu Sans'\",\"# set up matplotlib parameters to fit these charts in readme\\n\\nmatplotlib.rcParams.update({'font.size': 22})\",\"Set default font size for better visualization\\nfont = {'size': 11}\\nmatplotlib.rc('font', **font)\",\"SetFont\\nmatplotlib.rcParams['font.family'] = ['Noto Sans CJK JP']\",\" Settings for visualization\\nfont = {'size': 60}\\nmatplotlib.rc('font', **font)\"],\"marker\":{\"opacity\":0.5,\"size\":5},\"mode\":\"markers+text\",\"name\":\"146_Font size and style customization in matplotlib\",\"text\":[\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\"],\"textfont\":{\"size\":12},\"x\":[20.97139549255371,21.159191131591797,20.239734649658203,21.254878997802734,21.327939987182617,21.098934173583984,21.246702194213867,20.829730987548828,21.058151245117188,21.550321578979492,21.3242244720459,21.455583572387695,20.40627098083496,21.001811981201172,20.852493286132812,20.887102127075195,20.960052490234375,20.839685440063477,21.428382873535156,20.920133590698242,21.080781936645508,21.518756866455078,20.855297088623047],\"y\":[6.729861736297607,7.562346935272217,6.781768321990967,7.192374229431152,7.482904434204102,6.439345836639404,7.376909255981445,6.398699760437012,7.241337299346924,7.4584150314331055,7.444786548614502,7.662421703338623,6.570269584655762,6.817641258239746,7.024448871612549,6.807738304138184,6.387447357177734,6.403350830078125,7.056567668914795,7.1784796714782715,7.257977485656738,7.537403106689453,7.448300838470459],\"type\":\"scattergl\"},{\"hoverinfo\":\"text\",\"hovertext\":[\"Extract the first few elements of the dataframe to get an understanding of the data\",\"Inspect the first few entries of each dataframe to understand the data\",\"Inspect the first few rows of each dataframe to understand the data\",\"Looking at the first few rows of each dataframe to understand the data\",\"Inspect the first few rows of each dataframe to understand the data\",\" Viewing the first few rows of each dataframe to get an understanding of the data\",\"Inspect the first few rows of each dataframe to understand the data\",\"Inspect the first few rows of each DataFrame to understand the data\",\"Inspect the first few rows of each dataframe to understand their structure and available data\",\"Inspect the first few rows of each dataframe to understand the data\",\"Viewing the first few rows of the dataframes to understand the data\",\"Inspect dataframes' first few rows\",\"Inspect the first few rows of each dataframe to understand the data\",\"Inspect the first few rows of each dataframe to understand the data\",\"Inspect the first few rows of each dataframe to understand the data\",\"Inspect the first few rows of each DataFrame to understand the data\",\"Inspect the first few rows of each dataframe to understand the data\",\"Inspect the first few rows of each dataframe to understand the data\",\"Inspect the first rows of the dataframe to get an idea of the data\",\"Return the first few rows of each dataframe to inspect the data.\",\"Analyse the first rows of the dataframes to get an idea of the data\",\"Inspecting the dataframe for the first time\"],\"marker\":{\"opacity\":0.5,\"size\":5},\"mode\":\"markers+text\",\"name\":\"147_Inspecting and Understanding Dataframes\",\"text\":[\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\"],\"textfont\":{\"size\":12},\"x\":[13.85085678100586,14.09046745300293,13.850995063781738,13.873594284057617,13.762792587280273,13.32719898223877,13.745247840881348,13.474336624145508,13.365487098693848,13.665928840637207,13.34047794342041,13.315351486206055,13.816150665283203,13.708907127380371,13.947284698486328,14.068138122558594,13.768095016479492,13.623017311096191,13.607625961303711,13.032980918884277,14.047930717468262,12.917128562927246],\"y\":[-8.403707504272461,-8.575931549072266,-8.56259822845459,-8.637699127197266,-8.637001991271973,-9.10066032409668,-8.642220497131348,-8.679598808288574,-8.155694961547852,-8.514054298400879,-8.899322509765625,-8.159876823425293,-8.341720581054688,-8.867256164550781,-8.591957092285156,-8.697001457214355,-8.382872581481934,-8.805574417114258,-8.197052955627441,-8.580652236938477,-8.46461009979248,-7.520492076873779],\"type\":\"scattergl\"},{\"hoverinfo\":\"text\",\"hovertext\":[\"Display the first 5 records of the characters data\\ndf_characters.head()\",\"display first 5 records of the characters table\\ndf_characters.head()\",\"display only the first 5 records of df_characters\\ndf_characters.head()\",\"Show the first 5 records of the dataset\\ndf_characters.head()\",\"Show the first 5 records of the characters dataframe\\ndf_characters.head()\",\" Show the first 5 records of the characters dataframe\\ndf_characters.head()\",\"Print the first 5 records of the characters data frame\\ndf_characters.head()\",\" Display first 5 records for characters dataset\\ndf_characters.head()\",\"Display the first 5 records for the characters dataframe\\ndf_characters.head()\",\"Display the first 5 records of the characters DataFrame\\ndf_characters.head()\",\" Show first 5 entries of df_characters dataframe\\ndf_characters.head()\",\"Display first 5 records of the dataframe\\ndf_characters.head()\",\"Display the first 5 records of the characters dataframe\\ndf_characters.head()\",\"# Display the first 5 records of the characters dataframe\\ndf_characters.head()\",\"# Display first 5 records of characters dataframe\\ndf_characters.head()\",\"\\n# Displaying first 5 records\\ndf_characters.head()\",\"View the first 5 rows of the characters dataset\\ndf_characters.head()\",\"View the first 5 records of characters dataset\\ndf_characters.head()\",\"Data Preprocessing\\n# Show the first 5 records of the characters dataframe\\ndf_characters.head()\",\"View the first 5 records of characters dataframe\\ndf_characters.head()\",\"Show first 5 records of the characters dataframe\\ndf_characters.head(5)\",\"View the first 5 records of 'df_characters'\\ndf_characters.head()\"],\"marker\":{\"opacity\":0.5,\"size\":5},\"mode\":\"markers+text\",\"name\":\"148_Displaying first 5 records of characters dataframe\",\"text\":[\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\"],\"textfont\":{\"size\":12},\"x\":[-0.46077314019203186,-0.3602733910083771,-0.46854835748672485,0.007403270807117224,-0.47519996762275696,-0.5331493616104126,-0.5847964286804199,-0.5563086867332458,-0.7108553051948547,-0.6106283068656921,-0.7906253337860107,-0.715080201625824,-0.3563164472579956,-0.7613869309425354,-1.0326294898986816,-0.5320226550102234,-0.2496436983346939,-0.05657004192471504,-0.5566718578338623,-0.10227066278457642,-0.771187961101532,0.09480631351470947],\"y\":[13.589499473571777,13.495728492736816,13.688666343688965,13.294045448303223,13.711019515991211,13.467495918273926,13.394388198852539,13.12983512878418,13.945377349853516,13.523053169250488,13.032712936401367,13.915251731872559,13.673069953918457,13.765704154968262,13.544051170349121,13.403267860412598,12.510452270507812,13.141472816467285,13.67098617553711,12.984471321105957,13.9107027053833,13.214269638061523],\"type\":\"scattergl\"},{\"hoverinfo\":\"text\",\"hovertext\":[\"Filter some locations which contain non-ASCII characters\\ndf_locations_filtered = df_locations[df_locations['name'].apply(lambda x: x.isascii())].copy()\\n\\n# Extract character names\\ncharacters = df_characters['name'].tolist()\\n\",\"Filter only the canonical ones\\ndf_characters = df_characters[df_characters['is_canon']]\\n\\n# Convert the title of characters to lowercase\\ndf_characters['normalized_name'] = df_characters['name'].str.lower()\\n\\n# Display the dataframe\\ndf_characters.head()\",\"Ensure actors are consistently mapped with the same name\\ndf_script[\\\"raw_character_text\\\"].replace({\\\"brad goodman\\\": \\\"brad goodman psychiatrist\\\"}, inplace=True)\\ndf_script[\\\"raw_character_text\\\"].replace({\\\"brad goodman psychiatrist\\\": \\\"brad goodman\\\"}, inplace=True)\",\" Some useful variables\\nnames = list(df_characters.raw_character_text)\\nlocations = list(df_locations.raw_location_text)\",\" Reset character and location names to lowercase for easier matching\\ndf_characters['name'] = df_characters['name'].str.lower()\\ndf_locations['name'] = df_locations['name'].str.lower()\",\"Check if rows in script DF contain either characters or locations\\ncharacter_names = list(df_characters['character_name'].values)\\nlocation_names = list(df_locations['raw_location_text'].values)\",\" Strip invalid characters from character names and location names\\ndf_characters['name_stripped'] = df_characters['name'].str.replace('[^\\\\w\\\\s]', '')\\ndf_locations['name_stripped'] = df_locations['name'].str.replace('[^\\\\w\\\\s]', '')\",\"# Fix issue with character names\\ndf_characters['normalized_name'] = df_characters['normalized_name'].replace('lisa & bart', 'lisa, bart')\\n\\n# Display first few characters\\ndf_characters.head()\",\"Remove casing in the `character_name` column\\ndf_characters['character_name'] = df_characters['character_name'].str.lower()\",\"Converts 'raw_location_text' into a column of entity name\\ndf_script['location_entity'] = df_script['raw_location_text'].apply(lambda x: [i['text'] for i in sp(x).ents if i.label_ == 'GPE'])\",\"Split names into first and last names\\ndf_characters[['first_name', 'last_name']] = df_characters.character.str.split(\\\"_\\\", expand=True)\",\"Setting characters and locations to lowercase\\ndf_characters['normalized_name'] = df_characters['name'].str.lower().str.strip()\\ndf_characters['normalized_name'] = df_characters['normalized_name'].str.replace(\\\" \\\", \\\"_\\\")\\n\\ndf_locations['normalized_name'] = df_locations['name'].str.lower().str.strip()\\ndf_locations['normalized_name'] = df_locations['normalized_name'].str.replace(\\\" \\\", \\\"_\\\")\",\"Ensure that characters and locations have names\\ndf_characters['name'] = df_characters['name'].apply(lambda x: x.lower() if isinstance(x, str) else '')\\ndf_locations['name'] = df_locations['name'].apply(lambda x: x.lower() if isinstance(x, str) else '')\",\"Filter leading and trailing white spaces from character and location names\\ndf_characters['character'] = df_characters['character'].str.strip()\\ndf_locations['raw_location_text'] = df_locations['raw_location_text'].str.strip()\",\" Extract characters, locations, and raw text from script data\\ncharacters = [str(c).lower() for c in df_characters['character_name']]\\nlocations = [str(l).lower() for l in df_locations['raw_location_text']]\\nraw_text = [str(t).lower() for t in df_script['raw_text']]\",\" Strip leading\\u002ftrailing whitespaces from character names and location names\\ndf_characters['name'] = df_characters['name'].str.strip()\\ndf_locations['name'] = df_locations['name'].str.strip()\",\"Concatenate last_name and first_name strings\\ndf_script['character_name'] = df_script['raw_character_text'].str.lower().str.replace(\\\" \\\",\\\"\\\")\",\" Lowercase character names in the characters dataframe\\ndf_characters['name'] = df_characters['name'].str.lower()\",\"Normalize character names\\ndef normalize_characters(df):\\n    df['normalized_name'] = df.name.str.lower()\\n    df['normalized_name'] = df.normalized_name.str.replace(r\\\"[^\\\\w\\\\s]\\\", '', regex=True)\\n\\nnormalize_characters(df_characters)\",\"Setting series characters to lower case\\ndf_characters['normalized_name'] = df_characters['name'].apply(lambda x: x.lower())\",\" Mapping for names and locations\\ndf_characters['raw_character_text'].replace({'\\\\s{2,}': ' ', '^ ': '', '$ ': ''}, inplace=True, regex=True)\\ndf_locations['raw_location_text'].replace({'\\\\s{2,}': ' ', '^ ': '', '$ ': ''}, inplace=True, regex=True)\\ndf_script['raw_character_text'].replace({'\\\\s{2,}': ' ', '^ ': '', '$ ': ''}, inplace=True, regex=True)\\ndf_script['raw_location_text'].replace({'\\\\s{2,}': ' ', '^ ': '', '$ ': ''}, inplace=True, regex=True)\",\" Concatenate location name and normalized_text and split them with a space\\ndf_script['location_text'] = df_script['raw_location_text'] + ' ' + df_script['normalized_text']\\n\\n# Normalizes text field\\n# Converts string to lowercase and removes leading and trailing white spaces\\ndf_script['location_text'] = df_script['location_text'].str.lower().str.strip()\"],\"marker\":{\"opacity\":0.5,\"size\":5},\"mode\":\"markers+text\",\"name\":\"149_White space cleaning and normalization of character and location names\",\"text\":[\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\"],\"textfont\":{\"size\":12},\"x\":[5.441267013549805,5.816910266876221,5.102316856384277,4.988377571105957,5.345216274261475,5.243838310241699,5.687524318695068,6.393563270568848,5.983271598815918,4.932221412658691,6.083251953125,5.681478500366211,5.073404312133789,5.610692501068115,4.911318778991699,5.4198102951049805,5.789468288421631,5.964823246002197,6.177909851074219,6.006689071655273,5.358386993408203,4.912301540374756],\"y\":[8.785908699035645,9.467453002929688,8.24570369720459,8.77359676361084,8.966145515441895,8.319130897521973,9.272574424743652,9.296453475952148,9.094239234924316,8.514686584472656,9.943096160888672,9.294791221618652,8.80637264251709,9.020118713378906,8.50672721862793,8.857248306274414,9.664390563964844,9.104177474975586,9.883024215698242,9.766139030456543,8.891979217529297,9.252331733703613],\"type\":\"scattergl\"},{\"hoverinfo\":\"text\",\"hovertext\":[\"Link the episodes to the script lines\\ndf_script['episode'] = df_script.apply(lambda row: df_episodes.iloc[row['episode_id']].number, axis=1)\",\"Create new columns with episode title and writer names\\ndf_script['episode_title'] = df_script['episode_id'].map(df_episodes.set_index('id')['title'])\\ndf_script['writers'] = df_script['episode_id'].map(df_episodes.set_index('id')['writers'])\",\"Create a \\\"debut\\\" column in df_characters containing the episode_id of the character's debut episode.\",\"# Join the dataframes for simpsons\\ndf = df_script.set_index('episode_id').join(df_episodes.set_index('id'), lsuffix='script', rsuffix='ep')\\ndf = df.join(df_characters.set_index('id'), on='character_id')\",\" Separate script based on character IDs and episode IDs\\nmain_chars = list(df_characters[df_characters['main']] 'id')\\n\\n\\nep_ids = list(df_episodes['id'])\\nscripts = {}\\n\\nfor ep_id in ep_ids:\\n    # print(ep_id)\\n    \\n    df_ep_script = df_script[df_script['episode_id'] == ep_id]\\n    \\n    if len(df_ep_script) == 0:\\n        scripts[ep_id] = ''\\n        continue\\n    \\n    for char_id in main_chars:\\n        df_char_ep_script = df_ep_script[df_ep_script['character_id'] == char_id]\\n        script = df_char_ep_script['spoken_words'].values\\n        script = ' '.join([x for x in script if type(x) == str])\\n        \\n        scripts[(ep_id, char_id)] = script\",\" Create a new column for episode titles in df_script\\ndf_script['episode_title'] = df_script['episode_id'].map(df_episodes.set_index('id')['title'])\",\"# Add episode title to script dataframe\\ndf_script = df_script.join(df_episodes.set_index('id'), on='episode_id')\",\"alldata = df_script.join(df_episodes.set_index('id'), on='episode_id', rsuffix='_episode')\\nalldata = alldata.join(df_characters.set_index('id'), on='character_id', rsuffix='_character')\",\"Setting the 'character_id' column in 'episode' dataframe to match 'id' in 'character' dataframe.\",\"Map the episode names to each script line\\ndf_script['episode_name'] = df_script['episode_id'].map(df_episodes.set_index('id')['title'])\\n\\n# Remove the \\\\r formatting used in the script\\ndf_script['raw_text'] = df_script['raw_text'].str.replace('\\\\r', '')\",\"Create a joining table between the episodes and script lines DataFrame\\ndf_episodes['id'] = df_episodes['id'].astype(str)\\ndf_script['episode_id'] = df_script['episode_id'].astype(str)\\n\\ndf_episodes_script = df_episodes.set_index('id').join(\\n    df_script.set_index('episode_id'),\\n    rsuffix='_episode',\\n    how='right'\\n)\",\"Join df_script with df_episodes to add episode information to df_script\\ndf_joined = df_script.set_index('episode_id').join(df_episodes.set_index('id'), rsuffix='_episode')\",\"Create a dictionary mapping episode_id to episode_name to replace\\n# episode_id with episode_names in both episode_ids and episode_names\\nepisode_id_to_name = df_episodes.set_index('id')['title'].to_dict()\\n\\n# Replace episode_id with episode_name\\ndf_script['episode_id'] = df_script['episode_id'].replace(episode_id_to_name)\",\"Create a dictionary for each episode to easier lookup\\nepisode_to_script = {}\\nfor idx in tqdm(df_script.index):\\n    if df_script.loc[idx, 'episode_id'] not in episode_to_script:\\n        episode_to_script[df_script.loc[idx, 'episode_id']] = []\\n    episode_to_script[df_script.loc[idx, 'episode_id']].append(idx)\",\"Combine script lines with metadata\\ndf_joined = df_script.set_index('episode_id').join(\\n    df_episodes.set_index('id'),\\n    rsuffix='_ep'\\n).join(\\n    df_characters.set_index('id'),\\n    rsuffix='_ch'\\n).join(\\n    df_locations.set_index('id'),\\n    rsuffix='_loc'\\n).reset_index()\",\"Create a dictionary that maps episode_id to episode\\nepisode_dict = dict()\\nfor index, row in df_episodes.iterrows():\\n    episode = dict(row)\\n    episode_dict[episode['id']] = episode\",\"# Create a column with the name of the episode based on the id\\ndf_script['name_of_episode'] = df_script['episode_id'].apply(lambda x: df_episodes[df_episodes['id'] == x].iloc[0]['title'])\",\"Move 'The simpsons' to the front of the list\\ndf_episodes['title'] = df_episodes['title'].apply(lambda x: 'The Simpsons' if 'The Simpsons' in x else x)\\ndf_episodes['title'] = df_episodes['title'].apply(lambda x: 'The Simpsons' if x == 'Duh, The Simpsons' else x)\",\"Dictionary that maps episode ids to episode codes\\nepid_to_code = dict(zip(df_episodes.id, df_episodes.production_code))\",\"reate a new column for the episode_df mapping to imdb_id\\ndf_episodes['imdb_id'] = df_episodes['id'].apply(lambda x: 'tt' + str(1000000+x))\",\"Create a new column in df_script for the episode number\\nepisode_map = {row['id']: row['episode_id'] for index, row in df_script.iterrows()}\\ndf_script['episode_number'] = df_script['id'].map(lambda x: episode_map[x])\\n\\n# Create a new column in df_script for the character\\ncharacter_map = {row['id']: row['raw_character_text'] for index, row in df_script.iterrows()}\\ndf_script['character'] = df_script['id'].map(lambda x: character_map[x])\",\" Add episode titles to script lines table\\ndf_script['title'] = df_script.apply(lambda row: df_episodes[df_episodes['id'] == row['episode_id']]['title'].values[0], axis=1)\"],\"marker\":{\"opacity\":0.5,\"size\":5},\"mode\":\"markers+text\",\"name\":\"150_Mapping episode information to script data\",\"text\":[\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\"],\"textfont\":{\"size\":12},\"x\":[3.000730037689209,3.2226815223693848,4.601562976837158,3.1578433513641357,3.7804670333862305,3.28601336479187,3.1290132999420166,2.898942470550537,3.70625901222229,3.6411516666412354,2.3846232891082764,2.6624395847320557,3.6256508827209473,3.3549139499664307,2.067754030227661,3.682650089263916,3.162635326385498,3.7481772899627686,4.240124702453613,3.525926351547241,3.387267589569092,3.217374086380005],\"y\":[5.747582912445068,5.95086145401001,4.782751560211182,6.168579578399658,6.783947944641113,6.006971836090088,5.356024742126465,5.886251926422119,5.608462333679199,6.607821941375732,5.839211463928223,5.321618556976318,5.869588851928711,5.571496963500977,6.135619163513184,4.995089054107666,5.913662433624268,6.306452751159668,5.3631205558776855,5.474001407623291,5.686814308166504,5.918015480041504],\"type\":\"scattergl\"},{\"hoverinfo\":\"text\",\"hovertext\":[\"Display all columns for the script dataframe to have a better understanding of the dataframe\",\" Display the columns of the script data frame\\ndf_script.columns\",\"Display the columns of the script dataframe\\ndf_script.columns\",\"Display available scripts lines dataset columns\\ndf_script.columns\",\"Uncomment this line to see the column names\\n# df_script.columns\",\"Display available columns\\ndf_script.columns\",\"# What are the names of the columns in the script Dataframe?\\nprint(df_script.columns.tolist())\",\"Check the columns' names to see what to analyze\\ndf_script.columns\",\"Create and display the dataframe with all the information from a full script.\",\"Get the text data from the script dataframe.\",\"Check all the columns in the script dataframe\\nprint(df_script.columns)\",\"Display all the columns in the script dataframe\",\"Display available CSVs through their dataframes\\ndf_script.columns\",\"# Let's see what data do we have\\nprint('Columns:')\\nfor column in df_script.columns:\\n    print(f'\\\\t{column}')\",\"Set the script and entity to load into the DataFrame, and the column titles\",\" Display columns\\ndf_script.columns\",\"Check the available data columns\\nprint(df_script.columns)\",\"Columns of dataframe script\\nprint(df_script.columns.tolist())\",\"ention about the script\\nscript_columns = df_script.columns\\nprint(df_script.columns)\",\"View which columns are present\\ndf_script.columns\",\"View available columns\\ndf_script.columns\",\"Keep original column names for later reference\\noriginal_columns = df_script.columns\"],\"marker\":{\"opacity\":0.5,\"size\":5},\"mode\":\"markers+text\",\"name\":\"151_Displaying available columns in a dataframe\",\"text\":[\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\"],\"textfont\":{\"size\":12},\"x\":[8.609477043151855,7.82847785949707,8.152079582214355,7.114867210388184,7.79664945602417,7.94819450378418,7.550351142883301,7.64393949508667,7.794671058654785,7.536932468414307,7.873256206512451,8.357060432434082,7.55158805847168,7.41082239151001,8.938947677612305,7.878685474395752,7.959029197692871,7.657830238342285,7.659542560577393,7.67077112197876,7.785582542419434,8.183842658996582],\"y\":[-2.7196638584136963,-2.626612663269043,-2.335017442703247,-3.045325517654419,-1.5477886199951172,-2.5213940143585205,-2.3679375648498535,-1.9046666622161865,-3.0230417251586914,-2.679586410522461,-2.4241433143615723,-2.2560184001922607,-2.8235182762145996,-2.2660200595855713,-2.1411683559417725,-2.026644229888916,-1.9444658756256104,-2.2267048358917236,-1.7815858125686646,-1.8791946172714233,-2.485806465148926,-0.6371946930885315],\"type\":\"scattergl\"},{\"hoverinfo\":\"text\",\"hovertext\":[\" Display the dimension of the dataset\\nprint(\\\"Characters dimension: \\\", df_characters.shape)\\nprint(\\\"Locations dimension: \\\", df_locations.shape)\\nprint(\\\"Episodes dimension: \\\", df_episodes.shape)\\nprint(\\\"Script dimension: \\\", df_script.shape)\",\"Display the dimensions of the data with the .shape attribute\",\" Display dimension of datasets\\nprint(f\\\"Characters: {df_characters.shape}\\\")\\nprint(f\\\"Locations: {df_locations.shape}\\\")\\nprint(f\\\"Script: {df_script.shape}\\\")\\nprint(f\\\"Episodes: {df_episodes.shape}\\\")\",\"Looking at the dimensions of the tables\\nprint('Dimensions of characters table:', df_characters.shape)\\nprint('Dimensions of locations table:', df_locations.shape)\\nprint('Dimensions of script table:', df_script.shape)\\nprint('Dimensions of episodes table:', df_episodes.shape)\",\"View the dimensions of the dataframes\\nprint(\\\"Characters dimensions: \\\", df_characters.shape)\\nprint(\\\"Locations dimensions: \\\", df_locations.shape)\\nprint(\\\"Script dimensions: \\\", df_script.shape)\\nprint(\\\"Episodes dimensions: \\\", df_episodes.shape)\",\"characters and locations dimensions\\nprint('Dimension of characters data:', df_characters.shape)\\nprint('Dimension of locations data:', df_locations.shape)\",\" Display dimensions of datasets\\nprint(\\\"Characters:\\\", df_characters.shape)\\nprint(\\\"Locations:\\\", df_locations.shape)\\nprint(\\\"Script:\\\", df_script.shape)\\nprint(\\\"Episodes:\\\", df_episodes.shape)\",\" Data dimensions\\nprint(f'Simpsons characters: {df_characters.shape}')\\nprint(f'Simpsons locations: {df_locations.shape}')\\nprint(f'Simpsons script lines: {df_script.shape}')\\nprint(f'Simpsons episodes: {df_episodes.shape}')\",\"Dimensions\\nprint(df_script.shape)\\nprint(df_characters.shape)\\nprint(df_locations.shape)\\nprint(df_episodes.shape)\",\"Data Dimensions\\nprint('Dimensions of the Data')\\nprint('Characters:', df_characters.shape)\\nprint('Locations:', df_locations.shape)\\nprint('Script:', df_script.shape)\\nprint('Episodes:', df_episodes.shape)\",\"Inspect Data\\nprint(f'Dimensions of the Simpsons characters dataset: {df_characters.shape}')\\nprint(f'Dimensions of the Simpsons locations dataset: {df_locations.shape}')\\nprint(f'Dimensions of the Simpsons script dataset: {df_script.shape}')\\nprint(f'Dimensions of the Simpsons episodes dataset: {df_episodes.shape}')\",\"Initial overview of the data\\nprint(\\\"Characters dimension: {}\\\".format(df_characters.shape))\\nprint(\\\"Locations dimension: {}\\\".format(df_locations.shape))\\nprint(\\\"Script dimension: {}\\\".format(df_script.shape))\\nprint(\\\"Episodes dimension: {}\\\".format(df_episodes.shape))\",\"Show dimensions of data tables\\ndf_characters.shape, df_locations.shape, df_script.shape, df_episodes.shape\",\" Get first look of the simpsons script dataframe\\nprint(\\\"DataFrame Dimension (Rows, Columns):\\\", df_script.shape)\\nprint(\\\"\\\\nDataFrame Columns:\\\\n\\\", df_script.columns)\\ndf_script.head()\",\"Print dimensions of DataFrames\\nprint('Characters:\\\\t', df_characters.shape)\\nprint('Locations:\\\\t', df_locations.shape)\\nprint('Script:\\\\t\\\\t', df_script.shape)\\nprint('Episodes:\\\\t', df_episodes.shape)\",\" display the dimensions of the dataframes\\nprint(df_characters.shape, df_locations.shape, df_script.shape, df_episodes.shape)\",\"View dimensions of dataframes\\nprint('Characters :', df_characters.shape)\\nprint('Locations :', df_locations.shape)\\nprint('Lines :', df_script.shape)\\nprint('Episodes :', df_episodes.shape)\",\"View dimensions of the various data frames\\nprint(df_characters.shape)\\nprint(df_locations.shape)\\nprint(df_script.shape)\\nprint(df_episodes.shape)\",\"Display the dimensions of each dataframe\\nprint(\\\"Characters:\\\", df_characters.shape)\\nprint(\\\"Locations:\\\", df_locations.shape)\\nprint(\\\"Script lines:\\\", df_script.shape)\\nprint(\\\"Episodes:\\\", df_episodes.shape)\",\"Checking dataframes dimensions\\nprint('Dimensions characters:', df_characters.shape)\\nprint('Dimensions locations:', df_locations.shape)\\nprint('Dimensions script:', df_script.shape)\\nprint('Dimensions episodes:', df_episodes.shape)\",\"Display the dimensions of each table in the dataset\\nprint(\\\"Dimensions of characters table: \\\", df_characters.shape)\\nprint(\\\"Dimensions of locations table: \\\", df_locations.shape)\\nprint(\\\"Dimensions of script table: \\\", df_script.shape)\\nprint(\\\"Dimensions of episodes table: \\\", df_episodes.shape)\",\"Display main dataframes dimensions\\nprint(\\\"Characters df dimensions : {}\\\".format(df_characters.shape))\\nprint(\\\"Locations df dimensions : {}\\\".format(df_locations.shape))\\nprint(\\\"Script df dimensions: {}\\\".format(df_script.shape))\\nprint(\\\"Episodes df dimensions: {}\\\".format(df_episodes.shape))\"],\"marker\":{\"opacity\":0.5,\"size\":5},\"mode\":\"markers+text\",\"name\":\"152_Dimensions of Dataset Tables\",\"text\":[\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\"],\"textfont\":{\"size\":12},\"x\":[2.130742073059082,2.9499785900115967,2.326277494430542,1.0544260740280151,1.718104362487793,1.6657695770263672,2.089747905731201,1.7804584503173828,1.4260873794555664,1.185620665550232,1.8844600915908813,1.9413820505142212,1.9692909717559814,1.5376085042953491,1.448327660560608,2.304565191268921,1.974353551864624,2.2694082260131836,2.227093458175659,1.3062931299209595,1.768572211265564,2.162320852279663],\"y\":[-1.6502132415771484,-1.9680125713348389,-1.9604625701904297,-0.5598593950271606,-1.5229072570800781,-1.1942050457000732,-1.8228940963745117,-1.7896270751953125,-1.468566656112671,-1.4522299766540527,-1.651814579963684,-1.8219215869903564,-1.2803572416305542,-1.0484164953231812,-1.6737695932388306,-1.7462807893753052,-1.8498778343200684,-1.8501681089401245,-1.4983400106430054,-1.6404798030853271,-1.2051646709442139,-1.7597576379776],\"type\":\"scattergl\"},{\"hoverinfo\":\"text\",\"hovertext\":[\"Ensure matplotlib uses the 'seaborn-bright' style\\nplt.style.use('seaborn-bright')\",\"Configuro los estilos de los gr\\u00e1ficos\\nmatplotlib.style.use('seaborn-bright')\",\"\\n# Plots configuration\\nplt.style.use('seaborn')\",\"Set seaborn style for matplotlib plots\\nplt.style.use('seaborn')\",\"Set Seaborn aesthetics\",\" Set the style of the the plot\\nmatplotlib.style.use('seaborn-whitegrid')\",\"sns.set(style=\\\"darkgrid\\\")\",\"Set the style of the visualization\\nmatplotlib.style.use('seaborn-muted')\",\"# Set seaborn aesthetic parameters to defaults\\nsns.set()\",\"sns.set()\",\"Setting the style\\nplt.style.use('seaborn')\",\"# Value decomposition expansion over time by use of the scatterplot\\nplt.scatter(lambda x: x, emmys, plt.style.use('seaborn-deep', lambda x: x))\",\"# Data visualization\\nimport seaborn as sns\",\"Visualizing Data\\n# Setting up themes\\nplt.style.use('seaborn-whitegrid')\",\" optional: run seaborn theme set\\nimport seaborn as sns\\nsns.set()\",\" Set default style for plots\\nplt.style.use('seaborn')\",\"# Setting the style of the visualizations\\nplt.style.use('seaborn')\",\"Set seaborn style for our plots\\nmatplotlib.style.use('seaborn')\",\"Set seaborn aesthetic parameters to defaults\\nimport seaborn as sns\\nsns.set()\",\"Use the default theme\\nplt.style.use('seaborn')\",\"optional: using Seaborn for better plot styling\\nimport seaborn as sns\",\"Set a custom color palette for Seaborn and matplotlib\\nplt.rcParams['axes.prop_cycle'] = plt.cycler(color=plt.cm.tab10.colors)\"],\"marker\":{\"opacity\":0.5,\"size\":5},\"mode\":\"markers+text\",\"name\":\"153_Seaborn Aesthetics and Plot Styles\",\"text\":[\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\"],\"textfont\":{\"size\":12},\"x\":[21.098512649536133,20.97355079650879,20.61709213256836,20.550710678100586,20.145912170410156,20.6978759765625,19.76002311706543,20.709753036499023,19.756019592285156,19.542909622192383,20.146032333374023,8.049649238586426,20.368051528930664,20.60674476623535,19.772567749023438,20.189476013183594,20.62319564819336,20.718303680419922,19.965749740600586,20.140291213989258,20.290943145751953,21.078899383544922],\"y\":[5.097160339355469,5.485813140869141,5.720045566558838,5.256948947906494,5.287786483764648,5.191267967224121,5.801849365234375,5.256758689880371,5.484505653381348,5.373658657073975,5.7121124267578125,10.054250717163086,5.424590110778809,5.261982440948486,5.3515496253967285,5.349886417388916,5.506638526916504,5.190442085266113,5.443023204803467,5.475142955780029,5.557628154754639,4.704298496246338],\"type\":\"scattergl\"},{\"hoverinfo\":\"text\",\"hovertext\":[\"Show the first few lines of the table to get an idea of the data present.\",\"Print the number of lines in each of the tables\",\"Display the first few rows of each table to get an idea of the data\",\" CHeck first few rows of each table\",\"Inspecting first few records\",\"Display the first few lines of each table to get an idea of the data\",\"Checking the first 5 rows in the table\",\"Check the first 5 lines of the content for each table\",\"Check top 5 rows\",\"Print the schema and first few rows of each table\",\"Show the results of the first table.\",\"Check all the tables first 5 rows\",\"Check the first row\",\"Display a node like: 'Number of rows & columns in each table'\",\"Let's check the first rows of each table\",\" Show the first few rows of each table\",\" Print out the first couple of values from each table to get an understanding of the data.\",\"Check the first few rows of each table\",\"Checking the first 5 records\",\" Display the first few lines of each table to get a sense of the data\",\"Checking the first few rows\",\"Checking the first few rows.\"],\"marker\":{\"opacity\":0.5,\"size\":5},\"mode\":\"markers+text\",\"name\":\"154_Checking the first few rows of each table\",\"text\":[\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\"],\"textfont\":{\"size\":12},\"x\":[12.833351135253906,12.771578788757324,13.04359245300293,12.850296974182129,13.143531799316406,12.7712984085083,13.1466703414917,12.863715171813965,13.108017921447754,12.776474952697754,12.620698928833008,13.144089698791504,13.170801162719727,12.764579772949219,13.14868450164795,12.814899444580078,12.891847610473633,12.799145698547363,13.341773986816406,12.910406112670898,12.846433639526367,13.005119323730469],\"y\":[-1.7284224033355713,-2.0996484756469727,-2.527104139328003,-3.372250556945801,-3.816416025161743,-2.1250815391540527,-3.973173141479492,-3.272430896759033,-4.333677768707275,-2.169750690460205,-2.3884570598602295,-3.792113780975342,-3.5182342529296875,-2.2937207221984863,-3.207848072052002,-2.6543445587158203,-2.1147823333740234,-3.386105537414551,-4.3761162757873535,-2.3021609783172607,-3.863835334777832,-2.9484870433807373],\"type\":\"scattergl\"},{\"hoverinfo\":\"text\",\"hovertext\":[\"Check out the contents of these DataFrames\\nprint('Characters:')\\ndisplay(df_characters.head())\\nprint('Locations:')\\ndisplay(df_locations.head())\\nprint('Script:')\\ndisplay(df_script.head())\\nprint('Episodes:')\\ndisplay(df_episodes.head())\",\"Show some basic information about the datasets\\nprint('Characters')\\ndisplay(df_characters.head())\\nprint('Locations')\\ndisplay(df_locations.head())\\nprint('Script')\\ndisplay(df_script.head())\\nprint('Episodes')\\ndisplay(df_episodes.head())\",\" Display snippets of each dataframe\\nprint(\\\"\\\\nSimpsons characters dataframe\\\")\\ndisplay(df_characters.head())\\nprint(\\\"\\\\nSimpsons locations dataframe\\\")\\ndisplay(df_locations.head())\\nprint(\\\"\\\\nSimpsons script dataframe\\\")\\ndisplay(df_script.head())\\nprint(\\\"\\\\nSimpsons episodes dataframe\\\")\\ndisplay(df_episodes.head())\",\"Display available data\\nprint(\\\"Characters\\\")\\ndisplay(df_characters.head(5))\\nprint(\\\"Locations\\\")\\ndisplay(df_locations.head(5))\\nprint(\\\"Script\\\")\\ndisplay(df_script.head(5))\\nprint(\\\"Episodes\\\")\\ndisplay(df_episodes.head(5))\",\"Display basic information about the datasets\\nprint('Characters')\\ndisplay(df_characters.head())\\nprint('Locations')\\ndisplay(df_locations.head())\\nprint('Script')\\ndisplay(df_script.head())\\nprint('Episodes')\\ndisplay(df_episodes.head())\",\"Check the datasets\\nprint(\\\"Characters:\\\")\\ndisplay(df_characters.head())\\n\\nprint(\\\"Locations:\\\")\\ndisplay(df_locations.head())\\n\\nprint(\\\"Script:\\\")\\ndisplay(df_script.head())\\n\\nprint(\\\"Episodes:\\\")\\ndisplay(df_episodes.head())\",\" Visualize available datasets\\nprint(\\\"Characters:\\\")\\ndisplay(df_characters.head(3))\\nprint(\\\"Locations:\\\")\\ndisplay(df_locations.head(3))\\nprint(\\\"Script:\\\")\\ndisplay(df_script.head(3))\\nprint(\\\"Episodes:\\\")\\ndisplay(df_episodes.head(3))\",\"Show a small preview of the dataframes\\nprint('--- Characters ---')\\ndisplay(df_characters.head())\\nprint('\\\\n\\\\n--- Locations ---')\\ndisplay(df_locations.head())\\nprint('\\\\n\\\\n--- Script ---')\\ndisplay(df_script.head())\\nprint('\\\\n\\\\n--- Episodes ---')\\ndisplay(df_episodes.head())\",\"Quick overview of the data\\nprint(\\\"Characters:\\\")\\ndisplay(df_characters.head())\\n\\nprint(\\\"Locations:\\\")\\ndisplay(df_locations.head())\\n\\nprint(\\\"Script:\\\")\\ndisplay(df_script.head())\\n\\nprint(\\\"Episodes:\\\")\\ndisplay(df_episodes.head())\",\"Preview the datasets\\nprint(\\\"\\\\nPreview of 'simpsons_characters.csv'\\\")\\nprint(df_characters.head())\\nprint(\\\"\\\\nPreview of 'simpsons_locations.csv'\\\")\\nprint(df_locations.head())\\nprint(\\\"\\\\nPreview of 'simpsons_script_lines.csv'\\\")\\nprint(df_script.head())\\nprint(\\\"\\\\nPreview of 'simpsons_episodes.csv'\\\")\\nprint(df_episodes.head())\",\" Display some general information about the dataframes\\nprint(\\\"Characters\\\")\\ndisplay(df_characters.head())\\nprint(\\\"Locations\\\")\\ndisplay(df_locations.head())\\nprint(\\\"Script\\\")\\ndisplay(df_script.head())\\nprint(\\\"Episodes\\\")\\ndisplay(df_episodes.head())\",\" Display available datasets\\nprint('Characters:')\\ndisplay(df_characters.head())\\nprint('\\\\nLocations:')\\ndisplay(df_locations.head())\\nprint('\\\\nScript:')\\ndisplay(df_script.head())\\nprint('\\\\nEpisodes:')\\ndisplay(df_episodes.head())\",\" Display available data files\\nprint(f'Characters:')\\ndisplay(df_characters.head(2))\\nprint(f'Locations:')\\ndisplay(df_locations.head(2))\\nprint(f'Script:')\\ndisplay(df_script.head(2))\\nprint(f'Episodes:')\\ndisplay(df_episodes.head(2))\",\"Check data samples\\nprint(\\\"Characters:\\\")\\ndisplay(df_characters.sample(5))\\n\\nprint(\\\"Locations:\\\")\\ndisplay(df_locations.sample(5))\\n\\nprint(\\\"Script lines:\\\")\\ndisplay(df_script.sample(5))\\n\\nprint(\\\"Episodes:\\\")\\ndisplay(df_episodes.sample(5))\",\"Get an overview of the dataset\\nprint('\\u003e\\u003e\\u003e DataFrame Characters')\\ndisplay(df_characters.head())\\nprint('\\\\n')\\nprint('\\u003e\\u003e\\u003e DataFrame Locations')\\ndisplay(df_locations.head())\\nprint('\\\\n')\\nprint('\\u003e\\u003e\\u003e DataFrame Script')\\ndisplay(df_script.head())\\nprint('\\\\n')\\nprint('\\u003e\\u003e\\u003e DataFrame Episodes')\\ndisplay(df_episodes.head())\",\" Take a look at the first few records of each dataset\\nprint(\\\"Characters\\\")\\ndisplay(df_characters.head())\\n\\nprint(\\\"Locations\\\")\\ndisplay(df_locations.head())\\n\\nprint(\\\"Script\\\")\\ndisplay(df_script.head())\\n\\nprint(\\\"Episodes\\\")\\ndisplay(df_episodes.head())\",\"Inspect the content of each of these dataframes\\nprint(\\\"Characters\\\")\\ndisplay(df_characters.head())\\n\\nprint(\\\"Locations\\\")\\ndisplay(df_locations.head())\\n\\nprint(\\\"Script\\\")\\ndisplay(df_script.head())\\n\\nprint(\\\"Episodes\\\")\\ndisplay(df_episodes.head())\",\"Explore the dataset\\n# Display all the dataframes in a user friendly manner\\nprint(\\\"Characters\\\")\\ndisplay(df_characters.head(5))\\nprint(\\\"Locations\\\")\\ndisplay(df_locations.head(5))\\nprint(\\\"Script\\\")\\ndisplay(df_script.head(5))\\nprint(\\\"Episodes\\\")\\ndisplay(df_episodes.head(5))\",\" Display available dataframes in the dataset\\nprint('Characters:')\\ndisplay(df_characters.head(2))\\nprint('Locations:')\\ndisplay(df_locations.head(2))\\nprint('Scripts:')\\ndisplay(df_script.head(2))\\nprint('Episodes:')\\ndisplay(df_episodes.head(2))\",\"Print the characters, locations, and script DataFrames\\nprint('Characters DataFrame')\\ndisplay(df_characters.head())\\n\\nprint('Locations DataFrame')\\ndisplay(df_locations.head())\\n\\nprint('Script DataFrame')\\ndisplay(df_script.head())\\n\\nprint('Episodes DataFrame')\\ndisplay(df_episodes.head())\",\" Display our imported data\\nprint('Characters')\\ndisplay(df_characters.head(3))\\nprint('Locations')\\ndisplay(df_locations.head(3))\\nprint('Episodes')\\ndisplay(df_episodes.head(3))\\nprint('Script')\\ndisplay(df_script.head(3))\",\"Inspect the structure and contents of the dataframes\\nprint('Characters:')\\ndisplay(df_characters.head())\\n\\nprint('Locations:')\\ndisplay(df_locations.head())\\n\\nprint('Script:')\\ndisplay(df_script.head())\\n\\nprint('Episodes:')\\ndisplay(df_episodes.head())\"],\"marker\":{\"opacity\":0.5,\"size\":5},\"mode\":\"markers+text\",\"name\":\"155_Exploring and Visualizing Datasets related to Characters, Locations, Script, and Episodes\",\"text\":[\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\"],\"textfont\":{\"size\":12},\"x\":[-1.4363622665405273,-0.7993249297142029,-1.6003996133804321,-1.4285719394683838,-0.6470935940742493,-1.3944565057754517,-0.9689885377883911,-1.0439815521240234,-1.2396427392959595,-1.0673824548721313,-1.1690675020217896,-0.9193677306175232,-0.7682196497917175,-1.3290244340896606,-0.7809360027313232,-1.1980751752853394,-1.6511858701705933,-1.4393333196640015,-1.549432396888733,-0.8878928422927856,-1.588923692703247,-1.8199639320373535],\"y\":[3.1340973377227783,2.822704553604126,3.5931477546691895,3.0359413623809814,2.7128708362579346,2.5181078910827637,3.2820255756378174,3.511915445327759,2.6999306678771973,2.582904100418091,3.123263120651245,3.1874494552612305,2.7216055393218994,2.854828119277954,3.2936906814575195,3.1234395503997803,2.936577558517456,3.3211357593536377,3.075303554534912,3.27947735786438,2.719923496246338,3.1809146404266357],\"type\":\"scattergl\"},{\"hoverinfo\":\"text\",\"hovertext\":[\" View the first few rows of the characters dataframe\\ndf_characters.head()\",\" Viewing the first few rows of the characters dataframe\\ndf_characters.head()\",\"View the first few rows of the characters dataframe\\ndf_characters.head()\",\"View the first few rows of the characters DataFrame\\ndf_characters.head()\",\" View the first few rows of the characters dataframe\\ndf_characters.head()\",\"View first few rows of characters dataframe\\ndf_characters.head()\",\"# View the first few rows of the characters dataframe\\ndf_characters.head()\",\"View the first few rows of the characters dataframe\\ndf_characters.head()\",\"View the first few rows of the characters dataframe\\ndf_characters.head()\",\" View the first few rows of the characters dataframe\\ndf_characters.head()\",\"View the first few rows of the characters dataframe\\ndf_characters.head()\",\" View the first few rows of the characters DataFrame\\ndf_characters.head()\",\"View the first few rows of the characters DataFrame\\ndf_characters.head()\",\"View the first few rows of the characters dataframe\\ndf_characters.head()\",\" View the first few rows of the characters DataFrame\\ndf_characters.head()\",\"View the first few rows of the characters DataFrame\\ndf_characters.head()\",\"View the first few columns of the characters DataFrame\\ndf_characters.head()\",\"View the first few rows of the characters dataframe\\ndf_characters.head()\",\"View columns and first few rows of characters dataframe\\ndf_characters.head()\",\"View the first few rows of the characters DataFrame\\ndf_characters.head()\",\"View the first few rows of the characters dataframe\\ndf_characters.head()\"],\"marker\":{\"opacity\":0.5,\"size\":5},\"mode\":\"markers+text\",\"name\":\"156_View first few rows of characters dataframe\",\"text\":[\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\"],\"textfont\":{\"size\":12},\"x\":[-0.4991813600063324,-0.5275329947471619,-0.6391401290893555,-1.0810071229934692,-0.6494967341423035,-0.631754994392395,-0.9395402669906616,-0.7640265226364136,-0.6288470029830933,-0.9955008029937744,-0.6171648502349854,-0.7124055624008179,-0.6843714714050293,-0.9858194589614868,-0.8395410180091858,-0.8279484510421753,0.12575778365135193,-0.5996870994567871,-0.8316001296043396,-0.9372739791870117,-0.9929168820381165],\"y\":[19.633638381958008,19.464923858642578,19.907438278198242,19.693096160888672,19.755434036254883,19.823930740356445,19.908435821533203,19.43121337890625,19.84752082824707,19.90033721923828,19.596769332885742,19.498985290527344,19.78263282775879,19.93568229675293,19.833120346069336,19.615108489990234,19.257640838623047,19.68009376525879,19.557491302490234,19.646366119384766,19.885087966918945],\"type\":\"scattergl\"},{\"hoverinfo\":\"text\",\"hovertext\":[\"Display the first few rows of the dataset\\ndf_characters.head()\",\" Display the first few rows of the characters dataset\\ndf_characters.head()\",\"## Displaying the first rows of the characters dataset\\ndf_characters.head()\",\"Display the first few rows of the character dataset\\ndf_characters.head()\",\" Show the first few characters of the main datasets\\ndf_script.head()\",\"Show the first few rows of the characters data\\ndf_characters.head()\",\"Display the first few rows of the characters dataset\\ndf_characters.head()\",\"Print the first few records of the characters dataset\\ndf_characters.head()\",\" Show first rows of the characters dataset\\ndf_characters.head()\",\" Display the first few records of the characters dataset\\ndf_characters.head()\",\" Display the first few rows of the characters dataset\\ndf_characters.head()\",\"Optional: Display first few rows of the datasets\\ndf_characters.head()\",\"View first few rows of the characters dataset\\ndf_characters.head()\",\"Display the first few rows of the characters dataset\\ndf_characters.head()\",\"Show the first few rows of the characters dataset\\ndf_characters.head()\",\"Display the first few records of the characters dataset\\ndf_characters.head()\",\"Display the first few rows of the character dataset\\ndf_characters.head()\",\"Show the first rows of the characters dataset\\ndf_characters.head()\",\"Display the first few rows of the characters dataset\\ndf_characters.head()\",\" Show the first rows of the characters dataset\\ndf_characters.head()\",\" Display the first few records of the characters dataset\\ndf_characters.head()\"],\"marker\":{\"opacity\":0.5,\"size\":5},\"mode\":\"markers+text\",\"name\":\"157_Displaying first few records of a dataset\",\"text\":[\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\"],\"textfont\":{\"size\":12},\"x\":[1.9189027547836304,1.637923240661621,2.000821590423584,1.5108295679092407,2.0690598487854004,1.2983115911483765,1.6184223890304565,0.44918185472488403,1.784721851348877,0.7296227812767029,1.3986722230911255,2.687182903289795,1.4802383184432983,1.677210807800293,1.7907555103302002,0.780956506729126,1.5010627508163452,2.116666078567505,1.7284932136535645,2.1413214206695557,0.8055081367492676],\"y\":[16.366031646728516,16.286367416381836,16.58822250366211,16.34865951538086,16.032922744750977,17.05014991760254,16.342124938964844,16.711423873901367,15.902573585510254,16.39717674255371,16.21540069580078,16.05712127685547,17.05554962158203,16.363258361816406,16.223066329956055,16.214252471923828,16.41427230834961,16.029296875,16.279476165771484,16.076993942260742,16.34720802307129],\"type\":\"scattergl\"},{\"hoverinfo\":\"text\",\"hovertext\":[\"ill the missing values in the DataFrame\",\"Statistics and missing values count for all DataFrames\",\"Inspect data types and missing values\",\"Visualize missing data\",\"Inspect the structure of the data and look for inconsistencies and missing values.\",\"Check missing values in the dataframes\",\" Check for missing values\",\"Inspect the dataframes, check for missing values, etc.\",\"Check duplicates and missing data in each dataframe\",\"Visualize missing values\",\"Checking for missing values in our data.\",\" Check for and handle missing values\",\" Visualize missing values as a matrix\",\"Visualize the missing values in the dataframes\\nimport missingno as msno\",\"Visualizing the missing values in the dataframe\",\"Inspect data types and missing values in the scripts dataset\",\"Visualize the missing data\\nimport missingno as msno\",\" Checking for script dataset duplicate and missing values\",\"Visualizing missing values in the data\",\"Check for missing values\",\"Check for missing values in the dataset\"],\"marker\":{\"opacity\":0.5,\"size\":5},\"mode\":\"markers+text\",\"name\":\"158_Checking for Missing Values in Data\",\"text\":[\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\"],\"textfont\":{\"size\":12},\"x\":[7.72733736038208,6.944982051849365,9.537525177001953,11.616392135620117,9.604952812194824,7.619349002838135,8.704948425292969,8.491642951965332,8.260185241699219,10.667884826660156,9.204778671264648,8.775834083557129,11.068090438842773,7.504082202911377,7.794968128204346,8.361350059509277,10.945893287658691,7.8286662101745605,11.571369171142578,8.511195182800293,8.232645034790039],\"y\":[0.18052728474140167,0.20656242966651917,0.30188798904418945,-0.1882636398077011,-0.014185081236064434,0.061323828995227814,0.18861790001392365,-0.9920535087585449,-0.4710424244403839,0.07710236310958862,0.5210962295532227,0.5328441858291626,-0.042831942439079285,-0.010235832072794437,-0.1285119205713272,-0.13952641189098358,0.052655138075351715,0.5761470198631287,-0.021124333143234253,0.5638304948806763,0.6021936535835266],\"type\":\"scattergl\"},{\"hoverinfo\":\"text\",\"hovertext\":[\"Quick look at the data\",\" Quick overview of the data\",\"Information about the data.\",\" Look at the data\",\"Quick Look at the Data\",\"Quick exploration of the data\",\"Quick peek at the data\",\"Looking at the data\",\"The data came from Kaggle and is, to the best of my knowledge, a cleaned version of the original one.\",\"\\\"\\\"\\\"Look at the data.\\\"\\\"\\\"\",\"Data overview\",\" Let's get an overview of the data\",\" Quick look at the data\",\"Data overview\",\"Looking at the data\",\"Look at the data\",\"Some Quick Overviews\",\" Spotless data ;)\",\"Quick overlook of the data\",\"This data was made available by Alexandru Papiu and we can find this data in kaggle community.\",\"Quick spot check into data.\"],\"marker\":{\"opacity\":0.5,\"size\":5},\"mode\":\"markers+text\",\"name\":\"159_Quick overview of cleaned Kaggle data by Alexandru Papiu\",\"text\":[\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\"],\"textfont\":{\"size\":12},\"x\":[16.266599655151367,16.658645629882812,16.00696563720703,15.880793571472168,16.534488677978516,16.228439331054688,16.41375732421875,15.746810913085938,15.32181453704834,15.719721794128418,16.132848739624023,16.1610164642334,16.471643447875977,16.084243774414062,15.702157020568848,15.881316184997559,16.58664894104004,15.805012702941895,16.0960693359375,17.122783660888672,15.853364944458008],\"y\":[-1.368470311164856,-1.2630579471588135,-0.8774941563606262,-0.7252278327941895,-1.044816017150879,-0.7925166487693787,-0.9752205610275269,-0.40884512662887573,0.19141729176044464,-0.3921144902706146,-0.46419841051101685,-0.863466203212738,-1.3424980640411377,-0.08728592097759247,-0.5720992088317871,-0.6458735466003418,-1.7985085248947144,-0.4178667366504669,-1.0428056716918945,-1.7426859140396118,-0.8635014295578003],\"type\":\"scattergl\"},{\"hoverinfo\":\"text\",\"hovertext\":[\"limiting number of rows is generally a good practice in data exploration\\npd.options.display.max_rows = 10\",\"Set this option to see all rows\\npd.set_option('display.max_rows', 500)\",\"Set maximum row and column display\\npd.set_option('display.max_rows', 1000)\\npd.set_option('display.max_columns', 1000)\",\"Set maximum display columns for easier visualization\\npd.set_option('display.max_columns', 500)\",\"optional\\npd.set_option('display.max_rows', 300)\",\"Limit the maximal number of columns displayed to 50\\npd.set_option('display.max_columns', 50)\",\"Set params\\npd.set_option('display.max_columns', 500)\\npd.set_option('display.max_rows', 500)\\ntqdm.pandas()\",\"Set the max displayed columns to 100 and the rows to 50\",\"limit the number of lines being displayed\\npd.options.display.max_rows = 10\",\"Display settings for the number of columns and rows\\npd.set_option('display.max_columns', 500)\\npd.set_option('display.max_rows', 500)\",\"Set the max row display\\npd.set_option('display.max_row', 1000)\",\"Set number of rows to be displayed in the output\\npd.set_option('display.max_rows', 1000)\",\"# Display up to 50 characters\\npd.set_option('display.max_rows', 50)\",\"limits the number of different items in a list\",\"Enable large screen support\\npd.set_option('display.max_rows', 500)\",\"SOME_DISPLAY = 5\",\" Display max 500 columns\\u002frows\\npd.set_option('display.max_columns', 500)\\npd.set_option('display.max_rows', 500)\",\" Display new max rows\\npd.set_option('display.max_rows', 500)\",\"Set pd to print 100 columns max\\npd.set_option('display.max_columns', 100)\",\"Limit number of rows to display to make the data more manageable\\npd.options.display.max_rows = 10\",\"Set max display columns\\npd.set_option('display.max_columns', 500)\"],\"marker\":{\"opacity\":0.5,\"size\":5},\"mode\":\"markers+text\",\"name\":\"160_Set max display limits for rows and columns\",\"text\":[\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\"],\"textfont\":{\"size\":12},\"x\":[23.566184997558594,23.886690139770508,24.01424789428711,23.913833618164062,23.909000396728516,23.631269454956055,23.227989196777344,23.51032257080078,22.865127563476562,24.123626708984375,23.695207595825195,23.68672752380371,24.076812744140625,22.09851837158203,24.020233154296875,23.43776512145996,23.67490577697754,23.794944763183594,23.934791564941406,23.25365447998047,24.054216384887695],\"y\":[0.15308059751987457,-0.0016481727361679077,0.45817914605140686,0.04922202602028847,0.3375745713710785,-0.013664478436112404,0.5111352205276489,0.12439267337322235,-0.0754522904753685,0.6741486191749573,0.16918377578258514,0.029400547966361046,0.7786768674850464,-0.3222790062427521,0.683201014995575,0.19840842485427856,0.3427870273590088,0.25093764066696167,-0.12228527665138245,0.09342534095048904,-0.29553547501564026],\"type\":\"scattergl\"},{\"hoverinfo\":\"text\",\"hovertext\":[\"Show the first few rows of each DataFrame to understand its structure and information.\",\"Display the first few rows of the dataframe to understand the structure of the data.\",\"Optional: Display the first few rows of each dataframe to understand the data structure.\",\"Display the first few rows of each dataframe to understand its structure and the type of data it contains.\",\"Display the first few rows of each dataframe to understand its structure and the kind of data we're working with.\",\"Displays the first few rows of the dataframe to understand the structure of the dataframe.\",\" Display the first few rows of each dataframe to understand its structure and the available columns.\",\"Display the first few rows of each dataframe to understand its structure and what kind of data it contains\",\" Display the first few rows of each dataframe to understand its structure and data\",\" Display the first dataframe to understand the structure of the data.\",\"Display the top 10 rows of each dataframe to understand their structure and data\",\"Optional: Display the first few rows of each dataframe to understand their structure and contents.\",\"Display first few rows of each dataframe to understand structure and contents\",\"Display the first few rows of each dataframe to understand its structure.\",\" Display the first few rows of each dataframe to understand their structure and contents.\",\" Display the first few rows of each dataframe to understand their structure and contents.\",\"Displays the first few rows of the dataframe to inspect its structure and content.\",\"Display the top rows of each dataframe to understand the structure of the data.\",\"Display the first few rows of each dataframe to understand their structure and contents.\",\"Display the first few rows of each dataframe to understand its structure and contents.\",\" Show top few rows of each dataframe to understand the structure of the data.\"],\"marker\":{\"opacity\":0.5,\"size\":5},\"mode\":\"markers+text\",\"name\":\"161_Understanding DataFrame Structure and Contents\",\"text\":[\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\"],\"textfont\":{\"size\":12},\"x\":[11.500126838684082,11.111540794372559,11.16531753540039,11.066915512084961,11.114181518554688,11.029837608337402,11.491634368896484,11.38267707824707,11.65401840209961,11.192800521850586,12.134291648864746,11.24881649017334,11.265656471252441,11.548627853393555,11.053634643554688,11.286284446716309,11.271014213562012,12.005553245544434,11.173286437988281,11.115736961364746,11.91620922088623],\"y\":[-8.779826164245605,-8.83800220489502,-9.152668952941895,-8.76955795288086,-8.629667282104492,-9.270248413085938,-9.48823356628418,-8.515066146850586,-8.74223518371582,-8.077221870422363,-7.58551549911499,-9.348607063293457,-9.459637641906738,-8.793540000915527,-9.267308235168457,-9.342491149902344,-9.406109809875488,-6.835646152496338,-9.168482780456543,-9.238252639770508,-7.439104080200195],\"type\":\"scattergl\"},{\"hoverinfo\":\"text\",\"hovertext\":[\" Reverse episodes index so it matches the script pd (by date)\",\" Set index Episode and Processed text for df_script\",\"Setting the episode_id as index for querying\",\"Set the index of the episodes dataframe to use the episode_id as index\",\"Set the index of your dataframe to be the column episode_id if it's not already the case.\",\"Create an index for each episode\\ndf_episodes.set_index('id', inplace=True)\",\"Set a proper index for the episode DataFrame, as the plot will rely on it\",\"Set the episode ID as the index to make lookups easier\\ndf_script.set_index('episode_id', inplace=True)\",\"Fixing the index of episodes due to the duplicate indexes\",\"Set up the episods' index as integer\",\" Set index of episodes to 'id' for faster searching.\",\"Add an index to episodes dataframe\",\"Fix the index of the episodes' dataframe after concatenating the test and training data.\",\"Set index for faster filtering\\ndf_episodes.set_index('id', inplace=True)\\ndf_script.set_index('episode_id', inplace=True)\",\"Reset the index for episodes to ensure all indexes are unique\\ndf_episodes.reset_index(inplace=True)\",\"define UTC dates and reset index for simpsons_episodes if not done previously\",\" Set index of episodes to be the same as in the other two files\",\"Inspected the first values of each dataframe in search for the 'elusive' episode_id.\",\"Setting index on the episodes dataframe\",\"Using the index as the ID for each entity, i.e., character, location, and episode.\",\" set index to episode_id for easier access\\ndf_episodes = df_episodes.set_index('id')\"],\"marker\":{\"opacity\":0.5,\"size\":5},\"mode\":\"markers+text\",\"name\":\"162_Indexing and Resetting in DataFrame\",\"text\":[\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\"],\"textfont\":{\"size\":12},\"x\":[4.525151252746582,3.871873140335083,5.0972819328308105,4.304747104644775,3.908655881881714,3.5137743949890137,3.912165641784668,3.7137291431427,4.378773212432861,4.639345169067383,4.533145904541016,3.884643077850342,4.359279155731201,3.2602455615997314,3.8383536338806152,5.0141191482543945,4.838074684143066,3.9366261959075928,4.056404113769531,5.7807135581970215,3.5284993648529053],\"y\":[3.4539175033569336,3.918675184249878,2.976116895675659,3.271402359008789,3.6480021476745605,3.802278518676758,3.401843309402466,4.158703327178955,3.179048538208008,2.572040557861328,3.0808732509613037,3.463951349258423,3.2109251022338867,3.7341227531433105,3.6798880100250244,3.2514758110046387,3.3166146278381348,3.7830843925476074,3.1354317665100098,2.5081048011779785,3.777298927307129],\"type\":\"scattergl\"},{\"hoverinfo\":\"text\",\"hovertext\":[\"Filter the script to only keep the lines with characters and locations available in their respective datasets\",\"Limiting the script dataset to only the scenes taking place in a location.\",\"Clean the script (remove noisy data and keep only dialogues)\",\"Select only the parts of the script with at least two words.\",\" Limit the script data to only containing the main characters\",\" Filter out the script lines that are between the major characters, and keep only the ones that are in between locations.\",\"Removing script lines which are not associated with any speaking character.\",\"filter out script entries that dont have an associated location or character\",\"Filter out the script lines in locations.\",\"Remove 'blacklisted' or special characters from the script lines\",\"Filter the lines with locations\",\" Select the unique lines with dialogues from all scripts and drop missing values\",\"Filtering the scripts with null information and multiple characters\",\"For a selected subset of characters, extract a subset of the scripts only containing dialogs of these characters\",\"Only include the parts of the script that have been spoken by a character.\",\"Selecting scripts from the most frequently occurring characters and locations\",\"Remove script lines that have not spoken by characters and locations that are not known.\",\"Filter empty script lines\",\"Optional: Remove all production- and location-related script lines (scenes, songs, technical annotations, ...).\",\"Filter out the script with no character_id.\",\"Filter the locations to keep only the ones present in the script lines dataset.\"],\"marker\":{\"opacity\":0.5,\"size\":5},\"mode\":\"markers+text\",\"name\":\"163_Script Filtering and Extraction\",\"text\":[\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\"],\"textfont\":{\"size\":12},\"x\":[9.025103569030762,9.39809513092041,9.976207733154297,9.493170738220215,9.48157024383545,9.31624698638916,9.552197456359863,9.158123970031738,9.493682861328125,9.960846900939941,9.734395980834961,9.288612365722656,9.456613540649414,9.165423393249512,8.985746383666992,9.597994804382324,9.635445594787598,9.662671089172363,10.055353164672852,8.95869255065918,9.32651138305664],\"y\":[3.863973617553711,3.408518075942993,4.026115417480469,4.869715690612793,4.441686630249023,3.970362424850464,4.788110256195068,4.231793403625488,3.906494617462158,4.4571428298950195,3.959343671798706,3.9692490100860596,4.2364935874938965,4.4820170402526855,4.811144828796387,4.59600830078125,4.611828327178955,4.183321952819824,4.1249871253967285,4.9405341148376465,3.4978978633880615],\"type\":\"scattergl\"},{\"hoverinfo\":\"text\",\"hovertext\":[\"pd.set_option('display.max_columns', None)\",\"Don't worry about the lines below, as they're only effecting how the backend works and nothing for you to worry about.\\npd.options.display.max_columns = None  # Make sure we can see all of the columns\",\"pd.set_option('display.max_columns', None)\",\"pd.set_option('max_columns', None)\",\"pd.set_option(\\\"display.max_columns\\\", None)\",\" extended information to usersupport uniterrupted work.\\npd.set_option('display.max_columns', None)\",\"pd.set_option('display.max_columns', None)\",\"Display max columns at pd\\npd.set_option('display.max_columns', None)\",\"\\npd.set_option('display.max_columns', None)\",\"pd.set_option('display.max_columns', None)\",\"pd.set_option('display.max_columns', None)\",\"pd.set_option('display.max_columns', None)\",\"pd.set_option('display.max_columns', None)\",\"pd.set_option('display.max_columns', None)\",\"pd.set_option('display.max_columns', None)\",\"Display options\\npd.set_option('display.max_columns', None)\",\"Set\\npd.set_option('display.max_columns', None)\",\"pd.set_option('display.max_columns', None)\",\"pd.set_option('display.max_columns', None)\",\"pd.set_option('display.max_columns', None)\",\"pd.set_option('display.max_columns', None)\"],\"marker\":{\"opacity\":0.5,\"size\":5},\"mode\":\"markers+text\",\"name\":\"164_Display options and extended information in pandas set_option() function\",\"text\":[\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\"],\"textfont\":{\"size\":12},\"x\":[25.05600929260254,25.288021087646484,25.090452194213867,25.36391258239746,24.934993743896484,24.692100524902344,25.05375099182129,24.772174835205078,25.330408096313477,25.252878189086914,25.165327072143555,25.10237693786621,25.041034698486328,25.031702041625977,24.98268699645996,24.81760597229004,24.925819396972656,24.872440338134766,25.095108032226562,24.986597061157227,24.821269989013672],\"y\":[-2.011855125427246,-1.6954916715621948,-2.1901943683624268,-2.424919366836548,-2.2704615592956543,-1.356410264968872,-2.2132339477539062,-1.5691163539886475,-2.2435290813446045,-2.140321731567383,-2.1399295330047607,-1.9109537601470947,-1.993043303489685,-2.0301761627197266,-2.144124746322632,-1.6210771799087524,-1.6512832641601562,-1.9041460752487183,-2.1162917613983154,-1.8868240118026733,-2.0806772708892822],\"type\":\"scattergl\"},{\"hoverinfo\":\"text\",\"hovertext\":[\" Display the first few rows of each dataframe to understand the data\\nprint(df_characters.head())\\nprint(df_locations.head())\\nprint(df_script.head())\\nprint(df_episodes.head())\",\" Display the first few characters of the dataframes\\ndisplay(df_characters.head())\\ndisplay(df_locations.head())\\ndisplay(df_script.head())\\ndisplay(df_episodes.head())\",\"Sanity check: show the first rows of each dataframe\\ndisplay(df_characters.head())\\ndisplay(df_locations.head())\\ndisplay(df_script.head())\\ndisplay(df_episodes.head())\",\"Setting the print to display the first 3 rows by default\\nprint(df_characters.head(3))\\nprint(df_locations.head(3))\\nprint(df_script.head(3))\\nprint(df_episodes.head(3))\",\" Display the first few rows of each dataframe to understand their structure and contents\\ndisplay(df_characters.head())\\ndisplay(df_locations.head())\\ndisplay(df_script.head())\\ndisplay(df_episodes.head())\",\"Display the first few rows of each dataframe\\ndisplay(df_characters.head())\\ndisplay(df_locations.head())\\ndisplay(df_script.head())\\ndisplay(df_episodes.head())\",\"# Show first rows of the datasets\\ndisplay(df_characters.head())\\ndisplay(df_locations.head())\\ndisplay(df_script.head())\\ndisplay(df_episodes.head())\",\" Displaying the first rows of the dataframe\\nprint('Characters')\\ndisplay(df_characters.head())\\nprint('Locations')\\ndisplay(df_locations.head())\\nprint('Script')\\ndisplay(df_script.head())\\nprint('Episodes')\\ndisplay(df_episodes.head())\",\" Display the first few rows of each dataframe to understand its structure\\nprint(\\\"Characters\\\")\\ndisplay(df_characters.head())\\n\\nprint(\\\"Locations\\\")\\ndisplay(df_locations.head())\\n\\nprint(\\\"Script\\\")\\ndisplay(df_script.head())\\n\\nprint(\\\"Episodes\\\")\\ndisplay(df_episodes.head())\",\"display the first few rows of each dataframe\\ndisplay(df_characters.head())\\ndisplay(df_locations.head())\\ndisplay(df_script.head())\\ndisplay(df_episodes.head())\",\" Show the first 3 rows of all datasets\\ndisplay(df_characters.head(3))\\ndisplay(df_locations.head(3))\\ndisplay(df_script.head(3))\\ndisplay(df_episodes.head(3))\",\"Display the first few rows of each dataframe to understand its structure and content\\nprint('Characters')\\ndisplay(df_characters.head())\\nprint('Locations')\\ndisplay(df_locations.head())\\nprint('Script')\\ndisplay(df_script.head())\\nprint('Episodes')\\ndisplay(df_episodes.head())\",\"Display the first few records of each DataFrame to understand its structure\\nprint(\\\"Simpsons Characters DataFrame\\\")\\ndisplay(df_characters.head())\\n\\nprint(\\\"Simpsons Locations DataFrame\\\")\\ndisplay(df_locations.head())\\n\\nprint(\\\"Simpsons Script DataFrame\\\")\\ndisplay(df_script.head())\\n\\nprint(\\\"Simpsons Episodes DataFrame\\\")\\ndisplay(df_episodes.head())\",\" Display the first few rows of each dataframe\\ndisplay(df_characters.head())\\ndisplay(df_locations.head())\\ndisplay(df_script.head())\\ndisplay(df_episodes.head())\",\"display first few rows of each table\\ndisplay(df_characters.head())\\ndisplay(df_locations.head())\\ndisplay(df_script.head())\\ndisplay(df_episodes.head())\",\"# Display the first few rows of each dataframe\\ndisplay(df_characters.head())\\ndisplay(df_locations.head())\\ndisplay(df_script.head())\\ndisplay(df_episodes.head())\",\"Show the first few rows of each dataframe\\ndisplay(df_characters.head())\\ndisplay(df_locations.head())\\ndisplay(df_script.head())\\ndisplay(df_episodes.head())\",\"Display the first few rows of each dataframe to understand their structure\\nprint('Characters:')\\ndisplay(df_characters.head())\\n\\nprint('Locations:')\\ndisplay(df_locations.head())\\n\\nprint('Script:')\\ndisplay(df_script.head())\\n\\nprint('Episodes:')\\ndisplay(df_episodes.head())\",\"# Show first rows of the characters, locations, and script dataframes\\nprint(df_characters.head())\\nprint(df_locations.head())\\nprint(df_script.head())\",\"Display the first few rows of each dataframe to get an idea of their contents\\nprint(\\\"characters.csv\\\")\\ndisplay(df_characters.head())\\n\\nprint(\\\"\\\\nlocations.csv\\\")\\ndisplay(df_locations.head())\\n\\nprint(\\\"\\\\nscript_lines.csv\\\")\\ndisplay(df_script.head())\\n\\nprint(\\\"\\\\nepisodes.csv\\\")\\ndisplay(df_episodes.head())\",\" Display the first few rows of each dataframe\\n# print(\\\"\\\\n\\\\nFirst few rows of each dataframe:\\\")\\n# print(df_characters.head())\\n# print(df_locations.head())\\n# print(df_script.head())\\n# print(df_episodes.head())\"],\"marker\":{\"opacity\":0.5,\"size\":5},\"mode\":\"markers+text\",\"name\":\"165_Displaying dataframes\",\"text\":[\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\"],\"textfont\":{\"size\":12},\"x\":[-2.9425880908966064,-2.7831594944000244,-2.8486995697021484,-2.4279637336730957,-3.097991704940796,-2.607471227645874,-2.4626822471618652,-2.4508087635040283,-2.2507877349853516,-2.690838098526001,-2.847385883331299,-2.3358325958251953,-1.963830828666687,-2.5440163612365723,-2.6356141567230225,-2.5821290016174316,-2.896531581878662,-2.503776788711548,-2.430556297302246,-2.6758437156677246,-2.7052483558654785],\"y\":[5.49453592300415,5.393352031707764,5.57857084274292,5.46525764465332,5.806013107299805,5.426482677459717,5.330854415893555,5.555346965789795,5.44632625579834,5.6177802085876465,6.129795551300049,5.370866298675537,5.826336860656738,5.525663375854492,5.957922458648682,5.203031063079834,5.323747634887695,5.409553527832031,6.174466609954834,5.706587791442871,5.699623107910156],\"type\":\"scattergl\"},{\"hoverinfo\":\"text\",\"hovertext\":[\"\\nimport nltk\\nnltk.download('punkt')\",\"Instanciating a list of stopwords to be removed from the scripts\",\"List of stopwords\\nimport nltk\\nnltk.download('stopwords')\\nfrom nltk.corpus import stopwords\\nstop_words = set(stopwords.words('english'))\",\" Text preprocessing\\nimport re\\nimport string\\n\\nimport nltk\\n\\nfrom nltk.corpus import stopwords, wordnet\\nfrom nltk.tokenize import word_tokenize\\nfrom nltk.stem import WordNetLemmatizer\\n\\n# Download required resources\\nnltk.download('punkt')\\nnltk.download('stopwords')\\nnltk.download('wordnet')\",\"#\\u00a0List of stopwords\\nstopwords = spacy.lang.en.stop_words.STOP_WORDS\",\" Add extra data to stopwords. These words will be ignored in the analysis.\",\"Get the list of stopwords from Spacy.\",\"Create a generic stop words list to remove common words from our text analysis\\nstop_words = [\\\"i\\\", \\\"me\\\", \\\"my\\\", \\\"myself\\\", \\\"we\\\", \\\"our\\\", \\\"ours\\\", \\\"ourselves\\\", \\\"you\\\", \\\"your\\\", \\\"yours\\\", \\\"yourself\\\", \\\"yourselves\\\", \\\"he\\\", \\\"him\\\", \\\"his\\\", \\\"himself\\\", \\\"she\\\", \\\"her\\\", \\\"hers\\\", \\\"herself\\\", \\\"it\\\", \\\"its\\\", \\\"itself\\\", \\\"they\\\", \\\"them\\\", \\\"their\\\", \\\"theirs\\\", \\\"themselves\\\", \\\"what\\\", \\\"which\\\", \\\"who\\\", \\\"whom\\\", \\\"this\\\", \\\"that\\\", \\\"these\\\", \\\"those\\\", \\\"am\\\", \\\"is\\\", \\\"are\\\", \\\"was\\\", \\\"were\\\", \\\"be\\\", \\\"been\\\", \\\"being\\\", \\\"have\\\", \\\"has\\\", \\\"had\\\", \\\"having\\\", \\\"do\\\", \\\"does\\\", \\\"did\\\", \\\"doing\\\", \\\"a\\\", \\\"an\\\", \\\"the\\\", \\\"and\\\", \\\"but\\\", \\\"if\\\", \\\"or\\\", \\\"because\\\", \\\"as\\\", \\\"until\\\", \\\"while\\\", \\\"of\\\", \\\"at\\\", \\\"by\\\", \\\"for\\\", \\\"with\\\", \\\"about\\\", \\\"against\\\", \\\"between\\\", \\\"into\\\", \\\"through\\\", \\\"during\\\", \\\"before\\\", \\\"after\\\", \\\"above\\\", \\\"below\\\", \\\"to\\\", \\\"from\\\", \\\"up\\\", \\\"down\\\", \\\"in\\\", \\\"out\\\", \\\"on\\\", \\\"off\\\", \\\"over\\\", \\\"under\\\", \\\"again\\\", \\\"further\\\", \\\"then\\\", \\\"once\\\", \\\"here\\\", \\\"there\\\", \\\"when\\\", \\\"where\\\", \\\"why\\\", \\\"how\\\", \\\"all\\\", \\\"any\\\", \\\"both\\\", \\\"each\\\", \\\"few\\\", \\\"more\\\", \\\"most\\\", \\\"other\\\", \\\"some\\\", \\\"such\\\", \\\"no\\\", \\\"nor\\\", \\\"not\\\", \\\"only\\\", \\\"own\\\", \\\"same\\\", \\\"so\\\", \\\"than\\\", \\\"too\\\", \\\"very\\\", \\\"s\\\", \\\"t\\\", \\\"can\\\", \\\"will\\\", \\\"just\\\", \\\"don\\\", \\\"should\\\", \\\"now\\\"]\",\"Use the NLTK library to download the stopwords data\\nimport nltk\\nnltk.download('stopwords')\",\"tokenization by nltk and punctuation removal\\nimport nltk\\nfrom nltk.corpus import stopwords\\nfrom nltk.tokenize import word_tokenize, sent_tokenize\\nnltk.download('stopwords')\\nnltk.download('punkt')\\nstop_words = set(stopwords.words('english'))\",\"Declare the file path to the stopwords file\\nstopwords_file = \\\"stopwords.txt\\\"\",\"# Stopwords in the English language\\nimport nltk\\nnltk.download('stopwords')\",\"Import stop words from NLTK\",\"Define stop words and punctuation to be excluded from analysis\\nstop_words = spacy.lang.en.stop_words.STOP_WORDS\\npunctuations = spacy.lang.en.punctuation.PUNCT_PREFIXES\",\" A famous collection of stopwords\\nfrom nltk.corpus import stopwords\",\" Set of stopwords found in Spacy for english language\\nspacy_stopwords = spacy.lang.en.stop_words.STOP_WORDS\",\"Unload all the NLTK stopwords\\nimport nltk\\nfrom nltk.corpus import stopwords\\n\\n#nltk.download('stopwords')\\n\\nstopwords = set(stopwords.words('english'))\",\"from stop_words import get_stop_words\",\" Set the environment variable for NLTK data file\",\"Setting up the wordcloud stopwords\\nfrom wordcloud import STOPWORDS\\n\\nnlp = spacy.load('en')\\nstop_words = spacy.lang.en.STOP_WORDS # getting spacy's stop words\\nstop_words |= STOPWORDS # using the union operator to combine the stop words\",\"Remove common words that are called \\\"stop words\\\", such as 'the', 'a', 'an', 'in', etc.\"],\"marker\":{\"opacity\":0.5,\"size\":5},\"mode\":\"markers+text\",\"name\":\"166_stopwords and tokenization in nltk\",\"text\":[\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\"],\"textfont\":{\"size\":12},\"x\":[13.89887523651123,13.169647216796875,13.091130256652832,13.399161338806152,13.394978523254395,13.269500732421875,13.54698657989502,12.785493850708008,13.286529541015625,13.207923889160156,13.088226318359375,13.445417404174805,13.431800842285156,13.657519340515137,13.400131225585938,13.736536979675293,13.268147468566895,12.937230110168457,14.406271934509277,13.531617164611816,13.249885559082031],\"y\":[6.158905029296875,6.337124347686768,6.2603325843811035,6.225193500518799,6.863002777099609,6.367856025695801,6.998641490936279,6.2262959480285645,5.9696946144104,6.397089958190918,5.90431022644043,6.2308526039123535,5.73134708404541,6.939128398895264,5.579013824462891,7.457499980926514,6.31405782699585,6.043551445007324,5.654999256134033,7.55471658706665,6.530399322509766],\"type\":\"scattergl\"},{\"hoverinfo\":\"text\",\"hovertext\":[\"Sample the data to get a sense of what's in it\\ndf_script.sample(10)\",\" Load sample script lines\\ndf_script.sample(10)\",\"rsample 10% of script\\ndf_script = df_script.sample(frac=0.1, random_state=0)\",\" Sample the dataset\\nsample_size = 10000\\n\\ndf_script = df_script.sample(sample_size)\",\"\\ndf_script.sample(10)\",\"Create new dataframe with a fraction of the script lines for testing\\ndf_script_test = df_script.sample(frac=0.1, replace=True, random_state=1)\\n\\n# Save \\\"name\\\" and \\\"line\\\" columns to separate variables for testing\\ntest_names = df_script_test.name.values\\ntest_lines = df_script_test.raw_text.values\",\" Grabs a random sample from the dataframe\\nsample_line = df_script.sample()\",\"Visualise 5 random rows of script dataset\\ndf_script.sample(5)\",\" Sample the dataset\\ndf_script.sample(10)\",\"Sample the dataframe to understand its structure\\ndf_script.sample(10)\",\" Display some sampling of the data\\ndf_script.sample(5)\",\"Inspect a few rows\\ndf_script.sample(5, random_state=20)\",\" Print dfs to see sample data and how they look\",\" Optional:\\ndf_script = df_script.sample(frac=0.1)\",\"Select few random rows for a visual inspection\\ndf_script.sample(10)\",\"suffle the data\\ndf_script = df_script.sample(frac=1, random_state=0)\",\"View a sample\\nprint(df_script.sample(5))\",\"Create a sample of the dataframe\\ndf_script_sample = df_script.sample(n=1000, random_state=0)\",\"Displaying 10 random rows from the script dataframe\\ndf_script.sample(10)\",\"Set interim sampling levels\\nn = 10000\\nfrac = n \\u002f len(df_script)\"],\"marker\":{\"opacity\":0.5,\"size\":5},\"mode\":\"markers+text\",\"name\":\"167_Sampling Techniques in Data Analysis\",\"text\":[\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\"],\"textfont\":{\"size\":12},\"x\":[7.343501567840576,6.897884845733643,8.235881805419922,8.540549278259277,7.426180362701416,8.140003204345703,8.15054988861084,8.29798698425293,7.359003067016602,7.458512783050537,7.714158535003662,8.461801528930664,7.054387092590332,7.891790390014648,8.43325424194336,8.405168533325195,7.237240314483643,8.945250511169434,8.33165168762207,8.73758602142334],\"y\":[-3.3945465087890625,-3.4815456867218018,-2.4258012771606445,-2.5357048511505127,-2.834319829940796,-2.3127458095550537,-2.7840042114257812,-3.0197813510894775,-2.8013997077941895,-3.433164596557617,-3.3480587005615234,-2.7995569705963135,-3.411097526550293,-2.6231842041015625,-3.2910099029541016,-2.185546636581421,-3.5491836071014404,-2.2664401531219482,-2.8720483779907227,-2.6564602851867676],\"type\":\"scattergl\"},{\"hoverinfo\":\"text\",\"hovertext\":[\"Return the first 5 rows of the characters DataFrame\\ndf_characters.head()\",\"Show the first 5 rows of the characters dataframe\\ndf_characters.head()\",\"Show the first 5 characters of the characters dataframe\\ndf_characters.head()\",\"Show the first 5 rows of the characters dataframe\\ndf_characters.head()\",\"Show the first 5 rows of the df_characters dataframe\\ndf_characters.head()\",\"the first 5 rows of the characters dataframe\\ndf_characters.head()\",\"Show the first 5 rows of the characters dataframe\\ndf_characters.head()\",\" Example: Show the first 5 rows of the characters dataframe\\ndf_characters.head()\",\"Show the first 5 rows of the characters dataframe\\ndf_characters.head()\",\" Show the first 5 rows of the characters dataframe\\ndf_characters.head()\",\" Show the first 5 rows of the characters dataframe\\ndf_characters.head()\",\"Show first 5 rows of the dataframe 'df_characters'\\ndf_characters.head()\",\"Show the first 5 rows of the characters dataframe\\ndf_characters.head()\",\"Show the first 5 rows of \\\"df_characters\\\" dataframe\\ndf_characters.head()\",\" Show the first 5 characters in the characters dataframe\\ndf_characters.head()\",\"Show the first 5 rows of the characters DataFrame\\ndf_characters.head()\",\"Show the first 5 rows of the characters dataframe\\ndf_characters.head()\",\" Show the first 5 rows of the characters dataframe\\ndf_characters.head()\",\" Show first 5 rows of the characters dataframe\\ndf_characters.head()\",\"Show the first 5 rows of the characters dataframe\\ndf_characters.head()\"],\"marker\":{\"opacity\":0.5,\"size\":5},\"mode\":\"markers+text\",\"name\":\"168_Showing first 5 rows of df_characters dataframe\",\"text\":[\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\"],\"textfont\":{\"size\":12},\"x\":[-2.715162992477417,-1.9743032455444336,-2.607344150543213,-2.049912929534912,-2.1595325469970703,-1.7084282636642456,-2.1445016860961914,-2.1876120567321777,-1.8944642543792725,-1.776665210723877,-2.2491633892059326,-2.447416305541992,-2.0726516246795654,-2.380211353302002,-2.642387866973877,-1.8927407264709473,-2.0540902614593506,-1.970302939414978,-2.237868070602417,-1.9885817766189575],\"y\":[14.271329879760742,14.731141090393066,14.212651252746582,14.538216590881348,14.459877967834473,14.062969207763672,14.454543113708496,14.897817611694336,14.509367942810059,14.669143676757812,14.87621784210205,14.824350357055664,14.59162425994873,14.588189125061035,14.109798431396484,14.549430847167969,14.577387809753418,14.423524856567383,14.709283828735352,14.644209861755371],\"type\":\"scattergl\"},{\"hoverinfo\":\"text\",\"hovertext\":[\"Set index for fast access\",\"Setting the index to use for the DataFrames\",\" Set the index of each dataframe to be the unique identifier\",\"Change the index of each dataframe to the index of the respective dataframe\",\"Set the first column as the index in all DataFrames for easier access\",\"creating index for the original dataframes\",\"Create Indexers for each Dataframe\",\"Set index for every dataframe\",\"Ensure identical index for all the dataframes\",\"Set the index for each dataframe to be the unique identifier for each entry\",\" Set the dataframe's index to the `id` column, these ids will then be used to link data in the other dataframes\",\"Set the index on the de-serialized dataframes\",\"We can set the index of each dataframe to the id for faster access.\",\"Set the index of the dataframes to match the ID of the columns in the dataset\",\" Set the index of the DataFrames appropriately\",\"Setting index on the dataframes\",\"Ensure dataframes are sorted by index\",\"Set index of DataFrames for optimization\",\" Change the index of the dataframes\",\"Process data.frames and set index if necessary\"],\"marker\":{\"opacity\":0.5,\"size\":5},\"mode\":\"markers+text\",\"name\":\"169_Setting Index in DataFrames for Easier Access\",\"text\":[\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\"],\"textfont\":{\"size\":12},\"x\":[7.623882293701172,7.058816432952881,6.233285903930664,6.710427761077881,7.151636123657227,6.627624988555908,6.446594715118408,6.415239334106445,6.321221828460693,6.376902103424072,6.29528284072876,6.440662860870361,6.601818561553955,6.527780055999756,6.783246994018555,6.962713718414307,6.831077575683594,6.936522960662842,7.281335830688477,6.74755859375],\"y\":[1.7733790874481201,0.652562141418457,1.6609747409820557,0.7696477770805359,1.0109931230545044,1.0641306638717651,0.9247004985809326,1.0127081871032715,0.9981905817985535,1.3979240655899048,1.1107676029205322,0.8343105316162109,1.4742761850357056,1.2331844568252563,0.9311723113059998,0.9885795712471008,0.6043030023574829,0.8157527446746826,0.9621025323867798,1.0466374158859253],\"type\":\"scattergl\"},{\"hoverinfo\":\"text\",\"hovertext\":[\"Set some pandas options for printing and set the random seed for reproducibility.\",\"Set the seed for reproducibility\\nnp.random.seed(0)\",\" Set seeds for numpy and python to keep results consistent\\nnp.random.seed(42)\\nPYTHONHASHSEED = 0\",\"Set the random seed for reproducibility\\nnp.random.seed(0)\",\"# Set the seed for reproducibility\\nnp.random.seed(0)\",\"Set the seed for reproducibility\\nnp.random.seed(0)\",\" Set the seed for reproducibility\\nnp.random.seed(0)\",\"Set the seed for reproducibility\\nnp.random.seed(0)\",\"Set the seed for reproducibility\\nnp.random.seed(0)\",\"\\n# Set the seed for reproducibility\\nnp.random.seed(0)\",\"Setting the Seed\\nnp.random.seed(0)\",\"Make the models deterministic\\nspacy.util.fix_random_seed(0)\\nnp.random.seed(0)\",\"# Set random seed for reproducibility\\nnp.random.seed(0)\",\" Ensure reproducibility\\nnp.random.seed(0)\",\"# Set seed for reproducibility\\nnp.random.seed(1)\",\"For reproducibility\\nnp.random.seed(0)\",\"# Set seed for reproducibility\\nnp.random.seed(0)\",\"# Set numpy random seed for reproducibility\\nnp.random.seed(0)\",\"Set the seed for reproducibility\\nnp.random.seed(0)\",\"Set the random seed for reproducibility\\nnp.random.seed(0)\"],\"marker\":{\"opacity\":0.5,\"size\":5},\"mode\":\"markers+text\",\"name\":\"170_Set random seed for reproducibility\",\"text\":[\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\"],\"textfont\":{\"size\":12},\"x\":[29.455411911010742,29.728260040283203,30.015209197998047,30.227344512939453,29.586475372314453,29.90559196472168,29.98832893371582,29.909608840942383,29.75234031677246,29.84612274169922,30.385896682739258,30.400741577148438,29.75929069519043,29.636018753051758,29.76075553894043,29.71537971496582,29.6204833984375,30.164390563964844,29.7547550201416,30.16813087463379],\"y\":[14.26641845703125,13.956289291381836,14.036482810974121,13.964090347290039,13.745992660522461,14.070528030395508,14.106740951538086,13.978471755981445,13.968982696533203,13.690884590148926,13.35882568359375,13.631790161132812,13.872949600219727,13.953290939331055,13.40658950805664,13.289591789245605,13.730766296386719,13.891190528869629,13.836024284362793,13.760771751403809],\"type\":\"scattergl\"},{\"hoverinfo\":\"text\",\"hovertext\":[\"Inspect the characters dataframe\\ndf_characters.head()\",\"Inspect head of characters dataframe\",\"Inspect the characters dataframe\\ndf_characters.head()\",\"Examine the contents of the character dataframe\\ndf_characters.head()\",\"Inspect characters DataFrame\\ndf_characters.head()\",\"Display the dataframes for inspection\\ndf_characters.head()\",\"Inspect the characters DataFrame\\ndf_characters.head()\",\"Inspect character dataframe\\ndf_characters.head()\",\"Inspect data frames\\ndf_characters.head()\",\"Inspect the characters dataframe\\ndf_characters.head()\",\"Inspect a sample of the characters dataframe\\ndf_characters.head()\",\"Inspect the header of the characters DataFrame\\ndf_characters.head()\",\"Inspect the head of the characters dataframe\\ndf_characters.head()\",\" Inspect the contents of the characters dataframe\\ndf_characters.head()\",\"Inspect the characters dataframe\\ndf_characters.head()\",\"Visually inspect the characters dataframe\\ndf_characters.head()\",\"inspect the contents of the characters dataframe\\ndf_characters.head()\",\"Clean the characters dataframe.\\ndf_characters.head()\",\"Inspect the character dataframe\\ndf_characters.head()\",\"Sample the characters dataframe\\ndf_characters.head()\"],\"marker\":{\"opacity\":0.5,\"size\":5},\"mode\":\"markers+text\",\"name\":\"171_Dataframe Inspection - Characters\",\"text\":[\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\"],\"textfont\":{\"size\":12},\"x\":[7.584526062011719,7.685035228729248,7.416502952575684,7.63468074798584,7.72910213470459,6.618320941925049,7.275755882263184,7.733532428741455,6.720857620239258,7.456474304199219,7.682794570922852,7.1436920166015625,7.450260639190674,7.37629508972168,7.699041843414307,7.16752815246582,7.348798751831055,7.12831974029541,7.834368705749512,7.591669082641602],\"y\":[16.3670711517334,16.819101333618164,16.292524337768555,16.65833854675293,16.746257781982422,16.800580978393555,16.632688522338867,16.63951873779297,16.140029907226562,16.465051651000977,16.53818702697754,16.76111602783203,16.74750328063965,16.272674560546875,16.304821014404297,16.885778427124023,16.714040756225586,15.589430809020996,16.35167694091797,16.345417022705078],\"type\":\"scattergl\"},{\"hoverinfo\":\"text\",\"hovertext\":[\"Display first few lines of the dataframe\\ndf_script.head()\",\" Display the first few lines of the script dataframe to understand its structure\\ndf_script.head()\",\"# Show first lines of script data\\ndf_script.head()\",\"# Display first lines of the script dataframe\\ndf_script.head()\",\"To see the first lines of each dataframe, we can run \\\"\\\"\\\"\\\"df.head()\\\"\\\"\\\"\\\" for each one\",\" Show first few example script lines\\ndf_script.head()\",\"Display the first few lines of the dataframe to inspect its structure\\ndf_script.head()\",\"Show first script lines\\ndf_script.head(3)\",\"Output the first few lines of the script dataframe\\ndf_script.head()\",\"Display the first lines of the script dataframe\\ndf_script.head()\",\"Display first few lines of the dataframe df_script\\ndf_script.head()\",\" Show the first few script lines\\ndf_script.head()\",\"Display the first few lines of the script data to understand its structure\\ndf_script.head()\",\"Display the first 3 lines of the dataframe\\ndf_script.head(3)\",\"Displaying the first lines of the script dataframe\\ndf_script.head()\",\"Show how one line of dialogue is structured\\ndf_script.head(1)\",\"Display first lines of scripts dataframe\\ndf_script.head()\",\"Show the first few lines of the script data\\ndf_script.head()\",\"\\n# Display the first few lines of the script DataFrame\\ndf_script.head()\",\" View the first few lines of the dataframe\\nprint(df_script.head())\"],\"marker\":{\"opacity\":0.5,\"size\":5},\"mode\":\"markers+text\",\"name\":\"172_Displaying and Understanding the Structure of Script Data\",\"text\":[\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\"],\"textfont\":{\"size\":12},\"x\":[3.473773956298828,3.6822056770324707,3.5987377166748047,3.712156295776367,4.138952732086182,3.9988059997558594,3.7697038650512695,3.70576548576355,3.7831406593322754,3.621339797973633,3.5563249588012695,4.104409217834473,3.9117541313171387,3.5230872631073,3.6980810165405273,4.576615810394287,3.754611015319824,3.7588212490081787,3.237908363342285,3.373729705810547],\"y\":[-7.569962978363037,-6.371269226074219,-6.672444820404053,-7.3328471183776855,-7.213306903839111,-6.272376537322998,-6.823077201843262,-6.403500080108643,-7.497042655944824,-7.2153520584106445,-7.393689155578613,-6.103972434997559,-5.915139675140381,-7.178066730499268,-7.039739608764648,-6.1359710693359375,-7.065986156463623,-6.692335605621338,-7.015751361846924,-7.151259422302246],\"type\":\"scattergl\"},{\"hoverinfo\":\"text\",\"hovertext\":[\" Checking the structure of the dataframes\",\"Inspect the structure of the dataframes\",\"Inspect the structure of the dataframes\",\"Inspect the structure of the dataframes\",\"Check DataFrame structure for each dataset\",\"Format the dataframes to ensure consistency and quality\",\" Inspect the structure of the dataframes\",\"Inspect each DataFrame and their respective columns\",\"Inspect structure of each dataframe\",\"Inspect the structure of each of the dataframes\",\" Examine the structure of these DataFrames\",\"Exploring the structure of the dataframes\",\"Checking the general structure of each dataframe\",\"Format dataframe columns and values\",\"Inspect the format and structure of the data in the dataframes\",\"Inspect the structure of some of the loaded dataframes\",\"Inspect the structure of the dataframes\",\" inspect the structures of the dataframes\",\"display the dataframes to observe the structure\",\"Inspect the structure of each dataframe\"],\"marker\":{\"opacity\":0.5,\"size\":5},\"mode\":\"markers+text\",\"name\":\"173_Inspecting structures and formats of dataframes\",\"text\":[\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\"],\"textfont\":{\"size\":12},\"x\":[10.87340259552002,11.377523422241211,11.1096773147583,11.38238525390625,10.861418724060059,7.380947589874268,11.186677932739258,11.147836685180664,11.076993942260742,11.169854164123535,11.196871757507324,10.847957611083984,10.90658187866211,9.322275161743164,10.72724437713623,11.646650314331055,11.046062469482422,11.349681854248047,10.84945011138916,11.019571304321289],\"y\":[-4.68939733505249,-4.882611274719238,-5.036645889282227,-4.695309162139893,-4.298998832702637,-0.0890614464879036,-4.980273723602295,-4.529543876647949,-5.050948143005371,-4.850188255310059,-5.287839412689209,-5.208118915557861,-4.732382297515869,-3.0341637134552,-4.322575569152832,-4.474049091339111,-4.714877605438232,-4.737412452697754,-5.56851863861084,-4.8003830909729],\"type\":\"scattergl\"},{\"hoverinfo\":\"text\",\"hovertext\":[\"Checking the head of the dataframe\",\"This will allow us to simply call head(), tail() or sample() on our dataframe instead of remembering the name of the index column.\",\"Check the head of the dataframe\",\"Checking head of each dataframe to understand the data\",\"Inspect dataframes head\",\"Displays the head of the dataframes to understand how the data looks like\",\"Checking the head of the dataframe\",\"List the head of each dataframe\",\" Display the head of each dataframe to verify data was loaded correctly\",\" Display the head of each dataframe, by calling the head() function on each dataframe.\",\"Checking the data shape and head of each dataframe\",\"Display the dimensions and the head of the dataframes\",\"Inspect the head of each dataframe to understand the data\",\"Displaying the dataframe head as well as the metadata of each dataframe\",\"Visualize the dataframe elements using head()\",\"View dataframes headers\",\"Print the head of the first dataframe to inspect the structure and data\",\" Displaying a simple head of the dataframes\",\" Sample the data by printing the head of each dataframe\",\"Display the head of each dataframe to quickly check if the import was successful\"],\"marker\":{\"opacity\":0.5,\"size\":5},\"mode\":\"markers+text\",\"name\":\"174_Inspecting dataframe headers\",\"text\":[\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\"],\"textfont\":{\"size\":12},\"x\":[8.49724006652832,7.215272426605225,8.207539558410645,8.888967514038086,8.34422492980957,8.424135208129883,8.28229808807373,8.539690971374512,9.106574058532715,8.166305541992188,9.540873527526855,8.20979118347168,8.913806915283203,8.35826587677002,7.496548652648926,9.001599311828613,8.534173965454102,8.196683883666992,8.958072662353516,9.646053314208984],\"y\":[-4.481815814971924,0.8036527633666992,-4.369259834289551,-4.59181022644043,-4.685687065124512,-5.309580326080322,-4.381616592407227,-4.736053943634033,-4.5207390785217285,-5.060420036315918,-4.184779644012451,-4.701637268066406,-5.0873332023620605,-4.82654333114624,-5.214325904846191,-4.362053394317627,-4.937175273895264,-4.902341842651367,-4.4393229484558105,-4.064915657043457],\"type\":\"scattergl\"},{\"hoverinfo\":\"text\",\"hovertext\":[\"Let's take a look at the structure of the datasets.\",\"Let's take a look at the dimensions of the datasets.\",\"Let's take a look at the structure of the datasets.\",\" Let's take a look at the structure of the datasets.\",\"Let's take a look at the different datasets and see how they are structured.\",\"We'll see the structure of the main datasets\",\"Let's take a look at the dimensions of the datasets.\",\"We'll take a look at how the datasets are structured and which fields might be useful for our analysis.\",\"Let's take a quick look at the structure of the datasets.\",\"Let's take a quick look at the structure of the datasets.\",\" Let's take a look at the structure of the datasets.\",\"Let's take a brief look at the structure of the datasets.\",\"Let's get a feeling for the structure and information in these datasets.\",\"Let's take a look at the structure of our datasets.\",\" Let's take a look at the structure of the datasets.\",\"Let's take a look at the structure of the datasets.\",\"Let's explore the datasets first to see their structure and data types.\",\"Let's take a look at the structure of these datasets.\",\"Let's take a look at the structure of the datasets.\",\" Let's take a look at the structure of the datasets.\"],\"marker\":{\"opacity\":0.5,\"size\":5},\"mode\":\"markers+text\",\"name\":\"175_Structure of Datasets\",\"text\":[\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\"],\"textfont\":{\"size\":12},\"x\":[16.483278274536133,16.086830139160156,16.17259979248047,16.315176010131836,16.300065994262695,15.895825386047363,16.05842399597168,16.524869918823242,16.049497604370117,16.022436141967773,16.401058197021484,15.954773902893066,16.172529220581055,16.529945373535156,16.207048416137695,16.341527938842773,15.842056274414062,16.146656036376953,16.10763931274414,16.43537139892578],\"y\":[-4.60280704498291,-4.083367347717285,-4.570952892303467,-4.617607593536377,-4.8967742919921875,-4.404200553894043,-4.3169989585876465,-4.051203727722168,-4.148430824279785,-4.090020656585693,-4.607156276702881,-4.365128517150879,-3.894742250442505,-4.307358264923096,-4.552411079406738,-4.5135273933410645,-3.3265223503112793,-3.8564820289611816,-4.603966236114502,-4.356848239898682],\"type\":\"scattergl\"},{\"hoverinfo\":\"text\",\"hovertext\":[\"Show the first few rows of the characters dataframe\\ndf_characters.head()\",\"Show first few rows of the characters dataframe\\ndf_characters.head()\",\" Show the first few rows of the characters dataframe\\ndf_characters.head()\",\" Show the first few rows of the characters dataframe\\ndf_characters.head()\",\"Show the first few rows of the characters dataframe\\ndf_characters.head()\",\"Show the first few rows of the characters dataframe\\ndf_characters.head()\",\"Show the first few rows of the characters dataframe\\ndf_characters.head()\",\"Show the first few rows of the 'df_characters' DataFrame\\ndf_characters.head()\",\"Show the first few rows of the characters dataframe\\ndf_characters.head()\",\"Show the first few rows of the characters dataframe\\ndf_characters.head()\",\"Show the first few rows of the characters dataframe\\ndf_characters.head()\",\" Show first few rows of characters dataframe\\ndf_characters.head()\",\"Show the first few rows of the characters DataFrame\\ndf_characters.head()\",\"Show the first few rows of the dataframe df_characters\\ndf_characters.head()\",\"Show first few rows of characters dataframe\\ndf_characters.head()\",\"Show the first few rows of the characters dataframe\\ndf_characters.head()\",\" Show the first few rows of the characters dataframe\\ndf_characters.head()\",\"Show the first few rows of characters dataframe\\ndf_characters.head()\",\"Show the first few rows of the characters dataframe\\ndf_characters.head()\",\"Show first few rows of the characters dataframe\\ndf_characters.head()\"],\"marker\":{\"opacity\":0.5,\"size\":5},\"mode\":\"markers+text\",\"name\":\"176_Extracting first few rows of the characters dataframe\",\"text\":[\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\"],\"textfont\":{\"size\":12},\"x\":[-11.334115982055664,-11.374288558959961,-11.322118759155273,-10.995546340942383,-10.92536449432373,-11.080134391784668,-11.164525032043457,-11.105825424194336,-11.113847732543945,-11.123908996582031,-10.96562385559082,-11.266274452209473,-11.208731651306152,-11.292373657226562,-11.158729553222656,-11.391883850097656,-11.075035095214844,-11.258398056030273,-11.305906295776367,-11.18931770324707],\"y\":[0.6514379382133484,1.1283999681472778,0.6113169193267822,0.5880864858627319,0.8041237592697144,0.6286023259162903,0.5502690672874451,1.042689561843872,0.9286707639694214,0.6778927445411682,0.5092170238494873,1.3749468326568604,0.5357232093811035,0.6993937492370605,1.2925662994384766,0.9004786014556885,0.886848509311676,0.7408270835876465,0.8314779996871948,1.2985540628433228],\"type\":\"scattergl\"},{\"hoverinfo\":\"text\",\"hovertext\":[\"Show the first few lines of the dataframe containing the script lines\",\"Display first 5 rows of the script dataframe.\",\"Print the first 5 rows of the script dataframe.\",\" Display the first 5 lines of the dataframe containing the script lines.\",\"Show the first few rows of the dataframe containing all script lines\",\"Shows the first few rows of the script dataframe.\",\" Display the first few rows of the dataframe containing the script lines.\",\" Import the data from 'simpsons_script_lines.csv' into a pandas DataFrame and display the first 5 rows.\",\" Display the first 5 rows of the dataframe containing the script lines.\",\"Display the first 10 rows of the dataframe of script lines.\",\"Show the first rows of scripts data.\",\"Display the first few lines of the script dataframe and metadata about the datasets\",\" Display the first 5 rows of the dataframe containing the script lines.\",\" Show the first 5 elements of the script DataFrame.\",\"Display the first few rows of the dataframe containing script lines\",\"Display the first few rows of the dataframe containing the script lines.\",\"Select only the first 20 lines from the script dataset to avoid memory errors\",\"Show first 5 rows of the dataframe for the script of the Simpsons\",\"Display the first few rows of the table containing the script lines.\"],\"marker\":{\"opacity\":0.5,\"size\":5},\"mode\":\"markers+text\",\"name\":\"177_Displaying the First Few Rows of a Pandas DataFrame containing Script Lines\",\"text\":[\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\"],\"textfont\":{\"size\":12},\"x\":[4.5893635749816895,2.919123411178589,2.7220616340637207,3.3233461380004883,3.845651149749756,3.790956974029541,3.9627017974853516,2.4531304836273193,3.2201950550079346,3.490260124206543,4.188363552093506,4.882648468017578,3.0341899394989014,2.8856608867645264,3.9782283306121826,3.983053684234619,4.2310614585876465,2.8564720153808594,4.76174783706665],\"y\":[-2.6380813121795654,-3.5208792686462402,-4.062657356262207,-3.3010315895080566,-2.5806407928466797,-3.0411148071289062,-2.7387828826904297,-3.80727481842041,-3.2534828186035156,-3.1179909706115723,-2.262061834335327,-2.783867120742798,-3.156628131866455,-3.453896999359131,-2.64670729637146,-2.6519525051116943,-2.037888288497925,-3.9224631786346436,-1.8092139959335327],\"type\":\"scattergl\"},{\"hoverinfo\":\"text\",\"hovertext\":[\"Check that the datasets have been correctly loaded\",\" Checking the structure of the loaded datasets\",\"id we loaded all the datasets correctly?\",\"Check the dataset is correctly loaded\",\"Loading datasets\",\"Every dataset loaded successfully.\",\"begin by loading the datasets\",\"Check if we have loaded the datasets correctly\",\"Check if the dataset has been loaded correctly\",\" We can see that we're successful in loading the datasets by also calling the `.head()` function on each one of them.\",\" Load the provided datasets\",\"Consider loading only a subset of the data for performance reasons if the dataset is large.\",\" Display of loaded datasets\",\"Let's check the loaded datasets\",\"Check to see the loaded datasets look like.\",\"Checking if the datasets were loaded correctly\",\"Check if your datasets have been read correctly\",\"To_DO load all datasets and print the columns names and shapes to confirm everything was read correctly\",\"Check the loaded datasets\"],\"marker\":{\"opacity\":0.5,\"size\":5},\"mode\":\"markers+text\",\"name\":\"178_Checking if datasets have been loaded correctly\",\"text\":[\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\"],\"textfont\":{\"size\":12},\"x\":[14.240832328796387,14.630731582641602,14.863609313964844,14.27872371673584,14.123817443847656,14.758548736572266,14.88629150390625,14.413501739501953,14.599267959594727,14.77597713470459,14.409066200256348,13.34399127960205,14.802217483520508,14.748579025268555,14.601799011230469,14.664344787597656,13.666536331176758,14.129131317138672,14.531049728393555],\"y\":[0.41591155529022217,-0.7874178886413574,0.11119674891233444,0.20840077102184296,0.11040937155485153,0.5838009119033813,-0.21051613986492157,-0.218213751912117,0.08452790230512619,-0.01945129781961441,0.15811261534690857,-0.19494052231311798,-0.5612239241600037,-0.3993767201900482,0.7402750253677368,0.08863205462694168,0.14869312942028046,-0.3253175914287567,-0.17344880104064941],\"type\":\"scattergl\"},{\"hoverinfo\":\"text\",\"hovertext\":[\"Simple regularization\\ndf_script = df_script[['episode_id', 'raw_text']].groupby('episode_id').agg(lambda x: ' '.join(x)).reset_index()\",\"Store script lines by episode ID\\nepisode_script_lines = {}\\nfor episode_id, group in df_script.groupby('episode_id'):\\n    episode_script_lines[episode_id] = group['raw_text'].tolist()\",\"Create a full script from the line's dataframe and join by episode id\\ndf_episode_scripts = df_script.groupby('episode_id').apply(lambda x: ' '.join(x.speaking_line)).reset_index(name='full_script')\",\"Extract data\\ndf_char_ep_count = df_script[['character_id','episode_id']].groupby('character_id').episode_id.nunique().reset_index(name='episode_count')\\ndf_char_ep_count = df_char_ep_count[df_char_ep_count.episode_count \\u003e= 20]\\ndf_char_ep_count = df_char_ep_count.merge(df_characters, left_on='character_id', right_on='id').sort_values('episode_count', ascending=False)\",\"join transcript lines for each episode into single string\\ndf_script_grouped = df_script.groupby(by='episode_id').agg({'normalized_text': lambda x: ' '.join(x)}).reset_index(inplace=False)\\n\\nnlp = spacy.load('en')\",\"Scatter character by gender\\ngrouped_episodes = df_script.groupby('episode_id')['normalized_text'].apply(lambda x: ''.join(x)).reset_index()\\ngrouped_episodes = pd.merge(grouped_episodes, df_episodes, on='episode_id')\\n\\nspacy.prefer_gpu()\",\"Function to join lines from one chracter in one episode as a single line\\ndef dialogByCharacterAndEpisode(dataframe):\\n    dfs = dataframe.groupby(['episode_id','character_id'])['raw_text'].apply(lambda x: ' '.join(x)).reset_index()\\n    for index,row in dfs.iterrows():\\n        episode_id = row['episode_id']\\n        character_id = row['character_id']\\n        raw_text = row['raw_text']\\n        series = dataframe[(dataframe['episode_id'] == episode_id) & (dataframe['character_id'] == character_id)]['raw_text']\\n        for index, value in series.items():\\n            dataframe.at[index,'raw_text'] = raw_text\\n    dataframe.drop_duplicates(subset =['episode_id','character_id'], keep = 'last', inplace = True)\\n    return dataframe\",\"Combine the lines into single sentences in the `raw_text` column\\ndf_script_combined = df_script.groupby('episode_id')['raw_text'].apply(lambda x: ' '.join(x)).reset_index()\\ndf_script_combined.head()\",\"Add the full transcripts to the dataframe\\ndf_transcripts = df_script.groupby('episode_id').apply(lambda x: ' '.join(x['normalized_text'])).reset_index()\\ndf_transcripts.columns = ['episode_id', 'transcript']\\n\\ndf_episodes = df_episodes.set_index('id')\\ndf_episodes['full_transcript'] = df_transcripts.set_index('episode_id')\",\"# A bit of visualization\\ndf = df_script[['episode_id', 'character_id']].groupby('episode_id').count().reset_index(inplace=False)\\ndf = pd.merge(df, df_episodes[['id', 'original_air_date']], left_on='episode_id', right_on='id', how='inner')\\ndf['original_air_date'] = pd.to_datetime(df['original_air_date'])\\ndf = df.rename(columns={'character_id': 'line_count'})\\ndf[['episode_id', 'line_count']].sort_values(by='line_count', ascending=False)[:10]\",\"Aggregate both sentences and raw data by episode_id in one dataframe\\nepisodes_dialogues = pd.concat([df_script.groupby('episode_id').apply(lambda x: ' '.join(x['raw_text'])).rename('script'),\\n                                df_script.groupby('episode_id').apply(lambda x: ' '.join(x['spoken_words'].dropna())).rename('spoken_words'),\\n                                df_episodes.set_index('id')\\n                               ], axis=1, join='inner').reset_index(inplace=False)\",\"Filter out bad quality lines and join by episode_id\\ndf_script_filtered = df_script[\\n    (df_script['speaking_line'] == True)\\n    & (df_script['raw_text'].notna())\\n][['episode_id', 'raw_text']].groupby('episode_id').agg(lambda x: ' '.join(x)).reset_index()\",\"# Create a \\\"doc\\\" object for each episode script line containing annotations\\ndf_script['doc'] = list(nlp.pipe(df_script['normalized_text'], batch_size=5000))\",\" Build List of Episode Script Data\\nepisode_script_data = []\\nunique_episode_ids = df_script['episode_id'].unique()\\nfor episode_id in tqdm(unique_episode_ids, desc=\\\"Building Episode Script Data\\\"):\\n    episode_lines = df_script[df_script['episode_id'] == episode_id].sort_values(by='timestamp_in_ms')\\n    episode_lines = episode_lines.reset_index(inplace=False, drop=True)\\n    episode_script_data.append({\\n        'episode_id': episode_id,\\n        'title': episode_lines.loc[0, 'title'],\\n        'script': ' '.join([str(elem) for elem in episode_lines['normalized_text'] if pd.notnull(elem)])\\n    })\",\"Grouping by episode id and joining all lines by 'space'\\ndf_script_grouped = df_script.groupby('episode_id').apply(lambda x: ' '.join(x['normalized_text']))\\n\\n# Merging with episode ids in order to have the same ordering.\\ndf_script_grouped_pd = pd.DataFrame(df_script_grouped, columns=['script'])\\ndf_script_grouped_pd = df_script_grouped_pd.merge(df_episodes, left_index=True, right_on='id').set_index('id').sort_index()\\n\\n# Credits\\ndf_script_grouped = df_script_grouped_pd['script']\\n\\ndf_script_grouped_vc = df_script['episode_id'].value_counts().sort_index()\",\" Join all text for each row and store in the 'text' column for each data frame\\ndf_characters['text'] = df_characters['raw_character_text']\\ndf_characters = df_characters.groupby('raw_character_text').agg({'text': ' '.join}).reset_index()\\n\\ndf_locations['text'] = df_locations['normalized_location_text']\\ndf_locations = df_locations.groupby('normalized_location_text').agg({'text': ' '.join}).reset_index()\\n\\ndf_episodes['text'] = df_episodes['title']\\ndf_episodes = df_episodes.groupby('title').agg({'text': ' '.join}).reset_index()\",\" Calculate some simple statistics for each episode\\ndf_script['word_count'] = df_script['normalized_text'].apply(lambda x: len(str(x).split()))\\ndf_episodes['word_count'] = df_episodes['normalized_text'].apply(lambda x: len(str(x).split()))\\n\\ndf_episodes_stats = df_script.groupby('episode_id').agg(\\n    lines=('id', 'count'),\\n    characters=('raw_character_text', lambda x: x.nunique()),\\n    locations=('raw_location_text', lambda x: x.nunique()),\\n    average_words_per_line=('word_count', 'mean')\\n).reset_index()\\n\\n# Merge the episode statistics with the rest of the episode information\\ndf_episodes = df_episodes.merge(df_episodes_stats, on='id')\",\"Change end of line character to simulate a new paragraph\\n# Ceate a temporary column with the lines change\\ndf_script = df_script.assign(text_changed = df_script['raw_text'] + \\\"\\\\n\\\")\\n\\n# Group by episode_id and character_id to retrieve the full script of each character in a given episode\\ndf_script_episode_level = df_script.groupby(['episode_id', 'character_id']).agg({'text_changed': 'sum'}).reset_index()\\n\\n# Group by character_id to retrieve the full script of each character in the whole show\\ndf_script_character_level = df_script.groupby(['character_id']).agg({'text_changed': 'sum'}).reset_index()\",\"Join tables by episode_id and get the main characters\\ndf = pd.merge(\\n    df_script,\\n    # Get main characters per episode\\n    (\\n        df_script[df_script.raw_character_text.str.len() \\u003e 0]\\n        .groupby('episode_id')\\n        .agg({\\n            'raw_character_text':\\n            lambda x: Counter(x).most_common()[0][0]\\n        })\\n        .reset_index()\\n    ),\\n    on='episode_id'\\n)\\n\\ndf = pd.merge(\\n    df,\\n    df_episodes,\\n    on='episode_id'\\n)\"],\"marker\":{\"opacity\":0.5,\"size\":5},\"mode\":\"markers+text\",\"name\":\"179_Text aggregation and grouping in episode scripts\",\"text\":[\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\"],\"textfont\":{\"size\":12},\"x\":[4.03715705871582,4.035686016082764,3.958125352859497,4.188377380371094,4.844147682189941,3.52996563911438,3.2978017330169678,3.7344493865966797,4.132223129272461,3.278517246246338,4.753256797790527,4.307296276092529,10.961090087890625,3.1746861934661865,3.6861844062805176,3.6874847412109375,4.443739414215088,3.170107126235962,3.5829195976257324],\"y\":[7.294430732727051,6.671728134155273,7.09156608581543,7.122271537780762,7.329103469848633,6.8946661949157715,6.7682647705078125,7.213600158691406,7.173000812530518,7.2285284996032715,7.308410167694092,6.520300388336182,8.634456634521484,6.279698371887207,6.950200080871582,6.970115661621094,7.540128707885742,7.016731262207031,7.084319114685059],\"type\":\"scattergl\"},{\"hoverinfo\":\"text\",\"hovertext\":[\"Preview of the characters data file\\ndf_characters.head()\",\"Preview the characters data\\ndf_characters.head()\",\"Preview the data\\ndf_characters.head()\",\"Preview the data\\ndf_characters.head()\",\"Preview data\\ndf_characters.head()\",\"Get a preview of the characters data\\ndf_characters.head()\",\"Preview data\\ndf_characters.head()\",\"Preview the characters data\\ndf_characters.head()\",\"Preview the characters data\\ndf_characters.head()\",\"Preview data\\ndf_characters.head()\",\"Preview the data\\ndf_characters.head()\",\"Preview df_characters\\ndf_characters.head()\",\" Data preview\\ndf_characters.head()\",\"Preview data\\ndf_characters.head()\",\"Preview data\\ndf_characters.head()\",\"Preview the loaded data\\ndf_characters.head()\",\"Preview the characters data\\ndf_characters.head()\",\"Preview the characters data\\ndf_characters.head()\",\"Preview the characters data\\nprint(df_characters.head())\\n\\n# Display types and non-null values\\nprint(df_characters.info())\"],\"marker\":{\"opacity\":0.5,\"size\":5},\"mode\":\"markers+text\",\"name\":\"180_Previewing Characters' Data\",\"text\":[\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\"],\"textfont\":{\"size\":12},\"x\":[9.842361450195312,9.675971031188965,11.120521545410156,10.797873497009277,10.82026195526123,9.302915573120117,10.73486328125,9.610427856445312,9.442784309387207,11.070395469665527,10.771218299865723,10.42725944519043,11.052094459533691,10.76773452758789,10.912945747375488,10.80762004852295,9.582158088684082,9.695043563842773,8.526518821716309],\"y\":[16.79082489013672,16.70465850830078,17.715545654296875,17.48960304260254,17.45730209350586,16.76111602783203,17.533918380737305,16.808319091796875,16.84149169921875,17.61564064025879,17.206722259521484,17.21112632751465,17.311460494995117,17.308792114257812,17.369165420532227,17.474897384643555,16.929969787597656,16.772558212280273,16.537290573120117],\"type\":\"scattergl\"},{\"hoverinfo\":\"text\",\"hovertext\":[\" Set the style\\nmatplotlib.style.use('ggplot')\",\" Set the style of graphs to 'ggplot' for better visuals\\nplt.style.use('ggplot')\",\"Setting the default style\\nmatplotlib.style.use('ggplot')\",\" Set the default style for matplotlib to 'ggplot'\\nmatplotlib.style.use('ggplot')\",\"Set plot color scheme\\nmatplotlib.style.use('ggplot')\",\"Set plot style\\nmatplotlib.style.use('ggplot')\",\"Set the Style of the plots\\nmatplotlib.style.use('ggplot')\",\" Set up matplotlib style\\nmatplotlib.style.use('ggplot')\",\"Set the default style of the plots\\nmatplotlib.style.use('ggplot')\",\"Set visualization style\\nmatplotlib.style.use('ggplot')\",\"Ensure matplotlib uses the `ggplot` style\\nplt.style.use('ggplot')\",\"Setting the style of the plots\\nmatplotlib.style.use('ggplot')\",\"Show figures in this notebook\\nmatplotlib.style.use('ggplot')\",\"Setting up matplotlib style\\nplt.style.use('ggplot')\",\"Modify plot style to 'ggplot' style\\nplt.style.use('ggplot')\",\"configure matplotlib style\\nplt.style.use('ggplot')\",\"Set MATPLOTLIB to use ggplot style\\nplt.style.use('ggplot')\",\"# Manually add matplot lib to available styles\\nplt.style.use('ggplot')\",\"Image styles\\n# Matplotlib styles\\nplt.style.use('ggplot')\"],\"marker\":{\"opacity\":0.5,\"size\":5},\"mode\":\"markers+text\",\"name\":\"181_Matplotlib Style Use ggplot\",\"text\":[\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\"],\"textfont\":{\"size\":12},\"x\":[21.558801651000977,22.181385040283203,21.190353393554688,21.29297637939453,21.209394454956055,21.49449348449707,21.407875061035156,21.547401428222656,20.936580657958984,21.612512588500977,21.868091583251953,21.3305721282959,21.36459732055664,21.742229461669922,21.880897521972656,21.770883560180664,21.84801483154297,21.17742919921875,21.594161987304688],\"y\":[4.186678886413574,4.443156719207764,4.626307964324951,4.514947414398193,4.596080303192139,4.370004177093506,4.459477424621582,4.481307506561279,4.543425559997559,4.4014458656311035,4.226271629333496,4.3379669189453125,4.320067882537842,4.1683430671691895,4.246825218200684,4.087175369262695,4.368399620056152,3.9569475650787354,4.29132080078125],\"type\":\"scattergl\"},{\"hoverinfo\":\"text\",\"hovertext\":[\"inspecting each dataframe\\nprint(f\\\"Characters: {df_characters.shape[0]}\\\")\\ndf_characters.head(2)\",\"Print the head of the characters dataframe\\nprint(df_characters.head())\",\" Print the first few entries of the characters DataFrame\\nprint(f\\\"The shape of the Simpsons characters DataFrame is: {df_characters.shape}\\\")\",\"Print the head of the characters dataframe\\nprint(df_characters.head(5))\",\"Print head of characters dataframe\\ndf_characters.head()\",\"Print the character dataframe to understand the structure and contents\\nprint(df_characters.head())\",\" Print the head of the characters dataframe\\ndf_characters.head()\",\" Print the character DataFrame\\ndf_characters.head()\",\"Print the head of the characters dataframe\\ndf_characters.head()\",\"Print the head of the characters dataframe\\ndf_characters.head()\",\"Overview of characters DataFrame\\nprint(df_characters.shape)\\nprint(df_characters.head())\",\"Print the head of df_characters dataframe\\ndf_characters.head()\",\"Characters DataFrame\\nprint(\\\"Characters DataFrame\\\")\\ndf_characters.head()\",\"sample the characters dataframe\\nprint(\\\"Characters dataframe shape: \\\", df_characters.shape)\\ndf_characters.head()\",\"Print some data about the characters dataframe\\nprint(df_characters.head())\",\"Print the Characters data\\nprint(df_characters.head(5))\",\"\\nprint(df_characters.head())\",\"# Print the head of the characters dataframe\\nprint(df_characters.head())\",\"print(df_characters.head())\"],\"marker\":{\"opacity\":0.5,\"size\":5},\"mode\":\"markers+text\",\"name\":\"182_Inspecting Simpsons Character DataFrame\",\"text\":[\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\"],\"textfont\":{\"size\":12},\"x\":[5.663738250732422,4.8247199058532715,4.5315351486206055,4.716790199279785,4.8792853355407715,5.5683488845825195,4.996739864349365,5.298763751983643,4.936412334442139,4.837451457977295,5.161510467529297,4.587841033935547,4.964616298675537,5.284328460693359,5.611523628234863,4.918078899383545,5.125960350036621,5.384940147399902,5.118775367736816],\"y\":[15.009218215942383,16.556015014648438,14.5563325881958,16.361534118652344,16.833065032958984,16.40962028503418,16.66768455505371,16.367568969726562,16.84603500366211,16.9292049407959,15.958047866821289,16.582748413085938,16.04090690612793,15.420720100402832,16.224489212036133,15.776688575744629,16.339805603027344,16.256017684936523,16.459701538085938],\"type\":\"scattergl\"},{\"hoverinfo\":\"text\",\"hovertext\":[\"Remove invalid entries from the dataset\\ndf_script = df_script[df_script['timestamp_in_ms'].notna()]\\ndf_script = df_script[df_script['character_id'].notna()]\\ndf_script = df_script[df_script['location_id'].notna()]\",\" Remove potential corrupted data\\ndf_script = df_script[df_script['location_id'].notnull()].copy()\",\"Clean the script data\\ndf_script = df_script[pd.to_numeric(df_script['id'], errors='coerce').notnull()]\\ndf_script['id'] = df_script['id'].astype(int)\",\" Preprocessing\\n# Ensure no Null values for character_id\\ndf_script = df_script[~df_script[\\\"character_id\\\"].isnull()]\",\"Filter out characters that are not lines\\ndf_characters = df_characters[df_characters['character_id'].isin(df_script['character_id'])]\",\"Remove scripts that have invalid characters and locations\\ndf_script_cleaned = df_script[df_script['character_id'].isin(df_characters['id'])]\\ndf_script_cleaned = df_script_cleaned[df_script_cleaned['location_id'].isin(df_locations['id'])]\",\"Filter out any rows missing a location, character, or raw text\\ndf_script = df_script[\\n    df_script.raw_location_id.apply(lambda x: not pd.isnull(x)) &\\n    df_script.raw_character_id.apply(lambda x: not pd.isnull(x)) &\\n    df_script.raw_text.apply(lambda x: type(x) != float) # Ensure that the text column is a string\\n]\",\"Filter out lines that have no character\\ndf_script = df_script[df_script['character_id'] != 2]\",\"filter out the \\\"bad\\\" data\\ndf_script = df_script[~df_script.character_id.isna()]\\ndf_script = df_script[~df_script.location_id.isna()]\",\"Filter out the rows in df_script that do not contain a character_id in df_characters.\",\"Remove problematic entries\\ndf_script = df_script[df_script['character_id'].isin(df_characters['id'])].reset_index(drop=True)\",\"Remove string descriptions for scripts with non-alphanumeric IDs\\ndf_script = df_script[df_script['id'].apply(lambda x: x.isnumeric())]\",\"Ensure the dataframe (df_script) has the character_id, location_id\\ndf_script = df_script[~(df_script.is_na() == True)]\",\"Remove unneeded rows\\ndf_script = df_script[\\n    (df_script['character_id'] != 2) & (df_script['character_id'] != 3)\\n].reset_index(inplace=False, drop=True)\",\"# Filter the lines that have a location\\ndf_script_location = df_script[df_script['raw_location_text'].notnull()]\",\"# Filter English lines\\ndf_script_en = df_script[df_script['raw_character_text'].isin(df_characters[df_characters['character_id'] \\u003e 0]['character_name'])].copy()\",\"Remove location IDs that don't match with any location in df_locations\\nvalid_location_ids = set(df_locations.id)\",\"Remove corrupt data\\ndf_script = df_script[df_script['character_id'].isin(df_characters['id'])]\\ndf_script = df_script[df_script['location_id'].isin(df_locations['id'])]\",\" Remove the values with missing features 'character_id'\\ndf_script = df_script[df_script['character_id'].notna()].reset_index(inplace=False, drop=True)\"],\"marker\":{\"opacity\":0.5,\"size\":5},\"mode\":\"markers+text\",\"name\":\"183_Filtering and cleaning data in df_script and df_characters\",\"text\":[\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\"],\"textfont\":{\"size\":12},\"x\":[5.55844259262085,5.499941349029541,5.172438621520996,5.501599311828613,6.0254411697387695,5.049269199371338,5.663146495819092,6.032680988311768,5.720562934875488,5.797931671142578,5.290473937988281,5.573608875274658,5.093381404876709,5.4657392501831055,6.356026649475098,6.264458179473877,5.395233631134033,4.849379062652588,5.530888080596924],\"y\":[6.708242416381836,7.163056373596191,6.462331771850586,7.074036121368408,7.872938632965088,7.194538116455078,6.882369518280029,7.6285080909729,6.961370944976807,7.503381729125977,7.455796241760254,7.309889793395996,6.796947002410889,6.795627117156982,7.697926044464111,8.184761047363281,6.855886936187744,7.009029388427734,6.932751655578613],\"type\":\"scattergl\"},{\"hoverinfo\":\"text\",\"hovertext\":[\"Filter the columns jedi_order and species\",\" Remove the special value lines, we will not use them in this analysis\",\"Filter columns from dataset\",\"Filter out wrong sources\",\"Filtering necessaary columns for further processing and analysis\",\"Select columns for analysis\",\"Check all columns\",\"Filters\",\"select the fields important for this analysis\",\"Filtering datasets.\",\"Get only a few columns for the purpose of this analysis\",\"Filtering Data for Analysis\\n# \",\"Filtering the data for better modelling\",\" Select interesting columns\",\" Using the bounding box data to filter out only 4-sided boxes to be displayed\",\"Specify the columns that are useful in the context of this analysis\",\"Select only the columns we need\",\"Data preparation - this cell fixes the types of the columns and filters the dataframe by date\",\"Filtering the columns to keep only those which would be useful for modeling and analysis\"],\"marker\":{\"opacity\":0.5,\"size\":5},\"mode\":\"markers+text\",\"name\":\"184_Filtering and Analysis of Columns\",\"text\":[\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\"],\"textfont\":{\"size\":12},\"x\":[9.4373197555542,10.464301109313965,9.501774787902832,9.96678352355957,9.906302452087402,9.689469337463379,9.860593795776367,9.83719539642334,10.437570571899414,10.542850494384766,9.911975860595703,10.540762901306152,10.338138580322266,9.856952667236328,9.306652069091797,10.073317527770996,9.568138122558594,9.14691162109375,9.600292205810547],\"y\":[1.4498158693313599,2.085059881210327,1.090491771697998,1.9435502290725708,1.3911458253860474,0.9402006268501282,-0.5764502882957458,1.6425206661224365,1.1600315570831299,0.9176015853881836,1.1073259115219116,1.2921196222305298,1.3681588172912598,0.9700611233711243,1.5654085874557495,1.1495648622512817,0.7813979983329773,1.3391320705413818,1.6360224485397339],\"type\":\"scattergl\"},{\"hoverinfo\":\"text\",\"hovertext\":[\" Let's view the first few rows of each dataframe to understand their structure and contents.\",\"Let's start by printing the first few rows of each DataFrame to understand our data.\",\"Let's explore the first few rows of each dataframe to get an idea of what the data looks like.\",\"Let's display the first few rows of each dataframe to understand the data better.\",\"Let's display the first few rows of each dataframe to understand their structure.\",\"Let's print the first couple of rows of each dataframe to see what we're working with.\",\"To get a quick feel of the data in each of the DataFrames, we can display the first few rows of each DataFrame using the `head()` method.\",\"We'll print the first 3 rows of each dataframe to have a look at what we're dealing with.\",\"Let's display the first few lines of each dataframe to understand their structure.\",\"Let's print the first few rows of each Dataframe to understand their structure and available columns.\",\"Let's start by displaying the first few lines of each dataframe to get a sense of how the data is structured.\",\"Let's print the first 2 rows of these DataFrames to get an idea of their structure.\",\"Let's display the first few lines of each of these DataFrames to understand their structure and contents.\",\"Let's start by displaying the first few rows of each dataframe to understand their structure and content.\",\"Let's display the first few rows of each of these DataFrames to better understand their structure and the data they contain.\",\"let's display the firt few rows of each dataframe to understand its structure.\",\"Let's display the first few rows of each dataframe to understand their structure and contents.\",\"Let's display the first few lines of each dataframe to understand their structure and content better.\",\"Let's display the first few rows of each of these DataFrames to understand their structure and content.\"],\"marker\":{\"opacity\":0.5,\"size\":5},\"mode\":\"markers+text\",\"name\":\"185_Understanding the structure of data frames by printing the first few rows\",\"text\":[\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\"],\"textfont\":{\"size\":12},\"x\":[9.773731231689453,11.318394660949707,11.455526351928711,10.944750785827637,10.223155975341797,11.07883358001709,11.672072410583496,10.850523948669434,10.285033226013184,10.501626968383789,10.207342147827148,9.998678207397461,10.33022403717041,10.487278938293457,10.418840408325195,10.243401527404785,10.476820945739746,10.979951858520508,10.325685501098633],\"y\":[-8.644840240478516,-8.5941162109375,-7.359925270080566,-8.607101440429688,-9.001121520996094,-8.155198097229004,-8.220954895019531,-8.638076782226562,-8.056989669799805,-8.8284912109375,-8.436867713928223,-9.047009468078613,-8.07597827911377,-8.403428077697754,-8.736804008483887,-8.737701416015625,-8.966974258422852,-8.178866386413574,-8.767048835754395],\"type\":\"scattergl\"},{\"hoverinfo\":\"text\",\"hovertext\":[\"we reset the index inplace and drop the old index column at the same time\",\"we want to reset the index of the returned DataFrame\",\"Code to reset the index of the dataframes and drop the old index column\",\"We use 'reset_index(inplace=False, drop=True)' to reset the index of the DataFrame without inserting it as a column and dropping the current index.\",\" Applying reset_index(inplace=False, drop=True) to the pandas dataframes\",\"NOTE: The reset_index(inplace=False, drop=True) is necessary to prevent the automatic creation of a new index column.\",\"Setting the index after resetting it with Pandas.\",\"WARNING: It is bad practice to use inplace=True and assigning to the same variable, as this might lead to unexpected behavior.\",\" Add index to script dataframe\\ndf_script.reset_index(inplace=False, drop=True)\",\"It's actually recommended to create the indexes without using inplace=False, as it is deprecated in the latest version of pandas.\",\" There was an error in the code. The \\\"inplace\\\" parameter doesn't exist for the \\\"reset_index\\\" method.\",\"Make sure we always call `reset_index` with `inplace=False` and ignore the warning\",\"Reset index for consistency\",\" We need to \\\"reset_index(inplace=False, drop=True)\\\" to remove the new index that pandas creates automatically.\",\"`reset_index(inplace=False, drop=True)` is unnecessary\",\"Dropping the index again to be safe\",\"added index reset and inplace variable\",\" cleaned data (removed 'number' column, since it's already the index)\",\"If the `inplace` parameter is `False`, resets the index of the DataFrame in a non-destructive manner\"],\"marker\":{\"opacity\":0.5,\"size\":5},\"mode\":\"markers+text\",\"name\":\"186_Resetting index inplace and dropping old index column\",\"text\":[\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\"],\"textfont\":{\"size\":12},\"x\":[8.641214370727539,8.524808883666992,8.05410385131836,8.12084674835205,8.271844863891602,8.269372940063477,8.542987823486328,9.351022720336914,7.374123573303223,7.991169452667236,8.940046310424805,8.579032897949219,8.497906684875488,8.028030395507812,8.584161758422852,8.297419548034668,8.73495864868164,8.492259979248047,8.554099082946777],\"y\":[1.5038217306137085,0.49675145745277405,1.1332062482833862,0.7920514941215515,0.6584241390228271,1.139543056488037,0.6495842337608337,1.3965226411819458,1.6239758729934692,0.7291496396064758,1.2356036901474,1.2358819246292114,1.2776552438735962,0.6895223259925842,1.1173949241638184,1.4440581798553467,1.102156400680542,1.2431774139404297,0.8674458861351013],\"type\":\"scattergl\"},{\"hoverinfo\":\"text\",\"hovertext\":[\"Check the dataframes shape\\ndf_characters.shape, df_locations.shape, df_script.shape, df_episodes.shape\",\"Inspect dataframe shapes\\ndf_characters.shape, df_locations.shape, df_script.shape, df_episodes.shape\",\" Check if shape has changed\\ndf_characters.shape, df_locations.shape, df_script.shape, df_episodes.shape\",\"Check the data shape\\ndf_characters_shape = df_characters.shape\\ndf_locations_shape = df_locations.shape\\ndf_script_shape = df_script.shape\\ndf_episodes_shape = df_episodes.shape\",\"Inspect dataframe shapes\\ndf_characters.shape, df_locations.shape, df_script.shape, df_episodes.shape\",\"Check the number of rows in each data frame\\ndf_shape = {\\n    \\\"Episodes\\\": df_episodes.shape,\\n    \\\"Script\\\": df_script.shape,\\n    \\\"Characters\\\": df_characters.shape,\\n    \\\"Locations\\\": df_locations.shape\\n}\\n\\ndf_shape\",\"Check the number of lines, characters, locations and episodes\\ndf_script.shape[0], df_characters.shape[0], df_locations.shape[0], df_episodes.shape[0]\",\"Check dataframes shape\\ndf_characters.shape, df_locations.shape, df_script.shape, df_episodes.shape\",\"Check the shape of each dataframe\\ndf_characters.shape, df_locations.shape, df_script.shape, df_episodes.shape\",\"Check the shape of the dataframes\\ndf_characters.shape, df_locations.shape, df_script.shape, df_episodes.shape\",\"Check the shape of each dataframe\\ndf_characters.shape, df_locations.shape, df_script.shape, df_episodes.shape\",\"Check dataframe shapes\\ndf_characters.shape, df_locations.shape, df_script.shape, df_episodes.shape\",\"Check the number of rows and columns\\ndf_characters.shape, df_locations.shape, df_script.shape, df_episodes.shape\",\"Check the data shapes\\ndf_characters.shape, df_locations.shape, df_script.shape, df_episodes.shape\",\"Check the number of rows and the column names of the episodes dataframe\\ndf_episodes.shape, df_episodes.columns\",\"Check the dataframe shapes\\ndf_characters.shape, df_locations.shape, df_script.shape, df_episodes.shape\",\"Check the size & header of each data\\ndf_characters.shape, df_locations.shape, df_script.shape, df_episodes.shape\",\" Check the number of rows and columns for each dataframe\\ndf_characters.shape, df_locations.shape, df_script.shape, df_episodes.shape\"],\"marker\":{\"opacity\":0.5,\"size\":5},\"mode\":\"markers+text\",\"name\":\"187_Checking Dataframe Shapes\",\"text\":[\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\"],\"textfont\":{\"size\":12},\"x\":[0.15863919258117676,-0.4650576710700989,0.26552829146385193,-0.3522270917892456,-0.22415247559547424,0.6652081608772278,0.6662386655807495,0.19495250284671783,0.4612973928451538,0.35997843742370605,0.5731441378593445,0.07850214838981628,0.540228545665741,0.142035573720932,1.440073013305664,0.13900640606880188,0.3126280605792999,1.0062083005905151],\"y\":[0.03606076166033745,-0.16227029263973236,-0.12115063518285751,0.05465313047170639,-0.3020690083503723,-0.09222961217164993,0.37418878078460693,0.005779350642114878,0.3023553490638733,0.042526040226221085,0.5012946128845215,0.1660792976617813,0.3380357623100281,0.10173171758651733,1.0656033754348755,0.006439080461859703,-0.25522273778915405,0.29816073179244995],\"type\":\"scattergl\"},{\"hoverinfo\":\"text\",\"hovertext\":[\" Display first 5 characters of the dataframe\\ndf_script.head()\",\"Head displays the first 5 rows of the dataframe\\ndf_characters.head()\",\" Display the first five rows of the characters DataFrame\\ndf_characters.head()\",\" Display the first five rows of the characters dataframe\\ndf_characters.head()\",\"Display first five rows of the characters dataframe\\ndf_characters.head()\",\"Display first 5 rows from each dataframe\\ndf_characters.head(5)\",\" Display first 5 rows of the characters DataFrame\\ndf_characters.head()\",\"Display the first five rows of the characters dataframe\\ndf_characters.head()\",\"Display first 5 rows of characters dataframe\\ndf_characters.head()\",\"Display the first five rows of the characters dataframe\\ndf_characters.head()\",\" Display the first five rows of the characters dataframe\\ndf_characters.head()\",\"Display the first five rows of the characters dataframe\\ndf_characters.head()\",\"Display first 5 rows of characters dataframe\\ndf_characters.head()\",\" Display first 5 rows of df_characters dataframe\\ndf_characters.head()\",\"Display first 5 rows of characters dataframe\\ndf_characters.head()\",\"Display first 5 rows of characters dataframe\\ndf_characters.head()\",\"Display the first five rows of the characters dataframe\\ndf_characters.head()\",\" Display the first five rows of the dataframe\\ndf_characters.head()\"],\"marker\":{\"opacity\":0.5,\"size\":5},\"mode\":\"markers+text\",\"name\":\"188_Displaying first five rows of characters DataFrame\",\"text\":[\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\"],\"textfont\":{\"size\":12},\"x\":[-2.7041146755218506,-2.3228325843811035,-2.8085882663726807,-2.9564666748046875,-2.6570284366607666,-2.860325574874878,-2.048703193664551,-2.9557125568389893,-1.9003171920776367,-2.9669172763824463,-3.1181423664093018,-2.4767608642578125,-1.9241834878921509,-2.0762081146240234,-2.045029640197754,-1.8943450450897217,-2.983213186264038,-2.866224765777588],\"y\":[13.112838745117188,13.6051664352417,12.00450325012207,12.054729461669922,12.016568183898926,13.14995002746582,13.426328659057617,11.986217498779297,13.542267799377441,11.910736083984375,11.953974723815918,12.101655960083008,13.150205612182617,13.107969284057617,13.492911338806152,13.288399696350098,11.870678901672363,12.60501766204834],\"type\":\"scattergl\"},{\"hoverinfo\":\"text\",\"hovertext\":[\"# Display a few rows of the characters dataframe\\ndf_characters.head()\",\"# Shows the first entries of the characters dataframe\\ndf_characters.head()\",\"# Display the first rows of the characters dataframe\\ndf_characters.head()\",\"# Display the first few rows of the characters dataframe\\ndf_characters.head()\",\"# Display the first few columns\\ndf_characters.head()\",\"\\n# Display the first few rows of the dataframe\\ndf_characters.head()\",\"\\n# Display the first few rows of the character dataframe\\ndf_characters.head()\",\"# Display the first few rows of the characters dataframe\\ndf_characters.head()\",\"# Display the first few rows of the characters DataFrame\\ndf_characters.head()\",\"# Display the first few rows of the characters dataframe\\ndf_characters.head()\",\"# Showing the first few rows of the dataframes\\ndf_characters.head()\",\"Select the relevant columns in the characters dataframe\\ndf_characters = df_characters[['id', 'name']]\\n\\n# Display the first few rows of the dataframe\\ndf_characters.head()\",\"# Show first few rows of the characters dataframe\\ndf_characters.head()\",\"# Display the first few rows of the dataframe\\ndf_characters.head()\",\"# Display the first rows of the characters dataframe\\ndf_characters.head()\",\"Add the following code to display the first few rows of the characters dataframe:\\nprint(df_characters.head())\",\"# Show the first few rows of the characters DataFrame\\ndf_characters.head()\",\"# Display the first few rows of the characters DataFrame\\ndf_characters.head()\"],\"marker\":{\"opacity\":0.5,\"size\":5},\"mode\":\"markers+text\",\"name\":\"189_displaying first few rows of characters dataframe\",\"text\":[\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\"],\"textfont\":{\"size\":12},\"x\":[3.3855581283569336,2.280113697052002,1.9904123544692993,2.3581197261810303,1.561598777770996,2.256389617919922,2.666597366333008,2.4540488719940186,2.6415762901306152,2.439704656600952,2.4637551307678223,2.5882132053375244,2.266277551651001,2.2656197547912598,2.208430051803589,-3.604830026626587,2.5292611122131348,2.5290493965148926],\"y\":[17.914255142211914,18.531644821166992,17.788537979125977,18.01165008544922,18.199621200561523,18.045312881469727,17.855249404907227,18.038145065307617,17.873403549194336,17.988405227661133,17.993467330932617,17.091331481933594,18.339080810546875,18.110591888427734,17.980548858642578,22.429473876953125,18.29401969909668,17.894132614135742],\"type\":\"scattergl\"},{\"hoverinfo\":\"text\",\"hovertext\":[\"check the data\\ndf_characters.head()\",\"Check the data\\ndf_characters.head()\",\"Check we have the data\\ndf_characters.head()\",\"# Check the top of the characters data\\ndf_characters.head()\",\"Check a data sample for visual inspection\\ndf_characters.head()\",\" Check data samples\\ndf_characters.head()\",\"Check data\\ndf_characters.head()\",\"Check the data\\nprint(df_characters.head())\",\" Check data\\ndf_characters.head()\",\"Checking the data\\ndf_characters.head()\",\"Check the result\\ndf_characters.head()\",\"Check the data\\ndf_characters.head()\",\"Check characters info\\ndf_characters.head()\",\"Check the character data set\\ndf_characters.head()\",\"check the data\\ndf_characters.head()\",\"check data\\ndf_characters.head()\",\"Checking the head for df_characters\",\"Check data sample\\nprint(df_characters.head())\"],\"marker\":{\"opacity\":0.5,\"size\":5},\"mode\":\"markers+text\",\"name\":\"190_Checking Data Samples and Results in df_characters\",\"text\":[\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\"],\"textfont\":{\"size\":12},\"x\":[5.569390296936035,5.741549015045166,5.523693561553955,6.002219200134277,6.0121378898620605,5.683660507202148,5.596954345703125,5.886882781982422,5.72899055480957,6.007483005523682,5.630106449127197,5.8137030601501465,6.131123065948486,5.4505815505981445,5.641472816467285,5.545152187347412,6.465177059173584,5.856611728668213],\"y\":[13.065381050109863,13.096458435058594,12.545300483703613,13.056063652038574,14.152493476867676,13.653563499450684,13.031697273254395,12.757806777954102,13.347256660461426,13.42436695098877,13.032526969909668,13.030313491821289,13.87370491027832,13.306937217712402,12.90576171875,13.28600025177002,13.847557067871094,12.794646263122559],\"type\":\"scattergl\"},{\"hoverinfo\":\"text\",\"hovertext\":[\"Remove unnecesasry columns\",\"  - Remove invalid entries\",\" Remove unncessary information\",\"Dropping columns with no useful data\",\"Remove unneeded columns\",\"Remove unwanted columns\",\"Remove the rows which have no dialogue, and remove the unuseful columns\",\"Remove useless columns.\",\" Filter out unnecessary columns and rows.\",\"Remove potentially problematic rows\",\"Remove weird columns without a name\",\"Select the columns of interest and remove any potential NAs\",\"Remove the invalid rows where the character data is incorrect.\",\" Remove unwanted columns, convert columns types, etc.\",\"Remove unecessary columns\",\" Drop the first column, which is not needed\",\"Drop null columns and trim whitespaces\",\"Remove some extra columns in the characters table\"],\"marker\":{\"opacity\":0.5,\"size\":5},\"mode\":\"markers+text\",\"name\":\"191_Data Cleaning and Column Filtering\",\"text\":[\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\"],\"textfont\":{\"size\":12},\"x\":[9.875850677490234,9.979019165039062,10.69473934173584,9.380144119262695,9.407044410705566,9.437067985534668,9.55563735961914,9.713784217834473,9.328863143920898,9.394506454467773,9.36997127532959,8.885696411132812,10.464569091796875,9.917757987976074,9.65466022491455,9.065191268920898,9.605647087097168,9.511517524719238],\"y\":[2.3279078006744385,2.9242634773254395,2.822251081466675,1.8147265911102295,2.3674612045288086,2.1695621013641357,3.013424873352051,2.3113486766815186,2.0688729286193848,2.568535089492798,2.464430093765259,2.2967991828918457,3.856450319290161,2.140615463256836,2.369166612625122,1.818607211112976,1.9715625047683716,3.2031190395355225],\"type\":\"scattergl\"},{\"hoverinfo\":\"text\",\"hovertext\":[\"Show the first 5 rows of each dataframe to confirm data has been properly imported\\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()\",\"Check the first 5 rows of each dataframe\\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()\",\"Check the first 5 rows of each dataframe\\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()\",\"Check the first 5 rows of each dataframe\\nprint(df_characters.head())\\nprint(df_locations.head())\\nprint(df_script.head())\\nprint(df_episodes.head())\",\" Check the first 5 characters of each dataframe\\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()\",\"Check first 5 lines of each dataframe\\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()\",\" Check first 5 rows of each dataframe\\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()\",\" Check the first 5 rows of each dataframe\\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()\",\" Check the first 5 rows of each of the 4 dataframes\\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()\",\"Check the first 5 rows of each DataFrame\\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()\",\"Check the first 5 rows of each DataFrame\\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()\",\"Check the first 5 rows of each DataFrame\\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()\",\" Check the first five rows of each dataframe\\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()\",\"Check the first 5 rows of each DataFrame\\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()\",\"Check the first 5 rows of each dataframe\\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()\",\" Check the first 5 rows of each dataframe\\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()\",\"Check first 5 rows of each dataframe\\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()\",\" Check the first 5 rows of each DataFrame\\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()\"],\"marker\":{\"opacity\":0.5,\"size\":5},\"mode\":\"markers+text\",\"name\":\"192_Checking first 5 rows of each dataframe and confirming data import\",\"text\":[\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\"],\"textfont\":{\"size\":12},\"x\":[-4.144882678985596,-5.025075912475586,-4.692395210266113,-4.449470043182373,-4.901224613189697,-4.743624687194824,-4.903048515319824,-4.6879191398620605,-4.854001522064209,-4.631129264831543,-4.536489963531494,-4.891983985900879,-4.797091007232666,-4.723663330078125,-4.804732322692871,-4.819333553314209,-4.690319061279297,-4.697057723999023],\"y\":[8.343452453613281,8.735366821289062,8.729379653930664,8.526107788085938,8.919975280761719,9.096457481384277,9.044684410095215,8.954652786254883,9.008330345153809,8.919793128967285,8.598215103149414,8.933364868164062,9.067002296447754,8.725685119628906,8.723670959472656,8.690963745117188,9.198224067687988,8.833013534545898],\"type\":\"scattergl\"},{\"hoverinfo\":\"text\",\"hovertext\":[\"check the first few rows of the script dataframe\\ndf_script.head()\",\"Check the first 2 rows of the dataset\\nprint(df_script.head(2))\",\"Check the first few rows of the dataframe\\ndf_script.head()\",\"Check the contents of the first few rows of the dataframe\\nprint(df_script.head())\\n\\n# Check the number of rows and columns in the dataframe\\nprint(df_script.shape)\",\"Check the first rows of the dataset `df_script` (to identify common columns and column names)\",\"Check the first few rows of the df_script dataframe\\ndf_script.head()\",\"Check the first rows of the dataframe and its datatypes\\ndf_script.head()\",\"Checking the first 5 rows of the script dataset\\ndf_script.head()\",\"Check the first rows of the first dataset (the script)\\ndf_script.head()\",\"Inspect the first 5 rows of the dataset\\ndf_script.head()\",\" Explore the structure and contents of the script dataframe\\nprint(f\\\"Number of rows {df_script.shape[0]} and columns {df_script.shape[1]}\\\")\\ndf_script.head()\",\"Checking the first few rows of the data.\\ndf_script.head()\",\"Checking the first few rows of the `df_script` DataFrame to understand its structure and contents.\\ndf_script.head()\",\"Check the first couple of rows of the dataframe\\ndf_script.head()\",\"Quick inspection of first rows of df_script DataFrame\\ndf_script.head()\",\"Check the dataframe shape and first few rows for script dataframe\\nprint(df_script.shape)\\ndf_script.head()\",\"Check the first rows\\ndf_script.head()\",\"Check the first 5 rows of the dataset\\ndf_script.head()\"],\"marker\":{\"opacity\":0.5,\"size\":5},\"mode\":\"markers+text\",\"name\":\"193_Dataframe Exploration\",\"text\":[\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\"],\"textfont\":{\"size\":12},\"x\":[3.199401378631592,3.176478147506714,3.38039493560791,3.5266926288604736,3.3277053833007812,3.4469354152679443,3.423588275909424,2.6029038429260254,3.1386799812316895,2.9924445152282715,4.724021911621094,3.0622012615203857,3.6207375526428223,3.5680549144744873,2.959557294845581,4.233222007751465,3.01983642578125,2.830557107925415],\"y\":[-5.181175231933594,-4.314633846282959,-5.222743511199951,-4.955911636352539,-4.423064708709717,-5.039958477020264,-5.13944673538208,-4.717493057250977,-4.684614181518555,-4.467355251312256,-5.778505802154541,-4.927064418792725,-5.480001926422119,-4.916722297668457,-6.081707000732422,-5.150494575500488,-4.860547065734863,-4.597498416900635],\"type\":\"scattergl\"},{\"hoverinfo\":\"text\",\"hovertext\":[\"%load_ext autoreload\\n%autoreload 2\",\"Load the custom module for this problem set.\",\"%load_ext autoreload\\n%autoreload 2\",\"Set the global parameters for the notebook.\",\"Set notebook preferences\",\"Place the dataset files in a 'data' folder in the same directory as this notebook.\",\"We'll also use the following configuration in this notebook:\",\"Change this to the path of the cloned repo on your machine.\\nPATH = \\\"\\u002fcontent\\u002fSpringboard-Capstone-Three\\\"\",\" Pretend to run the importing of data and keep going with the notebook\",\"This will allow the visuals to be displayed in the notebook.\",\"In case of reopening Jupyter notebook, we will reload the data without the need to run the entire notebook\",\"For more details, check the documentation folder within the project folder.\",\"Add any additional libraries and set config parameters here.\",\"Optional; restart the kernels to be sure that changes are picked up when the notebook is re-run.\",\"Create a variable to freeze so we don't run the entire notebook in one go.\",\"%reload_ext autoreload\\n%autoreload 2\",\"Add your paths accordingly, as seen below.\",\"# Turn off notebook package\\n%reload_ext autoreload\\n%autoreload 2\"],\"marker\":{\"opacity\":0.5,\"size\":5},\"mode\":\"markers+text\",\"name\":\"194_Autoreload in Jupyter notebooks\",\"text\":[\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\"],\"textfont\":{\"size\":12},\"x\":[15.643259048461914,15.141090393066406,15.537074089050293,17.010356903076172,17.8951416015625,15.606191635131836,16.622568130493164,15.7114839553833,15.951014518737793,17.639286041259766,17.236818313598633,15.341059684753418,15.488213539123535,17.065696716308594,16.59588623046875,15.764695167541504,16.14027976989746,16.331653594970703],\"y\":[1.8245055675506592,2.9289748668670654,1.878133773803711,2.6758904457092285,2.854459285736084,1.6215412616729736,2.76713228225708,3.6616005897521973,2.421440362930298,2.937918186187744,2.415083169937134,3.4854745864868164,3.2569665908813477,2.729177236557007,2.147728443145752,2.1886110305786133,3.671135187149048,2.2450578212738037],\"type\":\"scattergl\"},{\"hoverinfo\":\"text\",\"hovertext\":[\"Show head of characters dataframe\\ndf_characters.head()\",\" Show head of the characters dataframe\\ndf_characters.head()\",\" Show head of characters dataframe\\ndf_characters.head()\",\"Display head of characters dataframe\",\"Show head of characters table\\ndf_characters.head()\",\"Show the head of the characters dataframe\\ndf_characters.head()\",\" Show the head of the characters dataframe\\ndf_characters.head()\",\"View head of the character dataframe\\ndf_characters.head()\",\"Show head of characters dataframe\\ndf_characters.head()\",\"Show head of the characters dataframe\\ndf_characters.head()\",\" Show head of the characters dataframe\\ndf_characters.head()\",\"Show the head of the characters dataframe\\ndf_characters.head()\",\"Show head of the characters dataframe\\ndf_characters.head()\",\"Head of characters dataframe\\ndf_characters.head()\",\" Show head of characters dataframe\",\" Show head of characters DataFrame\",\" Displaying the head of the Characters dataframe to understand the data\",\"Get the head of the characters dataframe\"],\"marker\":{\"opacity\":0.5,\"size\":5},\"mode\":\"markers+text\",\"name\":\"195_Displaying head of characters DataFrame\",\"text\":[\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\"],\"textfont\":{\"size\":12},\"x\":[8.433334350585938,8.295862197875977,8.459592819213867,7.39912223815918,7.616130828857422,8.133378982543945,8.326552391052246,7.95024299621582,8.499618530273438,8.636685371398926,8.438288688659668,8.177203178405762,8.42858600616455,8.540762901306152,7.88391637802124,7.927496433258057,7.571930408477783,7.690132141113281],\"y\":[17.97725486755371,17.830076217651367,17.972463607788086,17.980318069458008,17.59122657775879,17.613481521606445,17.884843826293945,17.754867553710938,17.85138702392578,18.190990447998047,17.731281280517578,17.708656311035156,17.716678619384766,18.149070739746094,17.880449295043945,17.888803482055664,17.748764038085938,17.31453514099121],\"type\":\"scattergl\"},{\"hoverinfo\":\"text\",\"hovertext\":[\"Set pandas to display all columns in dataframes\\npd.set_option('display.max_columns', None)\",\"Show all columns in pandas\\npd.set_option('display.max_columns', None)\",\"Set pandas to display all columns for dataframes\\npd.set_option('display.max_columns', None)\",\" Use pandas display option to show all the columns when displaying the dataframes\\n# Setting the option affects all dataframes throughout the notebook\\npd.set_option('display.max_columns', None)\",\" Set Pandas to display all columns\\npd.set_option('display.max_columns', None)\",\" We will also set the max_columns option of pandas so that we can see all columns while displaying the DataFrames.\",\"Set up Pandas to show all columns when displaying DataFrames\\npd.set_option('display.max_columns', None)\",\"Set pandas to show all columns in head()\\npd.set_option('display.max_columns', None)\",\"Set the `display.max_columns` option in Pandas to `None` to show all columns in DataFrames\\npd.set_option('display.max_columns', None)\",\"Set the dataframe display option to show all columns for visibility\\npd.set_option('display.max_columns', None)\",\"Allow pandas to display all columns, and provide autocomplete scoring based on column type\\npd.set_option('display.max_columns', None)\\npd.set_option('display.memory_usage', True)\",\"Set pandas to show all the columns in the dataframe\\npd.set_option('display.max_columns', None)\",\" option in pandas to display all columns in outputs\\npd.set_option('display.max_columns', None)\",\" Set the option to display all columns of the pandas dataframe\\npd.set_option('display.max_columns', None)\",\"# Set Pandas to display all of the columns\\npd.set_option('display.max_columns', None)\",\" Configure pandas to display all columns when showing DataFrames\\npd.set_option('display.max_columns', None)\",\"Setting pandas to show all columns when .head() is called on a dataframe\\npd.set_option('display.max_columns', None)\"],\"marker\":{\"opacity\":0.5,\"size\":5},\"mode\":\"markers+text\",\"name\":\"196_Setting display.max_columns option in pandas to show all columns in DataFrames\",\"text\":[\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\"],\"textfont\":{\"size\":12},\"x\":[20.50905990600586,21.19776153564453,20.856992721557617,21.4255428314209,21.15508460998535,21.66586685180664,20.54848289489746,20.998136520385742,21.054948806762695,20.81781578063965,21.668195724487305,20.84199333190918,20.874778747558594,21.073911666870117,21.491188049316406,20.754318237304688,20.808507919311523],\"y\":[0.5061022639274597,-0.09542517364025116,0.32774579524993896,0.3894447982311249,0.6768760681152344,0.7369597554206848,0.4907950162887573,0.5031024813652039,0.3113833963871002,0.22216877341270447,0.5435789227485657,0.35246390104293823,0.06534682214260101,0.4238395392894745,0.724433958530426,0.36343517899513245,0.16705851256847382],\"type\":\"scattergl\"},{\"hoverinfo\":\"text\",\"hovertext\":[\"Let's start by looking at the first few rows of each of our datasets.\",\"Now let's take a look at the first few rows of our datasets.\",\"Let's take a look at the first few rows of each dataset to understand what information is available.\",\"Let's take a look at the first few rows of each dataset to understand the data better.\",\"Let's take a look to the columns present in the different datasets.\",\" This dataset especially is quite spicy and is full of joint operations between different data sources!\",\"No we will examine the first 10 rows of the dataset and see what we are dealing with.\",\"First, let me go through the dataset and get to know the various fields and the data it holds.\",\"Let's take a look at the first few rows of each dataset.\",\"Let's take a look at the first few rows of each dataset to understand what kind of data we're working with.\",\" Let's take a look at the first few rows of each dataset.\",\"Take a look at the first 5 rows for all datasets.\",\"Before we proceed, let's take a look at the top few rows of these datasets.\",\"Let's take a look at the first few rows of each dataset.\",\"Let's start by taking a look at the first few rows of each dataset.\",\" Let us take a glance at the data to get a better understanding of the dataset.\",\"Let's have a look at the first 10 rows of each of our datasets.\"],\"marker\":{\"opacity\":0.5,\"size\":5},\"mode\":\"markers+text\",\"name\":\"197_Understanding Datasets and Their Information\",\"text\":[\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\"],\"textfont\":{\"size\":12},\"x\":[15.23115348815918,15.318388938903809,14.6806640625,15.023107528686523,15.082709312438965,15.469012260437012,14.950931549072266,15.936622619628906,14.632719993591309,14.573076248168945,14.965017318725586,14.63318157196045,14.596930503845215,14.999103546142578,14.85367202758789,15.408355712890625,15.293773651123047],\"y\":[-2.861161947250366,-3.1725246906280518,-3.2728641033172607,-3.622258186340332,-2.7767984867095947,-3.178175926208496,-3.1341676712036133,-2.5354740619659424,-3.1413562297821045,-3.605419397354126,-3.431560754776001,-3.45951771736145,-2.7295725345611572,-3.1594300270080566,-2.720149517059326,-3.236422061920166,-3.4113264083862305],\"type\":\"scattergl\"},{\"hoverinfo\":\"text\",\"hovertext\":[\"Print the first 5 rows of df_characters\\ndf_characters.head()\",\"Print first 5 rows of the data\\ndf_characters.head()\",\"Print the first 5 rows of the characters DataFrame\\ndf_characters.head()\",\"Print the first 5 rows of the characters dataframe\\nprint(df_characters.head())\",\"Print the first 5 rows of the characters DataFrame\\ndf_characters.head()\",\"Print the first 5 rows of the characters DataFrame\\ndf_characters.head()\",\"Print the first 5 rows of the characters dataframe\\ndf_characters.head()\",\"Print the first 5 rows of the characters dataframe\\ndf_characters.head()\",\" Print the first 5 elements of the characters dataframe\\ndf_characters.head()\",\"Prints the first five rowss of the characters dataframe\\ndf_characters.head()\",\"Print the first 5 lines of the dataframe\\nprint(df_characters.head())\",\"Print first 5 lines of first data file\\nprint(df_characters.head())\",\" Print the first 5 rows of the characters dataframe\\ndf_characters.head()\",\" Print the first 5 entries in the characters dataframe\\ndf_characters.head()\",\"# Print the first 5 rows of the characters dataframe\\ndf_characters.head()\",\"Print the first 5 rows of the characters dataframe\\ndf_characters.head()\",\"Print the first 5 rows of the dataframe for easy viewing.\\ndf_characters.head()\"],\"marker\":{\"opacity\":0.5,\"size\":5},\"mode\":\"markers+text\",\"name\":\"198_Printing the first 5 rows of a dataframe\",\"text\":[\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\"],\"textfont\":{\"size\":12},\"x\":[-1.4010837078094482,-1.3298062086105347,-1.4110076427459717,-1.3482081890106201,-1.612817406654358,-1.3857622146606445,-1.3956356048583984,-1.5166857242584229,-1.575402855873108,-1.6239449977874756,-0.8724192976951599,-0.7624033093452454,-1.5036580562591553,-1.331589698791504,-1.718743085861206,-1.5890825986862183,-1.6334806680679321],\"y\":[11.340380668640137,11.343832969665527,10.660033226013184,10.51684856414795,10.696846961975098,10.74103832244873,10.683196067810059,10.593278884887695,11.01931381225586,10.419857025146484,11.287614822387695,11.702109336853027,10.7203950881958,11.222477912902832,10.835604667663574,10.63630485534668,10.464893341064453],\"type\":\"scattergl\"},{\"hoverinfo\":\"text\",\"hovertext\":[\"Filter out the lines that are not real dialogues.\",\"Remove non dialogue records for dialogue prediction\",\" Preprocess the script dataset to filter out non-dialogue lines and combine multiple lines from the same character into a single entry.\",\"Filter out non-conversational lines such as scene changes\",\"Remove characters that do not have any speaking lines\",\"Ensure that we only consider spoken lines, and remove the rest.\",\"optional: remove non-spoken lines (if the line is not spoken by the characters)\",\"Filtering out the non-speaking lines\",\"Filter out non-speaking lines\",\"Filter out the non-dialogue meaning lines\",\"Filter out the non-dialogue lines\",\"Filter out non-dialogue lines\",\"Data cleaning since Dan's data set still has mentioned speaker but no spoken words, and no ids line by line\",\"Applying a simple filter to exclude meaningless descriptions, e.g. \\\"opening sequence\\\"\",\"Optional: Preprocess the names if not using scripts\\u002flines for filtering the dialogues\\n\\ndef preprocess(text):\\n    return text.lower()\",\" filter only the conversation lines, we will need them for Named Entity Recognition (NER)ruption\",\"Remove the entries with no spoken line and lines than have no character associated\"],\"marker\":{\"opacity\":0.5,\"size\":5},\"mode\":\"markers+text\",\"name\":\"199_Preprocessing script dataset to filter and clean dialogue lines\",\"text\":[\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\"],\"textfont\":{\"size\":12},\"x\":[9.47889232635498,9.447026252746582,9.430254936218262,9.248828887939453,10.198738098144531,10.021452903747559,10.01823902130127,9.923802375793457,9.96342945098877,9.679439544677734,9.683128356933594,9.861706733703613,9.506614685058594,9.659597396850586,9.793195724487305,9.51087474822998,9.898760795593262],\"y\":[5.422280788421631,4.542057991027832,5.472237586975098,5.720554351806641,5.124086856842041,5.2003936767578125,5.362707614898682,5.445740699768066,5.198052883148193,5.255465030670166,5.125598907470703,5.409430980682373,5.4583892822265625,5.681033611297607,5.6881513595581055,5.675963401794434,4.909952163696289],\"type\":\"scattergl\"},{\"hoverinfo\":\"text\",\"hovertext\":[\"Preview the dataframe with the script\\nprint(df_script.head())\",\"Preview dataframe with script lines\\ndf_script.head()\",\"Show a preview of the dataset\\ndf_script.head()\",\"Display a preview of the dataframe pertaining to script data\\ndf_script.head()\",\"Preview\\ndf_script.head()\",\"Preview the dataset\\ndf_script.head()\",\"Preview the script dataframe\\ndf_script.head()\",\" Preview data\\ndf_script.head()\",\"Preview the script dataframe\\ndf_script.head()\",\"Preview the dataset\\ndf_script.head()\",\"Preview data\\ndf_script.head()\",\"Display a preview of the loaded datasets\\ndf_script.head()\",\"Preview the first few entries of the script dataset\\ndf_script.head()\",\"Preview the dataframes\\ndf_script.head()\",\"Preview the script df\\ndf_script.head()\",\"Preview dataframe\\ndf_script.head()\",\"Preview data\\ndf_script.head()\"],\"marker\":{\"opacity\":0.5,\"size\":5},\"mode\":\"markers+text\",\"name\":\"200_Previewing and displaying data in a script dataframe\",\"text\":[\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\"],\"textfont\":{\"size\":12},\"x\":[-2.479271173477173,-2.2884316444396973,-1.7236442565917969,-2.225414752960205,-2.4417264461517334,-1.5517603158950806,-2.4788167476654053,-2.06022310256958,-2.411496639251709,-1.548494577407837,-2.0936882495880127,-1.4216854572296143,-1.0642595291137695,-2.3615329265594482,-2.4845476150512695,-2.3138794898986816,-2.059400796890259],\"y\":[-7.546475887298584,-7.605916976928711,-7.249566555023193,-7.793190002441406,-7.252803802490234,-7.154710292816162,-7.422800540924072,-7.139581680297852,-7.613246917724609,-7.109247207641602,-7.2538838386535645,-7.292384624481201,-7.032025337219238,-7.707338809967041,-7.415805816650391,-7.421130657196045,-7.054863452911377],\"type\":\"scattergl\"},{\"hoverinfo\":\"text\",\"hovertext\":[\"Display datasets' shapes\\nprint(f'characters: {df_characters.shape}, '\\n      f'locations: {df_locations.shape}, '\\n      f'script: {df_script.shape}, '\\n      f'episodes: {df_episodes.shape}')\",\"print(f\\\"Characters: {df_characters.shape}\\\")\\nprint(f\\\"Locations: {df_locations.shape}\\\")\\nprint(f\\\"Script: {df_script.shape}\\\")\\nprint(f\\\"Episodes: {df_episodes.shape}\\\")\",\" Display the dataset shapes\\nprint(f'Shape of characters dataset: {df_characters.shape}')\\nprint(f'Shape of locations dataset: {df_locations.shape}')\\nprint(f'Shape of script dataset: {df_script.shape}')\\nprint(f'Shape of episodes dataset: {df_episodes.shape}')\",\"Print file shapes\\nprint(f'Characters: {df_characters.shape}')\\nprint(f'Locations: {df_locations.shape}')\\nprint(f'Script: {df_script.shape}')\\nprint(f'Episodes: {df_episodes.shape}')\",\"Data Preprocessing\\n# First, let's get an idea of what our data looks like\\nprint(f\\\"Characters Shape: {df_characters.shape}\\\")\\nprint(f\\\"Locations Shape: {df_locations.shape}\\\")\\nprint(f\\\"Script Shape: {df_script.shape}\\\")\\nprint(f\\\"Episodes Shape: {df_episodes.shape}\\\")\",\" Print dataframe shapes\\nprint(f\\\"Characters: {df_characters.shape}\\\")\\nprint(f\\\"Locations: {df_locations.shape}\\\")\\nprint(f\\\"Script: {df_script.shape}\\\")\\nprint(f\\\"Episodes: {df_episodes.shape}\\\")\",\"Print the dataset shapes\\nprint(f'Characters: {df_characters.shape}')\\nprint(f'Locations: {df_locations.shape}')\\nprint(f'Script lines: {df_script.shape}')\\nprint(f'Episodes: {df_episodes.shape}')\",\"View dataframe shape\\nprint(f'Characters dataframe shape: {df_characters.shape}')\\nprint(f'Locations dataframe shape: {df_locations.shape}')\\nprint(f'Script dataframe shape: {df_script.shape}')\\nprint(f'Episodes dataframe shape: {df_episodes.shape}')\",\"View shape of datasets\\nprint(f\\\"Characters: {df_characters.shape}\\\")\\nprint(f\\\"Locations: {df_locations.shape}\\\")\\nprint(f\\\"Script: {df_script.shape}\\\")\\nprint(f\\\"Episodes: {df_episodes.shape}\\\")\",\"Get an idea of the structure of the data\\nprint(f'Characters  : {df_characters.shape}')\\nprint(f'Locations   : {df_locations.shape}')\\nprint(f'Script      : {df_script.shape}')\\nprint(f'Episodes    : {df_episodes.shape}')\",\"View dataframe shapes\\nprint(f\\\"Characters: {df_characters.shape}\\\")\\nprint(f\\\"Locations: {df_locations.shape}\\\")\\nprint(f\\\"Script: {df_script.shape}\\\")\\nprint(f\\\"Episodes: {df_episodes.shape}\\\")\",\"Print the shape and information of the datasets\\nprint(f'Shape of characters dataset: {df_characters.shape}')\\nprint(f'Shape of locations dataset: {df_locations.shape}')\\nprint(f'Shape of script dataset: {df_script.shape}')\\nprint(f'Shape of episodes dataset: {df_episodes.shape}')\",\"Inspect data shape\\nprint(f'df_characters shape: {df_characters.shape}')\\nprint(f'df_locations shape: {df_locations.shape}')\\nprint(f'df_script shape: {df_script.shape}')\\nprint(f'df_episodes shape: {df_episodes.shape}')\",\" Print dataframes' shape\\nprint(f'Characters: {df_characters.shape}')\\nprint(f'Locations: {df_locations.shape}')\\nprint(f'Script: {df_script.shape}')\\nprint(f'Episodes: {df_episodes.shape}')\",\"# Display statues and quantities\\nprint('Data statues:')\\nprint(f' - Characters: {df_characters.shape[0]}')\\nprint(f' - Locations: {df_locations.shape[0]}')\\nprint(f' - Script lines: {df_script.shape[0]}')\\nprint(f' - Episodes: {df_episodes.shape[0]}')\",\"Looking at the data for the first time\\nprint(f\\\"Characters data shape: {df_characters.shape}\\\")\\nprint(f\\\"Locations data shape: {df_locations.shape}\\\")\\nprint(f\\\"Script data shape: {df_script.shape}\\\")\\nprint(f\\\"Episodes data shape: {df_episodes.shape}\\\")\",\"Data at a glance\\nprint(f'Characters: {df_characters.shape[0]}')\\nprint(f'Locations: {df_locations.shape[0]}')\\nprint(f'Lines of script: {df_script.shape[0]}')\\nprint(f'Episodes: {df_episodes.shape[0]}')\"],\"marker\":{\"opacity\":0.5,\"size\":5},\"mode\":\"markers+text\",\"name\":\"201_Data Shapes and Sizes\",\"text\":[\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\"],\"textfont\":{\"size\":12},\"x\":[-0.8793206810951233,-0.1759149432182312,-0.7987713813781738,-0.16297107934951782,-0.9887515306472778,-0.5362626314163208,-0.9240672588348389,-1.0338325500488281,-0.939542293548584,-0.5828881859779358,-1.1403069496154785,-0.8831750154495239,-0.6484676003456116,-0.7340428829193115,-0.4935322403907776,-0.887628972530365,-0.6417118310928345],\"y\":[-2.766098737716675,-2.263216495513916,-2.5444955825805664,-2.408036231994629,-2.6883716583251953,-2.444685935974121,-2.348691940307617,-2.279921054840088,-2.1669363975524902,-2.6228930950164795,-2.2330992221832275,-2.4010796546936035,-2.7167930603027344,-2.37258243560791,-2.9322590827941895,-2.954265832901001,-2.382662773132324],\"type\":\"scattergl\"},{\"hoverinfo\":\"text\",\"hovertext\":[\"Print the first few lines of each dataframe to get an overview of the data.\",\"View the first few lines of each dataframe to understand the data\",\"Let us begin by displaying the first few lines of each data frame.\",\" Display the first few lines of each dataframe to get a sense of the data\",\" Display the first few lines of each dataframe to understand the data better.\",\" Display the first few lines of each dataframe to get an idea of the kind of information available.\",\" Optionally, you can display the first couple of lines for each of the DataFrames as well.\",\"Display the first few lines of the dataframes to understand the data\",\" Display the first few lines of each dataframe to understand the data\",\"Viewing the first few lines of each of our dataframes to better understand the data\",\" Displaying the first few lines of the dataframes to understand the data better.\",\"Explore the first lines of each dataframe\",\" Displaying the first few lines of each dataframe to get an overview of the data structure\",\"Display the first few lines of each dataframe to understand its structure and contents.\",\"Reading first line of each dataframe\",\"Show the first few lines of the data in each dataframe to understand what we are working with.\"],\"marker\":{\"opacity\":0.5,\"size\":5},\"mode\":\"markers+text\",\"name\":\"202_Displaying the first few lines of each dataframe to understand the data better\",\"text\":[\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\"],\"textfont\":{\"size\":12},\"x\":[12.159794807434082,12.098362922668457,11.784269332885742,12.440454483032227,11.879870414733887,12.171910285949707,11.978960037231445,12.060693740844727,12.069533348083496,12.19855785369873,12.116486549377441,12.414458274841309,11.74159049987793,11.836551666259766,12.520901679992676,11.544816017150879],\"y\":[-9.93109130859375,-8.883726119995117,-8.281036376953125,-9.246283531188965,-8.505136489868164,-8.780359268188477,-7.703238010406494,-9.067423820495605,-9.32262897491455,-8.81744384765625,-8.41707992553711,-8.34535026550293,-9.48235034942627,-8.595155715942383,-8.60512638092041,-8.603628158569336],\"type\":\"scattergl\"},{\"hoverinfo\":\"text\",\"hovertext\":[\"Filter lines up to 10 words to get rid of long and complex sentences in the character dialogues\\ndf_script['word_count'] = df_script['normalized_text'].apply(lambda x: len(x.split()))\",\"Normalize whitespace in columns\\nfor col in ['raw_text','speaking_line','normalized_text','word_count']:\\n    if df_script[col].dtype == 'object':\\n        df_script[col] = df_script[col].apply(lambda x: ' '.join(x.split()))\",\" The scripts are very large, so the loading will take some time\\ndf_script['word_count'] = df_script['raw_text'].apply(lambda x: len(x.split()))\",\"Filter characters and dialogues with more than 6 words\\ndf_script['word_count'] = df_script['normalized_text'].str.split().apply(len)\\ndf_script = df_script[df_script.word_count\\u003e=6]\\ndf_script.head()\",\"Sort the columns to make the data easier to understand\\ndf_script = df_script[[c for c in df_script.columns if c != 'word_count'] + ['word_count']]\",\"Create a dataframe `df_script_unique` with the column `spoken_words` containing unique `spoken_words` and the number of occurrences of these `spoken_words` under the column `count`\",\"Compute the count of words in each line of dialog\\ndf_script['word_count'] = df_script['normalized_text'].apply(lambda x: len(x.split()))\",\"Create a new column in df_script that corresponds to the length of each utterance.\",\"Estimate the episode's length based on the number of words in the script\\ndf_script['word_count'] = df_script['normalized_text'].apply(lambda x: len(x.split()))\",\" check word count distribution of the utterances\\ndf_script['word_count'] = df_script['normalized_text'].str.split().apply(len)\",\"Creating a new column with the number of words\\ndf_script['number_of_words'] = df_script['spoken_words'].apply(lambda x: len(x.split()))\",\" create new columns based on existing data\\ndf_script['word_count'] = df_script['spoken_words'].str.split().apply(len)\",\" Create an object for counting the words\\nword_freq = Counter()\\n\\n# Loop through the script to count the words\\nfor _, row in tqdm(df_script.iterrows(), total=len(df_script)):\\n    \\n    # Get the lowercase version of the line\\n    line = row['raw_text']\\n    line = line.lower()\\n    \\n    # Tokenize the line\\n    doc = nlp(line)\\n    \\n    # Update the word counter\\n    word_freq.update([token.text for token in doc if token.is_alpha])\",\"Add column with text length in words\\ndf_script['word_count'] = df_script['normalized_text'].str.split().apply(len)\",\"Add a 'word_count' column to the df_script dataframe\\ndf_script['word_count'] = df_script['raw_text'].apply(lambda x: len(x.split()))\",\"Estimate minutes required to read each script line\\nword_per_minute = 200 # estimation\\ndf_script['word_count'] = df_script['spoken_words'].apply(lambda x: len(x.split()))\\ndf_script['read_duration'] = df_script['word_count'] \\u002f word_per_minute\"],\"marker\":{\"opacity\":0.5,\"size\":5},\"mode\":\"markers+text\",\"name\":\"203_Script Word Count and Length Analysis\",\"text\":[\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\"],\"textfont\":{\"size\":12},\"x\":[8.910364151000977,7.681170463562012,9.126604080200195,8.382119178771973,8.221000671386719,8.367545127868652,8.740192413330078,8.514528274536133,8.74328899383545,8.723692893981934,8.525385856628418,8.471429824829102,8.817262649536133,8.583136558532715,8.972987174987793,8.66370964050293],\"y\":[7.849451065063477,7.909180164337158,8.528226852416992,8.05449104309082,7.077698230743408,7.821908950805664,8.287652015686035,7.630112648010254,7.698116779327393,7.9645256996154785,7.730635166168213,7.701821804046631,8.049162864685059,7.977710723876953,8.116339683532715,8.144490242004395],\"type\":\"scattergl\"},{\"hoverinfo\":\"text\",\"hovertext\":[\"Check the structure of the dataset\\ndf_script.head()\",\"Quick glance at the dataset\\ndf_script.head()\",\"The first 5 scripts in the dataset\\ndf_script.head()\",\"List the script dataset to understand its structure\\ndf_script.head()\",\"check script_df.head() to understand the dataset\",\" Explore scripts dataset\\n\\ndf_script.head()\",\"Look at the first couple of rows of all the datasets\\ndf_script.head(5)\",\" Quick look at the dataset\\ndf_script.head()\",\" Take a look at the first few lines of the dataset\\nprint(df_script.head())\",\"Output some useful information about the datasets\\nprint(df_script.shape)\\ndf_script.head()\",\"Look at some examples from the dataset\\ndf_script.head()\",\"Inspect the dataset\\ndf_script.head()\",\"An example of the dataset\\ndf_script.head()\",\"Information about the transcript dataset\\nprint(\\\"Number of transcript lines:\\\", len(df_script))\\ndf_script.head()\",\"Check the first few rows of the dataset to understand its structure\\ndf_script.head()\",\"# Show the first few lines of the dataset to understand its structure\\ndf_script.head()\"],\"marker\":{\"opacity\":0.5,\"size\":5},\"mode\":\"markers+text\",\"name\":\"204_Exploring Transcript Dataset and Structures - df_script.head() Examples, Length, and Quick Glance\",\"text\":[\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\"],\"textfont\":{\"size\":12},\"x\":[4.196939468383789,4.794210910797119,4.318624496459961,4.26977014541626,4.035735607147217,5.068790912628174,4.299890041351318,4.874554634094238,5.220441818237305,5.598226547241211,4.413815975189209,4.597055912017822,4.508571624755859,4.95957612991333,3.6642446517944336,4.052041053771973],\"y\":[-3.354888916015625,-3.6528306007385254,-3.7934365272521973,-4.179996013641357,-3.5322022438049316,-4.114027976989746,-3.4549949169158936,-3.7586183547973633,-3.114201545715332,-3.631704568862915,-3.8744375705718994,-3.6260132789611816,-4.199940204620361,-3.4523606300354004,-4.084744453430176,-4.733330249786377],\"type\":\"scattergl\"},{\"hoverinfo\":\"text\",\"hovertext\":[\"View the first 10 rows of the characters dataset\\ndf_characters.head(10)\",\"Show the first 10 rows of the characters dataframe\\ndf_characters.head(10)\",\" Display first 10 rows of the characters dataframe\\ndf_characters.head(10)\",\" Show the first 10 rows of the character dataset\\ndf_characters.head(10)\",\"Display the first 10 records of the character dataset\\ndf_characters.head(10)\",\" 10 first rows\\ndf_characters.head(10)\",\"Display the first 10 rows of the characters dataframe\\ndf_characters.head(10)\",\" View the first 10 rows of the characters dataframe\\ndf_characters.head(10)\",\"Display the first 10 entries of the characters dataframe\\ndf_characters.head(10)\",\"Show the first 10 elements of the characters dataframe\\nprint('Characters dataframe')\\nprint(df_characters.head(10))\\nprint('\\\\n')\",\"Show the first 10 row of the dataframe 'df_characters'\\ndf_characters.head(10)\",\" Display the first 10 rows of the characters dataframe\\ndf_characters.head(10)\",\"Show first 10 rows of the characters dataframe\\ndf_characters.head(10)\",\" Display the first 10 rows of each DataFrame\\ndf_characters.head(10)\",\" Show the first 10 rows of the characters dataframe\\ndf_characters.head(10)\",\"Print the first 10 rows of the characters dataframe\\ndf_characters.head(10)\"],\"marker\":{\"opacity\":0.5,\"size\":5},\"mode\":\"markers+text\",\"name\":\"205_\\\"Viewing First 10 Rows of Characters Dataframe\\\"\",\"text\":[\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\"],\"textfont\":{\"size\":12},\"x\":[0.3145614266395569,-0.4658946990966797,-0.43643125891685486,-0.07643633335828781,0.14217695593833923,-0.3647958040237427,-0.6615201234817505,-0.30511584877967834,-0.44747447967529297,-0.29175227880477905,-0.5782489776611328,-0.30946433544158936,-0.2195017784833908,-0.45425617694854736,-0.17304956912994385,-0.554107129573822],\"y\":[15.527434349060059,15.46288013458252,15.566889762878418,15.411613464355469,15.877591133117676,15.153364181518555,15.742877960205078,15.579681396484375,15.576403617858887,15.369938850402832,15.375165939331055,15.751975059509277,15.456586837768555,15.549991607666016,15.604144096374512,15.465311050415039],\"type\":\"scattergl\"},{\"hoverinfo\":\"text\",\"hovertext\":[\"Check that the character names have not changed\\nassert len(set(df_characters.character_id) - set(df_script.raw_character_text)) == 0\",\"# Functions for later\\ndef get_character_name_from_id(char_id):\\n    \\\"\\\"\\\"\\n    Function to extract the name of a character from his ID\\n    \\\"\\\"\\\"\\n    return df_characters[df_characters.character_id == char_id]['name'].values[0]\\n\\ndef get_location_name_from_id(loc_id):\\n    \\\"\\\"\\\"\\n    Function to extract the name of a location from its ID\\n    \\\"\\\"\\\"\\n    return df_locations[df_locations.location_id == loc_id]['name'].values[0]\",\"Mappings id \\u003c-\\u003e name\\nchar_id_to_name = dict(df_characters[['id', 'name']].values)\\nchar_name_to_id = {v: k for k, v in char_id_to_name.items()}\\n\\nloc_id_to_name = dict(df_locations[['id', 'name']].values)\\nloc_name_to_id = {v: k for k, v in loc_id_to_name.items()}\",\"Create mapping between character name and id\\ncharacter_id_mapping = {row['name'].lower(): row['id'] for idx, row in df_characters.iterrows()}\",\"Create dictionary mapping character IDs to character names\\ncharacter_id_to_name = {character_id: name for character_id, name in zip(df_characters['id'], df_characters['name'])}\",\" Set up variables for storing the required data\\n# Characters\\ncharacters = {}\\nfor index, row in df_characters.iterrows():\\n    char_id = row['id']\\n    name = row['name']\\n    characters[char_id] = name\",\" Build a mapping between character_id and character_name for easier lookup\\ncharacter_id_to_name = df_characters.set_index('character_id')['character_name'].to_dict()\",\"Function to get the character name from a normalized character id\\ndef get_character_name(character_id):\\n    return (df_characters[df_characters['id'] == character_id]['name'].values[0])\",\"Mapping from location_id to location_name\\nlocation_id_to_name = dict(df_locations[['id', 'name']].values)\",\"Setting `character_id` as the index\\ndf_characters.set_index('id', inplace=True)\\n\\n# Let's print the first 5 rows of the characters DataFrame\\ndf_characters.head()\",\"Create a dictionary for characters and locations (from id to string)\\ncharacters_dict = {}\\nlocations_dict = {}\",\"Define the types for pandas\\ndf_characters.astype({\\n    'id': int,\\n    'name': str,\\n    'normalized_name': str\\n})\",\"Create a dictionary to map character IDs to character names.\\ncharacters = dict(zip(df_characters['id'], df_characters['name']))\\nlocations = dict(zip(df_locations['id'], df_locations['name']))\",\"Create a mapping between character names and IDs for fast lookup\\nchar_id_map = {}\\nfor char in tqdm(df_characters.itertuples(), total=len(df_characters)):\\n    char_id_map[char.character_name.lower()] = char.id\",\" Create a cast dict\\ncast_dict = {}\\nfor index, character in df_characters.iterrows():\\n    cast_dict[character['id']] = character['name']\\n\\n# Create a location dict\\nlocation_dict = {}\\nfor index, location in df_locations.iterrows():\\n    location_dict[location['id']] = location['name']\",\" Construct the (id -\\u003e name) mapping for the characters\\nchar_id2name = df_characters.set_index('id')['name'].to_dict()\\n\\n# Construct the (id -\\u003e name) mapping for the locations\\nloc_id2name = df_locations.set_index('id')['name'].to_dict()\"],\"marker\":{\"opacity\":0.5,\"size\":5},\"mode\":\"markers+text\",\"name\":\"206_Mapping character and location IDs to names\",\"text\":[\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\"],\"textfont\":{\"size\":12},\"x\":[5.831918716430664,5.794384479522705,6.664548873901367,5.712963581085205,6.7773966789245605,6.079336166381836,6.492694854736328,6.886087417602539,6.003845691680908,4.809333801269531,7.160739421844482,6.393484115600586,6.020073890686035,5.5113677978515625,6.3289666175842285,6.420079231262207],\"y\":[9.774317741394043,9.008952140808105,9.005722045898438,9.414449691772461,9.335502624511719,9.74983024597168,9.47861385345459,9.201642990112305,8.512284278869629,10.244853019714355,8.256025314331055,9.315796852111816,9.170394897460938,9.545417785644531,8.934895515441895,8.742774963378906],\"type\":\"scattergl\"},{\"hoverinfo\":\"text\",\"hovertext\":[\"Display the first few rows for each table\\nprint('Characters')\\nprint(df_characters.head())\\nprint()\\nprint('Locations')\\nprint(df_locations.head())\\nprint()\\nprint('Script')\\nprint(df_script.head())\\nprint()\\nprint('Episodes')\\nprint(df_episodes.head())\",\"Show all table and column names\\nprint(\\\"\\\\nCharacters Table\\\")\\nprint(df_characters.dtypes)\\nprint(df_characters.head(3))\\nprint(\\\"\\\\nLocations Table\\\")\\nprint(df_locations.dtypes)\\nprint(df_locations.head(3))\\nprint(\\\"\\\\nScript Table\\\")\\nprint(df_script.dtypes)\\nprint(df_script.head(3))\\nprint(\\\"\\\\nEpisodes Table\\\")\\nprint(df_episodes.dtypes)\\nprint(df_episodes.head(3))\",\"Print out all the tables to see their structure\\nprint('Characters:')\\nprint(df_characters.head())\\nprint('\\\\nLocations:')\\nprint(df_locations.head())\\nprint('\\\\nScript:')\\nprint(df_script.head())\\nprint('\\\\nEpisodes:')\\nprint(df_episodes.head())\",\"\\n# Show first rows of the main tables\\nprint(\\\"Characters:\\\")\\nprint(df_characters.head())\\nprint(\\\"\\\\nLocations:\\\")\\nprint(df_locations.head())\\nprint(\\\"\\\\nScript:\\\")\\nprint(df_script.head())\\nprint(\\\"\\\\nEpisodes:\\\")\\nprint(df_episodes.head())\",\"Display each table\\nprint('Simpsons Characters')\\ndisplay(df_characters.head())\\n\\nprint('Simpsons Locations')\\ndisplay(df_locations.head())\\n\\nprint('Simpsons Scripts')\\ndisplay(df_script.head())\\n\\nprint('Simpsons Episodes')\\ndisplay(df_episodes.head())\",\"Shows the first 10 records for all the tables\\nprint(\\\"Characters\\\")\\nprint(df_characters.head(10))\\n\\nprint(\\\"\\\\nLocations\\\")\\nprint(df_locations.head(10))\\n\\nprint(\\\"\\\\nScript lines\\\")\\nprint(df_script.head(10))\\n\\nprint(\\\"\\\\nEpisodes\\\")\\nprint(df_episodes.head(10))\",\"Check size and structure of each table\\nprint(df_characters.head())\\nprint(df_locations.head())\\nprint(df_script.head())\\nprint(df_episodes.head())\",\"\\n# Print the first 5 lines of each table\\nprint('Characters:')\\nprint(df_characters.head())\\nprint('\\\\nLocations:')\\nprint(df_locations.head())\\nprint('\\\\nScript:')\\nprint(df_script.head())\\nprint('\\\\nEpisodes:')\\nprint(df_episodes.head())\",\"Print type and shape of each table\\nprint(\\\"Characters table - \\\", df_characters.shape)\\nprint(\\\"Locations table - \\\", df_locations.shape)\\nprint(\\\"Script table - \\\", df_script.shape)\\nprint(\\\"Episodes table - \\\", df_episodes.shape)\",\"Print head of each table\\nprint(df_characters.head())\\nprint(df_locations.head())\\nprint(df_script.head())\\nprint(df_episodes.head())\",\"heck all tables\\nprint(df_characters.head())\\n\\nprint(df_locations.head())\\n\\nprint(df_script.head())\\n\\nprint(df_episodes.head())\",\"Preview for each table\\nprint(\\\"Characters:\\\")\\nprint(df_characters.info())\\nprint(df_characters.head())\\nprint(\\\"\\\\nLocations:\\\")\\nprint(df_locations.info())\\nprint(df_locations.head())\\nprint(\\\"\\\\nScript:\\\")\\nprint(df_script.info())\\nprint(df_script.head())\\nprint(\\\"\\\\nEpisodes:\\\")\\nprint(df_episodes.info())\\nprint(df_episodes.head())\",\" Check the first few rows of each table\\nprint(df_characters.head())\\nprint(df_locations.head())\\nprint(df_script.head())\\nprint(df_episodes.head())\",\"Check out the schema of each table\\nprint(df_characters.head(3))\\nprint(df_locations.head(3))\\nprint(df_script.head(3))\\nprint(df_episodes.head(3))\",\"# show the first few rows of each table\\nprint(\\\"Characters\\\")\\nprint(df_characters.head())\\n\\nprint(\\\"\\\\nLocations\\\")\\nprint(df_locations.head())\\n\\nprint(\\\"\\\\nScript\\\")\\nprint(df_script.head())\\n\\nprint(\\\"\\\\nEpisodes\\\")\\nprint(df_episodes.head())\",\"Let see the first lines of each tables:\\nprint(\\\"\\\\nSIMPSONS CHARACTERS\\\")\\nprint(df_characters.head())\\nprint(\\\"\\\\nSIMPSONS LOCATIONS\\\")\\nprint(df_locations.head())\\nprint(\\\"\\\\nSIMPSONS SCRIPT\\\")\\nprint(df_script.head())\\nprint(\\\"\\\\nSIMPSONS EPISODES\\\")\\nprint(df_episodes.head())\"],\"marker\":{\"opacity\":0.5,\"size\":5},\"mode\":\"markers+text\",\"name\":\"207_table schema and structure of Simpsons dataset\",\"text\":[\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\"],\"textfont\":{\"size\":12},\"x\":[-2.3552029132843018,-2.3096532821655273,-2.020766019821167,-2.288733720779419,-1.730055332183838,-2.1713547706604004,-2.2278389930725098,-1.6493709087371826,-1.4853572845458984,-2.249124765396118,-2.200218439102173,-1.7882369756698608,-2.5383317470550537,-2.1481387615203857,-2.08193039894104,-2.270071268081665],\"y\":[4.7895283699035645,3.5321290493011475,3.697180986404419,4.08774995803833,3.631925344467163,3.880091428756714,3.215773105621338,4.1468892097473145,2.7314624786376953,3.3556594848632812,2.5640909671783447,3.8760998249053955,3.933544874191284,3.466430425643921,4.023022174835205,3.994532823562622],\"type\":\"scattergl\"},{\"hoverinfo\":\"text\",\"hovertext\":[\"Display the first few rows of the dataframe\\ndf_characters.head()\",\"display first few rows of the dataframe\\ndf_characters.head()\",\" Display the first few rows of the dataframe\\ndf_characters.head()\",\" Display the first few rows of the dataframe\\ndf_characters.head()\",\"Displaying the first few rows of the dataframe\\ndf_characters.head()\",\" Display the first few rows of the dataframe\\ndf_characters.head()\",\" Display the first few rows of the dataframe\\ndf_characters.head()\",\" Display the first few rows of each dataframe\\ndf_characters.head()\",\"Display the first few rows of the dataframe\\ndf_characters.head()\",\"Display first few rows of each dataframe\\ndf_characters.head()\",\" Display the first few rows of the dataframe\\ndf_characters.head()\",\"Display the first few rows of the dataframe\\ndf_characters.head()\",\" Display the first few rows of the dataframe\\ndf_characters.head()\",\" Display the first few rows of the dataframe\\ndf_characters.head()\",\"Display the first few rows of the dataframe \\\"df_characters\\\"\\ndf_characters.head()\",\" Display the first few rows of the dataframe\\ndf_characters.head()\"],\"marker\":{\"opacity\":0.5,\"size\":5},\"mode\":\"markers+text\",\"name\":\"208_displaying first few rows of dataframe\",\"text\":[\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\"],\"textfont\":{\"size\":12},\"x\":[2.118039608001709,2.172579288482666,2.4415407180786133,2.434422492980957,2.3261783123016357,2.056861162185669,2.395725727081299,2.255455493927002,2.3801321983337402,2.254444122314453,2.42553973197937,2.142423152923584,2.2678544521331787,2.489086627960205,2.051996946334839,2.216904640197754],\"y\":[28.039628982543945,28.045900344848633,27.997562408447266,28.32793617248535,28.25425910949707,28.053312301635742,28.305662155151367,27.9710693359375,28.285964965820312,28.112165451049805,28.261533737182617,28.007699966430664,28.189287185668945,27.967540740966797,28.395248413085938,28.29889678955078],\"type\":\"scattergl\"},{\"hoverinfo\":\"text\",\"hovertext\":[\"Select the fields of interest from the dataframes\",\"Join Dfs\",\"All four dataframes have an 'id' attribute that we can use to make joins work better.\",\"Join the dataframes\",\"Set keys for each dataframe\",\"Join the DataFrames\",\"Join dataframes\",\" Join the dataframes on the corresponding keys to create a unified dataframe\",\"Joining the datasets based on the available keys in the dataframes\",\"Add an index to the dataframe to be able to use the efficiency of the join operation.\",\"Join dataframes\",\"Joining the dataframe to get the full data\",\"Do the join on the dataframes\",\"Joining datasets to have a comprehensive dataframe\",\" Join the dataframes\",\"Join the dataframes\"],\"marker\":{\"opacity\":0.5,\"size\":5},\"mode\":\"markers+text\",\"name\":\"209_Joining DataFrames\",\"text\":[\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\"],\"textfont\":{\"size\":12},\"x\":[7.420958518981934,6.64932918548584,6.364129543304443,6.569389343261719,6.2824296951293945,6.6204962730407715,6.552488803863525,6.630805492401123,6.943153381347656,6.603296756744385,6.4193830490112305,6.72286319732666,6.3318095207214355,7.28341817855835,6.538378715515137,6.71811580657959],\"y\":[0.06072397157549858,-0.7951355576515198,0.6512387990951538,0.38554033637046814,0.47378432750701904,0.3103213310241699,0.02391888201236725,-0.07586323469877243,-0.04513618350028992,0.8056502938270569,0.3344253599643707,0.29674452543258667,0.5658586621284485,0.007248155772686005,0.12642768025398254,0.41546159982681274],\"type\":\"scattergl\"},{\"hoverinfo\":\"text\",\"hovertext\":[\"Let's display the first few lines of each dataset to understand their structure and contents.\",\"Print out the first two rows of each of the dataset.\",\" Display the first few lines of each dataset to understand the data\",\"Inspect the first 5 rows of each dataset to understand its structure and content\",\"Print some introductory information about each dataset, like number of columns, number of samples and the content of the first row\",\"Visualizing the dataset by printing out the first few rows\",\"Let's start by printing the first 5 lines of each of these datasets to understand how they look like.\",\" Displaying the first few entries for each of our datasets\",\"Checking the first few rows of data to understand the structure and content of the datasets.\",\"Inspect the first few rows of each dataset to understand its structure and content\",\" Show the main datasets to understand the structure and content\",\"Create a variable to hold the number of lines of the dataset.\",\" Displaying the original dataset's first few lines to get a sense of the information contained.\",\" Prints the top rows of the dataset to understand its structure\",\"Display the first few lines of each dataset to understand its structure and the available fields\",\" Let's echo the last rows of the datasets.\"],\"marker\":{\"opacity\":0.5,\"size\":5},\"mode\":\"markers+text\",\"name\":\"210_Exploring dataset structure and content\",\"text\":[\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\"],\"textfont\":{\"size\":12},\"x\":[14.328110694885254,13.360201835632324,13.307246208190918,14.103039741516113,13.974364280700684,13.390826225280762,14.29352855682373,13.3510160446167,13.993936538696289,13.905787467956543,14.80814266204834,13.121793746948242,13.599495887756348,13.217784881591797,13.773780822753906,13.068638801574707],\"y\":[-3.1288468837738037,-3.5094614028930664,-2.8712611198425293,-3.730290412902832,-2.6536073684692383,-3.519719123840332,-2.8932886123657227,-2.7819905281066895,-3.0163979530334473,-3.5523879528045654,-2.685913324356079,-1.7546648979187012,-3.2236011028289795,-4.649115085601807,-2.8949074745178223,-3.2897965908050537],\"type\":\"scattergl\"},{\"hoverinfo\":\"text\",\"hovertext\":[\" Display the first few rows of the dataset\\ndf_script.head()\",\" Display the first few rows of the script dataset\\ndf_script.head()\",\"Display the first few rows of the dataset for examination\\ndf_script.head()\",\" display the first few rows of the script dataset\\ndf_script.head()\",\"Show the first few rows of the script dataset\\ndf_script.head()\",\" Display the 4 firsts entries of the dataset\\ndf_script.head(4)\",\"Show first rows of the dataset\\ndf_script.head()\",\" Display the first few rows of the dataset\\ndf_script.head()\",\" Display the first few rows of the script dataset\\ndf_script.head()\",\"Show the top few rows of the script dataset\\ndf_script.head()\",\"Display the first few rows of the dataset\\ndf_script.head()\",\"# Display first few rows of the dataset\\ndf_script.head()\",\"Print the first few rows of the script dataset\\ndf_script.head()\",\" Display the first few rows of the script dataset\\ndf_script.head()\",\"Take a peak at the first few rows of the dataset\\ndf_script.head()\",\" Show the first few rows of the script dataset\\ndf_script.head()\"],\"marker\":{\"opacity\":0.5,\"size\":5},\"mode\":\"markers+text\",\"name\":\"211_dataset with first few rows displayed using df_script.head(4)\",\"text\":[\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\"],\"textfont\":{\"size\":12},\"x\":[0.763712465763092,1.1118552684783936,0.7217830419540405,1.1257578134536743,1.185302734375,0.649000346660614,1.2617363929748535,0.8154959678649902,1.2927947044372559,0.9167603254318237,0.8946595191955566,0.5130853652954102,1.3861457109451294,1.0531344413757324,0.6676735281944275,1.37110435962677],\"y\":[-6.627773284912109,-6.40271520614624,-6.616995811462402,-6.494451999664307,-5.9894609451293945,-6.459593772888184,-6.772899627685547,-6.489779949188232,-6.558326244354248,-6.196274280548096,-6.359078407287598,-6.539361476898193,-6.138613700866699,-6.527966022491455,-6.3275017738342285,-6.179210186004639],\"type\":\"scattergl\"},{\"hoverinfo\":\"text\",\"hovertext\":[\"View the characters dataframe\\ndf_characters.head()\",\"Explore the characters dataframe\\ndf_characters.head()\",\"View the characters dataframe\\ndf_characters.head()\",\"Explore the characters dataframe\\ndf_characters.head()\",\"View some basic data about the characters dataframe\\ndf_characters.head()\",\"Explore the characters dataframe\\ndf_characters.head()\",\"Explore the characters dataframe\\ndf_characters.head()\",\" View the characters dataframe\\ndf_characters.head()\",\" Explore the characters dataframe\\ndf_characters.head()\",\"View head of characters dataframe\\ndf_characters.head()\",\"View the characters dataframe\\ndf_characters.head()\",\"View the characters dataframe\\ndf_characters.head()\",\"View the characters dataframe\\ndf_characters.head()\",\"# Initial exploration of the characters dataframe\\ndf_characters.head()\",\"View the characters dataframe\\ndf_characters.head()\"],\"marker\":{\"opacity\":0.5,\"size\":5},\"mode\":\"markers+text\",\"name\":\"212_Initial exploration of character dataframe\",\"text\":[\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\"],\"textfont\":{\"size\":12},\"x\":[7.948204040527344,8.12617015838623,7.644676685333252,8.29326343536377,7.5098772048950195,8.042729377746582,8.178695678710938,7.906222343444824,8.097550392150879,7.748606204986572,7.765965938568115,7.924623489379883,7.980950355529785,8.32170295715332,7.861711502075195],\"y\":[18.93549346923828,19.285919189453125,18.788314819335938,19.088069915771484,18.120086669921875,19.123205184936523,19.292112350463867,18.840625762939453,19.282495498657227,18.380218505859375,18.934091567993164,18.802343368530273,19.02646255493164,19.354005813598633,18.832422256469727],\"type\":\"scattergl\"},{\"hoverinfo\":\"text\",\"hovertext\":[\"Get the most common words in the entire script\\nscript_text = \\\" \\\".join(df_script.raw_text)\\nscript_text = script_text.lower()  # Convert all text to lower case\\nscript_text = \\\" \\\".join(script_text.split())  # Remove extra whitespaces\\n\\n# Download the English model\\n!python -m spacy download en_core_web_sm\\n\\nnlp = spacy.load('en_core_web_sm')\\ndoc = nlp(script_text)\",\"Initialize spacy\\nnlp = spacy.load('en_core_web_sm', disable=['ner', 'parser'])\\n\\n# Preprocessing\\ndf_script = df_script.fillna('')\\ndf_script['character_id'] = df_script['character_id'].apply(lambda x: x.strip())\\ndf_script['location_id'] = df_script['location_id'].apply(lambda x: x.strip())\\ndf_script['raw_text'] = df_script['raw_text'].apply(lambda x: x.strip())\\n\\ndf_episodes = df_episodes.fillna('')\",\"TF-IDF for scripts\\nfrom sklearn.feature_extraction.text import TfidfVectorizer\",\" Define stop words and punctuation to remove from the script\\nstop_words = spacy.lang.en.stop_words.STOP_WORDS\\npunctuation = '!\\\"#$%&\\\\'()*+,-.\\u002f:;\\u003c=\\u003e?@[\\\\\\\\]^_`{|}~'\\n\\n# Load the language model and parse the dialog\\nnlp = spacy.load('en_core_web_sm')\\ndialogue = ' '.join(df_script['raw_text'].values)\\nparsed_dialogue = nlp(dialogue)\",\"Df2nlp_class.py\\n# Custom class for the following\\n# - Load\\n# - Preprocess\\n# - Tokenize\\n# - Build Corpus\\n# - Embedding representation\\n# - Helper functions\\n#      - txt to segments\\n#      - txt to sequences\\n# Import file\",\"# Filter the non-english sentences\\ndf_script['script'] = df_script['spoken_words']\\n\\n# Load the English tokenizer\\nnlp = spacy.blank('en')\\n\\n# Tokenize **approximately** to sentences\\ndocs = df_script.script[:1000].apply(lambda x: nlp(x))\\n\\nsentences = []\\nfor doc in docs:\\n    sentences.extend([sent.text.lower() for sent in doc.sents if len(sent.text) \\u003e 1])\",\"# Set up\\nnlp = spacy.load('en_core_web_sm')\\n\\n# Only consider named entities that are characters or locations\\ndf_script_filtered = df_script[(df_script['raw_character_text'].notnull()) | (df_script['raw_location_text'].notnull())]\\n# Replace nans with empty strings\\ndf_script_filtered = df_script_filtered.fillna('')\\n\\n# Lemmatization mapping\\nlemmatization_df = pd.read_csv('data\\u002flemmatization.csv', index_col=0, squeeze=True).to_dict()\",\"Create a spaCy object\\nnlp = spacy.load(\\\"en_core_web_sm\\\", disable=['ner', 'parser'])\\n\\n# Apply processing to each line in the script\\ndocs = list(nlp.pipe(df_script['raw_text'], batch_size=1000, n_process=-1))\",\"Create a spacy nlp object\\nnlp = spacy.load(\\\"en_core_web_sm\\\")\\n\\n# Process the text and add it to the dataframe\\nprocessed_script = []\",\" Create a new column for the spacy embeddings for each line in the script\\ndf_script['spacy_doc'] = df_script['normalized_text'].apply(lambda x: nlp(x))\",\"Remove non-English lines from the script dataframe\\n# English language detection\\nnlp = spacy.load('en_core_web_sm')\\n\\ndef detect_english_nlp(text):\\n    try:\\n        doc = nlp(text)\\n        # Consider a text in English if the stopwords are less than 60% of the total words\\n        if (len(doc) \\u003e 0 and len(doc) \\u002f len(text) \\u003e 0.4):\\n            return True\\n        else:\\n            return False\\n    # If the text is too large spacy returns a value error\\n    except:\\n        return False\\n\\ntqdm.pandas()\\ndf_script = df_script[df_script['raw_text'].progress_apply(detect_english_nlp)]\",\"Set character_id as index for fast sclicing\\ndf_characters.set_index('id', inplace=True)\\n\\n# Setup Spacy\\nnlp = spacy.load(\\\"en_core_web_sm\\\")\",\" Set up spaCy\\nnlp = spacy.load('en_core_web_sm')\\n\\n# Process the script data with spaCy (only applied when not already contained in the dataframe)\\nif 'spacy_processed' not in df_script.columns:\\n    doc = df_script['raw_text'].progress_apply(lambda x: nlp(x))\\n    df_script.insert(1, 'spacy_processed', doc)  # Insert spaCy processed data in a column in the dataframe.\",\"Text preprocessing\\n# We want to preprocess the spoken words, removing special characters and non-useful information in order to create a wordcloud\\ndf_script_processed = df_script[['raw_character_text', 'spoken_words']].dropna().copy()\\ndf_script_processed['spoken_words'] = df_script_processed['spoken_words'] \\\\\\n    .str.replace(r'[^A-Za-z\\\\s]', '') \\\\\\n    .str.lower()\\n\\n# Using Spacy for our corpora of text\\nnlp = spacy.load('en')\\n\\n# Let's filter the characters names from the text\\n# We'll perform only Named Entity Recognition and keep the identified characters\\ndf_script_processed = df_script_processed[:int(len(df_script_processed)\\u002f50)]\\nidentified_characters = {}\\nfor character in tqdm(df_script_processed.raw_character_text.unique()):\\n    character_doc = nlp(character)\\n    identified_characters[character] = list(set([ent.text for ent in character_doc.ents if ent.label_ == 'PERSON']))\\n\\n# Let's double-check the presence of those characters and their identification\\n{\\n    character: identified_characters[character]\\n    for character in identified_characters\\n    if identified_characters[character]\\n}\",\"merge the first and last names\\ndf_characters['name'] = df_characters['name'].str.split().apply(lambda x: x[0] + '_' + x[1] if len(x) \\u003e 1 else x[0])\\n\\n# Load model\\nnlp = spacy.load('en_core_web_sm')\"],\"marker\":{\"opacity\":0.5,\"size\":5},\"mode\":\"markers+text\",\"name\":\"213_Text processing and filtering with spaCy\",\"text\":[\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\"],\"textfont\":{\"size\":12},\"x\":[12.728421211242676,4.530887603759766,11.792078018188477,12.735109329223633,12.110332489013672,12.218198776245117,13.391550064086914,13.278337478637695,13.671631813049316,12.4983491897583,13.075485229492188,13.795478820800781,13.297582626342773,12.491147994995117,13.214879989624023],\"y\":[8.93683910369873,6.147058963775635,8.950763702392578,8.203485488891602,8.84000015258789,8.64501667022705,9.389907836914062,8.83728313446045,8.96751880645752,8.83648681640625,8.676795959472656,9.074586868286133,9.057809829711914,8.919376373291016,8.802687644958496],\"type\":\"scattergl\"},{\"hoverinfo\":\"text\",\"hovertext\":[\"Visualization of the number of lines per characters.\",\" Calculate and plot the number of lines per character.\",\" Show the first few lines of characters data.\",\"Display the number of lines of each character\",\"Count lines ready for parsing\",\"function to get characters lines\",\"Function to normalize the lines of a character\",\"Check number of lines for each Character ID\",\"Visualize number of lines per character\",\"Check the count of lines and characters\",\"Weight each character's occurrence by the length of the line (expanding counting heavily in longer lines)\",\" Check what the line looks like\",\" Visualize the number of lines spoken by each character.\",\"Get the number of lines for the characters.\",\"Print the number of lines with missing character, location or raw_text, if any.\"],\"marker\":{\"opacity\":0.5,\"size\":5},\"mode\":\"markers+text\",\"name\":\"214_Character line analysis\",\"text\":[\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\"],\"textfont\":{\"size\":12},\"x\":[9.90864086151123,9.892171859741211,10.3952054977417,10.262076377868652,10.288249969482422,10.107288360595703,10.10860538482666,9.839234352111816,9.675653457641602,10.430379867553711,10.256634712219238,10.696152687072754,9.602314949035645,10.203591346740723,9.856534957885742],\"y\":[7.525389194488525,7.906259059906006,8.439497947692871,7.47735071182251,7.201502323150635,6.7928996086120605,7.2959394454956055,7.944312572479248,7.360605716705322,7.482371807098389,7.731991767883301,6.697247505187988,7.635499000549316,7.175076484680176,7.603898048400879],\"type\":\"scattergl\"},{\"hoverinfo\":\"text\",\"hovertext\":[\"Create a dict to map character id to character name.\",\"Create character id to character name dictionary\",\"To harmonize the location names supplementary gathered from the internet, I'll ensure these strings either appear in lower case or are capitalized.\",\"Create character, location and episode maps to go from string to int and vice versa\",\"A function to retrieve the character information from the character_id.\",\"Build a dictionary for characters and locations for easier access\",\"Setup the selected character ID and retrieve the chosen character's name\",\"Define the name to ID mapping and ID to name mapping for characters and locations.\",\"Convert gender, character and location Id's to character and location names respectively.\",\"Load the character and location label encoders\",\"Create maps: lookup tables for location and character names\",\"anya all the tables to dictionaries\",\"Creates a dictionary to map character id to character name\",\"Create character's and location's names maps\",\"Set shorthands for character and location names\"],\"marker\":{\"opacity\":0.5,\"size\":5},\"mode\":\"markers+text\",\"name\":\"215_Creating Maps for Character and Location Names\",\"text\":[\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\"],\"textfont\":{\"size\":12},\"x\":[8.127116203308105,8.207928657531738,9.538121223449707,8.314506530761719,8.86099624633789,8.485910415649414,8.941269874572754,8.428620338439941,8.558183670043945,9.077522277832031,8.467389106750488,12.290356636047363,8.39210319519043,8.442111015319824,9.117040634155273],\"y\":[8.65452766418457,8.262497901916504,6.798506736755371,6.2068986892700195,8.451387405395508,7.421477794647217,8.0626220703125,7.1598286628723145,6.917081356048584,5.498895645141602,6.087713718414307,6.221729278564453,7.989279747009277,6.432009696960449,6.160426616668701],\"type\":\"scattergl\"},{\"hoverinfo\":\"text\",\"hovertext\":[\"Display the first few records of the characters dataframe\\ndf_characters.head()\",\" Display the first few records of the characters dataframe\\ndf_characters.head()\",\" Display the first few entries of df_characters\\ndf_characters.head()\",\" Display the first few records of `df_characters`\\ndf_characters.head()\",\"View the first few entries in the characters dataframe\\ndf_characters.head()\",\"Use the head function to display the first few records of the DataFrame\\ndf_characters.head()\",\"Display the first few records of the characters dataframe\\ndf_characters.head()\",\"begin by displaying the first few records of each DataFrame.\\ndf_characters.head()\",\"# Display first few records of df_chars\\ndf_characters.head()\",\"Displaying the first few entries of the characters dataframe\\ndf_characters.head()\",\"Display the first few entries of the characters data frame\\ndf_characters.head()\",\"Display the first few records of the characters dataframe\\ndf_characters.head()\",\"View first few records of characters DataFrame\\ndf_characters.head()\",\"View the first few records of the characters dataframe\\ndf_characters.head()\",\"Display the first few records of the characters data frame\\ndf_characters.head()\"],\"marker\":{\"opacity\":0.5,\"size\":5},\"mode\":\"markers+text\",\"name\":\"216_displaying the first few records of the characters dataframe\",\"text\":[\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\"],\"textfont\":{\"size\":12},\"x\":[-0.08826403319835663,-0.19312311708927155,0.2711080014705658,0.12453728914260864,0.08325798809528351,-0.5328648090362549,-0.3073202967643738,-0.28357693552970886,0.0806128978729248,0.19891738891601562,-0.24235214293003082,-0.2619490921497345,-0.35414430499076843,0.007086685858666897,-0.2906232476234436],\"y\":[18.074615478515625,18.063608169555664,18.3846378326416,18.01350212097168,19.27435302734375,18.093809127807617,18.131961822509766,17.90545082092285,17.596981048583984,18.808815002441406,19.050033569335938,18.18532371520996,18.692930221557617,18.552200317382812,18.326934814453125],\"type\":\"scattergl\"},{\"hoverinfo\":\"text\",\"hovertext\":[\" Display settings\\npd.set_option('display.max_columns', None)\\npd.set_option('display.max_rows', None)\",\"Show configurations for a better layout\\npd.options.display.max_columns = None\\npd.options.display.max_rows = 10\",\"Global configurations\\npd.set_option('display.max_columns', None)\\npd.set_option('display.max_rows', None)\",\"Display max rows and columns\\npd.set_option('display.max_rows', None)\\npd.set_option('display.max_columns', None)\",\"Display settings\\npd.set_option('display.max_columns', None)\\npd.set_option('display.max_rows', None)\",\"Display columns\\npd.set_option('display.max_columns', None)\\npd.set_option('display.max_rows', None)\",\"Rows to display\\npd.set_option('display.max_columns', None)\\npd.set_option('display.max_rows', None)\",\"Display all rows and columns\\npd.set_option('display.max_rows', None)\\npd.set_option('display.max_columns', None)\",\" Set maximum columns and rows to display\\npd.set_option('display.max_columns', None)\\npd.set_option('display.max_rows', None)\",\"Display configurations\\npd.set_option('display.max_columns', None)\\npd.set_option('display.max_rows', None)\",\"Explore the data\\npd.set_option('display.max_columns', None)\\npd.set_option('display.max_rows', None)\",\"Set constants or options\\n# Constants\\nSEED = 42\\n\\n# Options\\npd.set_option('display.max_columns', None)\\npd.set_option('display.max_rows', None)\",\" Set maximum columns and rows to display\\npd.set_option('display.max_columns', None)\\npd.set_option('display.max_rows', None)\",\"Rows and columns shown in their entirety\\npd.set_option('display.max_columns', None)\\npd.set_option('display.max_rows', None)\",\"Set the maximum number of columns\\u002frows printed without truncation\\npd.set_option('display.max_columns', None)\\npd.set_option('display.max_rows', None)\"],\"marker\":{\"opacity\":0.5,\"size\":5},\"mode\":\"markers+text\",\"name\":\"217_Display Configurations and Options\",\"text\":[\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\"],\"textfont\":{\"size\":12},\"x\":[24.56621742248535,24.88751792907715,24.4007625579834,24.548263549804688,24.39027214050293,24.64620018005371,24.846149444580078,24.689624786376953,24.565242767333984,24.397157669067383,24.513090133666992,24.204246520996094,24.716703414916992,24.676532745361328,24.117996215820312],\"y\":[0.4318619966506958,0.19048498570919037,-0.05199415609240532,0.14897789061069489,0.2814275026321411,0.2756551206111908,0.09751681983470917,0.40726810693740845,-0.12477632611989975,0.4708944857120514,-0.44256681203842163,-0.14199726283550262,-0.09326890856027603,-0.14878897368907928,-0.36830171942710876],\"type\":\"scattergl\"},{\"hoverinfo\":\"text\",\"hovertext\":[\"Inspect the first few rows of each dataframe to understand the structure of the data and the information it contains.\",\"Inspect the first few rows of each dataframe to understand its structure and the type of insights it might offer.\",\"Inspect the first few rows of each dataframe to understand its structure and contents.\",\"Inspect the first few rows of each dataframe to understand their structure and content.\",\"Inspect the dataframe's initial rows.\",\"Inspect the first few rows of each dataframe to understand its structure and contents.\",\"inspect the first few rows of each dataframe to see its structure.\",\"Inspect the first few rows of each dataframe to understand their structure and the type of data stored in them.\",\"Inspect the first few rows of each dataframe to understand its structure and the information it contains.\",\"Inspect the first few rows of each DataFrame to understand its structure and contents.\",\"Inspect the first few rows of each dataframe to understand its structure and available features.\",\"Inspect the first few rows of each dataframe to understand their structure and contents.\",\"Inspect the first few rows of each DataFrame to understand the structure and data types.\",\"Explore the dataframes (i.e., dimensions, first few rows, data types, NaNs)\",\"Inspect the first few rows of each dataframe to understand its structure and contents.\"],\"marker\":{\"opacity\":0.5,\"size\":5},\"mode\":\"markers+text\",\"name\":\"218_Understanding the structure and contents of dataframes\",\"text\":[\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\"],\"textfont\":{\"size\":12},\"x\":[11.561287879943848,11.915193557739258,12.286558151245117,11.52955436706543,12.435867309570312,12.018596649169922,11.681591033935547,11.490078926086426,11.611856460571289,12.140416145324707,11.766620635986328,11.909037590026855,11.673897743225098,12.047566413879395,12.149969100952148],\"y\":[-7.464479446411133,-7.643646717071533,-7.543187141418457,-7.823336601257324,-7.9086151123046875,-7.59769344329834,-7.02848482131958,-7.263704776763916,-7.191611289978027,-7.498515605926514,-7.922929286956787,-7.540031433105469,-7.049022197723389,-7.685257434844971,-7.573890686035156],\"type\":\"scattergl\"},{\"hoverinfo\":\"text\",\"hovertext\":[\" Tokenize the documents\",\"Tokenize using spacy\",\" Tokenizer for spacy model\",\" Tokenize script lines using SpaCy\",\"Tokenize using Spacy\",\" Tokenize the script lines using spacy.\",\"Set'token_default'space English-language'tokenizer.\",\"Create an instance of the English spacy tokenizer model.\",\"Initialization of a tokenizer using Spacy's English language model.\",\"Create a list of all character names and their corresponding tokens using Spacy\",\"Tokenizes a string into a list of words, filtering out unwanted tokens.\",\" Tokenization \",\"Set up the tokenization pipeline with spaCy\",\"Tokenize the script lines using Spacy's en_core_web_sm model.\",\"Declare a function for tokenizing the data using spacy\"],\"marker\":{\"opacity\":0.5,\"size\":5},\"mode\":\"markers+text\",\"name\":\"219_Tokenizing documents using Spacy\",\"text\":[\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\"],\"textfont\":{\"size\":12},\"x\":[13.632884979248047,13.668044090270996,14.339428901672363,13.214680671691895,13.684003829956055,13.067611694335938,13.94510269165039,14.101105690002441,14.150729179382324,13.379232406616211,13.20077133178711,13.663323402404785,13.989995956420898,13.616647720336914,13.987872123718262],\"y\":[5.781772613525391,5.89750337600708,5.867303848266602,5.741192817687988,5.835461616516113,5.5848283767700195,6.225314140319824,6.515260219573975,6.192706108093262,6.637170314788818,6.363759994506836,6.124632835388184,6.02642822265625,6.353473663330078,5.5410566329956055],\"type\":\"scattergl\"},{\"hoverinfo\":\"text\",\"hovertext\":[\"Create a function to filter the data frames by season.\",\"Filter script by season\",\"Selecting only a specific season data for the analysis due to the memory limitations in the local environment\",\"Removing all data after Season 20 (including) to avoid further spoilers\",\"Create dictionary for all the seasons\",\"Season filter\\nseasons = []\",\"Some more data preprocessing: remove rows with missing data and keep only the script lines from the first 10 seasons\",\"Define the paths to the season folders and the file names for all seasons.\",\" Parameters\\nseason_of_interest = 10\",\"Filter by season\",\"\\n# Selected season\\nseason_number = 8\",\"Filtering the dataset to only include data from the first 10 seasons\",\"Filter seasons before COVID-19\",\"Declare seasons for easy iteration\",\"Keep only data from the first 15 seasons (last season included = 15)\"],\"marker\":{\"opacity\":0.5,\"size\":5},\"mode\":\"markers+text\",\"name\":\"220_Season Filtering and Data Selection\",\"text\":[\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\"],\"textfont\":{\"size\":12},\"x\":[8.543000221252441,7.909731388092041,8.845571517944336,8.261974334716797,9.966474533081055,8.679206848144531,7.836920261383057,11.455530166625977,9.140600204467773,8.863022804260254,8.228409767150879,8.223196983337402,8.14714241027832,10.13337230682373,8.064340591430664],\"y\":[3.155989170074463,3.081791639328003,3.0007073879241943,2.798219919204712,3.0872464179992676,2.81144380569458,3.409327983856201,3.3727786540985107,2.7050509452819824,2.769911527633667,2.7880358695983887,2.954228162765503,2.717801809310913,2.702934980392456,3.1099777221679688],\"type\":\"scattergl\"},{\"hoverinfo\":\"text\",\"hovertext\":[\"Let's take a look at the first few lines of each dataframe.\",\"Let's take a look to the first lines of each Dataframe.\",\"Let's take a look at the first few lines of each DataFrame.\",\"Let's take a look at the first few lines of each of these DataFrames.\",\" Let's take a look at heads of each dataframe\",\"Let's have a look at the first few lines of each DataFrame.\",\"Let's take a look at the first few lines of each dataframe.\",\"Check the introduction of data and cleanup the relevant DataFrames.\",\"Let's try to see what each dataframe looks like.\",\"Let's take a look at the first few lines of each DataFrame.\",\"Right before we begin any analysis, let's take a look at the head of each dataframe.\",\"Let's check the data in each dataframe.\",\"Let's take a look at the first few lines of each dataframe.\",\"I commented out the lines creating the dataframes to avoid re-running them when unnecessary.\",\" Let's take a look at first few lines of each of these DataFrame using the head() method.\"],\"marker\":{\"opacity\":0.5,\"size\":5},\"mode\":\"markers+text\",\"name\":\"221_Dataframe analysis and cleanup\",\"text\":[\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\"],\"textfont\":{\"size\":12},\"x\":[9.748809814453125,10.168065071105957,9.94898509979248,9.87147045135498,9.178107261657715,9.772212982177734,9.731891632080078,9.897273063659668,10.248380661010742,9.630009651184082,9.40064811706543,9.895715713500977,9.704160690307617,9.727310180664062,9.87869930267334],\"y\":[-5.339358806610107,-6.208324432373047,-5.380393981933594,-6.309859275817871,-5.694506645202637,-5.5878424644470215,-5.4178242683410645,-4.695199489593506,-5.413593292236328,-5.375268459320068,-5.5824198722839355,-5.567372798919678,-5.358363151550293,-3.418318748474121,-5.615589141845703],\"type\":\"scattergl\"},{\"hoverinfo\":\"text\",\"hovertext\":[\"Print the amount of rows in each dataframe\\nprint(f'Characters df shape: {df_characters.shape}')\\nprint(f'Locations df shape: {df_locations.shape}')\\nprint(f'Script df shape: {df_script.shape}')\\nprint(f'Episodes df shape: {df_episodes.shape}')\",\"\\n# print the number of rows and columns in each dataframe\\nprint(\\\"Characters dataframe:\\\", df_characters.shape)\\nprint(\\\"Locations dataframe:\\\", df_locations.shape)\\nprint(\\\"Script dataframe:\\\", df_script.shape)\\nprint(\\\"Episodes dataframe:\\\", df_episodes.shape)\",\"Let's print the number of rows in each dataframe using the shape attribute.\",\" Display the size and first few rows of each dataframe\\nfor df_name, df in zip(['characters', 'locations', 'script', 'episodes'], [df_characters, df_locations, df_script, df_episodes]):\\n    print(df_name)\\n    print(f'Size: {df.shape}')\\n    display(df.head())\\n    print()\",\"Display the number of rows and columns for each dataset\\nprint(\\\"Characters:\\\", df_characters.shape)\\nprint(\\\"Locations:\\\", df_locations.shape)\\nprint(\\\"Script:\\\", df_script.shape)\\nprint(\\\"Episodes:\\\", df_episodes.shape)\",\"Display the number of rows and columns for each dataframes\\nfor name, dataframe in zip(['Characters', 'Locations', 'Episodes', 'Script'], [df_characters, df_locations, df_episodes, df_script]):\\n    print('{}: {} rows, {} columns'.format(name, dataframe.shape[0], dataframe.shape[1]))\",\"Display the number of rows and columns in each dataframe\\nprint(\\\"Characters:\\\")\\nprint(df_characters.shape)\\nprint(df_characters.columns)\\nprint(\\\"\\\\nLocations:\\\")\\nprint(df_locations.shape)\\nprint(df_locations.columns)\\nprint(\\\"\\\\nScript:\\\")\\nprint(df_script.shape)\\nprint(df_script.columns)\\nprint(\\\"\\\\nEpisodes:\\\")\\nprint(df_episodes.shape)\\nprint(df_episodes.columns)\",\"Print the number of rows in the characters, locations, script and episodes DataFrames\\nprint(df_characters .shape[0])\\nprint(df_locations.shape[0])\\nprint(df_script   .shape[0])\\nprint(df_episodes .shape[0])\",\" Display the number of rows and columns for each dataframe\\nprint(f'Characters: {df_characters.shape}')\\nprint(f'Locations: {df_locations.shape}')\\nprint(f'Script: {df_script.shape}')\\nprint(f'Episodes: {df_episodes.shape}')\",\"Display the number of rows and columns for each dataframe\\nfor name, df in zip(['Characters', 'Locations', 'Script', 'Episodes'], \\n                    [df_characters, df_locations, df_script, df_episodes]):\\n    print(f\\\"{name} has {df.shape[0]} rows and {df.shape[1]} columns\\\")\",\" Display the number of rows and columns for each dataframe\\nprint(\\\"characters:\\\", df_characters.shape)\",\"Display the number of rows and columns for each dataframe\\nprint(f\\\"Characters dataframe shape: {df_characters.shape}\\\")\\nprint(f\\\"Locations dataframe shape: {df_locations.shape}\\\")\\nprint(f\\\"Script dataframe shape: {df_script.shape}\\\")\\nprint(f\\\"Episodes dataframe shape: {df_episodes.shape}\\\")\",\" Display the number of rows and columns for each dataset\\nprint('Characters:', df_characters.shape)\\nprint('Locations:', df_locations.shape)\\nprint('Script:', df_script.shape)\\nprint('Episodes:', df_episodes.shape)\",\"Display the number of rows and columns in each dataset\\nprint(\\\"Characters:\\\", df_characters.shape)\\nprint(\\\"Locations:\\\", df_locations.shape)\\nprint(\\\"Script:\\\", df_script.shape)\\nprint(\\\"Episodes:\\\", df_episodes.shape)\",\"Show the number of rows and column in each dataframe\\ndf_episodes.shape, df_script.shape, df_characters.shape, df_locations.shape\"],\"marker\":{\"opacity\":0.5,\"size\":5},\"mode\":\"markers+text\",\"name\":\"222_Displaying Dataframe Shapes\",\"text\":[\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\"],\"textfont\":{\"size\":12},\"x\":[2.3842976093292236,2.125378131866455,2.78393816947937,1.3197628259658813,1.784721851348877,2.0155832767486572,2.5101981163024902,1.866264820098877,2.4131662845611572,1.8870599269866943,3.00164794921875,2.3865010738372803,2.3961408138275146,2.095763683319092,2.3525798320770264],\"y\":[-0.5581163763999939,-0.5225074887275696,-0.2820274829864502,0.12927496433258057,-0.20861957967281342,-0.24496880173683167,-0.39716091752052307,-0.365685373544693,-0.37308958172798157,-0.41576138138771057,0.2991540729999542,-0.46881604194641113,-0.3289831876754761,-0.0861193910241127,-0.5626425743103027],\"type\":\"scattergl\"},{\"hoverinfo\":\"text\",\"hovertext\":[\" Display the first 5 rows of each dataframe\\nprint(\\\"\\\\ncharacters\\\")\\nprint(df_characters.head())\\n\\nprint(\\\"\\\\nlocations\\\")\\nprint(df_locations.head())\\n\\nprint(\\\"\\\\nscript\\\")\\nprint(df_script.head())\\n\\nprint(\\\"\\\\nepisodes\\\")\\nprint(df_episodes.head())\",\"Show first 5 rows of each dataframe\\nprint('Characters:')\\nprint(df_characters.head(5))\\nprint('\\\\n\\\\nLocations:')\\nprint(df_locations.head(5))\\nprint('\\\\n\\\\nScript:')\\nprint(df_script.head(5))\\nprint('\\\\n\\\\nEpisodes:')\\nprint(df_episodes.head(5))\",\"Print the first 3 lines of each dataset\\nfor df, name in zip([df_characters, df_locations, df_script, df_episodes], \\n                    ['df_characters', 'df_locations', 'df_script', 'df_episodes']):\\n    print(name)\\n    display(df.head(3))\\n    print('\\\\n')\",\" Visualize the first few rows of each DataFrame\\nprint(\\\"Characters Data:\\\")\\nprint(df_characters.head(), end=\\\"\\\\n\\\\n\\\")\\n\\nprint(\\\"Locations Data:\\\")\\nprint(df_locations.head(), end=\\\"\\\\n\\\\n\\\")\\n\\nprint(\\\"Script Data:\\\")\\nprint(df_script.head(), end=\\\"\\\\n\\\\n\\\")\\n\\nprint(\\\"Episodes Data:\\\")\\nprint(df_episodes.head(), end=\\\"\\\\n\\\\n\\\")\",\"Print the first 5 rows of each dataframe to understand its structure\\nprint(\\\"Characters:\\\\n\\\", df_characters.head(), \\\"\\\\n\\\\n\\\")\\nprint(\\\"Locations:\\\\n\\\", df_locations.head(), \\\"\\\\n\\\\n\\\")\\nprint(\\\"Script lines:\\\\n\\\", df_script.head(), \\\"\\\\n\\\\n\\\")\\nprint(\\\"Episodes:\\\\n\\\", df_episodes.head())\",\" Display the first few rows of each dataframe\\nprint(\\\"Characters dataframe:\\\")\\nprint(df_characters.head(), '\\\\n')\\n\\nprint(\\\"Locations dataframe:\\\")\\nprint(df_locations.head(), '\\\\n')\\n\\nprint(\\\"Script dataframe:\\\")\\nprint(df_script.head(), '\\\\n')\\n\\nprint(\\\"Episodes dataframe:\\\")\\nprint(df_episodes.head())\",\"Display the first 5 rows of each DataFrame\\nprint(\\\"Characters\\\")\\ndisplay(df_characters.head())\\nprint(\\\"\\\\nLocations\\\")\\ndisplay(df_locations.head())\\nprint(\\\"\\\\nScript\\\")\\ndisplay(df_script.head())\\nprint(\\\"\\\\nEpisodes\\\")\\ndisplay(df_episodes.head())\",\" Display first 5 rows of the data\\nprint(\\\"Characters:\\\")\\ndisplay(df_characters.head())\\nprint(\\\"\\\\nLocations:\\\")\\ndisplay(df_locations.head())\\nprint(\\\"\\\\nScript:\\\")\\ndisplay(df_script.head())\\nprint(\\\"\\\\nEpisodes:\\\")\\ndisplay(df_episodes.head())\",\" Outputs first 5 rows of each dataset\\nprint(\\\"Characters dataset\\\")\\nprint(df_characters.head())\\nprint(\\\"\\\\n\\\")\\n\\nprint(\\\"Locations dataset\\\")\\nprint(df_locations.head())\\nprint(\\\"\\\\n\\\")\\n\\nprint(\\\"Script dataset\\\")\\nprint(df_script.head())\\nprint(\\\"\\\\n\\\")\\n\\nprint(\\\"Episodes dataset\\\")\\nprint(df_episodes.head())\",\"Display first 5 rows for each of the datasets\\nprint(\\\"\\\\n\\\\nCharacters:\\\")\\nprint(df_characters.head())\\n\\nprint(\\\"\\\\n\\\\nLocations:\\\")\\nprint(df_locations.head())\\n\\nprint(\\\"\\\\n\\\\nScript:\\\")\\nprint(df_script.head())\\n\\nprint(\\\"\\\\n\\\\nEpisodes:\\\")\\nprint(df_episodes.head())\",\" Display the first 5 rows of each dataframe\\nprint('Characters:')\\nprint(df_characters.head())\\nprint('\\\\n\\\\nLocations:')\\nprint(df_locations.head())\\nprint('\\\\n\\\\nScript:')\\nprint(df_script.head())\\nprint('\\\\n\\\\nEpisodes:')\\nprint(df_episodes.head())\",\"# Display the first 5 rows of each dataframe\\nprint(\\\"Characters:\\\")\\nprint(df_characters.head())\\nprint(\\\"\\\\nLocations:\\\")\\nprint(df_locations.head())\\nprint(\\\"\\\\nScript:\\\")\\nprint(df_script.head())\\nprint(\\\"\\\\nEpisodes:\\\")\\nprint(df_episodes.head())\",\" Display the first 5 rows of each DataFrame to see how the data is structured\\nprint(\\\"\\\\n\\\\n\\\")\\nprint(\\\"Characters:\\\")\\nprint(df_characters.head())\\n\\nprint(\\\"\\\\n\\\\n\\\")\\nprint(\\\"Locations:\\\")\\nprint(df_locations.head())\\n\\nprint(\\\"\\\\n\\\\n\\\")\\nprint(\\\"Script:\\\")\\nprint(df_script.head())\\n\\nprint(\\\"\\\\n\\\\n\\\")\\nprint(\\\"Episodes:\\\")\\nprint(df_episodes.head())\",\"Print the first 5 rows of each of the imported DataFrames\\nprint('\\\\nCharacters DataFrame:')\\nprint(df_characters.head(5))\\n\\nprint('\\\\nLocations DataFrame:')\\nprint(df_locations.head(5))\\n\\nprint('\\\\nScript DataFrame:')\\nprint(df_script.head(5))\\n\\nprint('\\\\nEpisodes DataFrame:')\\nprint(df_episodes.head(5))\",\"Check out the first few lines of dataframes\\nprint(\\\"First few lines of df_characters\\\")\\nprint(df_characters.head(3))\\nprint(\\\"\\\\n\\\\n\\\")\\n\\nprint(\\\"First few lines of df_locations\\\")\\nprint(df_locations.head(3))\\nprint(\\\"\\\\n\\\\n\\\")\\n\\nprint(\\\"First few lines of df_script\\\")\\nprint(df_script.head(3))\\nprint(\\\"\\\\n\\\\n\\\")\\n\\nprint(\\\"First few lines of df_episodes\\\")\\nprint(df_episodes.head(3))\"],\"marker\":{\"opacity\":0.5,\"size\":5},\"mode\":\"markers+text\",\"name\":\"223_Displaying Dataframe Head\",\"text\":[\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\"],\"textfont\":{\"size\":12},\"x\":[-1.3539177179336548,-1.2855007648468018,-0.9221413135528564,-1.898685097694397,-1.3625367879867554,-2.12819242477417,-1.5341222286224365,-1.4793883562088013,-1.570996880531311,-1.4214742183685303,-1.1683738231658936,-1.1647937297821045,-1.25156569480896,-1.46299147605896,-1.9685882329940796],\"y\":[5.828964710235596,5.933841228485107,4.186707496643066,4.993777275085449,5.265200138092041,5.192697048187256,5.794905662536621,5.282634735107422,4.6910247802734375,5.031074047088623,5.637308120727539,5.535302639007568,5.140119552612305,5.530482769012451,5.202968597412109],\"type\":\"scattergl\"},{\"hoverinfo\":\"text\",\"hovertext\":[\"Check the content of the first 5 rows of the dataframe containing the characters\",\" Check the first 5 rows of the characters dataframe.\",\"Checking the top 5 rows of the characters dataframe\",\"Check the first 5 rows of the characters dataframe.\",\"Check out the first 5 rows of the characters dataframe\",\"Check the first 5 rows of the characters dataframe\",\" The top 5 rows of the characters dataframe are:\",\"Check the first 5 rows of the characters dataframe to understand the data\",\"Check the first 5 rows of the characters dataframe.\",\"Check the first 5 rows of the characters dataframe.\",\" Check the first 5 rows of the characters dataframe.\",\"Check the first 5 rows of the characters dataframe.\",\"Checking the top 5 rows of the characters dataframe.\",\"Checking out the first 5 characters dataframe\",\"Check the first five rows of the characters dataframe.\"],\"marker\":{\"opacity\":0.5,\"size\":5},\"mode\":\"markers+text\",\"name\":\"224_Checking the top 5 rows of the characters dataframe\",\"text\":[\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\"],\"textfont\":{\"size\":12},\"x\":[10.918342590332031,10.58915901184082,9.921548843383789,10.266072273254395,10.652666091918945,10.619812965393066,9.55849552154541,10.73555850982666,10.593287467956543,10.68529224395752,10.411349296569824,10.631141662597656,10.062411308288574,10.250938415527344,10.297481536865234],\"y\":[13.495696067810059,13.806273460388184,13.196573257446289,13.79839038848877,13.995807647705078,13.542245864868164,12.195038795471191,13.451119422912598,13.603123664855957,13.930933952331543,13.925373077392578,13.832500457763672,13.170495986938477,13.704151153564453,13.820572853088379],\"type\":\"scattergl\"},{\"hoverinfo\":\"text\",\"hovertext\":[\"We'll parse all relevant columns to string types so we can perform string operations.\",\"Setting correct data types\",\"Ensure some required columns have the appropriate types\",\"Stablish the type of each column, filtering non-numeric and non-string type\",\"Checking the data types of each column\",\"Cast data into the appropriate data type\",\"Exploring columns types and some of the data\",\" Set the right variable types for each column\",\"Setting the correct types of each column\",\"Set up variables for each field type to make the code more readable.\",\" Checking the data types of every column\",\"Get data types\",\"Ensure the correct data types for each column\",\"Harmonize data column names and types\",\" Convert to correct types\"],\"marker\":{\"opacity\":0.5,\"size\":5},\"mode\":\"markers+text\",\"name\":\"225_Choosing and Managing Data Types in Columns\",\"text\":[\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\"],\"textfont\":{\"size\":12},\"x\":[10.886211395263672,11.179681777954102,11.16272258758545,10.237044334411621,10.414466857910156,10.887500762939453,10.559074401855469,10.848967552185059,10.780813217163086,11.25250244140625,10.309087753295898,10.996072769165039,10.813105583190918,10.614643096923828,11.069579124450684],\"y\":[0.5256787538528442,0.8868651986122131,0.6403495669364929,0.3514559864997864,-0.31099385023117065,0.5963691473007202,0.38884207606315613,0.5119938850402832,0.5024629831314087,0.9366896748542786,-0.3076413869857788,0.04725055396556854,0.1928340345621109,0.9030606150627136,0.8212233185768127],\"type\":\"scattergl\"},{\"hoverinfo\":\"text\",\"hovertext\":[\"View the first five rows of the characters dataframe\\ndf_characters.head()\",\" Viewing the first five rows of the characters dataframe\\ndf_characters.head()\",\" View the first 5 rows of the characters DataFrame\\ndf_characters.head()\",\" View the first 5 rows of the characters dataframe.\\ndf_characters.head()\",\" Viewing the first 5 rows of the characters dataframe\\ndf_characters.head(5)\",\" View the first 5 rows of the characters dataframe\\ndf_characters.head()\",\"View the first 5 rows of the character dataframe\\ndf_characters.head()\",\" View the first 5 rows of the characters dataframe\\ndf_characters.head()\",\"View the first 5 rows of the characters dataframe\\ndf_characters.head()\",\" View the first 5 rows of the characters dataframe\\ndf_characters.head()\",\"View the first 5 rows of the characters dataframe\\ndf_characters.head()\",\"View the first 5 rows of the characters DataFrame\\ndf_characters.head()\",\"View the first 5 rows of the characters dataframe\\ndf_characters.head()\",\" View the first 5 rows of the characters dataframe\\ndf_characters.head()\",\"View the first 5 rows of the characters dataframe\\ndf_characters.head()\"],\"marker\":{\"opacity\":0.5,\"size\":5},\"mode\":\"markers+text\",\"name\":\"226_View first 5 rows of characters dataframe\",\"text\":[\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\"],\"textfont\":{\"size\":12},\"x\":[16.346927642822266,16.130321502685547,16.59809684753418,16.332969665527344,16.201566696166992,16.31964683532715,16.166988372802734,16.45480728149414,16.3855037689209,16.291702270507812,16.3918514251709,16.41644287109375,16.536527633666992,16.322525024414062,16.573606491088867],\"y\":[-10.474929809570312,-10.315925598144531,-10.547378540039062,-10.707669258117676,-10.561348915100098,-10.625540733337402,-10.430436134338379,-10.332379341125488,-10.97197151184082,-10.481952667236328,-10.684687614440918,-10.683592796325684,-10.442432403564453,-10.571385383605957,-10.681570053100586],\"type\":\"scattergl\"},{\"hoverinfo\":\"text\",\"hovertext\":[\"# Show first 5 rows of each DataFrame\\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()\",\"View the first 5 rows of each dataframe\\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()\",\"Get the first 5 rows of each dataframe\\ndf_characters.head(), df_locations.head(), df_episodes.head(), df_script.head()\",\"View first 5 rows of each dataset\\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()\",\"Show first 5 rows of each dataframes\\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()\",\" Show the first 5 rows of each dataframe\\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()\",\" Show the first 5 rows of each dataframe\\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()\",\"Show the first 5 rows of each dataframe\\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()\",\" Show the first 5 rows of each dataframe\\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()\",\"Show first 5 rows of each dataset\\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()\",\"Print the first 5 rows of each dataset for inspection\\ndf_characters.head(), df_locations.head(), df_episodes.head(), df_script.head()\",\" Show the first 5 rows of each DataFrame\\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()\",\"Show the first 5 rows of each dataframe\\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()\",\" Show first 5 rows of each dataframe\\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()\"],\"marker\":{\"opacity\":0.5,\"size\":5},\"mode\":\"markers+text\",\"name\":\"227_View first 5 rows of datasets\",\"text\":[\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\"],\"textfont\":{\"size\":12},\"x\":[15.639287948608398,15.608233451843262,16.16140365600586,15.36313247680664,15.85742473602295,15.785277366638184,16.07337760925293,16.0108585357666,16.136911392211914,15.541011810302734,-2.614278554916382,16.24040985107422,15.886197090148926,15.9729585647583],\"y\":[-6.831893444061279,-6.633492469787598,-7.257980823516846,-6.751377105712891,-7.111006736755371,-7.200918674468994,-7.059296131134033,-7.095513820648193,-7.246975898742676,-6.854893207550049,4.533022880554199,-7.088410377502441,-7.0171709060668945,-7.272253513336182],\"type\":\"scattergl\"},{\"hoverinfo\":\"text\",\"hovertext\":[\"Load the spacy model\\nnlp = spacy.load('en_core_web_sm')\",\"# Load the model\\nnlp = spacy.load('en_core_web_sm')\",\"Load the spaCy model\\nnlp = spacy.load('en_core_web_sm')\",\" Set up spaCy model\\nnlp = spacy.load('en_core_web_sm')\",\" Load the spacy model\\nnlp = spacy.load('en_core_web_sm')\",\"Load the SpaCy model\\nnlp = spacy.load('en_core_web_sm')\",\"Load the spaCy model\\nnlp = spacy.load('en_core_web_sm')\",\"Load the spaCy model\\nnlp = spacy.load('en_core_web_sm')\",\"# Load the spaCy model\\nnlp = spacy.load('en_core_web_sm')\",\"Load the spaCy model\\nnlp = spacy.load('en_core_web_sm')\",\"Initialize the SpaCy model\\nnlp = spacy.load('en_core_web_sm')\",\"# Load spacy model\\nnlp = spacy.load('en_core_web_sm')\",\"Intializes spacy model\\nnlp = spacy.load('en_core_web_sm')\",\"# Load the spaCy model\\nnlp = spacy.load('en_core_web_sm')\"],\"marker\":{\"opacity\":0.5,\"size\":5},\"mode\":\"markers+text\",\"name\":\"228_Loading spaCy model\",\"text\":[\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\"],\"textfont\":{\"size\":12},\"x\":[17.207014083862305,16.98396873474121,17.537309646606445,16.736452102661133,17.448835372924805,17.35334587097168,17.28513526916504,17.55255699157715,17.46941375732422,17.245071411132812,16.683691024780273,17.53325843811035,17.039762496948242,17.403474807739258],\"y\":[9.995655059814453,9.35303783416748,10.12859058380127,9.942617416381836,10.062126159667969,10.145451545715332,10.11943244934082,9.966706275939941,9.733724594116211,9.935571670532227,9.690241813659668,9.904033660888672,10.336864471435547,9.738154411315918],\"type\":\"scattergl\"},{\"hoverinfo\":\"text\",\"hovertext\":[\"Display settings\\npd.set_option('display.max_columns', None)\",\"# Settings\\npd.set_option('display.max_columns', None)\",\"Display settings\\npd.set_option('display.max_columns', None)\",\"Settings\\npd.set_option('display.max_columns', None)\",\"Display settings\\npd.set_option('display.max_columns', None)\",\"ipandas style-settings\\npd.set_option('display.max_columns', None)\",\"Display settings\\npd.set_option('display.max_columns', None)\",\" Some global configs\\npd.set_option('display.max_columns', None)\",\"settings\\npd.set_option('display.max_columns', None)\",\"Setting the settings\\npd.set_option('display.max_columns', None)\",\"Settings\\npd.set_option('display.max_columns', None)\",\"Display settings\\npd.set_option('display.max_columns', None)\",\"Display documentation for settings\\npd.describe_option('display')\",\"Display settings\\npd.set_option('display.max_columns', None)\"],\"marker\":{\"opacity\":0.5,\"size\":5},\"mode\":\"markers+text\",\"name\":\"229_display settings\",\"text\":[\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\"],\"textfont\":{\"size\":12},\"x\":[25.343725204467773,24.96781349182129,25.427410125732422,25.418880462646484,25.552833557128906,25.795894622802734,25.6842041015625,25.09996223449707,25.456748962402344,25.018648147583008,25.461606979370117,25.405611038208008,25.93248176574707,25.62201690673828],\"y\":[0.029178285971283913,-0.7996296882629395,0.04038890451192856,-0.39561063051223755,0.08859911561012268,-0.3040955364704132,0.14176177978515625,-0.7813036441802979,-0.3899238109588623,-0.6614119410514832,-0.44595035910606384,-0.021696817129850388,0.23729346692562103,-0.05695695802569389],\"type\":\"scattergl\"},{\"hoverinfo\":\"text\",\"hovertext\":[\" Show the 10 first rows of the dataframe characters\",\"Display the first few rows of the dataframe containing characters\",\" Show first 3 rows of the characters dataframe\",\"Display the first few rows of the dataframe containing the characters.\",\" Display the first few rows of the dataframe containing the characters.\",\"Show the first few rows of the characters DataFrame\",\" Display the first few rows of the dataframe for the characters.\",\" Display the first few rows of the dataframe containing the characters.\",\"Dsiplay the first rows of the characters dataframe\",\"Merge the data in a single dataframe and show the first few characters\",\"Display the first records of characters dataframe to understand what we have in the dataframe\",\"Show first few rows of the characters dataframe\",\" Let's display the first 10 rows of the characters dataframe.\",\"Print the first lines of the characters csv.\"],\"marker\":{\"opacity\":0.5,\"size\":5},\"mode\":\"markers+text\",\"name\":\"230_Displaying rows of a dataframe with characters\",\"text\":[\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\"],\"textfont\":{\"size\":12},\"x\":[9.699009895324707,9.222705841064453,8.94517993927002,9.639077186584473,9.5159330368042,9.41572380065918,9.748212814331055,9.627272605895996,9.292004585266113,9.11516284942627,9.5501070022583,9.328269958496094,10.387839317321777,10.298617362976074],\"y\":[13.051675796508789,13.527786254882812,13.296899795532227,13.458250045776367,13.504598617553711,13.328859329223633,13.058320045471191,13.264198303222656,13.473479270935059,13.153273582458496,12.95457649230957,13.496854782104492,12.557021141052246,9.60325813293457],\"type\":\"scattergl\"},{\"hoverinfo\":\"text\",\"hovertext\":[\"Display the first few rows of the script dataframe to understand its structure\\ndf_script.head()\",\"Displaying the first 3 rows of the script DataFrame to understand its structure\\ndf_script.head(3)\",\" Show the first rows of the dataframe to understand the structure of the data\\ndf_script.head()\",\" Display the first few rows of the table to understand its structure\\ndf_script.head()\",\"Display the first few rows of the dataframe to understand its structure\\nprint(df_script.head())\",\"Displaying the first few rows of the script dataframe to understand its structure\\ndf_script.head()\",\" Display the first few records of the script data to understand its structure\\ndf_script.head()\",\" Display the first few rows of the dataframe to understand its structure\\ndf_script.head()\",\"Display the first few rows of the dataset to understand its structure and content\\ndf_script.head()\",\" Display the first few rows of the dataframe to understand its structure\\ndf_script.head()\",\" Show the first rows of the dataset to understand the structure\\ndf_script.head()\",\"Display the first few rows of the dataframe to understand its structure\\ndf_script.head()\",\" Display the first few rows of the dataframe to understand its structure\\ndf_script.head()\",\"Display the first few rows of the dataframe to understand its structure\\ndf_script.head()\"],\"marker\":{\"opacity\":0.5,\"size\":5},\"mode\":\"markers+text\",\"name\":\"231_Understanding the Structure of df_script DataFrame\",\"text\":[\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\"],\"textfont\":{\"size\":12},\"x\":[2.8448450565338135,3.0540771484375,2.821883201599121,2.1456544399261475,3.178966999053955,2.877307891845703,3.0273935794830322,3.0017893314361572,1.9302940368652344,2.7853667736053467,3.033885955810547,3.026348352432251,2.7030727863311768,2.675215482711792],\"y\":[-6.333413600921631,-6.721682548522949,-6.169179916381836,-6.543457984924316,-6.863446235656738,-6.194021224975586,-6.4746994972229,-6.938474655151367,-5.98385763168335,-6.8466291427612305,-5.509588241577148,-6.873814582824707,-6.886759281158447,-6.811857223510742],\"type\":\"scattergl\"},{\"hoverinfo\":\"text\",\"hovertext\":[\"Merge the dataframes together into a single dataframe based on the episode id.\",\"Merge all the dataframes with based on the episode id to have a clear dataframe with all the information.\",\"Merge the dataframes based on the episode ID\",\"Join the dataframes on the common episode_id to create a master dataframe\",\" Merge episode data into main dataframe\",\" Merge episode data into main dataframe\",\" Join the dataframes on the episode_id\",\"Creating a subset of the DataFrame to focus on a specific episode for analysis\",\" Join all DataFrames together on episode_id\",\"Specify data type for 'episode_id' to int in all dataframes for later merging of data frames\",\"Merge the datasets on 'episode_id' to have all relevant information in one dataframe.\",\"Join the datasets on episode_id and create one big dataframe\",\"Merge the dataframes at the hand of the episode_id.\",\"Merging required dataframes for analysis - there will be repeated values as each line in the script has a unique id which maps back to the same episode and resulting title.\"],\"marker\":{\"opacity\":0.5,\"size\":5},\"mode\":\"markers+text\",\"name\":\"232_Dataframe merging based on episode IDs\",\"text\":[\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\"],\"textfont\":{\"size\":12},\"x\":[4.571581840515137,4.853686332702637,4.539078235626221,4.506256580352783,4.784141540527344,4.951098918914795,4.855335712432861,4.0833740234375,4.401116847991943,4.182529449462891,4.62095832824707,4.9570088386535645,4.720495700836182,5.121871471405029],\"y\":[3.426119089126587,3.0779569149017334,2.9981560707092285,2.9456357955932617,3.0919923782348633,2.931318521499634,3.6705782413482666,3.187378168106079,3.327150583267212,3.2089855670928955,3.090421676635742,3.0212793350219727,3.378349781036377,3.327483654022217],\"type\":\"scattergl\"},{\"hoverinfo\":\"text\",\"hovertext\":[\" Display the dataframe to understand its structure\\ndf_script.head()\",\"view the script dataframe to understand what information it contains\\nprint(df_script.head())\",\"Show the head of the script dataframe to better understand its structure\\ndf_script.head()\",\" Show head of the dataframe to understand the structure\\ndf_script.head()\",\"View dataframe structure\\ndf_script.head()\",\"Display the header of the DataFrame to understand its structure\\ndf_script.head()\",\" Show the head of the dataframe to understand better what kind of data we are dealing with\\ndf_script.head()\",\"Explore the structure of the script DataFrame\\nprint(df_script.head())\",\"Visualize the head of the script DataFrame to understand its structure\\ndf_script.head()\",\"Print out the dataframe to better understand its structure\\ndf_script.head()\",\" View the dataframe containing the script lines\\ndf_script.head()\",\"View the structure of one of the DataFrames\\ndf_script.head()\",\"Inspect dataframes to get an idea of their structure\\ndf_script.head()\",\" Display the scripts dataframe to understand its structure\\ndf_script.head()\"],\"marker\":{\"opacity\":0.5,\"size\":5},\"mode\":\"markers+text\",\"name\":\"233_Analyzing the structure of a dataframe containing scripts\",\"text\":[\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\"],\"textfont\":{\"size\":12},\"x\":[5.15765905380249,5.6066975593566895,5.363299369812012,5.101661682128906,5.333077907562256,5.318904399871826,5.8863749504089355,5.202773094177246,5.618526458740234,5.227990627288818,6.487804889678955,4.740658283233643,4.83760929107666,4.959125995635986],\"y\":[-5.991447925567627,-5.027915954589844,-5.8738203048706055,-5.94794225692749,-5.721304416656494,-6.146297454833984,-6.046361446380615,-5.463907241821289,-5.885439395904541,-5.559025764465332,-5.179719924926758,-5.6106648445129395,-5.012038230895996,-5.875026702880859],\"type\":\"scattergl\"},{\"hoverinfo\":\"text\",\"hovertext\":[\"# Disable warning\\npd.options.mode.chained_assignment = None\",\"Disabling non-used pandas warning\\npd.options.mode.chained_assignment = None\",\"Setting with copy error\\npd.options.mode.chained_assignment = None  # default='warn'\",\" Set Warnings to ignore in notebook\\npd.set_option('mode.chained_assignment', None)\",\"Disable SettingWithCopyWarning\\npd.options.mode.chained_assignment = None  # default='warn'\",\"Setting DEPRECATED SettingWithCopy Warning to False\\npd.set_option('mode.chained_assignment', None)\",\"Ignore pandas warnings\\npd.options.mode.chained_assignment = None\",\" to avoid several warnings\\npd.options.mode.chained_assignment = None\",\"Enable validation as one validation raised unstable results\\npd.options.mode.chained_assignment = None\",\"Remove warning caused by unnamed index column in data files\\npd.options.mode.chained_assignment = None\",\" make sure transformations of default Jupyter mode is off\\npd.set_option('mode.chained_assignment', None)\",\"Ignore SettingWithCopyWarning\\npd.options.mode.chained_assignment = None\",\"Ignore pandas warning about chained assignments\\npd.options.mode.chained_assignment = None\",\"Disabling the SettingWithCopyWarning in pandas, as we are interested in modifying dataframes in place and not creating copies\\npd.options.mode.chained_assignment = None\"],\"marker\":{\"opacity\":0.5,\"size\":5},\"mode\":\"markers+text\",\"name\":\"234_Disabling SettingWithCopyWarning in Pandas\",\"text\":[\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\"],\"textfont\":{\"size\":12},\"x\":[18.240184783935547,18.568586349487305,18.379722595214844,18.507781982421875,17.911052703857422,17.900300979614258,18.44882583618164,18.439945220947266,18.505659103393555,18.65005111694336,18.134801864624023,17.977006912231445,18.387149810791016,18.02385711669922],\"y\":[5.458058834075928,5.204147815704346,5.643076419830322,5.222387790679932,5.209339618682861,5.2822394371032715,5.294562816619873,5.571742534637451,5.687996864318848,5.6009440422058105,5.817811965942383,5.141007423400879,5.185019493103027,5.22583532333374],\"type\":\"scattergl\"},{\"hoverinfo\":\"text\",\"hovertext\":[\"Display the first few records of each dataframe to understand its structure\\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()\",\" Display the first few rows of each DataFrame to understand its structure and content.\\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()\",\"Display the first few rows of each dataframe to understand its structure and contents\\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()\",\"Display the first few rows of each dataframe to understand its structure\\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()\",\"Display the first few rows of each dataframe to understand its structure\\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()\",\"Visualizing the first few rows of the dataframes to better understand the data\\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()\",\" Display the first few rows of each table to understand its structure and the information it contains.\\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()\",\"Display the first few records of each dataframe to understand its structure\\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()\",\"Display the first few rows of each table to understand their structure\\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()\",\"Show the first few rows of each dataframe to understand their structure\\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()\",\"Display the first few rows of each dataframe to understand their structure and content\\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()\",\"visualize the first few rows of each dataframe to understand the structure of the dataframes.\\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()\",\"Visualize the table's structure\\ndf_episodes.head()\",\"Display the first few rows of each dataset to understand its structure\\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()\"],\"marker\":{\"opacity\":0.5,\"size\":5},\"mode\":\"markers+text\",\"name\":\"235_Exploring Dataframes - Structure and Contents\",\"text\":[\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\"],\"textfont\":{\"size\":12},\"x\":[-3.8382794857025146,-3.676776885986328,-3.70855450630188,-3.707014799118042,-3.7347500324249268,-3.449645757675171,-3.330948829650879,-4.163314342498779,-3.3094136714935303,-3.6377408504486084,-3.517829656600952,-3.165309429168701,1.2972090244293213,-3.4014058113098145],\"y\":[5.9876837730407715,6.003259658813477,6.186949253082275,5.874599933624268,5.951789855957031,6.632087707519531,6.406320095062256,6.051226615905762,6.330653667449951,6.019000053405762,6.096659183502197,6.348110198974609,3.432312488555908,5.968390941619873],\"type\":\"scattergl\"},{\"hoverinfo\":\"text\",\"hovertext\":[\" Checking the first five rows of each dataframe\",\"Check and display the first 5 rows of each DataFrame\",\"Checking the first 5 rows from each dataframe to understand the structure of the data\",\" Check the first 5 rows of the script DataFrame\",\"Check the first 5 rows of the script dataframe to have an idea of the data\",\"Checking the first five rows of each DataFrame\",\"Checking the first 5 rows of each dataframe\",\"Checking the first 5 rows of each dataframe\",\"Check the first 5 rows of each of the dataframes.\",\"Check the shape and the first 5 rows of each DataFrame\",\"Optional: Display the first 5 entries for each dataframe to validate the import\",\"checking the datatypes and the first five rows of each dataframe\",\" Check the first 5 rows for each DataFrame to get an idea of the data\",\"Check the first 5 rows of the script dataframe\"],\"marker\":{\"opacity\":0.5,\"size\":5},\"mode\":\"markers+text\",\"name\":\"236_Checking dataframe structure and data for first five rows\",\"text\":[\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\"],\"textfont\":{\"size\":12},\"x\":[13.099337577819824,13.427423477172852,13.222135543823242,12.614385604858398,12.611102104187012,13.12960433959961,13.164332389831543,13.148681640625,12.68994140625,13.09086799621582,11.832569122314453,12.766043663024902,13.276585578918457,12.448735237121582],\"y\":[-5.400632858276367,-5.802815914154053,-6.039832592010498,-5.2046918869018555,-5.609418869018555,-5.26182746887207,-5.441658973693848,-5.444055557250977,-5.525120735168457,-5.787715435028076,-4.148627281188965,-4.961893558502197,-5.517360687255859,-5.40151834487915],\"type\":\"scattergl\"},{\"hoverinfo\":\"text\",\"hovertext\":[\"Inspecting the first rows of each dataframe\\nprint(\\\"_\\\"*80)\\n\\nprint(\\\"\\\\nCharacters data frame\\\")\\ndisplay(df_characters.head())\\n\\nprint(\\\"_\\\"*80)\\n\\nprint(\\\"\\\\nLocations data frame\\\")\\ndisplay(df_locations.head())\\n\\nprint(\\\"_\\\"*80)\\n\\nprint(\\\"\\\\nScript data frame\\\")\\ndisplay(df_script.head())\\n\\nprint(\\\"_\\\"*80)\\n\\nprint(\\\"\\\\nEpisodes data frame\\\")\\ndisplay(df_episodes.head())\",\"Print the first few lines of each dataframe\\nprint('Characters')\\nprint(df_characters.head())\\nprint('\\\\nLocations')\\nprint(df_locations.head())\\nprint('\\\\nScript')\\nprint(df_script.head())\\nprint('\\\\nEpisodes')\\nprint(df_episodes.head())\",\"View the first few entries for each dataframe\\nprint('Characters')\\ndisplay(df_characters.head())\\nprint('\\\\nLocations')\\ndisplay(df_locations.head())\\nprint('\\\\nScript lines')\\ndisplay(df_script.head())\\nprint('\\\\nEpisodes')\\ndisplay(df_episodes.head())\",\"Print the first few rows of each dataframe to understand its structure\\nprint(\\\"\\\\nCharacters:\\\")\\nprint(df_characters.head())\\nprint(\\\"\\\\nLocations:\\\")\\nprint(df_locations.head())\\nprint(\\\"\\\\nScript:\\\")\\nprint(df_script.head())\\nprint(\\\"\\\\nEpisodes:\\\")\\nprint(df_episodes.head())\",\"Print the first three rows of each dataframe to quickly get an overview of their contents\\nprint('\\\\nCharacters:')\\nprint(df_characters.head(3))\\n\\nprint('\\\\nLocations:')\\nprint(df_locations.head(3))\\n\\nprint('\\\\nScript:')\\nprint(df_script.head(3))\\n\\nprint('\\\\nEpisodes:')\\nprint(df_episodes.head(3))\",\"Print the first few rows of each dataframe to understand their structure\\nprint(\\\"Characters\\\")\\nprint(df_characters.head())\\nprint(\\\"\\\\n---------------------------------\\\")\\nprint(\\\"\\\\nLocations\\\")\\nprint(df_locations.head())\\nprint(\\\"\\\\n---------------------------------\\\")\\nprint(\\\"\\\\nScript\\\")\\nprint(df_script.head())\\nprint(\\\"\\\\n---------------------------------\\\")\\nprint(\\\"\\\\nEpisodes\\\")\\nprint(df_episodes.head())\",\"Print the first 5 rows of the characters, locations, script, and episodes DataFrames\\nprint(\\\"Characters DataFrame:\\\")\\nprint(df_characters.head())\\nprint(\\\"\\\\nLocations DataFrame:\\\")\\nprint(df_locations.head())\\nprint(\\\"\\\\nScript DataFrame:\\\")\\nprint(df_script.head())\\nprint(\\\"\\\\nEpisodes DataFrame:\\\")\\nprint(df_episodes.head())\",\" Look at first rows of the characters dataframe\\nprint(\\\"Characters:\\\")\\ndisplay(df_characters.head(5))\\n\\n# Look at first rows of the locations dataframe\\nprint(\\\"\\\\nLocations:\\\")\\ndisplay(df_locations.head(5))\\n\\n# Look at first rows of the script dataframe\\nprint(\\\"\\\\nScript:\\\")\\ndisplay(df_script.head(5))\\n\\n# Look at first rows of the episodes dataframe\\nprint(\\\"\\\\nEpisodes:\\\")\\ndisplay(df_episodes.head(5))\",\"Display first few characters of the datasets\\nprint(\\\"Characters\\\")\\ndisplay(df_characters.head())\\n\\nprint(\\\"\\\\n\\\\nLocations\\\")\\ndisplay(df_locations.head())\\n\\nprint(\\\"\\\\n\\\\nScript\\\")\\ndisplay(df_script.head())\\n\\nprint(\\\"\\\\n\\\\nEpisodes\\\")\\ndisplay(df_episodes.head())\",\"Print first few lines of each dataframe\\nprint('Characters:')\\nprint(df_characters.head())\\nprint('\\\\n\\\\nLocations:')\\nprint(df_locations.head())\\nprint('\\\\n\\\\nScript:')\\nprint(df_script.head())\\nprint('\\\\n\\\\nEpisodes:')\\nprint(df_episodes.head())\",\"Print the first three elements for each dataframe\\nprint(\\\"Characters\\\")\\nprint(df_characters.head(3), '\\\\n')\\n\\nprint(\\\"Locations\\\")\\nprint(df_locations.head(3), '\\\\n')\\n\\nprint(\\\"Script\\\")\\nprint(df_script.head(3), '\\\\n')\\n\\nprint(\\\"Episodes\\\")\\nprint(df_episodes.head(3))\",\" Print out the first few rows of each dataframe\\nprint(\\\"Characters:\\\")\\nprint(df_characters.head())\\n\\nprint(\\\"\\\\nLocations:\\\")\\nprint(df_locations.head())\\n\\nprint(\\\"\\\\nScript:\\\")\\nprint(df_script.head())\\n\\nprint(\\\"\\\\nEpisodes:\\\")\\nprint(df_episodes.head())\",\"Print the first few rows of each of the dataframes to understand the data better\\nprint(\\\"Characters Data:\\\")\\ndisplay(df_characters.head())\\nprint(\\\"\\\\nLocations Data:\\\")\\ndisplay(df_locations.head())\\nprint(\\\"\\\\nScript Data:\\\")\\ndisplay(df_script.head())\\nprint(\\\"\\\\nEpisodes Data:\\\")\\ndisplay(df_episodes.head())\"],\"marker\":{\"opacity\":0.5,\"size\":5},\"mode\":\"markers+text\",\"name\":\"237_Dataframe Inspections\",\"text\":[\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\"],\"textfont\":{\"size\":12},\"x\":[-2.293858051300049,-1.6587992906570435,-1.7830325365066528,-1.400870442390442,-1.815656065940857,-1.2743438482284546,-1.3814376592636108,-1.260214924812317,-1.3556734323501587,-1.3979823589324951,-1.7604416608810425,-1.4089096784591675,-1.7586469650268555],\"y\":[4.6144585609436035,4.901371479034424,4.644845008850098,4.818213939666748,4.736677646636963,5.095045566558838,5.213924884796143,4.43651819229126,3.916536331176758,4.51962947845459,4.552940845489502,4.884418487548828,4.700861930847168],\"type\":\"scattergl\"},{\"hoverinfo\":\"text\",\"hovertext\":[\"Display the first 5 lines of the table to understand its structure\\ndf_characters.head()\",\"# Display first 5 rows of characters data\\ndf_characters.head()\",\"List first 5 rows\\ndf_characters.head(5)\",\"Display the first 5 rows of the data\\ndf_characters.head()\",\"Display the first 5 rows of df_characters\\ndf_characters.head()\",\"# Display the first 5 rows of the character dataset\\ndf_characters.head()\",\"TODO: Show first 5 rows of df_characters\",\"display the 5 first rows of the table\\ndf_characters.head()\",\"# First 5 rows\\ndf_characters.head()\",\" Display first 5 rows of df_characters\\ndf_characters.head()\",\"First 5 rows of df_characters\\ndf_characters.head()\",\" Display first 5 rows of df_characters\\ndf_characters.head()\",\" Display first 5 rows of characters\\ndf_characters.head()\"],\"marker\":{\"opacity\":0.5,\"size\":5},\"mode\":\"markers+text\",\"name\":\"238_df_characters.head(5)\",\"text\":[\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\"],\"textfont\":{\"size\":12},\"x\":[0.15368489921092987,-1.1736290454864502,-1.455153226852417,-1.0306141376495361,-1.5620321035385132,-1.2875053882598877,-1.6764580011367798,-0.8334240317344666,-0.768636167049408,-1.564847707748413,-1.2680333852767944,-1.4690440893173218,-1.5272635221481323],\"y\":[13.785870552062988,12.744255065917969,12.536450386047363,12.568253517150879,13.009673118591309,12.78787899017334,12.614994049072266,13.236761093139648,12.790665626525879,12.921478271484375,13.027129173278809,13.070403099060059,12.727319717407227],\"type\":\"scattergl\"},{\"hoverinfo\":\"text\",\"hovertext\":[\"Generate length of dialogues\\ndf_script['raw_character_text'] = df_script['raw_character_text'].apply(lambda x: str(x))\",\"Set text length to take into account\\nTEXT_LENGTH = 3\",\"Create a new column to keep track of the total length of each line of dialogue.\\ndf_script['raw_character_text'].str.len()\",\"Creates a column with length of each script line\\ndf_script['line_length'] = df_script['raw_text'].str.len()\",\"Visualize the distributions of script line lengths\\nline_length = df_script['normalised_text'].str.len()\\nline_length.describe()\",\"Create additional column for line length\\ndf_script['line_length'] = df_script['raw_text'].str.len()\",\"New column containing the number of characters in each line\\ndf_script['n_characters'] = df_script.raw_text.str.len()\",\" Keep track of original length\\nlen_original = len(df_script)\",\"Global data\\nnlp = spacy.load('en')\\n\\n# Create a new column with the length of each line\\ndf_script['length'] = df_script['raw_text'].apply(len)\",\" Create a column containing the length of each line of dialogue\\ndf_script['length'] = df_script['raw_character_text'].str.len()\",\"Longest lines in the scripts\\nlongest_script_lines = df_script[df_script['raw_text'].str.len() == df_script['raw_text'].str.len().max()]\\nlongest_script_lines[['raw_text', 'timestamp_in_ms', 'speaking_line', 'character_id']]\",\"Create a column with the length of each line\\ndf_script['length'] = df_script['raw_text'].apply(len)\",\" Create a new column in df_script with the length of the line of text.\"],\"marker\":{\"opacity\":0.5,\"size\":5},\"mode\":\"markers+text\",\"name\":\"239_Length and Track Dialogue\",\"text\":[\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\"],\"textfont\":{\"size\":12},\"x\":[8.900619506835938,9.0938138961792,8.828548431396484,8.500133514404297,9.071569442749023,8.47695255279541,8.191950798034668,8.486145973205566,9.177008628845215,8.62566089630127,8.631996154785156,8.494894981384277,8.638713836669922],\"y\":[8.434823036193848,7.7459611892700195,7.878513813018799,8.61789321899414,8.078757286071777,8.417181968688965,8.902090072631836,8.299160957336426,8.529834747314453,8.0633544921875,8.217987060546875,8.243673324584961,7.856565952301025],\"type\":\"scattergl\"},{\"hoverinfo\":\"text\",\"hovertext\":[\"Setting random seed to 42 to determine the topic modeling outcome\\nnp.random.seed(42)\",\"ensuring a random seed for notebook reproducibility\\nnp.random.seed(21)\",\"Set seed for reproducibility\\nnp.random.seed(42)\",\"Setting seed for reproducibility\\nnp.random.seed(42)\",\"Set random seed for reproducibility\\nnp.random.seed(42)\",\"Set seed for reproducibility\\nnp.random.seed(42)\",\" Set Seed for Reproducibility\\nnp.random.seed(seed=42)\",\"Set seed for reproducibility\\nnp.random.seed(42)\",\"Random seed for reproducibility\\nnp.random.seed(42)\",\"Set seed for reproducibility\\nnp.random.seed(34)\",\"Set seed for reproducibility\\nnp.random.seed(42)\",\" Set a seed for reproducibility of random operations\\nnp.random.seed(42)\",\"Set seed for NLP\\nnp.random.seed(42)\"],\"marker\":{\"opacity\":0.5,\"size\":5},\"mode\":\"markers+text\",\"name\":\"240_Random Seed Reproducibility\",\"text\":[\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\"],\"textfont\":{\"size\":12},\"x\":[30.08156394958496,30.13813591003418,29.627490997314453,29.803815841674805,29.888225555419922,29.362550735473633,29.66233253479004,29.674325942993164,29.944101333618164,29.430932998657227,29.51679229736328,29.489126205444336,30.238210678100586],\"y\":[12.677722930908203,13.071741104125977,12.343511581420898,12.425921440124512,12.497051239013672,12.093888282775879,12.580212593078613,12.264779090881348,12.593942642211914,12.208207130432129,12.220319747924805,12.293652534484863,12.789632797241211],\"type\":\"scattergl\"},{\"hoverinfo\":\"text\",\"hovertext\":[\"Merge different tables to and remove possible inconsistencies and conflicts.\",\" Join the table to have a complete table with all information\",\"Merge all data together by their foreign keys.\",\"merging everything in one table\",\"Merge using \\\"merge\\\" method\",\"Merge multiple tables to create a more complete table\",\"Merge the tables by referencing the foreign keys\",\"Merge tables\",\"Split date into year, month and day, to make it easier to aggregate later on\",\" Merge tables to allow more efficient manipulation of the data\",\"Merge data in meaningful way.\",\"Create the master table by joining the other tables\",\" Merge the data using the provided script.\"],\"marker\":{\"opacity\":0.5,\"size\":5},\"mode\":\"markers+text\",\"name\":\"241_Data merging and manipulation using foreign keys\",\"text\":[\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\"],\"textfont\":{\"size\":12},\"x\":[10.446049690246582,10.064095497131348,10.306230545043945,10.324959754943848,11.272624969482422,10.429417610168457,10.39236068725586,10.701196670532227,10.524866104125977,10.389294624328613,10.737197875976562,10.678754806518555,10.214383125305176],\"y\":[0.24244339764118195,-0.08313338458538055,-0.13228321075439453,0.5500627160072327,0.6304783821105957,-0.044976040720939636,-0.16196002066135406,0.3414972722530365,1.2788844108581543,0.27480998635292053,0.10999085754156113,0.12137653678655624,0.5932981967926025],\"type\":\"scattergl\"},{\"hoverinfo\":\"text\",\"hovertext\":[\"Preprocess the data and perform exploratory data analysis (EDA)\",\"Exploratory data analysis (EDA)\",\" STEP 1: Exploratory Data Analysis (EDA)\",\"Exploratory Data Analysis (EDA)\",\"First, let's perform some basic exploratory data analysis (EDA) to get a feel for the data.\",\"EDA\",\"EDA - Samples\",\"# # Exploratory Data Analysis (EDA)\",\"Exploratory Data Analysis (EDA)\",\"Exploratory Data Analysis (EDA)\",\"Exploratory Data Analysis (EDA)\",\"Exploratory Data Analysis (EDA)\",\"needed in the EDA portion of the assignment\"],\"marker\":{\"opacity\":0.5,\"size\":5},\"mode\":\"markers+text\",\"name\":\"242_Exploratory Data Analysis (EDA)\",\"text\":[\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\"],\"textfont\":{\"size\":12},\"x\":[18.655319213867188,18.45999526977539,18.369556427001953,18.612865447998047,17.905872344970703,18.73908233642578,18.64175033569336,18.585573196411133,18.505281448364258,18.364355087280273,18.536073684692383,18.564891815185547,18.670127868652344],\"y\":[-5.109520435333252,-5.046873569488525,-4.809321403503418,-4.870246887207031,-4.227497577667236,-5.152802467346191,-5.272241592407227,-5.126056671142578,-4.9761857986450195,-5.003937244415283,-4.976737022399902,-5.00311279296875,-5.339657783508301],\"type\":\"scattergl\"},{\"hoverinfo\":\"text\",\"hovertext\":[\"Set plot style\\nmatplotlib.style.use('fivethirtyeight')\",\"Set styles and color palettes for the matplotlib visualisations\\nplt.style.use('fivethirtyeight')\\nmatplotlib.rcParams['font.family'] = 'monospace'\\nsns.set_palette(\\\"husl\\\", 7)\",\" Setup matplotlib style\\nplt.style.use('fivethirtyeight')\",\"Setting up matplotlib styles\\nplt.style.use('fivethirtyeight')\",\"set up the plotting style\\nmatplotlib.style.use('fivethirtyeight')\",\"Set custom style form matplotlib\\nplt.style.use('fivethirtyeight')\",\"Configure matplotlib styles and defaults\\nplt.style.use('fivethirtyeight')\",\"Setup matplotlib styles\\nplt.style.use('fivethirtyeight')\",\"Set up matplotlib style\\nplt.style.use('fivethirtyeight')\",\" Set the script to use the 'fivethirtyeight' matplotlib style\\nplt.style.use('fivethirtyeight')\",\"Optional, specify matplotlib style\\nplt.style.use('fivethirtyeight')\",\"Configure matplotlib style\\nplt.style.use('fivethirtyeight')\",\" Set matplotlib style\\nplt.style.use('fivethirtyeight')\"],\"marker\":{\"opacity\":0.5,\"size\":5},\"mode\":\"markers+text\",\"name\":\"243_matplotlib style configuration\",\"text\":[\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\"],\"textfont\":{\"size\":12},\"x\":[21.564638137817383,21.63443946838379,22.279111862182617,22.085193634033203,21.490219116210938,22.04630470275879,21.794036865234375,21.929018020629883,21.97661018371582,21.790830612182617,22.163679122924805,22.209819793701172,21.978214263916016],\"y\":[5.281190872192383,5.288051128387451,5.65260124206543,5.517340183258057,5.429336071014404,5.858119964599609,5.313930511474609,5.633492946624756,5.74399471282959,5.937081336975098,5.70344352722168,5.5899553298950195,5.8667826652526855],\"type\":\"scattergl\"},{\"hoverinfo\":\"text\",\"hovertext\":[\"Remove column \\\"id\\\" as it is unnecessary\\ndf_script.drop(columns=['id'], inplace=True)\",\"Create a series with the lines of the script\\ns_script_lines = df_script[['id', 'raw_text']].set_index('id').squeeze()\",\"Dropping the scriptid column, and indexing by this column\",\"Rename the 'id' column to 'script_id' in df_script DataFrame\\ndf_script.rename(columns={'id': 'script_id'}, inplace=True)\",\" Setting the index to line_id for simplicity\\ndf_script.set_index('id', inplace=True)\",\"Set index of scripts to line_id\\ndf_script.set_index('id', inplace=True)\",\" Set the script Unique Id as index\\ndf_script.set_index('id', inplace=True)\",\"Make scripts dataframe indexable by raw\\u002fpositional index and id\\ndf_script.set_index(pd.Index([df_script.id, df_script.index]), inplace=True)\",\" Set the script dataset index\\ndf_script.set_index('id', inplace=True)\",\" Remove the first column\\ndf_script = df_script.drop(['Unnamed: 0'], axis=1)\",\"Setting the script dataframe id to be the index of the dataframe.\",\"Make copy of data and set index\\ndf_script_clean = df_script.copy()\\ndf_script_clean.set_index('id', inplace=True)\",\" Set the `index` of the `DataFrame` `df_script` to be the column `'id'`\\ndf_script.set_index('id', inplace=True)\"],\"marker\":{\"opacity\":0.5,\"size\":5},\"mode\":\"markers+text\",\"name\":\"244_Setting the index of a DataFrame and making it indexable by id and positional index\",\"text\":[\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\"],\"textfont\":{\"size\":12},\"x\":[5.515091419219971,5.5083537101745605,6.36864709854126,5.093733310699463,5.884613990783691,5.929189682006836,5.95999002456665,5.3754963874816895,5.536844730377197,5.791609764099121,5.769474029541016,5.663338661193848,5.441742420196533],\"y\":[4.456976413726807,4.381274223327637,3.460761547088623,4.459053039550781,3.451547622680664,3.470133066177368,3.5902557373046875,2.7955822944641113,3.3513331413269043,3.8929288387298584,2.939314126968384,3.9829885959625244,3.488414764404297],\"type\":\"scattergl\"},{\"hoverinfo\":\"text\",\"hovertext\":[\"Set default style for plots\",\"Set default style for plotting\",\"Set up custom color palette for visualizations\\ncolors = [\\n    \\\"lightblue\\\",\\n    \\\"blue\\\",\\n    \\\"royalblue\\\",\\n    \\\"cornflowerblue\\\",\\n    \\\"lightsteelblue\\\",\\n]\",\"Set the style of matplotlib plots\\nmatplotlib.pyplot.style.use('dark_background')\",\"Setting some display options, and adding a custom color palette for plots.\",\"Set custom color palette for matplotlib\",\" Set up the visualisation defaults\",\"Set the font preferences and other preferences to make the plots look nicer\",\"Set the style of the plots.\",\"We also set some default style parameters for the plots.\",\"Set some plot configs for visual consistency\",\" Set the default style for plots\",\"Set default style for plots\"],\"marker\":{\"opacity\":0.5,\"size\":5},\"mode\":\"markers+text\",\"name\":\"245_Setting default plot style in matplotlib\",\"text\":[\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\"],\"textfont\":{\"size\":12},\"x\":[19.780614852905273,19.623035430908203,20.361671447753906,20.82371711730957,19.087495803833008,20.8136043548584,18.793506622314453,19.65610694885254,19.248449325561523,19.24530792236328,19.82163429260254,19.680429458618164,19.713212966918945],\"y\":[5.073602676391602,4.707038879394531,4.263799667358398,4.7878289222717285,4.627713203430176,4.570911407470703,4.544187545776367,5.620883941650391,5.033428192138672,4.83180046081543,4.7576680183410645,4.982828617095947,4.998215675354004],\"type\":\"scattergl\"},{\"hoverinfo\":\"text\",\"hovertext\":[\" Load the processed data from pickle files\",\"View the content of each file\",\"Check some sample data for each file\",\" Let's start by taking a look at the structure of these files.\",\"Check the content of these files.\",\"Let's take a brief look at these files.\",\" Check Files Size in MB\",\"View the content of each file\",\" Quick look at the contents of each file\",\"Look at the content of each file.\",\"Let's check the contents of these files.\",\"Check the content of the files\",\"Check the content of each file.\"],\"marker\":{\"opacity\":0.5,\"size\":5},\"mode\":\"markers+text\",\"name\":\"246_View file content\",\"text\":[\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\"],\"textfont\":{\"size\":12},\"x\":[13.948847770690918,14.080041885375977,13.759415626525879,14.717904090881348,14.647903442382812,14.63223648071289,14.003108024597168,13.948871612548828,13.998318672180176,14.451879501342773,14.980415344238281,14.568065643310547,14.406718254089355],\"y\":[0.8325314521789551,1.2268385887145996,0.7153822183609009,1.9111424684524536,2.1906821727752686,1.1552156209945679,1.3652526140213013,1.5463145971298218,1.6725425720214844,1.5476810932159424,1.5365396738052368,1.745134949684143,2.006744384765625],\"type\":\"scattergl\"},{\"hoverinfo\":\"text\",\"hovertext\":[\"Display the first few rows of the dataframe `df_characters`\",\"Inspect content of the `df_characters` dataframe by displaying its first few rows\",\" Examine the first few lines of the characters dataframe\\ndf_characters.head()\",\"Inspect the first lines of the characters dataframe\\ndf_characters.head()\",\"Inspect the first few lines of the characters dataframe\\ndf_characters.head()\",\"Explore the first lines of the characters DataFrame\\ndf_characters.head()\",\"Let's display first rows of `df_characters` DataFrame.\",\"Read few lines of the characters dataframe\\ndf_characters.head()\",\"Inspectig the first few lines of the df_characters dataframe\",\"Inspect the first few lines of the characters dataframe\\nprint(df_characters.head())\",\"Examine the first few lines of the characters dataframe\\ndf_characters.head()\",\"Inspecting first few lines of 'characters' dataframe\\ndf_characters.head()\",\"Display the dataframes to inspect the first few rows of each dataframe\\ndf_characters\"],\"marker\":{\"opacity\":0.5,\"size\":5},\"mode\":\"markers+text\",\"name\":\"247_Inspecting first few rows of df_characters dataframe\",\"text\":[\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\"],\"textfont\":{\"size\":12},\"x\":[8.467300415039062,8.100187301635742,6.292604923248291,6.081177234649658,6.047441005706787,5.688952922821045,7.8410468101501465,6.590071201324463,6.744344711303711,5.988508224487305,6.112118244171143,6.227687358856201,8.225597381591797],\"y\":[14.211135864257812,14.46533203125,18.210214614868164,18.373445510864258,18.56336212158203,18.20011329650879,14.361712455749512,17.796674728393555,17.03842544555664,18.519275665283203,17.967164993286133,18.34686279296875,14.365887641906738],\"type\":\"scattergl\"},{\"hoverinfo\":\"text\",\"hovertext\":[\"Reformat script\\ndf_script['timestamp_in_ms'] = pd.to_numeric(df_script['timestamp_in_ms'], errors='coerce')\\ndf_script['timestamp_in_seconds'] = df_script['timestamp_in_ms'] \\u002f 1000\\ndf_script['timestamp_in_minutes'] = df_script['timestamp_in_seconds'] \\u002f 60\",\"# Fix timestamps\\ndf_script['timestamp_in_ms'] = df_script['timestamp_in_ms'].replace('Timestamp(\\\\'', '').str.replace('\\\\')','').astype(int)\",\"Deal with decimal type column\\ndf_script['timestamp_in_ms'] = df_script['timestamp_in_ms'].fillna(0.0).astype(np.int64)\\n\\n# Convert `timestamp_in_ms` to datetime\\ndf_script['timestamp_in_ms'] = pd.to_datetime(df_script['timestamp_in_ms'], unit='ms').dt.time\",\" Compute time column from start and end timestamps\\ndf_script['time'] = pd.to_datetime(df_script.timestamp_in, unit='s') - pd.to_datetime(df_script.timestamp_out, unit='s')\",\" Remove unwanted columns\\ndel df_script['id']\\ndel df_script['number']\\ndel df_script['raw_text']\\ndel df_script['timestamp_in_ms']\",\"# THESE LINES MIGHT NEED TO BE UNCOMMENTED IF THEY THROW AN ERROR.\\n# df_script['timestamp_in_ms'] = df_script['timestamp_in_ms'].astype(float).astype(int)\",\" Convert timestamps to datetime\\ndf_script['timestamp_in_ms'] = df_script['timestamp_in_ms'].apply(pd.to_datetime)\",\"Remove unnecessary columns\\ndf_script = df_script.drop(columns=['id', 'number', 'raw_text', 'timestamp_in_ms'])\",\"Preprocessing\\n# Convert timestamps to datetime objects\\ndf_script.timestamp_in_ms = pd.to_datetime(df_script.timestamp_in_ms, unit='ms')\\n\\n# Extract script and achors\\nscripts = df_script.normalized_text\\nanchors = df_script.raw_text\",\"Setting correct data types for the script data frame\\ndf_script['timestamp_in_ms'] = pd.to_numeric(df_script['timestamp_in_ms'], errors='coerce').fillna(0).astype(np.int64)\\ndf_script['timestamp_in_ms'] = pd.to_numeric(df_script['timestamp_in_ms'], downcast='integer')\\n\\ndf_script['number'] = pd.to_numeric(df_script['number'], errors='coerce').fillna(0).astype(np.int32)\\ndf_script['number'] = pd.to_numeric(df_script['number'], downcast='integer')\",\"# Preprocessing\\ndf_script = df_script.fillna('')\\n\\n# Fix datatypes\\ndf_script['id'] = df_script['id'].astype(int)\\ndf_script['number'] = df_script['number'].astype(int)\\ndf_script['raw_text'] = df_script['raw_text'].astype(str)\\ndf_script['timestamp_in_ms'] = df_script['timestamp_in_ms'].astype(int)\",\"Add timestamp to the script dataframe\",\"Remove 'time' from timestamp column and set it to datetime\\ndf_script['timestamp_in_ms'] = df_script['timestamp_in_ms'].str.split('.', expand=True)[0]\"],\"marker\":{\"opacity\":0.5,\"size\":5},\"mode\":\"markers+text\",\"name\":\"248_Dataframe Timestamp Manipulation\",\"text\":[\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\"],\"textfont\":{\"size\":12},\"x\":[4.490843772888184,5.026678085327148,4.548522472381592,4.656492233276367,5.359494686126709,4.853670597076416,4.4834699630737305,5.490923881530762,4.628886699676514,4.529122829437256,4.843773365020752,4.9864277839660645,4.761921405792236],\"y\":[2.625563383102417,2.974597930908203,2.697679281234741,2.0970535278320312,4.186855792999268,3.419894218444824,2.1533806324005127,4.3928022384643555,2.3604164123535156,3.329423427581787,3.7725651264190674,2.513559103012085,2.8339345455169678],\"type\":\"scattergl\"},{\"hoverinfo\":\"text\",\"hovertext\":[\"Show head of `df_characters` to understand its structure\\ndf_characters.head()\",\" Test\\ndf_characters.head()\",\"Characters\\ndf_characters.head()\",\"df_characters.head()\",\"Exemplo como utilizar a base de dados \\ndf_characters.head()\",\" Showing head of df_characters to understand its structure\\ndf_characters.head()\",\"\\ndf_characters.head()\",\"df_characters.head()\",\"res\\u002fhead()\",\"df_characters.head()\",\"\\ndf_characters.head()\",\"\\ndf_characters.head()\",\"Let's check the df_characters head\"],\"marker\":{\"opacity\":0.5,\"size\":5},\"mode\":\"markers+text\",\"name\":\"249_df_characters.head()\",\"text\":[\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\"],\"textfont\":{\"size\":12},\"x\":[7.655142307281494,8.655394554138184,8.64708423614502,8.100798606872559,8.325480461120605,7.941744327545166,8.244751930236816,8.366371154785156,8.51058292388916,8.449678421020508,8.26832389831543,8.422229766845703,7.4500651359558105],\"y\":[15.654095649719238,15.163003921508789,15.420042037963867,15.131567001342773,15.680370330810547,15.478930473327637,15.187650680541992,15.302671432495117,15.646768569946289,15.243603706359863,15.220072746276855,15.34315299987793,14.445051193237305],\"type\":\"scattergl\"},{\"hoverinfo\":\"text\",\"hovertext\":[\"Load the dataset into pandas dataframes\",\"Load data into a pandas dataframe.\",\"Load the data files into Pandas dataframes\",\"Reading the data into pandas dataframes\",\"Create an alias for the pandas library, pd.\",\"Loading the data into Pandas DataFrames\",\"Loading the data into dataframes\",\"Build a Panda Script using Dataframes\",\"Load data from DataFrame\",\"Loads data into dataframes for further analysis.\",\"Imports and loading of dataframes\",\"Load the data into pandas DataFrames\",\"Code to load data from CSV files into pandas dataframes\"],\"marker\":{\"opacity\":0.5,\"size\":5},\"mode\":\"markers+text\",\"name\":\"250_Loading Data into Pandas DataFrames\",\"text\":[\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\"],\"textfont\":{\"size\":12},\"x\":[11.416448593139648,11.296586036682129,11.108101844787598,11.124176025390625,19.230356216430664,11.142666816711426,10.566184043884277,10.42151927947998,10.476282119750977,11.637466430664062,11.514205932617188,11.115959167480469,11.269281387329102],\"y\":[-2.0726158618927,-1.9065018892288208,-1.6565355062484741,-1.9075443744659424,1.4979643821716309,-1.7932019233703613,-2.1198928356170654,-1.6671231985092163,-1.8804529905319214,-2.011631727218628,-2.0824005603790283,-1.9008902311325073,-1.325560212135315],\"type\":\"scattergl\"},{\"hoverinfo\":\"text\",\"hovertext\":[\"Remove duplicated episode titles and join tables\",\"Join the datasets on the column \\\"episode_id\\\"\",\" Merge dataset on character id, location id, and episode id\",\"Check we can join the relevant tables on the episode ID\",\"Merge the datasets on episode_id and character_id\",\"Join the datasets on the episode id\",\" Merge the datasets into a single one based on 'episode_id' and 'id' columns.\",\"Merge all the datasets on 'episode_id' to get a complete view of each episode.\",\"Merge the different datasets by their episodes' ID\",\"Merge the data on `episode_id`\",\"Join the datasets on the episode_id and write the resulting DataFrame to a CSV file.\",\"Merge the datasets on episode id\",\"Create datasets for each episode\"],\"marker\":{\"opacity\":0.5,\"size\":5},\"mode\":\"markers+text\",\"name\":\"251_Merging and Joining Datasets on Episode and Character IDs\",\"text\":[\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\"],\"textfont\":{\"size\":12},\"x\":[5.619707107543945,5.4452433586120605,6.271883964538574,6.217160701751709,5.892854690551758,5.959824085235596,5.523340225219727,5.759272575378418,5.65199613571167,5.63671875,5.567117691040039,5.958300590515137,5.545653820037842],\"y\":[3.3423962593078613,3.211960554122925,2.778277635574341,3.6298651695251465,2.653477668762207,3.4115562438964844,3.015738010406494,3.4812850952148438,3.1225974559783936,2.986119270324707,3.3829925060272217,2.806607246398926,3.1660208702087402],\"type\":\"scattergl\"},{\"hoverinfo\":\"text\",\"hovertext\":[\"Check the size of each dataset\\nprint('Characters:', df_characters.shape)\\nprint('Locations:', df_locations.shape)\\nprint('Script:', df_script.shape)\\nprint('Episodes:', df_episodes.shape)\",\"Check the dataframe dimensions\\nprint('Characters shape:', df_characters.shape)\\nprint('Locations shape:', df_locations.shape)\\nprint('Script shape:', df_script.shape)\\nprint('Episodes shape:', df_episodes.shape)\",\" Original dataframe sizes\\nprint('Characters:', df_characters.shape)\\nprint('Locations:', df_locations.shape)\\nprint('Script:', df_script.shape)\\nprint('Episodes:', df_episodes.shape)\",\"print(f\\\"Script size: {df_script.shape}, Characters size:  {df_characters.shape}, Locations size: {df_locations.shape},  Episodes size: {df_episodes.shape}\\\")\",\"Let's take a quick look at the shapes of the dataframes to have an understanding of the size of each dataset.\\n\\nprint(\\\"Characters shape:\\\", df_characters.shape)\\nprint(\\\"Locations shape:\\\", df_locations.shape)\\nprint(\\\"Script shape:\\\", df_script.shape)\\nprint(\\\"Episodes shape:\\\", df_episodes.shape)\",\"\\nprint('Characters dataset size:', df_characters.shape)\\nprint('Locations dataset size:', df_locations.shape)\\nprint('Script dataset size:', df_script.shape)\\nprint('Episodes dataset size:', df_episodes.shape)\",\"Check basic dimensions\\nprint(df_characters.shape)\\nprint(df_locations.shape)\\nprint(df_script.shape)\\nprint(df_episodes.shape)\",\" Print the size of the datasets\\nprint(\\\"Characters: \\\", df_characters.shape)\\nprint(\\\"Locations: \\\", df_locations.shape)\\nprint(\\\"Script: \\\", df_script.shape)\\nprint(\\\"Episodes: \\\", df_episodes.shape)\",\"Display the size of the datasets\\nprint(\\\"Characters:\\\", df_characters.shape)\\nprint(\\\"Locations:\\\", df_locations.shape)\\nprint(\\\"Script lines:\\\", df_script.shape)\\nprint(\\\"Episodes:\\\", df_episodes.shape)\",\"Check the size of each dataset\\nprint('Characters dataset shape:', df_characters.shape)\\nprint('Locations dataset shape:', df_locations.shape)\\nprint('Script dataset shape:', df_script.shape)\\nprint('Episodes dataset shape:', df_episodes.shape)\",\"Display sizes of the dataframes\\ndf_characters.shape, df_locations.shape, df_script.shape, df_episodes.shape\",\"Check dataset sizes\\nprint(f'Simpsons Characters Dataset: {df_characters.shape}')\\nprint(f'Simpsons Locations Dataset: {df_locations.shape}')\\nprint(f'Simpsons Script Dataset: {df_script.shape}')\\nprint(f'Simpsons Episodes Dataset: {df_episodes.shape}')\"],\"marker\":{\"opacity\":0.5,\"size\":5},\"mode\":\"markers+text\",\"name\":\"252_Checking dataset sizes\",\"text\":[\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\"],\"textfont\":{\"size\":12},\"x\":[0.6055670976638794,0.759034276008606,1.3360669612884521,0.935083270072937,1.0782170295715332,1.1689505577087402,0.9366918802261353,1.1748323440551758,1.574750542640686,0.5420747995376587,1.8131418228149414,1.091783881187439],\"y\":[-1.264682412147522,-1.2179120779037476,-1.15566086769104,-1.607248067855835,-1.092667818069458,-1.6939793825149536,-1.4946682453155518,-1.4372540712356567,-1.3016952276229858,-1.2867070436477661,-1.5814037322998047,-1.327812671661377],\"type\":\"scattergl\"},{\"hoverinfo\":\"text\",\"hovertext\":[\"Merge script lines with characters and episodes\\ndf_merged = pd.merge(df_script, df_characters, how='left', left_on='character_id', right_on='id')\\ndf_merged = pd.merge(df_merged, df_episodes, how='left', left_on='episode_id', right_on='id').rename(columns={'name_x':'character', 'normalized_name':'location', 'name_y':'episode'})\\n\\n# Visualize the data\\ndf_merged.head()\",\" Merge episodes and script lines\\ndf_episodes['id'] = df_episodes['id'].astype(int)\\ndf_merged = df_script.merge(df_episodes, left_on='episode_id', right_on='id').iloc[:, 2:]\\n\\n# Add location names\\ndf_merged = df_merged.merge(df_locations, how='left', left_on='raw_location_text', right_on='raw_location_text')\\n\\n# Keep relevant columns\\ndf_merged = df_merged[[\\n    'id', 'spoken_words', 'raw_location_text', 'name', 'normalized_name', 'production_code', 'original_air_date', 'season', \\n    'number_in_season', 'number_in_series', 'us_viewers_in_millions', 'views', 'imdb_rating', 'imdb_votes', 'image_url'\\n]].rename({\\n    'spoken_words': 'dialogue',\\n    'raw_location_text': 'location',\\n    'name': 'episode_name',\\n    'normalized_name': 'location_name'\\n}, axis=1)\",\"Merge characters information\\ndf_episodes = pd.merge(df_episodes, df_characters, left_on='character_id', right_on='id', how='left', suffixes=('', '_character'))\\ndf_episodes.rename(columns={'name': 'character_name', 'normalized_name': 'character_normalized_name'}, inplace=True)\",\" Merge the script with the characters and locations\\ndf_script_char = df_script.merge(df_characters[['id', 'normalized_name']], \\n                                how='left', \\n                                left_on='character_id', \\n                                right_on='id').rename(columns={'normalized_name' : 'character'})\\ndf_script_char_loc = df_script_char.merge(df_locations, \\n                                          how='left', \\n                                          left_on='raw_location_id', \\n                                          right_on='normalized_name').rename(columns={'normalized_name' : 'location'})\\n\\n# Select only the important columns\\ndf_script_char_loc = df_script_char_loc[['episode_id', 'id', 'number', 'raw_character_text', 'raw_location_text',\\n                                         'speaking_line', 'character_id', 'location_id', 'character', 'location']]\",\"Merge the script with character, location and episode info\\ndf_merged = df_script.merge(df_characters[['id', 'normalized_name']], left_on='character_id', right_on='id', how='left').rename(columns={'normalized_name': 'character'}).drop(columns='id')\\ndf_merged = df_merged.merge(df_locations[['id', 'normalized_name']], left_on='location_id', right_on='id', how='left').rename(columns={'normalized_name': 'location'}).drop(columns='id')\\ndf_merged = df_merged.merge(df_episodes[['id', 'title']], left_on='episode_id', right_on='id', how='left').rename(columns={'title': 'episode'}).drop(columns='id')\\n\\n# Drop rows with no episode info\\ndf_merged = df_merged.dropna(subset=['episode'])\\n\\n# Reset index\\ndf_merged = df_merged.reset_index(inplace=False, drop=True)\",\"Merge character information\\ndf_characters = df_characters.rename(columns={'id': 'character_id'})\\ndf_script = df_script.merge(df_characters, on='character_id')\\n\\n# Merge location information\\ndf_locations = df_locations.rename(columns={'id': 'location_id'})\\ndf_script = df_script.merge(df_locations, on='location_id')\\n\\n# Merge episode information\\ndf_episodes = df_episodes.rename(columns={'id': 'episode_id'})\\ndf_script = df_script.merge(df_episodes, on='episode_id')\",\"# Combine locations and episodes\\n# First, rename the column to enable merging with episodes\\ndf_locations.rename(columns={'id':'location_id'}, inplace=True)\\n\\n# Then, inner join the two dataframes on 'location_id'\\ndf_location_episodes = df_locations.merge(df_episodes, on='location_id', how='inner')\\n\\ndf_characters.rename(columns={'id':'character_id'}, inplace=True)\\ndf_main_character_episode = df_characters.merge(df_episodes, on='main_character_id', how='inner')\",\"Merge characters, locations, and episode name into script data\\ndf_data = pd.merge(df_script, df_characters[['id', 'name', 'normalized_name']],\\n                   left_on='character_id', right_on='id').drop(columns=['id']).rename(\\n    columns={'name': 'character_name', 'normalized_name': 'character_normalized_name'})\\ndf_data = pd.merge(df_data, df_locations[['id', 'name', 'normalized_name']],\\n                   left_on='location_id', right_on='id').drop(columns=['id']).rename(\\n    columns={'name': 'location_name', 'normalized_name': 'location_normalized_name'})\\ndf_data = pd.merge(df_data, df_episodes[['id', 'title']],\\n                   left_on='episode_id', right_on='id').drop(columns=['id']).rename(\\n    columns={'title': 'episode_title'})\",\"Merge multiple dataframes into one by episode number\\ndf_full = df_script.merge(df_episodes, how='left', on='episode_id')\\ndf_full = df_full.merge(df_characters, how='left', on='character_id')\\ndf_full = df_full.merge(df_locations, how='left', on='location_id')\\n\\n# Create a DataFrame 'df_dialogue' to store the relevant columns\\ndf_dialogue = df_full[['episode_id', 'number', 'raw_text', 'name', 'normalized_name', 'us_president', 'location', 'normalized_location']]\\ndf_dialogue.rename(columns={'number': 'episode_number', 'raw_text': 'dialogue', 'name': 'character_name', 'normalized_name': 'character_id', 'us_president': 'president'}, inplace=True)\",\"merge script with character and location data\\ndf_characters.rename(columns={'id': 'character_id'}, inplace=True)\\ndf_locations.rename(columns={'id': 'location_id'}, inplace=True)\\ndf_episodes.rename(columns={'id': 'episode_id'}, inplace=True)\\n\\ndf_script = pd.merge(df_script,\\n                     df_characters[['character_id', 'name']],\\n                     on='character_id')\\ndf_script = pd.merge(df_script,\\n                     df_locations[['location_id', 'name']],\\n                     on='location_id')\\ndf_script = pd.merge(df_script,\\n                     df_episodes[['episode_id', 'title']],\\n                     on='episode_id')\",\"# Merge all the datasets\\ndf_merged = df_script.merge(df_episodes, on='episode_id', suffixes=('_script', '_episode'))\\ndf_merged = df_merged.merge(df_characters, on='character_id', suffixes=('_merged', '_character'))\\ndf_merged = df_merged.merge(df_locations, on='location_id', suffixes=('_merged', '_location'))\\n\\n# Rename some columns for clarity\\ndf_merged = df_merged.rename(columns={'normalized_text': 'spoken_words', 'name_merged': 'character_name', 'name_location': 'location_name'})\",\"Merge select columns from the script, character, and episode datasets\\ndf_merged = df_script[['episode_id', 'character_id', 'location_id', 'raw_text']]\\ndf_merged = df_merged.merge(df_characters[['id', 'name']], left_on='character_id', right_on='id').drop(columns=['id'])\\ndf_merged = df_merged.merge(df_locations[['id', 'name']], left_on='location_id', right_on='id').drop(columns=['id'])\\ndf_merged = df_merged.merge(df_episodes[['id', 'title']], left_on='episode_id', right_on='id').drop(columns=['id'])\\n\\n# Rename columns\\ndf_merged.columns = ['episode_id', 'character_id', 'location_id', 'raw_text', 'character_name', 'location_name', 'episode_title']\\n\\n# Display the merged dataframe\\ndf_merged.head()\"],\"marker\":{\"opacity\":0.5,\"size\":5},\"mode\":\"markers+text\",\"name\":\"253_Data merging and renaming in Python\",\"text\":[\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\"],\"textfont\":{\"size\":12},\"x\":[2.622600793838501,3.1363768577575684,2.9767465591430664,3.269862651824951,2.863420248031616,2.575565814971924,2.2921013832092285,3.0573904514312744,3.164780378341675,2.7436351776123047,3.5237252712249756,2.454704523086548],\"y\":[7.799036026000977,7.627899646759033,7.969504356384277,7.774463176727295,8.263238906860352,7.818340301513672,7.946722030639648,8.181923866271973,8.24842357635498,8.003743171691895,8.075695991516113,8.014982223510742],\"type\":\"scattergl\"},{\"hoverinfo\":\"text\",\"hovertext\":[\"# This is a special utility function that helps clean the memory (RAM) by performing garbage collection\\n# It's not that important to understand the details of this function, but it can help us avoid running out of memory\\ndef clean_memory():\\n    \\\"\\\"\\\"\\n    Perform a full garbage collection and return the memory usage\\n\\n    Returns\\n    -------\\n    memory_usage: float\\n        Memory usage in GB after running the garbage collection\\n    \\\"\\\"\\\"\\n    gc.enable()\\n    gc.collect()\\n    return psutil.Process(os.getpid()).memory_info().rss \\u002f 10**9\",\"TODO: Check memory usage and optimize if needed\",\"Transform some columns to the right data type for memory reduction\",\"Creating a good memory management function in order to reduce the memory usage of the dataset.\",\"Optimizing memory usage\",\"Clean up and remove unwated columns in order to speed up data loading and manipulation\",\"Converting to the right types to minimize memory usage\",\"Insane size, check compatibility also on low-RAM environments, e.g. enable arrow-based downcasting.\",\"To reduce memory usage, we should convert some columns to categoricals.\",\"Set the correct data types for each Dataframe to optimize the memory usage\",\"Keep only necessary columns to avoid RAM exhaustion\",\"Reduce memory footprint by downcasting integers and replacing objects with categoricals.\"],\"marker\":{\"opacity\":0.5,\"size\":5},\"mode\":\"markers+text\",\"name\":\"254_Memory optimization and management\",\"text\":[\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\"],\"textfont\":{\"size\":12},\"x\":[11.195853233337402,11.950813293457031,10.796819686889648,11.417070388793945,11.562724113464355,10.452929496765137,11.5401611328125,12.769246101379395,10.747821807861328,10.161446571350098,10.437005043029785,11.392674446105957],\"y\":[1.1887043714523315,1.1159905195236206,0.664680540561676,0.7712416052818298,0.7340742349624634,1.6911275386810303,1.091273546218872,0.987442672252655,0.7771509289741516,0.12566408514976501,1.0168906450271606,0.9901513457298279],\"type\":\"scattergl\"},{\"hoverinfo\":\"text\",\"hovertext\":[\"Preview the datasets\\ndf_characters.head()\",\"Preview the characters dataset\\ndf_characters.head()\",\" Preview the characters dataset\\ndf_characters.head()\",\"Preview the first dataset to get an idea\\ndf_characters.head()\",\"Preview the characters dataset\\ndf_characters.head()\",\"Preview the characters dataset\\ndf_characters.head()\",\" Preview datasets\\ndf_characters.head()\",\"Preview datasets\\ndf_characters.head()\",\"# Preview of the characters dataset\\ndf_characters.head()\",\"Preview the characters dataset\\ndf_characters.head()\",\"Preview the characters dataset\\ndf_characters.head()\",\"Preview the datasets to understand their structure and content\\ndf_characters.head()\"],\"marker\":{\"opacity\":0.5,\"size\":5},\"mode\":\"markers+text\",\"name\":\"255_Dataset Structure and Content Preview with df_characters.head()\",\"text\":[\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\"],\"textfont\":{\"size\":12},\"x\":[1.0921934843063354,1.3330748081207275,1.2543076276779175,0.9704418778419495,1.373602271080017,1.3796108961105347,0.7389572262763977,0.9252071380615234,0.9518398642539978,1.2280726432800293,1.2758033275604248,0.9121198058128357],\"y\":[14.2153959274292,13.755718231201172,14.19891357421875,14.269195556640625,13.98150634765625,13.898965835571289,14.156455039978027,14.089363098144531,14.305878639221191,14.316756248474121,13.925773620605469,13.987196922302246],\"type\":\"scattergl\"},{\"hoverinfo\":\"text\",\"hovertext\":[\"# Show first lines of dataframes\\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()\",\"### Show the first lines of each dataframe\\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()\",\" Display the first few lines of each dataframe\\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()\",\" Show first lines of each dataframe to understand their content\\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()\",\"Examining the data\\n# Display the first few lines of each dataframe\\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()\",\" Display the first lines of the loaded DataFrames\\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()\",\"Display the first few lines of each dataframe\\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()\",\" Display the first few lines of each dataframe\\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()\",\"display first lines of each dataframe\\ndisplay(df_characters.head())\\ndisplay(df_locations.head())\\ndisplay(df_script.head())\\ndisplay(df_episodes.head())\",\"Display the first few lines of each of the dataframes\\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()\",\"Display the first few lines of each dataset\\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()\",\" Display the first few lines of each dataframe\\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()\"],\"marker\":{\"opacity\":0.5,\"size\":5},\"mode\":\"markers+text\",\"name\":\"256_Examining loaded dataframes\",\"text\":[\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\"],\"textfont\":{\"size\":12},\"x\":[-4.99343204498291,-5.440186500549316,-4.9596686363220215,-5.270540237426758,-5.055338382720947,-5.328488826751709,-4.897141456604004,-5.2671098709106445,-5.174742221832275,-5.250699996948242,-4.761201858520508,-5.222835540771484],\"y\":[5.912382125854492,5.6724700927734375,5.491138935089111,5.551980495452881,5.312403678894043,5.706002712249756,5.370532989501953,5.580161094665527,5.409245014190674,5.6883955001831055,5.466657638549805,5.42731237411499],\"type\":\"scattergl\"},{\"hoverinfo\":\"text\",\"hovertext\":[\"View the first 5 lines of df_characters\\ndf_characters.head()\",\"View the first 5 lines of the characters dataframe\\ndf_characters.head()\",\"Display first 5 lines of characters dataset\\ndf_characters.head()\",\"Print the first 5 lines of the characters dataframe\\nprint(df_characters.head())\",\"Show the first 5 lines of the characters dataframe\\ndf_characters.head()\",\"Display the first 5 lines of the characters dataframe\\ndf_characters.head()\",\"View first 5 lines of the characters dataframe\\ndf_characters.head()\",\"Display first 5 lines of the characters dataset\\ndf_characters.head()\",\"Display first 5 lines of df_characters\\ndf_characters.head(5)\",\" Display the first 5 lines of the characters DataFrame\\ndf_characters.head()\",\" Show the first 5 lines of the df_characters DataFrame\\ndf_characters.head()\",\" Display the top 5 character lines in the dataset\\ndf_script.head()\"],\"marker\":{\"opacity\":0.5,\"size\":5},\"mode\":\"markers+text\",\"name\":\"257_Display top 5 character lines in dataset\",\"text\":[\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\"],\"textfont\":{\"size\":12},\"x\":[-0.01844007335603237,-0.13703186810016632,0.14917294681072235,-0.7613731026649475,-0.21754953265190125,-0.34596434235572815,-0.09061214327812195,0.12084691226482391,-0.2921901047229767,-0.14574994146823883,-0.306753009557724,0.8544520735740662],\"y\":[12.57790756225586,12.0641450881958,12.491535186767578,11.413603782653809,12.175589561462402,12.01683235168457,12.377753257751465,12.48945426940918,12.581565856933594,12.075235366821289,11.975167274475098,13.229336738586426],\"type\":\"scattergl\"},{\"hoverinfo\":\"text\",\"hovertext\":[\"Check if the dataframes were propertly loaded\\ndf_characters.head()\",\"Encoding errors in dataframe_character dataset\\ndf_characters[df_characters.original_title.str.contains('\\ufffd')]\",\"Check for a correct import by visualizing the head of the characters dataframe\\ndf_characters.head()\",\"Check imported DataFrames\\ndf_characters.head()\",\"Check the first few rows of the dataframe to verify that the data was loaded properly\\ndf_characters.head()\",\"Ensure the correct encoding for each dataframe\",\"Check if dataframes were imported correctly\\ndf_characters.head()\",\"Verify the dataframes are correctly loaded\\ndf_characters.head()\",\"Check if the dataframes have been imported correctly\\ndf_characters.head()\",\"Check the head of the dataframe to ensure information was imported correctly\\ndf_characters.head()\",\"Checking if the dataframe has been successfully loaded\\nprint(df_characters.head())\",\"Check everything imported correctly\\ndf_characters.head()\"],\"marker\":{\"opacity\":0.5,\"size\":5},\"mode\":\"markers+text\",\"name\":\"258_Checking if dataframes were imported correctly\",\"text\":[\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\"],\"textfont\":{\"size\":12},\"x\":[5.671733856201172,5.863351345062256,5.442648887634277,5.207093238830566,5.95974588394165,6.290431499481201,5.349493026733398,5.990819931030273,5.721982479095459,5.736294269561768,5.604041576385498,5.227940559387207],\"y\":[12.516464233398438,11.079853057861328,11.782809257507324,12.403305053710938,12.729598999023438,10.872085571289062,11.924138069152832,12.286026954650879,11.91380786895752,11.212295532226562,12.263969421386719,11.861637115478516],\"type\":\"scattergl\"},{\"hoverinfo\":\"text\",\"hovertext\":[\"Preview the dataframes\\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()\",\"Preview the data\\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()\",\"Preview the data.frames\\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()\",\"Preview the dataframes\\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()\",\"Preview the data in each DataFrame\\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()\",\"Preview the dataframes\\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()\",\"Preview tables\\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()\",\"Preview the datasets\\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()\",\"Preview all dataframes\\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()\",\" Show a preview of each DataFrame\\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()\",\"Optional - Preview tables\\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()\",\"Preview the dataframes\\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()\"],\"marker\":{\"opacity\":0.5,\"size\":5},\"mode\":\"markers+text\",\"name\":\"259_Previewing dataframes and tables in\",\"text\":[\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\"],\"textfont\":{\"size\":12},\"x\":[-3.588345766067505,-3.3429195880889893,-3.7652039527893066,-3.6530325412750244,-4.051869869232178,-3.5283100605010986,-3.1834044456481934,-2.940347194671631,-3.859788179397583,-4.135009765625,-3.412616014480591,-3.5803675651550293],\"y\":[3.9921414852142334,4.053094863891602,4.233671188354492,4.138915061950684,4.264540195465088,4.358043193817139,3.5817060470581055,4.006830215454102,4.221746921539307,4.1609086990356445,3.707589864730835,3.905599355697632],\"type\":\"scattergl\"},{\"hoverinfo\":\"text\",\"hovertext\":[\"Inspect the structure of each dataframe\\ndf_characters.head()\",\" let's take a look at individual dataframes to understand their structure and contents\\ndf_characters.head()\",\"Inspect the structure of each dataframe\\ndf_characters.head()\",\"Look at the top few rows of each dataframe to understand the data structure\\ndf_characters.head()\",\"Inspect the data frames to understand their structure and contents\\ndf_characters.head()\",\"# The data spans accross 4 tables, which are related between each other with keys.\\ndf_characters.head()\\n\",\"Let's take a look at the first few rows of the df_characters dataframe to understand its structure and contents.\\ndf_characters.head()\",\"Inspect the structure of the `df_characters` dataframe\\ndf_characters.head()\",\" Look at the dataframes to understand their structures\\ndf_characters.head()\",\"Inspect the dataframes to understand their structure and content\\ndf_characters.head()\",\"Examine dataframe structure\\ndf_characters.head()\",\"Take a look at the dataframes and the structure of the data in each of them\\ndf_characters.head()\"],\"marker\":{\"opacity\":0.5,\"size\":5},\"mode\":\"markers+text\",\"name\":\"260_Understanding the Structure and Contents of Dataframes\",\"text\":[\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\"],\"textfont\":{\"size\":12},\"x\":[4.916914463043213,5.460242748260498,5.0377373695373535,5.322880268096924,5.185393810272217,5.647546768188477,5.862355709075928,5.672341346740723,5.400489330291748,5.035218715667725,4.771768569946289,5.910854816436768],\"y\":[15.545723915100098,15.71894645690918,15.348024368286133,15.119644165039062,15.184407234191895,14.560956954956055,15.505670547485352,15.525562286376953,15.286182403564453,15.608610153198242,15.055638313293457,14.74669361114502],\"type\":\"scattergl\"},{\"hoverinfo\":\"text\",\"hovertext\":[\" Let's start by looking at the first few rows of each dataset to understand their structure.\",\" Let's take a look at the first few rows of each dataset to understand its structure.\",\"We'll look at the first few records of each dataset to understand their structure better.\",\"We can glimpse at each dataset to understand the structure and the information that it contains.\",\"Because we are working with real-life data, let's take a look at the first few rows of each dataset to understand their structure.\",\"Now, let's take a look at the first few rows of each dataset to understand their structure and contents.\",\" Let's take a look at the first few lines of each dataset to understand its structure.\",\"Understand the structure of the datasets\",\"Let's take a glance at the first five rows of the dataset to understand its structure and content.\",\"Let's take a look at the structure and the first few rows of these datasets.\",\" Looking at the first few lines of each dataset to understand the structure and the type of data present\",\"Let's take a look at the first few rows of our datasets to understand their structure.\"],\"marker\":{\"opacity\":0.5,\"size\":5},\"mode\":\"markers+text\",\"name\":\"261_Understanding the Structure of Datasets\",\"text\":[\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\"],\"textfont\":{\"size\":12},\"x\":[14.645118713378906,14.730342864990234,14.917667388916016,15.31812858581543,14.41518783569336,14.695181846618652,14.826409339904785,15.092166900634766,14.404241561889648,15.119368553161621,14.925572395324707,14.781859397888184],\"y\":[-3.506078004837036,-3.942460060119629,-3.7736916542053223,-3.1053459644317627,-4.1158905029296875,-3.608335018157959,-3.593925952911377,-3.0343291759490967,-3.7611024379730225,-3.8059895038604736,-2.8875906467437744,-4.06879186630249],\"type\":\"scattergl\"},{\"hoverinfo\":\"text\",\"hovertext\":[\"Previewing the dataframes\",\"Preview some dataframes\",\"Preview the dataframes\",\"Display a preview of the dataframes\",\"Preview the dataframes\",\"Previewing the dataframes\",\"Preview and reset index of all dataframes\",\" Preview the data to understand the structure and contents of each dataframe\",\"Get preview of the data in each of the DataFrames\",\"To ensure that the data has been read correctly, we can display a preview of each DataFrame using the `head()` method.\",\"Preview the dataframes to understand their structure and available columns\",\"Let's preview the dataframes\"],\"marker\":{\"opacity\":0.5,\"size\":5},\"mode\":\"markers+text\",\"name\":\"262_Previewing dataframes\",\"text\":[\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\"],\"textfont\":{\"size\":12},\"x\":[18.357051849365234,18.165719985961914,18.264434814453125,18.531021118164062,18.24886131286621,18.279691696166992,17.939210891723633,17.984600067138672,18.10471534729004,18.357160568237305,18.348773956298828,18.56296157836914],\"y\":[-3.536311388015747,-3.5755321979522705,-3.461749315261841,-3.4660401344299316,-3.5435283184051514,-3.388963222503662,-3.6499199867248535,-3.9399123191833496,-3.345036268234253,-3.888578176498413,-3.8030173778533936,-3.782912492752075],\"type\":\"scattergl\"},{\"hoverinfo\":\"text\",\"hovertext\":[\"Extract characters' genders and ages\\ngenders = {}\\nages = {}\\n\\nfor index, row in df_characters.iterrows():\\n    genders[row['id']] = row['gender']\\n    ages[row['id']] = row['age']\",\"Reformat the character construction.\\ndf_characters = df_characters[['id', 'name', 'normalized_name', 'gender', 'description', 'job', 'img_url']]\",\" Replace f'{gender}:aplha' by f'{gender}:alpha' for the characters dataframe\\ndf_characters['gender'] = df_characters['gender'].replace({'f':'female', 'm':'male', 'n':'neutral'})\",\"ne hot encoding to deal with the gender variable\\ndf_characters['gender'] = pd.get_dummies(df_characters['gender'])\\n\\n# Replacing bad symbols in the raw text\\ndf_script['raw_text'] = df_script['raw_text'].str.replace('\\\\n', ' ')\",\"Create a dictionary that maps character names to their gender\\nchar_gender_dict = df_characters.groupby('name').first().gender.to_dict()\",\"Extract genders for characters_forename column\\ndf_characters[['forename', 'gender']].sample(10)\",\"Select characters gender and distinct genders\\ngenders = df_characters[['gender', 'name']].drop_duplicates().dropna()\",\"Select required columns from df_characters\\ndf_characters = df_characters[['id', 'name', 'normalized_name', 'gender']]\\ndf_characters.head()\",\" Character to gender mapping\\ndf_gender = df_characters[['raw_character_text', 'gender']].groupby('raw_character_text').agg(lambda x: x.value_counts().index[0])\",\"# Function converting categorical columns to category type\\ndef convert_categorical(df, cols):\\n    for col in cols:\\n        df[col] = df[col].astype('category')\",\"Extract the gender and the line\\ndf_script_lines = df_script[['character_id', 'location_id', 'gender', 'normalized_text']]\"],\"marker\":{\"opacity\":0.5,\"size\":5},\"mode\":\"markers+text\",\"name\":\"263_Gender analysis and data manipulation\",\"text\":[\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\"],\"textfont\":{\"size\":12},\"x\":[6.424230575561523,6.317129135131836,6.565943717956543,6.33089017868042,7.1169023513793945,6.730258941650391,6.443973541259766,6.325194835662842,6.952441692352295,6.851417541503906,6.367447376251221],\"y\":[8.505440711975098,9.402058601379395,7.412381172180176,8.730487823486328,8.360858917236328,8.14402961730957,7.910378932952881,9.12208366394043,8.486948013305664,8.957006454467773,7.424768924713135],\"type\":\"scattergl\"},{\"hoverinfo\":\"text\",\"hovertext\":[\"Visualize the number of lines per character\\ndf_characters['line_count'] = df_script['character_id'].value_counts()\\ndf_characters_merged = df_characters.merge(df_locations, left_on='location_id', right_on='id', how='left')\\ndf_characters_merged['line_count'] = df_characters_merged['line_count'].fillna(0)\",\"Visualizing data\\n# Counting lines for each character\\nlines_per_character = df_script['character_id'].value_counts()\\nlines_per_character = lines_per_character.reset_index(inplace=False)\\nlines_per_character.columns = ['character_id', 'lines']\",\" Visualization on the number of lines for each character and location.\\nchar_lines = df_script['character_id'].value_counts()\\nchar_lines = char_lines[char_lines.index != 'nan']\\nchar_lines = char_lines[char_lines.index != ''])\\nloc_lines = df_script['location_id'].value_counts()\\nloc_lines = loc_lines[loc_lines.index != 'nan']\\nloc_lines = loc_lines[loc_lines.index != ''])\",\" Calculate the number of lines that contain the lines spoken by each character\\nlines_per_character = df_script.groupby('character_id').size()\\nlines_per_character = lines_per_character.sort_values(ascending=False)\",\"Top 10 most popular characters\\ntop_characters = df_script['character_id'].value_counts().head(10)\\n# Change character numeric ID to character name\\ntop_characters = pd.DataFrame(top_characters).merge(df_characters, left_index=True, right_on='id').set_index('id')\\ntop_characters.columns = ['count', 'character_name']\",\"Aggregating script lines by character ID\\nlines_per_character = df_script[df_script.speaking_line == True].groupby('character_id').agg('count').reset_index()\\nlines_per_character = lines_per_character[['character_id', 'id']]\\nlines_per_character.columns = ['character_id', 'line_count']\",\"Count the frequency of each character in the script\\ncount_char = Counter(df_script['character_id'])\\ntop_10_char = count_char.most_common(10)\",\"Count the number of script lines by character\\nscript_lines_count = df_script['character_id'].value_counts()\",\"Calculate the number of lines for each character\\nlines_per_character = df_script['character_id'].value_counts()\",\"counts number of lines each character has\\nlines_per_character = df_script\\n    .groupby('raw_character_text')['id']\\n    .count()\",\"Visualize the number of lines spoken by each character\\nline_count = df_script['character_id'].value_counts()\\ntop_characters = line_count.nlargest(10)\"],\"marker\":{\"opacity\":0.5,\"size\":5},\"mode\":\"markers+text\",\"name\":\"264_Character Lines\",\"text\":[\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\"],\"textfont\":{\"size\":12},\"x\":[7.9450883865356445,7.864171504974365,7.280386924743652,8.120238304138184,7.2905120849609375,7.573884963989258,7.679380416870117,7.802789211273193,7.988738059997559,8.094582557678223,8.595664978027344],\"y\":[8.913911819458008,9.54527759552002,8.865431785583496,8.938417434692383,10.179280281066895,8.779594421386719,9.810676574707031,9.175528526306152,9.168481826782227,8.855729103088379,9.243903160095215],\"type\":\"scattergl\"},{\"hoverinfo\":\"text\",\"hovertext\":[\" We need a parser to process the script\\nnlp = spacy.load('en_core_web_sm')\",\" For spaCy\\nnlp = spacy.load('en_core_web_sm')\",\"#global variables\\nnlp = spacy.load(\\\"en_core_web_sm\\\")\",\"nlp = spacy.load('en_core_web_sm')\",\"General settings\\nplt.style.use('fivethirtyeight')\\nnlp = spacy.load('en_core_web_sm')\",\"nlp = spacy.load(\\\"en_core_web_sm\\\")\",\"nlp = spacy.load(\\\"en_core_web_sm\\\")\",\"nlp = spacy.load('en_core_web_sm')\",\"NLP tools\\nnlp = spacy.load('en_core_web_sm')\",\"\\nnlp = spacy.load(\\\"en_core_web_sm\\\")\",\"nlp = spacy.load('en_core_web_sm')\"],\"marker\":{\"opacity\":0.5,\"size\":5},\"mode\":\"markers+text\",\"name\":\"265_NLP Tools with Spacy\",\"text\":[\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\"],\"textfont\":{\"size\":12},\"x\":[15.161639213562012,15.613601684570312,16.26685905456543,15.546331405639648,15.769330024719238,15.683775901794434,15.443042755126953,15.490363121032715,15.642780303955078,15.574663162231445,15.799142837524414],\"y\":[8.680275917053223,9.261909484863281,8.637630462646484,9.110316276550293,9.189620018005371,8.99990463256836,8.874994277954102,9.295099258422852,9.190925598144531,8.918537139892578,9.26888656616211],\"type\":\"scattergl\"},{\"hoverinfo\":\"text\",\"hovertext\":[\" Visualize the first few rows of the characters dataframe\\ndf_characters.head()\",\" Visualize the first few rows of the characters dataframe\\ndf_characters.head()\",\"Visual Representation of the Data\\n# Show the first 5 rows of the characters dataframe\\ndf_characters.head()\",\" visualize the first few rows of the characters dataframe\\ndf_characters.head()\",\" Visualize the first 5 rows of the characters dataframe\\ndf_characters.head()\",\" Visualise first few entries in characters database\\ndf_characters.head()\",\"# Visualizing the first few rows of the characters dataframe\\ndf_characters.head()\",\"Visualize the first few rows of the characters DataFrame\\ndf_characters.head()\",\" Visualize the first few rows of the characters dataframe\\ndf_characters.head()\",\"Visualise the first characters of the DataFrame 'df_characters'\",\" Visualize the first few rows of the characters dataframe\\ndf_characters.head()\"],\"marker\":{\"opacity\":0.5,\"size\":5},\"mode\":\"markers+text\",\"name\":\"266_Visualizing the first few rows of the characters dataframe\",\"text\":[\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\"],\"textfont\":{\"size\":12},\"x\":[-1.1215406656265259,-1.3747923374176025,-1.3025774955749512,-1.1181379556655884,-1.3176023960113525,0.5131878852844238,-1.005571961402893,-0.9061102867126465,-1.1680214405059814,7.600157737731934,-1.2123363018035889],\"y\":[22.28818702697754,22.440114974975586,21.91986656188965,22.291114807128906,21.80807113647461,18.47804069519043,22.343971252441406,22.245250701904297,22.360828399658203,15.27103328704834,22.42549705505371],\"type\":\"scattergl\"},{\"hoverinfo\":\"text\",\"hovertext\":[\"Change values that are \\\"bad\\\" to NaN so that I can easily inspect if I have any of these in the dataset\",\"The first thing to do is to remove NaN values.\",\"Remove all lines with NaN values, and all values that are the empty string\",\"Check if there are any NaNs in the data\",\"We need to remove some columns and nan values from scripts dataframe\",\"Merge dataframes and remove rows in which there are at least one NaN value\",\"Display which rows had NaN values for the script data\\ndf_script[df_script.isna().any(axis=1)]\",\"Check for any NaN's in the data\",\"Filtering the data to remove unnecessary columns and NaN values\",\"remove columns with mostly nan's\"],\"marker\":{\"opacity\":0.5,\"size\":5},\"mode\":\"markers+text\",\"name\":\"267_Handling NaN Values in Dataframes\",\"text\":[\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\"],\"textfont\":{\"size\":12},\"x\":[7.056744575500488,7.642185688018799,7.391637325286865,6.722513198852539,7.267445087432861,7.625410079956055,6.562579154968262,7.069887161254883,8.500152587890625,7.926601409912109],\"y\":[1.8831467628479004,2.2273151874542236,2.487213373184204,1.5077731609344482,2.3773887157440186,2.525984048843384,2.0442862510681152,1.6002179384231567,2.2855358123779297,2.3501062393188477],\"type\":\"scattergl\"}],                        {\"template\":{\"data\":{\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"white\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"bar\":[{\"error_x\":{\"color\":\"rgb(36,36,36)\"},\"error_y\":{\"color\":\"rgb(36,36,36)\"},\"marker\":{\"line\":{\"color\":\"white\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"rgb(36,36,36)\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"rgb(36,36,36)\"},\"baxis\":{\"endlinecolor\":\"rgb(36,36,36)\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"rgb(36,36,36)\"},\"type\":\"carpet\"}],\"choropleth\":[{\"colorbar\":{\"outlinewidth\":1,\"tickcolor\":\"rgb(36,36,36)\",\"ticks\":\"outside\"},\"type\":\"choropleth\"}],\"contourcarpet\":[{\"colorbar\":{\"outlinewidth\":1,\"tickcolor\":\"rgb(36,36,36)\",\"ticks\":\"outside\"},\"type\":\"contourcarpet\"}],\"contour\":[{\"colorbar\":{\"outlinewidth\":1,\"tickcolor\":\"rgb(36,36,36)\",\"ticks\":\"outside\"},\"colorscale\":[[0.0,\"#440154\"],[0.1111111111111111,\"#482878\"],[0.2222222222222222,\"#3e4989\"],[0.3333333333333333,\"#31688e\"],[0.4444444444444444,\"#26828e\"],[0.5555555555555556,\"#1f9e89\"],[0.6666666666666666,\"#35b779\"],[0.7777777777777778,\"#6ece58\"],[0.8888888888888888,\"#b5de2b\"],[1.0,\"#fde725\"]],\"type\":\"contour\"}],\"heatmapgl\":[{\"colorbar\":{\"outlinewidth\":1,\"tickcolor\":\"rgb(36,36,36)\",\"ticks\":\"outside\"},\"colorscale\":[[0.0,\"#440154\"],[0.1111111111111111,\"#482878\"],[0.2222222222222222,\"#3e4989\"],[0.3333333333333333,\"#31688e\"],[0.4444444444444444,\"#26828e\"],[0.5555555555555556,\"#1f9e89\"],[0.6666666666666666,\"#35b779\"],[0.7777777777777778,\"#6ece58\"],[0.8888888888888888,\"#b5de2b\"],[1.0,\"#fde725\"]],\"type\":\"heatmapgl\"}],\"heatmap\":[{\"colorbar\":{\"outlinewidth\":1,\"tickcolor\":\"rgb(36,36,36)\",\"ticks\":\"outside\"},\"colorscale\":[[0.0,\"#440154\"],[0.1111111111111111,\"#482878\"],[0.2222222222222222,\"#3e4989\"],[0.3333333333333333,\"#31688e\"],[0.4444444444444444,\"#26828e\"],[0.5555555555555556,\"#1f9e89\"],[0.6666666666666666,\"#35b779\"],[0.7777777777777778,\"#6ece58\"],[0.8888888888888888,\"#b5de2b\"],[1.0,\"#fde725\"]],\"type\":\"heatmap\"}],\"histogram2dcontour\":[{\"colorbar\":{\"outlinewidth\":1,\"tickcolor\":\"rgb(36,36,36)\",\"ticks\":\"outside\"},\"colorscale\":[[0.0,\"#440154\"],[0.1111111111111111,\"#482878\"],[0.2222222222222222,\"#3e4989\"],[0.3333333333333333,\"#31688e\"],[0.4444444444444444,\"#26828e\"],[0.5555555555555556,\"#1f9e89\"],[0.6666666666666666,\"#35b779\"],[0.7777777777777778,\"#6ece58\"],[0.8888888888888888,\"#b5de2b\"],[1.0,\"#fde725\"]],\"type\":\"histogram2dcontour\"}],\"histogram2d\":[{\"colorbar\":{\"outlinewidth\":1,\"tickcolor\":\"rgb(36,36,36)\",\"ticks\":\"outside\"},\"colorscale\":[[0.0,\"#440154\"],[0.1111111111111111,\"#482878\"],[0.2222222222222222,\"#3e4989\"],[0.3333333333333333,\"#31688e\"],[0.4444444444444444,\"#26828e\"],[0.5555555555555556,\"#1f9e89\"],[0.6666666666666666,\"#35b779\"],[0.7777777777777778,\"#6ece58\"],[0.8888888888888888,\"#b5de2b\"],[1.0,\"#fde725\"]],\"type\":\"histogram2d\"}],\"histogram\":[{\"marker\":{\"line\":{\"color\":\"white\",\"width\":0.6}},\"type\":\"histogram\"}],\"mesh3d\":[{\"colorbar\":{\"outlinewidth\":1,\"tickcolor\":\"rgb(36,36,36)\",\"ticks\":\"outside\"},\"type\":\"mesh3d\"}],\"parcoords\":[{\"line\":{\"colorbar\":{\"outlinewidth\":1,\"tickcolor\":\"rgb(36,36,36)\",\"ticks\":\"outside\"}},\"type\":\"parcoords\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}],\"scatter3d\":[{\"line\":{\"colorbar\":{\"outlinewidth\":1,\"tickcolor\":\"rgb(36,36,36)\",\"ticks\":\"outside\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":1,\"tickcolor\":\"rgb(36,36,36)\",\"ticks\":\"outside\"}},\"type\":\"scatter3d\"}],\"scattercarpet\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":1,\"tickcolor\":\"rgb(36,36,36)\",\"ticks\":\"outside\"}},\"type\":\"scattercarpet\"}],\"scattergeo\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":1,\"tickcolor\":\"rgb(36,36,36)\",\"ticks\":\"outside\"}},\"type\":\"scattergeo\"}],\"scattergl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":1,\"tickcolor\":\"rgb(36,36,36)\",\"ticks\":\"outside\"}},\"type\":\"scattergl\"}],\"scattermapbox\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":1,\"tickcolor\":\"rgb(36,36,36)\",\"ticks\":\"outside\"}},\"type\":\"scattermapbox\"}],\"scatterpolargl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":1,\"tickcolor\":\"rgb(36,36,36)\",\"ticks\":\"outside\"}},\"type\":\"scatterpolargl\"}],\"scatterpolar\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":1,\"tickcolor\":\"rgb(36,36,36)\",\"ticks\":\"outside\"}},\"type\":\"scatterpolar\"}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"scatterternary\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":1,\"tickcolor\":\"rgb(36,36,36)\",\"ticks\":\"outside\"}},\"type\":\"scatterternary\"}],\"surface\":[{\"colorbar\":{\"outlinewidth\":1,\"tickcolor\":\"rgb(36,36,36)\",\"ticks\":\"outside\"},\"colorscale\":[[0.0,\"#440154\"],[0.1111111111111111,\"#482878\"],[0.2222222222222222,\"#3e4989\"],[0.3333333333333333,\"#31688e\"],[0.4444444444444444,\"#26828e\"],[0.5555555555555556,\"#1f9e89\"],[0.6666666666666666,\"#35b779\"],[0.7777777777777778,\"#6ece58\"],[0.8888888888888888,\"#b5de2b\"],[1.0,\"#fde725\"]],\"type\":\"surface\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"rgb(237,237,237)\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"rgb(217,217,217)\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}]},\"layout\":{\"annotationdefaults\":{\"arrowhead\":0,\"arrowwidth\":1},\"autotypenumbers\":\"strict\",\"coloraxis\":{\"colorbar\":{\"outlinewidth\":1,\"tickcolor\":\"rgb(36,36,36)\",\"ticks\":\"outside\"}},\"colorscale\":{\"diverging\":[[0.0,\"rgb(103,0,31)\"],[0.1,\"rgb(178,24,43)\"],[0.2,\"rgb(214,96,77)\"],[0.3,\"rgb(244,165,130)\"],[0.4,\"rgb(253,219,199)\"],[0.5,\"rgb(247,247,247)\"],[0.6,\"rgb(209,229,240)\"],[0.7,\"rgb(146,197,222)\"],[0.8,\"rgb(67,147,195)\"],[0.9,\"rgb(33,102,172)\"],[1.0,\"rgb(5,48,97)\"]],\"sequential\":[[0.0,\"#440154\"],[0.1111111111111111,\"#482878\"],[0.2222222222222222,\"#3e4989\"],[0.3333333333333333,\"#31688e\"],[0.4444444444444444,\"#26828e\"],[0.5555555555555556,\"#1f9e89\"],[0.6666666666666666,\"#35b779\"],[0.7777777777777778,\"#6ece58\"],[0.8888888888888888,\"#b5de2b\"],[1.0,\"#fde725\"]],\"sequentialminus\":[[0.0,\"#440154\"],[0.1111111111111111,\"#482878\"],[0.2222222222222222,\"#3e4989\"],[0.3333333333333333,\"#31688e\"],[0.4444444444444444,\"#26828e\"],[0.5555555555555556,\"#1f9e89\"],[0.6666666666666666,\"#35b779\"],[0.7777777777777778,\"#6ece58\"],[0.8888888888888888,\"#b5de2b\"],[1.0,\"#fde725\"]]},\"colorway\":[\"#1F77B4\",\"#FF7F0E\",\"#2CA02C\",\"#D62728\",\"#9467BD\",\"#8C564B\",\"#E377C2\",\"#7F7F7F\",\"#BCBD22\",\"#17BECF\"],\"font\":{\"color\":\"rgb(36,36,36)\"},\"geo\":{\"bgcolor\":\"white\",\"lakecolor\":\"white\",\"landcolor\":\"white\",\"showlakes\":true,\"showland\":true,\"subunitcolor\":\"white\"},\"hoverlabel\":{\"align\":\"left\"},\"hovermode\":\"closest\",\"mapbox\":{\"style\":\"light\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"white\",\"polar\":{\"angularaxis\":{\"gridcolor\":\"rgb(232,232,232)\",\"linecolor\":\"rgb(36,36,36)\",\"showgrid\":false,\"showline\":true,\"ticks\":\"outside\"},\"bgcolor\":\"white\",\"radialaxis\":{\"gridcolor\":\"rgb(232,232,232)\",\"linecolor\":\"rgb(36,36,36)\",\"showgrid\":false,\"showline\":true,\"ticks\":\"outside\"}},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"white\",\"gridcolor\":\"rgb(232,232,232)\",\"gridwidth\":2,\"linecolor\":\"rgb(36,36,36)\",\"showbackground\":true,\"showgrid\":false,\"showline\":true,\"ticks\":\"outside\",\"zeroline\":false,\"zerolinecolor\":\"rgb(36,36,36)\"},\"yaxis\":{\"backgroundcolor\":\"white\",\"gridcolor\":\"rgb(232,232,232)\",\"gridwidth\":2,\"linecolor\":\"rgb(36,36,36)\",\"showbackground\":true,\"showgrid\":false,\"showline\":true,\"ticks\":\"outside\",\"zeroline\":false,\"zerolinecolor\":\"rgb(36,36,36)\"},\"zaxis\":{\"backgroundcolor\":\"white\",\"gridcolor\":\"rgb(232,232,232)\",\"gridwidth\":2,\"linecolor\":\"rgb(36,36,36)\",\"showbackground\":true,\"showgrid\":false,\"showline\":true,\"ticks\":\"outside\",\"zeroline\":false,\"zerolinecolor\":\"rgb(36,36,36)\"}},\"shapedefaults\":{\"fillcolor\":\"black\",\"line\":{\"width\":0},\"opacity\":0.3},\"ternary\":{\"aaxis\":{\"gridcolor\":\"rgb(232,232,232)\",\"linecolor\":\"rgb(36,36,36)\",\"showgrid\":false,\"showline\":true,\"ticks\":\"outside\"},\"baxis\":{\"gridcolor\":\"rgb(232,232,232)\",\"linecolor\":\"rgb(36,36,36)\",\"showgrid\":false,\"showline\":true,\"ticks\":\"outside\"},\"bgcolor\":\"white\",\"caxis\":{\"gridcolor\":\"rgb(232,232,232)\",\"linecolor\":\"rgb(36,36,36)\",\"showgrid\":false,\"showline\":true,\"ticks\":\"outside\"}},\"title\":{\"x\":0.05},\"xaxis\":{\"automargin\":true,\"gridcolor\":\"rgb(232,232,232)\",\"linecolor\":\"rgb(36,36,36)\",\"showgrid\":false,\"showline\":true,\"ticks\":\"outside\",\"title\":{\"standoff\":15},\"zeroline\":false,\"zerolinecolor\":\"rgb(36,36,36)\"},\"yaxis\":{\"automargin\":true,\"gridcolor\":\"rgb(232,232,232)\",\"linecolor\":\"rgb(36,36,36)\",\"showgrid\":false,\"showline\":true,\"ticks\":\"outside\",\"title\":{\"standoff\":15},\"zeroline\":false,\"zerolinecolor\":\"rgb(36,36,36)\"}}},\"shapes\":[{\"line\":{\"color\":\"#CFD8DC\",\"width\":2},\"type\":\"line\",\"x0\":12.287337017059325,\"x1\":12.287337017059325,\"y0\":-13.125758409500122,\"y1\":32.65453567504883},{\"line\":{\"color\":\"#9E9E9E\",\"width\":2},\"type\":\"line\",\"x0\":-13.100666427612305,\"x1\":37.675340461730954,\"y0\":9.764388632774352,\"y1\":9.764388632774352}],\"annotations\":[{\"showarrow\":false,\"text\":\"D1\",\"x\":-13.100666427612305,\"y\":9.764388632774352,\"yshift\":10},{\"showarrow\":false,\"text\":\"D2\",\"x\":12.287337017059325,\"xshift\":10,\"y\":32.65453567504883}],\"title\":{\"font\":{\"size\":22,\"color\":\"Black\"},\"text\":\"Next Thing After Importing Data:\",\"x\":0.5,\"xanchor\":\"center\",\"yanchor\":\"top\"},\"width\":1800,\"height\":1000,\"xaxis\":{\"visible\":false},\"yaxis\":{\"visible\":false}},                        {\"responsive\": true}                    ).then(function(){\n",
       "                            \n",
       "var gd = document.getElementById('2abf5e4c-ad08-4842-95db-956069ec5f0f');\n",
       "var x = new MutationObserver(function (mutations, observer) {{\n",
       "        var display = window.getComputedStyle(gd).display;\n",
       "        if (!display || display === 'none') {{\n",
       "            console.log([gd, 'removed!']);\n",
       "            Plotly.purge(gd);\n",
       "            observer.disconnect();\n",
       "        }}\n",
       "}});\n",
       "\n",
       "// Listen for the removal of the full notebook cells\n",
       "var notebookContainer = gd.closest('#notebook-container');\n",
       "if (notebookContainer) {{\n",
       "    x.observe(notebookContainer, {childList: true});\n",
       "}}\n",
       "\n",
       "// Listen for the clearing of the current output cell\n",
       "var outputEl = gd.closest('.output');\n",
       "if (outputEl) {{\n",
       "    x.observe(outputEl, {childList: true});\n",
       "}}\n",
       "\n",
       "                        })                };                });            </script>        </div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "topic_model.visualize_documents(answer_list, reduced_embeddings=reduced_embeddings, width=1800, height=1000, hide_annotations=True, title=\"Next Thing After Importing Data:\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at microsoft/CodeBERT-base and are newly initialized: ['classifier.out_proj.weight', 'classifier.out_proj.bias', 'classifier.dense.weight', 'classifier.dense.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"microsoft/CodeBERT-base\")\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"microsoft/CodeBERT-base\").to(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [01:08<00:00, 146.80it/s]\n"
     ]
    }
   ],
   "source": [
    "quality_scores = []\n",
    "needs_comment_scores = []\n",
    "\n",
    "for answer in tqdm(answer_list):\n",
    "    full_code = code + answer\n",
    "\n",
    "    # If the full_code is longer than 512 tokens, we need to truncate it\n",
    "    while len(tokenizer.encode(full_code, return_tensors=\"pt\")[0]) > 512:\n",
    "        full_code = full_code[1:]\n",
    "\n",
    "    input_ids = tokenizer.encode(full_code, return_tensors=\"pt\").to(device)\n",
    "    output = model(input_ids)\n",
    "    quality_scores.append(output.logits[0, 0].to(\"cpu\").tolist())\n",
    "    needs_comment_scores.append(output.logits[0, 1].to(\"cpu\").tolist())\n",
    "\n",
    "input_ids = tokenizer.encode(code, return_tensors=\"pt\").to(device)\n",
    "quality_score_before = model(input_ids).logits[0, 0].cpu().tolist()\n",
    "needs_comment_score_before = model(input_ids).logits[0, 1].cpu().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x300 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(1, 2, figsize=(10, 3))\n",
    "ax[0].hist(quality_scores, bins=100, label=\"10k Completions\")\n",
    "ax[0].set_title(\"'Quality' Scores\")\n",
    "ax[0].set_xlabel(\"Score\")\n",
    "ax[0].axvline(quality_score_before, color=\"red\", label=\"User Input\")\n",
    "ax[0].legend()\n",
    "\n",
    "ax[1].hist(needs_comment_scores, bins=100, label=\"10k Completions\")\n",
    "ax[1].set_title(\"'Needs Comment' Scores\");\n",
    "ax[1].set_xlabel(\"Score\")\n",
    "ax[1].axvline(needs_comment_score_before, color=\"red\", label=\"User Input\")\n",
    "ax[1].legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quality: 0.23252\n",
      "Answer: Define ordering of seasons and episodes\n",
      "season_episode_order = {\n",
      "    (1, 1): 1,   (1, 2): 2,   (1, 3): 3,   (1, 4): 4,\n",
      "    (2, 1): 5,   (2, 2): 6,   (2, 3): 7,   (2, 4): 8,\n",
      "    (3, 1): 9,   (3, 2): 10,  (3, 3): 11,  (3, 4): 12,\n",
      "    (4, 1): 13,  (4, 2): 14,  (4, 3): 15,  (4, 4): 16,\n",
      "    (5, 1): 17,  (5, 2): 18,  (5, 3): 19,  (5, 4): 20,\n",
      "    (6, 1): 21,  (6, 2): 22,  (6, 3): 23,  (6, 4): 24,\n",
      "    (7, 1): 25,  (7, 2): 26,  (7, 3): 27,  (7, 4): 28,\n",
      "    (8, 1): 29,  (8, 2): 30,  (8, 3): 31,  (8, 4): 32,\n",
      "    (9, 1): 33,  (9, 2): 34,  (9, 3): 35,  (9, 4): 36,\n",
      "    (10, 1): 37, (10, 2): 38, (10, 3): 39, (10, 4): 40,\n",
      "    (11, 1): 41, (11, 2): 42, (11, 3): 43, (11, 4): 44,\n",
      "    (12, 1): 45, (12, 2): 46, (12, 3): 47, (12, 4): 48,\n",
      "    (13, 1): 49, (13, 2): 50, (13, 3): 51, (13, 4): 52,\n",
      "    (14, 1): 53, (14, 2): 54, (14, 3): 55, (14, 4): 56,\n",
      "    (15, 1): 57, (15, 2): 58, (15, 3): 59, (15, 4): 60,\n",
      "    (16, 1): 61, (16, 2): 62, (16, 3): 63, (16, 4): 64,\n",
      "    (17, 1): 65, (17, 2): 66, (17, 3): 67, (17, 4): 68,\n",
      "    (18, 1): 69, (18, 2): 70, (18, 3): 71, (18, 4): 72,\n",
      "    (19, 1): 73, (19, 2): 74, (19, 3): 75, (19, 4): 76,\n",
      "    (20, 1): 77, (20, 2): 78, (20, 3): 79, (20, 4): 80,\n",
      "    (21, 1): 81, (21, 2): 82, (21, 3): 83, (21, 4): 84,\n",
      "    (22, 1): 85, (22, 2): 86, (22, 3): 87, (22, 4): 88,\n",
      "    (23, 1): 89, (23, 2): 90, (23, 3): 91, (23, 4): 92,\n",
      "    (24, 1): 93, (24, 2): 94, (24, 3): 95, (24, 4): 96,\n",
      "    (25, 1): 97, (25, 2): 98, (25, 3): 99, (25, 4): 100,\n",
      "    (26, 1): 101, (26, 2): 102, (26, 3): 103, (26, 4): 104,\n",
      "    (27, 1): 105, (27, 2): 106, (27, 3): 107, (27, 4): 108,\n",
      "    (28, 1): 109, (28, 2): 110, (28, 3): 111, (28, 4): 112,\n",
      "    (29, 1): 113, (29, 2): 114, (29, 3): 115, (29, 4): 116,\n",
      "    (30, 1): 117, (30, 2): 118, (30, 3): 119, (30, 4): 120,\n",
      "    (31, 1): 121, (31, 2): 122, (31, 3): 123, (31, 4): 124,\n",
      "    (32, 1): 125, (32, 2): 126, (32, 3): 127, (32, 4): 128\n",
      "}\n",
      "\n",
      "Quality: 0.21334\n",
      "Answer: 1. Data overview and preprocessing\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Show the best quality answers\n",
    "best_quality_answers = sorted(zip(quality_scores, answer_list), reverse=True)\n",
    "for quality, answer in best_quality_answers[:2]:\n",
    "    print(f\"Quality: {quality:.5f}\\nAnswer: {answer}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quality: 0.10720\n",
      "Answer:  Set text cleaning settings\n",
      "nlp = spacy.load(\"en_core_web_md\", disable=[\"parser\", \"ner\"])\n",
      "\n",
      "# Constants\n",
      "white_list_chars = [\n",
      "    \"bart\", \"homer\", \"marge\", \"maggie\", \"lisa\", \"krusty\", \"burns\",\n",
      "    \"millhouse\", \"apu\", \"moe\", \"ned\", \"edna\", \"skinner\", \"ralph\",\n",
      "    \"barney\", \"todd\", \"rod\", \"hans\", \"troy\", \"citizen\", \"abraham\",\n",
      "    \"lenny\", \"carl\", \"lionel\", \"selma\", \"patty\", \"milhouse\", \"montgomery\",\n",
      "    \"clancy\", \"waylon\", \"apu_nahasapeemapetilon\"\n",
      "]\n",
      "\n",
      "# Function to preprocess texts\n",
      "def clean_text(text: str) -> str:\n",
      "    # Convert to lowercase\n",
      "    text = text.lower()\n",
      "    \n",
      "    # Remove punctuation, digits and special characters\n",
      "    text = \" \".join(token.lemma_ for token in nlp(text) if token.is_alpha)\n",
      "    \n",
      "    return text\n",
      "\n",
      "Quality: 0.11111\n",
      "Answer: def preprocess_dialogue(dialogue):\n",
      "    \"\"\"\n",
      "    Function to preprocess dialogue text data\n",
      "    \n",
      "    Args:\n",
      "    dialogue - A string containing the dialogue\n",
      "    \n",
      "    Returns:\n",
      "    clean_dialogue - The preprocessed and cleaned dialogue\n",
      "    \"\"\"\n",
      "    # Convert to lowercase\n",
      "    dialogue = dialogue.lower()\n",
      "    \n",
      "    # Remove extra whitespaces\n",
      "    dialogue = ' '.join(dialogue.split())\n",
      "    \n",
      "    # Replace 'uh-huh' with 'yes'\n",
      "    dialogue = dialogue.replace('uh-huh', 'yes')\n",
      "    \n",
      "    # Replace 'uh-uh' with 'no'\n",
      "    dialogue = dialogue.replace('uh-uh', 'no')\n",
      "    \n",
      "    # Remove laughter 'haha', 'hahaha', 'hahahaha', etc\n",
      "    dialogue = dialogue.replace('ha', '')\n",
      "    \n",
      "    return dialogue\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Show the worst quality answers\n",
    "worst_quality_answers = sorted(zip(quality_scores, answer_list), reverse=False)\n",
    "for quality, answer in worst_quality_answers[:2]:\n",
    "    print(f\"Quality: {quality:.5f}\\nAnswer: {answer}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_quality_scores = {id: [] for id in topic_model.topics_}\n",
    "topic_needs_comment_scores = {id: [] for id in topic_model.topics_}\n",
    "\n",
    "for answer, quality_score, needs_comment_score, id in zip(answer_list, quality_scores, needs_comment_scores, topic_model.topics_):\n",
    "    topic_quality_scores[id].append(quality_score)\n",
    "    topic_needs_comment_scores[id].append(needs_comment_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 3500x2000 with 270 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Show the distribution of scores for all topics\n",
    "n_topics = len(np.unique(topic_model.topics_))\n",
    "\n",
    "N_COLS = 15\n",
    "N_ROWS = int(np.ceil(n_topics / N_COLS))\n",
    "\n",
    "fig, ax = plt.subplots(N_ROWS, N_COLS, figsize=(35, 20))\n",
    "\n",
    "bins = np.linspace(0.11, 0.22, 20)\n",
    "\n",
    "for i, (topic_id, quality_scores) in enumerate(topic_quality_scores.items()):\n",
    "    ax[i // N_COLS, i % N_COLS].hist(quality_scores, bins=bins)\n",
    "    ax[i // N_COLS, i % N_COLS].set_title(f\"{topic_id}\")\n",
    "    ax[i // N_COLS, i % N_COLS].set_yticks([])\n",
    "    ax[i // N_COLS, i % N_COLS].set_xticks([])\n",
    "\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the mean and std score for each topic\n",
    "topic_quality_scores_mean = {id: np.mean(scores) for id, scores in topic_quality_scores.items()}\n",
    "topic_quality_scores_std = {id: np.std(scores) for id, scores in topic_quality_scores.items()}\n",
    "\n",
    "# Sort the topics by their id\n",
    "sorted_topic_quality_scores_mean = sorted(topic_quality_scores_mean.items(), key=lambda x: x[0])\n",
    "sorted_topic_quality_scores_std = sorted(topic_quality_scores_std.items(), key=lambda x: x[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the size of each topic\n",
    "topic_sizes = Counter(topic_model.topics_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_sizes = {id: size for id, size in sorted(topic_sizes.items(), key=lambda x: x[0])}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x700 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot an errorbar plot for each topic\n",
    "fig, ax = plt.subplots(1, 1, figsize=(15, 7))\n",
    "ax.errorbar(list(topic_sizes.values()), list(topic_quality_scores_mean.values()), yerr=list(topic_quality_scores_std.values()), fmt='o')\n",
    "ax.set_xscale('log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for id, _ in sorted(topic_quality_scores_mean.items(), key=lambda x: x[1], reverse=True):\n",
    "#     print(f\"Topic {id}: {topic_model.get_topic(id)}, size: {topic_sizes[id]}, mean: {topic_quality_scores_mean[id]:.5f}, std: {topic_quality_scores_std[id]:.5f}\")\n",
    "\n",
    "# Create a dataframe with the topic id, name, size, mean score, and std score\n",
    "score_df = pd.DataFrame({\n",
    "    \"id\": [id for id, _ in sorted_topic_quality_scores_mean],\n",
    "    \"name\": [topic_model.get_topic(id) for id, _ in sorted_topic_quality_scores_mean],\n",
    "    \"size\": [topic_sizes[id] for id, _ in sorted_topic_quality_scores_mean],\n",
    "    \"mean\": [mean for _, mean in sorted_topic_quality_scores_mean],\n",
    "    \"std\": [std for _, std in sorted_topic_quality_scores_std],\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the dataframe to a csv file\n",
    "score_df.to_csv(\"topic_scores.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llmcoder",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
