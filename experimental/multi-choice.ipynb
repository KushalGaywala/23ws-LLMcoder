{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "from llmcoder.utils import get_openai_key, get_system_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/paulsaegert/anaconda3/envs/llmcoder/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from bertopic import BERTopic\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = OpenAI(api_key=get_openai_key())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "code = \"\"\"# General imports\n",
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import spacy\n",
    "import matplotlib\n",
    "from wordcloud import WordCloud\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "# Custom imports\n",
    "from tqdm import tqdm\n",
    "from collections import Counter\n",
    "\n",
    "# Ensure matplotlib works correctly with Jupyter\n",
    "%matplotlib inline\n",
    "\n",
    "df_characters = pd.read_csv('data/simpsons_characters.csv').reset_index(inplace=False, drop=True)\n",
    "df_locations = pd.read_csv('data/simpsons_locations.csv').reset_index(inplace=False, drop=True)\n",
    "df_script = pd.read_csv('data/simpsons_script_lines.csv').reset_index(inplace=False, drop=True)\n",
    "df_episodes = pd.read_csv('data/simpsons_episodes.csv').reset_index(inplace=False, drop=True)\n",
    "\n",
    "# \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [{\n",
    "    \"role\": \"system\",\n",
    "    \"content\": get_system_prompt(),\n",
    "}, {\n",
    "    \"role\": \"user\",\n",
    "    \"content\": code\n",
    "}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_SAMPLES = 1_000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:27<00:00, 35.91it/s]"
     ]
    }
   ],
   "source": [
    "assert N_SAMPLES <= 1000  # Otherwise this will get very expensive\n",
    "\n",
    "chat_completions = []\n",
    "\n",
    "pbar = tqdm(total=N_SAMPLES)\n",
    "while len(chat_completions) < N_SAMPLES:\n",
    "    chat_completion = client.chat.completions.create(messages=messages, model='ft:gpt-3.5-turbo-1106:personal::8LCi9Q0d', n=min(128, N_SAMPLES - len(chat_completions)))\n",
    "    chat_completions.extend(chat_completion.choices)\n",
    "    pbar.update(len(chat_completion.choices))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer_list = [choice.message.content for choice in chat_completions]\n",
    "\n",
    "len(answer_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "from umap import UMAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "embeddings = sentence_model.encode(answer_list, show_progress_bar=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bertopic.representation import OpenAI\n",
    "\n",
    "representation_model = OpenAI(client, model=\"gpt-3.5-turbo\", delay_in_seconds=5, chat=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-07 21:25:05,044 - BERTopic - Dimensionality - Fitting the dimensionality reduction algorithm\n",
      "2023-12-07 21:25:11,571 - BERTopic - Dimensionality - Completed ✓\n",
      "2023-12-07 21:25:11,573 - BERTopic - Cluster - Start clustering the reduced embeddings\n",
      "2023-12-07 21:25:11,645 - BERTopic - Cluster - Completed ✓\n",
      "2023-12-07 21:25:11,654 - BERTopic - Representation - Extracting topics from clusters using representation models.\n",
      "100%|██████████| 27/27 [02:45<00:00,  6.13s/it]\n",
      "2023-12-07 21:27:57,536 - BERTopic - Representation - Completed ✓\n"
     ]
    }
   ],
   "source": [
    "# Train BERTopic\n",
    "topic_model = BERTopic(verbose=True, representation_model=representation_model).fit(answer_list, embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reduce dimensionality of embeddings, this step is optional but much faster to perform iteratively:\n",
    "reduced_embeddings = UMAP(n_neighbors=10, n_components=2, min_dist=0.3, metric='cosine').fit_transform(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_representations = [topic_model.get_topic(topic_id) for topic_id in range(len(topic_model.get_topic_freq()))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_model.set_topic_labels(topic_representations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "hoverinfo": "text",
         "hovertext": [
          "drop episode, movie and title. Additional cleanup.",
          "Let's take a look at the top few rows of each table.",
          " Creating a new column that combines the raw_text for the character uttering the text of the script line\ndf_script = pd.merge(df_script, df_characters[['id', 'raw_character_text']], how='inner', left_on='character_id', right_on='id')\n\n# Cleaning\ndf_script['raw_character_text'] = df_script['raw_character_text'].str.replace('The ', '')\ndf_script['raw_character_text'] = df_script['raw_character_text'].str.replace('the ', '')\ndf_script = df_script.drop('id', axis=1)\n\n# New column\ndf_script['character_location'] = df_script['raw_character_text'] + ' ' + df_script['location_id'].fillna('').astype(str)\n\n# Query term\nquery_term = 'Homer'\n\n# Subset data to include only those script lines uttered by the character with the specified name\ndf_characters_search = df_script[df_script['raw_character_text'] == query_term].groupby(['episode_id'])['word_count'].sum().reset_index()\n\n# Include episode title\ndf_characters_search = pd.merge(df_characters_search, df_episodes[['id', 'title', 'original_air_date']], how='inner', left_on='episode_id', right_on='id')\n\n# Clean\ndf_characters_search = df_characters_search.sort_values(by='original_air_date').drop('id', axis=1)\n\n# Preview result\ndf_characters_search",
          "Creating dataframes with the primary data types.\ndf_script = df_script[['episode_id', 'number', 'raw_text', 'speaking_line', 'character_id', 'location_id']]\ndf_episodes = df_episodes[['id', 'title', 'original_air_date']]",
          "Extract character lines and cast them to lowercase\nlines = df_script[df_script['character_id'].notnull()]['normalized_text'].str.lower()",
          "Extract the id, name, and normalized_name columns\ndf_characters[['id', 'name', 'normalized_name']].head()",
          "Creating a list of stopwords that we do not want to include in the analysis, as they do not provide valuable information.",
          "Join the dataset on the character and location with our script data into one dataframe to contain the MEAN sentiment for each sentence.",
          " optional: transform data into a more usable form)",
          "Check the content of the script lines dataframe and clean it",
          "Let's check if everything is okay",
          "Check the version of pandas being used",
          "Remove duplicate and na values from episode dataset.",
          " If there is a character NLP root name that is a stopword\n# (e.g. 'arnold' is stopped by 'arn'), and we would like to search for it,\n# we should search for \" arn\" instead of \"arn .\", if we want to find\n# occurrences at the beginning of the sentence.",
          " Set the index of each dataframe with the 'id' column for faster query and access",
          " Replace NaN values with empty strings\ndf_characters = df_characters.fillna('')\ndf_locations = df_locations.fillna('')\ndf_script = df_script.fillna('')\ndf_episodes = df_episodes.fillna('')",
          "Hide irrelevant warnings\nimport warnings\nwarnings.filterwarnings('ignore', category=FutureWarning)\nwarnings.filterwarnings('ignore', category=DeprecationWarning)",
          "Text cleaning\n# Remove unused information\ndf_script = df_script.drop(['id','episode_id', 'number'], axis=1)\n\n# Drop lines with missing values\ndf_script = df_script.dropna()\n\n# Remove content in square brackets (often these are directions for the actor)\ndf_script = df_script.replace('\\[.*?\\]', '', regex=True)\n\n# Special case (it's indeed lines that starts with space)\ndf_script['raw_character_text'] = df_script['raw_character_text'].replace('^[ \\t]+', '', regex=True)\n\n# Special case (the character speaking is not always present)\ndf_script.loc[df_script['raw_character_text'].str.len() > 50, 'raw_character_text'] = np.nan\n\n# Drop lines with missing values again\ndf_script = df_script.dropna()",
          "Question 1: What are the most common words used by each character?",
          "To check the contents of the datasets, I can take a look at the first few rows of each DataFrame.",
          "# Number of unique characters\nlen(df_characters['raw_character_text'].unique())",
          "Convert column to Categories for Locations and Characters\ndf_script['raw_location'] = df_script['raw_location'].astype('category')\ndf_script['raw_character_text'] = df_script['raw_character_text'].astype('category')",
          "Clean the script by deleting rows with no character specified or no dialogues.",
          "Remove null characters from script data\ndf_script.dropna(subset = [\"normalized_text\"], inplace=True)",
          "Selecting only the dialogues from the script data\ndf_script = df_script[pd.notnull(df_script['raw_text'])]\n\ndf_script = df_script[['episode_id', 'raw_text']]\n\ndf_script.head(10)",
          "\n# Create a mapping between character name -> character_id\nchar_map = {row.character_name: row.character_id for row in df_characters.itertuples()}",
          "# to ensure compatibility of pandas with spacy\nimport warnings\nwarnings.filterwarnings(\"ignore\", category=FutureWarning)",
          "The columns used for the relationship between the different datasets are:\n# df_script -> speaking_line, character_id, location_id, episode_id\n# df_characters -> id, name\n# df_locations -> id, name\n# df_episodes -> id, title",
          " Join episodes dataframe to the script dataframe",
          "Define some constants to make the code more understandable and easier to change",
          " Data Preprocessing",
          "# Convert time stamps to datetime objects\ndf_script['timestamp_in_ms'] = pd.to_datetime(df_script['timestamp_in_ms'], unit='ms')\n\n# Selecting only relevant columns from the script dataframe\ndf_script = df_script[['raw_text', 'speaking_line', 'character_id', 'location_id', 'episode_id', 'timestamp_in_ms']]\n\ndf_script.head()",
          "Check character names for spelling errors\ndf_characters['raw_character_text'] = df_characters['raw_character_text'].str.lower()\ndf_characters['raw_character_text'].nunique(), df_characters['raw_character_text'].unique()",
          "Set timestamps to be datetime objects",
          " Since the input seems to be a continuation of the code, I will provide the next steps.",
          "Remove NaN values from the dataframes\ndf_characters = df_characters.dropna()\ndf_locations = df_locations.dropna()\ndf_script = df_script.dropna()\ndf_episodes = df_episodes.dropna()",
          "Clean the script dataframe\n# Remove leading/trailing whitespaces\ndf_script = df_script.apply(lambda x: x.str.strip() if x.dtype == \"object\" else x)",
          " I will add more code here...",
          "Filter NaN values for talking_text\ndf_script = df_script.dropna(subset=['talking_text'])",
          "Encode character names as integers\ndef encode_char(string):\n    try:\n        return char2int[string]\n    except:\n        return -1",
          "Remove unnecessary columns and data from the script dataframe\ndf_script = df_script.drop(columns=['id', 'number', 'raw_text', 'timestamp_in_ms'])\ndf_script = df_script.dropna()",
          "Filter only the script lines\ndf_script_lines = df_script[['id', 'episode_id', 'number', 'raw_text', 'timestamp_in_ms', 'speaking_line', 'character_id', 'location_id', 'raw_character_text', 'raw_location_text']]",
          " We'll replace NaN values with empty strings\ndf_script = df_script.fillna('')\n\n# Also replace NaN objects with 0 for simpler numeric processing in the future\ndf_episodes = df_episodes.fillna(0)",
          "Check data date ranges",
          " Text cleaning and preprocessing",
          "...and so on",
          " Let's see the first three columns of each table.",
          "# Merge script lines with episodes data to get season and episode information\ndf_script = pd.merge(df_script, df_episodes, on='episode_id')",
          "Create a subset of characters' lines\ndf_main_characters = df_characters[df_characters['name'].isin(['Marge Simpson', 'Lisa Simpson', 'Bart Simpson', 'Homer Simpson', 'Maggie Simpson'])]\ndf_main_characters.reset_index(inplace=True, drop=True)\n\n# Join the characters' lines with the script lines to obtain the text\ndf_main_characters_lines = pd.merge(df_script, df_main_characters, left_on='character_id', right_on='character_id', how='inner')",
          "Visualizing the most frequent words in script lines",
          "Most used characters\nmost_used_characters = df_script['character_id'].value_counts().index.tolist()\nmost_used_characters_counts = df_script['character_id'].value_counts().tolist()",
          "Remove some un-necessary columns\ndf_script = df_script.drop(df_script.columns[[0, 2, 3, 4, 7, 8, 9, 10, 11, 12, 13]], axis=1)",
          "Create a dictionary to map character ids to character names\ncharacter_name_mapper = dict(zip(df_characters['id'], df_characters['name']))",
          "Remove rows in the script dataframe with empty and non-ASCII lines",
          "Remove the columns we won't be using\ndf_script = df_script.drop(columns=['id', 'episode_id', 'number', 'raw_text', 'timestamp_in_ms', 'speaking_line', 'character_id'])",
          "Extract all lines of dialogues and their respective episode\ndf_dialogues = df_script[['episode_id', 'raw_text']]",
          " Drop rows with missing values in the columns of interest\ndf_script = df_script.dropna(subset=['normalized_text'])",
          "# Removing columns for practicality\ndf_script = df_script[['episode_id', 'number', 'raw_text']]",
          "Parsing date columns",
          "...",
          "Perform any necessary data preprocessing\n",
          "Dropping skippable columns to preserve memory\ndf_script.drop(columns=['number', 'raw_text', 'timestamp_in_ms', 'speaking_line', 'character_image_url', 'location_id', 'spoken_words', 'normalized_text'], inplace=True)",
          " Let's see what each dataframe looks like",
          "Dropping irrelevant columns from dataframe\ndf_script = df_script.drop(columns=['raw_text', 'timestamp_in_ms', 'speaking_line', 'character_id'])",
          "Extract words from script lines\nscript_lines = df_script['normalized_text'].dropna().values.tolist()",
          "Inspecting the first 5 entries.",
          "Drop rows (records) with missing values from the 'episode_id' and 'name' columns in the script data\ndf_script = df_script.dropna(subset=['episode_id', 'name'])",
          "Convert timestamp_in and timestamp_out fields into datetime type",
          " We will start by cleaning the dataset.",
          "Check for duplicates in 'id' column in all dataframes",
          "extract the dialog lines\ndf_lines = df_script[df_script[\"speaking_line\"]]\ndf_lines = df_lines.merge(df_episodes, left_on=\"episode_id\", right_on=\"id\")\ndf_lines = df_lines.sort_values([\"id_x\", \"timestamp_in_ms\"])",
          "Select main character\nmain_character = \"Marge Simpson\"",
          "Create script for a specific episode\n\tscript_s10e11 = df_script[df_script['episode_id'] == 211].copy()\n\tscript_s10e11.sort_values('timestamp_in_ms', inplace=True)\n\tscript_s10e11.reset_index(drop=True, inplace=True)",
          "Creating two lists from the script dataframe\nscene_texts = list(df_script.str.values)\nscene_locations = list(df_script.raw_location_text.values)",
          "Checking and printing a top of each dataframe",
          "Select character lines said by Homer\ndf_homer = df_script[df_script[\"character_id\"] == df_characters[df_characters[\"name\"] == \"homer_simpson\"].iloc[0][\"id\"]]",
          "Characters grouped by gender\ndf_characters['gender'].value_counts().plot(kind='bar')\nplt.title('Number of Characters by Gender')",
          "import warnings\nwarnings.filterwarnings(\"ignore\")",
          " Add the colon character at the end of the previous line as it appears we are defining a block of code.",
          "Create dictionaries with the index as the key and the row as the value for each dataframe",
          "convert episode air dates to datetime\ndf_episodes['air_date'] = pd.to_datetime(df_episodes['air_date'])",
          "List of all conversation lines",
          "Checking the first few records for values and counts",
          "NLP model, only keep rows with some non-null values\nnlp = spacy.load('en_core_web_sm')\n\ndf_script = df_script.dropna(subset=['raw_text']).reset_index(inplace=False, drop=True)",
          "2c. Convert date and time columns to datetime objects",
          "Check number of rows in each dataframe",
          " Drop lines where \"character_id\" and \"location_id\" is NaN\ndf_script.dropna(subset=['character_id', 'location_id'], inplace=True)",
          " The show started on December 17, 1989, and so we have data only from 1989 onward.",
          " Format date\ndf_episodes['original_air_date'] = pd.to_datetime(df_episodes['original_air_date'])",
          "Remove additional index column from the datasets\ndf_characters.drop(df_characters.columns[0], axis=1, inplace=True)\ndf_locations.drop(df_locations.columns[0], axis=1, inplace=True)\ndf_script.drop(df_script.columns[0], axis=1, inplace=True)\ndf_episodes.drop(df_episodes.columns[0], axis=1, inplace=True)",
          "Remove bad script data\ndf_script = df_script.dropna(subset=['normalized_text'])\ndf_script = df_script[df_script['timestamp_in_ms'] != 0]",
          "Extract reviews and movie titles\nreviews = df_script[df_script['raw_text'].str.contains('Moe_Szyslak', case=False)]\n\n# Clean up\n# Handling NA values\nreviews = reviews.dropna(subset=['raw_text'])\n\n# Select only relevant columns\nreviews = reviews[['episode_id', 'timestamp_in_ms', 'raw_text']]\n\n# Replace any instances of Moe Szyslak\nmoe_aliases = ['Moe_Szyslak', 'Moe \"Moe\" Szyslak']\nreviews['raw_text'] = reviews['raw_text'].str.replace('|'.join(moe_aliases), 'moe_szyslak', case=False)",
          " Clean a bit the datasets\ndf_characters = df_characters[['id', 'name', 'normalized_name']].drop_duplicates(subset=['id'])\n\n# Build a list of character's id\ncharacters_id = list(df_characters.id)\n\n# Clean the scripts a bit\ndf_script = df_script.dropna(subset=['character_id', 'raw_text'])\ndf_script = df_script[df_script.character_id.isin(characters_id)]",
          "Create a binary column in characters dataframe and set it to True\n# if character is in script, from vadimkantor github page\ncharacters = df_characters[df_characters['id'].isin(df_script['character_id'])]",
          "Visualizing the number of lines for the top 10 characters\ntop_10_characters = df_script['character_id'].value_counts().head(10)\n\nfig, ax = plt.subplots(figsize=(10,5))\nax.bar(top_10_characters.index, top_10_characters.values)\n\nax.set_xlabel('Character ID')\nax.set_ylabel('Number of lines')\nax.set_title('Number of lines for the top 10 characters')\n\nplt.show()",
          "Check a few of the scene settings - note some variation in capitalisation so will set lower case",
          "The first thing we can do is to take a peek at each of these tables using the head method.",
          " Transform float seasons to int\ndf_episodes['season'] = df_episodes['season'].astype(int)",
          "drop Unnamed: 0 and id with reset_index(inplace=False, drop=True)",
          "Container of unique Table Styles for survival guide.",
          "Filter the data to only include the 4 main characters: Homer, Marge, Bart, Lisa.",
          "Filter out characters and location from the script dataframe that are not in the respective character and location dataframes",
          "Visualize the top-10 characters by frequency in the dataset",
          "Remove 'The Simpsons Movie' because it is acting as a duplicate\ndf_episodes = df_episodes[df_episodes['title'] != 'The Simpsons Movie'].reset_index(inplace=False, drop=True)",
          " Change \"timestamp_in_ms\" and \"timestamp_in_ms\" to datetime\ndf_script['timestamp_in_ms'] = pd.to_datetime(df_script['timestamp_in_ms'], unit='ms')\ndf_script['timestamp_in_ms'] = pd.to_datetime(df_script['timestamp_in_ms'], errors='ignore')",
          "Dropping episodes without a script available\ndf_episodes = df_episodes.dropna(subset=['normalized_text'])",
          " Check sets of character IDs\nset(df_script['character_id'].unique()).intersection(set(df_characters['id'].unique()))",
          "Remove duplicate entries\ndf_characters = df_characters.drop_duplicates(subset=['id']).reset_index(drop=True)\ndf_locations = df_locations.drop_duplicates(subset=['id']).reset_index(drop=True)\ndf_script = df_script.drop_duplicates(subset=['id']).reset_index(drop=True)\ndf_episodes = df_episodes.drop_duplicates(subset=['id']).reset_index(drop=True)",
          "Convert the date column to datetime format\ndf_episodes['date'] = pd.to_datetime(df_episodes['original_air_date'])",
          "fillna for script\ndf_script.fillna('', inplace=True)",
          "# And improve speed by reducing the amount of data we're working on\nmain_characters_list = df_characters[df_characters['normalized_name'].str.contains('simpson')]['id'].to_list()\nmain_characters_list += [1, 2, 9, 8, 2, 155, 3, 206, 7]  # Main characters + 2 characters plus important\n\ndf_script_reduced = df_script[df_script['character_id'].isin(main_characters_list)]",
          "Transform data from strings to categories",
          " Check the content of the first few lines.",
          " Cleaning script file",
          "Create a dictionary to store character lines\nlines_by_characters = {}\n\n# Group script lines by character\nfor index, row in df_script.iterrows():\n    # Retrieving variables from the current line\n    character_id = row['character_id']\n    character_name = df_characters.loc[df_characters['id'] == character_id, 'name'].values[0]\n    line = row['raw_text']\n    \n    # Add character to the dictionary if not present\n    if not character_name in lines_by_characters:\n        lines_by_characters[character_name] = []\n    \n    # Add the line to the character in the dictionary\n    lines_by_characters[character_name].append(line)",
          "Hide warnings for clearer output\nimport warnings\nwarnings.filterwarnings('ignore')",
          " Select only Homer's lines to make the conversation more comprehendible and simplify the pre-processing",
          "Filter the dataframe with not null values for the lines and normalize the text to lowercase",
          "Remove redundancy in the script lines dataframe and filter for the main characters",
          "Let's keep only the essential lines of the script (dialogue) and reset the index.",
          "Bring all necessary pandas libraries to perform the imports correctly",
          "Remove duplicates from script DataFrame\ndf_script = df_script.drop_duplicates(subset=['id']).reset_index(inplace=False, drop=True)",
          "Replace NaN\ndf_script.fillna('', inplace=True)",
          "Data loading and preprocessing",
          "Replace NaN values with empty string\ndf_script = df_script.replace(np.nan, '', regex=True)",
          "Removing minor characters\nmajor_characters = [\n    'marge','homer','bart','lisa','maggie',\n    'moe','carl','lenny','ned','krusty',\n    'chief wiggum','skinner','patty','selma',\n    'abraham','mrburns','milhouse','apu','barney',\n    'sideshow bob','nelson','ralph'\n]\n\ndf_script_major = df_script[df_script['raw_character_text'].str.lower().isin(major_characters)].copy()",
          "Visualize a few example rows of each dataframe to understand the data structure\ndf_characters.head()",
          "Merge episodes and script data\ndf_script_episodes = pd.merge(df_script, df_episodes, on='episode_id', how='left')\n\n# Display the first few items in the merged DataFrame\ndf_script_episodes.head()",
          "Remove duplicate script lines and drop useless columns\ndf_script = df_script.drop_duplicates(subset=['episode_id', 'number_in_episode'])\ndf_script = df_script.drop(columns=['id', 'timestamp_in_ms', 'raw_text', 'spoken_words', 'normalized_text', 'word_count'])",
          "Create a toy dataframe to demonstrate the aggregation possibilities\nd = {\n    'name': ['Homer', 'Bart', 'Flanders', 'Marge', 'Lisa', 'Maggie'],\n    'gender': ['m', 'm', 'm', 'f', 'f', 'f'],  # m: male, f: female\n    'age': [36, 10, 60, 34, 8, 1],\n    'quote': ['D\\'oh!', 'Eat my shorts', 'Hi-dilly-ho, neighborinos', 'Hmm', 'If anyone wants me, I\\'ll be in my room', ' '],\n    'job': ['Nuclear safety inspector', 'Student', 'Owner of the Leftorium', 'Homemaker', 'Student', ' '],\n    'location': ['742 Evergreen Terrace', '742 Evergreen Terrace', '744 Evergreen Terrace', '742 Evergreen Terrace', '742 Evergreen Terrace', '742 Evergreen Terrace']\n}\ndf_toy = pd.DataFrame(data=d)",
          " Remove unwanted fields from df_script dataframe\ndf_script = df_script[['id', 'episode_id', 'number', 'raw_text', 'speaking_line', 'character_id', 'location_id']].copy()",
          "Filter only lines that contain a character\ndf_script = df_script[df_script['raw_character_text'].notna()]\n\n# Let's remove unwanted characters from the script\ndf_script['raw_text'] = df_script['raw_text'].str.replace(\"\\[.*\\]\", \"\").str.replace('\\n', ' ')\n\n# Apply spaCy's NLP to the script's lines. This might take a while...\nnlp = spacy.load(\"en_core_web_sm\")\ndf_script['nlp'] = list(tqdm(nlp.pipe(df_script['raw_text'], disable=[\"parser\"])))",
          "Limit dataset to those lines with characters speaking and are present in episodes dataset\ndf_script = df_script[(df_script.speaking_line == True) &\n                      (df_script.episode_id.isin(df_episodes.index))]",
          "# Remove special characters\ndf_script['normalized_text'] = df_script['normalized_text'].str.replace(r'[^A-Za-z\\s]', '').str.lower()",
          "Now we have successfully loaded the datasets into pandas dataframes.",
          "Remove bad rows from script dataframe",
          "Remove empty lines in the script\ndf_script = df_script.dropna(subset=['normalized_text'])",
          "Prepare data for NLP tasks\ndf = df_script[['normalized_text', 'episode_id','character_id']]\ndf = df.dropna()\ndf.reset_index(drop=True, inplace=True)",
          "Select main character names for filtering later",
          " Walk through the entire dataframe and remove spacing around each cell\nfor column in df_script.columns:\n    df_script[column] = df_script[column].apply(lambda x: x.strip())",
          "Next, we'll analyze the scripts to find the most common words used by each character.",
          null
         ],
         "marker": {
          "color": "#CFD8DC",
          "opacity": 0.5,
          "size": 5
         },
         "mode": "markers+text",
         "name": "other",
         "showlegend": false,
         "type": "scattergl",
         "x": [
          14.784468650817871,
          8.782552719116211,
          16.09589385986328,
          15.399581909179688,
          15.099934577941895,
          16.204769134521484,
          8.165989875793457,
          12.807180404663086,
          10.819150924682617,
          11.906885147094727,
          10.427976608276367,
          12.943852424621582,
          13.964313507080078,
          12.694559097290039,
          15.218306541442871,
          15.22984504699707,
          8.11804485321045,
          14.672380447387695,
          10.443682670593262,
          11.79755687713623,
          15.521859169006348,
          16.309236526489258,
          12.129671096801758,
          14.270599365234375,
          14.487558364868164,
          16.410207748413086,
          8.099252700805664,
          15.604280471801758,
          15.76136302947998,
          11.146031379699707,
          10.73110580444336,
          14.192940711975098,
          15.788545608520508,
          13.833696365356445,
          11.212892532348633,
          15.034764289855957,
          13.768792152404785,
          11.2212553024292,
          14.857532501220703,
          15.990585327148438,
          14.18886947631836,
          14.611000061035156,
          14.848505020141602,
          13.175745010375977,
          11.181014060974121,
          10.329833984375,
          8.761530876159668,
          15.382184982299805,
          15.46304988861084,
          10.537100791931152,
          15.43797779083252,
          14.416647911071777,
          16.311279296875,
          13.075213432312012,
          14.489923477172852,
          14.682424545288086,
          14.027873039245605,
          14.62777328491211,
          13.630001068115234,
          10.59459114074707,
          10.687055587768555,
          14.136072158813477,
          11.668334007263184,
          14.204033851623535,
          14.278491020202637,
          11.37519645690918,
          14.43997859954834,
          13.838968276977539,
          10.438036918640137,
          15.329241752624512,
          15.313207626342773,
          13.150273323059082,
          15.146193504333496,
          16.46379280090332,
          12.092573165893555,
          15.069393157958984,
          11.280926704406738,
          8.299729347229004,
          11.412463188171387,
          15.503483772277832,
          14.290390014648438,
          13.633973121643066,
          9.895004272460938,
          14.246204376220703,
          13.84125804901123,
          12.347296714782715,
          15.191182136535645,
          13.481313705444336,
          14.239947319030762,
          15.165956497192383,
          13.931346893310547,
          14.591638565063477,
          15.644303321838379,
          16.29178237915039,
          11.354665756225586,
          12.583858489990234,
          8.773667335510254,
          14.380669593811035,
          12.633407592773438,
          8.659427642822266,
          12.691252708435059,
          16.07899284362793,
          11.323486328125,
          15.333574295043945,
          14.025957107543945,
          14.41462516784668,
          15.7870512008667,
          15.534926414489746,
          14.205327033996582,
          14.910604476928711,
          15.480599403381348,
          15.756157875061035,
          11.042181968688965,
          11.581169128417969,
          15.686927795410156,
          8.204939842224121,
          13.850236892700195,
          14.725687980651855,
          14.82672119140625,
          12.193662643432617,
          10.664156913757324,
          15.304366111755371,
          14.854305267333984,
          10.601229667663574,
          14.699347496032715,
          15.399669647216797,
          11.137874603271484,
          15.624004364013672,
          14.739594459533691,
          15.716556549072266,
          14.906667709350586,
          14.256844520568848,
          14.618480682373047,
          15.55684757232666,
          10.616578102111816,
          12.741581916809082,
          14.050795555114746,
          14.689787864685059,
          12.963850975036621,
          13.42023754119873,
          10.416640281677246,
          13.444396018981934
         ],
         "y": [
          9.12549877166748,
          7.91491174697876,
          7.883766174316406,
          9.506765365600586,
          7.789941787719727,
          6.96633243560791,
          7.07426643371582,
          7.190088748931885,
          9.175493240356445,
          8.107933044433594,
          8.17011833190918,
          4.1958417892456055,
          8.409939765930176,
          6.634126663208008,
          7.734169960021973,
          9.914955139160156,
          6.774163722991943,
          8.936098098754883,
          2.4401419162750244,
          4.834652423858643,
          6.6818366050720215,
          7.607125759124756,
          8.083905220031738,
          8.674663543701172,
          8.001882553100586,
          7.215194225311279,
          6.713592052459717,
          10.075206756591797,
          9.153422355651855,
          8.017685890197754,
          9.100700378417969,
          9.499570846557617,
          6.874443531036377,
          9.710576057434082,
          8.0972261428833,
          9.639947891235352,
          9.106473922729492,
          7.9670538902282715,
          9.29337215423584,
          6.744905948638916,
          9.058316230773926,
          7.9030351638793945,
          9.852031707763672,
          9.220333099365234,
          8.96219539642334,
          8.6517915725708,
          7.899346351623535,
          8.892067909240723,
          7.261162281036377,
          2.929699420928955,
          6.903212070465088,
          9.09163761138916,
          7.028648376464844,
          8.937597274780273,
          9.019733428955078,
          7.9727702140808105,
          8.796242713928223,
          8.629871368408203,
          9.62517261505127,
          8.74600887298584,
          8.958169937133789,
          8.601425170898438,
          4.554985523223877,
          8.938517570495605,
          8.610694885253906,
          3.1337311267852783,
          8.804198265075684,
          9.793281555175781,
          9.015603065490723,
          7.667154788970947,
          8.311521530151367,
          6.721968173980713,
          8.746688842773438,
          9.335539817810059,
          3.20858097076416,
          7.315923690795898,
          0.912340521812439,
          6.865704536437988,
          7.974765777587891,
          7.735747814178467,
          9.85560417175293,
          7.1608405113220215,
          7.841956615447998,
          8.25556468963623,
          9.799840927124023,
          3.8136677742004395,
          9.34299087524414,
          8.726293563842773,
          9.742441177368164,
          9.210933685302734,
          9.063196182250977,
          8.904255867004395,
          7.3352227210998535,
          7.1138834953308105,
          0.5916918516159058,
          8.022459983825684,
          7.785797595977783,
          9.840388298034668,
          8.684138298034668,
          7.493310928344727,
          6.5843610763549805,
          7.550699710845947,
          0.37022513151168823,
          8.902853012084961,
          9.55221939086914,
          9.117255210876465,
          7.138205528259277,
          8.422290802001953,
          9.715902328491211,
          9.73783016204834,
          7.1269965171813965,
          7.623737812042236,
          8.050836563110352,
          7.97429895401001,
          7.373669624328613,
          6.736695766448975,
          7.047903060913086,
          8.092915534973145,
          7.835375785827637,
          8.01716423034668,
          5.448960781097412,
          7.830342769622803,
          9.88072681427002,
          8.855267524719238,
          9.598041534423828,
          7.216373920440674,
          -0.0050086998380720615,
          8.847918510437012,
          8.797457695007324,
          8.023109436035156,
          8.736595153808594,
          7.912976264953613,
          7.847292900085449,
          7.474494934082031,
          5.357010841369629,
          9.05893611907959,
          8.72687816619873,
          8.97971248626709,
          6.747644901275635,
          9.067753791809082,
          2.4444515705108643,
          7.7590651512146
         ]
        },
        {
         "hoverinfo": "text",
         "hovertext": [
          "View the first lines of each dataframe\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()",
          "Check data shape\nprint(f'Characters shape: {df_characters.shape}')\nprint(f'Locations shape: {df_locations.shape}')\nprint(f'Script shape: {df_script.shape}')\nprint(f'Episodes shape: {df_episodes.shape}')",
          "Display the loaded DataFrames\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()",
          " Show head of each DataFrame\nprint('\\nCharacters:')\ndisplay(df_characters.head())\nprint('\\nLocations:')\ndisplay(df_locations.head())\nprint('\\nScript:')\ndisplay(df_script.head())\nprint('\\nEpisodes:')\ndisplay(df_episodes.head())",
          "display(df_characters.head())\ndisplay(df_locations.head())\ndisplay(df_script.head())\ndisplay(df_episodes.head())",
          "Numer of episodes\nn_episodes = df_episodes.shape[0]",
          "Length of DataFrames\nprint('Number of characters:', len(df_characters))\nprint('Number of locations:', len(df_locations))\nprint('Number of script lines:', len(df_script))\nprint('Number of episodes:', len(df_episodes))",
          " Check data shapes\nprint(df_characters.shape)\nprint(df_locations.shape)\nprint(df_script.shape)\nprint(df_episodes.shape)",
          " Set pandas to display all columns when showing DataFrames\npd.set_option('display.max_columns', None)\n\n# Select only the Simpsons-related characters\ndf_characters = df_characters[(df_characters['in_simpsons'] == True) & (df_characters['in_movies'] == False)]\ndf_locations = df_locations[(df_locations['in_simpsons'] == True) & (df_locations['in_movies'] == False)]",
          "Explore the dataframe structure and some samples\nprint(f\"Characters: {len(df_characters):,}\")\nprint(f\"Locations: {len(df_locations):,}\")\nprint(f\"Script lines: {len(df_script):,}\")\nprint(f\"Episodes: {len(df_episodes):,}\")\n\ndf_script.head(5)",
          "Testing if everything is loaded properly\nprint(\"Characters\")\nprint(df_characters.head())\nprint(\"\\nLocations\")\nprint(df_locations.head())\nprint(\"\\nScript\")\nprint(df_script.head())\nprint(\"\\nEpisodes\")\nprint(df_episodes.head())",
          "# Clustering the locations\ndf_location_clusters = pd.read_csv('data/simpsons_location_clusters.csv')\ndf_location_clusters.head()",
          "Display up to 7 rows and all columns of each DataFrame for better visual inspection\nfor df in [df_script, df_characters, df_locations, df_episodes]:\n    display(df.head(7))",
          "Check if the DataFrames were loaded correctly\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()",
          "Displaying imported data frames\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()",
          "Preview the datasets\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()",
          "head() of each of the DataFrames\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()",
          " Data samples\ndf_episodes.head()",
          " Checking dataframe shapes\nprint(\"Characters:\", df_characters.shape)\nprint(\"Locations:\", df_locations.shape)\nprint(\"Script:\", df_script.shape)\nprint(\"Episodes\", df_episodes.shape)",
          " Print the shape of the datasets\nprint(f'The script dataset has {df_script.shape[0]} rows and {df_script.shape[1]} columns')\nprint(f'The characters dataset has {df_characters.shape[0]} rows and {df_characters.shape[1]} columns')\nprint(f'The locations dataset has {df_locations.shape[0]} rows and {df_locations.shape[1]} columns')\nprint(f'The episodes dataset has {df_episodes.shape[0]} rows and {df_episodes.shape[1]} columns')",
          " Display the first 5 rows of each table to understand the structure and relation between them\nprint('Characters table')\nprint(df_characters.head(), '\\n')\nprint('Locations table')\nprint(df_locations.head(), '\\n')\nprint('Episodes table')\nprint(df_episodes.head(), '\\n')\nprint('Script table')\nprint(df_script.head())",
          "Print out the first few records of each table\nprint('Characters')\nprint(df_characters.head())\nprint('Locations')\nprint(df_locations.head())\nprint('Script Lines')\nprint(df_script.head())\nprint('Episodes')\nprint(df_episodes.head())",
          "Look at the content of each DataFrame\nprint('Characters:')\ndisplay(df_characters.head(3))\nprint('Locations:')\ndisplay(df_locations.head(3))\nprint('Script:')\ndisplay(df_script.head(3))\nprint('Episodes:')\ndisplay(df_episodes.head(3))",
          "print(df_characters.head())\nprint(df_locations.head())\nprint(df_script.head())\nprint(df_episodes.head())",
          "Check if the files were loaded correctly\nprint(df_characters.head())\nprint(df_locations.head())\nprint(df_script.head())\nprint(df_episodes.head())",
          "# Display available datasets\nprint(\"Characters\")\nprint(df_characters.head())\nprint(\"\\nLocations\")\nprint(df_locations.head())\nprint(\"\\nScript\")\nprint(df_script.head())\nprint(\"\\nEpisodes\")\nprint(df_episodes.head())",
          "# Let's first display the size and memory usage of the datasets\ndatasets = {\n    'Characters': df_characters,\n    'Locations': df_locations,\n    'Script': df_script,\n    'Episodes': df_episodes\n}\n\nfor name, data in datasets.items():\n    print(f\"{name}: {data.shape} - {data.memory_usage().sum() / 1024**2:.2f} MiB\")",
          "# Windows specific fix for pathing issues\nif os.name == 'nt':\n    df_episodes['image_url'] = df_episodes['image_url'].str.replace('///C', 'C:/')",
          "check first few rows of each table\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()",
          " Check the first few entries of each dataframe to understand their structure and contents\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()",
          "Show dataframes shape\nprint(f\"Characters: {df_characters.shape}\")\nprint(f\"Locations: {df_locations.shape}\")\nprint(f\"Script: {df_script.shape}\")\nprint(f\"Episodes: {df_episodes.shape}\")",
          "Preview the data loaded from the CSVs\nprint(df_characters.head())\nprint(df_locations.head())\nprint(df_script.head())\nprint(df_episodes.head())",
          " Show data sample\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()",
          "Check if the episode's script has been loaded correctly\ndf_script.head()",
          "Check dimensions of the main dataframes\nprint('Dimensions of the characters dataframe:', df_characters.shape)\nprint('Dimensions of the locations dataframe:', df_locations.shape)\nprint('Dimensions of the script dataframe:', df_script.shape)\nprint('Dimensions of the episodes dataframe:', df_episodes.shape)",
          " display all the loaded data\nprint(\"Characters:\")\nprint(df_characters.head())\nprint(\"\\nLocations:\")\nprint(df_locations.head())\nprint(\"\\nScript:\")\nprint(df_script.head())\nprint(\"\\nEpisodes:\")\nprint(df_episodes.head())",
          "Display first 5 rows of each data frame\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()",
          "Display the first 5 rows of each dataframe\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()",
          " Sample the dataset to understand its structure\nprint(\"Character Data\")\nprint(df_characters.head())\nprint(\"Location Data\")\nprint(df_locations.head())\nprint(\"Script Data\")\nprint(df_script.head())\nprint(\"Episode Data\")\nprint(df_episodes.head())",
          "Check the basic information of the datasets\nprint('Characters:')\ndisplay(df_characters.info())\ndisplay(df_characters.head())\nprint('\\n\\nLocations:')\ndisplay(df_locations.info())\ndisplay(df_locations.head())\nprint('\\n\\nScript:')\ndisplay(df_script.info())\ndisplay(df_script.head())\nprint('\\n\\nEpisodes:')\ndisplay(df_episodes.info())\ndisplay(df_episodes.head())",
          "Check first 5 lines of each dataframe\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()",
          " Display the first 5 rows of each Dataframe\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()",
          "Display the dimensions of the dataset\nprint(\"Dimension of Simpsons Characters::\", df_characters.shape)\nprint(\"Dimension of Simpsons Locations::\", df_locations.shape)\nprint(\"Dimension of Simpsons Script::\", df_script.shape)\nprint(\"Dimension of Simpsons Episodes::\", df_episodes.shape)",
          " Display the header of each table to understand its structure\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()",
          "Check that the files have been loaded correctly\nprint(df_characters.head(5))\nprint(df_locations.head(5))\nprint(df_script.head(5))\nprint(df_episodes.head(5))",
          "# Check if everything is loaded correctly\nprint(\"Characters:\")\ndisplay(df_characters.head())\nprint(\"\\nLocations:\")\ndisplay(df_locations.head())\nprint(\"\\nScript:\")\ndisplay(df_script.head())\nprint(\"\\nEpisodes:\")\ndisplay(df_episodes.head())",
          "Print shapes\nprint(df_episodes.shape)\nprint(df_script.shape)",
          "Check first 5 rows of each dataframe\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()",
          " Show the data\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()",
          "Display the first few characters of the dataframes to understand their structure\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()",
          "Check if the data is loaded correctly\nprint('Characters')\ndisplay(df_characters.head())\nprint('Locations')\ndisplay(df_locations.head())\nprint('Script')\ndisplay(df_script.head())\nprint('Episodes')\ndisplay(df_episodes.head())",
          "View the structure of the data in the episodes dataset\ndf_episodes.head()",
          " Display the dataset shapes\nprint(f\"Simpsons characters: {df_characters.shape}\")\nprint(f\"Simpsons locations: {df_locations.shape}\")\nprint(f\"Simpsons script: {df_script.shape}\")\nprint(f\"Simpsons episodes: {df_episodes.shape}\")",
          " Explore first 5 rows of each dataframe\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()",
          "Preview the dataset structures\nprint(\"\\nCharacters sample:\")\nprint(df_characters.head())\nprint(\"\\nLocations sample:\")\nprint(df_locations.head())\nprint(\"\\nScript sample:\")\nprint(df_script.head())\nprint(\"\\nEpisodes sample:\")\nprint(df_episodes.head())",
          "# Display the first few entries for each dataframe\ndisplay(df_characters.head())\ndisplay(df_locations.head())\ndisplay(df_script.head())\ndisplay(df_episodes.head())",
          " Preview the data\nprint(\"Characters\")\ndisplay(df_characters.head())\nprint(\"Locations\")\ndisplay(df_locations.head())\nprint(\"Script\")\ndisplay(df_script.head())\nprint(\"Episodes\")\ndisplay(df_episodes.head())",
          "Display the first few rows of each dataframe\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()",
          "Function to display head of each dataframe\ndef display_head_of_dataframes():\n    display(df_characters.head())\n    display(df_locations.head())\n    display(df_script.head())\n    display(df_episodes.head())",
          "Print the head of each dataframe, to get a better understanding of what kind of data we're dealing with.\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()",
          " Displaying the first few rows of the dataframe\ndf_episodes.head()",
          "# Quick look at the data\nprint(df_characters.info())\nprint(df_locations.info())\nprint(df_script.info())\nprint(df_episodes.info())",
          "Data shapes\nprint(f\"Characters: {df_characters.shape}\")\nprint(f\"Locations: {df_locations.shape}\")\nprint(f\"Script: {df_script.shape}\")\nprint(f\"Episodes: {df_episodes.shape}\")",
          "Examine each dataframe\nprint('Characters data:')\nprint(df_characters.head())\n\nprint('\\nLocations data:')\nprint(df_locations.head())\n\nprint('\\nScript data:')\nprint(df_script.head())\n\nprint('\\nEpisodes data:')\nprint(df_episodes.head())",
          "Explore episodes dataframe",
          " Display the head of the episodes DataFrame\ndf_episodes.head()",
          " Display at least the first couple rows of each dataframe\nprint(\"Characters:\")\ndisplay(df_characters.head())\n\nprint(\"\\nLocations:\")\ndisplay(df_locations.head())\n\nprint(\"\\nScript:\")\ndisplay(df_script.head())\n\nprint(\"\\nEpisodes:\")\ndisplay(df_episodes.head())",
          " Check the shape of each dataframe\nprint(\"Characters:\", df_characters.shape)\nprint(\"Locations:\", df_locations.shape)\nprint(\"Script:\", df_script.shape)\nprint(\"Episodes:\", df_episodes.shape)",
          "Check if the dataframes were properly loaded\nprint(df_characters.head())\nprint(df_locations.head())\nprint(df_script.head())\nprint(df_episodes.head())",
          "View the available dataset\ndf_episodes.head()",
          "Check the dataframes contain the correct data\ndisplay(df_characters.head())\ndisplay(df_locations.head())\ndisplay(df_script.head())\ndisplay(df_episodes.head())",
          "Check out the first 5 rows of each tables\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()",
          "Show head",
          "\nprint(f'Characters: {df_characters.shape[0]}')\nprint(f'Locations: {df_locations.shape[0]}')\nprint(f'Script lines: {df_script.shape[0]}')\nprint(f'Episodes: {df_episodes.shape[0]}')",
          "Display the first few rows of the dataframes to ensure data was loaded correctly\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()",
          "Check the size and type of the dataframes\nprint(\"Characters dataframe has {} rows and {} columns\".format(*df_characters.shape))\nprint(\"Locations dataframe has {} rows and {} columns\".format(*df_locations.shape))\nprint(\"Scripts dataframe has {} rows and {} columns\".format(*df_script.shape))\nprint(\"Episodes dataframe has {} rows and {} columns\".format(*df_episodes.shape))",
          "print('Characters dataset shape: {}'.format(df_characters.shape))\nprint('Locations dataset shape: {}'.format(df_locations.shape))\nprint('Script dataset shape: {}'.format(df_script.shape))\nprint('Episodes dataset shape: {}'.format(df_episodes.shape))",
          " Check the format of each dataframe\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()",
          " Show the head of each dataframe\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()",
          "Quick overview of the episodes dataframe\ndf_episodes.head()",
          " Display the first 5 rows of each dataframe\nprint(\"Characters\")\ndisplay(df_characters.head())\nprint(\"\\nLocations\")\ndisplay(df_locations.head())\nprint(\"\\nScript\")\ndisplay(df_script.head())\nprint(\"\\nEpisodes\")\ndisplay(df_episodes.head())",
          "Print the head of each dataset\nprint(\"Characters:\")\ndisplay(df_characters.head())\nprint(\"Locations:\")\ndisplay(df_locations.head())\nprint(\"Script:\")\ndisplay(df_script.head())\nprint(\"Episodes:\")\ndisplay(df_episodes.head())",
          "Inspect the first rows of each table\nprint(\"Characters\")\ndisplay(df_characters.head())\n\nprint(\"Locations\")\ndisplay(df_locations.head())\n\nprint(\"Script\")\ndisplay(df_script.head())\n\nprint(\"Episodes\")\ndisplay(df_episodes.head())",
          "# Print size of the datasets\nprint(f'Simpson character data has {df_characters.shape[0]} rows and {df_characters.shape[1]} columns')\nprint(f'Simpson location data has {df_locations.shape[0]} rows and {df_locations.shape[1]} columns')\nprint(f'Simpson script data has {df_script.shape[0]} rows and {df_script.shape[1]} columns')\nprint(f'Simpson episode data has {df_episodes.shape[0]} rows and {df_episodes.shape[1]} columns')",
          "\ndf_episodes.head()",
          "df_episodes.head()",
          "Check the number of rows in each dataframe\nlen(df_characters), len(df_locations), len(df_script), len(df_episodes)",
          " Check data\nprint(f'Characters:')\ndisplay(df_characters.head())\n\nprint(f'\\n\\nLocations:')\ndisplay(df_locations.head())\n\nprint(f'\\n\\nScript:')\ndisplay(df_script.head())\n\nprint(f'\\nEpisodes:')\ndisplay(df_episodes.head())",
          "Let's print first few records to understand the structure of the datasets\nprint(df_characters.head(5))\nprint(df_locations.head(5))\nprint(df_script.head(5))\nprint(df_episodes.head(5))",
          "Display the first 5 rows of each dataframe to understand their structure and content\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()",
          "# Print top characters, locations, scripts and episodes\nprint(df_characters.head())\nprint(df_locations.head())\nprint(df_script.head())\nprint(df_episodes.head())",
          "Display the first rows of each dataframe to understand their structure\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()",
          "A quick overview of the data.\nprint('Script has shape', df_script.shape)\nprint('Characters has shape', df_characters.shape)\nprint('Locations has shape', df_locations.shape)\nprint('Episodes has shape', df_episodes.shape)\ndf_script.head()",
          "Print first 5 records of each dataframe\nfor df, name in zip([df_characters, df_locations, df_script, df_episodes], \n                    ['Characters', 'Locations', 'Script', 'Episodes']):\n    print(f'===== {name} =====')\n    display(df.head())\n    print('\\n\\n')",
          "Check the structure of each dataframe\nprint('Characters:')\nprint(df_characters.info())\nprint('Locations:')\nprint(df_locations.info())\nprint('Script:')\nprint(df_script.info())\nprint('Episodes:')\nprint(df_episodes.info())",
          "Show just the head of the DataFrames to understand their structure\nprint(df_characters.head())\nprint(df_locations.head())\nprint(df_script.head())",
          "show first five rows of each dataframe\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()",
          "Check the dataset details\ndf_characters.info()\ndf_locations.info()\ndf_script.info()\ndf_episodes.info()",
          "Check if the CSV data was imported successfully\nprint(df_characters.head())\nprint(df_locations.head())\nprint(df_script.head())\nprint(df_episodes.head())",
          "Check the result of the import\ndisplay(df_characters.head(10))\ndisplay(df_locations.head(10))\ndisplay(df_script.head(10))\ndisplay(df_episodes.head(10))",
          "Check if the data has been loaded correctly\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()",
          "Inspect the data sizes\nprint(df_characters.shape)\nprint(df_locations.shape)\nprint(df_script.shape)\nprint(df_episodes.shape)",
          "Quick overview\ndf_episodes.head()",
          "Display top 5 rows of each dataframe\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()",
          " check the number of characters, locations, and episode counts\nlen(df_characters), len(df_locations), len(df_episodes)",
          "Look at the size of these datasets\ndf_characters.shape, df_locations.shape, df_script.shape, df_episodes.shape",
          "Show the first 5 episodes available in the dataset\ndf_episodes.head()",
          "Preview each dataset to understand the data before exploration.\nprint(\"The characters data:\")\nprint(df_characters.head())\nprint(\"\\nThe locations data:\")\nprint(df_locations.head())\nprint(\"\\nThe episodes data:\")\nprint(df_episodes.head())\nprint(\"\\nThe script data:\")\nprint(df_script.head())",
          " Display available dataframes\nprint(\"Characters:\\t\", \",\".join(df_characters.columns))\nprint(\"Locations:\\t\", \",\".join(df_locations.columns))\nprint(\"Script:\\t\\t\", \",\".join(df_script.columns))\nprint(\"Episodes:\\t\", \",\".join(df_episodes.columns))",
          "Visualize dataframe sizes\nprint('Number of rows (characters, locations, script, episodes):', len(df_characters), len(df_locations), len(df_script), len(df_episodes))",
          "numbers of characters and locations\nn_characters = len(df_characters)\nn_locations = len(df_locations)\n\nn_episodes = len(df_episodes)",
          " Simple exploration\nprint(\n    df_script.shape,\n    df_characters.shape,\n    df_locations.shape,\n    df_episodes.shape\n)",
          " Show first few rows of each data table\ndisplay(df_characters.head())\ndisplay(df_locations.head())\ndisplay(df_script.head())\ndisplay(df_episodes.head())",
          "Check the first few lines of each dataframe to understand its structure\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()",
          "Print all the avialable datasets to examine their contents\nprint(\"Characters dataset columns: \", df_characters.columns)\nprint(\"Locations dataset columns: \", df_locations.columns)\nprint(\"Script dataset columns: \", df_script.columns)\nprint(\"Episodes dataset columns: \", df_episodes.columns)",
          "# Display the 'Head' of each dataframe to get an understanding of the data\nprint('Characters:')\nprint(df_characters.head())\nprint('Locations:')\nprint(df_locations.head())\nprint('Script:')\nprint(df_script.head())\nprint('Episodes:')\nprint(df_episodes.head())",
          " Ensure all dfs have the same id index as the script df\ndf_characters.index += 1\ndf_locations.index += 1\ndf_episodes.index += 1",
          "  ensure the data is correctly loaded\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()",
          " Helper function to sample a dataframe\ndef sample_dataframe(dataframe, n_samples=10):\n    return dataframe.loc[np.random.choice(dataframe.index, n_samples, replace=False)]\n\n# Sample the dataframes to speed up the analysis\ndf_characters_sample = sample_dataframe(df_characters, n_samples=50)\ndf_locations_sample = sample_dataframe(df_locations, n_samples=50)\ndf_script_sample = sample_dataframe(df_script, n_samples=500)\ndf_episodes_sample = sample_dataframe(df_episodes, n_samples=50)"
         ],
         "marker": {
          "opacity": 0.5,
          "size": 5
         },
         "mode": "markers+text",
         "name": "0_Dataset Sizes and Overview",
         "text": [
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          ""
         ],
         "textfont": {
          "size": 12
         },
         "type": "scattergl",
         "x": [
          17.377727508544922,
          15.086906433105469,
          16.31785774230957,
          16.61544418334961,
          16.52655029296875,
          15.025997161865234,
          15.289141654968262,
          15.236114501953125,
          15.546845436096191,
          15.606626510620117,
          16.562597274780273,
          15.739114761352539,
          17.524860382080078,
          16.508373260498047,
          16.40475845336914,
          16.166440963745117,
          16.40719223022461,
          15.319375038146973,
          15.278483390808105,
          15.319783210754395,
          17.295032501220703,
          17.420352935791016,
          16.113447189331055,
          16.311344146728516,
          16.42519187927246,
          16.321557998657227,
          15.190479278564453,
          15.892136573791504,
          17.311843872070312,
          16.669424057006836,
          15.082345008850098,
          16.271196365356445,
          16.186506271362305,
          16.47538185119629,
          15.433207511901855,
          16.475482940673828,
          17.804874420166016,
          17.869205474853516,
          15.955193519592285,
          16.3259220123291,
          17.47512435913086,
          17.889394760131836,
          15.2953462600708,
          17.1317138671875,
          16.37004852294922,
          16.677661895751953,
          15.18619155883789,
          17.807369232177734,
          16.213504791259766,
          17.28533172607422,
          16.519840240478516,
          15.490175247192383,
          15.064830780029297,
          17.712331771850586,
          16.198463439941406,
          17.408645629882812,
          16.41997528076172,
          17.65494728088379,
          16.38523292541504,
          16.262741088867188,
          17.471004486083984,
          15.961864471435547,
          15.022237777709961,
          16.23359489440918,
          15.334879875183105,
          15.960347175598145,
          17.252126693725586,
          15.443110466003418,
          16.435340881347656,
          15.66950798034668,
          16.378774642944336,
          17.27916145324707,
          13.702753067016602,
          15.037110328674316,
          17.487388610839844,
          15.391528129577637,
          15.035622596740723,
          16.4836368560791,
          16.196840286254883,
          15.450825691223145,
          17.584362030029297,
          16.28955078125,
          17.15142250061035,
          15.343735694885254,
          15.346795082092285,
          15.332632064819336,
          15.486485481262207,
          16.51300621032715,
          15.887081146240234,
          17.822853088378906,
          16.313217163085938,
          17.561323165893555,
          15.391858100891113,
          17.55023765563965,
          15.739559173583984,
          16.280807495117188,
          17.913259506225586,
          15.792362213134766,
          16.432247161865234,
          16.483572006225586,
          16.378061294555664,
          15.243059158325195,
          15.320072174072266,
          18.018051147460938,
          15.2893648147583,
          15.286802291870117,
          17.268953323364258,
          16.06327247619629,
          16.018590927124023,
          15.391188621520996,
          15.166887283325195,
          15.508720397949219,
          17.521833419799805,
          16.52754783630371,
          15.825366020202637,
          15.998976707458496,
          16.2790470123291,
          16.21781349182129,
          16.742164611816406
         ],
         "y": [
          11.333765983581543,
          13.137431144714355,
          11.377662658691406,
          11.868080139160156,
          11.737360954284668,
          10.909684181213379,
          11.673704147338867,
          12.879271507263184,
          12.258749008178711,
          11.80517578125,
          12.32323169708252,
          11.783936500549316,
          11.941022872924805,
          10.522112846374512,
          11.33003044128418,
          11.483648300170898,
          11.310101509094238,
          10.91637897491455,
          13.07032299041748,
          12.893014907836914,
          12.119505882263184,
          11.967093467712402,
          12.073420524597168,
          11.72447395324707,
          10.613094329833984,
          12.283148765563965,
          12.690217971801758,
          10.035667419433594,
          11.675030708312988,
          11.04008960723877,
          13.123796463012695,
          11.778186798095703,
          11.244565963745117,
          10.283966064453125,
          12.711725234985352,
          12.428366661071777,
          11.554862976074219,
          11.491195678710938,
          11.889959335327148,
          12.238911628723145,
          11.473331451416016,
          11.479808807373047,
          12.727643966674805,
          11.978859901428223,
          10.517688751220703,
          12.393260955810547,
          13.0039701461792,
          11.67291259765625,
          11.381641387939453,
          11.3505220413208,
          11.796788215637207,
          10.86263370513916,
          12.979849815368652,
          11.459999084472656,
          12.237537384033203,
          11.858717918395996,
          12.010214805603027,
          11.55324649810791,
          11.465811729431152,
          11.357661247253418,
          11.164984703063965,
          12.105247497558594,
          13.187952995300293,
          12.273768424987793,
          10.41978931427002,
          11.112537384033203,
          11.929625511169434,
          12.707181930541992,
          10.73262882232666,
          10.93581485748291,
          10.640356063842773,
          11.781475067138672,
          3.2274880409240723,
          13.25235652923584,
          11.521562576293945,
          12.7564115524292,
          13.049433708190918,
          10.9479398727417,
          11.218598365783691,
          10.823150634765625,
          11.95846939086914,
          12.128067016601562,
          12.101280212402344,
          12.638044357299805,
          10.947443962097168,
          10.913844108581543,
          11.742565155029297,
          12.200190544128418,
          11.68543529510498,
          11.536370277404785,
          11.675980567932129,
          11.462889671325684,
          12.833746910095215,
          11.859723091125488,
          12.213608741760254,
          11.434480667114258,
          11.335416793823242,
          11.902182579040527,
          10.699322700500488,
          11.075810432434082,
          10.502963066101074,
          12.631115913391113,
          10.901300430297852,
          11.36428451538086,
          11.505955696105957,
          12.333191871643066,
          11.13744068145752,
          12.245521545410156,
          12.14710807800293,
          11.908477783203125,
          11.422797203063965,
          12.800191879272461,
          11.883668899536133,
          11.199813842773438,
          12.368732452392578,
          11.925219535827637,
          10.369476318359375,
          10.389659881591797,
          10.041805267333984
         ]
        },
        {
         "hoverinfo": "text",
         "hovertext": [
          "View the first few rows of the characters dataframe\ndf_characters.head()",
          "Checking the first few rows of the characters data frame to understand its structure\ndf_characters.head()",
          "Inspect and display few rows of characters dataframe\ndf_characters.head()",
          " Quick overview of the characters dataset\ndf_characters.info()",
          " Check the dataframes to ensure they were loaded correctly\ndf_characters.head()",
          "df_characters.info()",
          "Inspect the character dataset\ndf_characters.head()",
          "Check the first few rows of the characters DataFrame\ndf_characters.head()",
          "# Glimpse of the characters dataframe\ndf_characters.head()",
          "Check loaded data\ndf_characters.head()",
          "Inspect the first few rows of the characters dataframe\ndf_characters.head()",
          "Inspect the first 2 rows of df_characters\ndf_characters.head(2)",
          "Checking the head of the characters dataframe",
          "Explore the character dataset\ndf_characters.head()",
          "Check the first few rows of `df_characters`\ndf_characters.head()",
          "Check the content of the data sets\ndf_characters.head()",
          "Inspect dataset using head()\ndf_characters.head(10)",
          "View characters dataframe\ndf_characters.head()",
          "Verify if the index has been reinitialized.\ndf_characters.head()",
          "Check data has been read correctly\ndf_characters.head()",
          "Check if the index has been reset\nprint(df_characters.head())",
          "Inspect the first few rows of the characters DataFrame\ndf_characters.head()",
          "check the head of the Characters data\ndf_characters.head()",
          "Inspecting the first few entries of the characters data frame.",
          "Inspect df_characters",
          "Preview the dataframes\ndf_characters.head(2)",
          "Look at the first couple of rows of the characters dataframe\ndf_characters.head()",
          " Explore characters dataframe",
          "Check the structure of the characters dataset\ndf_characters.head()",
          " Quick look at the characters dataset.\ndf_characters.head()",
          "Check that the data has been properly loaded\ndf_characters.head()",
          " Explore the data structure of df_characters\ndf_characters.head()",
          "# Read the first ten lines of each data frame to understand its structure\ndf_characters.head(10)",
          "View the first few rows of the characters dataframe\ndf_characters.head()",
          "Look at first few rows of each dataset\ndf_characters.head()",
          "Check the first few lines of the characters dataframe\ndf_characters.head()",
          " Check first 2 rows of df_characters dataframe\ndf_characters.head(2)",
          "Check the first 5 rows of the characters dataframe.",
          "Inspect & clean the characters dataframe",
          "Check the first few rows of the characters dataframe\ndf_characters.head()",
          " Check example dataframe\ndf_characters.head()",
          " View the first few rows of the characters dataframe\ndf_characters.head()",
          "Preview the characters DataFrame\ndf_characters.head()",
          "Initial look at characters data",
          " Check if the data was loaded correctly\ndf_characters.head()",
          "Display basic information about the characters dataset\ndf_characters.info()",
          "Inspect the characters dataset",
          "Inspect dataframe contents\ndf_characters.head()",
          " Explore the first dataframe (characters)",
          "Check out the first few rows of df_characters\ndf_characters.head()",
          " Check the first 5 rows of the characters dataframe",
          "Inspect the first few rows of the characters dataframe\ndf_characters.head()",
          "Check the first few rows of the characters dataframe",
          "Quick look to the df_characters dataframe",
          "Character level EDA",
          "Check the freshly imported data\ndf_characters.head()",
          "Inspect the contents of the character dataframe",
          "Check the top few rows of each dataframe\ndf_characters.head()",
          "Data at a glance\nprint(df_characters.info())",
          "Preview the dataframes\ndf_characters.head()",
          "Check data structure\ndf_characters.head()",
          "Checking the first few rows of the characters dataframe\ndf_characters.head()",
          "Have a look at the first couple of rows of the characters dataframe - the head - and the number of records - the shape.",
          "# Let's see what's inside the characters dataframe\ndf_characters.head()",
          "Check one of the tables to make sure the import worked correctly\ndf_characters.head()",
          " Explore first rows of characters dataframe\ndf_characters.head()",
          "Display and check the informations on the characters data.",
          "View the characters dataframe\ndf_characters.head()",
          "Check that the data is read in correctly\ndf_characters.head()",
          " Look at the character's dataset\nprint(\"Characters dataset\")\nprint(df_characters.head())",
          "Load the Word Embeddings model that will be used to infer the similarity between characters.",
          "Check to see what they look like\nprint(df_characters.head())",
          "Examine the contents of the characters dataframe\ndf_characters.head()",
          "Check the imported DataFrames\ndf_characters.head()",
          "Preview the character data\ndf_characters.head()",
          "View the characters dataframe\ndf_characters.head()",
          " Explore a few info about characters DataFrame\ndf_characters.info()",
          " We show the head of each dataframe to understand how they are organized\nprint(df_characters.head())",
          "Check the first few lines of the characters DataFrame\ndf_characters.head()",
          "Check the dataframes\ndf_characters.head(5)",
          "Set the length of the context by considering the first three characters.",
          "Inspect the structure of the characters DataFrame",
          "Show the tiles of the characters data\ndf_characters.head()",
          "Inspect the first few rows of the characters dataframe\ndf_characters.head()",
          "Check columns in characters data frame\ndf_characters.columns",
          "Preview the characters data\ndf_characters.head()",
          "Check and display the headers for the df_characters dataframe\ndf_characters.head()",
          "df_characters.head()",
          "check the first 5 rows of df_characters\ndf_characters.head()",
          "Inspect the first few rows of the characters DataFrame\ndf_characters.head()",
          "Preview the characters data\ndf_characters.head()",
          " Checking the first few rows of the characters dataframe.",
          "Checking the content of the characters dataset\ndf_characters.head()",
          "linking charcters is important. Characters to character interactions are the backbone of a story.",
          " Dataframes exploration\ndf_characters.head()",
          "Preview the data\ndf_characters.head()",
          "Quick exploration of the characters table",
          " View the first rows of the characters dataframe\ndf_characters.head()",
          "Display head of characters Dataframe\ndf_characters.head()"
         ],
         "marker": {
          "opacity": 0.5,
          "size": 5
         },
         "mode": "markers+text",
         "name": "1_Previewing First Few Rows of DataFrame",
         "text": [
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          ""
         ],
         "textfont": {
          "size": 12
         },
         "type": "scattergl",
         "x": [
          10.906805038452148,
          10.298500061035156,
          10.84740924835205,
          10.053507804870605,
          9.330979347229004,
          10.01414680480957,
          10.018148422241211,
          10.07076644897461,
          10.75423526763916,
          9.46955394744873,
          10.812734603881836,
          10.600794792175293,
          10.314166069030762,
          10.09835433959961,
          9.947097778320312,
          9.662261009216309,
          10.131818771362305,
          10.938398361206055,
          9.57362174987793,
          9.395122528076172,
          9.55156421661377,
          10.863271713256836,
          9.767915725708008,
          10.383814811706543,
          9.86141586303711,
          12.189397811889648,
          10.631999969482422,
          10.532614707946777,
          9.892821311950684,
          10.12901782989502,
          9.342415809631348,
          10.329094886779785,
          10.379608154296875,
          10.9246826171875,
          10.208577156066895,
          10.034594535827637,
          10.187536239624023,
          9.588163375854492,
          10.7279052734375,
          10.066737174987793,
          10.34121322631836,
          10.904585838317871,
          12.21740436553955,
          10.24854564666748,
          9.317736625671387,
          10.030613899230957,
          10.15880298614502,
          10.614246368408203,
          10.761767387390137,
          10.248998641967773,
          9.458725929260254,
          10.722128868103027,
          9.789027214050293,
          10.255160331726074,
          10.16778564453125,
          9.452027320861816,
          10.514265060424805,
          10.149023056030273,
          10.083970069885254,
          12.244450569152832,
          9.73715877532959,
          10.158923149108887,
          10.649687767028809,
          10.71051025390625,
          9.318760871887207,
          10.958927154541016,
          10.169265747070312,
          10.70258617401123,
          9.285674095153809,
          10.101621627807617,
          10.246498107910156,
          9.95781135559082,
          10.583662033081055,
          9.76980972290039,
          12.356485366821289,
          10.736207962036133,
          10.232008934020996,
          10.809560775756836,
          10.063904762268066,
          10.07200813293457,
          10.428949356079102,
          10.413519859313965,
          10.250232696533203,
          10.754508972167969,
          9.911996841430664,
          12.278657913208008,
          10.364126205444336,
          10.209896087646484,
          9.677862167358398,
          10.927855491638184,
          12.363964080810547,
          9.823010444641113,
          9.804065704345703,
          10.284467697143555,
          10.920541763305664,
          12.306865692138672,
          10.214680671691895,
          11.106449127197266,
          10.873661994934082
         ],
         "y": [
          -2.0415549278259277,
          -1.5119966268539429,
          -1.743979573249817,
          1.1178797483444214,
          -0.3005310297012329,
          0.8706690669059753,
          0.3507770895957947,
          -1.7390201091766357,
          -0.6320407390594482,
          0.03182829171419144,
          -1.8074666261672974,
          -1.6068274974822998,
          -0.9667585492134094,
          0.3293488919734955,
          -1.6992751359939575,
          0.01595251075923443,
          0.050660524517297745,
          -0.7257080674171448,
          0.08181041479110718,
          -0.055576059967279434,
          -0.09672560542821884,
          -1.8299477100372314,
          -0.06765017658472061,
          1.5346055030822754,
          0.41804277896881104,
          -0.9413186311721802,
          -1.100415825843811,
          0.6990858316421509,
          0.2183549553155899,
          0.3962889313697815,
          -0.07293800264596939,
          0.011303895153105259,
          -0.40570077300071716,
          -2.118569850921631,
          0.08228243142366409,
          -1.4178481101989746,
          -1.7681986093521118,
          -1.883504033088684,
          0.8678761124610901,
          -1.7606993913650513,
          -0.8814893364906311,
          -2.0569140911102295,
          -0.9801498055458069,
          1.6610187292099,
          -0.1531885266304016,
          1.0924828052520752,
          1.6443500518798828,
          -0.5970116257667542,
          -2.651524066925049,
          -0.6681755781173706,
          -1.9545414447784424,
          -1.8682152032852173,
          -2.039022922515869,
          0.7947227954864502,
          1.6152441501617432,
          -0.15227574110031128,
          0.9598850011825562,
          -1.7209420204162598,
          0.9925292730331421,
          -0.9645625352859497,
          0.005435213912278414,
          -1.7735881805419922,
          -0.08825691789388657,
          -0.6150287389755249,
          -0.23093122243881226,
          -2.588543176651001,
          1.7817902565002441,
          -0.7238754034042358,
          -0.13408643007278442,
          0.5201936960220337,
          1.6972781419754028,
          -0.2753037214279175,
          -0.6868392825126648,
          -0.6096779704093933,
          -1.0451074838638306,
          -0.638591468334198,
          0.9187915921211243,
          -0.10293813794851303,
          -1.446140170097351,
          -1.0326422452926636,
          1.940592646598816,
          0.9627524614334106,
          0.14218483865261078,
          -1.810154676437378,
          -1.7185866832733154,
          -0.9242203235626221,
          -1.0012742280960083,
          -0.3318280279636383,
          -1.709166407585144,
          -1.8929524421691895,
          -1.0577893257141113,
          -1.8212435245513916,
          0.0684502124786377,
          1.9780362844467163,
          -0.6348271369934082,
          -0.9829778075218201,
          1.873415470123291,
          -2.7045998573303223,
          -0.6458649039268494
         ]
        },
        {
         "hoverinfo": "text",
         "hovertext": [
          "Check if data looks good\ndf_script.head()",
          " Visualize data\nprint(df_script.head())",
          "Display the first few rows of the dataframe\ndf_script.head()",
          " Print the head of the DataFrame to see the data\nprint(df_script.head())",
          "Performing a simple check on the script dataframe.",
          "\ndf_script.head()",
          "Check the structure of the script dataframe\ndf_script.head()",
          " Quick look at the structure for the Demo\ndf_script.head()",
          "Take a look at what we're working with\ndf_script.head()",
          "Check data load\ndf_script",
          "Inspect dataset structure\ndf_script.head()",
          " Display the first few rows of the dataframe\ndf_script.head()",
          "# Displaying the dataframe\ndf_script.head()",
          "Ensure the data is loaded properly\ndf_script.head()",
          "# Display first few rows of the dataframe\ndf_script.head()",
          "df_script.head()",
          "display 5 random rows of the script dataset\ndf_script.sample(5)",
          "Create a variable to see how many rows the script dataframe has \nrows_script_df, __ = df_script.shape",
          "# Show the first few lines of the dataframe\ndf_script.head()",
          "Check the contents of the lines script dataframe\ndf_script.head()",
          "\n#df_script.head().T",
          "Check the first few rows of the dataset\ndf_script.head()",
          " Optional: Limit the number of rows for quicker processing\n# df_script = df_script[:1000]\n\n# Print the header of the file to ensure it was read correctly",
          "Display first rows of the script DataFrame\ndf_script.head()",
          "Data types\nprint(df_script.dtypes)",
          " Show first 5 rows of the \"df_script\" DataFrame\ndf_script.head()",
          "View the dataframe\ndf_script.head()",
          " Display the data\ndf_script.head()",
          "# Display the first few lines of the table `dataset`\ndf_script.head()",
          "display the data from the script dataframe\ndf_script.head()",
          "\ndf_script.head()",
          "df_script.head()",
          "Check the loaded datasets\ndf_script.head()",
          "Display first 5 rows of df script\ndf_script.head()",
          " Get the columns of the script dataframe.",
          "Display header of df_script\ndf_script.head()",
          "Save the dataframes to disk to avoid in-memory storage limits",
          " Display scripts\ndf_script.head(3)",
          "view data head for every data frame",
          " Display how the dataframe looks like\ndf_script.head()",
          "Check the script data\nprint(df_script.head())",
          "Check and display data head",
          "Check the content of the script DataFrame\ndf_script.head()",
          "Check first few rows of df_script\ndf_script.head()",
          "Quick look at the script data\ndf_script.head()",
          " Let's start by examining the script data\nprint(f\"The dataset has {df_script.shape[0]:,} rows.\")",
          " Display the first few rows of the dataset\ndf_script.head()",
          "Take the first few rows for a look\ndf_script.head()",
          " Check the df_scripts dataframe",
          "df_script.head()",
          " Display rows of script\ndf_script.head()",
          " Look the current iteration of the processed `df_script` DataFrame.",
          " List what's inside of the script DataFrame\ndf_script.head()",
          "Printing the head of the script DataFrame\nprint(df_script.head())",
          "Show the head of the script dataframe\ndf_script.head()",
          "Preview the data\ndf_script.head()",
          " Gets the first 5 rows of the script dataframe",
          "Limit the number of script lines for demonstration (optional)\ndf_script = df_script.head(10000)",
          "Checking the head of each DataFrame",
          "Function to display basic information about a DataFrame\ndef display_info(df, df_name):\n    print(f'{df_name} has {df.shape[0]} rows and {df.shape[1]})')",
          "Examine the dataframe\ndf_script.head()",
          "df_script.head()",
          "Check data with head",
          "Display script data\ndf_script.head()",
          " Check the content of 1 dataframe\ndf_script.head()",
          "Inspect dataframe\nprint(df_script.shape)\ndf_script.head()",
          "Display the first few rows of the script dataframe\ndf_script.head()",
          "Check example lines\ndf_script.head()",
          "Display the first 5 rows of the dataframe\ndf_script.head()",
          "Explore the structure of the dataset\ndf_script.head()",
          "Show the first row of the table to understand its structure\ndf_script.head(1)",
          " Helper function to display the head of each dataframe conveniently\ndef display_head_of_dataframes(dfs):\n    for df_name, df in dfs.items():\n        print(f\"\\033[1m{df_name}\\033[0m\")\n        display(df.head())",
          "Extracting 10,000 random lines from the dataset for analysis to avoid memory errors\ndf_script = df_script.sample(10000, random_state=42)",
          "check the beginning of the script data\nprint(f'Data contains {len(df_script)} lines from {df_script.id[0]} to {df_script.id[len(df_script)-1]}')\ndf_script.head()",
          "print(len(df_script))",
          "Print the head of the table_",
          "Data layout\ndf_script.head()",
          " Take a look at the script data\ndf_script.head()",
          "Sample the data\ndf_script.head()",
          " Print the head of the scripts dataframe to better understand the available fields",
          "View first few records of the dataset\ndf_script.head()"
         ],
         "marker": {
          "opacity": 0.5,
          "size": 5
         },
         "mode": "markers+text",
         "name": "2_Displaying the First Few Rows of a DataFrame in Python",
         "text": [
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          ""
         ],
         "textfont": {
          "size": 12
         },
         "type": "scattergl",
         "x": [
          13.793448448181152,
          14.341707229614258,
          14.012542724609375,
          13.940593719482422,
          13.210954666137695,
          15.513198852539062,
          13.854531288146973,
          15.349525451660156,
          15.4005765914917,
          13.717474937438965,
          14.57663345336914,
          14.043124198913574,
          14.192902565002441,
          15.327699661254883,
          13.994215965270996,
          15.42026424407959,
          13.857723236083984,
          14.037896156311035,
          14.052180290222168,
          13.93393611907959,
          15.540553092956543,
          14.281448364257812,
          14.49577808380127,
          13.942626953125,
          14.497513771057129,
          13.744107246398926,
          14.056682586669922,
          14.465683937072754,
          14.238037109375,
          14.250870704650879,
          15.495523452758789,
          15.50806999206543,
          14.415207862854004,
          13.700243949890137,
          13.751304626464844,
          14.231806755065918,
          14.176777839660645,
          14.928601264953613,
          13.324045181274414,
          14.115792274475098,
          13.897965431213379,
          13.229302406311035,
          13.601009368896484,
          14.24012279510498,
          14.907805442810059,
          14.408727645874023,
          14.105764389038086,
          14.301410675048828,
          13.55380630493164,
          15.328391075134277,
          14.377970695495605,
          13.805009841918945,
          13.964322090148926,
          14.0233154296875,
          13.98482608795166,
          14.682419776916504,
          13.246922492980957,
          14.789992332458496,
          13.117531776428223,
          13.024384498596191,
          13.79809284210205,
          15.460153579711914,
          13.260826110839844,
          14.5680513381958,
          13.556107521057129,
          13.981729507446289,
          13.973004341125488,
          15.346790313720703,
          13.568394660949707,
          14.594454765319824,
          14.41470718383789,
          13.810816764831543,
          14.294548034667969,
          14.230795860290527,
          14.133634567260742,
          14.712462425231934,
          14.976722717285156,
          14.987401008605957,
          15.097602844238281,
          14.0263032913208,
          13.980047225952148
         ],
         "y": [
          3.6170127391815186,
          2.9072954654693604,
          4.841675758361816,
          3.0059196949005127,
          4.3272199630737305,
          3.6259899139404297,
          3.605281114578247,
          3.709290027618408,
          3.679086446762085,
          3.9823780059814453,
          3.808826208114624,
          4.744289875030518,
          2.9833970069885254,
          3.6653411388397217,
          4.631283760070801,
          3.459179401397705,
          4.915759563446045,
          3.919783115386963,
          4.4653401374816895,
          3.590566873550415,
          3.5660059452056885,
          4.144733428955078,
          4.41151237487793,
          4.786281108856201,
          3.624556541442871,
          4.932836532592773,
          3.1102912425994873,
          3.153867483139038,
          4.54583215713501,
          2.9556548595428467,
          3.5944454669952393,
          3.5065155029296875,
          3.819979190826416,
          5.024141788482666,
          3.7207350730895996,
          2.9793379306793213,
          5.0652923583984375,
          3.2773935794830322,
          3.800971031188965,
          2.9134316444396973,
          3.74479341506958,
          3.468050241470337,
          3.6307921409606934,
          4.269384384155273,
          3.6539506912231445,
          3.9924986362457275,
          4.690160274505615,
          4.370387077331543,
          3.966904640197754,
          3.611821413040161,
          3.3583784103393555,
          4.010101318359375,
          3.2084672451019287,
          3.044288396835327,
          2.9789061546325684,
          3.3228800296783447,
          4.627769947052002,
          4.2307305335998535,
          3.5874409675598145,
          2.8216145038604736,
          3.4016833305358887,
          3.6685492992401123,
          3.4678738117218018,
          3.088956356048584,
          3.5622122287750244,
          3.2371275424957275,
          4.7693376541137695,
          3.593299388885498,
          4.883817672729492,
          3.857771158218384,
          4.743668556213379,
          2.8121049404144287,
          4.726227760314941,
          3.703645706176758,
          3.676694869995117,
          5.128032207489014,
          3.219024896621704,
          3.7986185550689697,
          3.6530256271362305,
          3.0750656127929688,
          4.604255199432373
         ]
        },
        {
         "hoverinfo": "text",
         "hovertext": [
          "Check the size of the datasets",
          " Let's take a look at the structure of the datasets.",
          " Let's take a look at the datasets",
          "Let's examine the structure of each dataset.",
          "Checking the structure of the datasets",
          "Let's start by having a quick look at the datasets.",
          "Let's take a look at the structure of each dataset.",
          "Check the record count and the datatypes of each column.",
          " Visualisation functions",
          "Let's take a look at each of the datasets to understand their structure and the type of data they contain.",
          "Let's check the number of records in each dataset.",
          "Exploring the dataset",
          "Until now we have successfully imported the required libraries and datasets.",
          "For a much detailed study of the dataset, we will take a look at all the datasets that we loaded in this section.",
          " Data Exploration",
          " Some initial checks",
          "Create a template for the analysis and quickly explore the data.",
          " Data exploration",
          "Inspect data part 1",
          "Let's begin by taking a look at the data.",
          " Check provided data sets",
          " 1. Exploration",
          "Let's check if these datasets are correctly loaded.",
          "Preview the datasets",
          " Visualizing the raw data",
          "Summary statistics",
          "Let's display the first rows of each dataset to understand its structure.",
          "We load a dataset with sample data.",
          "We need to process the text data to extract insights.",
          "Let's now display the first few lines of each of these datasets.",
          "Visualizing the datasets",
          "Get basic statistics about the dataset",
          " Checking the size of each dataset",
          "utility functions for the project",
          "Lets check the first few rows of each of these datasets to get an idea of what kind of data we are working with.",
          "Check the data to understand its structure",
          "Get the outlines of the datasets",
          "Get the complete dataset head in order to have a better idea of the data structure.",
          "Check the shape of each dataset",
          "Let's inspect the datasets to understand what data we are dealing with.",
          "Visualizing Data to gain insights",
          " Display some basic information about the datasets",
          " We need to process the data first before we start the analysis",
          "Let's take a peek of the datasets",
          "Exploring the data to understand its structure and content.",
          " Data Visualisation",
          "Visualising data",
          "Sample the data to get a better understanding of the content",
          "Some basic exploration",
          "Let's see what we're working with",
          "Check the loaded datasets",
          "Let's take a look at the first few rows of each of these datasets to understand how they are structured.",
          "This is a sample of AI-generated predictions based on the provided code.",
          "Let's start by getting familiar with the content of the datasets.",
          " These functions will come in handy later on.",
          "Let's start by looking at the structure and content of our data.",
          " Check how each dataset looks like",
          "Let us start by taking a look at these datasets."
         ],
         "marker": {
          "opacity": 0.5,
          "size": 5
         },
         "mode": "markers+text",
         "name": "3_Exploring Datasets",
         "text": [
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          ""
         ],
         "textfont": {
          "size": 12
         },
         "type": "scattergl",
         "x": [
          9.535138130187988,
          9.052628517150879,
          9.147045135498047,
          9.079710006713867,
          9.515730857849121,
          9.105988502502441,
          9.02172565460205,
          9.46647834777832,
          9.631279945373535,
          8.947992324829102,
          9.285344123840332,
          9.307822227478027,
          9.863269805908203,
          9.199400901794434,
          9.740303039550781,
          10.596625328063965,
          9.935229301452637,
          9.583464622497559,
          10.109588623046875,
          9.515564918518066,
          9.645777702331543,
          9.778307914733887,
          10.056709289550781,
          9.145797729492188,
          9.480895042419434,
          9.359057426452637,
          8.893786430358887,
          9.713656425476074,
          9.886479377746582,
          8.968783378601074,
          9.193838119506836,
          9.089763641357422,
          9.518595695495605,
          9.79212474822998,
          8.897647857666016,
          9.722410202026367,
          9.292807579040527,
          9.239191055297852,
          9.388800621032715,
          9.56068229675293,
          9.60602855682373,
          9.154952049255371,
          10.313288688659668,
          9.306028366088867,
          9.705267906188965,
          9.4557523727417,
          9.425796508789062,
          9.813776969909668,
          9.814130783081055,
          9.903186798095703,
          9.920536994934082,
          8.873645782470703,
          9.55870246887207,
          9.376179695129395,
          10.00809383392334,
          9.823028564453125,
          9.394331932067871,
          9.1519775390625
         ],
         "y": [
          7.8646626472473145,
          8.660438537597656,
          8.806159019470215,
          8.398174285888672,
          7.965454578399658,
          8.742961883544922,
          8.402975082397461,
          7.756711483001709,
          9.672211647033691,
          8.455442428588867,
          8.096281051635742,
          9.040760040283203,
          7.881346702575684,
          8.730053901672363,
          9.614356994628906,
          8.308968544006348,
          9.216818809509277,
          9.594808578491211,
          8.897851943969727,
          8.902091026306152,
          7.691403388977051,
          9.34347915649414,
          7.953888893127441,
          8.899064064025879,
          9.634408950805664,
          8.95203971862793,
          8.225249290466309,
          8.651313781738281,
          9.26880931854248,
          8.499738693237305,
          9.337875366210938,
          8.736384391784668,
          7.87275505065918,
          9.602303504943848,
          8.442161560058594,
          8.55051040649414,
          8.195448875427246,
          8.202122688293457,
          8.0393705368042,
          8.759506225585938,
          9.619039535522461,
          8.781389236450195,
          9.046310424804688,
          8.800494194030762,
          9.252008438110352,
          9.634660720825195,
          9.723947525024414,
          9.141395568847656,
          9.424650192260742,
          8.635682106018066,
          7.811663627624512,
          8.299910545349121,
          8.57048511505127,
          8.783452033996582,
          9.3189697265625,
          8.979689598083496,
          7.969076633453369,
          8.855769157409668
         ]
        },
        {
         "hoverinfo": "text",
         "hovertext": [
          "python -m spacy download en_core_web_sm",
          " Load the spacy model\nnlp = spacy.load('en_core_web_sm')",
          "Setup spacy\nnlp = spacy.load('en_core_web_sm')",
          "Get the English tokenizer from SpaCy for better performance\nnlp = spacy.load('en_core_web_sm', disable=['parser', 'tagger', 'ner'])",
          " Set up tokenization model\n# We will use the SpaCy library to lemmatize and tokenize the words\nnlp = spacy.load('en_core_web_sm', disable=['ner', 'parser'])",
          "install a dictionary\n!{sys.executable} -m spacy download en_core_web_sm",
          "Setting up the spacy model for preprocessing the text data.",
          "Load the spacy model for processing English language\nnlp = spacy.load(\"en_core_web_sm\")",
          " Set up spacy\nnlp = spacy.load('en_core_web_sm')",
          "Set environment variable for the path to spaCy model\nos.environ[\"SPACY_DATA\"] = '/usr/local/lib/python3.7/dist-packages/en_core_web_lg/'",
          " Load sm\nen_core_web_sm = spacy.load('en_core_web_sm')",
          "\n#create spacy nlp object\nnlp = spacy.load('en_core_web_sm')",
          " Install the spaCy language model\n!python -m spacy download en_core_web_sm",
          "Load the pre-defined NLP pipeline that you developed in the previous sections.",
          "# Design choices\n# We choose to use spacy to provide a fast and robust way to search words. Besides, it will be easy to query named entities we could encounter later on.",
          " Set up the spacy model for NLP analysis.",
          "Define global parameters\n# Number of top characters to display\ntop_n_characters = 15\n\n# Load the large english model\nnlp = spacy.load('en_core_web_lg')",
          "Loading BERT tokenizer and encoding the dataframe",
          "Download spaCy model\n!python -m spacy download en_core_web_sm",
          " Spacy model\nnlp = spacy.load('en_core_web_sm')",
          "Setting up spacy\nnlp = spacy.load(\"en_core_web_sm\")",
          "To use spaCy's NER, we start by loading a pre-trained model.",
          " Load Spacy\nnlp = spacy.load('en')",
          "Set up Spacy\nnlp = spacy.load('en_core_web_sm', disable=['parser', 'tagger', 'ner'])",
          "Declare path to the pretrained model\nmodel_base_path = 'models/spacy/'\nos.environ[\"MODERN_MODEL\"] = model_base_path\n\n# Load the model\nnlp = spacy.load(model_base_path)",
          "# Set up environment\nMODELS_DIR = \"/pi/ai/nlp/models\"\n\n# Load spacy model\nnlp = spacy.load('en_core_web_md')\n\n# Expand Pandas Matrix\npd.options.display.max_columns = 50",
          "spacy pre-trained model\nnlp = spacy.load('en')",
          "Load spacy model\nnlp = spacy.load('en_core_web_sm')",
          "Translate all the text to English with the help of `spacy` module",
          "Download the spacy language model\n!python -m spacy download en_core_web_sm",
          "Load the pre-trained model from spacy.",
          " Property setting\npd.set_option('max_colwidth', 800)\n\n# Preload spacy language model\nnlp = spacy.load('en_core_web_sm')",
          " Start the sentence tokenizer\nnlp = spacy.load(\"en_core_web_sm\")\nnlp.add_pipe('sentencizer')",
          "load language model\nnlp = spacy.load('en')",
          "Set up Spacy\nnlp = spacy.load('en_core_web_sm')\nnlp.max_length = 1500000",
          " Character recognition models: Implementation of the NER system to recognize characters' names within the frames' dialogue using spaCy's named entity recognition capabilities.",
          "Installing spacy language model for English",
          "Optional for preprocessing\nnlp = spacy.load('en_core_web_sm')",
          "nlp = spacy.load('en_core_web_sm')",
          "To ensure the libraries are correctly installed, we can run the following command on the terminal:\n```\npython -m spacy download en_core_web_sm\n```",
          "Load spaCy language model\nnlp = spacy.load('en_core_web_sm')",
          "character = spacy.load(\"en_core_web_lg\")",
          " Load the pre-trained large English NLP model\nnlp = spacy.load('en_core_web_lg')",
          "Set an environment variable to determine the stopwords language for the preprocessing step using spaCy and its language model.",
          "Create an instance of the English spaCy tokenizer."
         ],
         "marker": {
          "opacity": 0.5,
          "size": 5
         },
         "mode": "markers+text",
         "name": "4_SpaCy NLP Model Loading",
         "text": [
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          ""
         ],
         "textfont": {
          "size": 12
         },
         "type": "scattergl",
         "x": [
          5.579385280609131,
          4.935830593109131,
          4.930156230926514,
          5.2434797286987305,
          5.343018054962158,
          5.651276111602783,
          5.8132004737854,
          5.382181644439697,
          4.929876804351807,
          5.326015949249268,
          5.054239273071289,
          4.920751571655273,
          5.597084999084473,
          5.5274224281311035,
          5.718623638153076,
          5.816745758056641,
          5.1553802490234375,
          5.578561782836914,
          5.554988384246826,
          4.959695339202881,
          5.208807945251465,
          5.903894901275635,
          5.428506851196289,
          5.065357685089111,
          5.14094352722168,
          5.0100932121276855,
          5.538060665130615,
          5.101446628570557,
          5.756753444671631,
          5.679067611694336,
          5.664125919342041,
          5.010955810546875,
          5.30672025680542,
          5.57243537902832,
          4.939162254333496,
          6.035238265991211,
          5.718234062194824,
          4.8918938636779785,
          4.914423942565918,
          5.7035746574401855,
          5.227282524108887,
          4.9933085441589355,
          5.451068878173828,
          5.566835880279541,
          5.60699987411499
         ],
         "y": [
          7.415183067321777,
          7.818312168121338,
          8.182561874389648,
          8.46782398223877,
          8.623533248901367,
          7.442472457885742,
          8.516088485717773,
          8.112295150756836,
          8.12131404876709,
          7.545494079589844,
          7.781030178070068,
          8.232161521911621,
          7.6496124267578125,
          8.10587215423584,
          8.54697322845459,
          8.421651840209961,
          8.05393123626709,
          8.40259075164795,
          7.44068717956543,
          8.051486015319824,
          8.007291793823242,
          8.414055824279785,
          8.374493598937988,
          8.270724296569824,
          7.983619689941406,
          8.004315376281738,
          8.319440841674805,
          8.09707260131836,
          8.102110862731934,
          7.6868767738342285,
          8.252410888671875,
          8.002951622009277,
          8.443432807922363,
          8.267156600952148,
          8.037740707397461,
          8.560979843139648,
          7.90159273147583,
          8.285704612731934,
          8.22861099243164,
          7.346527576446533,
          8.099997520446777,
          7.884714603424072,
          8.14565658569336,
          8.521873474121094,
          8.376314163208008
         ]
        },
        {
         "hoverinfo": "text",
         "hovertext": [
          "Display up to 100 columns\npd.set_option('display.max_columns', 100)",
          "Display all column names to get an overview",
          "Some countries use comma as decimal separator, others use dot. To avoid truncating the decimal part of large numbers that are printed and will be later converted back to numbers, I set the format to round at the 4th decimal, then we convert numbers using the US format, and let the current system's locale determine how to display these rounded numbers.",
          " Display all columns\npd.set_option('display.max_columns', None)",
          "Setting the settings for printing all rows when needed\npd.set_option('display.max_rows', None)",
          "Change display settings to show \"max_columns\" number of columns.\n# This makes it easier to inspect DataFrames with many columns.",
          "Setting precision for pandas to avoid scientific notation for large numbers\npd.set_option('display.float_format', lambda x: '%.3f' % x)",
          "Set the maximum display width so that we can have a better idea of the data\npd.set_option('display.max_colwidth', 200)",
          " Set up constants for reusable color and optiona configurations.",
          "# Display all columns without truncation\npd.set_option('display.max_columns', None)",
          "Set default options for pandas.\npd.set_option('display.max_columns', None)\npd.set_option('display.max_rows', None)",
          "# Set pandas display options for easier debugging\npd.set_option('display.max_columns', None)\npd.set_option('display.width', None)",
          " Display all columns to enable easier exploration\npd.options.display.max_columns = None",
          "Improve the viewing experience of pandas dataframes\npd.set_option('display.max_columns', None)",
          " Configure pandas display options for better readability\npd.options.display.max_columns = 50\npd.options.display.max_colwidth = 100",
          "Set metadata and display options for pandas dataframes\npd.set_option('display.max_columns', None)",
          " Disabling a warning\npd.options.mode.chained_assignment = None",
          "Set width to see more columns\npd.set_option('display.max_columns', 100)",
          "Set the format of Floats to show two decimal digits",
          "Set maximum column width for dataframes\npd.set_option('display.max_colwidth', 150)",
          "display\npd.set_option('display.max_columns', None)",
          "Pretty print settings\npd.set_option('expand_frame_repr', False)\npd.set_option('display.max_columns', 500)\npd.set_option('display.width', 1000)",
          "display first few rows of each dataframe\npd.set_option('display.max_columns', 50)",
          " Display all column in the dataframe\npd.set_option('display.max_columns', None)",
          "Set display\npd.set_option('display.max_columns', None)\npd.set_option('display.max_colwidth', None)",
          " Optional: Display all columns.",
          "To display all rows and columns\npd.set_option('display.max_columns', None)\npd.set_option('display.max_rows', None)",
          "Display options for pandas DataFrame to assure that the content of the DataFrame gets displayed correctly.",
          " Display all columns\npd.set_option('display.max_columns', None)",
          "Set pandas to display wide tables as needed by this notebook\npd.set_option('display.max_columns', 50)",
          "Set the max width of the columns\npd.set_option('display.max_colwidth', 200)",
          "def round_down(num, divisor):\n    return num - (num%divisor)",
          "To avoid Panda's warning\npd.options.mode.chained_assignment = None",
          "set output display\npd.set_option('display.max_rows', 1000)",
          "Setting pandas to print any large field content up to 1024 characters, \n# the columns that contain the script lines and the normalized text\npd.set_option('display.max_colwidth', 1024)",
          " Configure pandas display options\npd.set_option('display.max_columns', None)",
          "# Pandas options for easier debugging\npd.set_option('display.max_columns', None)\npd.set_option('display.max_colwidth', None)"
         ],
         "marker": {
          "opacity": 0.5,
          "size": 5
         },
         "mode": "markers+text",
         "name": "5_pandas display options",
         "text": [
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          ""
         ],
         "textfont": {
          "size": 12
         },
         "type": "scattergl",
         "x": [
          6.234475612640381,
          7.136399269104004,
          6.872233867645264,
          6.563271522521973,
          6.569974899291992,
          6.450423717498779,
          6.6252970695495605,
          6.172503471374512,
          7.51871919631958,
          6.5545268058776855,
          6.547479629516602,
          6.447837829589844,
          6.631281852722168,
          6.66529655456543,
          6.344738006591797,
          6.702742099761963,
          6.745729923248291,
          6.116139888763428,
          6.976963520050049,
          6.179501533508301,
          6.467967510223389,
          6.256537437438965,
          6.34113073348999,
          6.550266742706299,
          6.171130180358887,
          6.934755802154541,
          6.441721439361572,
          6.784056186676025,
          6.523946762084961,
          6.287339210510254,
          6.123775482177734,
          6.859535217285156,
          6.6809210777282715,
          6.412071704864502,
          6.292720794677734,
          6.60793924331665,
          6.3530707359313965
         ],
         "y": [
          5.392941474914551,
          6.03317928314209,
          4.400899410247803,
          5.868389129638672,
          5.723591327667236,
          4.9995341300964355,
          4.7490081787109375,
          4.947951793670654,
          5.8256635665893555,
          5.819192409515381,
          5.35702657699585,
          4.916691303253174,
          5.830416679382324,
          5.175684452056885,
          4.897572040557861,
          5.34491491317749,
          5.652559757232666,
          5.070084095001221,
          4.516475200653076,
          4.933561325073242,
          5.6431474685668945,
          5.043010234832764,
          5.533276557922363,
          5.580588340759277,
          5.237067699432373,
          6.082560062408447,
          5.7883710861206055,
          5.05874490737915,
          5.737937927246094,
          5.023377895355225,
          4.970637798309326,
          4.430978298187256,
          5.360153675079346,
          5.624795436859131,
          4.899606227874756,
          5.38233757019043,
          5.050614833831787
         ]
        },
        {
         "hoverinfo": "text",
         "hovertext": [
          " Display first few rows of the characters dataframe\ndf_characters.head()",
          "Display the first few rows of the characters dataframe\ndf_characters.head()",
          " Display the first few rows of the characters dataframe\ndf_characters.head()",
          "Display the first few rows of the characters dataframe\ndf_characters.head()",
          " Display the first few rows of the characters dataframe\ndf_characters.head()",
          "Display the first few rows of the characters dataframe\ndf_characters.head()",
          " Display the first few rows of the characters DataFrame\ndf_characters.head()",
          " Display the first few rows of the characters dataframe\ndf_characters.head()",
          " Display the first few rows of the characters dataframe\ndf_characters.head()",
          " Displaying the first few rows of the characters dataframe\ndf_characters.head()",
          "Show the first lines of `df_characters`",
          "Show the first few lines of the characters dataframe\ndf_characters.head()",
          "Show the first few lines of the dataframe containing the characters",
          " Display the first rows of the characters dataframe\ndf_characters.head()",
          " Display the first few rows of the characters dataframe\ndf_characters.head()",
          "Displaying the first few rows of the characters dataframe\ndf_characters.head()",
          " Display the first few rows of the dataframe\ndf_characters.head()",
          "Visualize the first few rows of the characters dataframe\ndf_characters.head()",
          "Display the first few rows of the characters dataframe\ndf_characters.head()",
          "Display the first few rows of the characters DataFrame\ndf_characters.head()",
          " Display first rows of the characters dataframe\ndf_characters.head()",
          "Display the first few rows of the characters dataframe\ndf_characters.head()",
          "Visualise the first few rows of the characters dataframe\ndf_characters.head()",
          " Show the first few rows of the dataframe\ndf_characters.head()",
          "Display the first few rows of the characters dataframe\ndf_characters.head()",
          "# Display first 10 rows of the characters dataframe\ndf_characters.head(10)",
          "visualizing the first few rows of the characters data\ndf_characters.head()",
          "Display the first few rows of the characters dataframe\ndf_characters.head()",
          "Display the first few rows of the characters dataframe\ndf_characters.head()",
          "Show the first rows of the characters dataframe\ndf_characters.head()",
          "Visualize data\ndf_characters.head()",
          "Display the first few rows of the characters dataframe\ndf_characters.head()",
          " Display the first few characters of the DataFrames to understand the data",
          "Show first rows of the table to get a sense of what the data looks like\ndf_characters.head()",
          "Show first few rows of the characters dataframe\ndf_characters.head()",
          "Display the first few rows of the characters dataframe\ndf_characters.head()"
         ],
         "marker": {
          "opacity": 0.5,
          "size": 5
         },
         "mode": "markers+text",
         "name": "6_Displaying the first few rows of characters dataframe",
         "text": [
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          ""
         ],
         "textfont": {
          "size": 12
         },
         "type": "scattergl",
         "x": [
          11.735685348510742,
          12.052557945251465,
          11.766595840454102,
          11.912210464477539,
          11.929821014404297,
          11.744216918945312,
          11.940847396850586,
          11.877885818481445,
          11.786012649536133,
          11.975773811340332,
          11.443286895751953,
          11.68445873260498,
          11.17900276184082,
          11.513802528381348,
          11.794055938720703,
          11.986331939697266,
          11.745237350463867,
          11.488255500793457,
          11.826681137084961,
          11.870270729064941,
          11.483890533447266,
          11.804426193237305,
          11.447494506835938,
          11.732172012329102,
          11.849205017089844,
          11.752669334411621,
          11.38749885559082,
          11.945889472961426,
          11.851475715637207,
          11.474205017089844,
          11.321036338806152,
          12.036077499389648,
          11.034910202026367,
          11.622773170471191,
          11.610977172851562,
          12.00295639038086
         ],
         "y": [
          -5.079932689666748,
          -5.265755653381348,
          -5.400180816650391,
          -5.1438164710998535,
          -5.446505069732666,
          -5.339177131652832,
          -5.275204658508301,
          -5.308423042297363,
          -5.224494457244873,
          -5.002682209014893,
          -4.082815170288086,
          -4.574814319610596,
          -3.5766968727111816,
          -4.2565836906433105,
          -5.407116889953613,
          -5.096822738647461,
          -5.009398460388184,
          -0.11982502788305283,
          -5.203777313232422,
          -5.478643417358398,
          -4.296763896942139,
          -5.252363204956055,
          -0.09903229027986526,
          -4.964112758636475,
          -5.213696479797363,
          -5.378543376922607,
          0.01757653057575226,
          -5.3355512619018555,
          -5.293473720550537,
          -4.051198482513428,
          0.08930031955242157,
          -5.403472423553467,
          -3.1733286380767822,
          -4.0105881690979,
          -4.7032976150512695,
          -5.23352575302124
         ]
        },
        {
         "hoverinfo": "text",
         "hovertext": [
          "View the first 5 rows of the characters dataframe\ndf_characters.head()",
          "# Display the first 5 rows of the characters dataset\ndf_characters.head()",
          "Display the first 5 rows of the characters dataframe\ndf_characters.head()",
          "View the first 5 rows of the characters dataframe\ndf_characters.head()",
          "Display the first 5 rows of the characters dataframe\ndf_characters.head()",
          "Print the first 5 rows of the characters dataframe\ndf_characters.head()",
          "Display the top 5 rows of the dataframe\ndf_characters.head()",
          "# Display a random sample of the characters dataframe\ndf_characters.sample(5)",
          " Display first 5 rows of characters dataframe\ndf_characters.head()",
          "View the first 5 records of the character data\ndf_characters.head()",
          " Sample first 5 rows of characters dataframe\ndf_characters.head()",
          " Display the first 5 rows of the characters dataframe\ndf_characters.head()",
          "View the first 5 rows of the characters DataFrame\ndf_characters.head()",
          " Display the first 5 rows of the characters dataframe\ndf_characters.head()",
          " Show the first 5 rows of the characters dataset\ndf_characters.head()",
          "Show the first 5 rows of df_characters\ndf_characters.head()",
          "Display first 5 rows of df_characters\ndf_characters.head()",
          "Display the first 5 rows of the characters dataframe\ndf_characters.head()",
          " Display the first 5 rows of the characters dataframe\ndf_characters.head()",
          "Preview first 5 rows of df_characters\ndf_characters.head()",
          "View first 5 rows of characters dataframe",
          "Inspect the first 5 rows of the characters DataFrame\ndf_characters.head()",
          "Display top 5 rows of characters dataframe\ndf_characters.head()",
          "View the first 5 rows of the characters dataframe\ndf_characters.head()",
          "Displaying the 5 first rows of the dataframe \"df_characters\"",
          "Displaying the first 5 rows of the characters dataframe\ndf_characters.head(5)",
          "# display the first 5 rows of the df_characters dataframe\ndf_characters.head()",
          "Show the first 5 rows of the dataframe `df_characters`\ndf_characters.head()",
          "Show first 5 records of characters dataframe\ndf_characters.head()",
          "# The first 5 rows of the characters table\ndf_characters.head()",
          "showing the first 5 rows of the characters dataframe\ndf_characters.head()",
          "View data first 5 rows of `df_characters` DataFrame\ndf_characters.head()"
         ],
         "marker": {
          "opacity": 0.5,
          "size": 5
         },
         "mode": "markers+text",
         "name": "7_Displaying first 5 rows of characters dataframe",
         "text": [
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          ""
         ],
         "textfont": {
          "size": 12
         },
         "type": "scattergl",
         "x": [
          5.062814235687256,
          4.367095947265625,
          4.082237243652344,
          5.073887348175049,
          4.1356000900268555,
          4.0146074295043945,
          4.214926719665527,
          4.398277282714844,
          4.06145715713501,
          4.8326520919799805,
          4.302624702453613,
          4.057795524597168,
          4.957025051116943,
          4.087445259094238,
          4.405962944030762,
          4.466756820678711,
          4.477910041809082,
          4.098383903503418,
          3.976792812347412,
          4.7535176277160645,
          4.802554130554199,
          5.075534820556641,
          4.182624340057373,
          4.980483531951904,
          4.254603385925293,
          3.9814674854278564,
          3.9947307109832764,
          4.2663116455078125,
          4.422961711883545,
          4.686577320098877,
          4.517354488372803,
          5.075089931488037
         ],
         "y": [
          -2.5207674503326416,
          -2.3392374515533447,
          -2.7015373706817627,
          -2.6460630893707275,
          -2.6431925296783447,
          -2.703833818435669,
          -2.4445433616638184,
          -2.105121612548828,
          -2.6037356853485107,
          -2.5843088626861572,
          -2.5903193950653076,
          -2.626037836074829,
          -2.4875857830047607,
          -2.661071538925171,
          -2.5561656951904297,
          -2.5072343349456787,
          -2.606947660446167,
          -2.733983039855957,
          -2.74834942817688,
          -2.5043396949768066,
          -2.4673447608947754,
          -2.3508636951446533,
          -2.4081597328186035,
          -2.4003520011901855,
          -2.530805826187134,
          -2.503044843673706,
          -2.6203010082244873,
          -2.5765020847320557,
          -2.6552364826202393,
          -2.2541990280151367,
          -2.7852377891540527,
          -2.4677481651306152
         ]
        },
        {
         "hoverinfo": "text",
         "hovertext": [
          "Make it easier to access and manipulate names for the dataframes.",
          "The 'reset_index' method is used to reset the index of the dataframe after reading the CSV files. This method ensures that the index starts from 0 and increases consecutively.",
          " Since the data is already in CSV format, we can use Pandas read_csv function to read the data into dataframes.",
          "General Imports completed. Now, we have declared and initialized the dataframe variables.",
          "Let's take a quick look at the dataframes.",
          " Let's take a look at the structure of the dataframes.",
          " Importing dataframes with pandas using read_csv function.",
          "Let's start by taking a look at the first few rows of each dataframe.",
          "Let's take a look at the first few rows of each dataframe to understand the structure of the data.",
          "Let's quickly have a look at the structure of our dataframes.",
          "Let's have a look at each dataframe first.",
          "Take a quick look at the dataframes",
          "Now that we have loaded the data, we can see the first few rows of each dataframe to understand its structure and contents.",
          "We can see that all of the DataFrames now have an 'index' column which we should drop.",
          "Let's start by taking a look at the first few rows of each dataframe.",
          "First we start with reading the required csv files and resetting the index of the dataframes.",
          "Let's start by taking a look at the first few rows of each dataframe to understand what kind of data we are dealing with.",
          "Use the first few lines of each dataframe to understand the general content.",
          "We have successfully loaded the datasets into dataframes. Now we can explore and analyze the data to gain insights.",
          "Let's check the first rows of each dataframe to know the kind of data we are handling.",
          "We can start the data exploration by looking at the first few rows of each DataFrame.",
          " Let's take a look at the first few lines of each DataFrame.",
          "Let's take a look at the first few entries in these DataFrames.",
          "Let's first look at the structure of our dataframes",
          "Let us consider the structure of the first few rows of all dataframes to understand the data better.",
          "Let's take a look at the first few rows of each DataFrame to understand their structure and information they contain.",
          " Let's take a first look at the data available in our dataframes.",
          "First, we read the necessary CSV files into Pandas DataFrames for further processing.",
          " Now we have loaded the datasets into pandas dataframes, we can start by doing some basic exploratory data analysis to better understand the data.",
          "Let's take a look at the first few rows of each dataframe.",
          "Let's take a look at the structure and content of each dataframe."
         ],
         "marker": {
          "opacity": 0.5,
          "size": 5
         },
         "mode": "markers+text",
         "name": "8_Exploring Dataframes and Understanding Data Structure",
         "text": [
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          ""
         ],
         "textfont": {
          "size": 12
         },
         "type": "scattergl",
         "x": [
          11.294271469116211,
          11.36594295501709,
          10.845747947692871,
          10.771051406860352,
          10.860676765441895,
          10.87900161743164,
          10.809656143188477,
          11.069062232971191,
          11.163708686828613,
          10.739103317260742,
          11.0809965133667,
          10.96042251586914,
          11.16677188873291,
          11.41832160949707,
          11.059353828430176,
          11.19188404083252,
          10.903779983520508,
          11.26567554473877,
          10.459064483642578,
          11.453933715820312,
          11.048678398132324,
          11.06902027130127,
          10.835001945495605,
          10.939011573791504,
          11.108311653137207,
          11.384626388549805,
          10.684941291809082,
          10.876197814941406,
          10.783468246459961,
          11.302978515625,
          11.231513023376465
         ],
         "y": [
          4.983595371246338,
          5.465878486633301,
          5.497896671295166,
          5.14339542388916,
          4.584455490112305,
          4.493597030639648,
          5.556670188903809,
          4.936512470245361,
          4.326361179351807,
          4.63287878036499,
          4.716933250427246,
          4.5356245040893555,
          3.9522697925567627,
          5.296091079711914,
          4.913283348083496,
          5.455371856689453,
          4.866030693054199,
          4.496385097503662,
          5.096312999725342,
          4.38066291809082,
          4.809170722961426,
          4.702193260192871,
          4.633927345275879,
          4.653440475463867,
          4.2279887199401855,
          4.318885326385498,
          4.7116899490356445,
          5.442775249481201,
          5.275284290313721,
          4.648705959320068,
          4.508679389953613
         ]
        },
        {
         "hoverinfo": "text",
         "hovertext": [
          "Join characters, locations, episodes to script\ndf1 = df_script.join(df_characters, on='character_id', rsuffix='_character')\ndf2 = df1.join(df_locations, on='location_id', rsuffix='_location')\ndf3 = df2.join(df_episodes, on='episode_id', rsuffix='_episode')",
          "Merge the dataframes to create a single dataframe with all the information we need.\ndf = pd.merge(df_script,\n              df_episodes,\n              how='left',\n              left_on=['episode_id'],\n              right_on=['id'],\n              suffixes=('_script', '_episode')).drop(columns=['id_script'])\ndf = pd.merge(df,\n              df_characters,\n              how='left',\n              left_on=['character_id'],\n              right_on=['id'],\n              suffixes=('', '_character')).drop(columns=['id'])",
          " Merge the data to have all information on the same dataframe\ndf = (df_script\n      .merge(df_episodes[['id','title']], how='left', left_on='episode_id', right_on='id')\n      .merge(df_characters[['id', 'name']], how='left', left_on='character_id', right_on='id', suffixes=('', '_character'))\n      .merge(df_locations[['id','name']], how='left', left_on='location_id', right_on='id', suffixes=('', '_location'))\n      )",
          "# convert ids to numbers\ndf_script['episode_id'] = pd.to_numeric(df_script['episode_id'], errors='coerce')\ndf_script['character_id'] = pd.to_numeric(df_script['character_id'], errors='coerce')\ndf_script['location_id'] = pd.to_numeric(df_script['location_id'], errors='coerce')",
          "Combine scripts with characters, locations and episodes info\ndf_simpsons = df_script.merge(df_characters, on='character_id', how='outer')\\\n                       .merge(df_locations, on='location_id', how='outer')\\\n                       .merge(df_episodes, on='episode_id', how='outer')",
          "# Merge the tables on the episode_id\ndf = df_script.merge(\n    df_episodes, \n    left_on='episode_id', \n    right_on='id', \n    suffixes=('_script', '_episode')\n).merge(\n    df_characters, \n    left_on='character_id', \n    right_on='id', \n    suffixes=('_script', '_character')\n).merge(\n    df_locations, \n    left_on='location_id', \n    right_on='id', \n    suffixes=('_script', '_location')\n)",
          "Check the structure of dataset (schematics). If the datasets look very complicated with mult-levels of indexes and columns (a problem I have encontered before), consider the following operation:\n\n# be sure the indexes are only 1-level deep to make merging easier\nfor df in [df_script, df_episodes, df_characters, df_locations]: df.reset_index(inplace=True)\n\n# Merge all datasets\ndf = (df_script\n         .merge(df_episodes, on='episode_id')\n         .merge(df_characters, on='character_id')\n         .merge(df_locations, on='location_id')\n         .sort_values(by='id')\n         .reset_index(inplace=False, drop=True))",
          " Merge all data into a single dataframe\ndf_comb = df_script.join(df_characters, on='character_id', rsuffix='_character').join(df_locations, on='location_id', rsuffix='_location').join(df_episodes, on='episode_id', rsuffix='_episode')",
          "Join episode data to scripts\ndf = df_script.join(df_episodes, on='episode_id', rsuffix='_ep')\ndf = df.join(df_characters, on='character_id', rsuffix='_ch')\ndf = df.join(df_locations, on='location_id', rsuffix='_loc')\n\ndf = df.drop(columns=['id_ep', 'id_ch', 'id_loc'])\ndf.columns",
          "Join script with characters and locations\ndf_script = df_script[df_script.speaking_line == True].copy()  # Remove non speaking lines\ndf_script = pd.merge(df_script, df_episodes, on='episode_id', how='left')\ndf_script = pd.merge(df_script, df_characters, on='character_id', how='left')\ndf_script = pd.merge(df_script, df_locations, on='location_id', how='left')",
          " Merge script data with characters and locations\ndf_script = df_script[[\n    'episode_id',\n    'number',\n    'raw_text',\n    'timestamp_in_ms',\n    'speaking_line',\n    'character_id',\n    'location_id',\n    'raw_character_text',\n    'raw_location_text',\n    'spoken_words',\n    'normalized_text',\n]].merge(\n    df_characters.add_prefix('character_'),\n    left_on='character_id', \n    right_on='character_id', \n    suffixes=(None, '_dropped')\n).merge(\n    df_locations.add_prefix('location_'), \n    left_on='location_id', \n    right_on='location_id', \n    suffixes=(None, '_dropped')\n)\n\n# Merge with episodes data\ndf_script = df_script.merge(\n    df_episodes.add_prefix('episode_'),\n    left_on='episode_id',\n    right_on='episode_id',\n    suffixes=(None, '_dropped')\n)",
          "Join episodes dataset to script dataset\ndf = df_script.set_index('episode_id').join(df_episodes.set_index('id'), on='episode_id', rsuffix='_es')\n\n# Join characters and locations to the new script dataset\ndf = df.join(df_characters.set_index('id'), on='character_id', rsuffix='_ch')\ndf = df.join(df_locations.set_index('id'), on='location_id', rsuffix='_lo')\n\ndf.head(3)",
          "Merge all tables in one df\ndf = df_script.merge(df_characters, on='character_id').merge(df_locations, on='location_id').merge(df_episodes, on='episode_id')",
          " Merge in character information\ndf_merged_chars = df_script.merge(df_characters, how='left', left_on='character_id', right_on='character_id', suffixes=('_script', '_character'))\n\n# Merge in location information\ndf_merged_locs = df_merged_chars.merge(df_locations, how='left', left_on='raw_location_text', right_on='raw_location_text')\n\n# Merge in episode information\ndf_merged_eps = df_merged_locs.merge(df_episodes, how='left', left_on='episode_id', right_on='id', suffixes=('_script', '_episode'))",
          "Merge characters information into script dataframe\ndf_script = df_script.merge(df_characters,\n                            left_on='character_id',\n                            right_on='character_id',\n                            suffixes=(False, False))\n\n# Merge locations information into script dataframe\ndf_script = df_script.merge(df_locations,\n                            left_on='location_id',\n                            right_on='location_id',\n                            suffixes=(False, False))\n\n# Merge episodes information into script dataframe\ndf_script = df_script.merge(df_episodes,\n                            left_on='episode_id',\n                            right_on='id',\n                            suffixes=(False, False))",
          "Join all files together\nsimpsons = pd.merge(df_script, df_episodes,\n                    on='episode_id', how='left')\n\nsimpsons = pd.merge(simpsons, df_characters,\n                    on='character_id', how='left')\n\nsimpsons = pd.merge(simpsons, df_locations,\n                    on='location_id', how='left')",
          "Filter episode 1 in script dataframe\ndf_ep1 = df_script[df_script['episode_id'] == '1']\n\n# merge episode 1 script lines with characters and locations information\ndf_ep1_char_loc = df_ep1.merge(df_characters, how='left', left_on='character_id', right_on='id', suffixes=('', '_character'))\ndf_ep1_char_loc = df_ep1_char_loc.merge(df_locations, how='left', left_on='location_id', right_on='id', suffixes=('', '_location'))\n\ndf_ep1_char_loc[['character_id', 'name', 'normalized_name', 'raw_character_text', 'timestamp_in_ms', 'speaking_line', 'location_id', 'raw_location_text', 'word_count', 'episode_id', 'number', 'raw_text']]",
          "Merge for easier data management\ndf = df_script.merge(df_episodes.add_prefix('episode_'), left_on='episode_id', right_on='episode_id')\ndf = df.merge(df_characters.add_prefix('character_'), left_on='character_id', right_on='character_id')\ndf = df.merge(df_locations.add_prefix('location_'), left_on='location_id', right_on='location_id')",
          " Join relevant data\ndf = (\n    df_script[['episode_id', 'character_id', 'location_id', 'raw_text']]\n    .merge(df_episodes, left_on='episode_id', right_on='id')\n    .merge(df_characters, left_on='character_id', right_on='id')\n    .merge(df_locations, left_on='location_id', right_on='id')\n    .drop(['id_x', 'id_y', 'id', 'id', 'episode_id', 'number_in_season', 'number_in_series', 'video_url', 'image_url' ], axis=1)\n)",
          " Join the script lines with the characters and episodes dataframes\ndf = df_script.set_index('episode_id').join(df_episodes.set_index('id'), rsuffix='_ep')\ndf = df.set_index('character_id').join(df_characters.set_index('id'), rsuffix='_ch')\ndf = df.join(df_locations.set_index('id'), on='location_id')",
          "Merging data on script ids\ndf_merged = df_script.merge(df_episodes[['id', 'title']], left_on='episode_id', right_on='id', suffixes=('', '_episode'))\ndf_merged = df_merged.merge(df_episodes[['id', 'season', 'number', 'air_date']], left_on='episode_id', right_on='id', suffixes=('', '_episode'))\ndf_merged = df_merged.merge(df_characters[['id', 'name']], left_on='character_id', right_on='id', suffixes=('', '_character'))\ndf_merged = df_merged.merge(df_locations[['id', 'name']], left_on='location_id', right_on='id', suffixes=('', '_location'))",
          "Joining characters, locations and scripts based on the episode\ndf_characters_locations = pd.merge(\n    df_characters,\n    df_locations,\n    left_on='character_id',\n    right_on='character_id',\n    how='right'\n)",
          "Keep the original datasets to restore to a clean state if necessary\ndf_characters_original = df_characters.copy()\ndf_locations_original = df_locations.copy()\ndf_script_original = df_script.copy()\ndf_episodes_original = df_episodes.copy()",
          "Remove rows with poor data quality from df_script\ndf_script = df_script[df_script.character_id.isin(df_characters.id)]\ndf_script = df_script[df_script.location_id.isin(df_locations.id)]\ndf_script = df_script[df_script.episode_id.isin(df_episodes.id)]",
          " Merge locations and episodes on `id` column.\ndf_episodes_locs = pd.merge(df_episodes, df_locations, how='inner', left_on='id', right_on='location_id').reset_index(inplace=False, drop=True)",
          "concatenate the location name and the episode name to have a total of 190 unique entries\nunique_locations_episodes = df_locations['name'].apply(lambda x: x.lower()).append(df_episodes['title'].apply(lambda x: x.lower()))",
          "Merge script data with episode data\ndf_episodes = df_episodes.rename(columns={'id': 'episode_id'})",
          "Merge locations with episodes, and then with characters\ndf_isInEpisode = df_script.merge(df_episodes, left_on='episode_id', right_on='id')\ndf_isInEpisode = df_isInEpisode.merge(df_locations, left_on='location_id', right_on='id')\ndf_isInEpisode = df_isInEpisode.merge(df_characters, left_on='raw_character_text', right_on='name')"
         ],
         "marker": {
          "opacity": 0.5,
          "size": 5
         },
         "mode": "markers+text",
         "name": "9_DataFrame Merge and Join Operations",
         "text": [
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          ""
         ],
         "textfont": {
          "size": 12
         },
         "type": "scattergl",
         "x": [
          16.152950286865234,
          15.661316871643066,
          16.14455795288086,
          16.475074768066406,
          16.208284378051758,
          16.166967391967773,
          15.83088207244873,
          15.91661548614502,
          15.86334228515625,
          15.83428955078125,
          15.995563507080078,
          16.008804321289062,
          16.134056091308594,
          16.23155975341797,
          16.204002380371094,
          16.35245704650879,
          15.78684139251709,
          16.049474716186523,
          15.832096099853516,
          16.172565460205078,
          16.02784538269043,
          16.381898880004883,
          15.570403099060059,
          15.698896408081055,
          15.831012725830078,
          16.123523712158203,
          15.755728721618652,
          16.207616806030273
         ],
         "y": [
          9.215084075927734,
          8.8469877243042,
          8.68471622467041,
          8.80051326751709,
          8.55805492401123,
          8.767291069030762,
          8.918410301208496,
          9.208693504333496,
          9.130084991455078,
          8.396749496459961,
          8.257513046264648,
          9.251226425170898,
          8.838645935058594,
          8.483208656311035,
          8.558419227600098,
          8.653862953186035,
          8.460000991821289,
          8.622629165649414,
          8.734350204467773,
          9.122830390930176,
          8.629417419433594,
          8.342391014099121,
          8.946977615356445,
          8.948884010314941,
          8.74764633178711,
          8.581242561340332,
          8.67318058013916,
          8.432649612426758
         ]
        },
        {
         "hoverinfo": "text",
         "hovertext": [
          " Define helper function to get main-episode characters",
          "Set the script line limits to avoid incredibly long sequences, line length and episode length.",
          "Count line with dialogues by character, location and episode",
          "Create name list and sentence list",
          "Create a new column with the episode title in the lines dataframe",
          "Merging dataframe on character and locations on the episode_id",
          " Episode  where character appears",
          "Join the episode to the script lines on episode_id, script_id and raw_text, and only select the columns we need.",
          "Filter the data to keep only episodes that occured after 2000",
          "Split the dataframes in their episodes",
          " Combining the script lines with the episodes data to get the title of each episode.",
          "connect all the episodes to scripts and each script to a character and location",
          "Create a dictionary that maps episode ids to a list of script lines for that episode",
          "Make a list of episode ids for each season",
          "Combine `simpsons_script_lines` with `simpsons_episodes`",
          "Merge tables: episodes, script lines, characters, and locations",
          "Extract and process seasons/episodes numbers",
          "Create mappings to convert between character_id/episode_id and character_name/episode_name",
          " Filter the characters lines from the episode 1",
          "Combine the lines in the script with the respective episode and character.",
          "Merge the characters, script, and locations data frames on the episode_id and the id/episode_id columns respectively to get one consolidated data frame.",
          "Combine the episodes dataframe and the characters and location dataframe to get the exact location of the scenes",
          "Count lines per character and episode",
          " Check the number of lines for a representative episode",
          "For preprocessing we will only keep the rows: character_name, raw_text, word_count, episode_name, location_id.",
          "Merge the data based on the episode id",
          "Limit the script to the first 5 seasons"
         ],
         "marker": {
          "opacity": 0.5,
          "size": 5
         },
         "mode": "markers+text",
         "name": "10_Combining script lines with episodes and creating a dictionary of episode ids and script lines",
         "text": [
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          ""
         ],
         "textfont": {
          "size": 12
         },
         "type": "scattergl",
         "x": [
          13.0033597946167,
          12.868023872375488,
          13.595135688781738,
          13.46743392944336,
          15.354175567626953,
          13.96864128112793,
          13.318466186523438,
          13.485430717468262,
          13.815096855163574,
          15.274868965148926,
          13.144988059997559,
          13.103565216064453,
          13.347038269042969,
          13.421086311340332,
          12.862898826599121,
          13.325299263000488,
          13.468183517456055,
          13.710201263427734,
          13.28581714630127,
          13.06352710723877,
          13.550341606140137,
          13.809042930603027,
          13.432917594909668,
          13.372031211853027,
          13.492844581604004,
          13.701774597167969,
          13.159574508666992
         ],
         "y": [
          7.425449848175049,
          7.928696155548096,
          7.099838733673096,
          7.5375075340271,
          9.157493591308594,
          8.123597145080566,
          7.326766014099121,
          7.938916206359863,
          8.627822875976562,
          9.252640724182129,
          7.843502044677734,
          7.883644104003906,
          7.803640842437744,
          8.053092956542969,
          7.488497257232666,
          8.01584243774414,
          8.329963684082031,
          8.029203414916992,
          7.171269416809082,
          7.584227085113525,
          7.9241461753845215,
          8.209622383117676,
          7.247745513916016,
          7.338062763214111,
          7.86598014831543,
          8.097442626953125,
          8.234777450561523
         ]
        },
        {
         "hoverinfo": "text",
         "hovertext": [
          "Get all the scripts for a given character and calculates the number of words\ndef get_character_scripts(df_script,\n                          character_id,\n                          character_name,\n                          locations,\n                          min_words=50):\n    valid_characters = df_script[(df_script['raw_character_text'] == character_name) &\n                                 (df_script['timestamp_in_ms'] > 0) &\n                                 (~df_script['raw_location_text'].isin(locations))]\n\n    valid_characters['word_count'] = valid_characters['spoken_words'].str.split().map(len)\n    valid_characters = valid_characters[valid_characters['word_count'] >= min_words]\n    return valid_characters",
          "Extract characters mentioned\ndf_script_characters = df_script[df_script.speaker.str.lower().isin(df_characters.name.str.lower())]",
          " Spacy settings\nnlp = spacy.load('en_core_web_sm', disable=['parser', 'ner'])\n\n# Remove superhero speech from the characters' lines\nmask = df_script.raw_character_text.str.contains('^\\s*(V-|Simpsons|J\\W|Springfield|Ned\\W|Maude|Sea+\\W|Todd|Luann|Sherri|Terri|Rod(?:d?)|Milhouse|Kent\\W|Helen|Clancy\\W|Brockman|Lionel|Apu|\\s\\Wl\\W)?$', case=False, na = False)\ndf_script = df_script.loc[mask]",
          "Visualize the most common words in the Simpsons script\nscript_texts = df_script.reset_index(inplace=False, drop=True)['spoken_words']\nscript_texts.dropna(inplace=True)\nscript_texts = \" \".join(script_texts.astype(str).tolist())",
          " Drop unnecessary columns\ndf_script = df_script.drop(columns=['normed_text'])\ndf_script = df_script.drop(columns=['spoken_words'])",
          "Create WordCloud for the most frequent words in the script\nscript_text = ' '.join(df_script['normalized_text'].values)\n\n# Create a WordCloud object\nwordcloud = WordCloud(width=800, height=400, background_color ='black').generate(script_text)",
          "Filter out segment lines from script\ndf_script = df_script[df_script['speaking_line']]",
          " Remove all entries with empty spoken words in the script dataframe\ndf_script = df_script[df_script['spoken_words'].notna()]",
          "Function to compute the count of each character\ndef compute_character_mentions(script, characters):\n    character_mentions = {character: 0 for character in characters}\n    for character in characters:\n        character_mentions[character] = sum(script.raw_text.str.contains(character))\n    return character_mentions",
          "Extract character dialogues from the script data\ncharacters = df_script['raw_character_text'].value_counts().index\ndialogues = {}\nfor character in characters:\n    dialogues[character] = ' '.join(df_script[df_script['raw_character_text'] == character]['spoken_words'].fillna('').values)",
          "calculate the number of lines each character has spoken\nlines_per_character = df_script['raw_character_text'].value_counts()\n\n# Plot the distribution of number of lines spoken by each character\nplt.figure(figsize=(10, 6))\nplt.hist(lines_per_character, bins=range(50), edgecolor='black', log=True)\nplt.xscale('log')\nplt.yscale('log')\nplt.title('Distribution of Number of Lines Spoken by Each Character')\nplt.xlabel('Number of Lines Spoken')\nplt.ylabel('Number of Characters')\nplt.show()",
          "# Clean text\ndf_script['spoken_words'] = df_script['spoken_words'].apply(lambda x: x.lower().strip())",
          "Turn labels listed as 'talking, singing,' into one label column",
          "Remove any lines that are not speech from the script dataframe\ndf_script_speech = df_script.dropna(subset=['spoken_words']).copy()",
          "Create a table matching characters with their spoken lines\nconversation_lines = df_script[df_script['speaking_line'] == True]",
          "Add a lowercased version of the 'spoken_words' column for simplicity of future analyses\ndf_script['spoken_words_lower'] = df_script['spoken_words'].str.lower()",
          "Top characters\ntop_char_mask = df_script.raw_character_text.isin(df_script.raw_character_text.value_counts().index[:15])\ntop_char = df_script[top_char_mask]\n\n# Create a list of every line for the top characters\ntop_char_lines = top_char.groupby('raw_character_text').apply(lambda x: x['spoken_words'].str.cat()).reset_index().rename(columns={0: 'lines'})\ntop_char_lines.lines = top_char_lines.lines.apply(lambda x: str(x).replace(\"nan\", \"\"))\ntop_char_lines.lines = top_char_lines.lines.apply(lambda x: str(x).replace(\"...\", \"\"))\ntop_char_lines.lines = top_char_lines.lines.apply(lambda x: str(x).replace(\"I'm\", \"I am\"))",
          " Generate figure of the Simpsons family\n\nfrom constants import FAMILY_MEMBERS\n\n# Filter dataframe\ndf_family = df_characters[df_characters.character.str.lower().isin(FAMILY_MEMBERS)].reset_index(inplace=False, drop=True)\n\n# Display locations\nplt.figure(figsize=(15, 6))\nword_count = WordCloud(width=1000, height=500, background_color='white').generate(' '.join(df_family.character))\nplt.imshow(word_count, interpolation='bilinear')\nplt.axis('off')",
          "Filter the script dataframe to only include spoken words and not scene directions",
          "Create a new temporary column by combining the raw_text and spoken_words column.",
          "Filtering on the spoken lines, unifying the unigrams, and counting their occurrences for all the characters will lead us to a feature-space of about 78,000 columns.",
          " Remove the entries from script lines that have no speaker, location, or raw text\ndf_script = df_script[pd.notnull(df_script[\"raw_text\"]) & pd.notnull(df_script[\"speaking_line\"]) & pd.notnull(df_script[\"location_id\"])]",
          "Create a dataframe with the 5 most common words",
          "Filter script to only include spoken lines on the show (no scene switching or extra information)",
          " Define the input data and the target data\nX = df_script.speaking_line.values\ny = df_script.raw_character_text.values"
         ],
         "marker": {
          "opacity": 0.5,
          "size": 5
         },
         "mode": "markers+text",
         "name": "11_Script Analysis and Character Line Distribution",
         "text": [
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          ""
         ],
         "textfont": {
          "size": 12
         },
         "type": "scattergl",
         "x": [
          14.498130798339844,
          14.825112342834473,
          14.422075271606445,
          14.101676940917969,
          14.24020004272461,
          10.480656623840332,
          14.199346542358398,
          14.32009506225586,
          14.675565719604492,
          14.492796897888184,
          14.163505554199219,
          14.34202766418457,
          14.076929092407227,
          14.365589141845703,
          14.26501178741455,
          14.405282020568848,
          14.350008010864258,
          13.938494682312012,
          14.15562629699707,
          14.113057136535645,
          10.375114440917969,
          14.340201377868652,
          10.889490127563477,
          13.960847854614258,
          14.436656951904297
         ],
         "y": [
          6.732908725738525,
          7.0435967445373535,
          7.56366491317749,
          6.660534858703613,
          7.153886318206787,
          3.543860673904419,
          7.312322616577148,
          7.106225967407227,
          6.686307430267334,
          6.956051349639893,
          6.563337802886963,
          6.971583843231201,
          6.80974006652832,
          7.22019100189209,
          7.075632572174072,
          6.883462429046631,
          6.678048610687256,
          6.422750473022461,
          7.403261661529541,
          6.896717548370361,
          2.0996060371398926,
          7.397313594818115,
          3.0973730087280273,
          7.373837947845459,
          7.150695323944092
         ]
        },
        {
         "hoverinfo": "text",
         "hovertext": [
          " More imports",
          "Connect to the database\nimport sqlite3",
          "Enable logging\nimport logging",
          "\nimport string",
          "Just a simple line to ensure everything's working fine.\nprint('Backup successful.')",
          " Database creation\nfrom sqlalchemy import create_engine\n\n# Put the DB in the the /data folder.\n# We don't need to provide user or password since the DB is intended to be used locally in local development.",
          " If you get an error loading any of these files, you may need to update the file paths to match your local environment.",
          "Check the content of each of the files",
          "Checking the script CSV file is well defined and prepared for analysis",
          "print(\"Data Loaded\")",
          "See the statically typing of the imported files",
          "Check if data is loaded correctly.",
          "See the loaded csv data",
          "Check the CSV files have been read correctly",
          "What CSV files are present?\nos.listdir('data')",
          "Check imports and data",
          "Set custom logger for debugging\nimport logging\n\nlogging.basicConfig(level=logging.DEBUG, format=\"%(levelname)s: %(message)s\")",
          "Check if we have the data files",
          "Let's take a quick look at the structure of the files.",
          " Connect to database\nimport sqlite3",
          "Connecting to MongoDB",
          "Check that everything is correctly loaded",
          "Create and update queries folder if it doesn't exist."
         ],
         "marker": {
          "opacity": 0.5,
          "size": 5
         },
         "mode": "markers+text",
         "name": "12_Connecting to a Local SQLite Database",
         "text": [
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          ""
         ],
         "textfont": {
          "size": 12
         },
         "type": "scattergl",
         "x": [
          9.423986434936523,
          9.118836402893066,
          8.768707275390625,
          9.236769676208496,
          8.612070083618164,
          9.23697566986084,
          10.2577486038208,
          9.85621452331543,
          11.053754806518555,
          10.418563842773438,
          9.516926765441895,
          10.46888542175293,
          10.497031211853027,
          10.417012214660645,
          10.671571731567383,
          9.530290603637695,
          8.270283699035645,
          9.933104515075684,
          9.77724838256836,
          9.136622428894043,
          9.163641929626465,
          10.483084678649902,
          9.206913948059082
         ],
         "y": [
          7.041270732879639,
          6.782043933868408,
          6.901738166809082,
          6.948246479034424,
          6.493417739868164,
          6.644141674041748,
          7.40385103225708,
          7.365670680999756,
          7.258028984069824,
          7.608260154724121,
          7.192277908325195,
          7.654402256011963,
          7.317163944244385,
          7.255075454711914,
          7.014959335327148,
          7.243138790130615,
          6.784774303436279,
          7.282016277313232,
          7.466285228729248,
          6.675177097320557,
          6.610165119171143,
          7.791823387145996,
          6.683432102203369
         ]
        },
        {
         "hoverinfo": "text",
         "hovertext": [
          "Show the total number of records in each dataframe",
          "Inspect the first 5 rows of each dataframe.",
          "Display the first few rows of each DataFrame to understand its structure and available data.",
          "Check the first few rows of the dataframe to get an idea of the data",
          "Display the first few rows of each DataFrame to get an overview of the data",
          "Checking the first 5 rows of each data frame to ensure they look appropriate.",
          "Visually inspect the first five rows of each dataframe.",
          "Let's display the first rows of each resulting DataFrame to get a better understanding of the available data.",
          "Inspect each dataframe(types, first few rows)",
          " Display the first few lines of each dataframe to understand the data",
          "Display the first 5 rows of each dataframe to understand the structure of the data.",
          "display the first dataframe to inspect the data",
          " Display the first few rows of each dataframe to understand its structure and fields available.",
          "Inspect the first few rows of each dataframe to understand the data",
          "Optional: Display the first few rows of each dataframe to understand the data.",
          "Inspect the first few rows of each dataframe to understand the data",
          " Display the first 5 rows of each dataframe to get an idea of the data",
          "Display first 5 rows of each dataframe to understand the data",
          "Let's see the first 5 entries in each DataFrame.",
          "Display top 5 rows of each DataFrame to understand the data",
          " Print the first few rows of each dataframe to understand the data"
         ],
         "marker": {
          "opacity": 0.5,
          "size": 5
         },
         "mode": "markers+text",
         "name": "13_Understanding DataFrame Structure by Displaying First 5 Rows of Each DataFrame",
         "text": [
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          ""
         ],
         "textfont": {
          "size": 12
         },
         "type": "scattergl",
         "x": [
          11.774785995483398,
          11.60521411895752,
          11.247302055358887,
          11.399433135986328,
          11.482901573181152,
          11.623638153076172,
          11.529569625854492,
          11.125856399536133,
          11.531993865966797,
          11.223664283752441,
          11.434404373168945,
          11.396757125854492,
          11.26716423034668,
          11.228163719177246,
          11.228872299194336,
          11.273683547973633,
          11.685210227966309,
          11.598343849182129,
          11.335959434509277,
          11.684098243713379,
          11.401690483093262
         ],
         "y": [
          3.465601921081543,
          3.216808557510376,
          3.543238639831543,
          3.651946783065796,
          3.3914690017700195,
          3.231381893157959,
          3.096654176712036,
          3.6657168865203857,
          3.8136653900146484,
          3.4547982215881348,
          3.059627056121826,
          3.544991970062256,
          3.655747652053833,
          3.6785266399383545,
          3.6944355964660645,
          3.623288154602051,
          3.1747233867645264,
          3.148979663848877,
          3.187598705291748,
          3.119446039199829,
          3.430593729019165
         ]
        },
        {
         "hoverinfo": "text",
         "hovertext": [
          "Remove trivial columns where most of the values are NaN",
          " Drop column index that was added before ",
          "Filtering columns",
          "Remove useless columns for the analysis",
          "Remove the original index column, if it was loaded.",
          "Set index to speed up merge operation later",
          "Remove unnecessary columns for the cleaning of this database",
          "Load the data using Pandas and reset the index.",
          "Keep some useful columns only.",
          "Remove the unnecessary columns from the dataframes",
          " Remove any unnecessary columns to save memory",
          "Remove unwanted columns and merge the dataframes",
          "Cleaning the subtitle column by removing unwanted punctuation and characters",
          "1. Cleaning of the data\n# 1.1 Remove rows where important fields are NaN",
          "Set column for character and location and removing some unused columns",
          "Remove row with NaN value in 'raw_text' column and reset the indices",
          "Filter columns and join the tables",
          " Remove unintended columns for dataframe",
          "Filter unnecessary columns from the dataframe",
          "Remove old index columns",
          "Remove unwanted columns from main dataframe"
         ],
         "marker": {
          "opacity": 0.5,
          "size": 5
         },
         "mode": "markers+text",
         "name": "14_Removing unnecessary columns from dataframes",
         "text": [
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          ""
         ],
         "textfont": {
          "size": 12
         },
         "type": "scattergl",
         "x": [
          12.3106107711792,
          12.460625648498535,
          11.817598342895508,
          11.846955299377441,
          12.316926956176758,
          12.263147354125977,
          11.598040580749512,
          11.503567695617676,
          11.371912002563477,
          12.183477401733398,
          11.845877647399902,
          12.109074592590332,
          11.577094078063965,
          12.172770500183105,
          11.7120943069458,
          12.645367622375488,
          11.532076835632324,
          12.240392684936523,
          12.253893852233887,
          12.277231216430664,
          12.250679016113281
         ],
         "y": [
          9.626989364624023,
          8.547913551330566,
          9.260878562927246,
          9.038806915283203,
          8.410391807556152,
          8.782752990722656,
          9.166028022766113,
          5.905609607696533,
          9.09679126739502,
          9.260401725769043,
          9.048166275024414,
          9.543205261230469,
          8.735153198242188,
          9.486473083496094,
          8.962414741516113,
          9.378071784973145,
          9.300383567810059,
          9.276815414428711,
          9.339178085327148,
          8.684775352478027,
          9.35264778137207
         ]
        },
        {
         "hoverinfo": "text",
         "hovertext": [
          "Setting of random seed for reproducibility\nnp.random.seed(8)",
          "Set random seed for reproducibility\nnp.random.seed(0)",
          "Set random seed for reproduction of results\nnp.random.seed(42)",
          "Set random seed for reproducibility\nnp.random.seed(0)",
          "Setting the random seed for reproducibility\nnp.random.seed(0)",
          "Setting random seed for reproducibility\nnp.random.seed(0)",
          " Set random seed for reproducibility\nnp.random.seed(0)",
          "Set seed for reproducibility\nnp.random.seed(0)",
          "Set seed for reproducibility",
          "Set the seed for numpy's random number generator for reproducibility.",
          "Set SEED for reproducibility\nSEED = 45",
          "Set the seed for reproducibility\nnp.random.seed(42)",
          "Set random seed for reproducibility\nnp.random.seed(0)",
          "Set seed for reproducibility\nnp.random.seed(0)",
          "Set random seed for reproducibility\nnp.random.seed(56)",
          "Set random seed for reproducibility\nnp.random.seed(0)",
          " Set the seed for reproducibility\nnp.random.seed(0)",
          "Set random seed for reproducibility\nnp.random.seed(0)",
          "Setting the seed for reproducibility."
         ],
         "marker": {
          "opacity": 0.5,
          "size": 5
         },
         "mode": "markers+text",
         "name": "15_Setting Seed for Reproducibility",
         "text": [
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          ""
         ],
         "textfont": {
          "size": 12
         },
         "type": "scattergl",
         "x": [
          -0.6750485897064209,
          -0.7113944888114929,
          -0.6454142928123474,
          -0.6522327661514282,
          -0.7799030542373657,
          -0.7873996496200562,
          -0.6013884544372559,
          -0.7468516230583191,
          -0.9305680990219116,
          -0.5969296097755432,
          -0.8814573884010315,
          -0.8534432649612427,
          -0.6203089952468872,
          -0.7847040295600891,
          -0.5611372590065002,
          -0.716553807258606,
          -0.8107829093933105,
          -0.6313409209251404,
          -0.9233168363571167
         ],
         "y": [
          7.847376346588135,
          7.903292655944824,
          7.774837017059326,
          7.778036594390869,
          7.9525146484375,
          7.917212009429932,
          7.847599983215332,
          7.758988380432129,
          8.034364700317383,
          7.565019607543945,
          7.963282108306885,
          7.759133338928223,
          7.706089973449707,
          7.7164812088012695,
          7.714828968048096,
          7.642394065856934,
          7.656195640563965,
          7.71444845199585,
          8.006903648376465
         ]
        },
        {
         "hoverinfo": "text",
         "hovertext": [
          "Set plot graphs style\nmatplotlib.style.use('seaborn')",
          " Set the drawing parameters for the WordCloud and the matplotlib figure parameters",
          "Helper method to create a wordcloud from a text\ndef plot_wordcloud(text, title, ax, width, height):\n    wordcloud = WordCloud(width=width, height=height, background_color='white').generate(text)\n\n    ax.imshow(wordcloud, interpolation='bilinear')\n    ax.set_title(title, fontdict={'size': 14, 'color': 'black'})\n    ax.axis('off')",
          "set True to build the wordclouds from scratch. False will load the stored images\nbuild_wordclouds = True",
          "Set font scales and styles for matplotlib and seaborn\nmatplotlib.rcParams.update({'font.size': 14, 'font.family': 'sans', 'text.usetex': False})",
          "Set plot style\nplt.style.use('ggplot')",
          " Update the style\nmatplotlib.style.use('bmh')",
          " Set the parameters for the matplotlib visualization",
          "To use the colors_and_fonts helper module, its parent directory must be in the $PYTHONPATH. Let's add it and then test it.",
          "Set seaborn theme",
          "Intents\nfrom IPython.display import display, Math, Latex",
          "Seeing if Jupyter is available",
          "Visualization_CONFIG\nfont = {'family' : 'DejaVu Sans',\n        'weight' : 'normal',\n        'size'   : 14}\n\nmatplotlib.rc('font', **font)",
          "Show plots inline in a Jupyter Notebook\n%matplotlib inline",
          "Set Seaborn theme\nsns.set(style=\"whitegrid\")",
          "jupyter notebook\nfrom IPython.display import display",
          " Set up matplotlib with the appropriate settings for Jupyter notebook\nmatplotlib.rcParams.update({\n    'font.size': 14,\n    'figure.figsize': (15, 8),\n    'figure.facecolor': '#00000000',\n    'axes.labelsize': 14,\n    'axes.labelcolor': '#555555',\n    'axes.labelweight': 'bold',\n    'axes.labelsize': 14,\n    'axes.grid': True,\n    'grid.color': '#aaaaaa',\n    'grid.alpha': 0.3,\n    'axes.titlesize': 18,\n    'axes.titlecolor': '#555555',\n    'axes.titleweight': 'bold',\n    'axes.titlepad': 6.0,\n    'xtick.labelsize': 12,\n    'ytick.labelsize': 12,\n    'xtick.color': '#555555',\n    'ytick.color': '#555555',\n    'legend.fontsize': 12,\n    'legend.title_fontsize': 14,\n    'legend.edgecolor': '#000000',\n    'legend.facecolor': '#f0f0f0',\n    'svg.fonttype': 'path',  # Edit: I needed to add this line as web traffic said \n                             # my fonts were being rasterized\n})",
          " Stop output from being printed\nfrom IPython.display import HTML",
          "!pip install wordcloud"
         ],
         "marker": {
          "opacity": 0.5,
          "size": 5
         },
         "mode": "markers+text",
         "name": "16_Setting styles and fonts for Matplotlib in Jupyter Notebook",
         "text": [
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          ""
         ],
         "textfont": {
          "size": 12
         },
         "type": "scattergl",
         "x": [
          8.661957740783691,
          8.982500076293945,
          9.238980293273926,
          9.483325958251953,
          8.708333015441895,
          8.549315452575684,
          8.626482963562012,
          8.774188041687012,
          8.697263717651367,
          8.69500732421875,
          8.446666717529297,
          8.388160705566406,
          8.729134559631348,
          8.61397647857666,
          8.5947265625,
          8.47943115234375,
          8.683483123779297,
          8.24622917175293,
          9.299261093139648
         ],
         "y": [
          4.9136199951171875,
          5.120650768280029,
          5.062121391296387,
          5.468150615692139,
          4.9730224609375,
          4.829414367675781,
          4.877166748046875,
          4.972164154052734,
          5.561975002288818,
          4.910318374633789,
          5.5537543296813965,
          5.440611839294434,
          5.035490036010742,
          5.109190940856934,
          4.858018398284912,
          5.437490463256836,
          4.986906051635742,
          5.834867000579834,
          5.336853981018066
         ]
        },
        {
         "hoverinfo": "text",
         "hovertext": [
          "Inspect the dataframes",
          " Look at each dataframe's columns and data types",
          "Display the dataframe columns and some of the data to inspect what the data looks like.",
          "Check the resulting dataframes",
          " Just reimport the dataframes",
          "Inspect the dataframes",
          "Visualise all dataframes to understand the tabular structure",
          "Check the structure of each dataframe",
          "View the main dataframes to get an idea of the available fields",
          "Check what is the format of the first dataframe",
          "Inspect the dataframes",
          "Inspect the dataframes to understand their structure and contents",
          "Visualize some dataframes using pandas display method",
          "Check the basic information for each DataFrame",
          "Quick look at the dataframes head",
          "Check if the dataframes were loaded correctly",
          "The head of the DataFrames to understand the structure of the data",
          "Inspect dataframes quickly",
          "Inspect the dataframes"
         ],
         "marker": {
          "opacity": 0.5,
          "size": 5
         },
         "mode": "markers+text",
         "name": "17_Inspecting dataframes and understanding their structure",
         "text": [
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          ""
         ],
         "textfont": {
          "size": 12
         },
         "type": "scattergl",
         "x": [
          12.336613655090332,
          12.04787540435791,
          12.303934097290039,
          12.576687812805176,
          12.369110107421875,
          12.237353324890137,
          11.617931365966797,
          12.455890655517578,
          12.176297187805176,
          12.166722297668457,
          12.29536247253418,
          12.157773971557617,
          11.993668556213379,
          12.406771659851074,
          12.696163177490234,
          12.767524719238281,
          11.960953712463379,
          12.51077938079834,
          12.23788070678711
         ],
         "y": [
          4.676304340362549,
          4.450771808624268,
          4.731729507446289,
          4.086529731750488,
          4.821076393127441,
          4.573298454284668,
          4.234312057495117,
          4.163500785827637,
          4.629570484161377,
          4.025805473327637,
          4.692142009735107,
          4.441622734069824,
          4.764084339141846,
          4.154034614562988,
          4.070479393005371,
          4.2010698318481445,
          4.267073631286621,
          4.787423133850098,
          4.620866775512695
         ]
        },
        {
         "hoverinfo": "text",
         "hovertext": [
          "We have loaded four datasets: characters, locations, script lines, and episodes.",
          "Quick view of the Simpsons characters dataset\ndf_characters.head()",
          "Explore 'simpsons_script_lines.csv'",
          "Display how the Simpsons data looks like.",
          "These files contain information about the characters, locations, script lines, and episodes of the Simpsons TV show.",
          "Visualize the Simpsons characters dataset",
          "Exemplary instance of the dataset \"simpsons_script_lines\"\ndf_script.head()",
          "s_data_directory = 'simpsons_dataset'",
          " This code snippet reads in several CSV files using pandas and the read_csv method. These CSV files likely contain data related to the characters, locations, script lines, and episodes from the TV show \"The Simpsons.\" The data is then stored in corresponding pandas DataFrames named df_characters, df_locations, df_script, and df_episodes. The data from these DataFrames is likely to be used for further analysis, visualization, or processing.",
          "Replace `simpsons_characters.csv` and `simpsons_script_lines.csv` with cleaned datasets",
          "This line of code loads the datasets containing information about the characters, locations, script lines, and episodes of The Simpsons.",
          "Show the first few lines of the Simpsons characters dataset\ndf_characters.head()",
          "Inspecting the content of the 'simpsons_characters.csv' file.",
          "Display the first few lines of the Simpsons script dataset\ndf_script.head()",
          "Retrieving all the datasets from the given CSV files which contain relevant information about the Simpsons TV show.",
          "Visualizing the Simpsons script data",
          "Display the top 5 records of the Simpsons script dataframe to understand its structure and content\ndf_script.head()"
         ],
         "marker": {
          "opacity": 0.5,
          "size": 5
         },
         "mode": "markers+text",
         "name": "18_The Simpsons TV Show",
         "text": [
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          ""
         ],
         "textfont": {
          "size": 12
         },
         "type": "scattergl",
         "x": [
          11.824726104736328,
          12.577808380126953,
          11.824024200439453,
          12.062225341796875,
          11.658021926879883,
          12.153059959411621,
          12.859004020690918,
          11.149470329284668,
          11.695712089538574,
          11.943970680236816,
          11.55608081817627,
          12.842069625854492,
          11.827858924865723,
          13.088590621948242,
          11.535656929016113,
          11.973243713378906,
          13.352558135986328
         ],
         "y": [
          7.125058650970459,
          5.897441387176514,
          6.6577229499816895,
          6.38881254196167,
          6.623762130737305,
          6.314966201782227,
          5.777614593505859,
          6.626905918121338,
          6.6541428565979,
          6.550915718078613,
          6.837099552154541,
          5.83747673034668,
          6.57464599609375,
          5.59116792678833,
          6.692026615142822,
          6.405850887298584,
          5.354161739349365
         ]
        },
        {
         "hoverinfo": "text",
         "hovertext": [
          "Merge dataframe on essential columns: character, raw_location_text and raw_character_text for each script line",
          "Merge Simpsons script with corresponding characters and locations\ndf_script = df_script.merge(df_characters, on='character_id', how='left')\ndf_script = df_script.merge(df_locations, on='location_id', how='left')",
          "Combine the script with the locations and characters on the script lines table\ndf_script = df_script.merge(\n    df_characters,\n    how='left',\n    left_on='character_id',\n    right_on='id'\n).merge(\n    df_locations,\n    how='left',\n    left_on='location_id',\n    right_on='id'\n)",
          "Merge df_script with df_characters\ndf_script = df_script.merge(df_characters, how='left', left_on='character_id', right_on='id', suffixes=('', '_character'))",
          "Merge characters and locations with the script\ndf_with_characters = pd.merge(df_script, df_characters, how='left', on='character_id')\ndf_with_locations = pd.merge(df_with_characters, df_locations, how='left', on='location_id')",
          "# Correct inconsistent variable names\ndf_characters.rename(columns={'id':'character_id', 'name':'character_name'}, inplace=True)\ndf_locations.rename(columns={'id':'location_id', 'name':'location_name'}, inplace=True)\ndf_episodes.rename(columns={'id':'episode_id', 'title':'episode_title'}, inplace=True)",
          " Combine the character and location datasets into one dataframe\ndf_metadata = pd.concat([df_characters, df_locations], ignore_index=True)",
          "Merge characters and locations to script\n#df_characters = df_characters[['id', 'name']]\n#df_script = df_script.merge(df_characters, left_on='character_id', right_on='id')\n#df_script = df_script.drop('id', axis=1)\n\n#df_locations = df_locations[['id', 'name']]\n#df_script = df_script.merge(df_locations, left_on='location_id', right_on='id')\n#df_script = df_script.drop('id', axis=1)",
          " We need to convert character_id and location_id to ints\ndf_script['character_id'] = df_script['character_id'].fillna(-1).astype(int)\ndf_script['location_id'] = df_script['location_id'].fillna(-1).astype(int)",
          "Convert Character IDs to Character names\ndf_script_characters = pd.merge(df_script, df_characters, \n                                how='left', \n                                left_on=['character_id'], \n                                right_on=['id'])",
          "Clean out data - as I will be using character_id and location_id, the rest of the fields might not be useful\n# Cleaning is not mandatory, it really depends what you want to predict and how you want to analyze the data!\ndf_script.head()",
          "Merge characters into script\ndf_chars_script = pd.merge(df_script, df_characters, how='left', left_on='raw_character_text', right_on='name')\n\n# Merge locations into script\ndf_merged = pd.merge(df_chars_script, df_locations, how='left', left_on='raw_location_text', right_on='name')",
          " Preprocess data\n# Drop rows with missing values\ndf_script = df_script.dropna(subset=['character_id', 'location_id', 'raw_text'])\n\n# Merge dataframes\ndf_script_info = pd.merge(df_script, \n                          df_characters, \n                          how='left', \n                          on='character_id', \n                          suffixes=('_script', '_character'))\n\ndf_script_info = pd.merge(df_script_info, \n                          df_locations, \n                          how='left', \n                          on='location_id', \n                          suffixes=('_old', '_location'))",
          "Merge characters and script\ndf_characters_script = df_script.merge(df_characters, left_on='character_id', right_on='id')",
          " Merge the scripts with the corresponding characters and locations\ndf = df_script.merge(df_characters, 'left', on='character_id').merge(df_locations, 'left', on='location_id')",
          "Remove the rows with Nan in `uselocation_id` and `character_id` and merge with locations and characters respectively\ndf_script = df_script[(~df_script.uselocation_id.isna()) & (~df_script.character_id.isna())]\n\ndf_script = pd.merge(df_script, df_characters, left_on='character_id', right_on='raw_character_text')\ndf_script = pd.merge(df_script, df_locations, left_on='uselocation_id', right_on='raw_location_text')",
          "Concatenate location data\ndf_locations = pd.concat([df_locations, df_locations['image_url'].str.split(';', expand=True)], axis=1)\ndf_locations = df_locations.rename(columns={0: 'image_url_0', 1: 'image_url_1'})"
         ],
         "marker": {
          "opacity": 0.5,
          "size": 5
         },
         "mode": "markers+text",
         "name": "19_Merge characters and locations in script",
         "text": [
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          ""
         ],
         "textfont": {
          "size": 12
         },
         "type": "scattergl",
         "x": [
          16.328941345214844,
          16.79683494567871,
          16.91843032836914,
          16.880889892578125,
          16.934703826904297,
          16.40180015563965,
          16.929285049438477,
          16.886442184448242,
          16.708322525024414,
          16.627182006835938,
          16.627592086791992,
          16.823854446411133,
          16.7553653717041,
          16.776657104492188,
          16.85283851623535,
          16.91258430480957,
          16.742961883544922
         ],
         "y": [
          7.83400297164917,
          8.113709449768066,
          7.899691581726074,
          7.541343688964844,
          7.856141090393066,
          8.332087516784668,
          8.014825820922852,
          7.919136047363281,
          8.052458763122559,
          7.423878192901611,
          7.568443298339844,
          7.867867946624756,
          8.080918312072754,
          7.551226615905762,
          7.779621124267578,
          7.92085075378418,
          8.241056442260742
         ]
        },
        {
         "hoverinfo": "text",
         "hovertext": [
          "Check for missing values\ndf_episodes.isnull().sum()",
          "Check data integrity\nprint(df_characters.isnull().sum())\nprint(df_locations.isnull().sum())\nprint(df_script.isnull().sum())\nprint(df_episodes.isnull().sum())",
          " Check missing values in script dataframe\nprint(f'Missing values in script dataframe: {df_script.isnull().sum()}')",
          "Check for missing values in the script dataset\nmissing_values = df_script.isnull().sum()\nprint(missing_values)",
          "Explore data types and missing values",
          "Let's check how many null value we have for each dataframes",
          "Check out how many missing values there are in the script dataset\ndf_script.isnull().sum()",
          "Add dummy column so that we can simply take the mean\ndf_script['count'] = 1",
          "Visualize NaN (missing) values for each feature",
          "Get the missing values in the script dataset",
          "Check for null values in the scripts\ndf_script.isnull().sum()",
          "# Computing the number of missing values in the script dataframe\ndf_script.isnull().sum()",
          "Check for missing data\nprint(\"- Missing Data (Characters):\", df_characters.isnull().values.any())\nprint(\"- Missing Data (Locations):\", df_locations.isnull().values.any())\nprint(\"- Missing Data (Script):\", df_script.isnull().values.any())\nprint(\"- Missing Data (Episodes):\", df_episodes.isnull().values.any())",
          "Check for missing values",
          "check for null values in the data\ndf_characters.isnull().sum()",
          "Check for missing values\ndf_script.isnull().sum()"
         ],
         "marker": {
          "opacity": 0.5,
          "size": 5
         },
         "mode": "markers+text",
         "name": "20_Missing values in dataframes",
         "text": [
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          ""
         ],
         "textfont": {
          "size": 12
         },
         "type": "scattergl",
         "x": [
          10.847429275512695,
          10.630642890930176,
          10.92349910736084,
          10.897004127502441,
          10.67841625213623,
          12.333563804626465,
          10.945310592651367,
          11.315176963806152,
          10.97268009185791,
          10.854544639587402,
          10.959537506103516,
          11.007826805114746,
          10.737207412719727,
          10.771272659301758,
          10.728979110717773,
          11.020302772521973
         ],
         "y": [
          11.388335227966309,
          11.399225234985352,
          11.368672370910645,
          11.323335647583008,
          10.60669231414795,
          4.359701633453369,
          11.511581420898438,
          11.271415710449219,
          10.513066291809082,
          11.163202285766602,
          11.396634101867676,
          11.462307929992676,
          11.195086479187012,
          10.899145126342773,
          11.516335487365723,
          11.386303901672363
         ]
        },
        {
         "hoverinfo": "text",
         "hovertext": [
          " Split the script into tokens",
          "Preprocess script strings",
          " Take a look at the scripts data.",
          "Some script lines are not associated with a speaking character test that and remove it\n# ",
          "Divide the script in segments of a specific length",
          "Combine script with the characters speaking",
          "Tokenize the script by episode",
          "Extract the sentences from the first script line to analyze the sentiments and emotions associated with the text.",
          "Tokenize the text of the script lines.",
          " We need to merge the characters, locations and script datasets.",
          "Join the script with the characters and the locations",
          "Merge the script lines data with the characters and locations data to get comprehensive data for NLP analysis.",
          "For the script lines, let's focus on only the lines associated with characters, and not any stage directions.",
          "Define common entities for interpreting the script lines.",
          "Merge the script with characters and locations",
          " Tokenize script lines using Spacy"
         ],
         "marker": {
          "opacity": 0.5,
          "size": 5
         },
         "mode": "markers+text",
         "name": "21_Script Sentiment and Character Analysis",
         "text": [
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          ""
         ],
         "textfont": {
          "size": 12
         },
         "type": "scattergl",
         "x": [
          12.20760726928711,
          11.917876243591309,
          11.705174446105957,
          12.128374099731445,
          12.450159072875977,
          12.344499588012695,
          12.618449211120605,
          12.302029609680176,
          12.05229377746582,
          12.15128231048584,
          12.32158374786377,
          12.291790962219238,
          12.484692573547363,
          12.093661308288574,
          12.27127742767334,
          12.034957885742188
         ],
         "y": [
          7.8145928382873535,
          7.4662275314331055,
          7.480321407318115,
          7.782378673553467,
          7.61956262588501,
          7.565403938293457,
          7.765048027038574,
          7.1272149085998535,
          7.6364874839782715,
          7.444158554077148,
          7.507772445678711,
          7.160565376281738,
          7.5932722091674805,
          7.366555213928223,
          7.389638423919678,
          7.736891746520996
         ]
        },
        {
         "hoverinfo": "text",
         "hovertext": [
          "merge the required dataframes to have an easily accessible structure for script line data and enrich the structural data if necessary",
          "Merge the dataframes into one dataframe",
          "Cleaning the data",
          "Merging the datasets to access all relevant information in one dataframe.",
          "Data Cleaning",
          "Merge all datasets",
          "Merge the dataframes",
          "Join tables and clean data",
          "Merge and clean the datasets",
          "Merge the datasets",
          "Merge the datasets to obtain a single dataset that contains all information.",
          "Combine dataframes",
          " Merge dataframes",
          "Concatenate the dataframes to ease the processing",
          " First layers of filtering and cleaning"
         ],
         "marker": {
          "opacity": 0.5,
          "size": 5
         },
         "mode": "markers+text",
         "name": "22_Dataframe and Dataset Merging Techniques",
         "text": [
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          ""
         ],
         "textfont": {
          "size": 12
         },
         "type": "scattergl",
         "x": [
          11.903507232666016,
          11.835204124450684,
          11.11339282989502,
          11.546412467956543,
          11.155991554260254,
          11.454052925109863,
          11.816829681396484,
          11.339599609375,
          11.242829322814941,
          11.391351699829102,
          11.283090591430664,
          11.843792915344238,
          11.727551460266113,
          11.885650634765625,
          11.344768524169922
         ],
         "y": [
          9.98536205291748,
          10.148829460144043,
          9.195589065551758,
          10.127123832702637,
          9.220842361450195,
          9.987001419067383,
          10.114874839782715,
          9.442342758178711,
          9.716812133789062,
          10.040895462036133,
          10.018162727355957,
          10.209896087646484,
          10.164862632751465,
          10.283486366271973,
          9.299640655517578
         ]
        },
        {
         "hoverinfo": "text",
         "hovertext": [
          "Merge scripts with episode info\ndf_script_episode = df_script.merge(df_episodes, on='episode_id', how='outer')",
          "Filter episodes for season 1\ndf_episodes_seas1 = df_episodes[(df_episodes['original_air_year'] == 1989) & (df_episodes['season'] == 1)].sort_values('number_in_season')\n\n# Merge the filtered episodes with the scripts and characters\ndf_ep_script = df_script.merge(df_episodes_seas1, on='id', how='inner')\ndf_ep_script_chars = df_ep_script.merge(df_characters, left_on='character_id', right_on='id', how='left')",
          "Check if any scriptline would not have an episode\ndf_script['episode_id'].isin(df_episodes['id']).value_counts()",
          "DF slice\nepisode_7_script = df_script[df_script['episode_id'] == 7]\nepisode_7_script",
          "Filtering out episodes where the character is not present\nallowed_characters = set(df_characters['character_id'])\n\ndf_script['episode_id'] = df_script['episode_id'].astype('str')\nepisode_id, occurrences = np.unique(df_script['episode_id'], return_counts=True)\nepisode_id = list(episode_id)\nepisodes_character_present = []\n\nfor ep in tqdm(episode_id):\n    mentions = df_script[(df_script['episode_id'] == ep) & (df_script['character_id'].isin(allowed_characters))].shape[0]\n    if mentions > 0:\n        episodes_character_present.append(ep)\n\n# Subset episodes\ndf_episodes_filtered = df_episodes[df_episodes['id'].astype('str').isin(episodes_character_present)]",
          "Filter script dataframe for scenes: 1-15 (inclusive), season: 1, episode: 1\ndf_tmp = pd.DataFrame()\nfor scene in range(1, 16):\n    df_tmp = pd.concat([df_tmp, df_script[\n        (df_script['scene_number'] == scene) & \n        (df_script['season'] == 1) & \n        (df_script['episode_number'] == 1)]])\ndf_tmp.head()",
          "df_script = df_script[df_script[\"episode_id\"].notna()]",
          "ax = pd.cut(df_script['episode_id'], bins=len(df_episodes['id'].unique()), labels=False, retbins=False)",
          "Check if there is at least one other speaker in the same episode\ndf_script['there_is_a_pre_speaker'] = df_script.reset_index().apply(lambda x: 1 if x['episode_id'] in df_script[df_script['episode_id'] ==x['episode_id']]['speaker_id'].unique() else 0, axis=1)",
          "Filter by episode_id\ndf_script = df_script[df_script['episode_id'].isin(df_episodes['id'])]",
          "Filters invalid script lines and adds episodes to script\ndf_script = df_script[df_script['episode_id'].isin(df_episodes['id'])]",
          "Sort script dataframe by episode_id and then by id\ndf_script.sort_values(by=['episode_id', 'id'], inplace=True)",
          "Filter seasons to include 1-20 only\ndf_episodes = df_episodes[(df_episodes.season <= 20)]",
          "Check the number of lines per script for each episode\ndf_script['normalized_text'] = df_script['normalized_text'].str.strip()\ndf_script.groupby('episode_id').size()",
          "# Regroup by season\ndf_episodes_grouped = df_episodes.groupby('production_code').first()\ndf_episodes_grouped.reset_index(inplace=True)"
         ],
         "marker": {
          "opacity": 0.5,
          "size": 5
         },
         "mode": "markers+text",
         "name": "23_Script Filtering and Episode Analysis",
         "text": [
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          ""
         ],
         "textfont": {
          "size": 12
         },
         "type": "scattergl",
         "x": [
          15.713229179382324,
          15.201850891113281,
          14.850481033325195,
          15.103611946105957,
          14.99110221862793,
          14.80571174621582,
          14.907529830932617,
          15.047856330871582,
          14.834940910339355,
          14.881929397583008,
          14.757954597473145,
          15.22116756439209,
          14.490797996520996,
          14.60200309753418,
          15.417951583862305
         ],
         "y": [
          8.599082946777344,
          8.64816951751709,
          8.35120677947998,
          8.573010444641113,
          8.380090713500977,
          8.553680419921875,
          8.575559616088867,
          8.507671356201172,
          8.044926643371582,
          8.34758472442627,
          8.339752197265625,
          8.513819694519043,
          8.773750305175781,
          8.498072624206543,
          8.74969482421875
         ]
        },
        {
         "hoverinfo": "text",
         "hovertext": [
          "Create folders for cleaning process\nos.makedirs('data/clean_characters', exist_ok=True)\nos.makedirs('data/clean_locations', exist_ok=True)\nos.makedirs('data/clean_script', exist_ok=True)\nos.makedirs('data/clean_episodes', exist_ok=True)",
          "Check whether we have the correct scripts",
          "# Set directory path\ndir_path = 'data/visualization/'\n\n# Ensure directory exists\nif not os.path.exists(dir_path):\n    os.makedirs(dir_path)",
          "Setting the variable with the path for the project folder",
          "Define the path to the data directory and the output directory",
          "Set directory path for importing images\nimg_path = 'data/images/'",
          "Location of data folder\nDATA_PATH = \"data\"",
          " Create the 'simpsons' directory if it does not exist\ndirectory = 'simpsons'\nif not os.path.exists(directory):\n    os.makedirs(directory)",
          "Set output path for assets\nassets_out = 'output_assets'",
          "Directory of the scripts\nscripts_dir = 'scripts'",
          " PLease note that the file paths specified here assume that the current working directory is the root folder of the project. Adjust the paths accordingly if needed.",
          "Generically define data folder path for reading and writing notebooks\ndata_folder = 'data'"
         ],
         "marker": {
          "opacity": 0.5,
          "size": 5
         },
         "mode": "markers+text",
         "name": "24_Directory and Path Management",
         "text": [
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          ""
         ],
         "textfont": {
          "size": 12
         },
         "type": "scattergl",
         "x": [
          10.91554069519043,
          11.419693946838379,
          10.514376640319824,
          10.38225269317627,
          10.501730918884277,
          10.38918399810791,
          10.484816551208496,
          10.860072135925293,
          10.47916316986084,
          11.233208656311035,
          10.34127426147461,
          10.319051742553711
         ],
         "y": [
          6.902735710144043,
          7.508701801300049,
          6.5371785163879395,
          6.744001865386963,
          6.6817498207092285,
          6.565328598022461,
          6.782092094421387,
          6.652358055114746,
          6.545895576477051,
          7.0640339851379395,
          6.9203901290893555,
          6.828033924102783
         ]
        },
        {
         "hoverinfo": "text",
         "hovertext": [
          "Ensure all character names are in title format\ndf_characters.character_name = df_characters.character_name.str.title()\n\n# Ensure all raw_text elements are in string format\ndf_script.raw_text = df_script.raw_text.astype(str)",
          "encode characters\ndf_characters.fillna('', inplace=True)\ndf_characters['character_encoded'] = df_characters.character.str.replace('[^a-zA-Z\\d\\s:]', '').str.replace('\\s', '_').str.lower()",
          " Remove apostrophes from dataframe\ndf_characters = df_characters.replace({\"'\": ''}, regex=True)\ndf_locations = df_locations.replace({\"'\": ''}, regex=True)\ndf_script = df_script.replace({\"'\": ''}, regex=True)\ndf_episodes = df_episodes.replace({\"'\": ''}, regex=True)",
          "Remove any trailing whitespace from character names and location names in the character and location dataframes",
          "# Transforming character names into lowercase\ndf_characters['name'] = df_characters['name'].str.lower()",
          "Convert character and location names to lower case\ndf_characters['raw_character_text'] = df_characters['raw_character_text'].str.lower()\ndf_locations['raw_location_text'] = df_locations['raw_location_text'].str.lower()",
          " Convenience renaming\ndf_script = df_script.rename(columns={'raw_text':'text'})",
          "# Fix the character name and location name string by cleaning\ndf_script['character_name'] = df_script['character_name'].str.replace(r'\\s?', '', regex=True)\ndf_script['location_name'] = df_script['location_name'].str.replace(r'\\s?', '', regex=True)",
          " Convert raw text data to pandas dataframe",
          "Normalize name and title columns to lowercase\ndf_characters['name'] = df_characters['name'].str.lower()\ndf_locations['normalized_name'] = df_locations['normalized_name'].str.lower()\ndf_script['character_name'] = df_script['character_name'].str.lower()\ndf_script['raw_character_text'] = df_script['raw_character_text'].str.lower()\ndf_script['raw_location_text'] = df_script['raw_location_text'].str.lower()\ndf_episodes['title'] = df_episodes['title'].str.lower()",
          "Cleaning the character and location data.\ndf_characters = df_characters[df_characters['name'] != '?']"
         ],
         "marker": {
          "opacity": 0.5,
          "size": 5
         },
         "mode": "markers+text",
         "name": "25_Cleaning and Formatting Characters and Locations in Dataframes",
         "text": [
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          ""
         ],
         "textfont": {
          "size": 12
         },
         "type": "scattergl",
         "x": [
          16.029024124145508,
          15.964168548583984,
          16.132984161376953,
          16.3695011138916,
          16.027286529541016,
          16.14500617980957,
          16.044021606445312,
          16.35904312133789,
          16.134681701660156,
          15.8638916015625,
          16.291282653808594
         ],
         "y": [
          7.4123969078063965,
          7.16895055770874,
          9.519883155822754,
          7.348620891571045,
          7.210258483886719,
          7.319525718688965,
          7.748131275177002,
          7.487181186676025,
          7.551645278930664,
          7.6225996017456055,
          7.2096967697143555
         ]
        }
       ],
       "layout": {
        "annotations": [
         {
          "showarrow": false,
          "text": "D1",
          "x": -1.0701533138751984,
          "y": 4.469885039329529,
          "yshift": 10
         },
         {
          "showarrow": false,
          "text": "D2",
          "x": 9.825302752852439,
          "xshift": 10,
          "y": 15.240210008621215
         }
        ],
        "height": 1000,
        "shapes": [
         {
          "line": {
           "color": "#CFD8DC",
           "width": 2
          },
          "type": "line",
          "x0": 9.825302752852439,
          "x1": 9.825302752852439,
          "y0": -6.300439929962158,
          "y1": 15.240210008621215
         },
         {
          "line": {
           "color": "#9E9E9E",
           "width": 2
          },
          "type": "line",
          "x0": -1.0701533138751984,
          "x1": 20.720758819580077,
          "y0": 4.469885039329529,
          "y1": 4.469885039329529
         }
        ],
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "rgb(36,36,36)"
            },
            "error_y": {
             "color": "rgb(36,36,36)"
            },
            "marker": {
             "line": {
              "color": "white",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "white",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "rgb(36,36,36)",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "rgb(36,36,36)"
            },
            "baxis": {
             "endlinecolor": "rgb(36,36,36)",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "rgb(36,36,36)"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 1,
             "tickcolor": "rgb(36,36,36)",
             "ticks": "outside"
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 1,
             "tickcolor": "rgb(36,36,36)",
             "ticks": "outside"
            },
            "colorscale": [
             [
              0,
              "#440154"
             ],
             [
              0.1111111111111111,
              "#482878"
             ],
             [
              0.2222222222222222,
              "#3e4989"
             ],
             [
              0.3333333333333333,
              "#31688e"
             ],
             [
              0.4444444444444444,
              "#26828e"
             ],
             [
              0.5555555555555556,
              "#1f9e89"
             ],
             [
              0.6666666666666666,
              "#35b779"
             ],
             [
              0.7777777777777778,
              "#6ece58"
             ],
             [
              0.8888888888888888,
              "#b5de2b"
             ],
             [
              1,
              "#fde725"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 1,
             "tickcolor": "rgb(36,36,36)",
             "ticks": "outside"
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 1,
             "tickcolor": "rgb(36,36,36)",
             "ticks": "outside"
            },
            "colorscale": [
             [
              0,
              "#440154"
             ],
             [
              0.1111111111111111,
              "#482878"
             ],
             [
              0.2222222222222222,
              "#3e4989"
             ],
             [
              0.3333333333333333,
              "#31688e"
             ],
             [
              0.4444444444444444,
              "#26828e"
             ],
             [
              0.5555555555555556,
              "#1f9e89"
             ],
             [
              0.6666666666666666,
              "#35b779"
             ],
             [
              0.7777777777777778,
              "#6ece58"
             ],
             [
              0.8888888888888888,
              "#b5de2b"
             ],
             [
              1,
              "#fde725"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 1,
             "tickcolor": "rgb(36,36,36)",
             "ticks": "outside"
            },
            "colorscale": [
             [
              0,
              "#440154"
             ],
             [
              0.1111111111111111,
              "#482878"
             ],
             [
              0.2222222222222222,
              "#3e4989"
             ],
             [
              0.3333333333333333,
              "#31688e"
             ],
             [
              0.4444444444444444,
              "#26828e"
             ],
             [
              0.5555555555555556,
              "#1f9e89"
             ],
             [
              0.6666666666666666,
              "#35b779"
             ],
             [
              0.7777777777777778,
              "#6ece58"
             ],
             [
              0.8888888888888888,
              "#b5de2b"
             ],
             [
              1,
              "#fde725"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "line": {
              "color": "white",
              "width": 0.6
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 1,
             "tickcolor": "rgb(36,36,36)",
             "ticks": "outside"
            },
            "colorscale": [
             [
              0,
              "#440154"
             ],
             [
              0.1111111111111111,
              "#482878"
             ],
             [
              0.2222222222222222,
              "#3e4989"
             ],
             [
              0.3333333333333333,
              "#31688e"
             ],
             [
              0.4444444444444444,
              "#26828e"
             ],
             [
              0.5555555555555556,
              "#1f9e89"
             ],
             [
              0.6666666666666666,
              "#35b779"
             ],
             [
              0.7777777777777778,
              "#6ece58"
             ],
             [
              0.8888888888888888,
              "#b5de2b"
             ],
             [
              1,
              "#fde725"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 1,
             "tickcolor": "rgb(36,36,36)",
             "ticks": "outside"
            },
            "colorscale": [
             [
              0,
              "#440154"
             ],
             [
              0.1111111111111111,
              "#482878"
             ],
             [
              0.2222222222222222,
              "#3e4989"
             ],
             [
              0.3333333333333333,
              "#31688e"
             ],
             [
              0.4444444444444444,
              "#26828e"
             ],
             [
              0.5555555555555556,
              "#1f9e89"
             ],
             [
              0.6666666666666666,
              "#35b779"
             ],
             [
              0.7777777777777778,
              "#6ece58"
             ],
             [
              0.8888888888888888,
              "#b5de2b"
             ],
             [
              1,
              "#fde725"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 1,
             "tickcolor": "rgb(36,36,36)",
             "ticks": "outside"
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 1,
              "tickcolor": "rgb(36,36,36)",
              "ticks": "outside"
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 1,
              "tickcolor": "rgb(36,36,36)",
              "ticks": "outside"
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 1,
              "tickcolor": "rgb(36,36,36)",
              "ticks": "outside"
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 1,
              "tickcolor": "rgb(36,36,36)",
              "ticks": "outside"
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 1,
              "tickcolor": "rgb(36,36,36)",
              "ticks": "outside"
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 1,
              "tickcolor": "rgb(36,36,36)",
              "ticks": "outside"
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 1,
              "tickcolor": "rgb(36,36,36)",
              "ticks": "outside"
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 1,
              "tickcolor": "rgb(36,36,36)",
              "ticks": "outside"
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 1,
              "tickcolor": "rgb(36,36,36)",
              "ticks": "outside"
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 1,
              "tickcolor": "rgb(36,36,36)",
              "ticks": "outside"
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 1,
             "tickcolor": "rgb(36,36,36)",
             "ticks": "outside"
            },
            "colorscale": [
             [
              0,
              "#440154"
             ],
             [
              0.1111111111111111,
              "#482878"
             ],
             [
              0.2222222222222222,
              "#3e4989"
             ],
             [
              0.3333333333333333,
              "#31688e"
             ],
             [
              0.4444444444444444,
              "#26828e"
             ],
             [
              0.5555555555555556,
              "#1f9e89"
             ],
             [
              0.6666666666666666,
              "#35b779"
             ],
             [
              0.7777777777777778,
              "#6ece58"
             ],
             [
              0.8888888888888888,
              "#b5de2b"
             ],
             [
              1,
              "#fde725"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "rgb(237,237,237)"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "rgb(217,217,217)"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 1,
            "tickcolor": "rgb(36,36,36)",
            "ticks": "outside"
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "rgb(103,0,31)"
            ],
            [
             0.1,
             "rgb(178,24,43)"
            ],
            [
             0.2,
             "rgb(214,96,77)"
            ],
            [
             0.3,
             "rgb(244,165,130)"
            ],
            [
             0.4,
             "rgb(253,219,199)"
            ],
            [
             0.5,
             "rgb(247,247,247)"
            ],
            [
             0.6,
             "rgb(209,229,240)"
            ],
            [
             0.7,
             "rgb(146,197,222)"
            ],
            [
             0.8,
             "rgb(67,147,195)"
            ],
            [
             0.9,
             "rgb(33,102,172)"
            ],
            [
             1,
             "rgb(5,48,97)"
            ]
           ],
           "sequential": [
            [
             0,
             "#440154"
            ],
            [
             0.1111111111111111,
             "#482878"
            ],
            [
             0.2222222222222222,
             "#3e4989"
            ],
            [
             0.3333333333333333,
             "#31688e"
            ],
            [
             0.4444444444444444,
             "#26828e"
            ],
            [
             0.5555555555555556,
             "#1f9e89"
            ],
            [
             0.6666666666666666,
             "#35b779"
            ],
            [
             0.7777777777777778,
             "#6ece58"
            ],
            [
             0.8888888888888888,
             "#b5de2b"
            ],
            [
             1,
             "#fde725"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#440154"
            ],
            [
             0.1111111111111111,
             "#482878"
            ],
            [
             0.2222222222222222,
             "#3e4989"
            ],
            [
             0.3333333333333333,
             "#31688e"
            ],
            [
             0.4444444444444444,
             "#26828e"
            ],
            [
             0.5555555555555556,
             "#1f9e89"
            ],
            [
             0.6666666666666666,
             "#35b779"
            ],
            [
             0.7777777777777778,
             "#6ece58"
            ],
            [
             0.8888888888888888,
             "#b5de2b"
            ],
            [
             1,
             "#fde725"
            ]
           ]
          },
          "colorway": [
           "#1F77B4",
           "#FF7F0E",
           "#2CA02C",
           "#D62728",
           "#9467BD",
           "#8C564B",
           "#E377C2",
           "#7F7F7F",
           "#BCBD22",
           "#17BECF"
          ],
          "font": {
           "color": "rgb(36,36,36)"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "white",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "white",
          "polar": {
           "angularaxis": {
            "gridcolor": "rgb(232,232,232)",
            "linecolor": "rgb(36,36,36)",
            "showgrid": false,
            "showline": true,
            "ticks": "outside"
           },
           "bgcolor": "white",
           "radialaxis": {
            "gridcolor": "rgb(232,232,232)",
            "linecolor": "rgb(36,36,36)",
            "showgrid": false,
            "showline": true,
            "ticks": "outside"
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "white",
            "gridcolor": "rgb(232,232,232)",
            "gridwidth": 2,
            "linecolor": "rgb(36,36,36)",
            "showbackground": true,
            "showgrid": false,
            "showline": true,
            "ticks": "outside",
            "zeroline": false,
            "zerolinecolor": "rgb(36,36,36)"
           },
           "yaxis": {
            "backgroundcolor": "white",
            "gridcolor": "rgb(232,232,232)",
            "gridwidth": 2,
            "linecolor": "rgb(36,36,36)",
            "showbackground": true,
            "showgrid": false,
            "showline": true,
            "ticks": "outside",
            "zeroline": false,
            "zerolinecolor": "rgb(36,36,36)"
           },
           "zaxis": {
            "backgroundcolor": "white",
            "gridcolor": "rgb(232,232,232)",
            "gridwidth": 2,
            "linecolor": "rgb(36,36,36)",
            "showbackground": true,
            "showgrid": false,
            "showline": true,
            "ticks": "outside",
            "zeroline": false,
            "zerolinecolor": "rgb(36,36,36)"
           }
          },
          "shapedefaults": {
           "fillcolor": "black",
           "line": {
            "width": 0
           },
           "opacity": 0.3
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "rgb(232,232,232)",
            "linecolor": "rgb(36,36,36)",
            "showgrid": false,
            "showline": true,
            "ticks": "outside"
           },
           "baxis": {
            "gridcolor": "rgb(232,232,232)",
            "linecolor": "rgb(36,36,36)",
            "showgrid": false,
            "showline": true,
            "ticks": "outside"
           },
           "bgcolor": "white",
           "caxis": {
            "gridcolor": "rgb(232,232,232)",
            "linecolor": "rgb(36,36,36)",
            "showgrid": false,
            "showline": true,
            "ticks": "outside"
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "rgb(232,232,232)",
           "linecolor": "rgb(36,36,36)",
           "showgrid": false,
           "showline": true,
           "ticks": "outside",
           "title": {
            "standoff": 15
           },
           "zeroline": false,
           "zerolinecolor": "rgb(36,36,36)"
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "rgb(232,232,232)",
           "linecolor": "rgb(36,36,36)",
           "showgrid": false,
           "showline": true,
           "ticks": "outside",
           "title": {
            "standoff": 15
           },
           "zeroline": false,
           "zerolinecolor": "rgb(36,36,36)"
          }
         }
        },
        "title": {
         "font": {
          "color": "Black",
          "size": 22
         },
         "text": "Next Thing After Importing Data:",
         "x": 0.5,
         "xanchor": "center",
         "yanchor": "top"
        },
        "width": 1800,
        "xaxis": {
         "visible": false
        },
        "yaxis": {
         "visible": false
        }
       }
      },
      "text/html": [
       "<div>                            <div id=\"cfad44a6-b1a1-457c-ba57-2dbe0ca4d8b5\" class=\"plotly-graph-div\" style=\"height:1000px; width:1800px;\"></div>            <script type=\"text/javascript\">                require([\"plotly\"], function(Plotly) {                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"cfad44a6-b1a1-457c-ba57-2dbe0ca4d8b5\")) {                    Plotly.newPlot(                        \"cfad44a6-b1a1-457c-ba57-2dbe0ca4d8b5\",                        [{\"hoverinfo\":\"text\",\"hovertext\":[\"drop episode, movie and title. Additional cleanup.\",\"Let's take a look at the top few rows of each table.\",\" Creating a new column that combines the raw_text for the character uttering the text of the script line\\ndf_script = pd.merge(df_script, df_characters[['id', 'raw_character_text']], how='inner', left_on='character_id', right_on='id')\\n\\n# Cleaning\\ndf_script['raw_character_text'] = df_script['raw_character_text'].str.replace('The ', '')\\ndf_script['raw_character_text'] = df_script['raw_character_text'].str.replace('the ', '')\\ndf_script = df_script.drop('id', axis=1)\\n\\n# New column\\ndf_script['character_location'] = df_script['raw_character_text'] + ' ' + df_script['location_id'].fillna('').astype(str)\\n\\n# Query term\\nquery_term = 'Homer'\\n\\n# Subset data to include only those script lines uttered by the character with the specified name\\ndf_characters_search = df_script[df_script['raw_character_text'] == query_term].groupby(['episode_id'])['word_count'].sum().reset_index()\\n\\n# Include episode title\\ndf_characters_search = pd.merge(df_characters_search, df_episodes[['id', 'title', 'original_air_date']], how='inner', left_on='episode_id', right_on='id')\\n\\n# Clean\\ndf_characters_search = df_characters_search.sort_values(by='original_air_date').drop('id', axis=1)\\n\\n# Preview result\\ndf_characters_search\",\"Creating dataframes with the primary data types.\\ndf_script = df_script[['episode_id', 'number', 'raw_text', 'speaking_line', 'character_id', 'location_id']]\\ndf_episodes = df_episodes[['id', 'title', 'original_air_date']]\",\"Extract character lines and cast them to lowercase\\nlines = df_script[df_script['character_id'].notnull()]['normalized_text'].str.lower()\",\"Extract the id, name, and normalized_name columns\\ndf_characters[['id', 'name', 'normalized_name']].head()\",\"Creating a list of stopwords that we do not want to include in the analysis, as they do not provide valuable information.\",\"Join the dataset on the character and location with our script data into one dataframe to contain the MEAN sentiment for each sentence.\",\" optional: transform data into a more usable form)\",\"Check the content of the script lines dataframe and clean it\",\"Let's check if everything is okay\",\"Check the version of pandas being used\",\"Remove duplicate and na values from episode dataset.\",\" If there is a character NLP root name that is a stopword\\n# (e.g. 'arnold' is stopped by 'arn'), and we would like to search for it,\\n# we should search for \\\" arn\\\" instead of \\\"arn .\\\", if we want to find\\n# occurrences at the beginning of the sentence.\",\" Set the index of each dataframe with the 'id' column for faster query and access\",\" Replace NaN values with empty strings\\ndf_characters = df_characters.fillna('')\\ndf_locations = df_locations.fillna('')\\ndf_script = df_script.fillna('')\\ndf_episodes = df_episodes.fillna('')\",\"Hide irrelevant warnings\\nimport warnings\\nwarnings.filterwarnings('ignore', category=FutureWarning)\\nwarnings.filterwarnings('ignore', category=DeprecationWarning)\",\"Text cleaning\\n# Remove unused information\\ndf_script = df_script.drop(['id','episode_id', 'number'], axis=1)\\n\\n# Drop lines with missing values\\ndf_script = df_script.dropna()\\n\\n# Remove content in square brackets (often these are directions for the actor)\\ndf_script = df_script.replace('\\\\[.*?\\\\]', '', regex=True)\\n\\n# Special case (it's indeed lines that starts with space)\\ndf_script['raw_character_text'] = df_script['raw_character_text'].replace('^[ \\\\t]+', '', regex=True)\\n\\n# Special case (the character speaking is not always present)\\ndf_script.loc[df_script['raw_character_text'].str.len() \\u003e 50, 'raw_character_text'] = np.nan\\n\\n# Drop lines with missing values again\\ndf_script = df_script.dropna()\",\"Question 1: What are the most common words used by each character?\",\"To check the contents of the datasets, I can take a look at the first few rows of each DataFrame.\",\"# Number of unique characters\\nlen(df_characters['raw_character_text'].unique())\",\"Convert column to Categories for Locations and Characters\\ndf_script['raw_location'] = df_script['raw_location'].astype('category')\\ndf_script['raw_character_text'] = df_script['raw_character_text'].astype('category')\",\"Clean the script by deleting rows with no character specified or no dialogues.\",\"Remove null characters from script data\\ndf_script.dropna(subset = [\\\"normalized_text\\\"], inplace=True)\",\"Selecting only the dialogues from the script data\\ndf_script = df_script[pd.notnull(df_script['raw_text'])]\\n\\ndf_script = df_script[['episode_id', 'raw_text']]\\n\\ndf_script.head(10)\",\"\\n# Create a mapping between character name -\\u003e character_id\\nchar_map = {row.character_name: row.character_id for row in df_characters.itertuples()}\",\"# to ensure compatibility of pandas with spacy\\nimport warnings\\nwarnings.filterwarnings(\\\"ignore\\\", category=FutureWarning)\",\"The columns used for the relationship between the different datasets are:\\n# df_script -\\u003e speaking_line, character_id, location_id, episode_id\\n# df_characters -\\u003e id, name\\n# df_locations -\\u003e id, name\\n# df_episodes -\\u003e id, title\",\" Join episodes dataframe to the script dataframe\",\"Define some constants to make the code more understandable and easier to change\",\" Data Preprocessing\",\"# Convert time stamps to datetime objects\\ndf_script['timestamp_in_ms'] = pd.to_datetime(df_script['timestamp_in_ms'], unit='ms')\\n\\n# Selecting only relevant columns from the script dataframe\\ndf_script = df_script[['raw_text', 'speaking_line', 'character_id', 'location_id', 'episode_id', 'timestamp_in_ms']]\\n\\ndf_script.head()\",\"Check character names for spelling errors\\ndf_characters['raw_character_text'] = df_characters['raw_character_text'].str.lower()\\ndf_characters['raw_character_text'].nunique(), df_characters['raw_character_text'].unique()\",\"Set timestamps to be datetime objects\",\" Since the input seems to be a continuation of the code, I will provide the next steps.\",\"Remove NaN values from the dataframes\\ndf_characters = df_characters.dropna()\\ndf_locations = df_locations.dropna()\\ndf_script = df_script.dropna()\\ndf_episodes = df_episodes.dropna()\",\"Clean the script dataframe\\n# Remove leading\\u002ftrailing whitespaces\\ndf_script = df_script.apply(lambda x: x.str.strip() if x.dtype == \\\"object\\\" else x)\",\" I will add more code here...\",\"Filter NaN values for talking_text\\ndf_script = df_script.dropna(subset=['talking_text'])\",\"Encode character names as integers\\ndef encode_char(string):\\n    try:\\n        return char2int[string]\\n    except:\\n        return -1\",\"Remove unnecessary columns and data from the script dataframe\\ndf_script = df_script.drop(columns=['id', 'number', 'raw_text', 'timestamp_in_ms'])\\ndf_script = df_script.dropna()\",\"Filter only the script lines\\ndf_script_lines = df_script[['id', 'episode_id', 'number', 'raw_text', 'timestamp_in_ms', 'speaking_line', 'character_id', 'location_id', 'raw_character_text', 'raw_location_text']]\",\" We'll replace NaN values with empty strings\\ndf_script = df_script.fillna('')\\n\\n# Also replace NaN objects with 0 for simpler numeric processing in the future\\ndf_episodes = df_episodes.fillna(0)\",\"Check data date ranges\",\" Text cleaning and preprocessing\",\"...and so on\",\" Let's see the first three columns of each table.\",\"# Merge script lines with episodes data to get season and episode information\\ndf_script = pd.merge(df_script, df_episodes, on='episode_id')\",\"Create a subset of characters' lines\\ndf_main_characters = df_characters[df_characters['name'].isin(['Marge Simpson', 'Lisa Simpson', 'Bart Simpson', 'Homer Simpson', 'Maggie Simpson'])]\\ndf_main_characters.reset_index(inplace=True, drop=True)\\n\\n# Join the characters' lines with the script lines to obtain the text\\ndf_main_characters_lines = pd.merge(df_script, df_main_characters, left_on='character_id', right_on='character_id', how='inner')\",\"Visualizing the most frequent words in script lines\",\"Most used characters\\nmost_used_characters = df_script['character_id'].value_counts().index.tolist()\\nmost_used_characters_counts = df_script['character_id'].value_counts().tolist()\",\"Remove some un-necessary columns\\ndf_script = df_script.drop(df_script.columns[[0, 2, 3, 4, 7, 8, 9, 10, 11, 12, 13]], axis=1)\",\"Create a dictionary to map character ids to character names\\ncharacter_name_mapper = dict(zip(df_characters['id'], df_characters['name']))\",\"Remove rows in the script dataframe with empty and non-ASCII lines\",\"Remove the columns we won't be using\\ndf_script = df_script.drop(columns=['id', 'episode_id', 'number', 'raw_text', 'timestamp_in_ms', 'speaking_line', 'character_id'])\",\"Extract all lines of dialogues and their respective episode\\ndf_dialogues = df_script[['episode_id', 'raw_text']]\",\" Drop rows with missing values in the columns of interest\\ndf_script = df_script.dropna(subset=['normalized_text'])\",\"# Removing columns for practicality\\ndf_script = df_script[['episode_id', 'number', 'raw_text']]\",\"Parsing date columns\",\"...\",\"Perform any necessary data preprocessing\\n\",\"Dropping skippable columns to preserve memory\\ndf_script.drop(columns=['number', 'raw_text', 'timestamp_in_ms', 'speaking_line', 'character_image_url', 'location_id', 'spoken_words', 'normalized_text'], inplace=True)\",\" Let's see what each dataframe looks like\",\"Dropping irrelevant columns from dataframe\\ndf_script = df_script.drop(columns=['raw_text', 'timestamp_in_ms', 'speaking_line', 'character_id'])\",\"Extract words from script lines\\nscript_lines = df_script['normalized_text'].dropna().values.tolist()\",\"Inspecting the first 5 entries.\",\"Drop rows (records) with missing values from the 'episode_id' and 'name' columns in the script data\\ndf_script = df_script.dropna(subset=['episode_id', 'name'])\",\"Convert timestamp_in and timestamp_out fields into datetime type\",\" We will start by cleaning the dataset.\",\"Check for duplicates in 'id' column in all dataframes\",\"extract the dialog lines\\ndf_lines = df_script[df_script[\\\"speaking_line\\\"]]\\ndf_lines = df_lines.merge(df_episodes, left_on=\\\"episode_id\\\", right_on=\\\"id\\\")\\ndf_lines = df_lines.sort_values([\\\"id_x\\\", \\\"timestamp_in_ms\\\"])\",\"Select main character\\nmain_character = \\\"Marge Simpson\\\"\",\"Create script for a specific episode\\n\\tscript_s10e11 = df_script[df_script['episode_id'] == 211].copy()\\n\\tscript_s10e11.sort_values('timestamp_in_ms', inplace=True)\\n\\tscript_s10e11.reset_index(drop=True, inplace=True)\",\"Creating two lists from the script dataframe\\nscene_texts = list(df_script.str.values)\\nscene_locations = list(df_script.raw_location_text.values)\",\"Checking and printing a top of each dataframe\",\"Select character lines said by Homer\\ndf_homer = df_script[df_script[\\\"character_id\\\"] == df_characters[df_characters[\\\"name\\\"] == \\\"homer_simpson\\\"].iloc[0][\\\"id\\\"]]\",\"Characters grouped by gender\\ndf_characters['gender'].value_counts().plot(kind='bar')\\nplt.title('Number of Characters by Gender')\",\"import warnings\\nwarnings.filterwarnings(\\\"ignore\\\")\",\" Add the colon character at the end of the previous line as it appears we are defining a block of code.\",\"Create dictionaries with the index as the key and the row as the value for each dataframe\",\"convert episode air dates to datetime\\ndf_episodes['air_date'] = pd.to_datetime(df_episodes['air_date'])\",\"List of all conversation lines\",\"Checking the first few records for values and counts\",\"NLP model, only keep rows with some non-null values\\nnlp = spacy.load('en_core_web_sm')\\n\\ndf_script = df_script.dropna(subset=['raw_text']).reset_index(inplace=False, drop=True)\",\"2c. Convert date and time columns to datetime objects\",\"Check number of rows in each dataframe\",\" Drop lines where \\\"character_id\\\" and \\\"location_id\\\" is NaN\\ndf_script.dropna(subset=['character_id', 'location_id'], inplace=True)\",\" The show started on December 17, 1989, and so we have data only from 1989 onward.\",\" Format date\\ndf_episodes['original_air_date'] = pd.to_datetime(df_episodes['original_air_date'])\",\"Remove additional index column from the datasets\\ndf_characters.drop(df_characters.columns[0], axis=1, inplace=True)\\ndf_locations.drop(df_locations.columns[0], axis=1, inplace=True)\\ndf_script.drop(df_script.columns[0], axis=1, inplace=True)\\ndf_episodes.drop(df_episodes.columns[0], axis=1, inplace=True)\",\"Remove bad script data\\ndf_script = df_script.dropna(subset=['normalized_text'])\\ndf_script = df_script[df_script['timestamp_in_ms'] != 0]\",\"Extract reviews and movie titles\\nreviews = df_script[df_script['raw_text'].str.contains('Moe_Szyslak', case=False)]\\n\\n# Clean up\\n# Handling NA values\\nreviews = reviews.dropna(subset=['raw_text'])\\n\\n# Select only relevant columns\\nreviews = reviews[['episode_id', 'timestamp_in_ms', 'raw_text']]\\n\\n# Replace any instances of Moe Szyslak\\nmoe_aliases = ['Moe_Szyslak', 'Moe \\\"Moe\\\" Szyslak']\\nreviews['raw_text'] = reviews['raw_text'].str.replace('|'.join(moe_aliases), 'moe_szyslak', case=False)\",\" Clean a bit the datasets\\ndf_characters = df_characters[['id', 'name', 'normalized_name']].drop_duplicates(subset=['id'])\\n\\n# Build a list of character's id\\ncharacters_id = list(df_characters.id)\\n\\n# Clean the scripts a bit\\ndf_script = df_script.dropna(subset=['character_id', 'raw_text'])\\ndf_script = df_script[df_script.character_id.isin(characters_id)]\",\"Create a binary column in characters dataframe and set it to True\\n# if character is in script, from vadimkantor github page\\ncharacters = df_characters[df_characters['id'].isin(df_script['character_id'])]\",\"Visualizing the number of lines for the top 10 characters\\ntop_10_characters = df_script['character_id'].value_counts().head(10)\\n\\nfig, ax = plt.subplots(figsize=(10,5))\\nax.bar(top_10_characters.index, top_10_characters.values)\\n\\nax.set_xlabel('Character ID')\\nax.set_ylabel('Number of lines')\\nax.set_title('Number of lines for the top 10 characters')\\n\\nplt.show()\",\"Check a few of the scene settings - note some variation in capitalisation so will set lower case\",\"The first thing we can do is to take a peek at each of these tables using the head method.\",\" Transform float seasons to int\\ndf_episodes['season'] = df_episodes['season'].astype(int)\",\"drop Unnamed: 0 and id with reset_index(inplace=False, drop=True)\",\"Container of unique Table Styles for survival guide.\",\"Filter the data to only include the 4 main characters: Homer, Marge, Bart, Lisa.\",\"Filter out characters and location from the script dataframe that are not in the respective character and location dataframes\",\"Visualize the top-10 characters by frequency in the dataset\",\"Remove 'The Simpsons Movie' because it is acting as a duplicate\\ndf_episodes = df_episodes[df_episodes['title'] != 'The Simpsons Movie'].reset_index(inplace=False, drop=True)\",\" Change \\\"timestamp_in_ms\\\" and \\\"timestamp_in_ms\\\" to datetime\\ndf_script['timestamp_in_ms'] = pd.to_datetime(df_script['timestamp_in_ms'], unit='ms')\\ndf_script['timestamp_in_ms'] = pd.to_datetime(df_script['timestamp_in_ms'], errors='ignore')\",\"Dropping episodes without a script available\\ndf_episodes = df_episodes.dropna(subset=['normalized_text'])\",\" Check sets of character IDs\\nset(df_script['character_id'].unique()).intersection(set(df_characters['id'].unique()))\",\"Remove duplicate entries\\ndf_characters = df_characters.drop_duplicates(subset=['id']).reset_index(drop=True)\\ndf_locations = df_locations.drop_duplicates(subset=['id']).reset_index(drop=True)\\ndf_script = df_script.drop_duplicates(subset=['id']).reset_index(drop=True)\\ndf_episodes = df_episodes.drop_duplicates(subset=['id']).reset_index(drop=True)\",\"Convert the date column to datetime format\\ndf_episodes['date'] = pd.to_datetime(df_episodes['original_air_date'])\",\"fillna for script\\ndf_script.fillna('', inplace=True)\",\"# And improve speed by reducing the amount of data we're working on\\nmain_characters_list = df_characters[df_characters['normalized_name'].str.contains('simpson')]['id'].to_list()\\nmain_characters_list += [1, 2, 9, 8, 2, 155, 3, 206, 7]  # Main characters + 2 characters plus important\\n\\ndf_script_reduced = df_script[df_script['character_id'].isin(main_characters_list)]\",\"Transform data from strings to categories\",\" Check the content of the first few lines.\",\" Cleaning script file\",\"Create a dictionary to store character lines\\nlines_by_characters = {}\\n\\n# Group script lines by character\\nfor index, row in df_script.iterrows():\\n    # Retrieving variables from the current line\\n    character_id = row['character_id']\\n    character_name = df_characters.loc[df_characters['id'] == character_id, 'name'].values[0]\\n    line = row['raw_text']\\n    \\n    # Add character to the dictionary if not present\\n    if not character_name in lines_by_characters:\\n        lines_by_characters[character_name] = []\\n    \\n    # Add the line to the character in the dictionary\\n    lines_by_characters[character_name].append(line)\",\"Hide warnings for clearer output\\nimport warnings\\nwarnings.filterwarnings('ignore')\",\" Select only Homer's lines to make the conversation more comprehendible and simplify the pre-processing\",\"Filter the dataframe with not null values for the lines and normalize the text to lowercase\",\"Remove redundancy in the script lines dataframe and filter for the main characters\",\"Let's keep only the essential lines of the script (dialogue) and reset the index.\",\"Bring all necessary pandas libraries to perform the imports correctly\",\"Remove duplicates from script DataFrame\\ndf_script = df_script.drop_duplicates(subset=['id']).reset_index(inplace=False, drop=True)\",\"Replace NaN\\ndf_script.fillna('', inplace=True)\",\"Data loading and preprocessing\",\"Replace NaN values with empty string\\ndf_script = df_script.replace(np.nan, '', regex=True)\",\"Removing minor characters\\nmajor_characters = [\\n    'marge','homer','bart','lisa','maggie',\\n    'moe','carl','lenny','ned','krusty',\\n    'chief wiggum','skinner','patty','selma',\\n    'abraham','mrburns','milhouse','apu','barney',\\n    'sideshow bob','nelson','ralph'\\n]\\n\\ndf_script_major = df_script[df_script['raw_character_text'].str.lower().isin(major_characters)].copy()\",\"Visualize a few example rows of each dataframe to understand the data structure\\ndf_characters.head()\",\"Merge episodes and script data\\ndf_script_episodes = pd.merge(df_script, df_episodes, on='episode_id', how='left')\\n\\n# Display the first few items in the merged DataFrame\\ndf_script_episodes.head()\",\"Remove duplicate script lines and drop useless columns\\ndf_script = df_script.drop_duplicates(subset=['episode_id', 'number_in_episode'])\\ndf_script = df_script.drop(columns=['id', 'timestamp_in_ms', 'raw_text', 'spoken_words', 'normalized_text', 'word_count'])\",\"Create a toy dataframe to demonstrate the aggregation possibilities\\nd = {\\n    'name': ['Homer', 'Bart', 'Flanders', 'Marge', 'Lisa', 'Maggie'],\\n    'gender': ['m', 'm', 'm', 'f', 'f', 'f'],  # m: male, f: female\\n    'age': [36, 10, 60, 34, 8, 1],\\n    'quote': ['D\\\\'oh!', 'Eat my shorts', 'Hi-dilly-ho, neighborinos', 'Hmm', 'If anyone wants me, I\\\\'ll be in my room', ' '],\\n    'job': ['Nuclear safety inspector', 'Student', 'Owner of the Leftorium', 'Homemaker', 'Student', ' '],\\n    'location': ['742 Evergreen Terrace', '742 Evergreen Terrace', '744 Evergreen Terrace', '742 Evergreen Terrace', '742 Evergreen Terrace', '742 Evergreen Terrace']\\n}\\ndf_toy = pd.DataFrame(data=d)\",\" Remove unwanted fields from df_script dataframe\\ndf_script = df_script[['id', 'episode_id', 'number', 'raw_text', 'speaking_line', 'character_id', 'location_id']].copy()\",\"Filter only lines that contain a character\\ndf_script = df_script[df_script['raw_character_text'].notna()]\\n\\n# Let's remove unwanted characters from the script\\ndf_script['raw_text'] = df_script['raw_text'].str.replace(\\\"\\\\[.*\\\\]\\\", \\\"\\\").str.replace('\\\\n', ' ')\\n\\n# Apply spaCy's NLP to the script's lines. This might take a while...\\nnlp = spacy.load(\\\"en_core_web_sm\\\")\\ndf_script['nlp'] = list(tqdm(nlp.pipe(df_script['raw_text'], disable=[\\\"parser\\\"])))\",\"Limit dataset to those lines with characters speaking and are present in episodes dataset\\ndf_script = df_script[(df_script.speaking_line == True) &\\n                      (df_script.episode_id.isin(df_episodes.index))]\",\"# Remove special characters\\ndf_script['normalized_text'] = df_script['normalized_text'].str.replace(r'[^A-Za-z\\\\s]', '').str.lower()\",\"Now we have successfully loaded the datasets into pandas dataframes.\",\"Remove bad rows from script dataframe\",\"Remove empty lines in the script\\ndf_script = df_script.dropna(subset=['normalized_text'])\",\"Prepare data for NLP tasks\\ndf = df_script[['normalized_text', 'episode_id','character_id']]\\ndf = df.dropna()\\ndf.reset_index(drop=True, inplace=True)\",\"Select main character names for filtering later\",\" Walk through the entire dataframe and remove spacing around each cell\\nfor column in df_script.columns:\\n    df_script[column] = df_script[column].apply(lambda x: x.strip())\",\"Next, we'll analyze the scripts to find the most common words used by each character.\",null],\"marker\":{\"color\":\"#CFD8DC\",\"opacity\":0.5,\"size\":5},\"mode\":\"markers+text\",\"name\":\"other\",\"showlegend\":false,\"x\":[14.784468650817871,8.782552719116211,16.09589385986328,15.399581909179688,15.099934577941895,16.204769134521484,8.165989875793457,12.807180404663086,10.819150924682617,11.906885147094727,10.427976608276367,12.943852424621582,13.964313507080078,12.694559097290039,15.218306541442871,15.22984504699707,8.11804485321045,14.672380447387695,10.443682670593262,11.79755687713623,15.521859169006348,16.309236526489258,12.129671096801758,14.270599365234375,14.487558364868164,16.410207748413086,8.099252700805664,15.604280471801758,15.76136302947998,11.146031379699707,10.73110580444336,14.192940711975098,15.788545608520508,13.833696365356445,11.212892532348633,15.034764289855957,13.768792152404785,11.2212553024292,14.857532501220703,15.990585327148438,14.18886947631836,14.611000061035156,14.848505020141602,13.175745010375977,11.181014060974121,10.329833984375,8.761530876159668,15.382184982299805,15.46304988861084,10.537100791931152,15.43797779083252,14.416647911071777,16.311279296875,13.075213432312012,14.489923477172852,14.682424545288086,14.027873039245605,14.62777328491211,13.630001068115234,10.59459114074707,10.687055587768555,14.136072158813477,11.668334007263184,14.204033851623535,14.278491020202637,11.37519645690918,14.43997859954834,13.838968276977539,10.438036918640137,15.329241752624512,15.313207626342773,13.150273323059082,15.146193504333496,16.46379280090332,12.092573165893555,15.069393157958984,11.280926704406738,8.299729347229004,11.412463188171387,15.503483772277832,14.290390014648438,13.633973121643066,9.895004272460938,14.246204376220703,13.84125804901123,12.347296714782715,15.191182136535645,13.481313705444336,14.239947319030762,15.165956497192383,13.931346893310547,14.591638565063477,15.644303321838379,16.29178237915039,11.354665756225586,12.583858489990234,8.773667335510254,14.380669593811035,12.633407592773438,8.659427642822266,12.691252708435059,16.07899284362793,11.323486328125,15.333574295043945,14.025957107543945,14.41462516784668,15.7870512008667,15.534926414489746,14.205327033996582,14.910604476928711,15.480599403381348,15.756157875061035,11.042181968688965,11.581169128417969,15.686927795410156,8.204939842224121,13.850236892700195,14.725687980651855,14.82672119140625,12.193662643432617,10.664156913757324,15.304366111755371,14.854305267333984,10.601229667663574,14.699347496032715,15.399669647216797,11.137874603271484,15.624004364013672,14.739594459533691,15.716556549072266,14.906667709350586,14.256844520568848,14.618480682373047,15.55684757232666,10.616578102111816,12.741581916809082,14.050795555114746,14.689787864685059,12.963850975036621,13.42023754119873,10.416640281677246,13.444396018981934],\"y\":[9.12549877166748,7.91491174697876,7.883766174316406,9.506765365600586,7.789941787719727,6.96633243560791,7.07426643371582,7.190088748931885,9.175493240356445,8.107933044433594,8.17011833190918,4.1958417892456055,8.409939765930176,6.634126663208008,7.734169960021973,9.914955139160156,6.774163722991943,8.936098098754883,2.4401419162750244,4.834652423858643,6.6818366050720215,7.607125759124756,8.083905220031738,8.674663543701172,8.001882553100586,7.215194225311279,6.713592052459717,10.075206756591797,9.153422355651855,8.017685890197754,9.100700378417969,9.499570846557617,6.874443531036377,9.710576057434082,8.0972261428833,9.639947891235352,9.106473922729492,7.9670538902282715,9.29337215423584,6.744905948638916,9.058316230773926,7.9030351638793945,9.852031707763672,9.220333099365234,8.96219539642334,8.6517915725708,7.899346351623535,8.892067909240723,7.261162281036377,2.929699420928955,6.903212070465088,9.09163761138916,7.028648376464844,8.937597274780273,9.019733428955078,7.9727702140808105,8.796242713928223,8.629871368408203,9.62517261505127,8.74600887298584,8.958169937133789,8.601425170898438,4.554985523223877,8.938517570495605,8.610694885253906,3.1337311267852783,8.804198265075684,9.793281555175781,9.015603065490723,7.667154788970947,8.311521530151367,6.721968173980713,8.746688842773438,9.335539817810059,3.20858097076416,7.315923690795898,0.912340521812439,6.865704536437988,7.974765777587891,7.735747814178467,9.85560417175293,7.1608405113220215,7.841956615447998,8.25556468963623,9.799840927124023,3.8136677742004395,9.34299087524414,8.726293563842773,9.742441177368164,9.210933685302734,9.063196182250977,8.904255867004395,7.3352227210998535,7.1138834953308105,0.5916918516159058,8.022459983825684,7.785797595977783,9.840388298034668,8.684138298034668,7.493310928344727,6.5843610763549805,7.550699710845947,0.37022513151168823,8.902853012084961,9.55221939086914,9.117255210876465,7.138205528259277,8.422290802001953,9.715902328491211,9.73783016204834,7.1269965171813965,7.623737812042236,8.050836563110352,7.97429895401001,7.373669624328613,6.736695766448975,7.047903060913086,8.092915534973145,7.835375785827637,8.01716423034668,5.448960781097412,7.830342769622803,9.88072681427002,8.855267524719238,9.598041534423828,7.216373920440674,-0.0050086998380720615,8.847918510437012,8.797457695007324,8.023109436035156,8.736595153808594,7.912976264953613,7.847292900085449,7.474494934082031,5.357010841369629,9.05893611907959,8.72687816619873,8.97971248626709,6.747644901275635,9.067753791809082,2.4444515705108643,7.7590651512146],\"type\":\"scattergl\"},{\"hoverinfo\":\"text\",\"hovertext\":[\"View the first lines of each dataframe\\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()\",\"Check data shape\\nprint(f'Characters shape: {df_characters.shape}')\\nprint(f'Locations shape: {df_locations.shape}')\\nprint(f'Script shape: {df_script.shape}')\\nprint(f'Episodes shape: {df_episodes.shape}')\",\"Display the loaded DataFrames\\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()\",\" Show head of each DataFrame\\nprint('\\\\nCharacters:')\\ndisplay(df_characters.head())\\nprint('\\\\nLocations:')\\ndisplay(df_locations.head())\\nprint('\\\\nScript:')\\ndisplay(df_script.head())\\nprint('\\\\nEpisodes:')\\ndisplay(df_episodes.head())\",\"display(df_characters.head())\\ndisplay(df_locations.head())\\ndisplay(df_script.head())\\ndisplay(df_episodes.head())\",\"Numer of episodes\\nn_episodes = df_episodes.shape[0]\",\"Length of DataFrames\\nprint('Number of characters:', len(df_characters))\\nprint('Number of locations:', len(df_locations))\\nprint('Number of script lines:', len(df_script))\\nprint('Number of episodes:', len(df_episodes))\",\" Check data shapes\\nprint(df_characters.shape)\\nprint(df_locations.shape)\\nprint(df_script.shape)\\nprint(df_episodes.shape)\",\" Set pandas to display all columns when showing DataFrames\\npd.set_option('display.max_columns', None)\\n\\n# Select only the Simpsons-related characters\\ndf_characters = df_characters[(df_characters['in_simpsons'] == True) & (df_characters['in_movies'] == False)]\\ndf_locations = df_locations[(df_locations['in_simpsons'] == True) & (df_locations['in_movies'] == False)]\",\"Explore the dataframe structure and some samples\\nprint(f\\\"Characters: {len(df_characters):,}\\\")\\nprint(f\\\"Locations: {len(df_locations):,}\\\")\\nprint(f\\\"Script lines: {len(df_script):,}\\\")\\nprint(f\\\"Episodes: {len(df_episodes):,}\\\")\\n\\ndf_script.head(5)\",\"Testing if everything is loaded properly\\nprint(\\\"Characters\\\")\\nprint(df_characters.head())\\nprint(\\\"\\\\nLocations\\\")\\nprint(df_locations.head())\\nprint(\\\"\\\\nScript\\\")\\nprint(df_script.head())\\nprint(\\\"\\\\nEpisodes\\\")\\nprint(df_episodes.head())\",\"# Clustering the locations\\ndf_location_clusters = pd.read_csv('data\\u002fsimpsons_location_clusters.csv')\\ndf_location_clusters.head()\",\"Display up to 7 rows and all columns of each DataFrame for better visual inspection\\nfor df in [df_script, df_characters, df_locations, df_episodes]:\\n    display(df.head(7))\",\"Check if the DataFrames were loaded correctly\\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()\",\"Displaying imported data frames\\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()\",\"Preview the datasets\\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()\",\"head() of each of the DataFrames\\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()\",\" Data samples\\ndf_episodes.head()\",\" Checking dataframe shapes\\nprint(\\\"Characters:\\\", df_characters.shape)\\nprint(\\\"Locations:\\\", df_locations.shape)\\nprint(\\\"Script:\\\", df_script.shape)\\nprint(\\\"Episodes\\\", df_episodes.shape)\",\" Print the shape of the datasets\\nprint(f'The script dataset has {df_script.shape[0]} rows and {df_script.shape[1]} columns')\\nprint(f'The characters dataset has {df_characters.shape[0]} rows and {df_characters.shape[1]} columns')\\nprint(f'The locations dataset has {df_locations.shape[0]} rows and {df_locations.shape[1]} columns')\\nprint(f'The episodes dataset has {df_episodes.shape[0]} rows and {df_episodes.shape[1]} columns')\",\" Display the first 5 rows of each table to understand the structure and relation between them\\nprint('Characters table')\\nprint(df_characters.head(), '\\\\n')\\nprint('Locations table')\\nprint(df_locations.head(), '\\\\n')\\nprint('Episodes table')\\nprint(df_episodes.head(), '\\\\n')\\nprint('Script table')\\nprint(df_script.head())\",\"Print out the first few records of each table\\nprint('Characters')\\nprint(df_characters.head())\\nprint('Locations')\\nprint(df_locations.head())\\nprint('Script Lines')\\nprint(df_script.head())\\nprint('Episodes')\\nprint(df_episodes.head())\",\"Look at the content of each DataFrame\\nprint('Characters:')\\ndisplay(df_characters.head(3))\\nprint('Locations:')\\ndisplay(df_locations.head(3))\\nprint('Script:')\\ndisplay(df_script.head(3))\\nprint('Episodes:')\\ndisplay(df_episodes.head(3))\",\"print(df_characters.head())\\nprint(df_locations.head())\\nprint(df_script.head())\\nprint(df_episodes.head())\",\"Check if the files were loaded correctly\\nprint(df_characters.head())\\nprint(df_locations.head())\\nprint(df_script.head())\\nprint(df_episodes.head())\",\"# Display available datasets\\nprint(\\\"Characters\\\")\\nprint(df_characters.head())\\nprint(\\\"\\\\nLocations\\\")\\nprint(df_locations.head())\\nprint(\\\"\\\\nScript\\\")\\nprint(df_script.head())\\nprint(\\\"\\\\nEpisodes\\\")\\nprint(df_episodes.head())\",\"# Let's first display the size and memory usage of the datasets\\ndatasets = {\\n    'Characters': df_characters,\\n    'Locations': df_locations,\\n    'Script': df_script,\\n    'Episodes': df_episodes\\n}\\n\\nfor name, data in datasets.items():\\n    print(f\\\"{name}: {data.shape} - {data.memory_usage().sum() \\u002f 1024**2:.2f} MiB\\\")\",\"# Windows specific fix for pathing issues\\nif os.name == 'nt':\\n    df_episodes['image_url'] = df_episodes['image_url'].str.replace('\\u002f\\u002f\\u002fC', 'C:\\u002f')\",\"check first few rows of each table\\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()\",\" Check the first few entries of each dataframe to understand their structure and contents\\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()\",\"Show dataframes shape\\nprint(f\\\"Characters: {df_characters.shape}\\\")\\nprint(f\\\"Locations: {df_locations.shape}\\\")\\nprint(f\\\"Script: {df_script.shape}\\\")\\nprint(f\\\"Episodes: {df_episodes.shape}\\\")\",\"Preview the data loaded from the CSVs\\nprint(df_characters.head())\\nprint(df_locations.head())\\nprint(df_script.head())\\nprint(df_episodes.head())\",\" Show data sample\\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()\",\"Check if the episode's script has been loaded correctly\\ndf_script.head()\",\"Check dimensions of the main dataframes\\nprint('Dimensions of the characters dataframe:', df_characters.shape)\\nprint('Dimensions of the locations dataframe:', df_locations.shape)\\nprint('Dimensions of the script dataframe:', df_script.shape)\\nprint('Dimensions of the episodes dataframe:', df_episodes.shape)\",\" display all the loaded data\\nprint(\\\"Characters:\\\")\\nprint(df_characters.head())\\nprint(\\\"\\\\nLocations:\\\")\\nprint(df_locations.head())\\nprint(\\\"\\\\nScript:\\\")\\nprint(df_script.head())\\nprint(\\\"\\\\nEpisodes:\\\")\\nprint(df_episodes.head())\",\"Display first 5 rows of each data frame\\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()\",\"Display the first 5 rows of each dataframe\\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()\",\" Sample the dataset to understand its structure\\nprint(\\\"Character Data\\\")\\nprint(df_characters.head())\\nprint(\\\"Location Data\\\")\\nprint(df_locations.head())\\nprint(\\\"Script Data\\\")\\nprint(df_script.head())\\nprint(\\\"Episode Data\\\")\\nprint(df_episodes.head())\",\"Check the basic information of the datasets\\nprint('Characters:')\\ndisplay(df_characters.info())\\ndisplay(df_characters.head())\\nprint('\\\\n\\\\nLocations:')\\ndisplay(df_locations.info())\\ndisplay(df_locations.head())\\nprint('\\\\n\\\\nScript:')\\ndisplay(df_script.info())\\ndisplay(df_script.head())\\nprint('\\\\n\\\\nEpisodes:')\\ndisplay(df_episodes.info())\\ndisplay(df_episodes.head())\",\"Check first 5 lines of each dataframe\\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()\",\" Display the first 5 rows of each Dataframe\\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()\",\"Display the dimensions of the dataset\\nprint(\\\"Dimension of Simpsons Characters::\\\", df_characters.shape)\\nprint(\\\"Dimension of Simpsons Locations::\\\", df_locations.shape)\\nprint(\\\"Dimension of Simpsons Script::\\\", df_script.shape)\\nprint(\\\"Dimension of Simpsons Episodes::\\\", df_episodes.shape)\",\" Display the header of each table to understand its structure\\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()\",\"Check that the files have been loaded correctly\\nprint(df_characters.head(5))\\nprint(df_locations.head(5))\\nprint(df_script.head(5))\\nprint(df_episodes.head(5))\",\"# Check if everything is loaded correctly\\nprint(\\\"Characters:\\\")\\ndisplay(df_characters.head())\\nprint(\\\"\\\\nLocations:\\\")\\ndisplay(df_locations.head())\\nprint(\\\"\\\\nScript:\\\")\\ndisplay(df_script.head())\\nprint(\\\"\\\\nEpisodes:\\\")\\ndisplay(df_episodes.head())\",\"Print shapes\\nprint(df_episodes.shape)\\nprint(df_script.shape)\",\"Check first 5 rows of each dataframe\\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()\",\" Show the data\\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()\",\"Display the first few characters of the dataframes to understand their structure\\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()\",\"Check if the data is loaded correctly\\nprint('Characters')\\ndisplay(df_characters.head())\\nprint('Locations')\\ndisplay(df_locations.head())\\nprint('Script')\\ndisplay(df_script.head())\\nprint('Episodes')\\ndisplay(df_episodes.head())\",\"View the structure of the data in the episodes dataset\\ndf_episodes.head()\",\" Display the dataset shapes\\nprint(f\\\"Simpsons characters: {df_characters.shape}\\\")\\nprint(f\\\"Simpsons locations: {df_locations.shape}\\\")\\nprint(f\\\"Simpsons script: {df_script.shape}\\\")\\nprint(f\\\"Simpsons episodes: {df_episodes.shape}\\\")\",\" Explore first 5 rows of each dataframe\\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()\",\"Preview the dataset structures\\nprint(\\\"\\\\nCharacters sample:\\\")\\nprint(df_characters.head())\\nprint(\\\"\\\\nLocations sample:\\\")\\nprint(df_locations.head())\\nprint(\\\"\\\\nScript sample:\\\")\\nprint(df_script.head())\\nprint(\\\"\\\\nEpisodes sample:\\\")\\nprint(df_episodes.head())\",\"# Display the first few entries for each dataframe\\ndisplay(df_characters.head())\\ndisplay(df_locations.head())\\ndisplay(df_script.head())\\ndisplay(df_episodes.head())\",\" Preview the data\\nprint(\\\"Characters\\\")\\ndisplay(df_characters.head())\\nprint(\\\"Locations\\\")\\ndisplay(df_locations.head())\\nprint(\\\"Script\\\")\\ndisplay(df_script.head())\\nprint(\\\"Episodes\\\")\\ndisplay(df_episodes.head())\",\"Display the first few rows of each dataframe\\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()\",\"Function to display head of each dataframe\\ndef display_head_of_dataframes():\\n    display(df_characters.head())\\n    display(df_locations.head())\\n    display(df_script.head())\\n    display(df_episodes.head())\",\"Print the head of each dataframe, to get a better understanding of what kind of data we're dealing with.\\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()\",\" Displaying the first few rows of the dataframe\\ndf_episodes.head()\",\"# Quick look at the data\\nprint(df_characters.info())\\nprint(df_locations.info())\\nprint(df_script.info())\\nprint(df_episodes.info())\",\"Data shapes\\nprint(f\\\"Characters: {df_characters.shape}\\\")\\nprint(f\\\"Locations: {df_locations.shape}\\\")\\nprint(f\\\"Script: {df_script.shape}\\\")\\nprint(f\\\"Episodes: {df_episodes.shape}\\\")\",\"Examine each dataframe\\nprint('Characters data:')\\nprint(df_characters.head())\\n\\nprint('\\\\nLocations data:')\\nprint(df_locations.head())\\n\\nprint('\\\\nScript data:')\\nprint(df_script.head())\\n\\nprint('\\\\nEpisodes data:')\\nprint(df_episodes.head())\",\"Explore episodes dataframe\",\" Display the head of the episodes DataFrame\\ndf_episodes.head()\",\" Display at least the first couple rows of each dataframe\\nprint(\\\"Characters:\\\")\\ndisplay(df_characters.head())\\n\\nprint(\\\"\\\\nLocations:\\\")\\ndisplay(df_locations.head())\\n\\nprint(\\\"\\\\nScript:\\\")\\ndisplay(df_script.head())\\n\\nprint(\\\"\\\\nEpisodes:\\\")\\ndisplay(df_episodes.head())\",\" Check the shape of each dataframe\\nprint(\\\"Characters:\\\", df_characters.shape)\\nprint(\\\"Locations:\\\", df_locations.shape)\\nprint(\\\"Script:\\\", df_script.shape)\\nprint(\\\"Episodes:\\\", df_episodes.shape)\",\"Check if the dataframes were properly loaded\\nprint(df_characters.head())\\nprint(df_locations.head())\\nprint(df_script.head())\\nprint(df_episodes.head())\",\"View the available dataset\\ndf_episodes.head()\",\"Check the dataframes contain the correct data\\ndisplay(df_characters.head())\\ndisplay(df_locations.head())\\ndisplay(df_script.head())\\ndisplay(df_episodes.head())\",\"Check out the first 5 rows of each tables\\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()\",\"Show head\",\"\\nprint(f'Characters: {df_characters.shape[0]}')\\nprint(f'Locations: {df_locations.shape[0]}')\\nprint(f'Script lines: {df_script.shape[0]}')\\nprint(f'Episodes: {df_episodes.shape[0]}')\",\"Display the first few rows of the dataframes to ensure data was loaded correctly\\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()\",\"Check the size and type of the dataframes\\nprint(\\\"Characters dataframe has {} rows and {} columns\\\".format(*df_characters.shape))\\nprint(\\\"Locations dataframe has {} rows and {} columns\\\".format(*df_locations.shape))\\nprint(\\\"Scripts dataframe has {} rows and {} columns\\\".format(*df_script.shape))\\nprint(\\\"Episodes dataframe has {} rows and {} columns\\\".format(*df_episodes.shape))\",\"print('Characters dataset shape: {}'.format(df_characters.shape))\\nprint('Locations dataset shape: {}'.format(df_locations.shape))\\nprint('Script dataset shape: {}'.format(df_script.shape))\\nprint('Episodes dataset shape: {}'.format(df_episodes.shape))\",\" Check the format of each dataframe\\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()\",\" Show the head of each dataframe\\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()\",\"Quick overview of the episodes dataframe\\ndf_episodes.head()\",\" Display the first 5 rows of each dataframe\\nprint(\\\"Characters\\\")\\ndisplay(df_characters.head())\\nprint(\\\"\\\\nLocations\\\")\\ndisplay(df_locations.head())\\nprint(\\\"\\\\nScript\\\")\\ndisplay(df_script.head())\\nprint(\\\"\\\\nEpisodes\\\")\\ndisplay(df_episodes.head())\",\"Print the head of each dataset\\nprint(\\\"Characters:\\\")\\ndisplay(df_characters.head())\\nprint(\\\"Locations:\\\")\\ndisplay(df_locations.head())\\nprint(\\\"Script:\\\")\\ndisplay(df_script.head())\\nprint(\\\"Episodes:\\\")\\ndisplay(df_episodes.head())\",\"Inspect the first rows of each table\\nprint(\\\"Characters\\\")\\ndisplay(df_characters.head())\\n\\nprint(\\\"Locations\\\")\\ndisplay(df_locations.head())\\n\\nprint(\\\"Script\\\")\\ndisplay(df_script.head())\\n\\nprint(\\\"Episodes\\\")\\ndisplay(df_episodes.head())\",\"# Print size of the datasets\\nprint(f'Simpson character data has {df_characters.shape[0]} rows and {df_characters.shape[1]} columns')\\nprint(f'Simpson location data has {df_locations.shape[0]} rows and {df_locations.shape[1]} columns')\\nprint(f'Simpson script data has {df_script.shape[0]} rows and {df_script.shape[1]} columns')\\nprint(f'Simpson episode data has {df_episodes.shape[0]} rows and {df_episodes.shape[1]} columns')\",\"\\ndf_episodes.head()\",\"df_episodes.head()\",\"Check the number of rows in each dataframe\\nlen(df_characters), len(df_locations), len(df_script), len(df_episodes)\",\" Check data\\nprint(f'Characters:')\\ndisplay(df_characters.head())\\n\\nprint(f'\\\\n\\\\nLocations:')\\ndisplay(df_locations.head())\\n\\nprint(f'\\\\n\\\\nScript:')\\ndisplay(df_script.head())\\n\\nprint(f'\\\\nEpisodes:')\\ndisplay(df_episodes.head())\",\"Let's print first few records to understand the structure of the datasets\\nprint(df_characters.head(5))\\nprint(df_locations.head(5))\\nprint(df_script.head(5))\\nprint(df_episodes.head(5))\",\"Display the first 5 rows of each dataframe to understand their structure and content\\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()\",\"# Print top characters, locations, scripts and episodes\\nprint(df_characters.head())\\nprint(df_locations.head())\\nprint(df_script.head())\\nprint(df_episodes.head())\",\"Display the first rows of each dataframe to understand their structure\\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()\",\"A quick overview of the data.\\nprint('Script has shape', df_script.shape)\\nprint('Characters has shape', df_characters.shape)\\nprint('Locations has shape', df_locations.shape)\\nprint('Episodes has shape', df_episodes.shape)\\ndf_script.head()\",\"Print first 5 records of each dataframe\\nfor df, name in zip([df_characters, df_locations, df_script, df_episodes], \\n                    ['Characters', 'Locations', 'Script', 'Episodes']):\\n    print(f'===== {name} =====')\\n    display(df.head())\\n    print('\\\\n\\\\n')\",\"Check the structure of each dataframe\\nprint('Characters:')\\nprint(df_characters.info())\\nprint('Locations:')\\nprint(df_locations.info())\\nprint('Script:')\\nprint(df_script.info())\\nprint('Episodes:')\\nprint(df_episodes.info())\",\"Show just the head of the DataFrames to understand their structure\\nprint(df_characters.head())\\nprint(df_locations.head())\\nprint(df_script.head())\",\"show first five rows of each dataframe\\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()\",\"Check the dataset details\\ndf_characters.info()\\ndf_locations.info()\\ndf_script.info()\\ndf_episodes.info()\",\"Check if the CSV data was imported successfully\\nprint(df_characters.head())\\nprint(df_locations.head())\\nprint(df_script.head())\\nprint(df_episodes.head())\",\"Check the result of the import\\ndisplay(df_characters.head(10))\\ndisplay(df_locations.head(10))\\ndisplay(df_script.head(10))\\ndisplay(df_episodes.head(10))\",\"Check if the data has been loaded correctly\\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()\",\"Inspect the data sizes\\nprint(df_characters.shape)\\nprint(df_locations.shape)\\nprint(df_script.shape)\\nprint(df_episodes.shape)\",\"Quick overview\\ndf_episodes.head()\",\"Display top 5 rows of each dataframe\\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()\",\" check the number of characters, locations, and episode counts\\nlen(df_characters), len(df_locations), len(df_episodes)\",\"Look at the size of these datasets\\ndf_characters.shape, df_locations.shape, df_script.shape, df_episodes.shape\",\"Show the first 5 episodes available in the dataset\\ndf_episodes.head()\",\"Preview each dataset to understand the data before exploration.\\nprint(\\\"The characters data:\\\")\\nprint(df_characters.head())\\nprint(\\\"\\\\nThe locations data:\\\")\\nprint(df_locations.head())\\nprint(\\\"\\\\nThe episodes data:\\\")\\nprint(df_episodes.head())\\nprint(\\\"\\\\nThe script data:\\\")\\nprint(df_script.head())\",\" Display available dataframes\\nprint(\\\"Characters:\\\\t\\\", \\\",\\\".join(df_characters.columns))\\nprint(\\\"Locations:\\\\t\\\", \\\",\\\".join(df_locations.columns))\\nprint(\\\"Script:\\\\t\\\\t\\\", \\\",\\\".join(df_script.columns))\\nprint(\\\"Episodes:\\\\t\\\", \\\",\\\".join(df_episodes.columns))\",\"Visualize dataframe sizes\\nprint('Number of rows (characters, locations, script, episodes):', len(df_characters), len(df_locations), len(df_script), len(df_episodes))\",\"numbers of characters and locations\\nn_characters = len(df_characters)\\nn_locations = len(df_locations)\\n\\nn_episodes = len(df_episodes)\",\" Simple exploration\\nprint(\\n    df_script.shape,\\n    df_characters.shape,\\n    df_locations.shape,\\n    df_episodes.shape\\n)\",\" Show first few rows of each data table\\ndisplay(df_characters.head())\\ndisplay(df_locations.head())\\ndisplay(df_script.head())\\ndisplay(df_episodes.head())\",\"Check the first few lines of each dataframe to understand its structure\\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()\",\"Print all the avialable datasets to examine their contents\\nprint(\\\"Characters dataset columns: \\\", df_characters.columns)\\nprint(\\\"Locations dataset columns: \\\", df_locations.columns)\\nprint(\\\"Script dataset columns: \\\", df_script.columns)\\nprint(\\\"Episodes dataset columns: \\\", df_episodes.columns)\",\"# Display the 'Head' of each dataframe to get an understanding of the data\\nprint('Characters:')\\nprint(df_characters.head())\\nprint('Locations:')\\nprint(df_locations.head())\\nprint('Script:')\\nprint(df_script.head())\\nprint('Episodes:')\\nprint(df_episodes.head())\",\" Ensure all dfs have the same id index as the script df\\ndf_characters.index += 1\\ndf_locations.index += 1\\ndf_episodes.index += 1\",\"  ensure the data is correctly loaded\\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()\",\" Helper function to sample a dataframe\\ndef sample_dataframe(dataframe, n_samples=10):\\n    return dataframe.loc[np.random.choice(dataframe.index, n_samples, replace=False)]\\n\\n# Sample the dataframes to speed up the analysis\\ndf_characters_sample = sample_dataframe(df_characters, n_samples=50)\\ndf_locations_sample = sample_dataframe(df_locations, n_samples=50)\\ndf_script_sample = sample_dataframe(df_script, n_samples=500)\\ndf_episodes_sample = sample_dataframe(df_episodes, n_samples=50)\"],\"marker\":{\"opacity\":0.5,\"size\":5},\"mode\":\"markers+text\",\"name\":\"0_Dataset Sizes and Overview\",\"text\":[\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\"],\"textfont\":{\"size\":12},\"x\":[17.377727508544922,15.086906433105469,16.31785774230957,16.61544418334961,16.52655029296875,15.025997161865234,15.289141654968262,15.236114501953125,15.546845436096191,15.606626510620117,16.562597274780273,15.739114761352539,17.524860382080078,16.508373260498047,16.40475845336914,16.166440963745117,16.40719223022461,15.319375038146973,15.278483390808105,15.319783210754395,17.295032501220703,17.420352935791016,16.113447189331055,16.311344146728516,16.42519187927246,16.321557998657227,15.190479278564453,15.892136573791504,17.311843872070312,16.669424057006836,15.082345008850098,16.271196365356445,16.186506271362305,16.47538185119629,15.433207511901855,16.475482940673828,17.804874420166016,17.869205474853516,15.955193519592285,16.3259220123291,17.47512435913086,17.889394760131836,15.2953462600708,17.1317138671875,16.37004852294922,16.677661895751953,15.18619155883789,17.807369232177734,16.213504791259766,17.28533172607422,16.519840240478516,15.490175247192383,15.064830780029297,17.712331771850586,16.198463439941406,17.408645629882812,16.41997528076172,17.65494728088379,16.38523292541504,16.262741088867188,17.471004486083984,15.961864471435547,15.022237777709961,16.23359489440918,15.334879875183105,15.960347175598145,17.252126693725586,15.443110466003418,16.435340881347656,15.66950798034668,16.378774642944336,17.27916145324707,13.702753067016602,15.037110328674316,17.487388610839844,15.391528129577637,15.035622596740723,16.4836368560791,16.196840286254883,15.450825691223145,17.584362030029297,16.28955078125,17.15142250061035,15.343735694885254,15.346795082092285,15.332632064819336,15.486485481262207,16.51300621032715,15.887081146240234,17.822853088378906,16.313217163085938,17.561323165893555,15.391858100891113,17.55023765563965,15.739559173583984,16.280807495117188,17.913259506225586,15.792362213134766,16.432247161865234,16.483572006225586,16.378061294555664,15.243059158325195,15.320072174072266,18.018051147460938,15.2893648147583,15.286802291870117,17.268953323364258,16.06327247619629,16.018590927124023,15.391188621520996,15.166887283325195,15.508720397949219,17.521833419799805,16.52754783630371,15.825366020202637,15.998976707458496,16.2790470123291,16.21781349182129,16.742164611816406],\"y\":[11.333765983581543,13.137431144714355,11.377662658691406,11.868080139160156,11.737360954284668,10.909684181213379,11.673704147338867,12.879271507263184,12.258749008178711,11.80517578125,12.32323169708252,11.783936500549316,11.941022872924805,10.522112846374512,11.33003044128418,11.483648300170898,11.310101509094238,10.91637897491455,13.07032299041748,12.893014907836914,12.119505882263184,11.967093467712402,12.073420524597168,11.72447395324707,10.613094329833984,12.283148765563965,12.690217971801758,10.035667419433594,11.675030708312988,11.04008960723877,13.123796463012695,11.778186798095703,11.244565963745117,10.283966064453125,12.711725234985352,12.428366661071777,11.554862976074219,11.491195678710938,11.889959335327148,12.238911628723145,11.473331451416016,11.479808807373047,12.727643966674805,11.978859901428223,10.517688751220703,12.393260955810547,13.0039701461792,11.67291259765625,11.381641387939453,11.3505220413208,11.796788215637207,10.86263370513916,12.979849815368652,11.459999084472656,12.237537384033203,11.858717918395996,12.010214805603027,11.55324649810791,11.465811729431152,11.357661247253418,11.164984703063965,12.105247497558594,13.187952995300293,12.273768424987793,10.41978931427002,11.112537384033203,11.929625511169434,12.707181930541992,10.73262882232666,10.93581485748291,10.640356063842773,11.781475067138672,3.2274880409240723,13.25235652923584,11.521562576293945,12.7564115524292,13.049433708190918,10.9479398727417,11.218598365783691,10.823150634765625,11.95846939086914,12.128067016601562,12.101280212402344,12.638044357299805,10.947443962097168,10.913844108581543,11.742565155029297,12.200190544128418,11.68543529510498,11.536370277404785,11.675980567932129,11.462889671325684,12.833746910095215,11.859723091125488,12.213608741760254,11.434480667114258,11.335416793823242,11.902182579040527,10.699322700500488,11.075810432434082,10.502963066101074,12.631115913391113,10.901300430297852,11.36428451538086,11.505955696105957,12.333191871643066,11.13744068145752,12.245521545410156,12.14710807800293,11.908477783203125,11.422797203063965,12.800191879272461,11.883668899536133,11.199813842773438,12.368732452392578,11.925219535827637,10.369476318359375,10.389659881591797,10.041805267333984],\"type\":\"scattergl\"},{\"hoverinfo\":\"text\",\"hovertext\":[\"View the first few rows of the characters dataframe\\ndf_characters.head()\",\"Checking the first few rows of the characters data frame to understand its structure\\ndf_characters.head()\",\"Inspect and display few rows of characters dataframe\\ndf_characters.head()\",\" Quick overview of the characters dataset\\ndf_characters.info()\",\" Check the dataframes to ensure they were loaded correctly\\ndf_characters.head()\",\"df_characters.info()\",\"Inspect the character dataset\\ndf_characters.head()\",\"Check the first few rows of the characters DataFrame\\ndf_characters.head()\",\"# Glimpse of the characters dataframe\\ndf_characters.head()\",\"Check loaded data\\ndf_characters.head()\",\"Inspect the first few rows of the characters dataframe\\ndf_characters.head()\",\"Inspect the first 2 rows of df_characters\\ndf_characters.head(2)\",\"Checking the head of the characters dataframe\",\"Explore the character dataset\\ndf_characters.head()\",\"Check the first few rows of `df_characters`\\ndf_characters.head()\",\"Check the content of the data sets\\ndf_characters.head()\",\"Inspect dataset using head()\\ndf_characters.head(10)\",\"View characters dataframe\\ndf_characters.head()\",\"Verify if the index has been reinitialized.\\ndf_characters.head()\",\"Check data has been read correctly\\ndf_characters.head()\",\"Check if the index has been reset\\nprint(df_characters.head())\",\"Inspect the first few rows of the characters DataFrame\\ndf_characters.head()\",\"check the head of the Characters data\\ndf_characters.head()\",\"Inspecting the first few entries of the characters data frame.\",\"Inspect df_characters\",\"Preview the dataframes\\ndf_characters.head(2)\",\"Look at the first couple of rows of the characters dataframe\\ndf_characters.head()\",\" Explore characters dataframe\",\"Check the structure of the characters dataset\\ndf_characters.head()\",\" Quick look at the characters dataset.\\ndf_characters.head()\",\"Check that the data has been properly loaded\\ndf_characters.head()\",\" Explore the data structure of df_characters\\ndf_characters.head()\",\"# Read the first ten lines of each data frame to understand its structure\\ndf_characters.head(10)\",\"View the first few rows of the characters dataframe\\ndf_characters.head()\",\"Look at first few rows of each dataset\\ndf_characters.head()\",\"Check the first few lines of the characters dataframe\\ndf_characters.head()\",\" Check first 2 rows of df_characters dataframe\\ndf_characters.head(2)\",\"Check the first 5 rows of the characters dataframe.\",\"Inspect & clean the characters dataframe\",\"Check the first few rows of the characters dataframe\\ndf_characters.head()\",\" Check example dataframe\\ndf_characters.head()\",\" View the first few rows of the characters dataframe\\ndf_characters.head()\",\"Preview the characters DataFrame\\ndf_characters.head()\",\"Initial look at characters data\",\" Check if the data was loaded correctly\\ndf_characters.head()\",\"Display basic information about the characters dataset\\ndf_characters.info()\",\"Inspect the characters dataset\",\"Inspect dataframe contents\\ndf_characters.head()\",\" Explore the first dataframe (characters)\",\"Check out the first few rows of df_characters\\ndf_characters.head()\",\" Check the first 5 rows of the characters dataframe\",\"Inspect the first few rows of the characters dataframe\\ndf_characters.head()\",\"Check the first few rows of the characters dataframe\",\"Quick look to the df_characters dataframe\",\"Character level EDA\",\"Check the freshly imported data\\ndf_characters.head()\",\"Inspect the contents of the character dataframe\",\"Check the top few rows of each dataframe\\ndf_characters.head()\",\"Data at a glance\\nprint(df_characters.info())\",\"Preview the dataframes\\ndf_characters.head()\",\"Check data structure\\ndf_characters.head()\",\"Checking the first few rows of the characters dataframe\\ndf_characters.head()\",\"Have a look at the first couple of rows of the characters dataframe - the head - and the number of records - the shape.\",\"# Let's see what's inside the characters dataframe\\ndf_characters.head()\",\"Check one of the tables to make sure the import worked correctly\\ndf_characters.head()\",\" Explore first rows of characters dataframe\\ndf_characters.head()\",\"Display and check the informations on the characters data.\",\"View the characters dataframe\\ndf_characters.head()\",\"Check that the data is read in correctly\\ndf_characters.head()\",\" Look at the character's dataset\\nprint(\\\"Characters dataset\\\")\\nprint(df_characters.head())\",\"Load the Word Embeddings model that will be used to infer the similarity between characters.\",\"Check to see what they look like\\nprint(df_characters.head())\",\"Examine the contents of the characters dataframe\\ndf_characters.head()\",\"Check the imported DataFrames\\ndf_characters.head()\",\"Preview the character data\\ndf_characters.head()\",\"View the characters dataframe\\ndf_characters.head()\",\" Explore a few info about characters DataFrame\\ndf_characters.info()\",\" We show the head of each dataframe to understand how they are organized\\nprint(df_characters.head())\",\"Check the first few lines of the characters DataFrame\\ndf_characters.head()\",\"Check the dataframes\\ndf_characters.head(5)\",\"Set the length of the context by considering the first three characters.\",\"Inspect the structure of the characters DataFrame\",\"Show the tiles of the characters data\\ndf_characters.head()\",\"Inspect the first few rows of the characters dataframe\\ndf_characters.head()\",\"Check columns in characters data frame\\ndf_characters.columns\",\"Preview the characters data\\ndf_characters.head()\",\"Check and display the headers for the df_characters dataframe\\ndf_characters.head()\",\"df_characters.head()\",\"check the first 5 rows of df_characters\\ndf_characters.head()\",\"Inspect the first few rows of the characters DataFrame\\ndf_characters.head()\",\"Preview the characters data\\ndf_characters.head()\",\" Checking the first few rows of the characters dataframe.\",\"Checking the content of the characters dataset\\ndf_characters.head()\",\"linking charcters is important. Characters to character interactions are the backbone of a story.\",\" Dataframes exploration\\ndf_characters.head()\",\"Preview the data\\ndf_characters.head()\",\"Quick exploration of the characters table\",\" View the first rows of the characters dataframe\\ndf_characters.head()\",\"Display head of characters Dataframe\\ndf_characters.head()\"],\"marker\":{\"opacity\":0.5,\"size\":5},\"mode\":\"markers+text\",\"name\":\"1_Previewing First Few Rows of DataFrame\",\"text\":[\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\"],\"textfont\":{\"size\":12},\"x\":[10.906805038452148,10.298500061035156,10.84740924835205,10.053507804870605,9.330979347229004,10.01414680480957,10.018148422241211,10.07076644897461,10.75423526763916,9.46955394744873,10.812734603881836,10.600794792175293,10.314166069030762,10.09835433959961,9.947097778320312,9.662261009216309,10.131818771362305,10.938398361206055,9.57362174987793,9.395122528076172,9.55156421661377,10.863271713256836,9.767915725708008,10.383814811706543,9.86141586303711,12.189397811889648,10.631999969482422,10.532614707946777,9.892821311950684,10.12901782989502,9.342415809631348,10.329094886779785,10.379608154296875,10.9246826171875,10.208577156066895,10.034594535827637,10.187536239624023,9.588163375854492,10.7279052734375,10.066737174987793,10.34121322631836,10.904585838317871,12.21740436553955,10.24854564666748,9.317736625671387,10.030613899230957,10.15880298614502,10.614246368408203,10.761767387390137,10.248998641967773,9.458725929260254,10.722128868103027,9.789027214050293,10.255160331726074,10.16778564453125,9.452027320861816,10.514265060424805,10.149023056030273,10.083970069885254,12.244450569152832,9.73715877532959,10.158923149108887,10.649687767028809,10.71051025390625,9.318760871887207,10.958927154541016,10.169265747070312,10.70258617401123,9.285674095153809,10.101621627807617,10.246498107910156,9.95781135559082,10.583662033081055,9.76980972290039,12.356485366821289,10.736207962036133,10.232008934020996,10.809560775756836,10.063904762268066,10.07200813293457,10.428949356079102,10.413519859313965,10.250232696533203,10.754508972167969,9.911996841430664,12.278657913208008,10.364126205444336,10.209896087646484,9.677862167358398,10.927855491638184,12.363964080810547,9.823010444641113,9.804065704345703,10.284467697143555,10.920541763305664,12.306865692138672,10.214680671691895,11.106449127197266,10.873661994934082],\"y\":[-2.0415549278259277,-1.5119966268539429,-1.743979573249817,1.1178797483444214,-0.3005310297012329,0.8706690669059753,0.3507770895957947,-1.7390201091766357,-0.6320407390594482,0.03182829171419144,-1.8074666261672974,-1.6068274974822998,-0.9667585492134094,0.3293488919734955,-1.6992751359939575,0.01595251075923443,0.050660524517297745,-0.7257080674171448,0.08181041479110718,-0.055576059967279434,-0.09672560542821884,-1.8299477100372314,-0.06765017658472061,1.5346055030822754,0.41804277896881104,-0.9413186311721802,-1.100415825843811,0.6990858316421509,0.2183549553155899,0.3962889313697815,-0.07293800264596939,0.011303895153105259,-0.40570077300071716,-2.118569850921631,0.08228243142366409,-1.4178481101989746,-1.7681986093521118,-1.883504033088684,0.8678761124610901,-1.7606993913650513,-0.8814893364906311,-2.0569140911102295,-0.9801498055458069,1.6610187292099,-0.1531885266304016,1.0924828052520752,1.6443500518798828,-0.5970116257667542,-2.651524066925049,-0.6681755781173706,-1.9545414447784424,-1.8682152032852173,-2.039022922515869,0.7947227954864502,1.6152441501617432,-0.15227574110031128,0.9598850011825562,-1.7209420204162598,0.9925292730331421,-0.9645625352859497,0.005435213912278414,-1.7735881805419922,-0.08825691789388657,-0.6150287389755249,-0.23093122243881226,-2.588543176651001,1.7817902565002441,-0.7238754034042358,-0.13408643007278442,0.5201936960220337,1.6972781419754028,-0.2753037214279175,-0.6868392825126648,-0.6096779704093933,-1.0451074838638306,-0.638591468334198,0.9187915921211243,-0.10293813794851303,-1.446140170097351,-1.0326422452926636,1.940592646598816,0.9627524614334106,0.14218483865261078,-1.810154676437378,-1.7185866832733154,-0.9242203235626221,-1.0012742280960083,-0.3318280279636383,-1.709166407585144,-1.8929524421691895,-1.0577893257141113,-1.8212435245513916,0.0684502124786377,1.9780362844467163,-0.6348271369934082,-0.9829778075218201,1.873415470123291,-2.7045998573303223,-0.6458649039268494],\"type\":\"scattergl\"},{\"hoverinfo\":\"text\",\"hovertext\":[\"Check if data looks good\\ndf_script.head()\",\" Visualize data\\nprint(df_script.head())\",\"Display the first few rows of the dataframe\\ndf_script.head()\",\" Print the head of the DataFrame to see the data\\nprint(df_script.head())\",\"Performing a simple check on the script dataframe.\",\"\\ndf_script.head()\",\"Check the structure of the script dataframe\\ndf_script.head()\",\" Quick look at the structure for the Demo\\ndf_script.head()\",\"Take a look at what we're working with\\ndf_script.head()\",\"Check data load\\ndf_script\",\"Inspect dataset structure\\ndf_script.head()\",\" Display the first few rows of the dataframe\\ndf_script.head()\",\"# Displaying the dataframe\\ndf_script.head()\",\"Ensure the data is loaded properly\\ndf_script.head()\",\"# Display first few rows of the dataframe\\ndf_script.head()\",\"df_script.head()\",\"display 5 random rows of the script dataset\\ndf_script.sample(5)\",\"Create a variable to see how many rows the script dataframe has \\nrows_script_df, __ = df_script.shape\",\"# Show the first few lines of the dataframe\\ndf_script.head()\",\"Check the contents of the lines script dataframe\\ndf_script.head()\",\"\\n#df_script.head().T\",\"Check the first few rows of the dataset\\ndf_script.head()\",\" Optional: Limit the number of rows for quicker processing\\n# df_script = df_script[:1000]\\n\\n# Print the header of the file to ensure it was read correctly\",\"Display first rows of the script DataFrame\\ndf_script.head()\",\"Data types\\nprint(df_script.dtypes)\",\" Show first 5 rows of the \\\"df_script\\\" DataFrame\\ndf_script.head()\",\"View the dataframe\\ndf_script.head()\",\" Display the data\\ndf_script.head()\",\"# Display the first few lines of the table `dataset`\\ndf_script.head()\",\"display the data from the script dataframe\\ndf_script.head()\",\"\\ndf_script.head()\",\"df_script.head()\",\"Check the loaded datasets\\ndf_script.head()\",\"Display first 5 rows of df script\\ndf_script.head()\",\" Get the columns of the script dataframe.\",\"Display header of df_script\\ndf_script.head()\",\"Save the dataframes to disk to avoid in-memory storage limits\",\" Display scripts\\ndf_script.head(3)\",\"view data head for every data frame\",\" Display how the dataframe looks like\\ndf_script.head()\",\"Check the script data\\nprint(df_script.head())\",\"Check and display data head\",\"Check the content of the script DataFrame\\ndf_script.head()\",\"Check first few rows of df_script\\ndf_script.head()\",\"Quick look at the script data\\ndf_script.head()\",\" Let's start by examining the script data\\nprint(f\\\"The dataset has {df_script.shape[0]:,} rows.\\\")\",\" Display the first few rows of the dataset\\ndf_script.head()\",\"Take the first few rows for a look\\ndf_script.head()\",\" Check the df_scripts dataframe\",\"df_script.head()\",\" Display rows of script\\ndf_script.head()\",\" Look the current iteration of the processed `df_script` DataFrame.\",\" List what's inside of the script DataFrame\\ndf_script.head()\",\"Printing the head of the script DataFrame\\nprint(df_script.head())\",\"Show the head of the script dataframe\\ndf_script.head()\",\"Preview the data\\ndf_script.head()\",\" Gets the first 5 rows of the script dataframe\",\"Limit the number of script lines for demonstration (optional)\\ndf_script = df_script.head(10000)\",\"Checking the head of each DataFrame\",\"Function to display basic information about a DataFrame\\ndef display_info(df, df_name):\\n    print(f'{df_name} has {df.shape[0]} rows and {df.shape[1]})')\",\"Examine the dataframe\\ndf_script.head()\",\"df_script.head()\",\"Check data with head\",\"Display script data\\ndf_script.head()\",\" Check the content of 1 dataframe\\ndf_script.head()\",\"Inspect dataframe\\nprint(df_script.shape)\\ndf_script.head()\",\"Display the first few rows of the script dataframe\\ndf_script.head()\",\"Check example lines\\ndf_script.head()\",\"Display the first 5 rows of the dataframe\\ndf_script.head()\",\"Explore the structure of the dataset\\ndf_script.head()\",\"Show the first row of the table to understand its structure\\ndf_script.head(1)\",\" Helper function to display the head of each dataframe conveniently\\ndef display_head_of_dataframes(dfs):\\n    for df_name, df in dfs.items():\\n        print(f\\\"\\\\033[1m{df_name}\\\\033[0m\\\")\\n        display(df.head())\",\"Extracting 10,000 random lines from the dataset for analysis to avoid memory errors\\ndf_script = df_script.sample(10000, random_state=42)\",\"check the beginning of the script data\\nprint(f'Data contains {len(df_script)} lines from {df_script.id[0]} to {df_script.id[len(df_script)-1]}')\\ndf_script.head()\",\"print(len(df_script))\",\"Print the head of the table_\",\"Data layout\\ndf_script.head()\",\" Take a look at the script data\\ndf_script.head()\",\"Sample the data\\ndf_script.head()\",\" Print the head of the scripts dataframe to better understand the available fields\",\"View first few records of the dataset\\ndf_script.head()\"],\"marker\":{\"opacity\":0.5,\"size\":5},\"mode\":\"markers+text\",\"name\":\"2_Displaying the First Few Rows of a DataFrame in Python\",\"text\":[\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\"],\"textfont\":{\"size\":12},\"x\":[13.793448448181152,14.341707229614258,14.012542724609375,13.940593719482422,13.210954666137695,15.513198852539062,13.854531288146973,15.349525451660156,15.4005765914917,13.717474937438965,14.57663345336914,14.043124198913574,14.192902565002441,15.327699661254883,13.994215965270996,15.42026424407959,13.857723236083984,14.037896156311035,14.052180290222168,13.93393611907959,15.540553092956543,14.281448364257812,14.49577808380127,13.942626953125,14.497513771057129,13.744107246398926,14.056682586669922,14.465683937072754,14.238037109375,14.250870704650879,15.495523452758789,15.50806999206543,14.415207862854004,13.700243949890137,13.751304626464844,14.231806755065918,14.176777839660645,14.928601264953613,13.324045181274414,14.115792274475098,13.897965431213379,13.229302406311035,13.601009368896484,14.24012279510498,14.907805442810059,14.408727645874023,14.105764389038086,14.301410675048828,13.55380630493164,15.328391075134277,14.377970695495605,13.805009841918945,13.964322090148926,14.0233154296875,13.98482608795166,14.682419776916504,13.246922492980957,14.789992332458496,13.117531776428223,13.024384498596191,13.79809284210205,15.460153579711914,13.260826110839844,14.5680513381958,13.556107521057129,13.981729507446289,13.973004341125488,15.346790313720703,13.568394660949707,14.594454765319824,14.41470718383789,13.810816764831543,14.294548034667969,14.230795860290527,14.133634567260742,14.712462425231934,14.976722717285156,14.987401008605957,15.097602844238281,14.0263032913208,13.980047225952148],\"y\":[3.6170127391815186,2.9072954654693604,4.841675758361816,3.0059196949005127,4.3272199630737305,3.6259899139404297,3.605281114578247,3.709290027618408,3.679086446762085,3.9823780059814453,3.808826208114624,4.744289875030518,2.9833970069885254,3.6653411388397217,4.631283760070801,3.459179401397705,4.915759563446045,3.919783115386963,4.4653401374816895,3.590566873550415,3.5660059452056885,4.144733428955078,4.41151237487793,4.786281108856201,3.624556541442871,4.932836532592773,3.1102912425994873,3.153867483139038,4.54583215713501,2.9556548595428467,3.5944454669952393,3.5065155029296875,3.819979190826416,5.024141788482666,3.7207350730895996,2.9793379306793213,5.0652923583984375,3.2773935794830322,3.800971031188965,2.9134316444396973,3.74479341506958,3.468050241470337,3.6307921409606934,4.269384384155273,3.6539506912231445,3.9924986362457275,4.690160274505615,4.370387077331543,3.966904640197754,3.611821413040161,3.3583784103393555,4.010101318359375,3.2084672451019287,3.044288396835327,2.9789061546325684,3.3228800296783447,4.627769947052002,4.2307305335998535,3.5874409675598145,2.8216145038604736,3.4016833305358887,3.6685492992401123,3.4678738117218018,3.088956356048584,3.5622122287750244,3.2371275424957275,4.7693376541137695,3.593299388885498,4.883817672729492,3.857771158218384,4.743668556213379,2.8121049404144287,4.726227760314941,3.703645706176758,3.676694869995117,5.128032207489014,3.219024896621704,3.7986185550689697,3.6530256271362305,3.0750656127929688,4.604255199432373],\"type\":\"scattergl\"},{\"hoverinfo\":\"text\",\"hovertext\":[\"Check the size of the datasets\",\" Let's take a look at the structure of the datasets.\",\" Let's take a look at the datasets\",\"Let's examine the structure of each dataset.\",\"Checking the structure of the datasets\",\"Let's start by having a quick look at the datasets.\",\"Let's take a look at the structure of each dataset.\",\"Check the record count and the datatypes of each column.\",\" Visualisation functions\",\"Let's take a look at each of the datasets to understand their structure and the type of data they contain.\",\"Let's check the number of records in each dataset.\",\"Exploring the dataset\",\"Until now we have successfully imported the required libraries and datasets.\",\"For a much detailed study of the dataset, we will take a look at all the datasets that we loaded in this section.\",\" Data Exploration\",\" Some initial checks\",\"Create a template for the analysis and quickly explore the data.\",\" Data exploration\",\"Inspect data part 1\",\"Let's begin by taking a look at the data.\",\" Check provided data sets\",\" 1. Exploration\",\"Let's check if these datasets are correctly loaded.\",\"Preview the datasets\",\" Visualizing the raw data\",\"Summary statistics\",\"Let's display the first rows of each dataset to understand its structure.\",\"We load a dataset with sample data.\",\"We need to process the text data to extract insights.\",\"Let's now display the first few lines of each of these datasets.\",\"Visualizing the datasets\",\"Get basic statistics about the dataset\",\" Checking the size of each dataset\",\"utility functions for the project\",\"Lets check the first few rows of each of these datasets to get an idea of what kind of data we are working with.\",\"Check the data to understand its structure\",\"Get the outlines of the datasets\",\"Get the complete dataset head in order to have a better idea of the data structure.\",\"Check the shape of each dataset\",\"Let's inspect the datasets to understand what data we are dealing with.\",\"Visualizing Data to gain insights\",\" Display some basic information about the datasets\",\" We need to process the data first before we start the analysis\",\"Let's take a peek of the datasets\",\"Exploring the data to understand its structure and content.\",\" Data Visualisation\",\"Visualising data\",\"Sample the data to get a better understanding of the content\",\"Some basic exploration\",\"Let's see what we're working with\",\"Check the loaded datasets\",\"Let's take a look at the first few rows of each of these datasets to understand how they are structured.\",\"This is a sample of AI-generated predictions based on the provided code.\",\"Let's start by getting familiar with the content of the datasets.\",\" These functions will come in handy later on.\",\"Let's start by looking at the structure and content of our data.\",\" Check how each dataset looks like\",\"Let us start by taking a look at these datasets.\"],\"marker\":{\"opacity\":0.5,\"size\":5},\"mode\":\"markers+text\",\"name\":\"3_Exploring Datasets\",\"text\":[\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\"],\"textfont\":{\"size\":12},\"x\":[9.535138130187988,9.052628517150879,9.147045135498047,9.079710006713867,9.515730857849121,9.105988502502441,9.02172565460205,9.46647834777832,9.631279945373535,8.947992324829102,9.285344123840332,9.307822227478027,9.863269805908203,9.199400901794434,9.740303039550781,10.596625328063965,9.935229301452637,9.583464622497559,10.109588623046875,9.515564918518066,9.645777702331543,9.778307914733887,10.056709289550781,9.145797729492188,9.480895042419434,9.359057426452637,8.893786430358887,9.713656425476074,9.886479377746582,8.968783378601074,9.193838119506836,9.089763641357422,9.518595695495605,9.79212474822998,8.897647857666016,9.722410202026367,9.292807579040527,9.239191055297852,9.388800621032715,9.56068229675293,9.60602855682373,9.154952049255371,10.313288688659668,9.306028366088867,9.705267906188965,9.4557523727417,9.425796508789062,9.813776969909668,9.814130783081055,9.903186798095703,9.920536994934082,8.873645782470703,9.55870246887207,9.376179695129395,10.00809383392334,9.823028564453125,9.394331932067871,9.1519775390625],\"y\":[7.8646626472473145,8.660438537597656,8.806159019470215,8.398174285888672,7.965454578399658,8.742961883544922,8.402975082397461,7.756711483001709,9.672211647033691,8.455442428588867,8.096281051635742,9.040760040283203,7.881346702575684,8.730053901672363,9.614356994628906,8.308968544006348,9.216818809509277,9.594808578491211,8.897851943969727,8.902091026306152,7.691403388977051,9.34347915649414,7.953888893127441,8.899064064025879,9.634408950805664,8.95203971862793,8.225249290466309,8.651313781738281,9.26880931854248,8.499738693237305,9.337875366210938,8.736384391784668,7.87275505065918,9.602303504943848,8.442161560058594,8.55051040649414,8.195448875427246,8.202122688293457,8.0393705368042,8.759506225585938,9.619039535522461,8.781389236450195,9.046310424804688,8.800494194030762,9.252008438110352,9.634660720825195,9.723947525024414,9.141395568847656,9.424650192260742,8.635682106018066,7.811663627624512,8.299910545349121,8.57048511505127,8.783452033996582,9.3189697265625,8.979689598083496,7.969076633453369,8.855769157409668],\"type\":\"scattergl\"},{\"hoverinfo\":\"text\",\"hovertext\":[\"python -m spacy download en_core_web_sm\",\" Load the spacy model\\nnlp = spacy.load('en_core_web_sm')\",\"Setup spacy\\nnlp = spacy.load('en_core_web_sm')\",\"Get the English tokenizer from SpaCy for better performance\\nnlp = spacy.load('en_core_web_sm', disable=['parser', 'tagger', 'ner'])\",\" Set up tokenization model\\n# We will use the SpaCy library to lemmatize and tokenize the words\\nnlp = spacy.load('en_core_web_sm', disable=['ner', 'parser'])\",\"install a dictionary\\n!{sys.executable} -m spacy download en_core_web_sm\",\"Setting up the spacy model for preprocessing the text data.\",\"Load the spacy model for processing English language\\nnlp = spacy.load(\\\"en_core_web_sm\\\")\",\" Set up spacy\\nnlp = spacy.load('en_core_web_sm')\",\"Set environment variable for the path to spaCy model\\nos.environ[\\\"SPACY_DATA\\\"] = '\\u002fusr\\u002flocal\\u002flib\\u002fpython3.7\\u002fdist-packages\\u002fen_core_web_lg\\u002f'\",\" Load sm\\nen_core_web_sm = spacy.load('en_core_web_sm')\",\"\\n#create spacy nlp object\\nnlp = spacy.load('en_core_web_sm')\",\" Install the spaCy language model\\n!python -m spacy download en_core_web_sm\",\"Load the pre-defined NLP pipeline that you developed in the previous sections.\",\"# Design choices\\n# We choose to use spacy to provide a fast and robust way to search words. Besides, it will be easy to query named entities we could encounter later on.\",\" Set up the spacy model for NLP analysis.\",\"Define global parameters\\n# Number of top characters to display\\ntop_n_characters = 15\\n\\n# Load the large english model\\nnlp = spacy.load('en_core_web_lg')\",\"Loading BERT tokenizer and encoding the dataframe\",\"Download spaCy model\\n!python -m spacy download en_core_web_sm\",\" Spacy model\\nnlp = spacy.load('en_core_web_sm')\",\"Setting up spacy\\nnlp = spacy.load(\\\"en_core_web_sm\\\")\",\"To use spaCy's NER, we start by loading a pre-trained model.\",\" Load Spacy\\nnlp = spacy.load('en')\",\"Set up Spacy\\nnlp = spacy.load('en_core_web_sm', disable=['parser', 'tagger', 'ner'])\",\"Declare path to the pretrained model\\nmodel_base_path = 'models\\u002fspacy\\u002f'\\nos.environ[\\\"MODERN_MODEL\\\"] = model_base_path\\n\\n# Load the model\\nnlp = spacy.load(model_base_path)\",\"# Set up environment\\nMODELS_DIR = \\\"\\u002fpi\\u002fai\\u002fnlp\\u002fmodels\\\"\\n\\n# Load spacy model\\nnlp = spacy.load('en_core_web_md')\\n\\n# Expand Pandas Matrix\\npd.options.display.max_columns = 50\",\"spacy pre-trained model\\nnlp = spacy.load('en')\",\"Load spacy model\\nnlp = spacy.load('en_core_web_sm')\",\"Translate all the text to English with the help of `spacy` module\",\"Download the spacy language model\\n!python -m spacy download en_core_web_sm\",\"Load the pre-trained model from spacy.\",\" Property setting\\npd.set_option('max_colwidth', 800)\\n\\n# Preload spacy language model\\nnlp = spacy.load('en_core_web_sm')\",\" Start the sentence tokenizer\\nnlp = spacy.load(\\\"en_core_web_sm\\\")\\nnlp.add_pipe('sentencizer')\",\"load language model\\nnlp = spacy.load('en')\",\"Set up Spacy\\nnlp = spacy.load('en_core_web_sm')\\nnlp.max_length = 1500000\",\" Character recognition models: Implementation of the NER system to recognize characters' names within the frames' dialogue using spaCy's named entity recognition capabilities.\",\"Installing spacy language model for English\",\"Optional for preprocessing\\nnlp = spacy.load('en_core_web_sm')\",\"nlp = spacy.load('en_core_web_sm')\",\"To ensure the libraries are correctly installed, we can run the following command on the terminal:\\n```\\npython -m spacy download en_core_web_sm\\n```\",\"Load spaCy language model\\nnlp = spacy.load('en_core_web_sm')\",\"character = spacy.load(\\\"en_core_web_lg\\\")\",\" Load the pre-trained large English NLP model\\nnlp = spacy.load('en_core_web_lg')\",\"Set an environment variable to determine the stopwords language for the preprocessing step using spaCy and its language model.\",\"Create an instance of the English spaCy tokenizer.\"],\"marker\":{\"opacity\":0.5,\"size\":5},\"mode\":\"markers+text\",\"name\":\"4_SpaCy NLP Model Loading\",\"text\":[\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\"],\"textfont\":{\"size\":12},\"x\":[5.579385280609131,4.935830593109131,4.930156230926514,5.2434797286987305,5.343018054962158,5.651276111602783,5.8132004737854,5.382181644439697,4.929876804351807,5.326015949249268,5.054239273071289,4.920751571655273,5.597084999084473,5.5274224281311035,5.718623638153076,5.816745758056641,5.1553802490234375,5.578561782836914,5.554988384246826,4.959695339202881,5.208807945251465,5.903894901275635,5.428506851196289,5.065357685089111,5.14094352722168,5.0100932121276855,5.538060665130615,5.101446628570557,5.756753444671631,5.679067611694336,5.664125919342041,5.010955810546875,5.30672025680542,5.57243537902832,4.939162254333496,6.035238265991211,5.718234062194824,4.8918938636779785,4.914423942565918,5.7035746574401855,5.227282524108887,4.9933085441589355,5.451068878173828,5.566835880279541,5.60699987411499],\"y\":[7.415183067321777,7.818312168121338,8.182561874389648,8.46782398223877,8.623533248901367,7.442472457885742,8.516088485717773,8.112295150756836,8.12131404876709,7.545494079589844,7.781030178070068,8.232161521911621,7.6496124267578125,8.10587215423584,8.54697322845459,8.421651840209961,8.05393123626709,8.40259075164795,7.44068717956543,8.051486015319824,8.007291793823242,8.414055824279785,8.374493598937988,8.270724296569824,7.983619689941406,8.004315376281738,8.319440841674805,8.09707260131836,8.102110862731934,7.6868767738342285,8.252410888671875,8.002951622009277,8.443432807922363,8.267156600952148,8.037740707397461,8.560979843139648,7.90159273147583,8.285704612731934,8.22861099243164,7.346527576446533,8.099997520446777,7.884714603424072,8.14565658569336,8.521873474121094,8.376314163208008],\"type\":\"scattergl\"},{\"hoverinfo\":\"text\",\"hovertext\":[\"Display up to 100 columns\\npd.set_option('display.max_columns', 100)\",\"Display all column names to get an overview\",\"Some countries use comma as decimal separator, others use dot. To avoid truncating the decimal part of large numbers that are printed and will be later converted back to numbers, I set the format to round at the 4th decimal, then we convert numbers using the US format, and let the current system's locale determine how to display these rounded numbers.\",\" Display all columns\\npd.set_option('display.max_columns', None)\",\"Setting the settings for printing all rows when needed\\npd.set_option('display.max_rows', None)\",\"Change display settings to show \\\"max_columns\\\" number of columns.\\n# This makes it easier to inspect DataFrames with many columns.\",\"Setting precision for pandas to avoid scientific notation for large numbers\\npd.set_option('display.float_format', lambda x: '%.3f' % x)\",\"Set the maximum display width so that we can have a better idea of the data\\npd.set_option('display.max_colwidth', 200)\",\" Set up constants for reusable color and optiona configurations.\",\"# Display all columns without truncation\\npd.set_option('display.max_columns', None)\",\"Set default options for pandas.\\npd.set_option('display.max_columns', None)\\npd.set_option('display.max_rows', None)\",\"# Set pandas display options for easier debugging\\npd.set_option('display.max_columns', None)\\npd.set_option('display.width', None)\",\" Display all columns to enable easier exploration\\npd.options.display.max_columns = None\",\"Improve the viewing experience of pandas dataframes\\npd.set_option('display.max_columns', None)\",\" Configure pandas display options for better readability\\npd.options.display.max_columns = 50\\npd.options.display.max_colwidth = 100\",\"Set metadata and display options for pandas dataframes\\npd.set_option('display.max_columns', None)\",\" Disabling a warning\\npd.options.mode.chained_assignment = None\",\"Set width to see more columns\\npd.set_option('display.max_columns', 100)\",\"Set the format of Floats to show two decimal digits\",\"Set maximum column width for dataframes\\npd.set_option('display.max_colwidth', 150)\",\"display\\npd.set_option('display.max_columns', None)\",\"Pretty print settings\\npd.set_option('expand_frame_repr', False)\\npd.set_option('display.max_columns', 500)\\npd.set_option('display.width', 1000)\",\"display first few rows of each dataframe\\npd.set_option('display.max_columns', 50)\",\" Display all column in the dataframe\\npd.set_option('display.max_columns', None)\",\"Set display\\npd.set_option('display.max_columns', None)\\npd.set_option('display.max_colwidth', None)\",\" Optional: Display all columns.\",\"To display all rows and columns\\npd.set_option('display.max_columns', None)\\npd.set_option('display.max_rows', None)\",\"Display options for pandas DataFrame to assure that the content of the DataFrame gets displayed correctly.\",\" Display all columns\\npd.set_option('display.max_columns', None)\",\"Set pandas to display wide tables as needed by this notebook\\npd.set_option('display.max_columns', 50)\",\"Set the max width of the columns\\npd.set_option('display.max_colwidth', 200)\",\"def round_down(num, divisor):\\n    return num - (num%divisor)\",\"To avoid Panda's warning\\npd.options.mode.chained_assignment = None\",\"set output display\\npd.set_option('display.max_rows', 1000)\",\"Setting pandas to print any large field content up to 1024 characters, \\n# the columns that contain the script lines and the normalized text\\npd.set_option('display.max_colwidth', 1024)\",\" Configure pandas display options\\npd.set_option('display.max_columns', None)\",\"# Pandas options for easier debugging\\npd.set_option('display.max_columns', None)\\npd.set_option('display.max_colwidth', None)\"],\"marker\":{\"opacity\":0.5,\"size\":5},\"mode\":\"markers+text\",\"name\":\"5_pandas display options\",\"text\":[\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\"],\"textfont\":{\"size\":12},\"x\":[6.234475612640381,7.136399269104004,6.872233867645264,6.563271522521973,6.569974899291992,6.450423717498779,6.6252970695495605,6.172503471374512,7.51871919631958,6.5545268058776855,6.547479629516602,6.447837829589844,6.631281852722168,6.66529655456543,6.344738006591797,6.702742099761963,6.745729923248291,6.116139888763428,6.976963520050049,6.179501533508301,6.467967510223389,6.256537437438965,6.34113073348999,6.550266742706299,6.171130180358887,6.934755802154541,6.441721439361572,6.784056186676025,6.523946762084961,6.287339210510254,6.123775482177734,6.859535217285156,6.6809210777282715,6.412071704864502,6.292720794677734,6.60793924331665,6.3530707359313965],\"y\":[5.392941474914551,6.03317928314209,4.400899410247803,5.868389129638672,5.723591327667236,4.9995341300964355,4.7490081787109375,4.947951793670654,5.8256635665893555,5.819192409515381,5.35702657699585,4.916691303253174,5.830416679382324,5.175684452056885,4.897572040557861,5.34491491317749,5.652559757232666,5.070084095001221,4.516475200653076,4.933561325073242,5.6431474685668945,5.043010234832764,5.533276557922363,5.580588340759277,5.237067699432373,6.082560062408447,5.7883710861206055,5.05874490737915,5.737937927246094,5.023377895355225,4.970637798309326,4.430978298187256,5.360153675079346,5.624795436859131,4.899606227874756,5.38233757019043,5.050614833831787],\"type\":\"scattergl\"},{\"hoverinfo\":\"text\",\"hovertext\":[\" Display first few rows of the characters dataframe\\ndf_characters.head()\",\"Display the first few rows of the characters dataframe\\ndf_characters.head()\",\" Display the first few rows of the characters dataframe\\ndf_characters.head()\",\"Display the first few rows of the characters dataframe\\ndf_characters.head()\",\" Display the first few rows of the characters dataframe\\ndf_characters.head()\",\"Display the first few rows of the characters dataframe\\ndf_characters.head()\",\" Display the first few rows of the characters DataFrame\\ndf_characters.head()\",\" Display the first few rows of the characters dataframe\\ndf_characters.head()\",\" Display the first few rows of the characters dataframe\\ndf_characters.head()\",\" Displaying the first few rows of the characters dataframe\\ndf_characters.head()\",\"Show the first lines of `df_characters`\",\"Show the first few lines of the characters dataframe\\ndf_characters.head()\",\"Show the first few lines of the dataframe containing the characters\",\" Display the first rows of the characters dataframe\\ndf_characters.head()\",\" Display the first few rows of the characters dataframe\\ndf_characters.head()\",\"Displaying the first few rows of the characters dataframe\\ndf_characters.head()\",\" Display the first few rows of the dataframe\\ndf_characters.head()\",\"Visualize the first few rows of the characters dataframe\\ndf_characters.head()\",\"Display the first few rows of the characters dataframe\\ndf_characters.head()\",\"Display the first few rows of the characters DataFrame\\ndf_characters.head()\",\" Display first rows of the characters dataframe\\ndf_characters.head()\",\"Display the first few rows of the characters dataframe\\ndf_characters.head()\",\"Visualise the first few rows of the characters dataframe\\ndf_characters.head()\",\" Show the first few rows of the dataframe\\ndf_characters.head()\",\"Display the first few rows of the characters dataframe\\ndf_characters.head()\",\"# Display first 10 rows of the characters dataframe\\ndf_characters.head(10)\",\"visualizing the first few rows of the characters data\\ndf_characters.head()\",\"Display the first few rows of the characters dataframe\\ndf_characters.head()\",\"Display the first few rows of the characters dataframe\\ndf_characters.head()\",\"Show the first rows of the characters dataframe\\ndf_characters.head()\",\"Visualize data\\ndf_characters.head()\",\"Display the first few rows of the characters dataframe\\ndf_characters.head()\",\" Display the first few characters of the DataFrames to understand the data\",\"Show first rows of the table to get a sense of what the data looks like\\ndf_characters.head()\",\"Show first few rows of the characters dataframe\\ndf_characters.head()\",\"Display the first few rows of the characters dataframe\\ndf_characters.head()\"],\"marker\":{\"opacity\":0.5,\"size\":5},\"mode\":\"markers+text\",\"name\":\"6_Displaying the first few rows of characters dataframe\",\"text\":[\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\"],\"textfont\":{\"size\":12},\"x\":[11.735685348510742,12.052557945251465,11.766595840454102,11.912210464477539,11.929821014404297,11.744216918945312,11.940847396850586,11.877885818481445,11.786012649536133,11.975773811340332,11.443286895751953,11.68445873260498,11.17900276184082,11.513802528381348,11.794055938720703,11.986331939697266,11.745237350463867,11.488255500793457,11.826681137084961,11.870270729064941,11.483890533447266,11.804426193237305,11.447494506835938,11.732172012329102,11.849205017089844,11.752669334411621,11.38749885559082,11.945889472961426,11.851475715637207,11.474205017089844,11.321036338806152,12.036077499389648,11.034910202026367,11.622773170471191,11.610977172851562,12.00295639038086],\"y\":[-5.079932689666748,-5.265755653381348,-5.400180816650391,-5.1438164710998535,-5.446505069732666,-5.339177131652832,-5.275204658508301,-5.308423042297363,-5.224494457244873,-5.002682209014893,-4.082815170288086,-4.574814319610596,-3.5766968727111816,-4.2565836906433105,-5.407116889953613,-5.096822738647461,-5.009398460388184,-0.11982502788305283,-5.203777313232422,-5.478643417358398,-4.296763896942139,-5.252363204956055,-0.09903229027986526,-4.964112758636475,-5.213696479797363,-5.378543376922607,0.01757653057575226,-5.3355512619018555,-5.293473720550537,-4.051198482513428,0.08930031955242157,-5.403472423553467,-3.1733286380767822,-4.0105881690979,-4.7032976150512695,-5.23352575302124],\"type\":\"scattergl\"},{\"hoverinfo\":\"text\",\"hovertext\":[\"View the first 5 rows of the characters dataframe\\ndf_characters.head()\",\"# Display the first 5 rows of the characters dataset\\ndf_characters.head()\",\"Display the first 5 rows of the characters dataframe\\ndf_characters.head()\",\"View the first 5 rows of the characters dataframe\\ndf_characters.head()\",\"Display the first 5 rows of the characters dataframe\\ndf_characters.head()\",\"Print the first 5 rows of the characters dataframe\\ndf_characters.head()\",\"Display the top 5 rows of the dataframe\\ndf_characters.head()\",\"# Display a random sample of the characters dataframe\\ndf_characters.sample(5)\",\" Display first 5 rows of characters dataframe\\ndf_characters.head()\",\"View the first 5 records of the character data\\ndf_characters.head()\",\" Sample first 5 rows of characters dataframe\\ndf_characters.head()\",\" Display the first 5 rows of the characters dataframe\\ndf_characters.head()\",\"View the first 5 rows of the characters DataFrame\\ndf_characters.head()\",\" Display the first 5 rows of the characters dataframe\\ndf_characters.head()\",\" Show the first 5 rows of the characters dataset\\ndf_characters.head()\",\"Show the first 5 rows of df_characters\\ndf_characters.head()\",\"Display first 5 rows of df_characters\\ndf_characters.head()\",\"Display the first 5 rows of the characters dataframe\\ndf_characters.head()\",\" Display the first 5 rows of the characters dataframe\\ndf_characters.head()\",\"Preview first 5 rows of df_characters\\ndf_characters.head()\",\"View first 5 rows of characters dataframe\",\"Inspect the first 5 rows of the characters DataFrame\\ndf_characters.head()\",\"Display top 5 rows of characters dataframe\\ndf_characters.head()\",\"View the first 5 rows of the characters dataframe\\ndf_characters.head()\",\"Displaying the 5 first rows of the dataframe \\\"df_characters\\\"\",\"Displaying the first 5 rows of the characters dataframe\\ndf_characters.head(5)\",\"# display the first 5 rows of the df_characters dataframe\\ndf_characters.head()\",\"Show the first 5 rows of the dataframe `df_characters`\\ndf_characters.head()\",\"Show first 5 records of characters dataframe\\ndf_characters.head()\",\"# The first 5 rows of the characters table\\ndf_characters.head()\",\"showing the first 5 rows of the characters dataframe\\ndf_characters.head()\",\"View data first 5 rows of `df_characters` DataFrame\\ndf_characters.head()\"],\"marker\":{\"opacity\":0.5,\"size\":5},\"mode\":\"markers+text\",\"name\":\"7_Displaying first 5 rows of characters dataframe\",\"text\":[\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\"],\"textfont\":{\"size\":12},\"x\":[5.062814235687256,4.367095947265625,4.082237243652344,5.073887348175049,4.1356000900268555,4.0146074295043945,4.214926719665527,4.398277282714844,4.06145715713501,4.8326520919799805,4.302624702453613,4.057795524597168,4.957025051116943,4.087445259094238,4.405962944030762,4.466756820678711,4.477910041809082,4.098383903503418,3.976792812347412,4.7535176277160645,4.802554130554199,5.075534820556641,4.182624340057373,4.980483531951904,4.254603385925293,3.9814674854278564,3.9947307109832764,4.2663116455078125,4.422961711883545,4.686577320098877,4.517354488372803,5.075089931488037],\"y\":[-2.5207674503326416,-2.3392374515533447,-2.7015373706817627,-2.6460630893707275,-2.6431925296783447,-2.703833818435669,-2.4445433616638184,-2.105121612548828,-2.6037356853485107,-2.5843088626861572,-2.5903193950653076,-2.626037836074829,-2.4875857830047607,-2.661071538925171,-2.5561656951904297,-2.5072343349456787,-2.606947660446167,-2.733983039855957,-2.74834942817688,-2.5043396949768066,-2.4673447608947754,-2.3508636951446533,-2.4081597328186035,-2.4003520011901855,-2.530805826187134,-2.503044843673706,-2.6203010082244873,-2.5765020847320557,-2.6552364826202393,-2.2541990280151367,-2.7852377891540527,-2.4677481651306152],\"type\":\"scattergl\"},{\"hoverinfo\":\"text\",\"hovertext\":[\"Make it easier to access and manipulate names for the dataframes.\",\"The 'reset_index' method is used to reset the index of the dataframe after reading the CSV files. This method ensures that the index starts from 0 and increases consecutively.\",\" Since the data is already in CSV format, we can use Pandas read_csv function to read the data into dataframes.\",\"General Imports completed. Now, we have declared and initialized the dataframe variables.\",\"Let's take a quick look at the dataframes.\",\" Let's take a look at the structure of the dataframes.\",\" Importing dataframes with pandas using read_csv function.\",\"Let's start by taking a look at the first few rows of each dataframe.\",\"Let's take a look at the first few rows of each dataframe to understand the structure of the data.\",\"Let's quickly have a look at the structure of our dataframes.\",\"Let's have a look at each dataframe first.\",\"Take a quick look at the dataframes\",\"Now that we have loaded the data, we can see the first few rows of each dataframe to understand its structure and contents.\",\"We can see that all of the DataFrames now have an 'index' column which we should drop.\",\"Let's start by taking a look at the first few rows of each dataframe.\",\"First we start with reading the required csv files and resetting the index of the dataframes.\",\"Let's start by taking a look at the first few rows of each dataframe to understand what kind of data we are dealing with.\",\"Use the first few lines of each dataframe to understand the general content.\",\"We have successfully loaded the datasets into dataframes. Now we can explore and analyze the data to gain insights.\",\"Let's check the first rows of each dataframe to know the kind of data we are handling.\",\"We can start the data exploration by looking at the first few rows of each DataFrame.\",\" Let's take a look at the first few lines of each DataFrame.\",\"Let's take a look at the first few entries in these DataFrames.\",\"Let's first look at the structure of our dataframes\",\"Let us consider the structure of the first few rows of all dataframes to understand the data better.\",\"Let's take a look at the first few rows of each DataFrame to understand their structure and information they contain.\",\" Let's take a first look at the data available in our dataframes.\",\"First, we read the necessary CSV files into Pandas DataFrames for further processing.\",\" Now we have loaded the datasets into pandas dataframes, we can start by doing some basic exploratory data analysis to better understand the data.\",\"Let's take a look at the first few rows of each dataframe.\",\"Let's take a look at the structure and content of each dataframe.\"],\"marker\":{\"opacity\":0.5,\"size\":5},\"mode\":\"markers+text\",\"name\":\"8_Exploring Dataframes and Understanding Data Structure\",\"text\":[\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\"],\"textfont\":{\"size\":12},\"x\":[11.294271469116211,11.36594295501709,10.845747947692871,10.771051406860352,10.860676765441895,10.87900161743164,10.809656143188477,11.069062232971191,11.163708686828613,10.739103317260742,11.0809965133667,10.96042251586914,11.16677188873291,11.41832160949707,11.059353828430176,11.19188404083252,10.903779983520508,11.26567554473877,10.459064483642578,11.453933715820312,11.048678398132324,11.06902027130127,10.835001945495605,10.939011573791504,11.108311653137207,11.384626388549805,10.684941291809082,10.876197814941406,10.783468246459961,11.302978515625,11.231513023376465],\"y\":[4.983595371246338,5.465878486633301,5.497896671295166,5.14339542388916,4.584455490112305,4.493597030639648,5.556670188903809,4.936512470245361,4.326361179351807,4.63287878036499,4.716933250427246,4.5356245040893555,3.9522697925567627,5.296091079711914,4.913283348083496,5.455371856689453,4.866030693054199,4.496385097503662,5.096312999725342,4.38066291809082,4.809170722961426,4.702193260192871,4.633927345275879,4.653440475463867,4.2279887199401855,4.318885326385498,4.7116899490356445,5.442775249481201,5.275284290313721,4.648705959320068,4.508679389953613],\"type\":\"scattergl\"},{\"hoverinfo\":\"text\",\"hovertext\":[\"Join characters, locations, episodes to script\\ndf1 = df_script.join(df_characters, on='character_id', rsuffix='_character')\\ndf2 = df1.join(df_locations, on='location_id', rsuffix='_location')\\ndf3 = df2.join(df_episodes, on='episode_id', rsuffix='_episode')\",\"Merge the dataframes to create a single dataframe with all the information we need.\\ndf = pd.merge(df_script,\\n              df_episodes,\\n              how='left',\\n              left_on=['episode_id'],\\n              right_on=['id'],\\n              suffixes=('_script', '_episode')).drop(columns=['id_script'])\\ndf = pd.merge(df,\\n              df_characters,\\n              how='left',\\n              left_on=['character_id'],\\n              right_on=['id'],\\n              suffixes=('', '_character')).drop(columns=['id'])\",\" Merge the data to have all information on the same dataframe\\ndf = (df_script\\n      .merge(df_episodes[['id','title']], how='left', left_on='episode_id', right_on='id')\\n      .merge(df_characters[['id', 'name']], how='left', left_on='character_id', right_on='id', suffixes=('', '_character'))\\n      .merge(df_locations[['id','name']], how='left', left_on='location_id', right_on='id', suffixes=('', '_location'))\\n      )\",\"# convert ids to numbers\\ndf_script['episode_id'] = pd.to_numeric(df_script['episode_id'], errors='coerce')\\ndf_script['character_id'] = pd.to_numeric(df_script['character_id'], errors='coerce')\\ndf_script['location_id'] = pd.to_numeric(df_script['location_id'], errors='coerce')\",\"Combine scripts with characters, locations and episodes info\\ndf_simpsons = df_script.merge(df_characters, on='character_id', how='outer')\\\\\\n                       .merge(df_locations, on='location_id', how='outer')\\\\\\n                       .merge(df_episodes, on='episode_id', how='outer')\",\"# Merge the tables on the episode_id\\ndf = df_script.merge(\\n    df_episodes, \\n    left_on='episode_id', \\n    right_on='id', \\n    suffixes=('_script', '_episode')\\n).merge(\\n    df_characters, \\n    left_on='character_id', \\n    right_on='id', \\n    suffixes=('_script', '_character')\\n).merge(\\n    df_locations, \\n    left_on='location_id', \\n    right_on='id', \\n    suffixes=('_script', '_location')\\n)\",\"Check the structure of dataset (schematics). If the datasets look very complicated with mult-levels of indexes and columns (a problem I have encontered before), consider the following operation:\\n\\n# be sure the indexes are only 1-level deep to make merging easier\\nfor df in [df_script, df_episodes, df_characters, df_locations]: df.reset_index(inplace=True)\\n\\n# Merge all datasets\\ndf = (df_script\\n         .merge(df_episodes, on='episode_id')\\n         .merge(df_characters, on='character_id')\\n         .merge(df_locations, on='location_id')\\n         .sort_values(by='id')\\n         .reset_index(inplace=False, drop=True))\",\" Merge all data into a single dataframe\\ndf_comb = df_script.join(df_characters, on='character_id', rsuffix='_character').join(df_locations, on='location_id', rsuffix='_location').join(df_episodes, on='episode_id', rsuffix='_episode')\",\"Join episode data to scripts\\ndf = df_script.join(df_episodes, on='episode_id', rsuffix='_ep')\\ndf = df.join(df_characters, on='character_id', rsuffix='_ch')\\ndf = df.join(df_locations, on='location_id', rsuffix='_loc')\\n\\ndf = df.drop(columns=['id_ep', 'id_ch', 'id_loc'])\\ndf.columns\",\"Join script with characters and locations\\ndf_script = df_script[df_script.speaking_line == True].copy()  # Remove non speaking lines\\ndf_script = pd.merge(df_script, df_episodes, on='episode_id', how='left')\\ndf_script = pd.merge(df_script, df_characters, on='character_id', how='left')\\ndf_script = pd.merge(df_script, df_locations, on='location_id', how='left')\",\" Merge script data with characters and locations\\ndf_script = df_script[[\\n    'episode_id',\\n    'number',\\n    'raw_text',\\n    'timestamp_in_ms',\\n    'speaking_line',\\n    'character_id',\\n    'location_id',\\n    'raw_character_text',\\n    'raw_location_text',\\n    'spoken_words',\\n    'normalized_text',\\n]].merge(\\n    df_characters.add_prefix('character_'),\\n    left_on='character_id', \\n    right_on='character_id', \\n    suffixes=(None, '_dropped')\\n).merge(\\n    df_locations.add_prefix('location_'), \\n    left_on='location_id', \\n    right_on='location_id', \\n    suffixes=(None, '_dropped')\\n)\\n\\n# Merge with episodes data\\ndf_script = df_script.merge(\\n    df_episodes.add_prefix('episode_'),\\n    left_on='episode_id',\\n    right_on='episode_id',\\n    suffixes=(None, '_dropped')\\n)\",\"Join episodes dataset to script dataset\\ndf = df_script.set_index('episode_id').join(df_episodes.set_index('id'), on='episode_id', rsuffix='_es')\\n\\n# Join characters and locations to the new script dataset\\ndf = df.join(df_characters.set_index('id'), on='character_id', rsuffix='_ch')\\ndf = df.join(df_locations.set_index('id'), on='location_id', rsuffix='_lo')\\n\\ndf.head(3)\",\"Merge all tables in one df\\ndf = df_script.merge(df_characters, on='character_id').merge(df_locations, on='location_id').merge(df_episodes, on='episode_id')\",\" Merge in character information\\ndf_merged_chars = df_script.merge(df_characters, how='left', left_on='character_id', right_on='character_id', suffixes=('_script', '_character'))\\n\\n# Merge in location information\\ndf_merged_locs = df_merged_chars.merge(df_locations, how='left', left_on='raw_location_text', right_on='raw_location_text')\\n\\n# Merge in episode information\\ndf_merged_eps = df_merged_locs.merge(df_episodes, how='left', left_on='episode_id', right_on='id', suffixes=('_script', '_episode'))\",\"Merge characters information into script dataframe\\ndf_script = df_script.merge(df_characters,\\n                            left_on='character_id',\\n                            right_on='character_id',\\n                            suffixes=(False, False))\\n\\n# Merge locations information into script dataframe\\ndf_script = df_script.merge(df_locations,\\n                            left_on='location_id',\\n                            right_on='location_id',\\n                            suffixes=(False, False))\\n\\n# Merge episodes information into script dataframe\\ndf_script = df_script.merge(df_episodes,\\n                            left_on='episode_id',\\n                            right_on='id',\\n                            suffixes=(False, False))\",\"Join all files together\\nsimpsons = pd.merge(df_script, df_episodes,\\n                    on='episode_id', how='left')\\n\\nsimpsons = pd.merge(simpsons, df_characters,\\n                    on='character_id', how='left')\\n\\nsimpsons = pd.merge(simpsons, df_locations,\\n                    on='location_id', how='left')\",\"Filter episode 1 in script dataframe\\ndf_ep1 = df_script[df_script['episode_id'] == '1']\\n\\n# merge episode 1 script lines with characters and locations information\\ndf_ep1_char_loc = df_ep1.merge(df_characters, how='left', left_on='character_id', right_on='id', suffixes=('', '_character'))\\ndf_ep1_char_loc = df_ep1_char_loc.merge(df_locations, how='left', left_on='location_id', right_on='id', suffixes=('', '_location'))\\n\\ndf_ep1_char_loc[['character_id', 'name', 'normalized_name', 'raw_character_text', 'timestamp_in_ms', 'speaking_line', 'location_id', 'raw_location_text', 'word_count', 'episode_id', 'number', 'raw_text']]\",\"Merge for easier data management\\ndf = df_script.merge(df_episodes.add_prefix('episode_'), left_on='episode_id', right_on='episode_id')\\ndf = df.merge(df_characters.add_prefix('character_'), left_on='character_id', right_on='character_id')\\ndf = df.merge(df_locations.add_prefix('location_'), left_on='location_id', right_on='location_id')\",\" Join relevant data\\ndf = (\\n    df_script[['episode_id', 'character_id', 'location_id', 'raw_text']]\\n    .merge(df_episodes, left_on='episode_id', right_on='id')\\n    .merge(df_characters, left_on='character_id', right_on='id')\\n    .merge(df_locations, left_on='location_id', right_on='id')\\n    .drop(['id_x', 'id_y', 'id', 'id', 'episode_id', 'number_in_season', 'number_in_series', 'video_url', 'image_url' ], axis=1)\\n)\",\" Join the script lines with the characters and episodes dataframes\\ndf = df_script.set_index('episode_id').join(df_episodes.set_index('id'), rsuffix='_ep')\\ndf = df.set_index('character_id').join(df_characters.set_index('id'), rsuffix='_ch')\\ndf = df.join(df_locations.set_index('id'), on='location_id')\",\"Merging data on script ids\\ndf_merged = df_script.merge(df_episodes[['id', 'title']], left_on='episode_id', right_on='id', suffixes=('', '_episode'))\\ndf_merged = df_merged.merge(df_episodes[['id', 'season', 'number', 'air_date']], left_on='episode_id', right_on='id', suffixes=('', '_episode'))\\ndf_merged = df_merged.merge(df_characters[['id', 'name']], left_on='character_id', right_on='id', suffixes=('', '_character'))\\ndf_merged = df_merged.merge(df_locations[['id', 'name']], left_on='location_id', right_on='id', suffixes=('', '_location'))\",\"Joining characters, locations and scripts based on the episode\\ndf_characters_locations = pd.merge(\\n    df_characters,\\n    df_locations,\\n    left_on='character_id',\\n    right_on='character_id',\\n    how='right'\\n)\",\"Keep the original datasets to restore to a clean state if necessary\\ndf_characters_original = df_characters.copy()\\ndf_locations_original = df_locations.copy()\\ndf_script_original = df_script.copy()\\ndf_episodes_original = df_episodes.copy()\",\"Remove rows with poor data quality from df_script\\ndf_script = df_script[df_script.character_id.isin(df_characters.id)]\\ndf_script = df_script[df_script.location_id.isin(df_locations.id)]\\ndf_script = df_script[df_script.episode_id.isin(df_episodes.id)]\",\" Merge locations and episodes on `id` column.\\ndf_episodes_locs = pd.merge(df_episodes, df_locations, how='inner', left_on='id', right_on='location_id').reset_index(inplace=False, drop=True)\",\"concatenate the location name and the episode name to have a total of 190 unique entries\\nunique_locations_episodes = df_locations['name'].apply(lambda x: x.lower()).append(df_episodes['title'].apply(lambda x: x.lower()))\",\"Merge script data with episode data\\ndf_episodes = df_episodes.rename(columns={'id': 'episode_id'})\",\"Merge locations with episodes, and then with characters\\ndf_isInEpisode = df_script.merge(df_episodes, left_on='episode_id', right_on='id')\\ndf_isInEpisode = df_isInEpisode.merge(df_locations, left_on='location_id', right_on='id')\\ndf_isInEpisode = df_isInEpisode.merge(df_characters, left_on='raw_character_text', right_on='name')\"],\"marker\":{\"opacity\":0.5,\"size\":5},\"mode\":\"markers+text\",\"name\":\"9_DataFrame Merge and Join Operations\",\"text\":[\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\"],\"textfont\":{\"size\":12},\"x\":[16.152950286865234,15.661316871643066,16.14455795288086,16.475074768066406,16.208284378051758,16.166967391967773,15.83088207244873,15.91661548614502,15.86334228515625,15.83428955078125,15.995563507080078,16.008804321289062,16.134056091308594,16.23155975341797,16.204002380371094,16.35245704650879,15.78684139251709,16.049474716186523,15.832096099853516,16.172565460205078,16.02784538269043,16.381898880004883,15.570403099060059,15.698896408081055,15.831012725830078,16.123523712158203,15.755728721618652,16.207616806030273],\"y\":[9.215084075927734,8.8469877243042,8.68471622467041,8.80051326751709,8.55805492401123,8.767291069030762,8.918410301208496,9.208693504333496,9.130084991455078,8.396749496459961,8.257513046264648,9.251226425170898,8.838645935058594,8.483208656311035,8.558419227600098,8.653862953186035,8.460000991821289,8.622629165649414,8.734350204467773,9.122830390930176,8.629417419433594,8.342391014099121,8.946977615356445,8.948884010314941,8.74764633178711,8.581242561340332,8.67318058013916,8.432649612426758],\"type\":\"scattergl\"},{\"hoverinfo\":\"text\",\"hovertext\":[\" Define helper function to get main-episode characters\",\"Set the script line limits to avoid incredibly long sequences, line length and episode length.\",\"Count line with dialogues by character, location and episode\",\"Create name list and sentence list\",\"Create a new column with the episode title in the lines dataframe\",\"Merging dataframe on character and locations on the episode_id\",\" Episode  where character appears\",\"Join the episode to the script lines on episode_id, script_id and raw_text, and only select the columns we need.\",\"Filter the data to keep only episodes that occured after 2000\",\"Split the dataframes in their episodes\",\" Combining the script lines with the episodes data to get the title of each episode.\",\"connect all the episodes to scripts and each script to a character and location\",\"Create a dictionary that maps episode ids to a list of script lines for that episode\",\"Make a list of episode ids for each season\",\"Combine `simpsons_script_lines` with `simpsons_episodes`\",\"Merge tables: episodes, script lines, characters, and locations\",\"Extract and process seasons\\u002fepisodes numbers\",\"Create mappings to convert between character_id\\u002fepisode_id and character_name\\u002fepisode_name\",\" Filter the characters lines from the episode 1\",\"Combine the lines in the script with the respective episode and character.\",\"Merge the characters, script, and locations data frames on the episode_id and the id\\u002fepisode_id columns respectively to get one consolidated data frame.\",\"Combine the episodes dataframe and the characters and location dataframe to get the exact location of the scenes\",\"Count lines per character and episode\",\" Check the number of lines for a representative episode\",\"For preprocessing we will only keep the rows: character_name, raw_text, word_count, episode_name, location_id.\",\"Merge the data based on the episode id\",\"Limit the script to the first 5 seasons\"],\"marker\":{\"opacity\":0.5,\"size\":5},\"mode\":\"markers+text\",\"name\":\"10_Combining script lines with episodes and creating a dictionary of episode ids and script lines\",\"text\":[\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\"],\"textfont\":{\"size\":12},\"x\":[13.0033597946167,12.868023872375488,13.595135688781738,13.46743392944336,15.354175567626953,13.96864128112793,13.318466186523438,13.485430717468262,13.815096855163574,15.274868965148926,13.144988059997559,13.103565216064453,13.347038269042969,13.421086311340332,12.862898826599121,13.325299263000488,13.468183517456055,13.710201263427734,13.28581714630127,13.06352710723877,13.550341606140137,13.809042930603027,13.432917594909668,13.372031211853027,13.492844581604004,13.701774597167969,13.159574508666992],\"y\":[7.425449848175049,7.928696155548096,7.099838733673096,7.5375075340271,9.157493591308594,8.123597145080566,7.326766014099121,7.938916206359863,8.627822875976562,9.252640724182129,7.843502044677734,7.883644104003906,7.803640842437744,8.053092956542969,7.488497257232666,8.01584243774414,8.329963684082031,8.029203414916992,7.171269416809082,7.584227085113525,7.9241461753845215,8.209622383117676,7.247745513916016,7.338062763214111,7.86598014831543,8.097442626953125,8.234777450561523],\"type\":\"scattergl\"},{\"hoverinfo\":\"text\",\"hovertext\":[\"Get all the scripts for a given character and calculates the number of words\\ndef get_character_scripts(df_script,\\n                          character_id,\\n                          character_name,\\n                          locations,\\n                          min_words=50):\\n    valid_characters = df_script[(df_script['raw_character_text'] == character_name) &\\n                                 (df_script['timestamp_in_ms'] \\u003e 0) &\\n                                 (~df_script['raw_location_text'].isin(locations))]\\n\\n    valid_characters['word_count'] = valid_characters['spoken_words'].str.split().map(len)\\n    valid_characters = valid_characters[valid_characters['word_count'] \\u003e= min_words]\\n    return valid_characters\",\"Extract characters mentioned\\ndf_script_characters = df_script[df_script.speaker.str.lower().isin(df_characters.name.str.lower())]\",\" Spacy settings\\nnlp = spacy.load('en_core_web_sm', disable=['parser', 'ner'])\\n\\n# Remove superhero speech from the characters' lines\\nmask = df_script.raw_character_text.str.contains('^\\\\s*(V-|Simpsons|J\\\\W|Springfield|Ned\\\\W|Maude|Sea+\\\\W|Todd|Luann|Sherri|Terri|Rod(?:d?)|Milhouse|Kent\\\\W|Helen|Clancy\\\\W|Brockman|Lionel|Apu|\\\\s\\\\Wl\\\\W)?$', case=False, na = False)\\ndf_script = df_script.loc[mask]\",\"Visualize the most common words in the Simpsons script\\nscript_texts = df_script.reset_index(inplace=False, drop=True)['spoken_words']\\nscript_texts.dropna(inplace=True)\\nscript_texts = \\\" \\\".join(script_texts.astype(str).tolist())\",\" Drop unnecessary columns\\ndf_script = df_script.drop(columns=['normed_text'])\\ndf_script = df_script.drop(columns=['spoken_words'])\",\"Create WordCloud for the most frequent words in the script\\nscript_text = ' '.join(df_script['normalized_text'].values)\\n\\n# Create a WordCloud object\\nwordcloud = WordCloud(width=800, height=400, background_color ='black').generate(script_text)\",\"Filter out segment lines from script\\ndf_script = df_script[df_script['speaking_line']]\",\" Remove all entries with empty spoken words in the script dataframe\\ndf_script = df_script[df_script['spoken_words'].notna()]\",\"Function to compute the count of each character\\ndef compute_character_mentions(script, characters):\\n    character_mentions = {character: 0 for character in characters}\\n    for character in characters:\\n        character_mentions[character] = sum(script.raw_text.str.contains(character))\\n    return character_mentions\",\"Extract character dialogues from the script data\\ncharacters = df_script['raw_character_text'].value_counts().index\\ndialogues = {}\\nfor character in characters:\\n    dialogues[character] = ' '.join(df_script[df_script['raw_character_text'] == character]['spoken_words'].fillna('').values)\",\"calculate the number of lines each character has spoken\\nlines_per_character = df_script['raw_character_text'].value_counts()\\n\\n# Plot the distribution of number of lines spoken by each character\\nplt.figure(figsize=(10, 6))\\nplt.hist(lines_per_character, bins=range(50), edgecolor='black', log=True)\\nplt.xscale('log')\\nplt.yscale('log')\\nplt.title('Distribution of Number of Lines Spoken by Each Character')\\nplt.xlabel('Number of Lines Spoken')\\nplt.ylabel('Number of Characters')\\nplt.show()\",\"# Clean text\\ndf_script['spoken_words'] = df_script['spoken_words'].apply(lambda x: x.lower().strip())\",\"Turn labels listed as 'talking, singing,' into one label column\",\"Remove any lines that are not speech from the script dataframe\\ndf_script_speech = df_script.dropna(subset=['spoken_words']).copy()\",\"Create a table matching characters with their spoken lines\\nconversation_lines = df_script[df_script['speaking_line'] == True]\",\"Add a lowercased version of the 'spoken_words' column for simplicity of future analyses\\ndf_script['spoken_words_lower'] = df_script['spoken_words'].str.lower()\",\"Top characters\\ntop_char_mask = df_script.raw_character_text.isin(df_script.raw_character_text.value_counts().index[:15])\\ntop_char = df_script[top_char_mask]\\n\\n# Create a list of every line for the top characters\\ntop_char_lines = top_char.groupby('raw_character_text').apply(lambda x: x['spoken_words'].str.cat()).reset_index().rename(columns={0: 'lines'})\\ntop_char_lines.lines = top_char_lines.lines.apply(lambda x: str(x).replace(\\\"nan\\\", \\\"\\\"))\\ntop_char_lines.lines = top_char_lines.lines.apply(lambda x: str(x).replace(\\\"...\\\", \\\"\\\"))\\ntop_char_lines.lines = top_char_lines.lines.apply(lambda x: str(x).replace(\\\"I'm\\\", \\\"I am\\\"))\",\" Generate figure of the Simpsons family\\n\\nfrom constants import FAMILY_MEMBERS\\n\\n# Filter dataframe\\ndf_family = df_characters[df_characters.character.str.lower().isin(FAMILY_MEMBERS)].reset_index(inplace=False, drop=True)\\n\\n# Display locations\\nplt.figure(figsize=(15, 6))\\nword_count = WordCloud(width=1000, height=500, background_color='white').generate(' '.join(df_family.character))\\nplt.imshow(word_count, interpolation='bilinear')\\nplt.axis('off')\",\"Filter the script dataframe to only include spoken words and not scene directions\",\"Create a new temporary column by combining the raw_text and spoken_words column.\",\"Filtering on the spoken lines, unifying the unigrams, and counting their occurrences for all the characters will lead us to a feature-space of about 78,000 columns.\",\" Remove the entries from script lines that have no speaker, location, or raw text\\ndf_script = df_script[pd.notnull(df_script[\\\"raw_text\\\"]) & pd.notnull(df_script[\\\"speaking_line\\\"]) & pd.notnull(df_script[\\\"location_id\\\"])]\",\"Create a dataframe with the 5 most common words\",\"Filter script to only include spoken lines on the show (no scene switching or extra information)\",\" Define the input data and the target data\\nX = df_script.speaking_line.values\\ny = df_script.raw_character_text.values\"],\"marker\":{\"opacity\":0.5,\"size\":5},\"mode\":\"markers+text\",\"name\":\"11_Script Analysis and Character Line Distribution\",\"text\":[\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\"],\"textfont\":{\"size\":12},\"x\":[14.498130798339844,14.825112342834473,14.422075271606445,14.101676940917969,14.24020004272461,10.480656623840332,14.199346542358398,14.32009506225586,14.675565719604492,14.492796897888184,14.163505554199219,14.34202766418457,14.076929092407227,14.365589141845703,14.26501178741455,14.405282020568848,14.350008010864258,13.938494682312012,14.15562629699707,14.113057136535645,10.375114440917969,14.340201377868652,10.889490127563477,13.960847854614258,14.436656951904297],\"y\":[6.732908725738525,7.0435967445373535,7.56366491317749,6.660534858703613,7.153886318206787,3.543860673904419,7.312322616577148,7.106225967407227,6.686307430267334,6.956051349639893,6.563337802886963,6.971583843231201,6.80974006652832,7.22019100189209,7.075632572174072,6.883462429046631,6.678048610687256,6.422750473022461,7.403261661529541,6.896717548370361,2.0996060371398926,7.397313594818115,3.0973730087280273,7.373837947845459,7.150695323944092],\"type\":\"scattergl\"},{\"hoverinfo\":\"text\",\"hovertext\":[\" More imports\",\"Connect to the database\\nimport sqlite3\",\"Enable logging\\nimport logging\",\"\\nimport string\",\"Just a simple line to ensure everything's working fine.\\nprint('Backup successful.')\",\" Database creation\\nfrom sqlalchemy import create_engine\\n\\n# Put the DB in the the \\u002fdata folder.\\n# We don't need to provide user or password since the DB is intended to be used locally in local development.\",\" If you get an error loading any of these files, you may need to update the file paths to match your local environment.\",\"Check the content of each of the files\",\"Checking the script CSV file is well defined and prepared for analysis\",\"print(\\\"Data Loaded\\\")\",\"See the statically typing of the imported files\",\"Check if data is loaded correctly.\",\"See the loaded csv data\",\"Check the CSV files have been read correctly\",\"What CSV files are present?\\nos.listdir('data')\",\"Check imports and data\",\"Set custom logger for debugging\\nimport logging\\n\\nlogging.basicConfig(level=logging.DEBUG, format=\\\"%(levelname)s: %(message)s\\\")\",\"Check if we have the data files\",\"Let's take a quick look at the structure of the files.\",\" Connect to database\\nimport sqlite3\",\"Connecting to MongoDB\",\"Check that everything is correctly loaded\",\"Create and update queries folder if it doesn't exist.\"],\"marker\":{\"opacity\":0.5,\"size\":5},\"mode\":\"markers+text\",\"name\":\"12_Connecting to a Local SQLite Database\",\"text\":[\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\"],\"textfont\":{\"size\":12},\"x\":[9.423986434936523,9.118836402893066,8.768707275390625,9.236769676208496,8.612070083618164,9.23697566986084,10.2577486038208,9.85621452331543,11.053754806518555,10.418563842773438,9.516926765441895,10.46888542175293,10.497031211853027,10.417012214660645,10.671571731567383,9.530290603637695,8.270283699035645,9.933104515075684,9.77724838256836,9.136622428894043,9.163641929626465,10.483084678649902,9.206913948059082],\"y\":[7.041270732879639,6.782043933868408,6.901738166809082,6.948246479034424,6.493417739868164,6.644141674041748,7.40385103225708,7.365670680999756,7.258028984069824,7.608260154724121,7.192277908325195,7.654402256011963,7.317163944244385,7.255075454711914,7.014959335327148,7.243138790130615,6.784774303436279,7.282016277313232,7.466285228729248,6.675177097320557,6.610165119171143,7.791823387145996,6.683432102203369],\"type\":\"scattergl\"},{\"hoverinfo\":\"text\",\"hovertext\":[\"Show the total number of records in each dataframe\",\"Inspect the first 5 rows of each dataframe.\",\"Display the first few rows of each DataFrame to understand its structure and available data.\",\"Check the first few rows of the dataframe to get an idea of the data\",\"Display the first few rows of each DataFrame to get an overview of the data\",\"Checking the first 5 rows of each data frame to ensure they look appropriate.\",\"Visually inspect the first five rows of each dataframe.\",\"Let's display the first rows of each resulting DataFrame to get a better understanding of the available data.\",\"Inspect each dataframe(types, first few rows)\",\" Display the first few lines of each dataframe to understand the data\",\"Display the first 5 rows of each dataframe to understand the structure of the data.\",\"display the first dataframe to inspect the data\",\" Display the first few rows of each dataframe to understand its structure and fields available.\",\"Inspect the first few rows of each dataframe to understand the data\",\"Optional: Display the first few rows of each dataframe to understand the data.\",\"Inspect the first few rows of each dataframe to understand the data\",\" Display the first 5 rows of each dataframe to get an idea of the data\",\"Display first 5 rows of each dataframe to understand the data\",\"Let's see the first 5 entries in each DataFrame.\",\"Display top 5 rows of each DataFrame to understand the data\",\" Print the first few rows of each dataframe to understand the data\"],\"marker\":{\"opacity\":0.5,\"size\":5},\"mode\":\"markers+text\",\"name\":\"13_Understanding DataFrame Structure by Displaying First 5 Rows of Each DataFrame\",\"text\":[\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\"],\"textfont\":{\"size\":12},\"x\":[11.774785995483398,11.60521411895752,11.247302055358887,11.399433135986328,11.482901573181152,11.623638153076172,11.529569625854492,11.125856399536133,11.531993865966797,11.223664283752441,11.434404373168945,11.396757125854492,11.26716423034668,11.228163719177246,11.228872299194336,11.273683547973633,11.685210227966309,11.598343849182129,11.335959434509277,11.684098243713379,11.401690483093262],\"y\":[3.465601921081543,3.216808557510376,3.543238639831543,3.651946783065796,3.3914690017700195,3.231381893157959,3.096654176712036,3.6657168865203857,3.8136653900146484,3.4547982215881348,3.059627056121826,3.544991970062256,3.655747652053833,3.6785266399383545,3.6944355964660645,3.623288154602051,3.1747233867645264,3.148979663848877,3.187598705291748,3.119446039199829,3.430593729019165],\"type\":\"scattergl\"},{\"hoverinfo\":\"text\",\"hovertext\":[\"Remove trivial columns where most of the values are NaN\",\" Drop column index that was added before \",\"Filtering columns\",\"Remove useless columns for the analysis\",\"Remove the original index column, if it was loaded.\",\"Set index to speed up merge operation later\",\"Remove unnecessary columns for the cleaning of this database\",\"Load the data using Pandas and reset the index.\",\"Keep some useful columns only.\",\"Remove the unnecessary columns from the dataframes\",\" Remove any unnecessary columns to save memory\",\"Remove unwanted columns and merge the dataframes\",\"Cleaning the subtitle column by removing unwanted punctuation and characters\",\"1. Cleaning of the data\\n# 1.1 Remove rows where important fields are NaN\",\"Set column for character and location and removing some unused columns\",\"Remove row with NaN value in 'raw_text' column and reset the indices\",\"Filter columns and join the tables\",\" Remove unintended columns for dataframe\",\"Filter unnecessary columns from the dataframe\",\"Remove old index columns\",\"Remove unwanted columns from main dataframe\"],\"marker\":{\"opacity\":0.5,\"size\":5},\"mode\":\"markers+text\",\"name\":\"14_Removing unnecessary columns from dataframes\",\"text\":[\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\"],\"textfont\":{\"size\":12},\"x\":[12.3106107711792,12.460625648498535,11.817598342895508,11.846955299377441,12.316926956176758,12.263147354125977,11.598040580749512,11.503567695617676,11.371912002563477,12.183477401733398,11.845877647399902,12.109074592590332,11.577094078063965,12.172770500183105,11.7120943069458,12.645367622375488,11.532076835632324,12.240392684936523,12.253893852233887,12.277231216430664,12.250679016113281],\"y\":[9.626989364624023,8.547913551330566,9.260878562927246,9.038806915283203,8.410391807556152,8.782752990722656,9.166028022766113,5.905609607696533,9.09679126739502,9.260401725769043,9.048166275024414,9.543205261230469,8.735153198242188,9.486473083496094,8.962414741516113,9.378071784973145,9.300383567810059,9.276815414428711,9.339178085327148,8.684775352478027,9.35264778137207],\"type\":\"scattergl\"},{\"hoverinfo\":\"text\",\"hovertext\":[\"Setting of random seed for reproducibility\\nnp.random.seed(8)\",\"Set random seed for reproducibility\\nnp.random.seed(0)\",\"Set random seed for reproduction of results\\nnp.random.seed(42)\",\"Set random seed for reproducibility\\nnp.random.seed(0)\",\"Setting the random seed for reproducibility\\nnp.random.seed(0)\",\"Setting random seed for reproducibility\\nnp.random.seed(0)\",\" Set random seed for reproducibility\\nnp.random.seed(0)\",\"Set seed for reproducibility\\nnp.random.seed(0)\",\"Set seed for reproducibility\",\"Set the seed for numpy's random number generator for reproducibility.\",\"Set SEED for reproducibility\\nSEED = 45\",\"Set the seed for reproducibility\\nnp.random.seed(42)\",\"Set random seed for reproducibility\\nnp.random.seed(0)\",\"Set seed for reproducibility\\nnp.random.seed(0)\",\"Set random seed for reproducibility\\nnp.random.seed(56)\",\"Set random seed for reproducibility\\nnp.random.seed(0)\",\" Set the seed for reproducibility\\nnp.random.seed(0)\",\"Set random seed for reproducibility\\nnp.random.seed(0)\",\"Setting the seed for reproducibility.\"],\"marker\":{\"opacity\":0.5,\"size\":5},\"mode\":\"markers+text\",\"name\":\"15_Setting Seed for Reproducibility\",\"text\":[\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\"],\"textfont\":{\"size\":12},\"x\":[-0.6750485897064209,-0.7113944888114929,-0.6454142928123474,-0.6522327661514282,-0.7799030542373657,-0.7873996496200562,-0.6013884544372559,-0.7468516230583191,-0.9305680990219116,-0.5969296097755432,-0.8814573884010315,-0.8534432649612427,-0.6203089952468872,-0.7847040295600891,-0.5611372590065002,-0.716553807258606,-0.8107829093933105,-0.6313409209251404,-0.9233168363571167],\"y\":[7.847376346588135,7.903292655944824,7.774837017059326,7.778036594390869,7.9525146484375,7.917212009429932,7.847599983215332,7.758988380432129,8.034364700317383,7.565019607543945,7.963282108306885,7.759133338928223,7.706089973449707,7.7164812088012695,7.714828968048096,7.642394065856934,7.656195640563965,7.71444845199585,8.006903648376465],\"type\":\"scattergl\"},{\"hoverinfo\":\"text\",\"hovertext\":[\"Set plot graphs style\\nmatplotlib.style.use('seaborn')\",\" Set the drawing parameters for the WordCloud and the matplotlib figure parameters\",\"Helper method to create a wordcloud from a text\\ndef plot_wordcloud(text, title, ax, width, height):\\n    wordcloud = WordCloud(width=width, height=height, background_color='white').generate(text)\\n\\n    ax.imshow(wordcloud, interpolation='bilinear')\\n    ax.set_title(title, fontdict={'size': 14, 'color': 'black'})\\n    ax.axis('off')\",\"set True to build the wordclouds from scratch. False will load the stored images\\nbuild_wordclouds = True\",\"Set font scales and styles for matplotlib and seaborn\\nmatplotlib.rcParams.update({'font.size': 14, 'font.family': 'sans', 'text.usetex': False})\",\"Set plot style\\nplt.style.use('ggplot')\",\" Update the style\\nmatplotlib.style.use('bmh')\",\" Set the parameters for the matplotlib visualization\",\"To use the colors_and_fonts helper module, its parent directory must be in the $PYTHONPATH. Let's add it and then test it.\",\"Set seaborn theme\",\"Intents\\nfrom IPython.display import display, Math, Latex\",\"Seeing if Jupyter is available\",\"Visualization_CONFIG\\nfont = {'family' : 'DejaVu Sans',\\n        'weight' : 'normal',\\n        'size'   : 14}\\n\\nmatplotlib.rc('font', **font)\",\"Show plots inline in a Jupyter Notebook\\n%matplotlib inline\",\"Set Seaborn theme\\nsns.set(style=\\\"whitegrid\\\")\",\"jupyter notebook\\nfrom IPython.display import display\",\" Set up matplotlib with the appropriate settings for Jupyter notebook\\nmatplotlib.rcParams.update({\\n    'font.size': 14,\\n    'figure.figsize': (15, 8),\\n    'figure.facecolor': '#00000000',\\n    'axes.labelsize': 14,\\n    'axes.labelcolor': '#555555',\\n    'axes.labelweight': 'bold',\\n    'axes.labelsize': 14,\\n    'axes.grid': True,\\n    'grid.color': '#aaaaaa',\\n    'grid.alpha': 0.3,\\n    'axes.titlesize': 18,\\n    'axes.titlecolor': '#555555',\\n    'axes.titleweight': 'bold',\\n    'axes.titlepad': 6.0,\\n    'xtick.labelsize': 12,\\n    'ytick.labelsize': 12,\\n    'xtick.color': '#555555',\\n    'ytick.color': '#555555',\\n    'legend.fontsize': 12,\\n    'legend.title_fontsize': 14,\\n    'legend.edgecolor': '#000000',\\n    'legend.facecolor': '#f0f0f0',\\n    'svg.fonttype': 'path',  # Edit: I needed to add this line as web traffic said \\n                             # my fonts were being rasterized\\n})\",\" Stop output from being printed\\nfrom IPython.display import HTML\",\"!pip install wordcloud\"],\"marker\":{\"opacity\":0.5,\"size\":5},\"mode\":\"markers+text\",\"name\":\"16_Setting styles and fonts for Matplotlib in Jupyter Notebook\",\"text\":[\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\"],\"textfont\":{\"size\":12},\"x\":[8.661957740783691,8.982500076293945,9.238980293273926,9.483325958251953,8.708333015441895,8.549315452575684,8.626482963562012,8.774188041687012,8.697263717651367,8.69500732421875,8.446666717529297,8.388160705566406,8.729134559631348,8.61397647857666,8.5947265625,8.47943115234375,8.683483123779297,8.24622917175293,9.299261093139648],\"y\":[4.9136199951171875,5.120650768280029,5.062121391296387,5.468150615692139,4.9730224609375,4.829414367675781,4.877166748046875,4.972164154052734,5.561975002288818,4.910318374633789,5.5537543296813965,5.440611839294434,5.035490036010742,5.109190940856934,4.858018398284912,5.437490463256836,4.986906051635742,5.834867000579834,5.336853981018066],\"type\":\"scattergl\"},{\"hoverinfo\":\"text\",\"hovertext\":[\"Inspect the dataframes\",\" Look at each dataframe's columns and data types\",\"Display the dataframe columns and some of the data to inspect what the data looks like.\",\"Check the resulting dataframes\",\" Just reimport the dataframes\",\"Inspect the dataframes\",\"Visualise all dataframes to understand the tabular structure\",\"Check the structure of each dataframe\",\"View the main dataframes to get an idea of the available fields\",\"Check what is the format of the first dataframe\",\"Inspect the dataframes\",\"Inspect the dataframes to understand their structure and contents\",\"Visualize some dataframes using pandas display method\",\"Check the basic information for each DataFrame\",\"Quick look at the dataframes head\",\"Check if the dataframes were loaded correctly\",\"The head of the DataFrames to understand the structure of the data\",\"Inspect dataframes quickly\",\"Inspect the dataframes\"],\"marker\":{\"opacity\":0.5,\"size\":5},\"mode\":\"markers+text\",\"name\":\"17_Inspecting dataframes and understanding their structure\",\"text\":[\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\"],\"textfont\":{\"size\":12},\"x\":[12.336613655090332,12.04787540435791,12.303934097290039,12.576687812805176,12.369110107421875,12.237353324890137,11.617931365966797,12.455890655517578,12.176297187805176,12.166722297668457,12.29536247253418,12.157773971557617,11.993668556213379,12.406771659851074,12.696163177490234,12.767524719238281,11.960953712463379,12.51077938079834,12.23788070678711],\"y\":[4.676304340362549,4.450771808624268,4.731729507446289,4.086529731750488,4.821076393127441,4.573298454284668,4.234312057495117,4.163500785827637,4.629570484161377,4.025805473327637,4.692142009735107,4.441622734069824,4.764084339141846,4.154034614562988,4.070479393005371,4.2010698318481445,4.267073631286621,4.787423133850098,4.620866775512695],\"type\":\"scattergl\"},{\"hoverinfo\":\"text\",\"hovertext\":[\"We have loaded four datasets: characters, locations, script lines, and episodes.\",\"Quick view of the Simpsons characters dataset\\ndf_characters.head()\",\"Explore 'simpsons_script_lines.csv'\",\"Display how the Simpsons data looks like.\",\"These files contain information about the characters, locations, script lines, and episodes of the Simpsons TV show.\",\"Visualize the Simpsons characters dataset\",\"Exemplary instance of the dataset \\\"simpsons_script_lines\\\"\\ndf_script.head()\",\"s_data_directory = 'simpsons_dataset'\",\" This code snippet reads in several CSV files using pandas and the read_csv method. These CSV files likely contain data related to the characters, locations, script lines, and episodes from the TV show \\\"The Simpsons.\\\" The data is then stored in corresponding pandas DataFrames named df_characters, df_locations, df_script, and df_episodes. The data from these DataFrames is likely to be used for further analysis, visualization, or processing.\",\"Replace `simpsons_characters.csv` and `simpsons_script_lines.csv` with cleaned datasets\",\"This line of code loads the datasets containing information about the characters, locations, script lines, and episodes of The Simpsons.\",\"Show the first few lines of the Simpsons characters dataset\\ndf_characters.head()\",\"Inspecting the content of the 'simpsons_characters.csv' file.\",\"Display the first few lines of the Simpsons script dataset\\ndf_script.head()\",\"Retrieving all the datasets from the given CSV files which contain relevant information about the Simpsons TV show.\",\"Visualizing the Simpsons script data\",\"Display the top 5 records of the Simpsons script dataframe to understand its structure and content\\ndf_script.head()\"],\"marker\":{\"opacity\":0.5,\"size\":5},\"mode\":\"markers+text\",\"name\":\"18_The Simpsons TV Show\",\"text\":[\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\"],\"textfont\":{\"size\":12},\"x\":[11.824726104736328,12.577808380126953,11.824024200439453,12.062225341796875,11.658021926879883,12.153059959411621,12.859004020690918,11.149470329284668,11.695712089538574,11.943970680236816,11.55608081817627,12.842069625854492,11.827858924865723,13.088590621948242,11.535656929016113,11.973243713378906,13.352558135986328],\"y\":[7.125058650970459,5.897441387176514,6.6577229499816895,6.38881254196167,6.623762130737305,6.314966201782227,5.777614593505859,6.626905918121338,6.6541428565979,6.550915718078613,6.837099552154541,5.83747673034668,6.57464599609375,5.59116792678833,6.692026615142822,6.405850887298584,5.354161739349365],\"type\":\"scattergl\"},{\"hoverinfo\":\"text\",\"hovertext\":[\"Merge dataframe on essential columns: character, raw_location_text and raw_character_text for each script line\",\"Merge Simpsons script with corresponding characters and locations\\ndf_script = df_script.merge(df_characters, on='character_id', how='left')\\ndf_script = df_script.merge(df_locations, on='location_id', how='left')\",\"Combine the script with the locations and characters on the script lines table\\ndf_script = df_script.merge(\\n    df_characters,\\n    how='left',\\n    left_on='character_id',\\n    right_on='id'\\n).merge(\\n    df_locations,\\n    how='left',\\n    left_on='location_id',\\n    right_on='id'\\n)\",\"Merge df_script with df_characters\\ndf_script = df_script.merge(df_characters, how='left', left_on='character_id', right_on='id', suffixes=('', '_character'))\",\"Merge characters and locations with the script\\ndf_with_characters = pd.merge(df_script, df_characters, how='left', on='character_id')\\ndf_with_locations = pd.merge(df_with_characters, df_locations, how='left', on='location_id')\",\"# Correct inconsistent variable names\\ndf_characters.rename(columns={'id':'character_id', 'name':'character_name'}, inplace=True)\\ndf_locations.rename(columns={'id':'location_id', 'name':'location_name'}, inplace=True)\\ndf_episodes.rename(columns={'id':'episode_id', 'title':'episode_title'}, inplace=True)\",\" Combine the character and location datasets into one dataframe\\ndf_metadata = pd.concat([df_characters, df_locations], ignore_index=True)\",\"Merge characters and locations to script\\n#df_characters = df_characters[['id', 'name']]\\n#df_script = df_script.merge(df_characters, left_on='character_id', right_on='id')\\n#df_script = df_script.drop('id', axis=1)\\n\\n#df_locations = df_locations[['id', 'name']]\\n#df_script = df_script.merge(df_locations, left_on='location_id', right_on='id')\\n#df_script = df_script.drop('id', axis=1)\",\" We need to convert character_id and location_id to ints\\ndf_script['character_id'] = df_script['character_id'].fillna(-1).astype(int)\\ndf_script['location_id'] = df_script['location_id'].fillna(-1).astype(int)\",\"Convert Character IDs to Character names\\ndf_script_characters = pd.merge(df_script, df_characters, \\n                                how='left', \\n                                left_on=['character_id'], \\n                                right_on=['id'])\",\"Clean out data - as I will be using character_id and location_id, the rest of the fields might not be useful\\n# Cleaning is not mandatory, it really depends what you want to predict and how you want to analyze the data!\\ndf_script.head()\",\"Merge characters into script\\ndf_chars_script = pd.merge(df_script, df_characters, how='left', left_on='raw_character_text', right_on='name')\\n\\n# Merge locations into script\\ndf_merged = pd.merge(df_chars_script, df_locations, how='left', left_on='raw_location_text', right_on='name')\",\" Preprocess data\\n# Drop rows with missing values\\ndf_script = df_script.dropna(subset=['character_id', 'location_id', 'raw_text'])\\n\\n# Merge dataframes\\ndf_script_info = pd.merge(df_script, \\n                          df_characters, \\n                          how='left', \\n                          on='character_id', \\n                          suffixes=('_script', '_character'))\\n\\ndf_script_info = pd.merge(df_script_info, \\n                          df_locations, \\n                          how='left', \\n                          on='location_id', \\n                          suffixes=('_old', '_location'))\",\"Merge characters and script\\ndf_characters_script = df_script.merge(df_characters, left_on='character_id', right_on='id')\",\" Merge the scripts with the corresponding characters and locations\\ndf = df_script.merge(df_characters, 'left', on='character_id').merge(df_locations, 'left', on='location_id')\",\"Remove the rows with Nan in `uselocation_id` and `character_id` and merge with locations and characters respectively\\ndf_script = df_script[(~df_script.uselocation_id.isna()) & (~df_script.character_id.isna())]\\n\\ndf_script = pd.merge(df_script, df_characters, left_on='character_id', right_on='raw_character_text')\\ndf_script = pd.merge(df_script, df_locations, left_on='uselocation_id', right_on='raw_location_text')\",\"Concatenate location data\\ndf_locations = pd.concat([df_locations, df_locations['image_url'].str.split(';', expand=True)], axis=1)\\ndf_locations = df_locations.rename(columns={0: 'image_url_0', 1: 'image_url_1'})\"],\"marker\":{\"opacity\":0.5,\"size\":5},\"mode\":\"markers+text\",\"name\":\"19_Merge characters and locations in script\",\"text\":[\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\"],\"textfont\":{\"size\":12},\"x\":[16.328941345214844,16.79683494567871,16.91843032836914,16.880889892578125,16.934703826904297,16.40180015563965,16.929285049438477,16.886442184448242,16.708322525024414,16.627182006835938,16.627592086791992,16.823854446411133,16.7553653717041,16.776657104492188,16.85283851623535,16.91258430480957,16.742961883544922],\"y\":[7.83400297164917,8.113709449768066,7.899691581726074,7.541343688964844,7.856141090393066,8.332087516784668,8.014825820922852,7.919136047363281,8.052458763122559,7.423878192901611,7.568443298339844,7.867867946624756,8.080918312072754,7.551226615905762,7.779621124267578,7.92085075378418,8.241056442260742],\"type\":\"scattergl\"},{\"hoverinfo\":\"text\",\"hovertext\":[\"Check for missing values\\ndf_episodes.isnull().sum()\",\"Check data integrity\\nprint(df_characters.isnull().sum())\\nprint(df_locations.isnull().sum())\\nprint(df_script.isnull().sum())\\nprint(df_episodes.isnull().sum())\",\" Check missing values in script dataframe\\nprint(f'Missing values in script dataframe: {df_script.isnull().sum()}')\",\"Check for missing values in the script dataset\\nmissing_values = df_script.isnull().sum()\\nprint(missing_values)\",\"Explore data types and missing values\",\"Let's check how many null value we have for each dataframes\",\"Check out how many missing values there are in the script dataset\\ndf_script.isnull().sum()\",\"Add dummy column so that we can simply take the mean\\ndf_script['count'] = 1\",\"Visualize NaN (missing) values for each feature\",\"Get the missing values in the script dataset\",\"Check for null values in the scripts\\ndf_script.isnull().sum()\",\"# Computing the number of missing values in the script dataframe\\ndf_script.isnull().sum()\",\"Check for missing data\\nprint(\\\"- Missing Data (Characters):\\\", df_characters.isnull().values.any())\\nprint(\\\"- Missing Data (Locations):\\\", df_locations.isnull().values.any())\\nprint(\\\"- Missing Data (Script):\\\", df_script.isnull().values.any())\\nprint(\\\"- Missing Data (Episodes):\\\", df_episodes.isnull().values.any())\",\"Check for missing values\",\"check for null values in the data\\ndf_characters.isnull().sum()\",\"Check for missing values\\ndf_script.isnull().sum()\"],\"marker\":{\"opacity\":0.5,\"size\":5},\"mode\":\"markers+text\",\"name\":\"20_Missing values in dataframes\",\"text\":[\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\"],\"textfont\":{\"size\":12},\"x\":[10.847429275512695,10.630642890930176,10.92349910736084,10.897004127502441,10.67841625213623,12.333563804626465,10.945310592651367,11.315176963806152,10.97268009185791,10.854544639587402,10.959537506103516,11.007826805114746,10.737207412719727,10.771272659301758,10.728979110717773,11.020302772521973],\"y\":[11.388335227966309,11.399225234985352,11.368672370910645,11.323335647583008,10.60669231414795,4.359701633453369,11.511581420898438,11.271415710449219,10.513066291809082,11.163202285766602,11.396634101867676,11.462307929992676,11.195086479187012,10.899145126342773,11.516335487365723,11.386303901672363],\"type\":\"scattergl\"},{\"hoverinfo\":\"text\",\"hovertext\":[\" Split the script into tokens\",\"Preprocess script strings\",\" Take a look at the scripts data.\",\"Some script lines are not associated with a speaking character test that and remove it\\n# \",\"Divide the script in segments of a specific length\",\"Combine script with the characters speaking\",\"Tokenize the script by episode\",\"Extract the sentences from the first script line to analyze the sentiments and emotions associated with the text.\",\"Tokenize the text of the script lines.\",\" We need to merge the characters, locations and script datasets.\",\"Join the script with the characters and the locations\",\"Merge the script lines data with the characters and locations data to get comprehensive data for NLP analysis.\",\"For the script lines, let's focus on only the lines associated with characters, and not any stage directions.\",\"Define common entities for interpreting the script lines.\",\"Merge the script with characters and locations\",\" Tokenize script lines using Spacy\"],\"marker\":{\"opacity\":0.5,\"size\":5},\"mode\":\"markers+text\",\"name\":\"21_Script Sentiment and Character Analysis\",\"text\":[\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\"],\"textfont\":{\"size\":12},\"x\":[12.20760726928711,11.917876243591309,11.705174446105957,12.128374099731445,12.450159072875977,12.344499588012695,12.618449211120605,12.302029609680176,12.05229377746582,12.15128231048584,12.32158374786377,12.291790962219238,12.484692573547363,12.093661308288574,12.27127742767334,12.034957885742188],\"y\":[7.8145928382873535,7.4662275314331055,7.480321407318115,7.782378673553467,7.61956262588501,7.565403938293457,7.765048027038574,7.1272149085998535,7.6364874839782715,7.444158554077148,7.507772445678711,7.160565376281738,7.5932722091674805,7.366555213928223,7.389638423919678,7.736891746520996],\"type\":\"scattergl\"},{\"hoverinfo\":\"text\",\"hovertext\":[\"merge the required dataframes to have an easily accessible structure for script line data and enrich the structural data if necessary\",\"Merge the dataframes into one dataframe\",\"Cleaning the data\",\"Merging the datasets to access all relevant information in one dataframe.\",\"Data Cleaning\",\"Merge all datasets\",\"Merge the dataframes\",\"Join tables and clean data\",\"Merge and clean the datasets\",\"Merge the datasets\",\"Merge the datasets to obtain a single dataset that contains all information.\",\"Combine dataframes\",\" Merge dataframes\",\"Concatenate the dataframes to ease the processing\",\" First layers of filtering and cleaning\"],\"marker\":{\"opacity\":0.5,\"size\":5},\"mode\":\"markers+text\",\"name\":\"22_Dataframe and Dataset Merging Techniques\",\"text\":[\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\"],\"textfont\":{\"size\":12},\"x\":[11.903507232666016,11.835204124450684,11.11339282989502,11.546412467956543,11.155991554260254,11.454052925109863,11.816829681396484,11.339599609375,11.242829322814941,11.391351699829102,11.283090591430664,11.843792915344238,11.727551460266113,11.885650634765625,11.344768524169922],\"y\":[9.98536205291748,10.148829460144043,9.195589065551758,10.127123832702637,9.220842361450195,9.987001419067383,10.114874839782715,9.442342758178711,9.716812133789062,10.040895462036133,10.018162727355957,10.209896087646484,10.164862632751465,10.283486366271973,9.299640655517578],\"type\":\"scattergl\"},{\"hoverinfo\":\"text\",\"hovertext\":[\"Merge scripts with episode info\\ndf_script_episode = df_script.merge(df_episodes, on='episode_id', how='outer')\",\"Filter episodes for season 1\\ndf_episodes_seas1 = df_episodes[(df_episodes['original_air_year'] == 1989) & (df_episodes['season'] == 1)].sort_values('number_in_season')\\n\\n# Merge the filtered episodes with the scripts and characters\\ndf_ep_script = df_script.merge(df_episodes_seas1, on='id', how='inner')\\ndf_ep_script_chars = df_ep_script.merge(df_characters, left_on='character_id', right_on='id', how='left')\",\"Check if any scriptline would not have an episode\\ndf_script['episode_id'].isin(df_episodes['id']).value_counts()\",\"DF slice\\nepisode_7_script = df_script[df_script['episode_id'] == 7]\\nepisode_7_script\",\"Filtering out episodes where the character is not present\\nallowed_characters = set(df_characters['character_id'])\\n\\ndf_script['episode_id'] = df_script['episode_id'].astype('str')\\nepisode_id, occurrences = np.unique(df_script['episode_id'], return_counts=True)\\nepisode_id = list(episode_id)\\nepisodes_character_present = []\\n\\nfor ep in tqdm(episode_id):\\n    mentions = df_script[(df_script['episode_id'] == ep) & (df_script['character_id'].isin(allowed_characters))].shape[0]\\n    if mentions \\u003e 0:\\n        episodes_character_present.append(ep)\\n\\n# Subset episodes\\ndf_episodes_filtered = df_episodes[df_episodes['id'].astype('str').isin(episodes_character_present)]\",\"Filter script dataframe for scenes: 1-15 (inclusive), season: 1, episode: 1\\ndf_tmp = pd.DataFrame()\\nfor scene in range(1, 16):\\n    df_tmp = pd.concat([df_tmp, df_script[\\n        (df_script['scene_number'] == scene) & \\n        (df_script['season'] == 1) & \\n        (df_script['episode_number'] == 1)]])\\ndf_tmp.head()\",\"df_script = df_script[df_script[\\\"episode_id\\\"].notna()]\",\"ax = pd.cut(df_script['episode_id'], bins=len(df_episodes['id'].unique()), labels=False, retbins=False)\",\"Check if there is at least one other speaker in the same episode\\ndf_script['there_is_a_pre_speaker'] = df_script.reset_index().apply(lambda x: 1 if x['episode_id'] in df_script[df_script['episode_id'] ==x['episode_id']]['speaker_id'].unique() else 0, axis=1)\",\"Filter by episode_id\\ndf_script = df_script[df_script['episode_id'].isin(df_episodes['id'])]\",\"Filters invalid script lines and adds episodes to script\\ndf_script = df_script[df_script['episode_id'].isin(df_episodes['id'])]\",\"Sort script dataframe by episode_id and then by id\\ndf_script.sort_values(by=['episode_id', 'id'], inplace=True)\",\"Filter seasons to include 1-20 only\\ndf_episodes = df_episodes[(df_episodes.season \\u003c= 20)]\",\"Check the number of lines per script for each episode\\ndf_script['normalized_text'] = df_script['normalized_text'].str.strip()\\ndf_script.groupby('episode_id').size()\",\"# Regroup by season\\ndf_episodes_grouped = df_episodes.groupby('production_code').first()\\ndf_episodes_grouped.reset_index(inplace=True)\"],\"marker\":{\"opacity\":0.5,\"size\":5},\"mode\":\"markers+text\",\"name\":\"23_Script Filtering and Episode Analysis\",\"text\":[\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\"],\"textfont\":{\"size\":12},\"x\":[15.713229179382324,15.201850891113281,14.850481033325195,15.103611946105957,14.99110221862793,14.80571174621582,14.907529830932617,15.047856330871582,14.834940910339355,14.881929397583008,14.757954597473145,15.22116756439209,14.490797996520996,14.60200309753418,15.417951583862305],\"y\":[8.599082946777344,8.64816951751709,8.35120677947998,8.573010444641113,8.380090713500977,8.553680419921875,8.575559616088867,8.507671356201172,8.044926643371582,8.34758472442627,8.339752197265625,8.513819694519043,8.773750305175781,8.498072624206543,8.74969482421875],\"type\":\"scattergl\"},{\"hoverinfo\":\"text\",\"hovertext\":[\"Create folders for cleaning process\\nos.makedirs('data\\u002fclean_characters', exist_ok=True)\\nos.makedirs('data\\u002fclean_locations', exist_ok=True)\\nos.makedirs('data\\u002fclean_script', exist_ok=True)\\nos.makedirs('data\\u002fclean_episodes', exist_ok=True)\",\"Check whether we have the correct scripts\",\"# Set directory path\\ndir_path = 'data\\u002fvisualization\\u002f'\\n\\n# Ensure directory exists\\nif not os.path.exists(dir_path):\\n    os.makedirs(dir_path)\",\"Setting the variable with the path for the project folder\",\"Define the path to the data directory and the output directory\",\"Set directory path for importing images\\nimg_path = 'data\\u002fimages\\u002f'\",\"Location of data folder\\nDATA_PATH = \\\"data\\\"\",\" Create the 'simpsons' directory if it does not exist\\ndirectory = 'simpsons'\\nif not os.path.exists(directory):\\n    os.makedirs(directory)\",\"Set output path for assets\\nassets_out = 'output_assets'\",\"Directory of the scripts\\nscripts_dir = 'scripts'\",\" PLease note that the file paths specified here assume that the current working directory is the root folder of the project. Adjust the paths accordingly if needed.\",\"Generically define data folder path for reading and writing notebooks\\ndata_folder = 'data'\"],\"marker\":{\"opacity\":0.5,\"size\":5},\"mode\":\"markers+text\",\"name\":\"24_Directory and Path Management\",\"text\":[\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\"],\"textfont\":{\"size\":12},\"x\":[10.91554069519043,11.419693946838379,10.514376640319824,10.38225269317627,10.501730918884277,10.38918399810791,10.484816551208496,10.860072135925293,10.47916316986084,11.233208656311035,10.34127426147461,10.319051742553711],\"y\":[6.902735710144043,7.508701801300049,6.5371785163879395,6.744001865386963,6.6817498207092285,6.565328598022461,6.782092094421387,6.652358055114746,6.545895576477051,7.0640339851379395,6.9203901290893555,6.828033924102783],\"type\":\"scattergl\"},{\"hoverinfo\":\"text\",\"hovertext\":[\"Ensure all character names are in title format\\ndf_characters.character_name = df_characters.character_name.str.title()\\n\\n# Ensure all raw_text elements are in string format\\ndf_script.raw_text = df_script.raw_text.astype(str)\",\"encode characters\\ndf_characters.fillna('', inplace=True)\\ndf_characters['character_encoded'] = df_characters.character.str.replace('[^a-zA-Z\\\\d\\\\s:]', '').str.replace('\\\\s', '_').str.lower()\",\" Remove apostrophes from dataframe\\ndf_characters = df_characters.replace({\\\"'\\\": ''}, regex=True)\\ndf_locations = df_locations.replace({\\\"'\\\": ''}, regex=True)\\ndf_script = df_script.replace({\\\"'\\\": ''}, regex=True)\\ndf_episodes = df_episodes.replace({\\\"'\\\": ''}, regex=True)\",\"Remove any trailing whitespace from character names and location names in the character and location dataframes\",\"# Transforming character names into lowercase\\ndf_characters['name'] = df_characters['name'].str.lower()\",\"Convert character and location names to lower case\\ndf_characters['raw_character_text'] = df_characters['raw_character_text'].str.lower()\\ndf_locations['raw_location_text'] = df_locations['raw_location_text'].str.lower()\",\" Convenience renaming\\ndf_script = df_script.rename(columns={'raw_text':'text'})\",\"# Fix the character name and location name string by cleaning\\ndf_script['character_name'] = df_script['character_name'].str.replace(r'\\\\s?', '', regex=True)\\ndf_script['location_name'] = df_script['location_name'].str.replace(r'\\\\s?', '', regex=True)\",\" Convert raw text data to pandas dataframe\",\"Normalize name and title columns to lowercase\\ndf_characters['name'] = df_characters['name'].str.lower()\\ndf_locations['normalized_name'] = df_locations['normalized_name'].str.lower()\\ndf_script['character_name'] = df_script['character_name'].str.lower()\\ndf_script['raw_character_text'] = df_script['raw_character_text'].str.lower()\\ndf_script['raw_location_text'] = df_script['raw_location_text'].str.lower()\\ndf_episodes['title'] = df_episodes['title'].str.lower()\",\"Cleaning the character and location data.\\ndf_characters = df_characters[df_characters['name'] != '?']\"],\"marker\":{\"opacity\":0.5,\"size\":5},\"mode\":\"markers+text\",\"name\":\"25_Cleaning and Formatting Characters and Locations in Dataframes\",\"text\":[\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\"],\"textfont\":{\"size\":12},\"x\":[16.029024124145508,15.964168548583984,16.132984161376953,16.3695011138916,16.027286529541016,16.14500617980957,16.044021606445312,16.35904312133789,16.134681701660156,15.8638916015625,16.291282653808594],\"y\":[7.4123969078063965,7.16895055770874,9.519883155822754,7.348620891571045,7.210258483886719,7.319525718688965,7.748131275177002,7.487181186676025,7.551645278930664,7.6225996017456055,7.2096967697143555],\"type\":\"scattergl\"}],                        {\"template\":{\"data\":{\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"white\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"bar\":[{\"error_x\":{\"color\":\"rgb(36,36,36)\"},\"error_y\":{\"color\":\"rgb(36,36,36)\"},\"marker\":{\"line\":{\"color\":\"white\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"rgb(36,36,36)\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"rgb(36,36,36)\"},\"baxis\":{\"endlinecolor\":\"rgb(36,36,36)\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"rgb(36,36,36)\"},\"type\":\"carpet\"}],\"choropleth\":[{\"colorbar\":{\"outlinewidth\":1,\"tickcolor\":\"rgb(36,36,36)\",\"ticks\":\"outside\"},\"type\":\"choropleth\"}],\"contourcarpet\":[{\"colorbar\":{\"outlinewidth\":1,\"tickcolor\":\"rgb(36,36,36)\",\"ticks\":\"outside\"},\"type\":\"contourcarpet\"}],\"contour\":[{\"colorbar\":{\"outlinewidth\":1,\"tickcolor\":\"rgb(36,36,36)\",\"ticks\":\"outside\"},\"colorscale\":[[0.0,\"#440154\"],[0.1111111111111111,\"#482878\"],[0.2222222222222222,\"#3e4989\"],[0.3333333333333333,\"#31688e\"],[0.4444444444444444,\"#26828e\"],[0.5555555555555556,\"#1f9e89\"],[0.6666666666666666,\"#35b779\"],[0.7777777777777778,\"#6ece58\"],[0.8888888888888888,\"#b5de2b\"],[1.0,\"#fde725\"]],\"type\":\"contour\"}],\"heatmapgl\":[{\"colorbar\":{\"outlinewidth\":1,\"tickcolor\":\"rgb(36,36,36)\",\"ticks\":\"outside\"},\"colorscale\":[[0.0,\"#440154\"],[0.1111111111111111,\"#482878\"],[0.2222222222222222,\"#3e4989\"],[0.3333333333333333,\"#31688e\"],[0.4444444444444444,\"#26828e\"],[0.5555555555555556,\"#1f9e89\"],[0.6666666666666666,\"#35b779\"],[0.7777777777777778,\"#6ece58\"],[0.8888888888888888,\"#b5de2b\"],[1.0,\"#fde725\"]],\"type\":\"heatmapgl\"}],\"heatmap\":[{\"colorbar\":{\"outlinewidth\":1,\"tickcolor\":\"rgb(36,36,36)\",\"ticks\":\"outside\"},\"colorscale\":[[0.0,\"#440154\"],[0.1111111111111111,\"#482878\"],[0.2222222222222222,\"#3e4989\"],[0.3333333333333333,\"#31688e\"],[0.4444444444444444,\"#26828e\"],[0.5555555555555556,\"#1f9e89\"],[0.6666666666666666,\"#35b779\"],[0.7777777777777778,\"#6ece58\"],[0.8888888888888888,\"#b5de2b\"],[1.0,\"#fde725\"]],\"type\":\"heatmap\"}],\"histogram2dcontour\":[{\"colorbar\":{\"outlinewidth\":1,\"tickcolor\":\"rgb(36,36,36)\",\"ticks\":\"outside\"},\"colorscale\":[[0.0,\"#440154\"],[0.1111111111111111,\"#482878\"],[0.2222222222222222,\"#3e4989\"],[0.3333333333333333,\"#31688e\"],[0.4444444444444444,\"#26828e\"],[0.5555555555555556,\"#1f9e89\"],[0.6666666666666666,\"#35b779\"],[0.7777777777777778,\"#6ece58\"],[0.8888888888888888,\"#b5de2b\"],[1.0,\"#fde725\"]],\"type\":\"histogram2dcontour\"}],\"histogram2d\":[{\"colorbar\":{\"outlinewidth\":1,\"tickcolor\":\"rgb(36,36,36)\",\"ticks\":\"outside\"},\"colorscale\":[[0.0,\"#440154\"],[0.1111111111111111,\"#482878\"],[0.2222222222222222,\"#3e4989\"],[0.3333333333333333,\"#31688e\"],[0.4444444444444444,\"#26828e\"],[0.5555555555555556,\"#1f9e89\"],[0.6666666666666666,\"#35b779\"],[0.7777777777777778,\"#6ece58\"],[0.8888888888888888,\"#b5de2b\"],[1.0,\"#fde725\"]],\"type\":\"histogram2d\"}],\"histogram\":[{\"marker\":{\"line\":{\"color\":\"white\",\"width\":0.6}},\"type\":\"histogram\"}],\"mesh3d\":[{\"colorbar\":{\"outlinewidth\":1,\"tickcolor\":\"rgb(36,36,36)\",\"ticks\":\"outside\"},\"type\":\"mesh3d\"}],\"parcoords\":[{\"line\":{\"colorbar\":{\"outlinewidth\":1,\"tickcolor\":\"rgb(36,36,36)\",\"ticks\":\"outside\"}},\"type\":\"parcoords\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}],\"scatter3d\":[{\"line\":{\"colorbar\":{\"outlinewidth\":1,\"tickcolor\":\"rgb(36,36,36)\",\"ticks\":\"outside\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":1,\"tickcolor\":\"rgb(36,36,36)\",\"ticks\":\"outside\"}},\"type\":\"scatter3d\"}],\"scattercarpet\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":1,\"tickcolor\":\"rgb(36,36,36)\",\"ticks\":\"outside\"}},\"type\":\"scattercarpet\"}],\"scattergeo\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":1,\"tickcolor\":\"rgb(36,36,36)\",\"ticks\":\"outside\"}},\"type\":\"scattergeo\"}],\"scattergl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":1,\"tickcolor\":\"rgb(36,36,36)\",\"ticks\":\"outside\"}},\"type\":\"scattergl\"}],\"scattermapbox\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":1,\"tickcolor\":\"rgb(36,36,36)\",\"ticks\":\"outside\"}},\"type\":\"scattermapbox\"}],\"scatterpolargl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":1,\"tickcolor\":\"rgb(36,36,36)\",\"ticks\":\"outside\"}},\"type\":\"scatterpolargl\"}],\"scatterpolar\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":1,\"tickcolor\":\"rgb(36,36,36)\",\"ticks\":\"outside\"}},\"type\":\"scatterpolar\"}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"scatterternary\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":1,\"tickcolor\":\"rgb(36,36,36)\",\"ticks\":\"outside\"}},\"type\":\"scatterternary\"}],\"surface\":[{\"colorbar\":{\"outlinewidth\":1,\"tickcolor\":\"rgb(36,36,36)\",\"ticks\":\"outside\"},\"colorscale\":[[0.0,\"#440154\"],[0.1111111111111111,\"#482878\"],[0.2222222222222222,\"#3e4989\"],[0.3333333333333333,\"#31688e\"],[0.4444444444444444,\"#26828e\"],[0.5555555555555556,\"#1f9e89\"],[0.6666666666666666,\"#35b779\"],[0.7777777777777778,\"#6ece58\"],[0.8888888888888888,\"#b5de2b\"],[1.0,\"#fde725\"]],\"type\":\"surface\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"rgb(237,237,237)\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"rgb(217,217,217)\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}]},\"layout\":{\"annotationdefaults\":{\"arrowhead\":0,\"arrowwidth\":1},\"autotypenumbers\":\"strict\",\"coloraxis\":{\"colorbar\":{\"outlinewidth\":1,\"tickcolor\":\"rgb(36,36,36)\",\"ticks\":\"outside\"}},\"colorscale\":{\"diverging\":[[0.0,\"rgb(103,0,31)\"],[0.1,\"rgb(178,24,43)\"],[0.2,\"rgb(214,96,77)\"],[0.3,\"rgb(244,165,130)\"],[0.4,\"rgb(253,219,199)\"],[0.5,\"rgb(247,247,247)\"],[0.6,\"rgb(209,229,240)\"],[0.7,\"rgb(146,197,222)\"],[0.8,\"rgb(67,147,195)\"],[0.9,\"rgb(33,102,172)\"],[1.0,\"rgb(5,48,97)\"]],\"sequential\":[[0.0,\"#440154\"],[0.1111111111111111,\"#482878\"],[0.2222222222222222,\"#3e4989\"],[0.3333333333333333,\"#31688e\"],[0.4444444444444444,\"#26828e\"],[0.5555555555555556,\"#1f9e89\"],[0.6666666666666666,\"#35b779\"],[0.7777777777777778,\"#6ece58\"],[0.8888888888888888,\"#b5de2b\"],[1.0,\"#fde725\"]],\"sequentialminus\":[[0.0,\"#440154\"],[0.1111111111111111,\"#482878\"],[0.2222222222222222,\"#3e4989\"],[0.3333333333333333,\"#31688e\"],[0.4444444444444444,\"#26828e\"],[0.5555555555555556,\"#1f9e89\"],[0.6666666666666666,\"#35b779\"],[0.7777777777777778,\"#6ece58\"],[0.8888888888888888,\"#b5de2b\"],[1.0,\"#fde725\"]]},\"colorway\":[\"#1F77B4\",\"#FF7F0E\",\"#2CA02C\",\"#D62728\",\"#9467BD\",\"#8C564B\",\"#E377C2\",\"#7F7F7F\",\"#BCBD22\",\"#17BECF\"],\"font\":{\"color\":\"rgb(36,36,36)\"},\"geo\":{\"bgcolor\":\"white\",\"lakecolor\":\"white\",\"landcolor\":\"white\",\"showlakes\":true,\"showland\":true,\"subunitcolor\":\"white\"},\"hoverlabel\":{\"align\":\"left\"},\"hovermode\":\"closest\",\"mapbox\":{\"style\":\"light\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"white\",\"polar\":{\"angularaxis\":{\"gridcolor\":\"rgb(232,232,232)\",\"linecolor\":\"rgb(36,36,36)\",\"showgrid\":false,\"showline\":true,\"ticks\":\"outside\"},\"bgcolor\":\"white\",\"radialaxis\":{\"gridcolor\":\"rgb(232,232,232)\",\"linecolor\":\"rgb(36,36,36)\",\"showgrid\":false,\"showline\":true,\"ticks\":\"outside\"}},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"white\",\"gridcolor\":\"rgb(232,232,232)\",\"gridwidth\":2,\"linecolor\":\"rgb(36,36,36)\",\"showbackground\":true,\"showgrid\":false,\"showline\":true,\"ticks\":\"outside\",\"zeroline\":false,\"zerolinecolor\":\"rgb(36,36,36)\"},\"yaxis\":{\"backgroundcolor\":\"white\",\"gridcolor\":\"rgb(232,232,232)\",\"gridwidth\":2,\"linecolor\":\"rgb(36,36,36)\",\"showbackground\":true,\"showgrid\":false,\"showline\":true,\"ticks\":\"outside\",\"zeroline\":false,\"zerolinecolor\":\"rgb(36,36,36)\"},\"zaxis\":{\"backgroundcolor\":\"white\",\"gridcolor\":\"rgb(232,232,232)\",\"gridwidth\":2,\"linecolor\":\"rgb(36,36,36)\",\"showbackground\":true,\"showgrid\":false,\"showline\":true,\"ticks\":\"outside\",\"zeroline\":false,\"zerolinecolor\":\"rgb(36,36,36)\"}},\"shapedefaults\":{\"fillcolor\":\"black\",\"line\":{\"width\":0},\"opacity\":0.3},\"ternary\":{\"aaxis\":{\"gridcolor\":\"rgb(232,232,232)\",\"linecolor\":\"rgb(36,36,36)\",\"showgrid\":false,\"showline\":true,\"ticks\":\"outside\"},\"baxis\":{\"gridcolor\":\"rgb(232,232,232)\",\"linecolor\":\"rgb(36,36,36)\",\"showgrid\":false,\"showline\":true,\"ticks\":\"outside\"},\"bgcolor\":\"white\",\"caxis\":{\"gridcolor\":\"rgb(232,232,232)\",\"linecolor\":\"rgb(36,36,36)\",\"showgrid\":false,\"showline\":true,\"ticks\":\"outside\"}},\"title\":{\"x\":0.05},\"xaxis\":{\"automargin\":true,\"gridcolor\":\"rgb(232,232,232)\",\"linecolor\":\"rgb(36,36,36)\",\"showgrid\":false,\"showline\":true,\"ticks\":\"outside\",\"title\":{\"standoff\":15},\"zeroline\":false,\"zerolinecolor\":\"rgb(36,36,36)\"},\"yaxis\":{\"automargin\":true,\"gridcolor\":\"rgb(232,232,232)\",\"linecolor\":\"rgb(36,36,36)\",\"showgrid\":false,\"showline\":true,\"ticks\":\"outside\",\"title\":{\"standoff\":15},\"zeroline\":false,\"zerolinecolor\":\"rgb(36,36,36)\"}}},\"shapes\":[{\"line\":{\"color\":\"#CFD8DC\",\"width\":2},\"type\":\"line\",\"x0\":9.825302752852439,\"x1\":9.825302752852439,\"y0\":-6.300439929962158,\"y1\":15.240210008621215},{\"line\":{\"color\":\"#9E9E9E\",\"width\":2},\"type\":\"line\",\"x0\":-1.0701533138751984,\"x1\":20.720758819580077,\"y0\":4.469885039329529,\"y1\":4.469885039329529}],\"annotations\":[{\"showarrow\":false,\"text\":\"D1\",\"x\":-1.0701533138751984,\"y\":4.469885039329529,\"yshift\":10},{\"showarrow\":false,\"text\":\"D2\",\"x\":9.825302752852439,\"xshift\":10,\"y\":15.240210008621215}],\"title\":{\"font\":{\"size\":22,\"color\":\"Black\"},\"text\":\"Next Thing After Importing Data:\",\"x\":0.5,\"xanchor\":\"center\",\"yanchor\":\"top\"},\"width\":1800,\"height\":1000,\"xaxis\":{\"visible\":false},\"yaxis\":{\"visible\":false}},                        {\"responsive\": true}                    ).then(function(){\n",
       "                            \n",
       "var gd = document.getElementById('cfad44a6-b1a1-457c-ba57-2dbe0ca4d8b5');\n",
       "var x = new MutationObserver(function (mutations, observer) {{\n",
       "        var display = window.getComputedStyle(gd).display;\n",
       "        if (!display || display === 'none') {{\n",
       "            console.log([gd, 'removed!']);\n",
       "            Plotly.purge(gd);\n",
       "            observer.disconnect();\n",
       "        }}\n",
       "}});\n",
       "\n",
       "// Listen for the removal of the full notebook cells\n",
       "var notebookContainer = gd.closest('#notebook-container');\n",
       "if (notebookContainer) {{\n",
       "    x.observe(notebookContainer, {childList: true});\n",
       "}}\n",
       "\n",
       "// Listen for the clearing of the current output cell\n",
       "var outputEl = gd.closest('.output');\n",
       "if (outputEl) {{\n",
       "    x.observe(outputEl, {childList: true});\n",
       "}}\n",
       "\n",
       "                        })                };                });            </script>        </div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "topic_model.visualize_documents(answer_list, reduced_embeddings=reduced_embeddings, width=1800, height=1000, hide_annotations=True, title=\"Next Thing After Importing Data:\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at microsoft/CodeBERT-base and are newly initialized: ['classifier.out_proj.weight', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.dense.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"microsoft/CodeBERT-base\")\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"microsoft/CodeBERT-base\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [12:51<00:00,  1.30it/s]\n"
     ]
    }
   ],
   "source": [
    "quality_scores = []\n",
    "needs_comment_scores = []\n",
    "\n",
    "for answer in tqdm(answer_list):\n",
    "    full_code = code + answer\n",
    "\n",
    "    # If the full_code is longer than 512 tokens, we need to truncate it\n",
    "    while len(tokenizer.encode(full_code, return_tensors=\"pt\")[0]) > 512:\n",
    "        answer = answer[1:]\n",
    "        full_code = code + answer\n",
    "\n",
    "    input_ids = tokenizer.encode(full_code, return_tensors=\"pt\")\n",
    "    output = model(input_ids)\n",
    "    quality_scores.append(output.logits[0, 0].tolist())\n",
    "    needs_comment_scores.append(output.logits[0, 1].tolist())\n",
    "\n",
    "quality_score_before = model(tokenizer.encode(code, return_tensors=\"pt\")).logits[0, 0].tolist()\n",
    "needs_comment_score_before = model(tokenizer.encode(code, return_tensors=\"pt\")).logits[0, 1].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 2000x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(1, 2, figsize=(20, 5))\n",
    "ax[0].hist(quality_scores, bins=100)\n",
    "ax[0].set_title(\"Quality Scores\")\n",
    "ax[1].hist(needs_comment_scores, bins=100)\n",
    "ax[1].set_title(\"Needs Comment Scores\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quality: -0.25664\n",
      "Answer: calculate the number of lines each character has spoken\n",
      "lines_per_character = df_script['raw_character_text'].value_counts()\n",
      "\n",
      "# Plot the distribution of number of lines spoken by each character\n",
      "plt.figure(figsize=(10, 6))\n",
      "plt.hist(lines_per_character, bins=range(50), edgecolor='black', log=True)\n",
      "plt.xscale('log')\n",
      "plt.yscale('log')\n",
      "plt.title('Distribution of Number of Lines Spoken by Each Character')\n",
      "plt.xlabel('Number of Lines Spoken')\n",
      "plt.ylabel('Number of Characters')\n",
      "plt.show()\n",
      "\n",
      "Quality: -0.25674\n",
      "Answer: Text cleaning\n",
      "# Remove unused information\n",
      "df_script = df_script.drop(['id','episode_id', 'number'], axis=1)\n",
      "\n",
      "# Drop lines with missing values\n",
      "df_script = df_script.dropna()\n",
      "\n",
      "# Remove content in square brackets (often these are directions for the actor)\n",
      "df_script = df_script.replace('\\[.*?\\]', '', regex=True)\n",
      "\n",
      "# Special case (it's indeed lines that starts with space)\n",
      "df_script['raw_character_text'] = df_script['raw_character_text'].replace('^[ \\t]+', '', regex=True)\n",
      "\n",
      "# Special case (the character speaking is not always present)\n",
      "df_script.loc[df_script['raw_character_text'].str.len() > 50, 'raw_character_text'] = np.nan\n",
      "\n",
      "# Drop lines with missing values again\n",
      "df_script = df_script.dropna()\n",
      "\n",
      "Quality: -0.25862\n",
      "Answer: Testing if everything is loaded properly\n",
      "print(\"Characters\")\n",
      "print(df_characters.head())\n",
      "print(\"\\nLocations\")\n",
      "print(df_locations.head())\n",
      "print(\"\\nScript\")\n",
      "print(df_script.head())\n",
      "print(\"\\nEpisodes\")\n",
      "print(df_episodes.head())\n",
      "\n",
      "Quality: -0.25949\n",
      "Answer:  Display at least the first couple rows of each dataframe\n",
      "print(\"Characters:\")\n",
      "display(df_characters.head())\n",
      "\n",
      "print(\"\\nLocations:\")\n",
      "display(df_locations.head())\n",
      "\n",
      "print(\"\\nScript:\")\n",
      "display(df_script.head())\n",
      "\n",
      "print(\"\\nEpisodes:\")\n",
      "display(df_episodes.head())\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Show the best quality answers\n",
    "best_quality_answers = sorted(zip(quality_scores, answer_list), reverse=True)\n",
    "for quality, answer in best_quality_answers[:4]:\n",
    "    print(f\"Quality: {quality:.5f}\\nAnswer: {answer}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quality: -0.32108\n",
      "Answer:  Merge script data with characters and locations\n",
      "df_script = df_script[[\n",
      "    'episode_id',\n",
      "    'number',\n",
      "    'raw_text',\n",
      "    'timestamp_in_ms',\n",
      "    'speaking_line',\n",
      "    'character_id',\n",
      "    'location_id',\n",
      "    'raw_character_text',\n",
      "    'raw_location_text',\n",
      "    'spoken_words',\n",
      "    'normalized_text',\n",
      "]].merge(\n",
      "    df_characters.add_prefix('character_'),\n",
      "    left_on='character_id', \n",
      "    right_on='character_id', \n",
      "    suffixes=(None, '_dropped')\n",
      ").merge(\n",
      "    df_locations.add_prefix('location_'), \n",
      "    left_on='location_id', \n",
      "    right_on='location_id', \n",
      "    suffixes=(None, '_dropped')\n",
      ")\n",
      "\n",
      "# Merge with episodes data\n",
      "df_script = df_script.merge(\n",
      "    df_episodes.add_prefix('episode_'),\n",
      "    left_on='episode_id',\n",
      "    right_on='episode_id',\n",
      "    suffixes=(None, '_dropped')\n",
      ")\n",
      "\n",
      "Quality: -0.30983\n",
      "Answer: Merge the dataframes to create a single dataframe with all the information we need.\n",
      "df = pd.merge(df_script,\n",
      "              df_episodes,\n",
      "              how='left',\n",
      "              left_on=['episode_id'],\n",
      "              right_on=['id'],\n",
      "              suffixes=('_script', '_episode')).drop(columns=['id_script'])\n",
      "df = pd.merge(df,\n",
      "              df_characters,\n",
      "              how='left',\n",
      "              left_on=['character_id'],\n",
      "              right_on=['id'],\n",
      "              suffixes=('', '_character')).drop(columns=['id'])\n",
      "\n",
      "Quality: -0.30058\n",
      "Answer: # Correct inconsistent variable names\n",
      "df_characters.rename(columns={'id':'character_id', 'name':'character_name'}, inplace=True)\n",
      "df_locations.rename(columns={'id':'location_id', 'name':'location_name'}, inplace=True)\n",
      "df_episodes.rename(columns={'id':'episode_id', 'title':'episode_title'}, inplace=True)\n",
      "\n",
      "Quality: -0.29965\n",
      "Answer: # Merge the tables on the episode_id\n",
      "df = df_script.merge(\n",
      "    df_episodes, \n",
      "    left_on='episode_id', \n",
      "    right_on='id', \n",
      "    suffixes=('_script', '_episode')\n",
      ").merge(\n",
      "    df_characters, \n",
      "    left_on='character_id', \n",
      "    right_on='id', \n",
      "    suffixes=('_script', '_character')\n",
      ").merge(\n",
      "    df_locations, \n",
      "    left_on='location_id', \n",
      "    right_on='id', \n",
      "    suffixes=('_script', '_location')\n",
      ")\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Show the worst quality answers\n",
    "worst_quality_answers = sorted(zip(quality_scores, answer_list), reverse=False)\n",
    "for quality, answer in worst_quality_answers[:4]:\n",
    "    print(f\"Quality: {quality:.5f}\\nAnswer: {answer}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llmcoder",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
