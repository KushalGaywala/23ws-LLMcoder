{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llmcoder.analyze.MypyAnalyzer import MypyAnalyzer\n",
    "from llmcoder.analyze.SignatureAnalyzer import SignatureAnalyzer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Mypy] No missing stubs found.\n",
      "[Mypy] /tmp/tmp6eocp9ea.py:4: error: Argument 1 to \"analyze\" of \"APIDocumentationAnalyzer\" has incompatible type \"Callable[[object], str]\"; expected \"str\"  [arg-type]\n",
      "[Mypy] /tmp/tmp6eocp9ea.py:4: error: Name \"completion\" is not defined  [name-defined]\n",
      "[Mypy] /tmp/tmp6eocp9ea.py:4: error: Name \"generator\" is not defined  [name-defined]\n",
      "[Mypy] Found 3 errors in 1 file (checked 1 source file)\n",
      "[Signatures] Using context from previous analyzers: ['mypy_analyzer_v1']\n",
      "[Signatures] all_matches=['APIDocumentationAnalyzer.analyze']\n",
      "[Signatures] Found problematic function or class: APIDocumentationAnalyzer.analyze\n",
      "[Signatures] all_matches=[]\n",
      "[Signatures] all_matches=[]\n",
      "[Signatures] function_calls=[('llmcoder', 'APIDocumentationAnalyzer', 'analyze')]\n",
      "[Signatures] Got signatures and documentations:\n",
      "[Signatures] APIDocumentationAnalyzer.analyze: (self, input: str, completion: str, context: dict[str, dict[str, bool | str]] | None = None) -> dict[str, bool | str], analyze analyzes the code that is passed in APIDocumentAnalyze class object and returns the documentation with the API References\n"
     ]
    }
   ],
   "source": [
    "# Argument 1 to \"analyze\" of \"APIDocumentationAnalyzer\" has incompatible type \"Callable[[object], str]\"; expected \"str\"  [arg-type]\n",
    "code = \"\"\"\n",
    "from llmcoder.analyze import APIDocumentationAnalyzer\n",
    "a = APIDocumentationAnalyzer()\n",
    "analyzer_results = [a.an\"\"\"\n",
    "\n",
    "completion = \"\"\"alyze(input, completion, generator)]\"\"\"\n",
    "\n",
    "mypy = MypyAnalyzer(verbose=True)\n",
    "sig = SignatureAnalyzer(verbose=True)\n",
    "\n",
    "mypy_result = mypy.analyze(code, completion)\n",
    "sig_result = sig.analyze(code, completion, {'mypy_analyzer_v1': mypy_result})\n",
    "\n",
    "assert \"APIDocumentationAnalyzer.analyze\" in sig_result['message']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Mypy] No missing stubs found.\n",
      "[Mypy] /tmp/tmp607smb__.py:4: error: \"analyze\" of \"APIDocumentationAnalyzer\" gets multiple values for keyword argument \"input\"  [misc]\n",
      "[Mypy] Found 1 error in 1 file (checked 1 source file)\n",
      "[Signatures] Using context from previous analyzers: ['mypy_analyzer_v1']\n",
      "[Signatures] all_matches=['APIDocumentationAnalyzer.analyze']\n",
      "[Signatures] Found problematic function or class: APIDocumentationAnalyzer.analyze\n",
      "[Signatures] function_calls=[('llmcoder', 'APIDocumentationAnalyzer', 'analyze')]\n",
      "[Signatures] Got signatures and documentations:\n",
      "[Signatures] APIDocumentationAnalyzer.analyze: (self, input: str, completion: str, context: dict[str, dict[str, bool | str]] | None = None) -> dict[str, bool | str], analyze analyzes the code that is passed in APIDocumentAnalyze class object and returns the documentation with the API References\n"
     ]
    }
   ],
   "source": [
    "# \"analyze\" of \"APIDocumentationAnalyzer\" gets multiple values for keyword argument \"input\"  [misc]\n",
    "code = \"\"\"\n",
    "from llmcoder.analyze import APIDocumentationAnalyzer\n",
    "a = APIDocumentationAnalyzer()\n",
    "analyzer_results = [a.an\"\"\"\n",
    "\n",
    "completion = \"\"\"alyze(input=\"a\", input=\"b\", completion=\"v\")]\"\"\"\n",
    "\n",
    "mypy = MypyAnalyzer(verbose=True)\n",
    "sig = SignatureAnalyzer(verbose=True)\n",
    "\n",
    "mypy_result = mypy.analyze(code, completion)\n",
    "sig_result = sig.analyze(code, completion, {'mypy_analyzer_v1': mypy_result})\n",
    "\n",
    "assert \"APIDocumentationAnalyzer.analyze\" in sig_result['message']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Mypy] No missing stubs found.\n",
      "[Mypy] /tmp/tmp8xfecj65.py:3: error: Unexpected keyword argument \"seed\" for \"LLMCoder\"  [call-arg]\n",
      "[Mypy] Found 1 error in 1 file (checked 1 source file)\n",
      "[Signatures] Using context from previous analyzers: ['mypy_analyzer_v1']\n",
      "[Signatures] all_matches=['LLMCoder']\n",
      "[Signatures] Found problematic function or class: LLMCoder\n",
      "[Signatures] function_calls=[(None, 'LLMCoder', None)]\n",
      "[Signatures] Got signatures and documentations:\n",
      "[Signatures] LLMCoder: (analyzers: list[str] = None, model_first: str = 'ft:gpt-3.5-turbo-1106:personal::8LCi9Q0d', model_feedback: str = 'ft:gpt-3.5-turbo-1106:personal::8LCi9Q0d', feedback_variant: str = 'coworker', system_prompt: str | None = None, max_iter: int = 10, log_conversation: bool = True, n_procs: int = 1, verbose: bool = True) -> None, Initialize the LLMCoder\n"
     ]
    }
   ],
   "source": [
    "# Unexpected keyword argument \"seed\" for \"LLMCoder\"  [call-arg]\n",
    "code = \"\"\"\n",
    "from llmcoder import LLMCoder\n",
    "coder = LLMCoder(\"\"\"\n",
    "\n",
    "completion = \"\"\"seed=1)\"\"\"\n",
    "\n",
    "mypy = MypyAnalyzer(verbose=True)\n",
    "sig = SignatureAnalyzer(verbose=True)\n",
    "\n",
    "mypy_result = mypy.analyze(code, completion)\n",
    "sig_result = sig.analyze(code, completion, {'mypy_analyzer_v1': mypy_result})\n",
    "\n",
    "assert \"LLMCoder: (\" in sig_result['message']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Mypy] No missing stubs found.\n",
      "[Mypy] /tmp/tmpatem03xl.py:3: error: Too many arguments for \"APIDocumentationAnalyzer\"  [call-arg]\n",
      "[Mypy] Found 1 error in 1 file (checked 1 source file)\n",
      "[Signatures] Using context from previous analyzers: ['mypy_analyzer_v1']\n",
      "[Signatures] all_matches=['APIDocumentationAnalyzer']\n",
      "[Signatures] Found problematic function or class: APIDocumentationAnalyzer\n",
      "[Signatures] function_calls=[('llmcoder', 'APIDocumentationAnalyzer', None)]\n",
      "[Signatures] Got signatures and documentations:\n",
      "[Signatures] APIDocumentationAnalyzer: () -> None, Helper class that provides a standard way to create an ABC using\n"
     ]
    }
   ],
   "source": [
    "# Too many arguments for \"APIDocumentationAnalyzer\"  [call-arg]\n",
    "code = \"\"\"\n",
    "from llmcoder.analyze import APIDocumentationAnalyzer\n",
    "a = APIDocumentationAnalyzer(\"\"\"\n",
    "\n",
    "completion = \"\"\"1, 2, 3, 4, 5, 6, 7)\"\"\"\n",
    "\n",
    "mypy = MypyAnalyzer(verbose=True)\n",
    "sig = SignatureAnalyzer(verbose=True)\n",
    "\n",
    "mypy_result = mypy.analyze(code, completion)\n",
    "sig_result = sig.analyze(code, completion, {'mypy_analyzer_v1': mypy_result})\n",
    "\n",
    "assert \"APIDocumentationAnalyzer: (\" in sig_result['message']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Mypy] No missing stubs found.\n",
      "[Mypy] /tmp/tmp1di49uki.py:5: error: Argument 1 to \"analyze\" of \"APIDocumentationAnalyzer\" has incompatible type \"int\"; expected \"str\"  [arg-type]\n",
      "[Mypy] Found 1 error in 1 file (checked 1 source file)\n",
      "[Signatures] Using context from previous analyzers: ['mypy_analyzer_v1']\n",
      "[Signatures] all_matches=['APIDocumentationAnalyzer.analyze']\n",
      "[Signatures] Found problematic function or class: APIDocumentationAnalyzer.analyze\n",
      "[Signatures] function_calls=[('llmcoder', 'APIDocumentationAnalyzer', 'analyze')]\n",
      "[Signatures] Got signatures and documentations:\n",
      "[Signatures] APIDocumentationAnalyzer.analyze: (self, input: str, completion: str, context: dict[str, dict[str, bool | str]] | None = None) -> dict[str, bool | str], analyze analyzes the code that is passed in APIDocumentAnalyze class object and returns the documentation with the API References\n"
     ]
    }
   ],
   "source": [
    "# Argument 1 to \"analyze\" of \"APIDocumentationAnalyzer\" has incompatible type \"int\"; expected \"str\"  [arg-type]\n",
    "code = \"\"\"\n",
    "from llmcoder.analyze import APIDocumentationAnalyzer\n",
    "a = APIDocumentationAnalyzer()\n",
    "\n",
    "a.analyze(\"\"\"\n",
    "\n",
    "completion = \"\"\"1, completion=\"a\")\"\"\"\n",
    "\n",
    "mypy = MypyAnalyzer(verbose=True)\n",
    "sig = SignatureAnalyzer(verbose=True)\n",
    "\n",
    "mypy_result = mypy.analyze(code, completion)\n",
    "sig_result = sig.analyze(code, completion, {'mypy_analyzer_v1': mypy_result})\n",
    "\n",
    "assert \"APIDocumentationAnalyzer.analyze: (\" in sig_result['message']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Mypy] No missing stubs found.\n",
      "[Mypy] /tmp/tmp9gcbi8f0.py:5: error: \"analyze\" of \"APIDocumentationAnalyzer\" gets multiple values for keyword argument \"input\"  [misc]\n",
      "[Mypy] Found 1 error in 1 file (checked 1 source file)\n",
      "[Signatures] Using context from previous analyzers: ['mypy_analyzer_v1']\n",
      "[Signatures] all_matches=['APIDocumentationAnalyzer.analyze']\n",
      "[Signatures] Found problematic function or class: APIDocumentationAnalyzer.analyze\n",
      "[Signatures] function_calls=[('llmcoder', 'APIDocumentationAnalyzer', 'analyze')]\n",
      "[Signatures] Got signatures and documentations:\n",
      "[Signatures] APIDocumentationAnalyzer.analyze: (self, input: str, completion: str, context: dict[str, dict[str, bool | str]] | None = None) -> dict[str, bool | str], analyze analyzes the code that is passed in APIDocumentAnalyze class object and returns the documentation with the API References\n"
     ]
    }
   ],
   "source": [
    "# analyze\" of \"APIDocumentationAnalyzer\" gets multiple values for keyword argument \"input\"  [misc]\n",
    "code = \"\"\"\n",
    "from llmcoder.analyze import APIDocumentationAnalyzer\n",
    "a = APIDocumentationAnalyzer()\n",
    "\n",
    "a.analyze(\"\"\"\n",
    "\n",
    "completion = \"\"\"input=\"a\", input=\"b\", completion=\"a\")\"\"\"\n",
    "\n",
    "mypy = MypyAnalyzer(verbose=True)\n",
    "sig = SignatureAnalyzer(verbose=True)\n",
    "\n",
    "mypy_result = mypy.analyze(code, completion)\n",
    "sig_result = sig.analyze(code, completion, {'mypy_analyzer_v1': mypy_result})\n",
    "\n",
    "assert \"APIDocumentationAnalyzer.analyze: (\" in sig_result['message']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Mypy] No missing stubs found.\n",
      "[Mypy] /tmp/tmp735_557x.py:4: error: Missing positional arguments \"input\", \"completion\" in call to \"analyze\" of \"APIDocumentationAnalyzer\"  [call-arg]\n",
      "[Mypy] Found 1 error in 1 file (checked 1 source file)\n",
      "[Signatures] Using context from previous analyzers: ['mypy_analyzer_v1']\n",
      "[Signatures] all_matches=['APIDocumentationAnalyzer.analyze']\n",
      "[Signatures] Found problematic function or class: APIDocumentationAnalyzer.analyze\n",
      "[Signatures] function_calls=[('llmcoder', 'APIDocumentationAnalyzer', 'analyze')]\n",
      "[Signatures] Got signatures and documentations:\n",
      "[Signatures] APIDocumentationAnalyzer.analyze: (self, input: str, completion: str, context: dict[str, dict[str, bool | str]] | None = None) -> dict[str, bool | str], analyze analyzes the code that is passed in APIDocumentAnalyze class object and returns the documentation with the API References\n"
     ]
    }
   ],
   "source": [
    "# Missing positional arguments \"input\", \"completion\" in call to \"analyze\" of \"APIDocumentationAnalyzer\"  [call-arg]\n",
    "code = \"\"\"\n",
    "from llmcoder.analyze import APIDocumentationAnalyzer\n",
    "a = APIDocumentationAnalyzer()\n",
    "analyzer_results = [a.an\"\"\"\n",
    "\n",
    "completion = \"\"\"alyze()]\"\"\"\n",
    "\n",
    "mypy = MypyAnalyzer(verbose=True)\n",
    "sig = SignatureAnalyzer(verbose=True)\n",
    "\n",
    "mypy_result = mypy.analyze(code, completion)\n",
    "sig_result = sig.analyze(code, completion, {'mypy_analyzer_v1': mypy_result})\n",
    "\n",
    "assert \"APIDocumentationAnalyzer.analyze\" in sig_result['message']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Mypy] No missing stubs found.\n",
      "[Mypy] /tmp/tmp_fc6yttt.py:4: error: Too many arguments for \"analyze\" of \"APIDocumentationAnalyzer\"  [call-arg]\n",
      "[Mypy] Found 1 error in 1 file (checked 1 source file)\n",
      "[Signatures] Using context from previous analyzers: ['mypy_analyzer_v1']\n",
      "[Signatures] all_matches=['APIDocumentationAnalyzer.analyze', 'analyze']\n",
      "[Signatures] Found problematic function or class: APIDocumentationAnalyzer.analyze\n",
      "[Signatures] Found problematic function or class: analyze\n",
      "[Signatures] function_calls=[('llmcoder', 'analyze', None), ('llmcoder', 'APIDocumentationAnalyzer', 'analyze')]\n",
      "[Signatures] No import found for analyze\n",
      "[Signatures] Got signatures and documentations:\n",
      "[Signatures] APIDocumentationAnalyzer.analyze: (self, input: str, completion: str, context: dict[str, dict[str, bool | str]] | None = None) -> dict[str, bool | str], analyze analyzes the code that is passed in APIDocumentAnalyze class object and returns the documentation with the API References\n"
     ]
    }
   ],
   "source": [
    "# Too many arguments for \"analyze\" of \"APIDocumentationAnalyzer\"  [call-arg]\n",
    "code = \"\"\"\n",
    "from llmcoder.analyze import APIDocumentationAnalyzer\n",
    "a = APIDocumentationAnalyzer()\n",
    "analyzer_results = [a.an\"\"\"\n",
    "\n",
    "completion = \"\"\"alyze(\"a\", \"b\", {\"a\": {\"a\": True}}, \"d\")]\"\"\"\n",
    "\n",
    "mypy = MypyAnalyzer(verbose=True)\n",
    "sig = SignatureAnalyzer(verbose=True)\n",
    "\n",
    "mypy_result = mypy.analyze(code, completion)\n",
    "sig_result = sig.analyze(code, completion, {'mypy_analyzer_v1': mypy_result})\n",
    "\n",
    "assert \"APIDocumentationAnalyzer.analyze\" in sig_result['message']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Mypy] No missing stubs found.\n",
      "[Mypy] /tmp/tmp68ylc9m6.py:10: error: Signature of \"analyze\" incompatible with supertype \"Analyzer\"  [override]\n",
      "[Mypy] /tmp/tmp68ylc9m6.py:10: note:      Superclass:\n",
      "[Mypy] /tmp/tmp68ylc9m6.py:10: note:          def analyze(self, input: str, completion: str, context: dict[str, dict[str, float | int | str]] | None = ...) -> dict[Any, Any]\n",
      "[Mypy] /tmp/tmp68ylc9m6.py:10: note:      Subclass:\n",
      "[Mypy] /tmp/tmp68ylc9m6.py:10: note:          def analyze(self, input: str, completion: str, install_stubs: bool = ..., *mypy_args: str | None) -> dict[Any, Any]\n",
      "[Mypy] Found 1 error in 1 file (checked 1 source file)\n",
      "[Signatures] Using context from previous analyzers: ['mypy_analyzer_v1']\n",
      "[Signatures] all_matches=['Analyzer.analyze']\n",
      "[Signatures] Found problematic function or class: Analyzer.analyze\n",
      "[Signatures] all_matches=[]\n",
      "[Signatures] all_matches=[]\n",
      "[Signatures] all_matches=[]\n",
      "[Signatures] all_matches=[]\n",
      "[Signatures] function_calls=[]\n",
      "[Signatures] Got signatures and documentations:\n"
     ]
    }
   ],
   "source": [
    "# Signature of \"analyze\" incompatible with supertype \"Analyzer\"  [override]\n",
    "code = \"\"\"\n",
    "import os\n",
    "import re\n",
    "import subprocess\n",
    "import tempfile\n",
    "\n",
    "from llmcoder.analyze.Analyzer import Analyzer\n",
    "\n",
    "class MypyAnalyzer(Analyzer):\n",
    "    def analyze(\"\"\"\n",
    "\n",
    "completion = \"\"\"self, input: str, completion: str, install_stubs: bool = True, *mypy_args: str | None) -> dict:\n",
    "        return {}\"\"\"\n",
    "\n",
    "mypy = MypyAnalyzer(verbose=True)\n",
    "sig = SignatureAnalyzer(verbose=True)\n",
    "\n",
    "mypy_result = mypy.analyze(code, completion)\n",
    "sig_result = sig.analyze(code, completion, {'mypy_analyzer_v1': mypy_result})\n",
    "\n",
    "assert \"Analyzer.analyze\" in sig_result['message']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Mypy] No missing stubs found.\n",
      "[Mypy] /tmp/tmp4hoa0ibv.py:7: error: Skipping analyzing \"bertopic.representation\": module is installed, but missing library stubs or py.typed marker  [import-untyped]\n",
      "[Mypy] /tmp/tmp4hoa0ibv.py:7: note: See https://mypy.readthedocs.io/en/stable/running_mypy.html#missing-imports\n",
      "[Mypy] /tmp/tmp4hoa0ibv.py:9: error: Skipping analyzing \"bertopic\": module is installed, but missing library stubs or py.typed marker  [import-untyped]\n",
      "[Mypy] /tmp/tmp4hoa0ibv.py:10: error: Skipping analyzing \"sentence_transformers\": module is installed, but missing library stubs or py.typed marker  [import-untyped]\n",
      "[Mypy] /tmp/tmp4hoa0ibv.py:11: error: Skipping analyzing \"umap\": module is installed, but missing library stubs or py.typed marker  [import-untyped]\n",
      "[Mypy] /tmp/tmp4hoa0ibv.py:58: error: Need type annotation for \"chat_completions\" (hint: \"chat_completions: List[<type>] = ...\")  [var-annotated]\n",
      "[Mypy] /tmp/tmp4hoa0ibv.py:63: error: Argument \"messages\" to \"create\" of \"Completions\" has incompatible type \"list[dict[str, str]]\"; expected \"list[ChatCompletionSystemMessageParam | ChatCompletionUserMessageParam | ChatCompletionAssistantMessageParam | ChatCompletionToolMessageParam | ChatCompletionFunctionMessageParam]\"  [arg-type]\n",
      "[Mypy] /tmp/tmp4hoa0ibv.py:65: error: Value of type \"ChatCompletion\" is not indexable  [index]\n",
      "[Mypy] Found 7 errors in 1 file (checked 1 source file)\n",
      "[Signatures] Using context from previous analyzers: ['mypy_analyzer_v1']\n",
      "[Signatures] all_matches=['Completions.create']\n",
      "[Signatures] Found problematic function or class: Completions.create\n",
      "[Signatures] all_matches=[]\n",
      "[Signatures] function_calls=[]\n",
      "[Signatures] result=[]\n",
      "[Signatures] Got signatures and documentations:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'pass': False,\n",
       " 'type': 'info',\n",
       " 'score': 0,\n",
       " 'message': 'Cannot find the relevant signatures of Completions.create'}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Argument \"messages\" to \"create\" of \"Completions\" has incompatible type \"list[dict[str, str]]\"; expected \"list[ChatCompletionSystemMessageParam | ChatCompletionUserMessageParam | ChatCompletionAssistantMessageParam | ChatCompletionToolMessageParam | ChatCompletionFunctionMessageParam]\"  [arg-type]\n",
    "code = \"\"\"\n",
    "import json\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from openai import OpenAI\n",
    "from bertopic.representation import OpenAI as OpenAIRep\n",
    "from collections import Counter\n",
    "from bertopic import BERTopic\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from umap import UMAP\n",
    "import numpy as np\n",
    "\n",
    "from llmcoder.utils import get_openai_key, get_system_prompt\n",
    "from llmcoder import LLMCoder\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# device = torch.device(\"cpu\")\n",
    "\n",
    "client = OpenAI(api_key=get_openai_key())\n",
    "\n",
    "code = \\\"\\\"\\\"# General imports\n",
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import spacy\n",
    "import matplotlib\n",
    "from wordcloud import WordCloud\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "# Custom imports\n",
    "from tqdm import tqdm\n",
    "from collections import Counter\n",
    "\n",
    "# Ensure matplotlib works correctly with Jupyter\n",
    "%matplotlib inline\n",
    "\n",
    "df_characters = pd.read_csv('data/simpsons_characters.csv').reset_index(inplace=False, drop=True)\n",
    "df_locations = pd.read_csv('data/simpsons_locations.csv').reset_index(inplace=False, drop=True)\n",
    "df_script = pd.read_csv('data/simpsons_script_lines.csv').reset_index(inplace=False, drop=True)\n",
    "df_episodes = pd.read_csv('data/simpsons_episodes.csv').reset_index(inplace=False, drop=True)\n",
    "\n",
    "# \\\"\\\"\\\"\n",
    "\n",
    "messages = [{\n",
    "    \"role\": \"system\",\n",
    "    \"content\": get_system_prompt(),\n",
    "}, {\n",
    "    \"role\": \"user\",\n",
    "    \"content\": code\n",
    "}]\n",
    "\n",
    "N_SAMPLES = 10_000\n",
    "\n",
    "assert N_SAMPLES <= 10000  # Otherwise this will get very expensive\n",
    "\n",
    "chat_completions = []\n",
    "\n",
    "pbar = tqdm(total=N_SAMPLES)\n",
    "while len(chat_completions) < N_SAMPLES:\n",
    "    chat_completion = client.chat.completions.create(\"\"\"\n",
    "\n",
    "completion = \"\"\" model=\"gpt-3.5-turbo\",\n",
    "                                                     messages=messages)\n",
    "    chat_completions.append(chat_completion)\n",
    "    messages[1][\"content\"] = chat_completion[\"choices\"][0][\"message\"][\"content\"]\n",
    "    pbar.update(1)\n",
    "pbar.close()\"\"\"\n",
    "\n",
    "mypy = MypyAnalyzer(verbose=True)\n",
    "sig = SignatureAnalyzer(verbose=True)\n",
    "\n",
    "mypy_result = mypy.analyze(code, completion)\n",
    "sig_result = sig.analyze(code, completion, {'mypy_analyzer_v1': mypy_result})\n",
    "\n",
    "# assert \"Completions.messages\" in sig_result['message']\n",
    "sig_result"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llmcoder",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
