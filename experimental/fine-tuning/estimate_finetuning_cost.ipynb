{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import numpy as np\n",
    "import tiktoken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "enc = tiktoken.get_encoding(\"p50k_base\")\n",
    "assert enc.decode(enc.encode(\"hello world\")) == \"hello world\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read all examples from the examples folder\n",
    "examples = []\n",
    "\n",
    "for filename in os.listdir('examples'):\n",
    "    with open(os.path.join('examples', filename), 'r') as f:\n",
    "        examples.append(json.load(f))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'role': 'system',\n",
       "  'content': '\\n# Instructions:\\nYou are an autocomplete system for Python. Generate or complete Python code based on the user\\'s description or the provided code snippet.\\n\\nThe user may\\n1. Describe code, either directly or in a Python comment. In this case, you should implement the described code.\\n2. Write incomplete code. In this case, you should complete the code from the last cursor position.\\n3. If the last character is a newline or tab, come up with one or more possible next lines of code.\\n\\n\\n## Example 1:\\n\\n[INPUT]\\n# Function that adds two numbers\\ndef\\n[/INPUT]\\n\\n[ANSWER]\\n```python\\n add_numbers(a, b):\\n    return a + b\\n```\\n[/ANSWER]\\n\\n\\n## Example 2:\\n\\n[INPUT]\\n```python\\ndef factorial(n):\\n    # Computes the fact\\n```\\n[/INPUT]\\n\\n[ANSWER]\\n```python\\n    # Computes the factorial of a number\\n    if n == 0:\\n        return 1\\n    else:\\n        return n * factorial(n-1)\\n```\\n[/ANSWER]\\n\\n\\n## Example 3:\\n\\n[INPUT]\\nI need a function that checks if a number is prime\\n[/INPUT]\\n\\n[ANSWER]\\n```python\\ndef is_prime(number):\\n    if number > 1:\\n        for i in range(2, int(number**0.5)+1):\\n            if (number % i) == 0:\\n                return False\\n        return True\\n    else:\\n        return False\\n```\\n[/ANSWER]\\n\\n\\n# Rules:\\n- Your entire response must be valid Python code.\\n- Avoid evasive or incomplete answers.\\n- Any comments or notes must be made in Python code block, i.e., ```python ... ```.\\n- You must not add any additional comments or notes outside of the ```python ... ``` blocks. Your entire response must only consist of one Python code block.\\n- You must end your response after ending the Python code block with \"```\".\\n'},\n",
       " {'role': 'user',\n",
       "  'content': 'import os\\nfrom aleph_alpha_client import Client, CompletionRequest, Prompt\\n\\nclient = Client(token=os.getenv(\"AA_TOKEN\"))\\nrequest = CompletionRequest(\\n    '},\n",
       " {'role': 'assistant',\n",
       "  'content': '```python\\ntext=\"import os\\\\nfrom aleph_alpha_client import Client, CompletionRequest, Prompt\\\\n\\\\nclient = Client(token=os.getenv(\\\\\"AA_TOKEN\\\\\"))\\\\nrequest = CompletionRequest(\"\\n```'},\n",
       " {'role': 'comment',\n",
       "  'content': '\\n- unexpected \\'text\\' key with value \\'import os\\nfrom aleph_alpha_client import Client, CompletionRequest, Prompt\\n\\nclient = Client(token=os.getenv(\"AA_TOKEN\"))\\nrequest = CompletionRequest(\\' as data\\n\\nGround Truth:\\n```python\\nprompt=Prompt.from_text(\"Provide a short description of AI:\"),\\n    maximum_tokens=64,\\n)\\nresponse = client.complete(request, model=\"luminous-extended\")\\n\\nprint(response.completions[0].completion)\\n```\\n'}]"
      ]
     },
     "execution_count": 226,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "examples[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "# base cost per 1k tokens * number of tokens in the input file * number of epochs trained\n",
    "# Count the system and user messages as input tokens\n",
    "# Count the assistant messages as output tokens\n",
    "\n",
    "messages_system = [message['content']  for example in examples for message in example if message['role'] == 'system']\n",
    "messages_user = [message['content']  for example in examples for message in example if message['role'] == 'user']\n",
    "messages_assistant = [message['content']  for example in examples for message in example if message['role'] == 'assistant']\n",
    "\n",
    "\n",
    "text_input = ' '.join(messages_system + messages_user)\n",
    "text_output = ' '.join(messages_assistant)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input tokens: 13545\n",
      "Output tokens: 3082\n"
     ]
    }
   ],
   "source": [
    "n_input_tokens = len(enc.encode(text_input))\n",
    "n_output_tokens = len(enc.encode(text_output))\n",
    "print(f'Input tokens: {n_input_tokens}')\n",
    "print(f'Output tokens: {n_output_tokens}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input tokens per example: 588.2 ± 155.6\n",
      "Output tokens per example: 134.0 ± 114.1\n"
     ]
    }
   ],
   "source": [
    "# Determine the number of tokens per example\n",
    "n_system_tokens_per_example = [len(enc.encode(message)) for message in messages_system]\n",
    "n_user_tokens_per_example = [len(enc.encode(message)) for message in messages_user]\n",
    "n_assistant_tokens_per_example = [len(enc.encode(message)) for message in messages_assistant]\n",
    "\n",
    "n_input_tokens_per_example = [n_system + n_user for n_system, n_user in zip(n_system_tokens_per_example, n_user_tokens_per_example)]\n",
    "n_output_tokens_per_example = n_assistant_tokens_per_example\n",
    "\n",
    "input_tokens_per_example_mean = np.mean(n_input_tokens_per_example)\n",
    "output_tokens_per_example_mean = np.mean(n_output_tokens_per_example)\n",
    "\n",
    "input_tokens_per_example_std = np.std(n_input_tokens_per_example)\n",
    "output_tokens_per_example_std = np.std(n_output_tokens_per_example)\n",
    "\n",
    "print(f'Input tokens per example: {input_tokens_per_example_mean:.1f} ± {input_tokens_per_example_std:.1f}')\n",
    "print(f'Output tokens per example: {output_tokens_per_example_mean:.1f} ± {output_tokens_per_example_std:.1f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GPT-3.5-Turbo\n",
    "price_input_per_1k_tokens = 0.0010\n",
    "price_output_per_1k_tokens = 0.0020\n",
    "\n",
    "# GPT-4\n",
    "# price_input_per_1k_tokens = 0.03\n",
    "# price_output_per_1k_tokens = 0.06"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Price per example: 0.00086 ± 0.00038 USD\n"
     ]
    }
   ],
   "source": [
    "# Determine the price per example\n",
    "price_input_per_example = price_input_per_1k_tokens * input_tokens_per_example_mean / 1000\n",
    "price_output_per_example = price_output_per_1k_tokens * output_tokens_per_example_mean / 1000\n",
    "\n",
    "price_input_per_example_err = price_input_per_1k_tokens * input_tokens_per_example_std / 1000\n",
    "price_output_per_example_err = price_output_per_1k_tokens * output_tokens_per_example_std / 1000\n",
    "\n",
    "price_total_per_example = price_input_per_example + price_output_per_example\n",
    "\n",
    "price_total_per_example_err = price_input_per_example_err + price_output_per_example_err\n",
    "\n",
    "print(f'Price per example: {price_total_per_example:.5f} ± {price_total_per_example_err:.5f} USD')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_examples = 100\n",
    "n_epochs = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input tokens total: 117.6k ± 31.1k\n",
      "Output tokens total: 26.8k ± 22.8k\n"
     ]
    }
   ],
   "source": [
    "# Estimate the total number of input and output tokens accounting for the number of epochs and examples\n",
    "n_input_tokens_total = input_tokens_per_example_mean * n_epochs * n_examples\n",
    "n_output_tokens_total = output_tokens_per_example_mean * n_epochs * n_examples\n",
    "\n",
    "n_input_tokens_total_err = input_tokens_per_example_std * n_epochs * n_examples\n",
    "n_output_tokens_total_err = output_tokens_per_example_std * n_epochs * n_examples\n",
    "\n",
    "print(f'Input tokens total: {n_input_tokens_total / 1000:.1f}k ± {n_input_tokens_total_err / 1000:.1f}k')\n",
    "print(f'Output tokens total: {n_output_tokens_total / 1000:.1f}k ± {n_output_tokens_total_err / 1000:.1f}k')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Price for 100 examples: 0.09 ± 0.04 USD\n"
     ]
    }
   ],
   "source": [
    "# Estimate the price for 100 examples\n",
    "price_total = price_total_per_example * n_examples\n",
    "\n",
    "price_total_err = price_total_per_example_err * n_examples\n",
    "\n",
    "print(f'Price for 100 examples: {price_total:.2f} ± {price_total_err:.2f} USD')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]"
  },
  "vscode": {
   "interpreter": {
    "hash": "df4835117a709c33ff9c41bf5c3d188b602f1c1171064c7e67af8e7930025aeb"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
