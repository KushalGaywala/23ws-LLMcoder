{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llmcoder import LLMCoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "llmcoder = LLMCoder(analyzers=[\"mypy_analyzer_v1\"], max_iter=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "code = ['''from llmcoder import LLMCoder\n",
    "\n",
    "# Create an LLMCoder with a random seed of 0\n",
    "llmcoder = ''',\n",
    "'''import os\n",
    "from aleph_alpha_client import Client, CompletionRequest, Prompt\n",
    "\n",
    "\n",
    "\n",
    "client = Client(os.''' # https://github.com/Aleph-Alpha/aleph-alpha-client\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating first completion...\n",
      "Starting feedback loop...\n",
      "Starting feedback iteration 1...\n",
      "Analyzing code...\n",
      "Running MypyAnalyzer...\n",
      "No missing stubs found.\n",
      "0 / 1 analyzers passed\n",
      "Starting feedback iteration 2...\n",
      "Analyzing code...\n",
      "Running MypyAnalyzer...\n",
      "No missing stubs found.\n",
      "1 / 1 analyzers passed\n"
     ]
    }
   ],
   "source": [
    "result = llmcoder.complete(code[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'getenv(\"ALEPH_API_KEY\", \"\"))'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SYSTEM\n",
      "You are AutocompleteGPT, a useful AI autocomplete tool that provides code completions based on the user's code.\n",
      "You are a precision-focused tool for code autocompletion, adept in languages like Python, JavaScript, C++, and SQL.\n",
      "Precisely continue the code from the point of interruption and do not repeat or modify the original code, even if it is incorrect or the code interrupts in the middle of a line.\n",
      "Your code is well documented with comments and annotations, and you should provide a clear explanation of the code's purpose in your code completion.\n",
      "Your unique capability is to provide completions without altering, repeating, or commenting on the original code.\n",
      "You offer only the necessary code to complete the snippet, ensuring the response is exclusively code, with no additional comments, explanations, or annotations.\n",
      "This approach makes you an ideal assistant for users seeking straightforward and efficient code extensions, enhancing their work with accurate, logic-driven completions while maintaining the integrity and simplicity of the original input.\n",
      "Your response begins with the next characters of the line if the last line of the user'S code is incomplete, or the next line if the last line of the user's code is complete.\n",
      "Your application is a VSCode extension like GitHub Copilot, which provides seamless code completions based on the user's code at the point of interruption.\n",
      "--------------------------------------------------------------------------------\n",
      "USER\n",
      "import os\n",
      "from aleph_alpha_client import Client, CompletionRequest, Prompt\n",
      "\n",
      "\n",
      "\n",
      "client = Client(os.\n",
      "--------------------------------------------------------------------------------\n",
      "ASSISTANT\n",
      "getenv(\"ALEPH_API_KEY\"))\n",
      "--------------------------------------------------------------------------------\n",
      "USER\n",
      "[INST]\n",
      "The completion you provided resulted in the following errors:\n",
      "your completion:6: error: Argument 1 to \"Client\" has incompatible type \"str | None\"; expected \"str\"  [arg-type]\n",
      "Found 1 error in 1 file (checked 1 source file)\n",
      "\n",
      "\n",
      "Fix, improve and rewrite your completion for the following code:\n",
      "[/INST]\n",
      "import os\n",
      "from aleph_alpha_client import Client, CompletionRequest, Prompt\n",
      "\n",
      "\n",
      "\n",
      "client = Client(os.\n",
      "--------------------------------------------------------------------------------\n",
      "ASSISTANT\n",
      "getenv(\"ALEPH_API_KEY\", \"\"))\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for message in llmcoder.messages:\n",
    "    print(message['role'].upper())\n",
    "    # Remove colors from the content of the message\n",
    "    message['content'] = re.sub(r'\\x1b[^m]*m', '', message['content'])\n",
    "    print(message['content'])\n",
    "    print('-' * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copilot:\n",
    "# from llmcoder import LLMCoder\n",
    "\n",
    "# # Create an LLMCoder with a random seed of 0\n",
    "# llmcoder = LLMCoder(0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llmcoder",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
